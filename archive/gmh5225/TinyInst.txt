Project Path: arc_gmh5225_TinyInst_8f_uld0u

Source Tree:

```txt
arc_gmh5225_TinyInst_8f_uld0u
├── CMakeLists.txt
├── CONTRIBUTING.md
├── LICENSE
├── README.md
├── Windows
│   ├── debugger.cpp
│   ├── debugger.h
│   ├── winunwind.cpp
│   └── winunwind.h
├── arch
│   ├── arm64
│   │   ├── arm64_assembler.cpp
│   │   ├── arm64_assembler.h
│   │   ├── arm64_helpers.cpp
│   │   ├── arm64_helpers.h
│   │   ├── arm64_litecov.cpp
│   │   └── reg.h
│   └── x86
│       ├── reg.h
│       ├── x86_assembler.cpp
│       ├── x86_assembler.h
│       ├── x86_helpers.cpp
│       ├── x86_helpers.h
│       └── x86_litecov.cpp
├── assembler.h
├── common.cpp
├── common.h
├── coverage.cpp
├── coverage.h
├── instruction.h
├── litecov.cpp
├── litecov.h
├── macOS
│   ├── README.md
│   ├── debugger.cpp
│   ├── debugger.h
│   ├── dyld_cache_map_parser.cpp
│   ├── dyld_cache_map_parser.h
│   ├── machtarget.cpp
│   ├── machtarget.h
│   ├── mig.defs
│   ├── unwindmacos.cpp
│   └── unwindmacos.h
├── third_party
│   ├── CMakeLists.txt
│   ├── llvm
│   │   ├── LEB128.h
│   │   ├── LICENSE.TXT
│   │   └── libunwind
│   │       ├── CompactUnwinder.hpp
│   │       └── dwarf2.h
│   ├── mbuild
│   ├── reil
│   │   └── reil
│   │       └── aarch64
│   │           ├── decoder.cpp
│   │           ├── decoder.h
│   │           └── printer.cpp
│   └── xed
├── tinyinst-coverage.cpp
├── tinyinst.cpp
├── tinyinst.h
└── unwind.h

```

`CMakeLists.txt`:

```txt
# Copyright 2020 Google LLC
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     https://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

cmake_minimum_required(VERSION "3.1")
set (CMAKE_CXX_STANDARD 17)

# Determine whether TinyInst should be build for arm64 or x86
if(APPLE AND NOT DEFINED ${ARCHITECTURE})
  EXECUTE_PROCESS(COMMAND uname -m COMMAND tr -d '\n' OUTPUT_VARIABLE ARCHITECTURE)
  if(${ARCHITECTURE} MATCHES arm64)
    add_definitions(-DARM64)
  endif()
endif()

add_subdirectory(third_party)

project("tinyinst")

include_directories(${CMAKE_CURRENT_BINARY_DIR}/third_party/obj/wkit/include)

if(${ARCHITECTURE} MATCHES arm64)
  set (arch_specific_files
      arch/arm64/reg.h
      arch/arm64/arm64_helpers.h
      arch/arm64/arm64_helpers.cpp
      arch/arm64/arm64_assembler.h
      arch/arm64/arm64_assembler.cpp
      arch/arm64/arm64_litecov.cpp
  )
else()
  set (arch_specific_files
      arch/x86/reg.h
      arch/x86/x86_helpers.h
      arch/x86/x86_helpers.cpp
      arch/x86/x86_assembler.h
      arch/x86/x86_assembler.cpp
      arch/x86/x86_litecov.cpp
  )
endif()

set (cross_platform_files
     common.h
     common.cpp
     assembler.h
     instruction.h
     tinyinst.h
     tinyinst.cpp
     coverage.h
     coverage.cpp
     litecov.h
     litecov.cpp
     unwind.h
)

if (WIN32)
  set (platform_specific_files
       Windows/debugger.h
       Windows/debugger.cpp
       Windows/winunwind.cpp
       Windows/winunwind.h
  )
elseif (APPLE)
  if (${ARCHITECTURE} MATCHES arm64)
    set(CMAKE_REQUIRED_LINK_OPTIONS "-arch;arm64")
  endif()

  add_custom_command(
    OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_client.c
           ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_server.c
           ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_client.h
           ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_server.h
    COMMAND mig -user ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_client.c
                -server ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_server.c
                -header ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_client.h
                -sheader ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig_server.h
                ${CMAKE_CURRENT_SOURCE_DIR}/macOS/mig.defs
    COMMENT "Generating Mig files"
  )

  set (platform_specific_files
       macOS/debugger.h
       macOS/debugger.cpp
       macOS/machtarget.h
       macOS/machtarget.cpp
       macOS/mig_client.h
       macOS/mig_client.c
       macOS/mig_server.h
       macOS/mig_server.c
       macOS/unwindmacos.cpp
       macOS/unwindmacos.h
       macOS/dyld_cache_map_parser.cpp
       macOS/dyld_cache_map_parser.h
  )
endif()

add_library(tinyinst STATIC
  ${arch_specific_files}
  ${arch_specific_files}
  ${platform_specific_files}
  ${cross_platform_files}
)

target_include_directories(tinyinst PUBLIC
  ${CMAKE_CURRENT_SOURCE_DIR}
  ${CMAKE_CURRENT_BINARY_DIR}/third_party/obj/wkit/include
)

if((${ARCHITECTURE} MATCHES arm64) AND APPLE)
  add_dependencies(tinyinst reil)
  target_link_libraries(tinyinst reil)
else()
  add_dependencies(tinyinst xed)
  if (WIN32)
    target_link_libraries(tinyinst
                          ${CMAKE_CURRENT_BINARY_DIR}/third_party/obj/wkit/lib/xed.lib
                          Dbghelp.lib
    )
  elseif (APPLE)
    target_link_libraries(tinyinst
                          ${CMAKE_CURRENT_BINARY_DIR}/third_party/obj/wkit/lib/libxed.a
    )
  endif()
endif()

project("litecov")

add_executable(litecov
  tinyinst-coverage.cpp
)

target_link_libraries(litecov tinyinst)

```

`CONTRIBUTING.md`:

```md
# How to Contribute

We'd love to accept your patches and contributions to this project. There are
just a few small guidelines you need to follow.

## Contributor License Agreement

Contributions to this project must be accompanied by a Contributor License
Agreement. You (or your employer) retain the copyright to your contribution;
this simply gives us permission to use and redistribute your contributions as
part of the project. Head over to <https://cla.developers.google.com/> to see
your current agreements on file or to sign a new one.

You generally only need to submit a CLA once, so if you've already submitted one
(even if it was for a different project), you probably don't need to do it
again.

## Code reviews

All submissions, including submissions by project members, require review. We
use GitHub pull requests for this purpose. Consult
[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more
information on using pull requests.

## Community Guidelines

This project follows [Google's Open Source Community
Guidelines](https://opensource.google/conduct/).

```

`LICENSE`:

```

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

```

`README.md`:

```md
# TinyInst

```
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

## What is TinyInst?

TinyInst is a lightweight dynamic instrumentation library that can be used to instrument only selected module(s) in the process, while leaving the rest of the process to run natively. It is meant to be easy to understand, easy to hack on and easy to hack with. It is not designed to be compatible with all targets (more on that later).

### How does it compare to [DynamoRIO](https://dynamorio.org/) and [PIN](https://software.intel.com/en-us/articles/pintool)?

TinyInst is not meant as a replacement for complex instrumentation frameworks such as DynamoRIO and PIN, but rather an alternative for scenarios where a more lightweight solution would do. TinyInst assumes that the target is well-behaved (in the sense explained below) which is not the case for more complex frameworks. Thus, you probably won’t be able to successfully run TinyInst against malware as [was done with DynamoRIO previously](https://www.slideshare.net/MaximShudrak/fuzzing-malware-for-fun-profit-applying-coverageguided-fuzzing-to-find-bugs-in-modern-malware). On the other hand, if a target does not work with other frameworks due to the module that does not need to be instrumented, and the instrumented module is well-behaved, it might work with TinyInst. Because with TinyInst, most of the process will run natively, it will have shorter process startup time, and might outperform other solutions in cases where the target process spends a lot of time in the modules where instrumentation is not needed.

### How does it compare to [Mesos](https://github.com/gamozolabs/mesos) and [TrapFuzz](https://github.com/googleprojectzero/p0tools/tree/master/TrapFuzz)?

TinyInst is a full binary rewriting solution, so arbitrary behavior can be changed in the target module. This allows it, for example, to be able to extract edge coverage instead of only basic blocks. Additionally, TinyInst does not depend on other software, such as IDA Pro, to identify basic blocks.

### Which operating system does TinyInst support?

TinyInst is available on Windows (32- and 64-bit) and macOS (64-bit) with some [limitations](https://github.com/googleprojectzero/TinyInst/tree/master/macOS).

### Which targets are compatible with TinyInst?

TinyInst assumes all instrumented modules are well-behaved in the sense that

- There is no self-modifying code
- Return address on the stack is never accessed by the program directly
OR/AND (depending on the settings)
- No data is ever stored before the top of the stack (on addresses lower than pointed to by ESP/RSP). This condition can be relaxed into "no data before (ESP/RSP - arbitrary_offset)" using the `-stack_offset` flag.

TinyInst also requires DEP/NX to be enabled for the target process. If that is not already the case, you can use the `-force_dep` flag to force it on. However, in the unlikely case that the target genuinely needs DEP off to function properly, forcing it on might cause it to misbehave.

### What is the performance overhead?

According to early measurements on image decoding, on a well-behaving 64-bit target with default TinyInst settings, the performance overhead was around 15% without a client and about 20% with the example coverage-collecting client. Note that this does not include the timeout introduced by initially instrumented the modules. See performance tips below for more details.

## Building TinyInst

1. Open a terminal and set up your build environment (e.g. On Windows, run vcvars64.bat / vcvars32.bat)

2. Navigate to the directory containing the source

3. Run the following commands (change the generator according to the version of IDE and platform you want to build for):

#### Windows
```
mkdir build
cd build
cmake -G "Visual Studio 16 2019" -A x64 ..
cmake --build . --config Release
```

#### macOS
```
mkdir build
cd build
cmake -G Xcode ..
cmake --build . --config Release
```

Note #1: 64-bit build will also run against 32-bit targets

Note #2: Encountering problems creating a 32-bit build on 64-bit windows due to the environment not being properly set up and libraries missing? Open the generated .sln file in Visual Studio and build from there instead of running cmake --build. Also note that 64-bit build is going to work on 32-bit targets, so creating a 32-bit build might not be necessary.

## Using TinyInst

TinyInst is primarily meant to be used as a library inside other programs.

A TinyInst client is written as a subclass of the TinyInst class. The client can then override the API methods it needs. The API methods are defined below.

After the client is created, it must be initialized with command line options by calling

`void init(int argc, char **argv);`

The command line options are defined below and a client can also define their own. After that, to run and control an instrumented program, the following functions can be used.

`DebuggerStatus Run(int argc, char **argv, uint32_t timeout);`
`DebuggerStatus Attach(unsigned int pid, uint32_t timeout);`

These functions either run a program (using the specified command line) or attach to an already running program. If no target method is specified, the target will continue running until either the program exits, the program crashes, or the timeout (given in milliseconds) expires. If a target method is defined, TinyInst is going to return whenever the target method is entered and whenever target method returns, allowing the caller to perform additional tasks.

When `Run` and `Attach` return while the target process is still alive, the following functions can be used to either terminate the process or continue execution.

`DebuggerStatus Kill();`

`DebuggerStatus Continue(uint32_t timeout);`

TinyInst comes with an example coverage binary, which can be invoked using

`<options> -- <target command line>`

Example on Windows:

`litecov.exe -instrument_module notepad.exe -coverage_file coverage.txt -- notepad.exe`


## Instrumentation API

### Debugger event callbacks 

These callbacks are for information only and the client should not emit any instrumented code during them. Clients must call the same handler defined in the superclass before handling these events themselves.

`OnProcessCreated`
Called when the target process is created or attached.

`OnProcessExit`
Called when the target process exits.

`OnProcessEntrypoint`
Called when the process (main binary) entrypoint gets reached

`OnTargetMethodReached`
If the target method is defined, called when the target method is reached for the first time.

`OnModuleLoaded`
Called when a module is loaded. Called for each module, not just instrumented ones.

`OnModuleUnloaded`
Called when a module is unloaded. Called for each module, not just instrumented ones.

`OnException`
Called when an exception is encountered. The client must either return true (if the exception was handled) or the result of the same method on the parent class.

### Instrumentation callbacks

During these callbacks, the client can add code to the target by calling `WriteCode()`. Note that the client is responsible for saving and restoring any context (such as registers and flags clobbered in the inserted code).

`InstrumentBasicBlock`
Can be used to insert code that's going to run on a particular basic block

`InstrumentEdge`
Can be used to insert code that's going to run on a particular edge. Note: For performance reasons, this callback is only emitted on non-deterministic edges (i.e. conditional jumps) and indirect jumps/calls (e.g. `call rax`). For edges where the next basic block is always known given the previous basic block (e.g. `jmp offset`, `call offset`), no callback will be emitted.

`InstrumentInstruction`
Can be used to modify the instruction or insert code before it. Depending on the return code the original instruction is either going to be emitted or not after the callback.

### Other callbacks

`OnModuleEntered`
Called when a control flow is transferred into an instrumented module from another module

`OnModuleInstrumented`
Called when a module gets instrumented. This happens generally when the process entrypoint is reached (if the target method is not defined) or when the target method is reached (if it is defined). The client can initialize its instrumentation-related data here

`OnModuleUninstrumented`
Called when instrumentation data is no longer valid and needs to be cleared. Note that this is not the same as module being unloaded as, by default, instrumentation persists across module unloads / reloads. This callback can be used to clear any instrumentation-related data in the client.

## Command Line Options

### Instrumentation related

`-instrument_module [module name]` specifies which module to instrument, multiple `-instrument_module` options can be specified to instrument multiple modules.

`-indirect_instrumentation [none|local|global|auto]` which instrumentation to use for indirect jump/calls

`-patch_return_addresses` - replaces return address with the original value, causes returns to be instrumented using whatever `-indirect_instrumentation` method is specified

`-generate_unwind` - Generates stack unwinding data for instrumented code (for faster C++ exception handling). Note that it might not work correctly on some older Windows versions.

`-persist_instrumentation_data` (default = true) Does not reinstrument module on module unloads / reloads. Only works if the module is loaded on the same address it was loaded before.

`-instrument_cross_module_calls` (default=true) If multiple `-instrument_module` modules are specified and one calls into another, jump to instrumented code of the other module without causing an exception (which would cause slowdowns).

`-stack_offset` (default=0) When saving context on the stack, leave this many bytes on top of the stack (before stack pointer) unchanged.

`-patch_module_entries [off|data|code|all]` Attempts to resolve slowdowns due to excessive module entries by searching for pointers to previously detected entrypoints and replacing them with their instrumented counterparts. The value of the flag controls where to searh for these pointers. Warning: Enabling this could potentially introduce instabilities to the target.

### Debugging related

`-trace_debug_events` - prints debugger events (modules loaded, exceptions, etc.) 

`-trace_basic_blocks` - prints basic blocks as they get executed

`-trace_module_entries` - prints all entries into instrumented code

`-full_address_map` - Maintains an instruction-level map of addresses in instrumented code to addresses in the original code. Memory-heavy, but useful for debugging.

### Target method and persistence

TinyInst allows user to define a target method. If a target method is defined, no code will be instrumented (everything will run natively) until the target method is reached for the first time. Additionally, TinyInst will break execution on the target method entry and exit.

`-target_module` - module containing the target method

`-target_method` - name of the target method. This only works if the target method is exported or you have symbols for the target module.

`-target_offset` - use when target method can't be specified by name. Relative address of the target method from the module base

`-loop` - if this flag is specified, TinyInst will run the target method in an infinite loop (or until Kill() is called or process terminates for another reason). Function arguments will be saved and restored between iterations. This is mainly used to force persistence for fuzzing.

`-nargs` - number of target method arguments to save between iterations. To be used together with `-loop`

`-callcon [ms64|stdcall|fastcall|thiscall]` - calling convention target method uses. To be used together with `-loop`

### Other

`-target_env key=value` - [currently macOS only] specifies an additional environment variable to pass to the target process. Multiple `-target_env` options can be specified to pass multiple environment variables.

`-force_dep` - [Windows only] Force-enables DEP for the target process.

## Coverage module

TinyInst comes with an (example) coverage module, `LiteCov`. The coverage module can collect basic block or edge coverage (controlled using `-covtype` flag). In addition to this, the module can extract "compare" coverage (counting the number of bytes that match in cmp/sub instructions) by specifying the `-cmp_coverage` flag.

Special feature of the coverage module is that the coverage buffer in the target process is initially allocated as read-only, causing an exception the first time new coverage is encountered. Combined with an option to ignore a certain subset of coverage, this enables quickly querying if running the target with a given input resulted in new coverage or not.

## How TinyInst works?

TinyInst is built on top of a custom debugger. The debugger watches the target process for events such as modules being loaded, breakpoint being hit, exceptions being fired etc. The debugger also implements breakpoints and persistence if the target method is specified.

When a module to be instrumented is loaded, it is initially "instrumented" in the following way

- All executable regions in the module are marked as non-executable, while retaining other permissions (read/write) as they were originally. This causes an exception whenever control flow reaches an instrumented module, which is caught and handled by the debugger.

- An executable region of memory is allocated within 2GB of the original module address range. This is where the instrumented/rewritten code of the module will be placed. 2GB is important as it allows all instructions that use addressing in the form of [rip+offset] to be replaced with [rip+fixed_offset].

Whenever an instrumented module is entered (whether for the first time or any other time), the basic block that was hit is instrumented, together with all basic blocks that can be reliably discovered by recursively following conditional branches as well as direct calls and jumps (e.g. jmp offset, call offset).

This is sufficient to run the instrumented code because

- all direct jumps/calls will land in the instrumented code at the correct location

- all indirect jump/calls (e.g. call rax) will land in their original code location, which causes an exception, which the debugger resolves by replacing the instruction pointer with the corresponding location in the instrumented code.

However, while this works, note that it will cause an exception on every indirect call/jump whose target is in an instrumented module. Since exception handling is slow, instrumenting targets with a lot of indirection (e.g. virtual methods in C++, function pointers) will be slow without additional instrumentation.

### Instrumenting indirect calls and jumps

TinyInst can instrument indirect calls and jumps to avoid exceptions on (already-seen) indirect targets. An instrumented call/jump, instead of jumping to the original target, will instead jump to the head of the linked list of stubs. Each stub contains a pair of (original_target, translated_target). It tests if the jump/call target matches original_target, and if so, control flow is directed to translated_target. Otherwise, it jumps to the next stub. If the end of the list is reached, that means the jump/call target hasn’t been seen before. This will cause a breakpoint that is caught by the debugger, which will be resolved by creating another stub and inserting it into the list.

This mechanism can be implemented in 2 ways
- per-callsite (local) list
- global hashtable used by all indirect jumps/calls

Global hashtable results in better performance. Local (per-callsite list) allows getting correct edges (with correct source address) on indirect calls/jumps.

Note that on modern Windows, due to CFG, all indirect jump/calls happen from the same location, therefore with CFG-compiled binaries, it is impossible (without some kind of special handling) to get accurate edges anyway. This, along with the performance benefit, is the reason why global hashlist is the default method for handling indirect calls/jumps in TinyInst.

### Return address patching

By default, when a call happens in instrumented code, the return address being written is going to be the next instruction in the *instrumented code*. This works correctly in most cases, however it will cause problems if the target process ever accesses return addresses for purposes other than return. A notable example of this is stack unwinding during exception handling on 64-bit Windows and Mac. Therefore, targets that need to catch exceptions won’t work correctly with TinyInst by default.

This can be resolved in most cases by adding `-generate_unwind` flag, which causes TinyInst to generate and register stack unwinding / exception handling metadata for the target process. Note that `-generate_unwind` might not work correctly on some older Windows versions due to requiring UNWIND_INFO version 2.

TinyInst also has an option (exposed through `-patch_return_addresses` flag) to rewrite return addresses into their corresponding values in the non-instrumented code whenever a call occurs. Note however that this option introduces quite a large overhead, as it causes a context switch on every return (backwards edge) from an uninstrumented into an instrumented module.

## Performance tips

The biggest overhead in TinyInst comes from an exception being thrown whenever an instrumented module is entered from a non-instrumented module. You can see these exceptions being triggered using the `-trace_module_entries` flag. Indirect jump/call instrumentation should be used whenever possible and return instrumentation should not be used whenever possible. TinyInst performs best on modules (or module groups) that are reasonably self-contained. For example if you have two modules, A and B, where A calls B often but only B is instrumented, this will cause a lot of slowdown. Better performance could be achieved by instrumenting both A and B.

## Debugging tips

Use `-trace_basic_blocks` to see basic blocks as they are being executed. You’ll see both the addresses in the instrumented code and the corresponding addresses in the non-instrumented code.

Use the OnException() callback to examine program state when the crash occurs.

## Disclaimer

This is not an official Google product.



```

`Windows/debugger.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#define  _CRT_SECURE_NO_WARNINGS

#include <stdio.h>
#include <stdbool.h>
#include <inttypes.h>

#include "windows.h"
#include "psapi.h"
#include "dbghelp.h"

#include "../common.h"
#include "debugger.h"


#define CALLCONV_MICROSOFT_X64 0
#define CALLCONV_THISCALL 1
#define CALLCONV_FASTCALL 2
#define CALLCONV_CDECL 3
#define CALLCONV_DEFAULT 4

#define BREAKPOINT_UNKNOWN 0
#define BREAKPOINT_ENTRYPOINT 1
#define BREAKPOINT_TARGET 2

#define PERSIST_END_EXCEPTION 0x0F22

// cleans up all breakpoint structures
// does not actually remove breakpoints in target process 
void Debugger::DeleteBreakpoints() {
  for (auto iter = breakpoints.begin(); iter != breakpoints.end(); iter++) {
    delete *iter;
  }
  breakpoints.clear();
}

void Debugger::CreateException(EXCEPTION_RECORD *win_exception_record,
                               Exception *exception)
{
  switch (win_exception_record->ExceptionCode) {
  case EXCEPTION_BREAKPOINT:
  case 0x4000001f:
    exception->type = BREAKPOINT;
    break;
  case EXCEPTION_ACCESS_VIOLATION:
    exception->type = ACCESS_VIOLATION;
    break;
  case EXCEPTION_ILLEGAL_INSTRUCTION:
    exception->type = ILLEGAL_INSTRUCTION;
    break;
  case EXCEPTION_STACK_OVERFLOW:
    exception->type = STACK_OVERFLOW;
    break;
  default:
    exception->type = OTHER;
    break;
  }

  exception->ip = win_exception_record->ExceptionAddress;

  exception->maybe_execute_violation = false;
  exception->maybe_write_violation = false;
  exception->access_address = 0;
  if (win_exception_record->ExceptionCode == EXCEPTION_ACCESS_VIOLATION) {
    if (win_exception_record->ExceptionInformation[0] == 8) {
      exception->maybe_execute_violation = true;
    }
    if (win_exception_record->ExceptionInformation[0] == 1) {
      exception->maybe_write_violation = true;
    }

    exception->access_address = (void *)(win_exception_record->ExceptionInformation[1]);
  }
}

void Debugger::RetrieveThreadContext() {
  if (have_thread_context) return; // already done
  lcContext.ContextFlags = CONTEXT_ALL;
  HANDLE thread_handle = OpenThread(THREAD_ALL_ACCESS, FALSE, thread_id);
  GetThreadContext(thread_handle, &lcContext);
  CloseHandle(thread_handle);
  have_thread_context = true;
}

void Debugger::SaveRegisters(SavedRegisters* registers) {
  RetrieveThreadContext();
  memcpy(&registers->saved_context, &lcContext, sizeof(registers->saved_context));
}

void Debugger::RestoreRegisters(SavedRegisters* registers) {
  have_thread_context = false;
  HANDLE thread_handle = OpenThread(THREAD_ALL_ACCESS, FALSE, thread_id);
  if (!SetThreadContext(thread_handle, &lcContext)) {
    FATAL("Error restoring registers");
  }
  CloseHandle(thread_handle);
}

size_t Debugger::GetRegister(Register r) {
  RetrieveThreadContext();

#ifdef _WIN64

  switch (r) {
  case RAX:
    return lcContext.Rax;
  case RCX:
    return lcContext.Rcx;
  case RDX:
    return lcContext.Rdx;
  case RBX:
    return lcContext.Rbx;
  case RSP:
    return lcContext.Rsp;
  case RBP:
    return lcContext.Rbp;
  case RSI:
    return lcContext.Rsi;
  case RDI:
    return lcContext.Rdi;
  case R8:
    return lcContext.R8;
  case R9:
    return lcContext.R9;
  case R10:
    return lcContext.R10;
  case R11:
    return lcContext.R11;
  case R12:
    return lcContext.R12;
  case R13:
    return lcContext.R13;
  case R14:
    return lcContext.R14;
  case R15:
    return lcContext.R15;
  case RIP:
    return lcContext.Rip;
  default:
    FATAL("Unimplemented");
  }

#else

  switch (r) {
  case RAX:
    return lcContext.Eax;
  case RCX:
    return lcContext.Ecx;
  case RDX:
    return lcContext.Edx;
  case RBX:
    return lcContext.Ebx;
  case RSP:
    return lcContext.Esp;
  case RBP:
    return lcContext.Ebp;
  case RSI:
    return lcContext.Esi;
  case RDI:
    return lcContext.Edi;
  case RIP:
    return lcContext.Eip;
  default:
    FATAL("Unimplemented");
}

#endif

}

void Debugger::SetRegister(Register r, size_t value) {
  RetrieveThreadContext();

#ifdef _WIN64

  switch (r) {
  case RAX:
    lcContext.Rax = value;
    break;
  case RCX:
    lcContext.Rcx = value;
    break;
  case RDX:
    lcContext.Rdx = value;
    break;
  case RBX:
    lcContext.Rbx = value;
    break;
  case RSP:
    lcContext.Rsp = value;
    break;
  case RBP:
    lcContext.Rbp = value;
    break;
  case RSI:
    lcContext.Rsi = value;
    break;
  case RDI:
    lcContext.Rdi = value;
    break;
  case R8:
    lcContext.R8 = value;
    break;
  case R9:
    lcContext.R9 = value;
    break;
  case R10:
    lcContext.R10 = value;
    break;
  case R11:
    lcContext.R11 = value;
    break;
  case R12:
    lcContext.R12 = value;
    break;
  case R13:
    lcContext.R13 = value;
    break;
  case R14:
    lcContext.R14 = value;
    break;
  case R15:
    lcContext.R15 = value;
    break;
  case RIP:
    lcContext.Rip = value;
    break;
  default:
    FATAL("Unimplemented");
  }

#else

  switch (r) {
  case RAX:
    lcContext.Eax = value;
    break;
  case RCX:
    lcContext.Ecx = value;
    break;
  case RDX:
    lcContext.Edx = value;
    break;
  case RBX:
    lcContext.Ebx = value;
    break;
  case RSP:
    lcContext.Esp = value;
    break;
  case RBP:
    lcContext.Ebp = value;
    break;
  case RSI:
    lcContext.Esi = value;
    break;
  case RDI:
    lcContext.Edi = value;
    break;
  case RIP:
    lcContext.Eip = value;
    break;
  default:
    FATAL("Unimplemented");
  }

#endif

  HANDLE thread_handle = OpenThread(THREAD_ALL_ACCESS, FALSE, thread_id);
  SetThreadContext(thread_handle, &lcContext);
  CloseHandle(thread_handle);
}


// converts between MemoryProtection and Windows protection flags
DWORD Debugger::WindowsProtectionFlags(MemoryProtection protection) {
  switch (protection) {
  case READONLY:
    return PAGE_READONLY;
  case READWRITE:
    return PAGE_READWRITE;
  case READEXECUTE:
    return PAGE_EXECUTE_READ;
  case READWRITEEXECUTE:
    return PAGE_EXECUTE_READWRITE;
  default:
    FATAL("Unumplemented memory protection");
  }
}

// allocates memory within 2GB of memory region
// between region_min and region_max
void *Debugger::RemoteAllocateNear(uint64_t region_min,
  uint64_t region_max,
  size_t size,
  MemoryProtection protection,
  bool use_shared_memory)
{
  void *ret = NULL;

  // try before first
  uint64_t min_address = region_max;
  if (min_address < 0x80000000) min_address = 0;
  else min_address -= 0x80000000;
  uint64_t max_address = region_min;
  if (max_address < size) max_address = 0;
  else max_address -= size;

  ret = RemoteAllocateBefore(min_address,
    max_address,
    size,
    protection);

  if (ret) return ret;

  min_address = region_max;
  uint64_t address_range_max = 0xFFFFFFFFFFFFFFFFULL;
  if (child_ptr_size == 4) {
    address_range_max = 0xFFFFFFFFULL;
  }
  if ((address_range_max - 0x80000000) < region_min) {
    max_address = address_range_max - size;
  } else {
    max_address = region_min + 0x80000000 - size;
  }

  ret = RemoteAllocateAfter(min_address,
    max_address,
    size,
    protection);

  return ret;
}


// allocates memory in target process as close as possible
// to max_address, but at address larger than min_address
void *Debugger::RemoteAllocateBefore(uint64_t min_address,
  uint64_t max_address,
  size_t size,
  MemoryProtection protection)
{
  DWORD protection_flags = WindowsProtectionFlags(protection);

  MEMORY_BASIC_INFORMATION meminfobuf;
  void *ret_address = NULL;

  uint64_t cur_code = max_address;
  while (cur_code > min_address) {
    // Don't attempt allocating on the null page
    if (cur_code < 0x1000) break;

    size_t step = size;

    size_t query_ret = VirtualQueryEx(child_handle,
      (LPCVOID)cur_code,
      &meminfobuf,
      sizeof(MEMORY_BASIC_INFORMATION));
    if (!query_ret) break;

    if (meminfobuf.State == MEM_FREE) {
      if (meminfobuf.RegionSize >= size) {
        size_t address = (size_t)meminfobuf.BaseAddress +
          (meminfobuf.RegionSize - size);
        ret_address = VirtualAllocEx(child_handle,
          (LPVOID)address,
          size,
          MEM_COMMIT | MEM_RESERVE,
          protection_flags);
        if (ret_address) {
          if (((size_t)ret_address >= min_address) &&
            ((size_t)ret_address <= max_address)) {
            return ret_address;
          } else {
            return NULL;
          }
        }
      } else {
        step = size - meminfobuf.RegionSize;
      }
    }

    cur_code = (size_t)meminfobuf.BaseAddress;
    if (cur_code < step) break;
    else cur_code -= step;
  }

  return ret_address;
}

// allocates memory in target process as close as possible
// to min_address, but not higher than max_address
void *Debugger::RemoteAllocateAfter(uint64_t min_address,
  uint64_t max_address,
  size_t size,
  MemoryProtection protection)
{
  DWORD protection_flags = WindowsProtectionFlags(protection);

  MEMORY_BASIC_INFORMATION meminfobuf;
  void *ret_address = NULL;

  uint64_t cur_code = min_address;
  while (cur_code < max_address) {
    size_t query_ret = VirtualQueryEx(child_handle,
      (LPCVOID)cur_code,
      &meminfobuf,
      sizeof(MEMORY_BASIC_INFORMATION));
    if (!query_ret) break;

    if (meminfobuf.State == MEM_FREE) {
      size_t region_address = (size_t)meminfobuf.BaseAddress;
      size_t region_size = meminfobuf.RegionSize;
      // make sure we are allocating on an address that
      // is aligned according to allocation_granularity
      size_t alignment = region_address & (allocation_granularity - 1);
      if (alignment) {
        size_t offset = (allocation_granularity - alignment);
        region_address += offset;
        if (region_size > offset) {
          region_size -= offset;
        } else {
          region_size = 0;
        }
      }
      if (region_size >= size) {
        ret_address = VirtualAllocEx(child_handle,
          (LPVOID)region_address,
          size,
          MEM_COMMIT | MEM_RESERVE,
          protection_flags);
        if (ret_address) {
          if (((size_t)ret_address >= min_address) &&
            ((size_t)ret_address <= max_address)) {
            return ret_address;
          } else {
            return NULL;
          }
        }
      }
    }

    cur_code = (size_t)meminfobuf.BaseAddress + meminfobuf.RegionSize;
  }

  return ret_address;
}

void Debugger::RemoteFree(void *address, size_t size) {
  if (!child_handle) return;
  VirtualFreeEx(child_handle, address, 0, MEM_RELEASE);
}

void Debugger::RemoteWrite(void *address, void *buffer, size_t size) {
  SIZE_T size_written;
  if (WriteProcessMemory(
    child_handle,
    address,
    buffer,
    size,
    &size_written))
  {
    return;
  }

  // we need to (a) read page permissions
  // (b) make it writable, and (c) restore permissions
  DWORD oldProtect;
  if (!VirtualProtectEx(child_handle,
    address,
    size,
    PAGE_READWRITE,
    &oldProtect))
  {
    FATAL("Error in VirtualProtectEx");
  }

  if (!WriteProcessMemory(
    child_handle,
    address,
    buffer,
    size,
    &size_written))
  {
    FATAL("Error writing target memory\n");
  }

  DWORD ignore;
  if (!VirtualProtectEx(child_handle,
    address,
    size,
    oldProtect,
    &ignore))
  {
    FATAL("Error in VirtualProtectEx");
  }
}

void Debugger::RemoteRead(void *address, void *buffer, size_t size) {
  SIZE_T size_read;
  if (!ReadProcessMemory(
    child_handle,
    address,
    buffer,
    size,
    &size_read))
  {
    FATAL("Error reading target memory\n");
  }
}

void Debugger::RemoteProtect(void *address, size_t size, MemoryProtection protect) {
  DWORD protection_flags = WindowsProtectionFlags(protect);
  DWORD old_protect;

  if (!VirtualProtectEx(child_handle,
    address,
    size,
    protection_flags,
    &old_protect))
  {
    FATAL("Could not apply memory protection");
  }
}


// detects executable memory regions in the module
// makes them non-executable
// and copies code out into this process
void Debugger::ExtractCodeRanges(void *module_base,
                                 size_t min_address,
                                 size_t max_address,
                                 std::list<AddressRange> *executable_ranges,
                                 size_t *code_size)
{
  LPCVOID end_address = (char *)max_address;
  LPCVOID cur_address = module_base;
  MEMORY_BASIC_INFORMATION meminfobuf;

  AddressRange newRange;

  for (auto iter = executable_ranges->begin();
    iter != executable_ranges->end(); iter++)
  {
    free(iter->data);
  }
  executable_ranges->clear();
  *code_size = 0;

  while (cur_address < end_address) {
    size_t ret = VirtualQueryEx(child_handle,
      cur_address,
      &meminfobuf,
      sizeof(MEMORY_BASIC_INFORMATION));
    if (!ret) break;

    if (meminfobuf.Protect & 0xF0) {
      // printf("%p, %llx, %lx\n", meminfobuf.BaseAddress, meminfobuf.RegionSize, meminfobuf.Protect);

      SIZE_T size_read;
      newRange.data = (char *)malloc(meminfobuf.RegionSize);
      if (!ReadProcessMemory(child_handle,
        meminfobuf.BaseAddress,
        newRange.data,
        meminfobuf.RegionSize,
        &size_read))
      {
        FATAL("Error in ReadProcessMemory");
      }
      if (size_read != meminfobuf.RegionSize) {
        FATAL("Error in ReadProcessMemory");
      }

      uint8_t low = meminfobuf.Protect & 0xFF;
      low = low >> 4;
      DWORD newProtect = (meminfobuf.Protect & 0xFFFFFF00) + low;
      DWORD oldProtect;
      if (!VirtualProtectEx(child_handle,
        meminfobuf.BaseAddress,
        meminfobuf.RegionSize,
        newProtect,
        &oldProtect))
      {
        FATAL("Error in VirtualProtectEx");
      }

      newRange.from = (size_t)meminfobuf.BaseAddress;
      newRange.to = (size_t)meminfobuf.BaseAddress + meminfobuf.RegionSize;
      executable_ranges->push_back(newRange);

      *code_size += newRange.to - newRange.from;
    }

    cur_address = (char *)meminfobuf.BaseAddress + meminfobuf.RegionSize;
  }
}

// sets all pages containing (previously detected)
// code to non-executable
void Debugger::ProtectCodeRanges(std::list<AddressRange> *executable_ranges) {
  MEMORY_BASIC_INFORMATION meminfobuf;

  for (auto iter = executable_ranges->begin();
    iter != executable_ranges->end(); iter++)
  {
    size_t ret = VirtualQueryEx(child_handle,
      (void *)iter->from,
      &meminfobuf,
      sizeof(MEMORY_BASIC_INFORMATION));

    // if the module was already instrumented, everything must be the same as before
    if (!ret) {
      FATAL("Error in ProtectCodeRanges."
        "Target incompatible with persist_instrumentation_data");
    }
    if (iter->from != (size_t)meminfobuf.BaseAddress) {
      FATAL("Error in ProtectCodeRanges."
        "Target incompatible with persist_instrumentation_data");
    }
    if (iter->to != (size_t)meminfobuf.BaseAddress + meminfobuf.RegionSize) {
      FATAL("Error in ProtectCodeRanges."
        "Target incompatible with persist_instrumentation_data");
    }
    if (!(meminfobuf.Protect & 0xF0)) {
      FATAL("Error in ProtectCodeRanges."
        "Target incompatible with persist_instrumentation_data");
    }

    uint8_t low = meminfobuf.Protect & 0xFF;
    low = low >> 4;
    DWORD newProtect = (meminfobuf.Protect & 0xFFFFFF00) + low;
    DWORD oldProtect;
    if (!VirtualProtectEx(child_handle,
      meminfobuf.BaseAddress,
      meminfobuf.RegionSize,
      newProtect,
      &oldProtect))
    {
      FATAL("Error in VirtualProtectEx");
    }
  }
}

void Debugger::PatchPointersRemote(size_t min_address, size_t max_address, std::unordered_map<size_t, size_t>& search_replace) {
  if (child_ptr_size == 4) {
    PatchPointersRemoteT<uint32_t>(min_address, max_address, search_replace);
  } else {
    PatchPointersRemoteT<uint64_t>(min_address, max_address, search_replace);
  }
}

template<typename T>
void Debugger::PatchPointersRemoteT(size_t min_address, size_t max_address, std::unordered_map<size_t, size_t>& search_replace) {
  size_t module_size = max_address - min_address;
  char* buf = (char *)malloc(module_size);
  RemoteRead((void *)min_address, buf, module_size);

  size_t remote_address = min_address;
  for (size_t i = 0; i < (module_size - child_ptr_size + 1); i++) {
    T ptr = *(T *)(buf + i);
    auto iter = search_replace.find(ptr);
    if (iter != search_replace.end()) {
      // printf("patching entry %zx at address %zx\n", (size_t)ptr, remote_address);
      T fixed_ptr = (T)iter->second;
      RemoteWrite((void *)remote_address, &fixed_ptr, child_ptr_size);
    }
    remote_address += 1;
  }

  free(buf);
}

// returns an array of handles for all modules loaded in the target process
DWORD Debugger::GetLoadedModules(HMODULE **modules) {
  DWORD module_handle_storage_size = 1024 * sizeof(HMODULE);
  HMODULE *module_handles = (HMODULE *)malloc(module_handle_storage_size);
  DWORD hmodules_size;
  while (true) {
    if (!EnumProcessModulesEx(child_handle,
                              module_handles,
                              module_handle_storage_size,
                              &hmodules_size,
                              LIST_MODULES_ALL))
    {
      FATAL("EnumProcessModules failed, %x\n", GetLastError());
    }
    if (hmodules_size <= module_handle_storage_size) break;
    module_handle_storage_size *= 2;
    module_handles = (HMODULE *)realloc(module_handles, module_handle_storage_size);
  }
  *modules = module_handles;
  return hmodules_size / sizeof(HMODULE);
}

// parses PE headers and gets the module entypoint
void *Debugger::GetModuleEntrypoint(void *base_address) {
  unsigned char headers[4096];
  SIZE_T num_read = 0;
  if (!ReadProcessMemory(child_handle, base_address, headers, 4096, &num_read) ||
     (num_read != 4096))
  {
    FATAL("Error reading target memory\n");
  }
  DWORD pe_offset;
  pe_offset = *((DWORD *)(headers + 0x3C));
  unsigned char *pe = headers + pe_offset;
  DWORD signature = *((DWORD *)pe);
  if (signature != 0x00004550) {
    FATAL("PE signature error\n");
  }
  pe = pe + 0x18;
  WORD magic = *((WORD *)pe);
  if ((magic != 0x10b) && (magic != 0x20b)) {
    FATAL("Unknown PE magic value\n");
  }
  DWORD entrypoint_offset = *((DWORD *)(pe + 16));
  if (entrypoint_offset == 0) return NULL;
  return (char *)base_address + entrypoint_offset;
}

// parses PE headers and gets the image size
DWORD Debugger::GetImageSize(void *base_address) {
  unsigned char headers[4096];
  SIZE_T num_read = 0;
  if (!ReadProcessMemory(child_handle, base_address, headers, 4096, &num_read) ||
    (num_read != 4096))
  {
    FATAL("Error reading target memory\n");
  }
  DWORD pe_offset;
  pe_offset = *((DWORD *)(headers + 0x3C));
  unsigned char *pe = headers + pe_offset;
  DWORD signature = *((DWORD *)pe);
  if (signature != 0x00004550) {
    FATAL("PE signature error\n");
  }
  pe = pe + 0x18;
  WORD magic = *((WORD *)pe);
  if ((magic != 0x10b) && (magic != 0x20b)) {
    FATAL("Unknown PE magic value\n");
  }
  DWORD SizeOfImage = *((DWORD *)(pe + 56));
  return SizeOfImage;
}


// parses PE headers and gets the image size
void Debugger::GetImageSize(void *base_address, size_t *min_address, size_t *max_address) {
  *min_address = (size_t)base_address;
  DWORD SizeOfImage = GetImageSize(base_address);
  *max_address = *min_address + SizeOfImage;
}

// adds a one-time breakpoint at a specified address
// type, is an arbitrary int
// that can be accessed later when the breakpoint gets hit
void Debugger::AddBreakpoint(void *address, int type) {
  Breakpoint *new_breakpoint = new Breakpoint;
  SIZE_T rwsize = 0;
  if (!ReadProcessMemory(child_handle, address, &(new_breakpoint->original_opcode), 1, &rwsize) ||
     (rwsize != 1)) {
    FATAL("Error reading target memory\n");
  }
  rwsize = 0;
  unsigned char cc = 0xCC;
  if (!WriteProcessMemory(child_handle, address, &cc, 1, &rwsize) || (rwsize != 1)) {
    FATAL("Error writing target memory\n");
  }
  FlushInstructionCache(child_handle, address, 1);
  new_breakpoint->address = address;
  new_breakpoint->type = type;
  breakpoints.push_back(new_breakpoint);
}

// damn it Windows, why don't you have a GetProcAddress
// that works on another process
DWORD Debugger::GetProcOffset(HMODULE module, const char *name) {
  char* base_of_dll = (char*)module;
  DWORD size_of_image = GetImageSize(base_of_dll);

  // try the exported symbols next
  char* modulebuf = (char*)malloc(size_of_image);
  SIZE_T num_read;
  if (!ReadProcessMemory(child_handle, base_of_dll, modulebuf, size_of_image, &num_read) ||
    (num_read != size_of_image))
  {
    FATAL("Error reading target memory\n");
  }

  DWORD pe_offset;
  pe_offset = *((DWORD *)(modulebuf + 0x3C));
  char *pe = modulebuf + pe_offset;
  DWORD signature = *((DWORD *)pe);
  if (signature != 0x00004550) {
    free(modulebuf);
    return 0;
  }
  pe = pe + 0x18;
  WORD magic = *((WORD *)pe);
  DWORD exporttableoffset;
  if (magic == 0x10b) {
    exporttableoffset = *(DWORD *)(pe + 96);
  } else if (magic == 0x20b) {
    exporttableoffset = *(DWORD *)(pe + 112);
  } else {
    free(modulebuf);
    return 0;
  }

  if (!exporttableoffset) {
    free(modulebuf);
    return 0;
  }

  char *exporttable = modulebuf + exporttableoffset;

  DWORD numentries = *(DWORD *)(exporttable + 24);
  DWORD addresstableoffset = *(DWORD *)(exporttable + 28);
  DWORD nameptrtableoffset = *(DWORD *)(exporttable + 32);
  DWORD ordinaltableoffset = *(DWORD *)(exporttable + 36);
  DWORD *nameptrtable = (DWORD *)(modulebuf + nameptrtableoffset);
  WORD *ordinaltable = (WORD *)(modulebuf + ordinaltableoffset);
  DWORD *addresstable = (DWORD *)(modulebuf + addresstableoffset);

  DWORD i;
  for (i = 0; i < numentries; i++) {
    char *nameptr = modulebuf + nameptrtable[i];
    if (strcmp(name, nameptr) == 0) break;
  }

  if (i == numentries) {
    free(modulebuf);
    return 0;
  }

  WORD oridnal = ordinaltable[i];
  DWORD offset = addresstable[oridnal];

  free(modulebuf);
  return offset;
}

// Gets the registered safe exception handlers for the module
void Debugger::GetExceptionHandlers(size_t module_haeder, std::unordered_set <size_t>& handlers) {
  // only present on x86
  if (child_ptr_size != 4) return;

  DWORD size_of_image = GetImageSize((void *)module_haeder);

  char* modulebuf = (char*)malloc(size_of_image);
  SIZE_T num_read;
  if (!ReadProcessMemory(child_handle, (void *)module_haeder, modulebuf, size_of_image, &num_read) ||
    (num_read != size_of_image))
  {
    FATAL("Error reading target memory\n");
  }

  DWORD pe_offset;
  pe_offset = *((DWORD*)(modulebuf + 0x3C));
  char* pe = modulebuf + pe_offset;
  DWORD signature = *((DWORD*)pe);
  if (signature != 0x00004550) {
    free(modulebuf);
    return;
  }
  pe = pe + 0x18;
  WORD magic = *((WORD*)pe);
  DWORD lc_offset;
  DWORD lc_size;
  if (magic == 0x10b) {
    lc_offset = *(DWORD*)(pe + 176);
    lc_size = *(DWORD*)(pe + 180);
  } else if (magic == 0x20b) {
    lc_offset = *(DWORD*)(pe + 192);
    lc_size = *(DWORD*)(pe + 196);
  } else {
    free(modulebuf);
    return;
  }

  if (!lc_offset || (lc_size != 64)) {
    free(modulebuf);
    return;
  }

  char* lc = modulebuf + lc_offset;

  size_t seh_table_address;
  DWORD seh_count;
  if (magic == 0x10b) {
    seh_table_address = *(DWORD*)(lc + 64);
    seh_count = *(DWORD*)(lc + 68);
  } else if (magic == 0x20b) {
    seh_table_address = *(uint64_t*)(lc + 96);
    seh_count = *(DWORD*)(lc + 104);
  } else {
    free(modulebuf);
    return;
  }

  size_t seh_table_offset = seh_table_address - module_haeder;

  DWORD* seh_table = (DWORD *)(modulebuf + seh_table_offset);
  for (DWORD i = 0; i < seh_count; i++) {
    handlers.insert(module_haeder + seh_table[i]);
  }

  free(modulebuf);
}

// attempt to obtain the address of target function
// in various ways
char *Debugger::GetTargetAddress(HMODULE module) {
  char* base_of_dll = (char *)module;

  // if persist_offset is defined, use that
  if (target_offset) {
    return base_of_dll + target_offset;
  }

  DWORD offset = GetProcOffset(module, target_method.c_str());
  if (offset) {
    return (char *)module + offset;
  }

  // finally, try the debug symbols
  char *method_address = NULL;
  char base_name[MAX_PATH];
  GetModuleBaseNameA(child_handle,
                     module,
                     (LPSTR)(&base_name),
                     sizeof(base_name));

  char module_path[MAX_PATH];
  if (!GetModuleFileNameExA(child_handle,
                            module,
                            module_path,
                            sizeof(module_path)))
    return NULL;

  ULONG64 buffer[(sizeof(SYMBOL_INFO) +
    MAX_SYM_NAME * sizeof(TCHAR) +
    sizeof(ULONG64) - 1) /
    sizeof(ULONG64)];
  PSYMBOL_INFO pSymbol = (PSYMBOL_INFO)buffer;
  pSymbol->SizeOfStruct = sizeof(SYMBOL_INFO);
  pSymbol->MaxNameLen = MAX_SYM_NAME;
  SymInitialize(child_handle, NULL, false);
  DWORD64 sym_base_address = SymLoadModuleEx(child_handle,
                                             NULL,
                                             module_path,
                                             NULL,
                                             0,
                                             0,
                                             NULL,
                                             0);
  if (SymFromName(child_handle, target_method.c_str(), pSymbol)) {
    target_offset = (unsigned long)(pSymbol->Address - sym_base_address);
    method_address = base_of_dll + target_offset;
  }
  SymCleanup(child_handle);

  return method_address;
}

// called when a module gets loaded
void Debugger::OnModuleLoaded(void *module, char *module_name) {
  // printf("In on_module_loaded, name: %s, base: %p\n", module_name, module_info.lpBaseOfDll);

  if (target_function_defined && _stricmp(module_name, target_module.c_str()) == 0) {
    target_address = GetTargetAddress((HMODULE)module);
    if (!target_address) {
      FATAL("Error determining target method address\n");
    }

    AddBreakpoint(target_address, BREAKPOINT_TARGET);
  }
}

// called when a module gets unloaded
void Debugger::OnModuleUnloaded(void *module) { }

// reads numitems entries from stack in remote process
// from stack_addr
// into buffer
void Debugger::ReadStack(void *stack_addr, void **buffer, size_t numitems) {
  SIZE_T numrw = 0;
#ifdef _WIN64
  if (wow64_target) {
    uint32_t *buf32 = (uint32_t *)malloc(numitems * child_ptr_size);
    ReadProcessMemory(child_handle, stack_addr, buf32, numitems * child_ptr_size, &numrw);
    for (size_t i = 0; i < numitems; i++) {
      buffer[i] = (void *)((size_t)buf32[i]);
    }
    free(buf32);
    return;
  }
#endif
  ReadProcessMemory(child_handle, stack_addr, buffer, numitems * child_ptr_size, &numrw);
}

// writes numitems entries to stack in remote process
// from buffer
// into stack_addr
void Debugger::WriteStack(void *stack_addr, void **buffer, size_t numitems) {
  SIZE_T numrw = 0;
#ifdef _WIN64
  if (wow64_target) {
    uint32_t *buf32 = (uint32_t *)malloc(numitems * child_ptr_size);
    for (size_t i = 0; i < numitems; i++) {
      buf32[i] = (uint32_t)((size_t)buffer[i]);
    }
    WriteProcessMemory(child_handle, stack_addr, buf32, numitems * child_ptr_size, &numrw);
    free(buf32);
    return;
  }
#endif
  WriteProcessMemory(child_handle, stack_addr, buffer, numitems * child_ptr_size, &numrw);
}

// called when the target method is reached
void Debugger::HandleTargetReachedInternal() {
  // printf("in OnTargetMethod\n");

  SIZE_T numrw = 0;

  CONTEXT lcContext;
  lcContext.ContextFlags = CONTEXT_ALL;
  HANDLE thread_handle = OpenThread(THREAD_ALL_ACCESS, FALSE, thread_id);
  GetThreadContext(thread_handle, &lcContext);

  // read out and save the params
#ifdef _WIN64
  saved_sp = (void *)lcContext.Rsp;
#else
  saved_sp = (void *)lcContext.Esp;
#endif

  saved_return_address = 0;
  ReadProcessMemory(child_handle, saved_sp, &saved_return_address, child_ptr_size, &numrw);

  if (loop_mode) {
    switch (calling_convention) {
#ifdef _WIN64
    case CALLCONV_DEFAULT:
    case CALLCONV_MICROSOFT_X64:
      if (target_num_args > 0) saved_args[0] = (void *)lcContext.Rcx;
      if (target_num_args > 1) saved_args[1] = (void *)lcContext.Rdx;
      if (target_num_args > 2) saved_args[2] = (void *)lcContext.R8;
      if (target_num_args > 3) saved_args[3] = (void *)lcContext.R9;
      if (target_num_args > 4) {
        ReadStack((void *)(lcContext.Rsp + 5 * child_ptr_size), saved_args + 4, target_num_args - 4);
      }
      break;
    case CALLCONV_CDECL:
      if (target_num_args > 0) {
        ReadStack((void *)(lcContext.Rsp + child_ptr_size), saved_args, target_num_args);
      }
      break;
    case CALLCONV_FASTCALL:
      if (target_num_args > 0) saved_args[0] = (void *)lcContext.Rcx;
      if (target_num_args > 1) saved_args[1] = (void *)lcContext.Rdx;
      if (target_num_args > 3) {
        ReadStack((void *)(lcContext.Rsp + child_ptr_size), saved_args + 2, target_num_args - 2);
      }
      break;
    case CALLCONV_THISCALL:
      if (target_num_args > 0) saved_args[0] = (void *)lcContext.Rcx;
      if (target_num_args > 3) {
        ReadStack((void *)(lcContext.Rsp + child_ptr_size), saved_args + 1, target_num_args - 1);
      }
      break;
#else
    case CALLCONV_MICROSOFT_X64:
      FATAL("X64 callong convention not supported for 32-bit targets");
      break;
    case CALLCONV_DEFAULT:
    case CALLCONV_CDECL:
      if (target_num_args > 0) {
        ReadStack((void *)(lcContext.Esp + child_ptr_size), saved_args, target_num_args);
      }
      break;
    case CALLCONV_FASTCALL:
      if (target_num_args > 0) saved_args[0] = (void *)lcContext.Ecx;
      if (target_num_args > 1) saved_args[1] = (void *)lcContext.Edx;
      if (target_num_args > 3) {
        ReadStack((void *)(lcContext.Esp + child_ptr_size), saved_args + 2, target_num_args - 2);
      }
      break;
    case CALLCONV_THISCALL:
      if (target_num_args > 0) saved_args[0] = (void *)lcContext.Ecx;
      if (target_num_args > 3) {
        ReadStack((void *)(lcContext.Esp + child_ptr_size), saved_args + 1, target_num_args - 1);
      }
      break;
#endif
    default:
      break;
    }

    // todo store any target-specific additional context here
  }

  // modify the return address on the stack so that an exception is triggered
  // when the target function finishes executing
  // another option would be to allocate a block of executable memory
  // and point return address over there, but this is quicker
  size_t return_address = PERSIST_END_EXCEPTION;
  WriteProcessMemory(child_handle, saved_sp, &return_address, child_ptr_size, &numrw);

  CloseHandle(thread_handle);

  if (!target_reached) {
    target_reached = true;
    OnTargetMethodReached();
  }
}

// called every time the target method returns
void Debugger::HandleTargetEnded() {
  // printf("in OnTargetMethodEnded\n");

  CONTEXT lcContext;
  lcContext.ContextFlags = CONTEXT_ALL;
  HANDLE thread_handle = OpenThread(THREAD_ALL_ACCESS, FALSE, thread_id);
  GetThreadContext(thread_handle, &lcContext);

#ifdef _WIN64
  target_return_value = (uint64_t)lcContext.Rax;
#else
  target_return_value = (uint64_t)lcContext.Eax;
#endif

  if (loop_mode) {
    // restore params
#ifdef _WIN64
    lcContext.Rip = (size_t)target_address;
    lcContext.Rsp = (size_t)saved_sp;
#else
    lcContext.Eip = (size_t)target_address;
    lcContext.Esp = (size_t)saved_sp;
#endif

    // restore return address as it might have been overwritten by instrumentation
    SIZE_T numrw = 0;
    size_t return_address = PERSIST_END_EXCEPTION;
    WriteProcessMemory(child_handle, saved_sp, &return_address, child_ptr_size, &numrw);

    switch (calling_convention) {
#ifdef _WIN64
    case CALLCONV_DEFAULT:
    case CALLCONV_MICROSOFT_X64:
      if (target_num_args > 0) lcContext.Rcx = (size_t)saved_args[0];
      if (target_num_args > 1) lcContext.Rdx = (size_t)saved_args[1];
      if (target_num_args > 2) lcContext.R8 = (size_t)saved_args[2];
      if (target_num_args > 3) lcContext.R9 = (size_t)saved_args[3];
      if (target_num_args > 4) {
        WriteStack((void *)(lcContext.Rsp + 5 * child_ptr_size), saved_args + 4, target_num_args - 4);
      }
      break;
    case CALLCONV_CDECL:
      if (target_num_args > 0) {
        WriteStack((void *)(lcContext.Rsp + child_ptr_size), saved_args, target_num_args);
      }
      break;
    case CALLCONV_FASTCALL:
      if (target_num_args > 0) lcContext.Rcx = (size_t)saved_args[0];
      if (target_num_args > 1) lcContext.Rdx = (size_t)saved_args[1];
      if (target_num_args > 3) {
        WriteStack((void *)(lcContext.Rsp + child_ptr_size), saved_args + 2, target_num_args - 2);
      }
      break;
    case CALLCONV_THISCALL:
      if (target_num_args > 0) lcContext.Rcx = (size_t)saved_args[0];
      if (target_num_args > 3) {
        WriteStack((void *)(lcContext.Rsp + child_ptr_size), saved_args + 1, target_num_args - 1);
      }
      break;
#else
    case CALLCONV_MICROSOFT_X64:
      FATAL("X64 callong convention not supported for 32-bit targets");
      break;
    case CALLCONV_DEFAULT:
    case CALLCONV_CDECL:
      if (target_num_args > 0) {
        WriteStack((void *)(lcContext.Esp + child_ptr_size), saved_args, target_num_args);
      }
      break;
    case CALLCONV_FASTCALL:
      if (target_num_args > 0) lcContext.Ecx = (size_t)saved_args[0];
      if (target_num_args > 1) lcContext.Edx = (size_t)saved_args[1];
      if (target_num_args > 3) {
        WriteStack((void *)(lcContext.Esp + child_ptr_size), saved_args + 2, target_num_args - 2);
      }
      break;
    case CALLCONV_THISCALL:
      if (target_num_args > 0) lcContext.Ecx = (size_t)saved_args[0];
      if (target_num_args > 3) {
        WriteStack((void *)(lcContext.Esp + child_ptr_size), saved_args + 1, target_num_args - 1);
      }
      break;
#endif
    default:
      break;
    }

    // todo restore any target-specific additional context here

  } else { /*  loop_mode == false */

#ifdef _WIN64
    lcContext.Rip = (size_t)saved_return_address;
#else
    lcContext.Eip = (size_t)saved_return_address;
#endif

    // restore target entry breakpoint
    // note that this time, the breakpoint address might be
    // in instrumented code
    // so we need to use translated address
    AddBreakpoint((void *)GetTranslatedAddress((size_t)target_address),
                  BREAKPOINT_TARGET);
  }

  SetThreadContext(thread_handle, &lcContext);
  CloseHandle(thread_handle);
}

// called when process entrypoint gets reached
void Debugger::OnEntrypoint() {
  // printf("Entrypoint\n");

  HMODULE *module_handles = NULL;
  DWORD num_modules = GetLoadedModules(&module_handles);
  for (DWORD i = 0; i < num_modules; i++) {
    char base_name[MAX_PATH];
    GetModuleBaseNameA(child_handle, module_handles[i], (LPSTR)(&base_name), sizeof(base_name));
    if(trace_debug_events)
      printf("Debugger: Loaded module %s at %p\n", base_name, (void *)module_handles[i]);
    OnModuleLoaded((void *)module_handles[i], base_name);
  }
  if (module_handles) free(module_handles);

  child_entrypoint_reached = true;

  if (trace_debug_events) printf("Debugger: Process entrypoint reached\n");
}

// called when the debugger hits a breakpoint
int Debugger::HandleDebuggerBreakpoint(void *address) {
  int ret = BREAKPOINT_UNKNOWN;
  SIZE_T rwsize = 0;

  Breakpoint *breakpoint = NULL, *tmp_breakpoint;
  for (auto iter = breakpoints.begin(); iter != breakpoints.end(); iter++) {
    tmp_breakpoint = *iter;
    if (tmp_breakpoint->address == address) {
      breakpoint = tmp_breakpoint;
      breakpoints.erase(iter);
      break;
    }
  }

  if (!breakpoint) return ret;

  // restore address
  if (!WriteProcessMemory(child_handle, address, &breakpoint->original_opcode, 1, &rwsize) ||
     (rwsize != 1))
  {
    FATAL("Error writing child memory\n");
  }
  FlushInstructionCache(child_handle, address, 1);
  // restore context
  CONTEXT lcContext;
  lcContext.ContextFlags = CONTEXT_ALL;
  HANDLE thread_handle = OpenThread(THREAD_ALL_ACCESS, FALSE, thread_id);
  GetThreadContext(thread_handle, &lcContext);
#ifdef _WIN64
  lcContext.Rip--;
#else
  lcContext.Eip--;
#endif
  SetThreadContext(thread_handle, &lcContext);
  CloseHandle(thread_handle);
  // handle breakpoint
  switch (breakpoint->type) {
  case BREAKPOINT_ENTRYPOINT:
    OnEntrypoint();
    break;
  case BREAKPOINT_TARGET:
    if (trace_debug_events) printf("Target method reached\n");
    HandleTargetReachedInternal();
    break;
  default:
    break;
  }

  // return the brekpoint type
  ret = breakpoint->type;

  // delete the breakpoint object
  free(breakpoint);

  return ret;
}

// called when a dll gets loaded
void Debugger::HandleDllLoadInternal(LOAD_DLL_DEBUG_INFO *LoadDll) {
  // Don't do anything until the processentrypoint is reached.
  // Before that time we can't do much anyway, a lot of calls are going to fail
  // Modules loaded before entrypoint is reached are going to be enumerated at that time
  if (child_entrypoint_reached) {
    char filename[MAX_PATH];
    GetFinalPathNameByHandleA(LoadDll->hFile, (LPSTR)(&filename), sizeof(filename), 0);
    char *base_name = strrchr(filename, '\\');
    if (base_name) base_name += 1;
    else base_name = filename;
    if (trace_debug_events)
      printf("Debugger: Loaded module %s at %p\n",
        base_name,
        (void *)LoadDll->lpBaseOfDll);
    OnModuleLoaded(LoadDll->lpBaseOfDll, base_name);
  }
}

// called when a process gets created
// or attached to
void Debugger::OnProcessCreated() {
  CREATE_PROCESS_DEBUG_INFO *info = &dbg_debug_event.u.CreateProcessInfo;

  if (attach_mode) {
    // assume entrypoint has been reached already
    child_handle = info->hProcess;
    child_thread_handle = info->hThread;
    child_entrypoint_reached = true;
    GetProcessPlatform();

    // In case of attaching to an existing process
    // the dll load event for the main module
    // will *not* be generated.
    // Handle the main module load below
    char filename[MAX_PATH];
    GetFinalPathNameByHandleA(info->hFile, (LPSTR)(&filename), sizeof(filename), 0);
    char* base_name = strrchr(filename, '\\');
    if (base_name) base_name += 1;
    else base_name = filename;
    if (trace_debug_events)
      printf("Debugger: Loaded module %s at %p\n",
        base_name,
        (void*)info->lpBaseOfImage);
    OnModuleLoaded(info->lpBaseOfImage, base_name);

  } else {
    // add a brekpoint to the process entrypoint
    void *entrypoint = GetModuleEntrypoint(info->lpBaseOfImage);
    AddBreakpoint(entrypoint, BREAKPOINT_ENTRYPOINT);
  }
}

// called when an exception in the target occurs
DebuggerStatus Debugger::HandleExceptionInternal(EXCEPTION_RECORD *exception_record)
{
  CreateException(exception_record, &last_exception);

  // note: instrumentation could have placed breakpoints
  // on the same addresses as debugger
  // handle one-time debugger breakpoints first
  if ((exception_record->ExceptionCode == EXCEPTION_BREAKPOINT) ||
      (exception_record->ExceptionCode == 0x4000001f))
  {
    void *address = exception_record->ExceptionAddress;
    // printf("Breakpoint at address %p\n", address);
    int breakpoint_type = HandleDebuggerBreakpoint(address);
    if (breakpoint_type == BREAKPOINT_TARGET) {
      return DEBUGGER_TARGET_START;
    } else if (breakpoint_type != BREAKPOINT_UNKNOWN) {
      return DEBUGGER_CONTINUE;
    }
  }

  // check if cleient can handle it
  if (OnException(&last_exception)) {
    return DEBUGGER_CONTINUE;
  }

  // don't print exceptions handled by clients
  if (trace_debug_events)
    printf("Debugger: Exception %x at address %p\n",
      exception_record->ExceptionCode,
      exception_record->ExceptionAddress);

  switch (exception_record->ExceptionCode)
  {
  case EXCEPTION_BREAKPOINT:
  case 0x4000001f: //STATUS_WX86_BREAKPOINT
    // not handled above
    dbg_continue_status = DBG_EXCEPTION_NOT_HANDLED;
    return DEBUGGER_CONTINUE;

  case EXCEPTION_ACCESS_VIOLATION: {
    if (target_function_defined && 
       ((size_t)exception_record->ExceptionAddress == PERSIST_END_EXCEPTION))
    {
      if (trace_debug_events) printf("Debugger: Persistence method ended\n");
      HandleTargetEnded();
      return DEBUGGER_TARGET_END;
    } else {
      // Debug(&DebugEv->u.Exception.ExceptionRecord);
      dbg_continue_status = DBG_EXCEPTION_NOT_HANDLED;
      return DEBUGGER_CRASHED;
    }
    break;
  }

  case EXCEPTION_ILLEGAL_INSTRUCTION:
  case EXCEPTION_PRIV_INSTRUCTION:
  case EXCEPTION_INT_DIVIDE_BY_ZERO:
  case EXCEPTION_STACK_OVERFLOW:
  case STATUS_HEAP_CORRUPTION:
  case STATUS_STACK_BUFFER_OVERRUN:
  case STATUS_FATAL_APP_EXIT:
    dbg_continue_status = DBG_EXCEPTION_NOT_HANDLED;
    return DEBUGGER_CRASHED;
    break;

  default:
    if (trace_debug_events)
      printf("Unhandled exception %x\n", exception_record->ExceptionCode);
    dbg_continue_status = DBG_EXCEPTION_NOT_HANDLED;
    return DEBUGGER_CONTINUE;
  }
}

// standard debugger loop that listens to events in the target process
DebuggerStatus Debugger::DebugLoop(uint32_t timeout, bool killing)
{
  DebuggerStatus ret;
  bool alive = true;

  if (dbg_continue_needed) {
    ContinueDebugEvent(dbg_debug_event.dwProcessId,
      dbg_debug_event.dwThreadId,
      dbg_continue_status);
  }

  LPDEBUG_EVENT DebugEv = &dbg_debug_event;

  while (alive)
  {
    have_thread_context = false;

    uint64_t begin_time = GetCurTime();
    BOOL wait_ret = WaitForDebugEvent(DebugEv, 100);
    uint64_t end_time = GetCurTime();

    uint64_t time_elapsed = end_time - begin_time;
    timeout = ((uint64_t)timeout >= time_elapsed) ? timeout - (uint32_t)time_elapsed : 0;

    // printf("timeout: %u\n", timeout);
    // printf("time: %lld\n", get_cur_time_us());

    if (wait_ret) {
      dbg_continue_needed = true;
    } else {
      dbg_continue_needed = false;
    }

    if (timeout == 0) return DEBUGGER_HANGED;

    if (!wait_ret) {
      //printf("WaitForDebugEvent returned 0\n");
      continue;
    }

    dbg_continue_status = DBG_CONTINUE;

    thread_id = DebugEv->dwThreadId;

    // printf("eventCode: %x\n", DebugEv->dwDebugEventCode);

    switch (DebugEv->dwDebugEventCode)
    {
    case EXCEPTION_DEBUG_EVENT:
      if (!killing) {
        ret = HandleExceptionInternal(&DebugEv->u.Exception.ExceptionRecord);
        if (ret == DEBUGGER_CRASHED) OnCrashed(&last_exception);
        if (ret != DEBUGGER_CONTINUE) return ret;
      } else {
        dbg_continue_status = DBG_EXCEPTION_NOT_HANDLED;
      }
      break;

    case CREATE_THREAD_DEBUG_EVENT:
      break;

    case CREATE_PROCESS_DEBUG_EVENT: {
      if (trace_debug_events) printf("Debugger: Process created or attached\n");
      OnProcessCreated();
      CloseHandle(DebugEv->u.CreateProcessInfo.hFile);
      break;
    }

    case EXIT_THREAD_DEBUG_EVENT:
      break;

    case EXIT_PROCESS_DEBUG_EVENT:
      if (trace_debug_events) printf("Debugger: Process exit\n");
      OnProcessExit();
      alive = false;
      break;

    case LOAD_DLL_DEBUG_EVENT: {
      if(!killing) HandleDllLoadInternal(&DebugEv->u.LoadDll);
      CloseHandle(DebugEv->u.LoadDll.hFile);
      break;
    }

    case UNLOAD_DLL_DEBUG_EVENT:
      if (trace_debug_events)
        printf("Debugger: Unloaded module from %p\n", DebugEv->u.UnloadDll.lpBaseOfDll);
      OnModuleUnloaded(DebugEv->u.UnloadDll.lpBaseOfDll);
      break;

   default:
      break;
    }

    ContinueDebugEvent(DebugEv->dwProcessId,
      DebugEv->dwThreadId,
      dbg_continue_status);
  }

  return DEBUGGER_PROCESS_EXIT;
}

// starts the target process
void Debugger::StartProcess(char *cmd) {
  dbg_continue_needed = false;

  STARTUPINFOA si;
  STARTUPINFOEXA si_ex;
  LPSTARTUPINFOA si_ptr;
  LPSTARTUPINFOA si_basic_ptr;
  LPPROC_THREAD_ATTRIBUTE_LIST attr_list_buf = NULL;

  DWORD creation_flags = DEBUG_PROCESS | DEBUG_ONLY_THIS_PROCESS;

  PROCESS_INFORMATION pi;
  HANDLE hJob = NULL;
  JOBOBJECT_EXTENDED_LIMIT_INFORMATION job_limit;

  DeleteBreakpoints();

  if (sinkhole_stds && devnul_handle == INVALID_HANDLE_VALUE) {
    devnul_handle = CreateFile(
      "nul",
      GENERIC_READ | GENERIC_WRITE,
      FILE_SHARE_READ | FILE_SHARE_WRITE,
      NULL,
      OPEN_EXISTING,
      0,
      NULL);

    if (devnul_handle == INVALID_HANDLE_VALUE) {
      FATAL("Unable to open the nul device.");
    }
  }
  BOOL inherit_handles = TRUE;

  if (force_dep) {
    ZeroMemory(&si_ex, sizeof(si_ex));
    si_ex.StartupInfo.cb = sizeof(si_ex);

    creation_flags |= EXTENDED_STARTUPINFO_PRESENT;

    SIZE_T attr_size = 0;
    InitializeProcThreadAttributeList(NULL, 1, 0, &attr_size);
    if (attr_size == 0) {
      FATAL("Error getting attribute list size");
    }

    attr_list_buf = (LPPROC_THREAD_ATTRIBUTE_LIST)malloc(attr_size);
    if (!InitializeProcThreadAttributeList(attr_list_buf, 1, 0, &attr_size)) {
      FATAL("Error in InitializeProcThreadAttributeList");
    }

    DWORD flags = PROCESS_CREATION_MITIGATION_POLICY_DEP_ENABLE;
    size_t flags_size = sizeof(flags);

    if (!UpdateProcThreadAttribute(attr_list_buf,
      0, PROC_THREAD_ATTRIBUTE_MITIGATION_POLICY,
      &flags, flags_size, NULL, NULL))
    {
      FATAL("Error in UpdateProcThreadAttribute");
    }

    si_ex.lpAttributeList = attr_list_buf;

    si_ptr = (LPSTARTUPINFOA)&si_ex;
    si_basic_ptr = &si_ex.StartupInfo;
  } else {
    ZeroMemory(&si, sizeof(si));
    si.cb = sizeof(si);
    si_ptr = &si;
    si_basic_ptr = &si;
  }

  if (sinkhole_stds) {
    si_basic_ptr->hStdOutput = si_basic_ptr->hStdError = devnul_handle;
    si_basic_ptr->dwFlags |= STARTF_USESTDHANDLES;
  } else {
    inherit_handles = FALSE;
  }

  ZeroMemory(&pi, sizeof(pi));

  if (mem_limit || cpu_aff) {
    hJob = CreateJobObject(NULL, NULL);
    if (hJob == NULL) {
      FATAL("CreateJobObject failed, GLE=%d.\n", GetLastError());
    }

    ZeroMemory(&job_limit, sizeof(job_limit));
    if (mem_limit) {
      job_limit.BasicLimitInformation.LimitFlags |= JOB_OBJECT_LIMIT_PROCESS_MEMORY;
      job_limit.ProcessMemoryLimit = (size_t)(mem_limit * 1024 * 1024);
    }

    if (cpu_aff) {
      job_limit.BasicLimitInformation.LimitFlags |= JOB_OBJECT_LIMIT_AFFINITY;
      job_limit.BasicLimitInformation.Affinity = (DWORD_PTR)cpu_aff;
    }

    if (!SetInformationJobObject(
      hJob,
      JobObjectExtendedLimitInformation,
      &job_limit,
      sizeof(job_limit)
    )) {
      FATAL("SetInformationJobObject failed, GLE=%d.\n", GetLastError());
    }
  }

  if (!CreateProcessA(NULL,
                      cmd,
                      NULL,
                      NULL,
                      inherit_handles,
                      creation_flags,
                      NULL,
                      NULL,
                      si_ptr,
                      &pi))
  {
    FATAL("CreateProcess failed, GLE=%d.\n", GetLastError());
  }

  if (attr_list_buf) {
    DeleteProcThreadAttributeList(attr_list_buf);
    free(attr_list_buf);
  }

  child_handle = pi.hProcess;
  child_thread_handle = pi.hThread;
  child_entrypoint_reached = false;
  target_reached = false;
  have_thread_context = false;

  if (mem_limit || cpu_aff) {
    if (!AssignProcessToJobObject(hJob, child_handle)) {
      FATAL("AssignProcessToJobObject failed, GLE=%d.\n", GetLastError());
    }
  }

  GetProcessPlatform();
}

void Debugger::GetProcessPlatform() {
  BOOL wow64current, wow64remote;
  if (!IsWow64Process(child_handle, &wow64remote)) {
    FATAL("IsWow64Process failed");
  }
  if (wow64remote) {
    wow64_target = 1;
    child_ptr_size = 4;
    if (calling_convention == CALLCONV_DEFAULT) {
      calling_convention = CALLCONV_CDECL;
    }
  }
  if (!IsWow64Process(GetCurrentProcess(), &wow64current)) {
    FATAL("IsWow64Process failed");
  }
  // Will probably fail before we reach this, but oh well
  if (sizeof(void*) < child_ptr_size) {
    FATAL("64-bit build is needed to run 64-bit targets\n");
  }
}

// kills the target process
// (if not dead already)
DebuggerStatus Debugger::Kill() {
  if (!child_handle) return DEBUGGER_PROCESS_EXIT;

  TerminateProcess(child_handle, 0);
  
  dbg_last_status = DebugLoop(0xFFFFFFFFUL, true);
  if (dbg_last_status != DEBUGGER_PROCESS_EXIT) {
    FATAL("Error killing target process\n");
  }

  CloseHandle(child_handle);
  CloseHandle(child_thread_handle);

  child_handle = NULL;
  child_thread_handle = NULL;
  have_thread_context = false;

  // delete any breakpoints that weren't hit
  DeleteBreakpoints();

  return dbg_last_status;
}

// attaches to an active process
DebuggerStatus Debugger::Attach(unsigned int pid, uint32_t timeout) {
  attach_mode = true;

  if (!DebugActiveProcess(pid)) {
    DWORD error_code = GetLastError();
    

    if(error_code == 5) {
      HANDLE hToken = NULL;
      LUID luid;
      TOKEN_PRIVILEGES tp;
      
      if(!OpenProcessToken(GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, &hToken)) {
        FATAL("OpenProcessToken() failed, error code = %d\n", GetLastError());
      }
      
      if(!LookupPrivilegeValueA(NULL, "SeDebugPrivilege", &luid)) {
        FATAL("LookupPrivilegeValueA() failed, error code = %d\n", GetLastError());
      }
      
      tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED;
      tp.Privileges[0].Luid = luid;
      tp.PrivilegeCount = 1;
      
      if(!AdjustTokenPrivileges(hToken, FALSE, &tp, sizeof(TOKEN_PRIVILEGES), NULL, NULL)) {
        FATAL("AdjustTokenPrivileges() failed, error code = %d\n", GetLastError());
      }
      
      if(!DebugActiveProcess(pid)) {
        FATAL("Could not attach to the process.\n"
              "Make sure the process exists and you have permissions to debug it.\n");
      }
      
    } else {
      FATAL("DebugActiveProcess() failed, error code = %d\n", error_code);
    }
  }

  dbg_last_status = DEBUGGER_ATTACHED;

  return Continue(timeout);
}

// starts the process and waits for the next event
DebuggerStatus Debugger::Run(char *cmd, uint32_t timeout) {
  attach_mode = false;

  StartProcess(cmd);

  return Continue(timeout);
}

DebuggerStatus Debugger::Run(int argc, char **argv, uint32_t timeout) {
    char* cmd = NULL;
    cmd = ArgvToCmd(argc, argv);

    DebuggerStatus ret_dbg_status = Run(cmd, timeout);
    free(cmd);

    return ret_dbg_status;
}

// continues after Run() or previous Continue()
// return with a non-terminal status
DebuggerStatus Debugger::Continue(uint32_t timeout) {
  if (!child_handle && (dbg_last_status != DEBUGGER_ATTACHED))
    return DEBUGGER_PROCESS_EXIT;

  if (loop_mode && (dbg_last_status == DEBUGGER_TARGET_END)) {
    // saves us a breakpoint
    dbg_last_status = DEBUGGER_TARGET_START;
    return dbg_last_status;
  }

  dbg_last_status = DebugLoop(timeout);

  if (dbg_last_status == DEBUGGER_PROCESS_EXIT) {
    CloseHandle(child_handle);
    CloseHandle(child_thread_handle);
    child_handle = NULL;
    child_thread_handle = NULL;
  }

  return dbg_last_status;
}

// initializes options from command line
void Debugger::Init(int argc, char **argv) {
  have_thread_context = false;
  sinkhole_stds = false;
  mem_limit = 0;
  cpu_aff = 0;

  attach_mode = false;
  trace_debug_events = false;
  loop_mode = false;
  target_function_defined = false;

  target_return_value = 0;

  child_handle = NULL;
  child_thread_handle = NULL;

  target_module[0] = 0;
  target_method[0] = 0;
  target_offset = 0;
  saved_args = NULL;
  target_num_args = 0;
  calling_convention = CALLCONV_DEFAULT;
  target_address = NULL;

  char *option;

  trace_debug_events = GetBinaryOption("-trace_debug_events",
                                       argc, argv,
                                       trace_debug_events);

  option = GetOption("-target_module", argc, argv);
  if (option) target_module = option;

  option = GetOption("-target_method", argc, argv);
  if (option) target_method = option;

  loop_mode = GetBinaryOption("-loop", argc, argv, loop_mode);

  option = GetOption("-nargs", argc, argv);
  if (option) target_num_args = atoi(option);

  option = GetOption("-target_offset", argc, argv);
  if (option) target_offset = strtoul(option, NULL, 0);

  option = GetOption("-callconv", argc, argv);
  if (option) {
    if (strcmp(option, "stdcall") == 0)
      calling_convention = CALLCONV_CDECL;
    else if (strcmp(option, "fastcall") == 0)
      calling_convention = CALLCONV_FASTCALL;
    else if (strcmp(option, "thiscall") == 0)
      calling_convention = CALLCONV_THISCALL;
    else if (strcmp(option, "ms64") == 0)
      calling_convention = CALLCONV_MICROSOFT_X64;
    else
      FATAL("Unknown calling convention");
  }

  force_dep = GetBinaryOption("-force_dep", argc, argv, false);

  // check if we are running in persistence mode
  if (target_module[0] || target_offset || target_method[0]) {
    target_function_defined = true;
    if ((target_module[0] == 0) || ((target_offset == 0) && (target_method[0] == 0))) {
      FATAL("target_module and either target_offset or target_method must be specified together\n");
    }
  }

  if (loop_mode && !target_function_defined) {
    FATAL("Target function needs to be defined to use the loop mode\n");
  }

  if (target_num_args) {
    saved_args = (void **)malloc(target_num_args * sizeof(void *));
  }

  // get allocation granularity
  SYSTEM_INFO system_info;
  GetSystemInfo(&system_info);
  allocation_granularity = system_info.dwAllocationGranularity;
}

```

`Windows/debugger.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef DEBUGGER_H
#define DEBUGGER_H

#include <string>
#include <list>
#include <unordered_set>
#include <unordered_map>

#include "common.h"
#include "windows.h"
#include "arch/x86/reg.h"


enum DebuggerStatus {
  DEBUGGER_NONE,
  DEBUGGER_CONTINUE,
  DEBUGGER_PROCESS_EXIT,
  DEBUGGER_TARGET_START,
  DEBUGGER_TARGET_END,
  DEBUGGER_CRASHED,
  DEBUGGER_HANGED,
  DEBUGGER_ATTACHED
};

struct SavedRegisters {
  CONTEXT saved_context;
};

class Debugger {
public:

  virtual void Init(int argc, char **argv);
  DebuggerStatus Run(char *cmd, uint32_t timeout);
  DebuggerStatus Run(int argc, char **argv, uint32_t timeout);
  DebuggerStatus Kill();
  DebuggerStatus Continue(uint32_t timeout);
  DebuggerStatus Attach(unsigned int pid, uint32_t timeout);

  bool IsTargetAlive() { return (child_handle != NULL); };
  bool IsTargetFunctionDefined() { return target_function_defined; }

  uint64_t GetTargetReturnValue() { return target_return_value; }
  
  enum ExceptionType {
    BREAKPOINT,
    ACCESS_VIOLATION,
    ILLEGAL_INSTRUCTION,
    STACK_OVERFLOW,
    OTHER
  };

  struct Exception {
    ExceptionType type;
    void *ip;
    bool maybe_write_violation;
    bool maybe_execute_violation;
    void *access_address;
  };

  Exception GetLastException() {
    return last_exception;
  }

protected:

  enum MemoryProtection {
    READONLY,
    READWRITE,
    READEXECUTE,
    READWRITEEXECUTE
  };

  virtual void OnModuleLoaded(void *module, char *module_name);
  virtual void OnModuleUnloaded(void *module);
  virtual void OnTargetMethodReached() {}
  virtual void OnProcessCreated();
  virtual void OnProcessExit() {};
  virtual void OnEntrypoint();

  // should return true if the exception has been handled
  virtual bool OnException(Exception *exception_record) {
    return false;
  }

  virtual void OnCrashed(Exception *exception_record) { }

  void *GetModuleEntrypoint(void *base_address);
  void ReadStack(void *stack_addr, void **buffer, size_t numitems);
  void WriteStack(void *stack_addr, void **buffer, size_t numitems);
  void GetImageSize(void *base_address, size_t *min_address, size_t *max_address);

  // helper functions
  void *RemoteAllocateNear(uint64_t region_min,
    uint64_t region_max,
    size_t size,
    MemoryProtection protection,
    bool use_shared_memory = false);

  void ExtractCodeRanges(void *module_base,
                         size_t min_address,
                         size_t max_address,
                         std::list<AddressRange> *executable_ranges,
                         size_t *code_size);

  void ProtectCodeRanges(std::list<AddressRange> *executable_ranges);

  // returns address in (potentially) instrumented code
  virtual size_t GetTranslatedAddress(size_t address) { return address; }

  void RemoteFree(void *address, size_t size);
  void RemoteWrite(void *address, void *buffer, size_t size);
  void RemoteRead(void *address, void *buffer, size_t size);
  void RemoteProtect(void *address, size_t size, MemoryProtection protect);

  size_t GetRegister(Register r);
  void SetRegister(Register r, size_t value);

  void *GetTargetMethodAddress() { return target_address;  }

  DWORD GetProcOffset(HMODULE module, const char* name); 

  void SaveRegisters(SavedRegisters* registers);
  void RestoreRegisters(SavedRegisters* registers);

  void GetExceptionHandlers(size_t module_haeder, std::unordered_set <size_t>& handlers);

  void PatchPointersRemote(size_t min_address, size_t max_address, std::unordered_map<size_t, size_t>& search_replace);
  template<typename T>
  void PatchPointersRemoteT(size_t min_address, size_t max_address, std::unordered_map<size_t, size_t>& search_replace);

private:
  struct Breakpoint {
    void *address;
    int type;
    unsigned char original_opcode;
  };
  std::list<Breakpoint *> breakpoints;

  void StartProcess(char *cmd);
  void GetProcessPlatform();
  DebuggerStatus DebugLoop(uint32_t timeout, bool killing=false);
  int HandleDebuggerBreakpoint(void *address);
  void HandleDllLoadInternal(LOAD_DLL_DEBUG_INFO *LoadDll);
  DebuggerStatus HandleExceptionInternal(EXCEPTION_RECORD *exception_record);
  void HandleTargetReachedInternal();
  void HandleTargetEnded();
  char *GetTargetAddress(HMODULE module);
  void AddBreakpoint(void *address, int type);
  DWORD GetLoadedModules(HMODULE **modules);
  void DeleteBreakpoints();
  DWORD WindowsProtectionFlags(MemoryProtection protection);
  DWORD GetImageSize(void *base_address);
  void *RemoteAllocateBefore(uint64_t min_address,
                             uint64_t max_address,
                             size_t size,
                             MemoryProtection protection);
  void *RemoteAllocateAfter(uint64_t min_address,
                            uint64_t max_address,
                            size_t size,
                            MemoryProtection protection);

protected:

  bool child_entrypoint_reached;
  bool target_reached;

  int32_t child_ptr_size = sizeof(void *);

private:
  HANDLE child_handle, child_thread_handle;

  HANDLE devnul_handle = INVALID_HANDLE_VALUE;

  DEBUG_EVENT dbg_debug_event;
  DWORD dbg_continue_status;
  bool dbg_continue_needed;
  DebuggerStatus dbg_last_status;

  int wow64_target = 0;

protected:
  bool target_function_defined;
  bool loop_mode;
  bool attach_mode;
  bool trace_debug_events;

  bool sinkhole_stds;
  uint64_t mem_limit;
  uint64_t cpu_aff;

private:
  // persistence related
  int target_num_args;
  uint64_t target_offset;
  std::string target_module;
  std::string target_method;
  int calling_convention;
  void *target_address;
  void *saved_sp;
  void *saved_return_address;
  void **saved_args;

  uint64_t target_return_value;

  void RetrieveThreadContext();
  void CreateException(EXCEPTION_RECORD *win_exception_record,
                       Exception *exception);

  Exception last_exception;
  // thread id of the last event
  DWORD thread_id;
  CONTEXT lcContext;
  bool have_thread_context;
  size_t allocation_granularity;

  bool force_dep;
};

#endif // DEBUGGER_H

```

`Windows/winunwind.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifdef _WIN64

#include "winunwind.h"

WinUnwindData::~WinUnwindData() {
  for (auto pair : unwind_infos)
    delete pair.second;
  for (auto info : original_function_infos)
    delete info;
}

FunctionInfo* WinUnwindData::LookupFunctionInfoForTranslate(size_t IP) {
  if (original_function_infos.empty()) return NULL;

  if (last_lookup_translate
    && (IP >= last_lookup_translate->function_start)
    && (IP < last_lookup_translate->function_end))
  {
    return last_lookup_translate;
  }

  last_lookup_translate = LookupFunctionInfoSlow(IP);
  return last_lookup_translate;
}

FunctionInfo* WinUnwindData::LookupFunctionInfoForOther(size_t IP) {
  if (original_function_infos.empty()) return NULL;

  if (last_lookup_other
    && (IP >= last_lookup_other->function_start)
    && (IP < last_lookup_other->function_end))
  {
    return last_lookup_other;
  }

  last_lookup_other = LookupFunctionInfoSlow(IP);
  return last_lookup_other;
}

FunctionInfo* WinUnwindData::LookupFunctionInfoSlow(size_t IP) {
  // binary search yay
  int m, L = 0, R = (int)(original_function_infos.size() - 1);
  while (L <= R) {
    m = (L + R) / 2;
    FunctionInfo* cur = original_function_infos[m];
    if (IP >= cur->function_end) {
      L = m + 1;
    } else if (IP < cur->function_start) {
      R = m - 1;
    } else if ((IP >= cur->function_start) && (IP < cur->function_end)) {
      return cur;
    } else {
      return NULL;
    }
  }
  return NULL;
}


void WinUnwindData::DoTranslate(size_t original_address, size_t translated_address) {
  if (last_translated_entry && last_lookup_translate && 
      (original_address >= last_lookup_translate->function_start) &&
      (original_address < last_lookup_translate->function_end))
  {
    last_translated_entry->function_end = translated_address;
    return;
  }

  CommitLastTranslated();

  LookupFunctionInfoForTranslate(original_address);
  if (!last_lookup_translate) {
    return;
  }

  last_translated_entry = new FunctionInfo;
  *last_translated_entry = *last_lookup_translate;
  last_translated_entry->function_start = translated_address;
  last_translated_entry->function_end = translated_address;
}

void WinUnwindData::CommitLastTranslated() {
  if (last_translated_entry) {
    translated_infos.push_back(*last_translated_entry);
    delete last_translated_entry;
    last_translated_entry = NULL;
  }
}

void WinUnwindGenerator::OnModuleInstrumented(ModuleInfo* module) {
  if (tinyinst_.child_ptr_size == 4) {
    FATAL("-generate_unwind is unneeded (and thus incompatible) with 32-bit targets");
  }

  WinUnwindData* unwind_data = new WinUnwindData;
  module->unwind_data = unwind_data;

  // read the entire image
  // TODO (ifratric) can this fail for some modules?
  size_t image_size = module->max_address - module->min_address;
  BYTE* modulebuf = (BYTE*)malloc(image_size);
  tinyinst_.RemoteRead((void *)module->min_address, modulebuf, image_size);

  DWORD exception_table_offset;
  DWORD exception_table_size;
  if (!GetExceptionTableOffsetAndSize((char*)modulebuf, &exception_table_offset, &exception_table_size)) {
    FATAL("Error getting exception table");
  }
  if ((size_t)exception_table_offset + exception_table_size > image_size) {
    FATAL("Exception table out of bounds");
  }
  if (exception_table_size % (3 * sizeof(DWORD))) {
    FATAL("Incorrect exception table format?");
  }

  DWORD* exception_table = (DWORD*)(modulebuf + exception_table_offset);
  DWORD* exception_table_end = (DWORD*)(modulebuf + exception_table_offset + exception_table_size);

  DWORD function_start;
  DWORD function_end;
  DWORD unwind_info_offset;

  while (exception_table < exception_table_end) {
    size_t function_info_addr = module->min_address + ((BYTE *)exception_table - modulebuf);

    function_start = *exception_table; exception_table++;
    function_end = *exception_table; exception_table++;
    unwind_info_offset = *exception_table; exception_table++;

    if (function_start >= function_end) continue;

    UnwindInfo* unwind_info = ReadUnwindInfo(module, modulebuf, image_size, unwind_info_offset);

    FunctionInfo *new_info = new FunctionInfo;

    new_info->function_start = module->min_address + function_start;
    new_info->function_end = module->min_address + function_end;

    new_info->function_info_addr = function_info_addr;

    new_info->unwind_info = unwind_info;

    unwind_data->original_function_infos.push_back(new_info);
  }

  size_t code_size_before = module->instrumented_code_allocated;

  for (size_t handler : unwind_data->handlers) {
    WriteHandler(module, handler);
  }

  for (auto pair : unwind_data->unwind_infos) {
    WriteUnwindInfo(module, pair.second);
  }

  size_t code_size_after = module->instrumented_code_allocated;
  tinyinst_.CommitCode(module, code_size_before, (code_size_after - code_size_before));

  free(modulebuf);
}

UnwindInfo* WinUnwindGenerator::ReadUnwindInfo(ModuleInfo* module, unsigned char* modulebuf, size_t image_size, uint32_t unwind_info_offset) {
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;

  auto iter = unwind_data->unwind_infos.find(unwind_info_offset);
  if (iter != unwind_data->unwind_infos.end()) {
    return iter->second;
  }

  UnwindInfo* new_info = new UnwindInfo();
  unwind_data->unwind_infos[unwind_info_offset] = new_info;

  // need to loop here because of chained unwind infos
  while (1) {
    BYTE* unwind_info = modulebuf + unwind_info_offset;

    size_t handler_address = 0;
    size_t handler_data = 0;

    BYTE version_flags = *unwind_info;
    BYTE version = version_flags & 7;
    BYTE flags = (version_flags & 0xF8) >> 3;
    if (version > 2) {
      WARN("Unknown UNWIND_INFO version\n");
      break;
    }
    unwind_info += 1;

    BYTE prolog_size = *unwind_info;
    unwind_info += 1;

    BYTE num_unwind_codes = *unwind_info;
    unwind_info += 1;

    BYTE frame_register = *unwind_info;
    unwind_info += 1;

    USHORT* codes = (USHORT*)unwind_info;
    for (int i = 0; i < num_unwind_codes; i++) {
      new_info->unwind_codes.push_back(codes[i]);
    }

    if (num_unwind_codes % 2) num_unwind_codes++; // alignment
    unwind_info += sizeof(USHORT) * num_unwind_codes;

    if (flags & (UNW_FLAG_EHANDLER | UNW_FLAG_UHANDLER)) {
      DWORD handler_offset = *((DWORD*)unwind_info);
      handler_address = module->min_address + handler_offset;
      handler_data = module->min_address + (unwind_info - modulebuf) + sizeof(DWORD);
      unwind_data->handlers.insert(handler_address);
    } else if (flags & UNW_FLAG_CHAININFO) {
      // we don't care about the chained function start/end (?)
      unwind_info += 2 * sizeof(DWORD);
      unwind_info_offset = *((DWORD*)unwind_info);
      continue;
    }

    // printf("version: %x, frame_register: %x\n", version_flags, frame_register);

    new_info->version_flags = version_flags;
    new_info->frame_register = frame_register;

    new_info->handler = handler_address;
    new_info->handler_data = handler_data;

    FixUnwindCodes(new_info);

    return new_info;
  }

  return NULL;
}

int WinUnwindGenerator::GetExceptionTableOffsetAndSize(char* data, DWORD* offset, DWORD *size) {
  DWORD pe_offset;
  pe_offset = *((DWORD*)(data + 0x3C));
  char* pe = data + pe_offset;
  DWORD signature = *((DWORD*)pe);
  if (signature != 0x00004550) {
    return 0;
  }
  pe = pe + 0x18;
  WORD magic = *((WORD*)pe);
  if (magic == 0x10b) {
    *offset = *(DWORD*)(pe + 120);
    *size = *(DWORD*)(pe + 124);
  } else if (magic == 0x20b) {
    *offset = *(DWORD*)(pe + 136);
    *size = *(DWORD*)(pe + 140);
  } else {
    return 0;
  }

  return 1;
}

void WinUnwindGenerator::OnModuleUninstrumented(ModuleInfo* module) {
  delete module->unwind_data;
  module->unwind_data = NULL;
}

void WinUnwindGenerator::OnModuleLoaded(void* module, char* module_name) {
  if (!strcmp(module_name, "ntdll.dll") && !RtlAddFunctionTable_addr) {
    DWORD offset = tinyinst_.GetProcOffset((HMODULE)module, "RtlAddFunctionTable");
    if (!offset) {
      FATAL("Error locating RtlAddFunctionTable");
    }
    RtlAddFunctionTable_addr = (size_t)module + offset;
  }
}

void WinUnwindGenerator::WriteHandler(ModuleInfo* module, size_t original_handler) {
  WinUnwindData* data = (WinUnwindData*)module->unwind_data;

  auto iter = data->translated_handler_map.find(original_handler);
  if (iter != data->translated_handler_map.end()) {
    return;
  }

  size_t handler_address = tinyinst_.GetCurrentInstrumentedAddress(module);

  data->handler_start_breakpoints[handler_address] = original_handler;
  tinyinst_.assembler_->Breakpoint(module);

  unsigned char ret = 0xC3;
  tinyinst_.WriteCode(module, &ret, sizeof(ret));

  data->translated_handler_map[original_handler] = handler_address;
}

void WinUnwindGenerator::FixUnwindCodes(UnwindInfo* info) {
  // bump the version to at least 2
  if ((info->version_flags & 0x7) == 1) info->version_flags++;

  // remove the chain info flag
  info->version_flags &= 0xDF;

  info->prolog_size = 0;

  std::vector<USHORT> new_unwind_codes;

  // set the epilog size to 0
  new_unwind_codes.push_back(0x0600);
  new_unwind_codes.push_back(0x0600);

  size_t i = 0;
  while (i < info->unwind_codes.size()) {
    USHORT code = info->unwind_codes[i];

    // claar offset
    code &= 0xFF00;

    USHORT opcode = ((code & 0x0F00) >> 8);
    USHORT opinfo = (code >> 12);

    size_t extra = 0;
    bool skip = false;

    switch (opcode) {
    case 0: /* UWOP_PUSH_NONVOL */
      break;
    case 1: /* UWOP_ALLOC_LARGE */
      if (!opinfo) extra = 1;
      else extra = 2;
      break;
    case 2: /* UWOP_ALLOC_SMALL */
      break;
    case 3: /* UWOP_SET_FPREG */
      break;
    case 4: /* UWOP_SAVE_NONVOL */
      extra = 1;
      break;
    case 5: /* UWOP_SAVE_NONVOL_FAR */
      extra = 2;
      break;
    case 6: /* UWOP_EPILOG */
      skip = true; // we already added epilog
      extra = 1;
      break;
    case 7: /* UWOP_SPARE_CODE */
      extra = 2;
      break;
    case 8: /* UWOP_SAVE_XMM128 */
      extra = 1;
      break;
    case 9: /* UWOP_SAVE_XMM128_FAR */
      extra = 2;
      break;
    case 10: /* UWOP_PUSH_MACHFRAME */
      break;
    default:
      WARN("Unknown unwind opcode");
      break;
    }

    if(!skip) new_unwind_codes.push_back(code);
    i++;

    for (size_t j = 0; j < extra; j++) {
      if (i > info->unwind_codes.size()) {
        WARN("Unknown or malformed unwind code format");
        break;
      }
      code = info->unwind_codes[i];
      if (!skip) new_unwind_codes.push_back(code);
      i++;
    }
  }

  info->unwind_codes = new_unwind_codes;
}

DWORD WinUnwindGenerator::WriteUnwindInfo(ModuleInfo* module, UnwindInfo* info) {
  WinUnwindData* data = (WinUnwindData*)module->unwind_data;

  DWORD offset = (DWORD)module->instrumented_code_allocated;

  // must be DWORD aligned
  if (offset % sizeof(DWORD)) {
    int padding_bytes = sizeof(DWORD) - (offset % sizeof(DWORD));
    char padding[] = { 0, 0, 0, 0 };
    tinyinst_.WriteCode(module, padding, padding_bytes);
    offset += padding_bytes;
  }

  info->translated_offset = offset;

  if (info->unwind_codes.size() > 255) {
    WARN("Unwind code array too large");
    return 0;
  }

  BYTE flags = info->version_flags;
  tinyinst_.WriteCode(module, &flags, sizeof(flags));

  BYTE prolog = info->prolog_size;
  tinyinst_.WriteCode(module, &prolog, sizeof(prolog));

  BYTE count = (BYTE)info->unwind_codes.size();
  tinyinst_.WriteCode(module, &count, sizeof(count));

  tinyinst_.WriteCode(module, &info->frame_register, sizeof(info->frame_register));

  // unwind code array
  if (!info->unwind_codes.empty()) {
    tinyinst_.WriteCode(module, &(info->unwind_codes[0]), info->unwind_codes.size() * sizeof(info->unwind_codes[0]));
  }

  // padding
  if (info->unwind_codes.size() % 2) {
    USHORT padding = 0;
    tinyinst_.WriteCode(module, &padding, sizeof(padding));
  }

  if (info->handler) {
    size_t translated_handler = data->translated_handler_map[info->handler];
    DWORD handler_offset = (DWORD)(translated_handler - (size_t)module->instrumented_code_remote);
    tinyinst_.WriteCode(module, &handler_offset, sizeof(handler_offset));

    // in our case, the handler data is going to be a pointer to the original handler data
    tinyinst_.WritePointer(module, info->handler_data);
  }

  return offset;
}

void WinUnwindGenerator::WriteFunctionInfo(ModuleInfo* module, FunctionInfo* info, FunctionTable *functionTable) {
  // write this entry to the function table
  if (functionTable->num_entries >= functionTable->max_entries) {
    FATAL("Insufficient size allocated for function table");
  }
  functionTable->num_entries++;
  DWORD start_offset = (DWORD)(info->function_start - (size_t)module->instrumented_code_remote);
  DWORD end_offset = (DWORD)(info->function_end - (size_t)module->instrumented_code_remote);
  tinyinst_.WriteCodeAtOffset(module, functionTable->offset, &start_offset, sizeof(DWORD));
  functionTable->offset += sizeof(DWORD);
  tinyinst_.WriteCodeAtOffset(module, functionTable->offset, &end_offset, sizeof(DWORD));
  functionTable->offset += sizeof(DWORD);
  tinyinst_.WriteCodeAtOffset(module, functionTable->offset, &info->unwind_info->translated_offset, sizeof(DWORD));
  functionTable->offset += sizeof(DWORD);
}

size_t WinUnwindGenerator::WriteFunctionTable(ModuleInfo* module, FunctionTable& functionTable, size_t max_entries) {
  if (functionTable.addr) return functionTable.addr;

  size_t function_table_addr = tinyinst_.GetCurrentInstrumentedAddress(module);

  // must be DWORD aligned
  if (function_table_addr % sizeof(DWORD)) {
    int padding_bytes = sizeof(DWORD) - (function_table_addr % sizeof(DWORD));
    char padding[] = { 0, 0, 0, 0 };
    tinyinst_.WriteCode(module, padding, padding_bytes);
    function_table_addr += padding_bytes;
  }

  function_table_addr = tinyinst_.GetCurrentInstrumentedAddress(module);
  size_t function_table_offset = module->instrumented_code_allocated;

  size_t buf_size = max_entries * sizeof(DWORD) * 3;
  DWORD* buf = (DWORD*)malloc(buf_size);

  DWORD max_offset = (DWORD)module->instrumented_code_size;

  DWORD* cur = buf;
  for (size_t i = 0; i < max_entries; i++) {
    *cur = max_offset; cur++;
    *cur = max_offset; cur++;
    *cur = 0xFFFFFFFF; cur++;
  }

  tinyinst_.WriteCode(module, buf, buf_size);

  free(buf);

  functionTable.addr = function_table_addr;
  functionTable.num_entries = 0;
  functionTable.max_entries = max_entries;
  functionTable.offset = function_table_offset;

  return function_table_addr;
}

size_t WinUnwindGenerator::MaybeRedirectExecution(ModuleInfo* module, size_t IP) {
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;

  size_t code_size_before = module->instrumented_code_allocated;

  // TODO(ifratric) is this sufficient?
  size_t max_function_table_size = unwind_data->original_function_infos.size() * 3;
  size_t function_table_addr = WriteFunctionTable(module, unwind_data->function_table, max_function_table_size);

  unwind_data->CommitLastTranslated();

  size_t function_table_old_offset = unwind_data->function_table.offset;
  for (auto iter = unwind_data->translated_infos.begin(); iter != unwind_data->translated_infos.end(); iter++) {
    WriteFunctionInfo(module, &(*iter), &unwind_data->function_table);
  }
  size_t function_table_new_offset = unwind_data->function_table.offset;
  if (function_table_old_offset != function_table_new_offset) {
    tinyinst_.CommitCode(module, function_table_old_offset, function_table_new_offset - function_table_old_offset);
  }

  unwind_data->translated_infos.clear();

  if (unwind_data->table_registered) {
    // compute how much data we wrote and commit it all to the target process
    size_t code_size_after = module->instrumented_code_allocated;
    if (code_size_after != code_size_before) {
      tinyinst_.CommitCode(module, code_size_before, (code_size_after - code_size_before));
    }

    return IP;
  }

  if (!RtlAddFunctionTable_addr) {
    FATAL("Need to register unwind info but the address of RtlAddFunctionTable is unknown");
  }

  size_t continue_address = tinyinst_.GetCurrentInstrumentedAddress(module);

  tinyinst_.assembler_->OffsetStack(module, -tinyinst_.sp_offset);

  unsigned char register_assembly_part1[] = {
    // push flags and volatile registers
    0x9C, 0x50, 0x51, 0x52, 0x41, 0x50, 0x41, 0x51, 0x41, 0x52, 0x41, 0x53,
    // save rbp, rsp
    0x55, // push rbp
    0x48, 0x89, 0xE5, // mov rbp, rsp
    // fix stack alignment
    0x48, 0xF7, 0xC4, 0x0F, 0x00, 0x00, 0x00, // test   rsp,0xf
    0x0F, 0x84, 0x02, 0x00, 0x00, 0x00, // je skip_alignment
    //0x0F, 0x85, 0x02, 0x00, 0x00, 0x00, // jne skip_alignment
    0x6A, 0x00, // push 0
    // load parameters
    0x48, 0x8B, 0x05, 0x1A, 0x00, 0x00, 0x00, // mov rax, [rip+offset]
    0x48, 0x8B, 0x0D, 0x1B, 0x00, 0x00, 0x00, // mov rcx, [rip+offset]
    0x4C, 0x8B, 0x05, 0x1C, 0x00, 0x00, 0x00, // mov r8, [rip+offset]
    0x48, 0x8B, 0x15, 0x1D, 0x00, 0x00, 0x00, // mov rdx, [rip+offset]
    0xE9, 0x20, 0x00, 0x00, 0x00, // jmp 0x18
  };

  tinyinst_.WriteCode(module, register_assembly_part1, sizeof(register_assembly_part1));
  tinyinst_.WritePointer(module, RtlAddFunctionTable_addr);
  tinyinst_.WritePointer(module, function_table_addr);
  tinyinst_.WritePointer(module, (size_t)module->instrumented_code_remote);
  tinyinst_.WritePointer(module, max_function_table_size);

  unsigned char register_assembly_part2[] = {
    // allocate shadow space
    0x48, 0x8D, 0x64, 0x24, 0xE0, // lea rsp,[rsp-0x20]
    // RtlAddFunctionTable(function_table_addr, 1, instrumented_code_remote)
    0xFF, 0xD0, // call rax
    // free shadow space
    0x48, 0x8D, 0x64, 0x24, 0x20, // lea rsp,[rsp+0x20]
    //restore rsp, rbp
    0x48, 0x89, 0xEC, // mov    rsp,rbp
    0x5D, // pop rbp
    // pop volatile registers and flags
    0x41, 0x5B, 0x41, 0x5A, 0x41, 0x59, 0x41, 0x58, 0x5A, 0x59, 0x58, 0x9D
  };

  tinyinst_.WriteCode(module, register_assembly_part2, sizeof(register_assembly_part2));

  tinyinst_.assembler_->OffsetStack(module, tinyinst_.sp_offset);

  unwind_data->register_breakpoint = tinyinst_.GetCurrentInstrumentedAddress(module);
  tinyinst_.assembler_->Breakpoint(module);
  unwind_data->register_continue_IP = IP;
  tinyinst_.SaveRegisters(&unwind_data->register_saved_registers);

  // compute how much data we wrote and commit it all to the target process
  size_t code_size_after = module->instrumented_code_allocated;
  tinyinst_.CommitCode(module, code_size_before, (code_size_after - code_size_before));

  unwind_data->table_registered = true;

  return continue_address;
}

bool WinUnwindGenerator::HandleBreakpoint(ModuleInfo* module, void* address) {
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;
  if (!unwind_data) return false;

  if (size_t(address) == unwind_data->register_breakpoint) {
    // size_t rax = tinyinst_.GetRegister(RAX);
    // printf("Registration complete, rax: %zx\n", rax);
    tinyinst_.RestoreRegisters(&unwind_data->register_saved_registers);
    tinyinst_.SetRegister(RIP, unwind_data->register_continue_IP);
    return true;
  }

  auto handler_iter = unwind_data->handler_start_breakpoints.find((size_t)address);
  if (handler_iter != unwind_data->handler_start_breakpoints.end()) {
    // printf("handler start breakpoint\n");

    PDISPATCHER_CONTEXT pdispatcher_context = (PDISPATCHER_CONTEXT)tinyinst_.GetRegister(R9);
    DISPATCHER_CONTEXT dispatcher_context;
 
    tinyinst_.RemoteRead((void*)pdispatcher_context, &dispatcher_context, sizeof(dispatcher_context));

    auto iter = unwind_data->return_addresses.find(dispatcher_context.ControlPc);
    if (iter == unwind_data->return_addresses.end()) {
      WARN("Return address not found");
    } else {
      // lookup original return address from map
      dispatcher_context.ControlPc = iter->second.original_return_address;

      FunctionInfo* original_function_info = iter->second.original_function_info;

      // handler data passed to the instrumented handler is a pointer
      // to the original handler data. Thus we could to read it from memory
      // to restore it.
      // However, it's faster for now to just set it from original_function_info
      // (avoids a RemoteRead)
      // size_t fixed_handler_data;
      // tinyinst_.RemoteRead(dispatcher_context.HandlerData, &fixed_handler_data, sizeof(fixed_handler_data));
      // dispatcher_context.HandlerData = (PVOID)fixed_handler_data;
      dispatcher_context.HandlerData = (PVOID)original_function_info->unwind_info->handler_data;

      // seems unecessary for now
      // dispatcher_context.LanguageHandler = (PEXCEPTION_ROUTINE)handler_iter->second;

      // TODO(ifratric) do we need to restore this
      dispatcher_context.ImageBase = module->min_address;
      dispatcher_context.FunctionEntry = (PRUNTIME_FUNCTION)original_function_info->function_info_addr;
    }

    tinyinst_.RemoteWrite((void*)pdispatcher_context, &dispatcher_context, sizeof(dispatcher_context));

    // redirect execution to the corresponding original handler
    tinyinst_.SetRegister(RIP, handler_iter->second);
    return true;
  }

  return false;
}

void WinUnwindGenerator::OnReturnAddress(ModuleInfo* module,
  size_t original_address,
  size_t translated_address)
{
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;

  FunctionInfo *info = unwind_data->LookupFunctionInfoForOther(original_address - 1);
  if (!info) return;

  WinUnwindData::ReturnAddressInfo ret_info;
  ret_info.original_return_address = original_address;
  ret_info.original_function_info = info;

  // printf("Return address %zx %zx\n", translated_address, original_address);

  unwind_data->return_addresses[translated_address] = ret_info;
}

void WinUnwindGenerator::OnBasicBlockStart(ModuleInfo* module,
  size_t original_address,
  size_t translated_address)
{
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;
  unwind_data->DoTranslate(original_address, translated_address);
}

void WinUnwindGenerator::OnInstruction(ModuleInfo* module,
  size_t original_address,
  size_t translated_address)
{
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;
  unwind_data->DoTranslate(original_address, translated_address);
}

void WinUnwindGenerator::OnBasicBlockEnd(ModuleInfo* module,
  size_t original_address,
  size_t translated_address)
{
  WinUnwindData* unwind_data = (WinUnwindData*)module->unwind_data;
  if (unwind_data->last_translated_entry) 
    unwind_data->last_translated_entry->function_end = translated_address;
}

#endif // _WIN64

```

`Windows/winunwind.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef WINUNWIND_H
#define WINUNWIND_H

#ifdef _WIN64

#include "unwind.h"
#include "tinyinst.h"

#include <vector>
#include <set>
#include <unordered_map>

struct UnwindInfo {
	BYTE version_flags;
	BYTE prolog_size;
	BYTE frame_register;

	std::vector<USHORT> unwind_codes;

	size_t handler;
	size_t handler_data;

	DWORD translated_offset;
};

struct FunctionInfo {
	size_t function_start;
	size_t function_end;

	UnwindInfo* unwind_info;

	// address of this function info in the original code
	size_t function_info_addr;
};

struct FunctionTable {
	FunctionTable() : max_entries(0), addr(0) {}

	size_t addr;
	size_t offset;
	size_t num_entries;
	size_t max_entries;
};

class WinUnwindData : public UnwindData {
public:
	WinUnwindData() : table_registered(false),
		register_breakpoint(0), register_continue_IP(0),
		last_lookup_translate(NULL), last_lookup_other(NULL),
	  last_translated_entry(NULL) {}

	~WinUnwindData();

	// maps from offset (in the original code) to UnwindInfo
	// presumably a single UnwindInfo can be referenced from
	// multtiple FunctionInfo structures
	std::unordered_map<uint32_t, UnwindInfo *> unwind_infos;
	std::vector<FunctionInfo *> original_function_infos;
	std::set<size_t> handlers;

	bool table_registered;
	size_t register_breakpoint;
	size_t register_continue_IP;
	SavedRegisters register_saved_registers;

	struct ReturnAddressInfo {
		size_t original_return_address;
		FunctionInfo* original_function_info;
	};

	// Maps the return addresses in the instrumented code (the keys)
	// to the return addresses in the original code (the values).
	std::unordered_map<size_t, ReturnAddressInfo> return_addresses;

	FunctionInfo* LookupFunctionInfoForTranslate(size_t IP);
	FunctionInfo* LookupFunctionInfoForOther(size_t IP);
	FunctionInfo* LookupFunctionInfoSlow(size_t IP);

	FunctionInfo* last_lookup_translate;
	FunctionInfo* last_lookup_other;
	FunctionInfo* last_translated_entry;

	// FunctionInfo structures for the instrumented code
	// that haven't been written to the remote process yet
	std::vector<FunctionInfo> translated_infos;

	void DoTranslate(size_t original_address, size_t translated_address);
	
	// maps from original handler to translated handler
	std::unordered_map<size_t, size_t> translated_handler_map;
	// maps from translated handler to original handler
	std::unordered_map<size_t, size_t> handler_start_breakpoints;

	// info about the function table for the instrumented code
	// (in the remote process)
	FunctionTable function_table;

	void CommitLastTranslated();
};

class WinUnwindGenerator : public UnwindGenerator {
public:
	WinUnwindGenerator(TinyInst& tinyinst) : UnwindGenerator(tinyinst), RtlAddFunctionTable_addr(0) { }

	void OnModuleInstrumented(ModuleInfo* module) override;
	void OnModuleUninstrumented(ModuleInfo* module) override;

	void OnModuleLoaded(void* module, char* module_name) override;

	size_t MaybeRedirectExecution(ModuleInfo* module, size_t IP) override;

	bool HandleBreakpoint(ModuleInfo* module, void* address) override;

	void OnReturnAddress(ModuleInfo* module,
		size_t original_address,
		size_t translated_address) override;

	void OnBasicBlockStart(ModuleInfo* module,
		size_t original_address,
		size_t translated_address) override;

	void OnInstruction(ModuleInfo* module,
		size_t original_address,
		size_t translated_address) override;

	void OnBasicBlockEnd(ModuleInfo* module,
		size_t original_address,
		size_t translated_address) override;

	bool Is64BitOnly() override { return true; }

protected:
	UnwindInfo* ReadUnwindInfo(ModuleInfo* module, unsigned char* modulebuf, size_t image_size, uint32_t unwind_info_offset);

	int GetExceptionTableOffsetAndSize(char* data, DWORD* offset, DWORD* size);

	void WriteFunctionInfo(ModuleInfo* module, FunctionInfo *info, FunctionTable* functionTable);

	DWORD WriteUnwindInfo(ModuleInfo* module, UnwindInfo* info);

	void WriteHandler(ModuleInfo* module, size_t original_handler);

	size_t WriteFunctionTable(ModuleInfo* module, FunctionTable &functionTable, size_t max_entries);

	void FixUnwindCodes(UnwindInfo* info);

	size_t RtlAddFunctionTable_addr;
};

#endif // _WIN64

#endif // WINUNWIND_H

```

`arch/arm64/arm64_assembler.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "arch/arm64/arm64_assembler.h"

#include <cassert>
#include <iomanip>
#include <iostream>
#include <iterator>
#include <variant>

#include "arch/arm64/arm64_helpers.h"
#include "common.h"

// brk 0
uint32_t BREAKPOINT = 0xd4200000;

// nop
uint32_t NOP = 0xd503201f;

// blr xzr
uint32_t CRASH = 0xd63f03e0;

uint32_t MRS_X0_NZCV = 0xd53b4200;
uint32_t MSR_NZCV_X0 = 0xd51b4200;

// strip pac tag
uint32_t XPACI_X0 = 0xdac143e0;

void PrintInstruction(uint64_t address, arm64::Instruction &instr) {
  std::cout << "0x" << std::hex << address << ": "
            << " " << std::setw(8) << std::setfill(' ')
            << *((uint32_t *)instr.address) << "   " << instr << "\n";
}

void PrintInstruction(Instruction &inst) {
  PrintInstruction(inst.address, inst.instr);
}

// load the return address into the lr register
void Arm64Assembler::SetReturnAddress(ModuleInfo *module,
                                       uint64_t return_address) {
  EmitLoadLit(module, Register::LR, 64, false, return_address);
}

void Arm64Assembler::JmpAddress(ModuleInfo *module, size_t address) {
  FATAL("not available on arm64");
}

void Arm64Assembler::Crash(ModuleInfo *module) {
  tinyinst_.WriteCode(module, &CRASH, sizeof(CRASH));
}

void Arm64Assembler::Breakpoint(ModuleInfo *module) {
  tinyinst_.WriteCode(module, &BREAKPOINT, sizeof(BREAKPOINT));
}

void Arm64Assembler::Nop(ModuleInfo *module) {
  tinyinst_.WriteCode(module, &NOP, sizeof(NOP));
}

static bool IsReturnInstruction(arm64::Opcode opcode) {
  switch (opcode) {
    case arm64::Opcode::kRetaa:
    case arm64::Opcode::kRetab:
    case arm64::Opcode::kRetaaz:
    case arm64::Opcode::kRetabz:
    case arm64::Opcode::kRet:
      return true;
    default:
      return false;
  }
}

static bool IsCondJmpInstruction(arm64::Opcode opcode) {
  switch (opcode) {
    case arm64::Opcode::kBCond:
    case arm64::Opcode::kCbnz:
    case arm64::Opcode::kCbz:
    case arm64::Opcode::kTbnz:
    case arm64::Opcode::kTbz:
      return true;
    default:
      return false;
  }
}

static bool IsJmpInstruction(arm64::Opcode opcode) {
  switch (opcode) {
    case arm64::Opcode::kB:
    case arm64::Opcode::kBr:
    case arm64::Opcode::kBraa:
    case arm64::Opcode::kBraaz:
    case arm64::Opcode::kBrab:
    case arm64::Opcode::kBrabz:
      return true;
    default:
      return false;
  }
}

static bool IsCallInstruction(arm64::Opcode opcode) {
  switch (opcode) {
    case arm64::Opcode::kBl:
    case arm64::Opcode::kBlr:
    case arm64::Opcode::kBlraa:
    case arm64::Opcode::kBlraaz:
    case arm64::Opcode::kBlrab:
    case arm64::Opcode::kBlrabz:
      return true;
    default:
      return false;
  }
}

void Arm64Assembler::EmitLoadLit(ModuleInfo *module, Register dst_reg,
                                 size_t size, bool is_signed, uint64_t value) {
  //    ldr dst_reg, label_value
  //    b next_instr
  //  label_value:
  //    0x11111111
  //    0x22222222
  // next_instr
  uint64_t addr = (uint64_t)module->instrumented_code_local +
                  module->instrumented_code_allocated;
  uint32_t ldr_lit_instr = ldr_lit(dst_reg, 8, size, is_signed);
  tinyinst_.WriteCode(module, &ldr_lit_instr, sizeof(ldr_lit_instr));
  uint32_t b_instr = b(0, 12);
  tinyinst_.WriteCode(module, &b_instr, sizeof(b_instr));
  tinyinst_.WriteCode(module, &value, sizeof(value));
}

void Arm64Assembler::FixOffset(ModuleInfo *module, uint32_t jmp_offset,
                               uint32_t target_offset) {
  uint64_t instr_address =
      (uint64_t)module->instrumented_code_local + jmp_offset;
  int32_t relative_offset = target_offset - jmp_offset;
  if (relative_offset & 3) {
    FATAL("relative_offset must be aligned");
  }

  relative_offset >>= 2;

  uint32_t instr = *((uint32_t *)instr_address);
  arm64::Instruction inst = arm64::DecodeInstruction(instr_address, instr);

  uint32_t encoded_imm = 0;
  switch (inst.opcode) {
    case arm64::Opcode::kBCond:
    case arm64::Opcode::kCbnz:
    case arm64::Opcode::kCbz:
    case arm64::Opcode::kLdrLiteral:
      encoded_imm = EncodeSignedImmediate(23, 5, relative_offset);
      break;

    case arm64::Opcode::kB:
    case arm64::Opcode::kBl:
      encoded_imm = EncodeSignedImmediate(25, 0, relative_offset);
      break;

    case arm64::Opcode::kTbz:
    case arm64::Opcode::kTbnz:
      encoded_imm = EncodeSignedImmediate(18, 5, relative_offset);
      break;

    default:
      PrintInstruction(instr_address, inst);
      FATAL("Unhandled instruction: %d\n", inst.opcode);
      break;
  }

  *((uint32_t *)instr_address) |= encoded_imm;
}


void Arm64Assembler::OffsetStack(ModuleInfo *module, int32_t offset) {
  uint32_t opcode = 0;
  if (offset & 0xF) {
    FATAL("Stack must be 16 bytes aligned");
  }
  if (offset < 0) {
    opcode = sub_reg_imm(Register::SP, Register::SP, std::abs(offset));
  } else {
    opcode = add_reg_imm(Register::SP, Register::SP, offset);
  }
  tinyinst_.WriteCode(module, &opcode, sizeof(opcode));
}

// ldr x0, [sp + offset]
void Arm64Assembler::ReadStack(ModuleInfo *module, int32_t offset) {
  ReadRegStack(module, Register::X0, offset);
}

// str x0, [sp + offset]
void Arm64Assembler::WriteStack(ModuleInfo *module, int32_t offset) {
  WriteRegStack(module, Register::X0, offset);
}

// ldr x0, [sp + offset]
void Arm64Assembler::ReadRegStack(ModuleInfo *module, Register dst,
                                  int32_t offset) {
  uint32_t ldr_instr = 0;

  if (std::abs(offset) < 255) {
    ldr_instr = ldr(64, dst, Register::SP, offset);
    tinyinst_.WriteCode(module, &ldr_instr, sizeof(ldr_instr));
  }

  else if (std::abs(offset) < 4096) {
    OffsetStack(module, offset);

    ldr_instr = ldr(64, dst, Register::SP, 0);
    tinyinst_.WriteCode(module, &ldr_instr, sizeof(ldr_instr));

    OffsetStack(module, -offset);
  } else {
    FATAL("offset out of range, max is [-0x1000, +0x1000], was: %d", offset);
  }
}

// str x0, [sp + offset]
void Arm64Assembler::WriteRegStack(ModuleInfo *module, Register src,
                                   int32_t offset) {
  uint32_t str_instr = 0;

  if (std::abs(offset) < 255) {
    str_instr = str(64, src, Register::SP, offset);
    tinyinst_.WriteCode(module, &str_instr, sizeof(str_instr));
  }

  else if (std::abs(offset) < 4096) {
    OffsetStack(module, offset);

    str_instr = str(64, src, Register::SP, 0);
    tinyinst_.WriteCode(module, &str_instr, sizeof(str_instr));

    OffsetStack(module, -offset);
  }

  else {
    FATAL("offset out of range, max is [-0x1000, +0x1000], was: %d", offset);
  }
}

void Arm64Assembler::InstrumentGlobalIndirect(ModuleInfo *module,
                                              Instruction &inst,
                                              size_t instruction_address) {
  FATAL(
      "-indirect_instrumentation=global is not supported on arm64 \
         please use 'local'");
}

// converts an indirect jump/call into a MOV instruction
// which moves the target of the indirect call into the X0 register
// and writes this instruction into the code buffer
//
// returns the register number which is used by the original code
// to perform the branch.
uint8_t Arm64Assembler::MovIndirectTarget(ModuleInfo *module, Instruction &inst) {
  Register target_address_reg = Register::X0;
  bool strip_pac = false;

  switch (inst.instr.opcode) {
    case arm64::Opcode::kBraa:
    case arm64::Opcode::kBrab:
    case arm64::Opcode::kBraaz:
    case arm64::Opcode::kBrabz:

    case arm64::Opcode::kBlraa:
    case arm64::Opcode::kBlrab:
    case arm64::Opcode::kBlraaz:
    case arm64::Opcode::kBlrabz:
      strip_pac = true;
      // fall through
    case arm64::Opcode::kBr:
    case arm64::Opcode::kBlr:
      target_address_reg =
          reg(std::get<arm64::Register>(inst.instr.operands[0]));
      break;

    case arm64::Opcode::kRetaa:
    case arm64::Opcode::kRetab:
      strip_pac = true;
        // fall through
    case arm64::Opcode::kRet:
      target_address_reg = Register::LR;
      break;

    default:
      FATAL("not implemented yet");
  }

  uint32_t mov_instr = mov(Register::X0, target_address_reg);
  tinyinst_.WriteCode(module, &mov_instr, sizeof(mov_instr));
  if (strip_pac) {
    tinyinst_.WriteCode(module, &XPACI_X0, sizeof(XPACI_X0));
  }
  return static_cast<uint8_t>(target_address_reg);
}

// translates indirect jump or call
// using local jumptable
void Arm64Assembler::InstrumentLocalIndirect(ModuleInfo *module,
                                             Instruction &inst,
                                             size_t instruction_address,
                                             size_t bb_address) {
  if (tinyinst_.sp_offset) {
    OffsetStack(module, -tinyinst_.sp_offset);
  }

  // XXX: save few instructions if sp_offset is != 0 save instructions by
  // including the offset which is needed to store flags and x0 by including
  // it in the if clause.
  OffsetStack(module, -32);

  // stack layout
  // x0
  // x1
  // alu flags
  WriteRegStack(module, Register::X1, 16);
  WriteRegStack(module, Register::X0, 8);
  tinyinst_.WriteCode(module, &MRS_X0_NZCV, sizeof(MRS_X0_NZCV));
  WriteRegStack(module, Register::X0, 0);

  // Emit instructions that load the target address to the X0 register.
  uint8_t branch_register_number = MovIndirectTarget(module, inst);

  // InstrumentLocalIndirect iterates through a linked list until the it
  // finds the code that was generated for the target address. Jumps are
  // performed with the help of the X1 register.
  uint32_t ldr_lit_instr = ldr_lit(Register::X1, 12, 64, false);
  uint32_t br_instr = br(Register::X1);
  tinyinst_.WriteCode(module, &ldr_lit_instr, sizeof(ldr_lit_instr));
  tinyinst_.WriteCode(module, &br_instr, sizeof(br_instr));

  // The end of the list is a breakpoint which is generated here.
  size_t breakpoint_address = tinyinst_.GetCurrentInstrumentedAddress(module);
  Breakpoint(module);
  module->br_indirect_newtarget_list[breakpoint_address] = {
      module->instrumented_code_allocated, bb_address, branch_register_number,
  };

  // Write address of the breakpoint to the head of the linked list
  // (this is the address which is loaded into X2).
  uint64_t address = (uint64_t)breakpoint_address;
  tinyinst_.WriteCode(module, &address, sizeof(address));
}

void Arm64Assembler::TranslateJmp(ModuleInfo *module, ModuleInfo *target_module,
                                  size_t original_target,
                                  IndirectBreakpoinInfo& breakpoint_info,
                                  bool global_indirect,
                                  size_t previous_offset) {
  uint64_t addr = (uint64_t)module->instrumented_code_local +
                  module->instrumented_code_allocated;
  size_t translate_jmp_off = module->instrumented_code_allocated;

  // Register number that was used by the original instruction
  // to perform the branch.
  uint64_t reg_num = breakpoint_info.branch_register;

  // offset of this instruction must be fixed
  size_t ldr_offset = module->instrumented_code_allocated;
  uint32_t ldr_lit_instr =
      ldr_lit(static_cast<Register>(reg_num), 0, 64, /*is_signed*/ false);
  tinyinst_.WriteCode(module, &ldr_lit_instr, sizeof(ldr_lit_instr));

  uint32_t cmp_instr = cmp(Register::X0, static_cast<Register>(reg_num));
  tinyinst_.WriteCode(module, &cmp_instr, sizeof(cmp_instr));

  uint32_t b_cond_instr = b_cond("eq", 8);
  tinyinst_.WriteCode(module, &b_cond_instr, sizeof(b_cond_instr));

  uint32_t b_previous_list_head_instr =
      b(0, (int32_t)((int64_t)previous_offset -
                     (int64_t)module->instrumented_code_allocated));
  tinyinst_.WriteCode(module, &b_previous_list_head_instr,
                      sizeof(b_previous_list_head_instr));

  // restore registers
  // stack layout
  // x1
  // x0
  // alu flags
  ReadRegStack(module, Register::X0, 0);
  tinyinst_.WriteCode(module, &MSR_NZCV_X0, sizeof(MSR_NZCV_X0));
  ReadRegStack(module, Register::X0, 8);
  ReadRegStack(module, Register::X1, 16);
  OffsetStack(module, 32);

  if (tinyinst_.sp_offset) {
    OffsetStack(module, tinyinst_.sp_offset);
  }

  // consider indirect call/jump an edge and insert appropriate instrumentation
  tinyinst_.InstrumentEdge(module, target_module, breakpoint_info.source_bb,
                           original_target);

  uint32_t br_instr = br(static_cast<Register>(reg_num));
  tinyinst_.WriteCode(module, &br_instr, sizeof(br_instr));
  FixOffset(module, ldr_offset, module->instrumented_code_allocated);
}

static int32_t GetRipRelativeOffset(Instruction &inst) {
  int64_t off64 = 0;

  switch (inst.instr.opcode) {
    case arm64::Opcode::kBCond:
    case arm64::Opcode::kB:
    case arm64::Opcode::kBl:
      off64 = static_cast<int64_t>(
          std::get<arm64::Immediate>(inst.instr.operands[0]).value);
      break;

    case arm64::Opcode::kCbz:
    case arm64::Opcode::kCbnz:
    case arm64::Opcode::kAdr:
    case arm64::Opcode::kAdrp:
      off64 = static_cast<int64_t>(
          std::get<arm64::Immediate>(inst.instr.operands[1]).value);
      break;

    case arm64::Opcode::kTbz:
    case arm64::Opcode::kTbnz:
      off64 = static_cast<int64_t>(
          std::get<arm64::Immediate>(inst.instr.operands[2]).value);
      break;

    case arm64::Opcode::kLdrLiteral:
    case arm64::Opcode::kLdrsLiteral:
      off64 =
          std::get<arm64::ImmediateOffset>(inst.instr.operands[1]).offset.value;
      break;

    default:
      PrintInstruction(inst);
      FATAL("Instruction not implemeted yet");
      break;
  }

  int32_t off32 = static_cast<int32_t>(off64);
  if (off32 != off64) {
    FATAL("imm unexpectedly does not fit into int32 (%lld vs %d)", off64,
          off32);
  }
  return off32;
}


bool Arm64Assembler::IsRipRelative(ModuleInfo *module, Instruction &inst,
                                   size_t instruction_address,
                                   size_t *mem_address) {
  bool pc_relative = false;
  int64_t offset;

  switch (inst.instr.opcode) {
    case arm64::kLdrLiteral:
    case arm64::kLdrsLiteral:
    case arm64::kAdr:
      pc_relative = true;
      offset = GetRipRelativeOffset(inst);
      break;

    case arm64::kAdrp:
      pc_relative = true;
      offset = GetRipRelativeOffset(inst);
      offset <<= 12;
      break;

    case arm64::kPrfmLiteral:
      // ¯\_(ツ)_/¯
      pc_relative = true;
      offset = 0;
      break;

    default:
      break;
  }

  if (!pc_relative) return false;

  *mem_address = (size_t)(instruction_address + offset);
  return pc_relative;
}

void Arm64Assembler::FixInstructionAndOutput(
    ModuleInfo *module, Instruction &inst, const unsigned char *input,
    const unsigned char *input_address_remote, bool convert_call_to_jmp) {
  size_t mem_address = 0;
  bool rip_relative =
      IsRipRelative(module, inst, (size_t)input_address_remote, &mem_address);

  size_t original_instruction_size = 4;

  bool needs_fixing = rip_relative || convert_call_to_jmp;

  // fast path
  // just copy instruction bytes without encoding
  if (!needs_fixing) {
    tinyinst_.WriteCode(module, (void *)input, original_instruction_size);
    return;
  }

  if (convert_call_to_jmp) {
    FATAL("convert_call_to_jmp not implemented");
  }

  if (!rip_relative) {
    tinyinst_.WriteCode(module, (void *)input, original_instruction_size);
    return;
  }

  switch (inst.instr.opcode) {
    case arm64::Opcode::kAdr: {
      uint64_t addr = (uint64_t)input_address_remote;
      addr += GetRipRelativeOffset(inst);
      auto dst_reg = std::get<arm64::Register>(inst.instr.operands[0]);
      EmitLoadLit(module, reg(dst_reg), dst_reg.size, false, addr);
      break;
    }

    case arm64::Opcode::kAdrp: {
      uint64_t addr = ((uint64_t)input_address_remote) >> 12;
      addr += GetRipRelativeOffset(inst);
      addr <<= 12;
      auto dst_reg = std::get<arm64::Register>(inst.instr.operands[0]);
      EmitLoadLit(module, reg(dst_reg), dst_reg.size, false, addr);
      break;
    }

    case arm64::Opcode::kLdrLiteral: {
      uint64_t addr = (uint64_t)input_address_remote;
      addr += GetRipRelativeOffset(inst);
      auto dst_reg = std::get<arm64::Register>(inst.instr.operands[0]);
      EmitLoadLit(module, reg(dst_reg), 64, false, addr);
      uint32_t ldr_instr = ldr(dst_reg.size, reg(dst_reg), reg(dst_reg), 0);
      tinyinst_.WriteCode(module, &ldr_instr, sizeof(ldr_instr));
      break;
    }

    case arm64::Opcode::kLdrsLiteral: {
      FATAL("arm64::kLdrsLiteral");
      break;
    }

    case arm64::Opcode::kPrfmLiteral:
      // ¯\_(ツ)_/¯
      tinyinst_.WriteCode(module, &NOP, sizeof(NOP));
      break;

    default:
      PrintInstruction(inst);
      FATAL("not implemented yet");
      break;
  }
}

void Arm64Assembler::InstrumentRet(
    const char *address, ModuleInfo *module, std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes, Instruction &inst,
    const char *code_ptr, size_t offset, size_t last_offset) {
  TinyInst::IndirectInstrumentation ii_mode =
      tinyinst_.ShouldInstrumentIndirect(module, inst,
                                         (size_t)address + last_offset);

  if (ii_mode != TinyInst::IndirectInstrumentation::II_NONE) {
    tinyinst_.InstrumentIndirect(module, inst, (size_t)address + last_offset,
                                 ii_mode, (size_t)address);
  } else {
    FixInstructionAndOutput(module, inst,
                            (unsigned char *)(code_ptr + last_offset),
                            (unsigned char *)(address + last_offset));
  }
}

static uint32_t GetInstructionWithClearedImmediateBits(Instruction &inst) {
  uint32_t instruction = *((uint32_t *)inst.instr.address);

  switch (inst.instr.opcode) {
    case arm64::Opcode::kBCond:
      // clear all bits that are used for immediate value
      instruction &= ~bits(23, 5, 0xFFFFFFFF);
      break;
    case arm64::Opcode::kTbz:
    case arm64::Opcode::kTbnz:
      instruction &= ~bits(18, 5, 0xFFFFFFFF);
      break;
    case arm64::Opcode::kCbz:
    case arm64::Opcode::kCbnz:
      instruction &= ~bits(23, 5, 0xFFFFFFFF);
      break;
    default:
      PrintInstruction(inst);
      FATAL("Instruction not implemeted yet");
      break;
  }
  return instruction;
}

void Arm64Assembler::InstrumentCondJmp(
    const char *address, ModuleInfo *module, std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes, Instruction &inst,
    const char *code_ptr, size_t offset, size_t last_offset) {
  // j* target_address
  // gets instrumented as:
  //   j* label
  //   <edge instrumentation>
  //   jmp continue_address
  // label:
  //   <edge instrumentation>
  //   jmp target_address

  uint32_t cond_jmp_instr = GetInstructionWithClearedImmediateBits(inst);
  int32_t branch_offset = GetRipRelativeOffset(inst);

  const char *target_address1 = address + offset;
  const char *target_address2 = address + last_offset + branch_offset;

  if (tinyinst_.GetModule((size_t)target_address2) != module) {
    WARN("Relative jump to a differen module in bb at %p\n",
         static_cast<const void *>(address));
    tinyinst_.InvalidInstruction(module);
    return;
  }

  // preliminary encode cond branch instruction
  // offset will be changed later as we don't know
  // the size of edge instrumentation yet
  // assuming 0 for now
  size_t cond_branch_offset = module->instrumented_code_allocated;
  tinyinst_.WriteCode(module, &cond_jmp_instr, sizeof(cond_jmp_instr));

  // instrument the 1st edge
  tinyinst_.InstrumentEdge(module, module, (size_t)address,
                           (size_t)target_address1);

  uint32_t branch_instr = b(0, 0);
  // jmp target_address1
  tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

  tinyinst_.FixOffsetOrEnqueue(
      module,
      (uint32_t)((size_t)target_address1 - (size_t)(module->min_address)),
      (uint32_t)(module->instrumented_code_allocated - 4), queue, offset_fixes);

  // offset to the "label:" mentioned above
  uint32_t label_offset = module->instrumented_code_allocated;

  // fix conditional branch
  FixOffset(module, cond_branch_offset, label_offset);

  // instrument the 2nd edge
  tinyinst_.InstrumentEdge(module, module, (size_t)address,
                           (size_t)target_address2);

  // jmp target_address2
  tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

  tinyinst_.FixOffsetOrEnqueue(
      module,
      (uint32_t)((size_t)target_address2 - (size_t)(module->min_address)),
      (uint32_t)(module->instrumented_code_allocated - 4), queue, offset_fixes);
}

void Arm64Assembler::InstrumentJmp(
    const char *address, ModuleInfo *module, std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes, Instruction &inst,
    const char *code_ptr, size_t offset, size_t last_offset) {
  // direct branch
  if (inst.instr.opcode == arm64::Opcode::kB) {
    // jmp address
    // gets instrumented as:
    // jmp fixed_address
    size_t b_instr_off = module->instrumented_code_allocated;

    int32_t branch_offset = GetRipRelativeOffset(inst);

    const char *target_address = address + last_offset + branch_offset;

    if (tinyinst_.GetModule((size_t)target_address) != module) {
      WARN("Relative jump to a differen module in bb at %p\n", (void *)address);
      tinyinst_.InvalidInstruction(module);
      return;
    }

    uint32_t branch_instr = b(0, 0);
    // jmp target_address1
    tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

    tinyinst_.FixOffsetOrEnqueue(
        module,
        (uint32_t)((size_t)target_address - (size_t)(module->min_address)),
        (uint32_t)(module->instrumented_code_allocated - 4), queue,
        offset_fixes);
  }

  // indirect branch
  else {
    TinyInst::IndirectInstrumentation ii_mode =
        tinyinst_.ShouldInstrumentIndirect(module, inst,
                                           (size_t)address + last_offset);
    if (ii_mode != TinyInst::IndirectInstrumentation::II_NONE) {
      tinyinst_.InstrumentIndirect(module, inst, (size_t)address + last_offset,
                                   ii_mode, (size_t)address);
    } else {
      FixInstructionAndOutput(module, inst,
                              (unsigned char *)(code_ptr + last_offset),
                              (unsigned char *)(address + last_offset));
    }
  }
}

void Arm64Assembler::InstrumentCall(
    const char *address, ModuleInfo *module, std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes, Instruction &inst,
    const char *code_ptr, size_t offset, size_t last_offset) {
  // direct branch
  if (inst.instr.opcode == arm64::Opcode::kBl) {
    // call target_address
    // gets instrumented as:
    //   call label
    //   jmp return_address
    // label:
    //   jmp target_address

    int32_t branch_offset = GetRipRelativeOffset(inst);

    const char *return_address = address + offset;
    const char *call_address = address + last_offset + branch_offset;

    if (tinyinst_.GetModule((size_t)call_address) != module) {
      WARN("Relative jump to a differen module in bb at %p\n",
           static_cast<const void *>(address));
      tinyinst_.InvalidInstruction(module);
      return;
    }

    if (!tinyinst_.patch_return_addresses) {
      uint64_t addr = (uint64_t)module->instrumented_code_allocated +
                      (uint64_t)module->instrumented_code_local;
      size_t b_instr_off = module->instrumented_code_allocated;

      uint32_t bl_instr = bl(0, 8);
      tinyinst_.WriteCode(module, &bl_instr, sizeof(bl_instr));

      size_t translated_return_address = tinyinst_.GetCurrentInstrumentedAddress(module);
      tinyinst_.OnReturnAddress(module, (size_t)return_address, translated_return_address);

      uint32_t branch_instr = b(0, 0);
      // jmp return_address
      tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

      tinyinst_.FixOffsetOrEnqueue(
          module,
          (uint32_t)((size_t)return_address - (size_t)(module->min_address)),
          (uint32_t)(module->instrumented_code_allocated - 4), queue,
          offset_fixes);

      // jmp call_address
      tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

      tinyinst_.FixOffsetOrEnqueue(
          module,
          (uint32_t)((size_t)call_address - (size_t)(module->min_address)),
          (uint32_t)(module->instrumented_code_allocated - 4), queue,
          offset_fixes);
    } else {
      SetReturnAddress(module, (uint64_t)return_address);

      uint32_t branch_instr = b(0, 0);
      // jmp call_address
      tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

      tinyinst_.FixOffsetOrEnqueue(
          module,
          (uint32_t)((size_t)call_address - (size_t)(module->min_address)),
          (uint32_t)(module->instrumented_code_allocated - 4), queue,
          offset_fixes);
      // done, we don't need to do anything else as return gets redirected
      // later
    }
  }
  // indirect branch
  else {
    const char *return_address = address + offset;
    TinyInst::IndirectInstrumentation ii_mode =
        tinyinst_.ShouldInstrumentIndirect(module, inst,
                                           (size_t)address + last_offset);

    if (ii_mode != TinyInst::IndirectInstrumentation::II_NONE) {
      if (tinyinst_.patch_return_addresses) {
        SetReturnAddress(module, (uint64_t)return_address);

        tinyinst_.InstrumentIndirect(module, inst,
                                     (size_t)address + last_offset, ii_mode,
                                     (size_t)address);
      } else {
        //   call label
        //   jmp return_address
        //  label:
        //    <indirect instrumentation>
        uint32_t bl_instr = bl(0, 8);
        tinyinst_.WriteCode(module, &bl_instr, sizeof(bl_instr));

        size_t translated_return_address = tinyinst_.GetCurrentInstrumentedAddress(module);
        tinyinst_.OnReturnAddress(module, (size_t)return_address, translated_return_address);

        uint32_t branch_instr = b(0, 0);
        // jmp return_address
        tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

        tinyinst_.FixOffsetOrEnqueue(
            module,
            (uint32_t)((size_t)return_address - (size_t)(module->min_address)),
            (uint32_t)(module->instrumented_code_allocated - 4), queue,
            offset_fixes);

        tinyinst_.InstrumentIndirect(module, inst,
                                     (size_t)address + last_offset, ii_mode,
                                     (size_t)address);
      }
    } else {
      if (tinyinst_.patch_return_addresses) {
        SetReturnAddress(module, (uint64_t)return_address);
        FixInstructionAndOutput(module, inst,
                                (unsigned char *)(code_ptr + last_offset),
                                (unsigned char *)(address + last_offset), true);
      } else {
        FixInstructionAndOutput(module, inst,
                                (unsigned char *)(code_ptr + last_offset),
                                (unsigned char *)(address + last_offset));

        size_t translated_return_address = tinyinst_.GetCurrentInstrumentedAddress(module);
        tinyinst_.OnReturnAddress(module, (size_t)return_address, translated_return_address);

        uint32_t branch_instr = b(0, 0);
        tinyinst_.WriteCode(module, &branch_instr, sizeof(branch_instr));

        tinyinst_.FixOffsetOrEnqueue(
            module,
            (uint32_t)((size_t)return_address - (size_t)(module->min_address)),
            (uint32_t)(module->instrumented_code_allocated - 4), queue,
            offset_fixes);
      }
    }
  }
}

void Arm64Assembler::HandleBasicBlockEnd(
    const char *address, ModuleInfo *module, std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes, Instruction &inst,
    const char *code_ptr, size_t offset, size_t last_offset) {

  if (IsReturnInstruction(inst.instr.opcode)) {
    InstrumentRet(address, module, queue, offset_fixes, inst, code_ptr, offset,
                  last_offset);
  }

  else if (IsCondJmpInstruction(inst.instr.opcode)) {
    InstrumentCondJmp(address, module, queue, offset_fixes, inst, code_ptr,
                      offset, last_offset);
  } else if (IsJmpInstruction(inst.instr.opcode)) {
    InstrumentJmp(address, module, queue, offset_fixes, inst, code_ptr, offset,
                  last_offset);
  }

  else if (IsCallInstruction(inst.instr.opcode)) {
    InstrumentCall(address, module, queue, offset_fixes, inst, code_ptr, offset,
                   last_offset);
  }

  else {
    PrintInstruction(inst);
    FATAL("Unexpected control-flow instruction");
  }
}

bool Arm64Assembler::DecodeInstruction(Instruction &inst,
                                       const unsigned char *buffer,
                                       unsigned int buffer_size) {
  uint32_t opcode;
  memcpy(&opcode, buffer, sizeof(opcode));
  inst.instr = arm64::DecodeInstruction((uint64_t)buffer, opcode);
  inst.address = (size_t)buffer;
  inst.length = 4;
  inst.bbend = false;

  switch (inst.instr.opcode) {
    case arm64::Opcode::kBl:
    case arm64::Opcode::kBlr:
    case arm64::Opcode::kBlraa:
    case arm64::Opcode::kBlraaz:
    case arm64::Opcode::kBlrab:
    case arm64::Opcode::kBlrabz:
      inst.bbend = true;
      inst.iclass = InstructionClass::ICALL;
      break;

    case arm64::Opcode::kB:
    case arm64::Opcode::kBr:
    case arm64::Opcode::kBraa:
    case arm64::Opcode::kBraaz:
    case arm64::Opcode::kBrab:
    case arm64::Opcode::kBrabz:
    case arm64::Opcode::kCbnz:
    case arm64::Opcode::kCbz:
    case arm64::Opcode::kTbnz:
    case arm64::Opcode::kTbz:
    case arm64::Opcode::kBCond:
      inst.bbend = true;
      inst.iclass = InstructionClass::IJUMP;
      break;

    case arm64::Opcode::kRet:
    case arm64::Opcode::kRetaa:
    case arm64::Opcode::kRetaaz:
    case arm64::Opcode::kRetab:
    case arm64::Opcode::kRetabz:
      inst.bbend = true;
      inst.iclass = InstructionClass::RET;
      break;

    default:
      inst.iclass = InstructionClass::OTHER;
      break;
  }
  return true;
}

void Arm64Assembler::Init(){};

```

`arch/arm64/arm64_assembler.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ARCH_ARM64_ARM64_ASSEMBLER_H
#define ARCH_ARM64_ARM64_ASSEMBLER_H

#include "arch/arm64/arm64_helpers.h"
#include "assembler.h"
#include "tinyinst.h"

class Arm64Assembler : public Assembler {
 public:
  using Assembler::Assembler;
  virtual ~Arm64Assembler() {}
  void Init() override;

  bool DecodeInstruction(Instruction &inst, const unsigned char *buffer,
                         unsigned int buffer_size) override;
  void FixInstructionAndOutput(ModuleInfo *module, Instruction &inst,
                               const unsigned char *input,
                               const unsigned char *input_address_remote,
                               bool convert_call_to_jmp = false) override;
  void HandleBasicBlockEnd(
      const char *address, ModuleInfo *module, std::set<char *> *queue,
      std::list<std::pair<uint32_t, uint32_t>> *offset_fixes, Instruction &inst,
      const char *code_ptr, size_t offset, size_t last_offset) override;

  void JmpAddress(ModuleInfo *module, size_t address) override;
  void Nop(ModuleInfo *module) override;
  void Breakpoint(ModuleInfo *module) override;
  void Crash(ModuleInfo *module) override;

  void OffsetStack(ModuleInfo *module, int32_t offset) override;
  bool IsRipRelative(ModuleInfo *module, Instruction &inst,
                     size_t instruction_address, size_t *mem_address) override;
  void TranslateJmp(ModuleInfo *module, ModuleInfo *target_module,
                    size_t original_target,
                    IndirectBreakpoinInfo &breakpoint_info,
                    bool global_indirect, size_t previous_offset) override;
  void InstrumentLocalIndirect(ModuleInfo *module, Instruction &inst,
                               size_t instruction_address,
                               size_t bb_address) override;
  void InstrumentGlobalIndirect(ModuleInfo *module, Instruction &inst,
                                size_t instruction_address) override;
  void FixOffset(ModuleInfo *module, uint32_t jmp_offset,
                 uint32_t target_offset) override;

 protected:
  void ReadRegStack(ModuleInfo *module, Register dst, int32_t offset);
  void WriteRegStack(ModuleInfo *module, Register src, int32_t offset);
  void EmitLoadLit(ModuleInfo *module, Register dst_reg, size_t size,
                   bool is_signed, uint64_t value);

 private:
  uint8_t MovIndirectTarget(ModuleInfo *module, Instruction &inst);

  void ReadStack(ModuleInfo *module, int32_t offset);
  void WriteStack(ModuleInfo *module, int32_t offset);

  void SetReturnAddress(ModuleInfo *module, uint64_t return_address);

  void InstrumentRet(const char *address, ModuleInfo *module,
                     std::set<char *> *queue,
                     std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
                     Instruction &inst, const char *code_ptr, size_t offset,
                     size_t last_offset);
  void InstrumentCondJmp(const char *address, ModuleInfo *module,
                         std::set<char *> *queue,
                         std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
                         Instruction &inst, const char *code_ptr, size_t offset,
                         size_t last_offset);
  void InstrumentJmp(const char *address, ModuleInfo *module,
                     std::set<char *> *queue,
                     std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
                     Instruction &inst, const char *code_ptr, size_t offset,
                     size_t last_offset);
  void InstrumentCall(const char *address, ModuleInfo *module,
                      std::set<char *> *queue,
                      std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
                      Instruction &inst, const char *code_ptr, size_t offset,
                      size_t last_offset);

  friend class LiteCov;
};
#endif  // ARCH_ARM64_ARM64_ASSEMBLER_H

```

`arch/arm64/arm64_helpers.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "arch/arm64/arm64_helpers.h"

#include <algorithm>
#include <vector>

#include "common.h"


Register reg(arm64::Register r) {
  switch(r.name) {
        case arm64::Register::kX0:
      return X0;
    case arm64::Register::kX1:
      return X1;
    case arm64::Register::kX2:
      return X2;
    case arm64::Register::kX3:
      return X3;
    case arm64::Register::kX4:
      return X4;
    case arm64::Register::kX5:
      return X5;
    case arm64::Register::kX6:
      return X6;
    case arm64::Register::kX7:
      return X7;
    case arm64::Register::kX8:
      return X8;
    case arm64::Register::kX9:
      return X9;
    case arm64::Register::kX10:
      return X10;
    case arm64::Register::kX11:
      return X11;
    case arm64::Register::kX12:
      return X12;
    case arm64::Register::kX13:
      return X13;
    case arm64::Register::kX14:
      return X14;
    case arm64::Register::kX15:
      return X15;
    case arm64::Register::kX16:
      return X16;
    case arm64::Register::kX17:
      return X17;
    case arm64::Register::kX18:
      return X18;
    case arm64::Register::kX19:
      return X19;
    case arm64::Register::kX20:
      return X20;
    case arm64::Register::kX21:
      return X21;
    case arm64::Register::kX22:
      return X22;
    case arm64::Register::kX23:
      return X23;
    case arm64::Register::kX24:
      return X24;
    case arm64::Register::kX25:
      return X25;
    case arm64::Register::kX26:
      return X26;
    case arm64::Register::kX27:
      return X27;
    case arm64::Register::kX28:
      return X28;
    case arm64::Register::kX29:
      return X29;
    case arm64::Register::kX30:
      return X30;
    case arm64::Register::kXzr:
      return XZR;
    default:
      FATAL("unsupported register");
  }
}

uint32_t bits(uint32_t msb, uint32_t lsb, uint32_t val) {
  uint32_t mask = 0xffffffffu >> (32 - (msb - lsb + 1));
  return (val & mask) << lsb;
}

uint32_t bit(uint32_t lsb) {
  return 1 << lsb;
}

uint32_t EncodeSignedImmediate(const uint8_t msb, const uint8_t lsb, int32_t value) {
  int32_t min = ((2 << (msb - lsb)) / 2) * -1;
  int32_t max = ((2 << (msb - lsb)) / 2) - 1;
  if (value < min || value > max) {
    FATAL("number must be in range [%d, %d], was %d", min, max, value);
    return 0; // not reached
  }
  return bits(msb, lsb, value);
}

uint32_t EncodeUnsignedImmediate(const uint8_t msb, const uint8_t lsb, uint32_t value) {
  int32_t max = ((2 << (msb - lsb))) - 1;
  if (value > max) {
    FATAL("number must be in range [0, %d], was %d", max, value);
    return 0; // not reached
  }
  return bits(msb, lsb, value);
}

uint32_t ldr_lit(Register dst_reg, int64_t rip_offset, size_t size, bool is_signed) {
  uint32_t instr = 0;

  uint32_t opc = 0;
  /**/ if(!is_signed && size == 32) opc = 0b00; // LDR (literal) 32-bit
  else if(!is_signed && size == 64) opc = 0b01; // LDR (literal) 64-bit
  else if( is_signed && size == 32) opc = 0b10; // LDRSW (literal) 32-bit
  else FATAL("size must be either unsigned 32/64, or signed 32\n");

  if (rip_offset & 3) {
    FATAL("rip_offset must be aligned");
  }

  // load/store
  instr |= bits(28, 25, 0b0100);

  // load literal
  instr |= bits(29, 28, 0b01);

  // instr
  instr |= bits(31, 30, opc);
  instr |= EncodeSignedImmediate(23, 5, rip_offset >> 2);
  instr |= bits(4, 0, static_cast<uint32_t>(dst_reg));

  return instr;
}

uint32_t br(Register dst_reg) {
  uint32_t instr = 0;

  // branch exception
  instr |= bits(28, 25, 0b1010);


  // branch register
  instr |= bits(31, 29, 0b110);
  instr |= bits(25, 22, 0b1000);

  instr |= bits(20, 16, 0b11111);

  instr |= bits(9, 5, dst_reg);
  return instr;
}

uint32_t b_cond(const std::string &cond, int32_t off) {
  static const std::vector<const std::string> condition_codes = {
      "eq", "ne", "cs", "cc", "mi", "pl", "vs", "vc",
      "hi", "ls", "ge", "lt", "gt", "le", "al", "al"
  };

  if(off & 3) {
    FATAL("offset must be aligned to 4, was: %d", off);
  }

  auto it = std::find(condition_codes.begin(), condition_codes.end(), cond);
  if(it == condition_codes.end()) {
    FATAL("unknown condition: %s", cond.c_str());
  }

  auto cond_bits = std::distance(condition_codes.begin(), it);

  uint32_t instr = 0;

  // branch exception
  instr |= bits(28, 25, 0b1010);
  // branch cond
  instr |= bits(31, 29, 0b010);
  // for cond branch all further instruction bits are 0

  // operands
  instr |= EncodeSignedImmediate(24, 5, off >> 2);
  instr |= bits(3, 0, static_cast<uint32_t>(cond_bits));
  return instr;
}

uint32_t load_store(uint8_t op, uint8_t size, Register data_reg, Register base_reg, int32_t offset) {
  uint32_t instr = 0;

  uint32_t size_bin = 0;
  /**/ if(size == 64) size_bin = 0b11;
  else if(size == 32) size_bin = 0b10;
  else if(size == 16) size_bin = 0b01;
  else if(size ==  8) size_bin = 0b00;
  else FATAL("size must be either 64, 32, 16, or 8\n");

  // load/store
  instr |= bits(28, 25, 0b0100);

  // sz
  instr |= bits(31, 30, size_bin);

  // unscaled imm, reg offset, unsigned imm
  instr |= bits(29, 28, 0b11);

  // LD*R/B/H or / ST*R/B/H
  instr |= bits(23, 22, op);

  instr |= bits(4, 0, static_cast<uint32_t>(data_reg));

  // base 
  instr |= bits(9, 5, static_cast<uint32_t>(base_reg));
  // offset
  instr |= EncodeSignedImmediate(20, 12, offset);

  return instr;
}

uint32_t movzn(Register dst_reg, int32_t imm) {
  uint32_t instr = 0;

  // 64 bit
  instr |= bit(31);

  // data processing imm
  instr |= bits(28, 25, 0b1000);

  // move wide imm
  instr |= bits(25, 23, 0b101);

  if(imm < 0) {
    // movn
    instr |= bits(30, 29, 0b00);
  }
  else {
    // movz
    instr |= bits(30, 29, 0b10);
  }

  instr |= EncodeUnsignedImmediate(20, 5, std::abs(imm));
  instr |= bits(4, 0, static_cast<uint32_t>(dst_reg));
  return instr;
}

uint32_t ldr(uint8_t size, Register data_reg, Register base_reg, int32_t offset) {
  // LD*R/B/H == 0b01
  return load_store(0b01, size, data_reg, base_reg, offset);
}

uint32_t str(uint8_t size, Register data_reg, Register base_reg, int32_t offset) {
  // LD*R/B/H == 0b00
  return load_store(0b00, size, data_reg, base_reg, offset);
}


// TODO: change op to reil instruction constant
uint32_t add_sub_reg_imm(uint8_t op, Register dst_reg, Register src_reg, uint32_t offset) {
  uint32_t instr = 0;

  // data process immm
  instr |= bits(28, 25, 0b01000);

  // add/sub imm
  instr |= bits(25, 23, 0b010);

  // 64 bit
  instr |= bit(31);

  // add or sub
  if(op == 1) {
    // sub
    instr |= bit(30);
  }
  else {
    // add
    // dont set bit
  }

  instr |= bits(4, 0, dst_reg);
  instr |= bits(9, 5, src_reg);
  instr |= EncodeUnsignedImmediate(21, 10, offset);

  return instr;
}


uint32_t cmp(Register src1, Register src2) {
  uint32_t instr = 0;

  // data processing register
  instr |= bits(28, 25, 0b0101);

  // data process reg
  instr |= bits(24, 21, 0b1000);

  // size ==  64 bit
  instr |= bit(31);

  // sub
  instr |= bit(30);

  // set flag
  instr |= bit(29);

  instr |= bits(20, 16, src2);
  instr |= bits(9, 5, src1);
  instr |= bits(4, 0, Register::XZR);
  return instr;
}



uint32_t sub_reg_imm(Register dst_reg, Register src_reg, uint32_t offset) {
  return add_sub_reg_imm(1, dst_reg, src_reg, offset);
}

uint32_t add_reg_imm(Register dst_reg, Register src_reg, uint32_t offset) {
  return add_sub_reg_imm(0, dst_reg, src_reg, offset);
}

uint32_t branch_imm(size_t instr_address, size_t address, bool do_link) {
  uint32_t instr = 0;

  // check 4 byte alignment
  if (address & 3 || instr_address & 3) {
    FATAL("Source and Target address (%lx/%lx) must be alignt to 4 bytes", instr_address, address);
  }

  int32_t offset = (int32_t)(address - instr_address);

  // bl xzr
  instr |= bits(28, 25, 0b1010);
  instr |= EncodeSignedImmediate(25,  0, offset>>2);

  if(do_link) {
    instr |= bit(31);
  }

  return instr;
}

uint32_t orr_shifted_reg(Register dst, Register rn, Register src) {
  uint32_t instr = 0;

  // data processing register
  instr |= bits(28, 25, 0b0101);

  // logical shifted Register

  // size = 64bit
  instr |= bit(31);

  // kOrrShiftedRegister
  instr |= bits(30, 29, 0b01);

  instr |= bits( 4,  0, dst);
  instr |= bits( 9,  5, rn);
  instr |= bits(20, 16, src);

  return instr;
}

// Encode arm64 Bitwise Exclusive OR (shifted register) instruction.
// (https://developer.arm.com/documentation/dui0801/g/A64-General-Instructions/EOR--shifted-register-)
uint32_t eor_shifted_reg(uint8_t sz, Register rd, Register rn, Register rm, arm64::Shift::Type shift_type, uint8_t shift_count) {
  uint32_t instr = 0;

  if(sz == 64) {
    instr |= bit(31);
  }
  else if (sz == 32) {

  }
  else {
    FATAL("eor: unexpected size. Valid is 32 or 64, was %d", sz);
  }

  // data processing register
  instr |= bits(29, 25, 0b0101);

  // logical shift instr
  // bit 28 not set
  // bit 24 not set

  // kEorShiftedRegister
  instr |= bits(30, 29, 0b10);

  // dst
  instr |= bits(4, 0, rd);

  // src1
  instr |= bits(9, 5, rn);

  // src2
  instr |= bits(20, 16, rm);

  // count
  instr |= EncodeUnsignedImmediate(15, 10, shift_count);

  switch (shift_type) {
    case arm64::Shift::kNone:
    case arm64::Shift::kLsl:
      break;
    case arm64::Shift::kLsr:
      instr |= bits(23, 22, 0b01);
      break;
    case arm64::Shift::kAsr:
      instr |= bits(23, 22, 0b10);
      break;
    case arm64::Shift::kRor:
      instr |= bits(23, 22, 0b11);
      break;
    default:
      FATAL("eor: unknown shift type: %d", shift_type);
  }

  return instr;
}

uint32_t movz_imm(Register dst, int32_t imm) {
  uint32_t instr = 0;

  // data processing immediate
  instr |= bits(28, 25, 0b1000);

  // mov wide immediate
  instr |= bits(25, 23, 0b101);

  // size == 64 bit
  instr |= bit(31);

  // kMovz
  instr |= bits(30, 29, 0b10);

  instr |= EncodeUnsignedImmediate(20, 5, imm);
  instr |= bits(4, 0, dst);
  return instr;
}

uint32_t mov(Register dst, Register src) {
  return orr_shifted_reg(dst, Register::XZR, src);
}

uint32_t b(size_t instr_address, size_t address) {
  return branch_imm(instr_address, address, false);
}

uint32_t bl(size_t instr_address, size_t address) {
  return branch_imm(instr_address, address, true);
}

```

`arch/arm64/arm64_helpers.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ARCH_ARM64_ARM64_HELPERS_H
#define ARCH_ARM64_ARM64_HELPERS_H

#include <cstdint>
#include <cstddef>
#include <string>

#include "third_party/reil/reil/aarch64/decoder.h"
#include "arch/arm64/reg.h"

namespace arm64 = reil::aarch64::decoder;

Register reg(arm64::Register r);

uint32_t bits(uint32_t msb, uint32_t lsb, uint32_t val);
uint32_t bit(uint32_t lsb);

uint32_t EncodeSignedImmediate(const uint8_t msb, const uint8_t lsb, int32_t value);
uint32_t EncodeUnsignedImmediate(const uint8_t msb, const uint8_t lsb, uint32_t value);

uint32_t ldr(uint8_t size, Register data_reg, Register base_reg, int32_t offset);
uint32_t str(uint8_t size, Register data_reg, Register base_reg, int32_t offset);
uint32_t ldr_lit(Register dst_reg, int64_t rip_offset, size_t size, bool is_signed);
uint32_t load_store(uint8_t op, uint8_t size, Register data_reg, Register base_reg, int32_t offset);

uint32_t movzn(Register dst_reg, int32_t imm);
uint32_t movz_imm(Register dst, int32_t imm);
uint32_t mov(Register dst, Register src);

uint32_t add_sub_reg_imm(uint8_t op, Register dst_reg, Register src_reg, uint32_t offset);
uint32_t sub_reg_imm(Register dst_reg, Register src_reg, uint32_t offset);
uint32_t add_reg_imm(Register dst_reg, Register src_reg, uint32_t offset);
uint32_t orr_shifted_reg(Register dst, Register rn, Register src);
uint32_t eor_shifted_reg(uint8_t sz, Register rd, Register rn, Register rm, arm64::Shift::Type shift_type, uint8_t shift_count);

uint32_t cmp(Register src1, Register src2);

uint32_t branch_imm(size_t instr_address, size_t address, bool do_link);
uint32_t b(size_t instr_address, size_t address);
uint32_t bl(size_t instr_address, size_t address);
uint32_t br(Register dst_reg);
uint32_t b_cond(const std::string &cond, int32_t off);


#endif  // ARCH_ARM64_ARM64_HELPERS_H

```

`arch/arm64/arm64_litecov.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "arch/arm64/arm64_assembler.h"
#include "arch/arm64/arm64_helpers.h"
#include "common.h"
#include "instruction.h"
#include "litecov.h"

void LiteCov::NopCovInstructions(ModuleInfo *module, size_t code_offset) {
  uint32_t b_instr = b(0, skip_cov_instruction_br_off);
  WriteCodeAtOffset(module, code_offset, &b_instr, sizeof(b_instr));
  // need to commit since this isn't a part of normal instrumentation process
  CommitCode(module, code_offset, sizeof(b_instr));
}

void LiteCov::NopCmpCovInstructions(ModuleInfo *module,
                                    CmpCoverageRecord &cmp_record,
                                    int matched_width) {
  if (matched_width >= cmp_record.width - 8) {
    uint32_t b_instr = b(0, cmp_record.instrumentation_size);
    WriteCodeAtOffset(module, cmp_record.instrumentation_offset, &b_instr,
                      sizeof(b_instr));
    CommitCode(module, cmp_record.instrumentation_offset, sizeof(b_instr));
    cmp_record.ignored = true;
    return;
  }

  if (matched_width >= cmp_record.match_width) {
    cmp_record.match_width = matched_width + 8;
    char new_offset_data = static_cast<char>(cmp_record.match_width);
    WriteCodeAtOffset(module, cmp_record.match_width_offset, &new_offset_data,
                      1);
    CommitCode(module, cmp_record.instrumentation_offset, 1);
  }
}

void LiteCov::EmitCoverageInstrumentation(ModuleInfo *module,
                                          size_t bit_address,
                                          size_t mov_address) {
  //////////////////////////////////////////////////
  // mov [coverage_buffer + coverage_buffer_next], 1
  //////////////////////////////////////////////////

  Arm64Assembler *arm64asm = static_cast<Arm64Assembler *>(assembler_);

  size_t cov_instruction_start_off = module->instrumented_code_allocated;
  if (sp_offset) {
    arm64asm->OffsetStack(module, -sp_offset);
  }
  // 3 instr
  arm64asm->OffsetStack(module, -16);
  arm64asm->WriteRegStack(module, X0, 0);
  arm64asm->WriteRegStack(module, X1, 8);

  // 4 + 2 instr
  arm64asm->EmitLoadLit(module, X0, 64, false, bit_address);
  uint32_t mov = movz_imm(X1, 1);
  WriteCode(module, &mov, sizeof(mov));
  uint32_t strb = str(8, X1, X0, 0);
  WriteCode(module, &strb, sizeof(strb));

  // 3 instr
  arm64asm->ReadRegStack(module, X1, 8);
  arm64asm->ReadRegStack(module, X0, 0);
  arm64asm->OffsetStack(module, 16);

  if (sp_offset) {
    arm64asm->OffsetStack(module, sp_offset);
  }

  skip_cov_instruction_br_off = 
    module->instrumented_code_allocated - cov_instruction_start_off;
}

InstructionResult LiteCov::InstrumentInstruction(ModuleInfo *module,
                                                 Instruction &inst,
                                                 size_t bb_address,
                                                 size_t instruction_address) {
  if (!compare_coverage) {
    return INST_NOTHANDLED;
  }

  if (inst.instr.opcode != arm64::Opcode::kSubImmediate &&
      inst.instr.opcode != arm64::Opcode::kAddImmediate &&
      inst.instr.opcode != arm64::Opcode::kSubShiftedRegister &&
      inst.instr.opcode != arm64::Opcode::kAddShiftedRegister &&
      inst.instr.opcode != arm64::Opcode::kSubExtendedRegister &&
      inst.instr.opcode != arm64::Opcode::kAddExtendedRegister) {
    return INST_NOTHANDLED;
  }

  arm64::Register rd = std::get<arm64::Register>(inst.instr.operands[0]);
  int operand_width = rd.size;

  // Skip instructions that are unlikely to be used as compare:
  //  most compare instructions have zero register as destination
  //  switch statements use subs (setting flag)
  if (rd.name != arm64::Register::kXzr &&
      !(inst.instr.set_flags &&
        (inst.instr.opcode == arm64::Opcode::kSubImmediate ||
        inst.instr.opcode == arm64::Opcode::kSubShiftedRegister ||
        inst.instr.opcode == arm64::Opcode::kSubExtendedRegister))) {
    return INST_NOTHANDLED;
  }

  arm64::Register rn = std::get<arm64::Register>(inst.instr.operands[1]);
  if (rn.name == arm64::Register::kSp) {
    return INST_NOTHANDLED;
  }

  if (inst.instr.opcode == arm64::Opcode::kSubShiftedRegister ||
      inst.instr.opcode == arm64::Opcode::kAddShiftedRegister ||
      inst.instr.opcode == arm64::Opcode::kAddExtendedRegister ||
      inst.instr.opcode == arm64::Opcode::kSubExtendedRegister) {
    arm64::Register rm = std::get<arm64::Register>(inst.instr.operands[2]);
    if (rm.name == arm64::Register::kSp) {
      return INST_NOTHANDLED;
    }
  }

  // kSubExtendedRegister / kAddExtendedRegister might have sizes smaller than
  // 32 bit. In case of 8 bit cmp, skip, in case of 16bit cmp add and-instr
  // after xor.
  bool is_ext_16_bit = false;

  if (inst.instr.opcode == arm64::Opcode::kAddExtendedRegister ||
      inst.instr.opcode == arm64::Opcode::kSubExtendedRegister) {
    arm64::Extend extend = std::get<arm64::Extend>(inst.instr.operands[3]);

    // skip byte cmp
    if (extend.type == arm64::Extend::Type::kUxtb ||
        extend.type == arm64::Extend::Type::kSxtb) {
      return INST_NOTHANDLED;
    }
  }


  ModuleCovData *data = (ModuleCovData *)module->client_data;

  size_t bb_offset = bb_address - module->min_address;
  size_t cmp_offset = instruction_address - bb_address;
  if (cmp_offset >= 0x1000000) {
    // only allow one cmp instrumentation per bb
    WARN("Too large basic block for cmp coverage\n");
    return INST_NOTHANDLED;
  }

  // check what we matched already
  int match_width = operand_width - 8;
  for (; match_width >= 8; match_width -= 8) {
    uint64_t already_matched_code =
        GetCmpCode(bb_offset, cmp_offset, match_width);
    if (data->ignore_coverage.find(already_matched_code) !=
        data->ignore_coverage.end()) {
      break;
    }
  }
  match_width += 8;
  if (match_width == operand_width) {
    // we already have an (almost) full match
    return INST_NOTHANDLED;
  }

  size_t instrumentation_start_offset = module->instrumented_code_allocated;

  Arm64Assembler *arm64asm = static_cast<Arm64Assembler *>(assembler_);

  if (sp_offset) {
    arm64asm->OffsetStack(module, -sp_offset);
  }
  arm64asm->OffsetStack(module, -16);
  arm64asm->WriteRegStack(module, X1, 8);
  arm64asm->WriteRegStack(module, X0, 0);

  uint32_t eor_instr = 0;
  if (inst.instr.opcode == arm64::Opcode::kSubShiftedRegister ||
      inst.instr.opcode == arm64::Opcode::kAddShiftedRegister) {
    arm64::Register rn = std::get<arm64::Register>(inst.instr.operands[1]);
    arm64::Register rm = std::get<arm64::Register>(inst.instr.operands[2]);
    arm64::Shift shift = std::get<arm64::Shift>(inst.instr.operands[3]);

    eor_instr = eor_shifted_reg(operand_width, X0, reg(rn), reg(rm), shift.type,
                                shift.count);
  } else if (inst.instr.opcode == arm64::Opcode::kSubImmediate ||
             inst.instr.opcode == arm64::Opcode::kAddImmediate) {
    // Immediate encoding for xor is complex (DecodeBitMasks), hence, move
    // the imm into x0 or x1 for eor
    Register imm_reg = X0;
    if (rn.name == arm64::Register::Name::kX0) {
      imm_reg = X1;
    }

    auto imm = std::get<arm64::Immediate>(inst.instr.operands[2]);
    uint32_t mov_imm_instr = movz_imm(imm_reg, imm.value);
    WriteCode(module, &mov_imm_instr, sizeof(mov_imm_instr));

    eor_instr = eor_shifted_reg(operand_width, X0, reg(rn), imm_reg,
                                arm64::Shift::Type::kNone, 0);
  }

  else if (inst.instr.opcode == arm64::Opcode::kAddExtendedRegister ||
           inst.instr.opcode == arm64::Opcode::kSubExtendedRegister) {
    arm64::Register rn = std::get<arm64::Register>(inst.instr.operands[1]);
    arm64::Register rm = std::get<arm64::Register>(inst.instr.operands[2]);
    arm64::Extend extend = std::get<arm64::Extend>(inst.instr.operands[3]);

    if (extend.type == arm64::Extend::Type::kUxth ||
        extend.type == arm64::Extend::Type::kSxth) {
      is_ext_16_bit = true;
    }

    // ensure 32 bit op
    operand_width = 32;
    eor_instr = eor_shifted_reg(operand_width, X0, reg(rn), reg(rm),
                                arm64::Shift::Type::kNone, 0);
  }

  WriteCode(module, &eor_instr, sizeof(eor_instr));

  if (is_ext_16_bit) {
    // and x0, x0, 0xffff
    uint32_t and_instr = 0x92403c00;
    WriteCode(module, &and_instr, sizeof(and_instr));
  }

  // count leading zeros depending on operand width
  if (operand_width == 64) {
    uint32_t clz_x0_instr = 0xdac01000;
    WriteCode(module, &clz_x0_instr, sizeof(clz_x0_instr));
  } else {
    uint32_t clz_w0_instr = 0x5ac01000;
    WriteCode(module, &clz_w0_instr, sizeof(clz_w0_instr));
  }

  arm64asm->EmitLoadLit(module, X1, operand_width, false, match_width);
  size_t match_width_offset = module->instrumented_code_allocated - 8;

  uint32_t cmp_x0_x1_instr = cmp(X0, X1);
  WriteCode(module, &cmp_x0_x1_instr, sizeof(cmp_x0_x1_instr));

  size_t jmp_offset = module->instrumented_code_allocated;
  uint32_t b_lt = b_cond("lt", 0);
  WriteCode(module, &b_lt, sizeof(b_lt));

  size_t bit_address =
      (size_t)data->coverage_buffer_remote + data->coverage_buffer_next;
  arm64asm->EmitLoadLit(module, X1, 64, false, bit_address);
  size_t mov_address = GetCurrentInstrumentedAddress(module) - 8;

  uint32_t str_match = str(64, X0, X1, 0);
  WriteCode(module, &str_match, sizeof(str_match));

  arm64asm->FixOffset(module, jmp_offset, module->instrumented_code_allocated);

  arm64asm->ReadRegStack(module, X0, 0);
  arm64asm->ReadRegStack(module, X1, 8);
  arm64asm->OffsetStack(module, 16);
  if (sp_offset) {
    arm64asm->OffsetStack(module, sp_offset);
  }

  CmpCoverageRecord *cmp_record = new CmpCoverageRecord();
  cmp_record->ignored = false;
  cmp_record->width = operand_width;
  cmp_record->match_width = match_width;
  cmp_record->match_width_offset = match_width_offset;
  cmp_record->instrumentation_offset = instrumentation_start_offset;
  cmp_record->bb_address = bb_address;
  cmp_record->bb_offset = bb_offset;
  cmp_record->cmp_offset = cmp_offset;
  cmp_record->instrumentation_size =
      module->instrumented_code_allocated - instrumentation_start_offset;
  data->coverage_to_cmp[GetCmpCode(bb_offset, cmp_offset, 0)] = cmp_record;
  data->buf_to_cmp[data->coverage_buffer_next] = cmp_record;
  data->coverage_buffer_next++;

  // return INST_NOTHANDLED which causes
  // the original instruction to be repeated
  return INST_NOTHANDLED;
}

```

`arch/arm64/reg.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ARCH_ARM64_REG_H
#define ARCH_ARM64_REG_H

#define ARCH_SP SP
#define ARCH_PC PC
#define ARCH_RETURN_VALUE_REGISTER X0
#define ORIG_ADDR_REG X0

enum Register {
  X0 = 0,
  X1,
  X2,
  X3,
  X4,
  X5,
  X6,
  X7,
  X8,
  X9,
  X10,
  X11,
  X12,
  X13,
  X14,
  X15,
  X16,
  X17,
  X18,
  X19,
  X20,
  X21,
  X22,
  X23,
  X24,
  X25,
  X26,
  X27,
  X28,
  X29,  // fp
  X30,  // lr
  X31,  // sp
  PC,
  CPSR,
  FP = X29,
  LR = X30,
  SP = X31,
  XZR = X31, // magic..
};

#endif  // ARCH_ARM64_REG_H

```

`arch/x86/reg.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ARCH_X86_REG_H
#define ARCH_X86_REG_H

#define ARCH_SP RSP
#define ARCH_PC RIP
#define ARCH_RETURN_VALUE_REGISTER RAX
#define ARCH_PC RIP
#define ORIG_ADDR_REG RAX

enum Register {
  RAX,
  RCX,
  RDX,
  RBX,
  RSP,
  RBP,
  RSI,
  RDI,
  R8,
  R9,
  R10,
  R11,
  R12,
  R13,
  R14,
  R15,
  RIP
};

#endif  // ARCH_X86_REG_H

```

`arch/x86/x86_assembler.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "arch/x86/x86_assembler.h"

// int3
unsigned char BREAKPOINT[] = {0xCC};

// nop
unsigned char NOP[] = {0x90};

// jmp offset
unsigned char JMP[] = {0xe9, 0x00, 0x00, 0x00, 0x00};

// call offset
unsigned char CALL[] = {0xe8, 0x00, 0x00, 0x00, 0x00};

// warning, this is rip-relative on x64 but absolute on 32-bit
// jmp [offset]
unsigned char JMP_MEM[] = {0xFF, 0x25, 0x00, 0x00, 0x00, 0x00};

// lea rsp, [rsp + disp]
unsigned char LEARSP[] = {0x48, 0x8d, 0xa4, 0x24, 0x00, 0x00, 0x00, 0x00};
// lea esp, [esp + disp]
unsigned char LEAESP[] = {0x8D, 0xA4, 0x24, 0x00, 0x00, 0x00, 0x00};

// push flags
// push rax
// push rbx
unsigned char PUSH_FAB[] = {0x9c, 0x50, 0x53};

// push flags
// push rax
unsigned char PUSH_FA[] = {0x9c, 0x50};

// push flags
unsigned char PUSH_F[] = {0x9c};

// push rax
unsigned char PUSH_A[] = {0x50};

// push rbx
unsigned char PUSH_B[] = {0x53};

// pop rbx
// pop rax
// pop flags
unsigned char POP_BAF[] = {0x5B, 0x58, 0x9d};

// pop rax
// pop flags
unsigned char POP_AF[] = {0x58, 0x9d};

// pop rax
unsigned char POP_A[] = {0x58};

// and rbx, constant
unsigned char AND_RBX[] = {0x48, 0x81, 0xe3, 0x00, 0x00, 0x00, 0x00};
// and ebx, constant
unsigned char AND_EBX[] = {0x81, 0xe3, 0x00, 0x00, 0x00, 0x00};

// mov rbx, rax
unsigned char MOV_RBXRAX[] = {0x48, 0x89, 0xC3};
// mov ebx, eax
unsigned char MOV_EBXEAX[] = {0x89, 0xC3};

// add rbx, [offset]
unsigned char ADD_RBXRIPRELATIVE[] = {0x48, 0x03, 0x1D, 0x00, 0x00, 0x00, 0x00};
// add ebx, [offset]
unsigned char ADD_EBXRIPRELATIVE[] = {0x03, 0x1D, 0x00, 0x00, 0x00, 0x00};

// jmp [rbx]
unsigned char JMP_B[] = {0xFF, 0x23};

// cmp rax, [offset]
unsigned char CMP_RAX[] = {0x48, 0x3B, 0x05, 0x00, 0x00, 0x00, 0x00};
// cmp eax, [offset]
unsigned char CMP_EAX[] = {0x3B, 0x05, 0x00, 0x00, 0x00, 0x00};

// je offset
unsigned char JE[] = {0x0F, 0x84, 0x00, 0x00, 0x00, 0x00};

// mov [rsp], imm
unsigned char WRITE_SP_IMM[] = {0xC7, 0x04, 0x24, 0xAA, 0xAA, 0xAA, 0xAA};
// mov [rsp+4], imm
unsigned char WRITE_SP_4_IMM[] = {0xC7, 0x44, 0x24, 0x04,
                                  0xAA, 0xAA, 0xAA, 0xAA};

// mov rax, [rsp + offset]
unsigned char MOV_RAX_RSPMEM[] = {0x48, 0x8B, 0x84, 0x24,
                                  0xAA, 0xAA, 0xAA, 0x0A};
// mov eax, [esp + offset]
unsigned char MOV_EAX_ESPMEM[] = {0x8B, 0x84, 0x24, 0xAA, 0xAA, 0xAA, 0x0A};

// mov [rsp + offset], rax
unsigned char MOV_RSPMEM_RAX[] = {0x48, 0x89, 0x84, 0x24,
                                  0xAA, 0xAA, 0xAA, 0x0A};
// mov [esp + offset], eax
unsigned char MOV_ESPMEM_EAX[] = {0x89, 0x84, 0x24, 0xAA, 0xAA, 0xAA, 0x0A};

// mov byte ptr [0], 0
unsigned char CRASH_64[] = {0xC6, 0x04, 0x25, 0x00, 0x00, 0x00, 0x00, 0x00};
unsigned char CRASH_32[] = {0xC6, 0x05, 0x00, 0x00, 0x00, 0x00, 0x00};

// fixes the memory displacement of the current instruction
// (assumes it is in the 4 last bytes)
inline void X86Assembler::FixDisp4(ModuleInfo *module, int32_t disp) {
  *(int32_t *)(module->instrumented_code_local +
               module->instrumented_code_allocated - 4) = disp;
}

void X86Assembler::Crash(ModuleInfo *module) {
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, CRASH_64, sizeof(CRASH_64));
  } else {
    tinyinst_.WriteCode(module, CRASH_32, sizeof(CRASH_32));
  }
}

void X86Assembler::Breakpoint(ModuleInfo *module) {
  tinyinst_.WriteCode(module, &BREAKPOINT, sizeof(BREAKPOINT));
}

void X86Assembler::Nop(ModuleInfo *module) {
  tinyinst_.WriteCode(module, &NOP, sizeof(NOP));
}

void X86Assembler::JmpAddress(ModuleInfo *module, size_t address) {
  // just insert a jump to address
  tinyinst_.WriteCode(module, JMP_MEM, sizeof(JMP_MEM));
  if (tinyinst_.child_ptr_size == 4) {
    FixDisp4(module, (int32_t)tinyinst_.GetCurrentInstrumentedAddress(module));
  }
  tinyinst_.WritePointer(module, (size_t)address);
}

// checks if the instruction uses RIP-relative addressing,
// e.g. mov rax, [rip+displacement]; call [rip+displacement]
// and, if so, returns the memory address being referenced
bool X86Assembler::IsRipRelative(ModuleInfo *module,
                                 Instruction& inst,
                                 size_t instruction_address,
                                 size_t *mem_address) {
  bool rip_relative = false;
  int64_t disp;

  uint32_t memops = xed_decoded_inst_number_of_memory_operands(&inst.xedd);

  for (uint32_t i = 0; i < memops; i++) {
    xed_reg_enum_t base = xed_decoded_inst_get_base_reg(&inst.xedd, i);
    switch (base) {
      case XED_REG_RIP:
      case XED_REG_EIP:
      case XED_REG_IP:
        rip_relative = true;
        disp = xed_decoded_inst_get_memory_displacement(&inst.xedd, i);
        break;
      default:
        break;
    }
  }

  if (!rip_relative) return false;

  size_t instruction_size = xed_decoded_inst_get_length(&inst.xedd);
  *mem_address = (size_t)(instruction_address + instruction_size + disp);

  return rip_relative;
}

// adds/subtracts a given offset to the stack pointer
// this is done using LEA instruction rather than ADD/SUB
// to avoid clobbering the flags
void X86Assembler::OffsetStack(ModuleInfo *module, int32_t offset) {
  // lea rsp, [rsp + offset]
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, LEARSP, sizeof(LEARSP));
  } else {
    tinyinst_.WriteCode(module, LEAESP, sizeof(LEAESP));
  }

  FixDisp4(module, offset);
}

// mov rax, [rsp + offset]
void X86Assembler::ReadStack(ModuleInfo *module, int32_t offset) {
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, MOV_RAX_RSPMEM, sizeof(MOV_RAX_RSPMEM));
  } else {
    tinyinst_.WriteCode(module, MOV_EAX_ESPMEM, sizeof(MOV_EAX_ESPMEM));
  }
  FixDisp4(module, offset);
}

// mov [rsp + offset], rax
void X86Assembler::WriteStack(ModuleInfo *module, int32_t offset) {
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, MOV_RSPMEM_RAX, sizeof(MOV_RSPMEM_RAX));
  } else {
    tinyinst_.WriteCode(module, MOV_ESPMEM_EAX, sizeof(MOV_ESPMEM_EAX));
  }
  FixDisp4(module, offset);
}

// adds another observed original_target -> actual_target pair
// to the golbal jumptable at the appropriate location
void X86Assembler::TranslateJmp(ModuleInfo *module,
                                ModuleInfo *target_module,
                                size_t original_target,
                                IndirectBreakpoinInfo& breakpoint_info,
                                bool global_indirect,
                                size_t previous_offset) {

  // cmp RAX, [original_target]
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, CMP_RAX, sizeof(CMP_RAX));
  } else {
    tinyinst_.WriteCode(module, CMP_EAX, sizeof(CMP_EAX));
  }
  size_t cmp_offset = module->instrumented_code_allocated;

  // je label
  tinyinst_.WriteCode(module, JE, sizeof(JE));
  FixDisp4(module, sizeof(JMP));

  // jmp previous_list_head
  tinyinst_.WriteCode(module, JMP, sizeof(JMP));
  FixDisp4(module, (int32_t)((int64_t)previous_offset -
                             (int64_t)module->instrumented_code_allocated));

  // (maybe) pop RBX
  // pop RAX
  // pop flags
  if (global_indirect) {
    tinyinst_.WriteCode(module, POP_BAF, sizeof(POP_BAF));
  } else {
    tinyinst_.WriteCode(module, POP_AF, sizeof(POP_AF));
  }

  if (tinyinst_.sp_offset) {
    OffsetStack(module, tinyinst_.sp_offset);
  }

  // consider indirect call/jump an edge and insert appropriate instrumentation
  tinyinst_.InstrumentEdge(module, target_module, breakpoint_info.source_bb,
                           original_target);

  // jmp [actual_target]
  tinyinst_.WriteCode(module, JMP_MEM, sizeof(JMP_MEM));

  if (tinyinst_.child_ptr_size == 8) {
    FixDisp4(module, (int32_t)tinyinst_.child_ptr_size);
    *(int32_t *)(module->instrumented_code_local + cmp_offset - 4) =
    (int32_t)((int64_t)module->instrumented_code_allocated -
              (int64_t)cmp_offset);
  } else {
    FixDisp4(module,
             (int32_t)(tinyinst_.GetCurrentInstrumentedAddress(module) +
             tinyinst_.child_ptr_size));
    *(int32_t *)(module->instrumented_code_local + cmp_offset - 4) =
        (int32_t)tinyinst_.GetCurrentInstrumentedAddress(module);
  }
}

void X86Assembler::InstrumentRet(ModuleInfo *module,
                                 Instruction &inst,
                                 size_t instruction_address,
                                 TinyInst::IndirectInstrumentation mode,
                                 size_t bb_address) {
  // lots of moving around, but the problem is
  // we need to store context in the same place
  // where the return address is

  // at the end, the stack must be
  // saved RAX
  // saved EFLAGS
  // <sp_offset>
  // and RAX must contain return address

  // store rax to a safe offset
  int32_t ax_offset = -tinyinst_.sp_offset - 2 * tinyinst_.child_ptr_size;
  WriteStack(module, ax_offset);
  // copy return address to a safe offset
  int32_t ret_offset = ax_offset - tinyinst_.child_ptr_size;
  ReadStack(module, 0);
  WriteStack(module, ret_offset);
  // get ret immediate
  int32_t imm = (int32_t)xed_decoded_inst_get_unsigned_immediate(&inst.xedd);
  // align the stack
  int32_t ret_pop =
      (int32_t)tinyinst_.child_ptr_size + imm - tinyinst_.sp_offset;
  OffsetStack(module, ret_pop);  // pop
  ax_offset -= ret_pop;
  ret_offset -= ret_pop;
  // write data to stack
  tinyinst_.WriteCode(module, PUSH_F, sizeof(PUSH_F));
  ax_offset += tinyinst_.child_ptr_size;
  ret_offset += tinyinst_.child_ptr_size;
  ReadStack(module, ax_offset);
  tinyinst_.WriteCode(module, PUSH_A, sizeof(PUSH_A));
  ax_offset += tinyinst_.child_ptr_size;
  ret_offset += tinyinst_.child_ptr_size;
  ReadStack(module, ret_offset);
  tinyinst_.InstrumentIndirect(module,
                               inst,
                               instruction_address,
                               mode,
                               bb_address);
}

// converts an indirect jump/call into a MOV instruction
// which moves the target of the indirect call into the RAX/EAX register
// and writes this instruction into the code buffer
void X86Assembler::MovIndirectTarget(ModuleInfo *module,
                                     Instruction &inst,
                                     size_t original_address,
                                     int32_t stack_offset) {
  size_t mem_address = 0;
  bool rip_relative =
      IsRipRelative(module, inst, original_address, &mem_address);

  xed_error_enum_t xed_error;
  uint32_t olen;

  const xed_inst_t *xi = xed_decoded_inst_inst(&inst.xedd);
  const xed_operand_t *op = xed_inst_operand(xi, 0);
  xed_operand_enum_t operand_name = xed_operand_name(op);

  xed_state_t dstate;
  dstate.mmode = (xed_machine_mode_enum_t)tinyinst_.child_ptr_size == 8
                     ? XED_MACHINE_MODE_LONG_64
                     : XED_MACHINE_MODE_LEGACY_32;
  dstate.stack_addr_width = (xed_address_width_enum_t)tinyinst_.child_ptr_size;

  xed_reg_enum_t dest_reg;
  if (tinyinst_.child_ptr_size == 4) {
    dest_reg = XED_REG_EAX;
  } else {
    dest_reg = XED_REG_RAX;
  }

  xed_encoder_request_t mov;
  xed_encoder_request_zero_set_mode(&mov, &dstate);
  xed_encoder_request_set_iclass(&mov, XED_ICLASS_MOV);

  xed_encoder_request_set_effective_operand_width(
      &mov, (uint32_t)(tinyinst_.child_ptr_size * 8));
  xed_encoder_request_set_effective_address_size(
      &mov, (uint32_t)(tinyinst_.child_ptr_size * 8));

  xed_encoder_request_set_reg(&mov, XED_OPERAND_REG0, dest_reg);
  xed_encoder_request_set_operand_order(&mov, 0, XED_OPERAND_REG0);

  if (operand_name == XED_OPERAND_MEM0) {
    xed_encoder_request_set_mem0(&mov);
    xed_reg_enum_t base_reg = xed_decoded_inst_get_base_reg(&inst.xedd, 0);
    xed_encoder_request_set_base0(&mov, base_reg);
    xed_encoder_request_set_seg0(&mov, xed_decoded_inst_get_seg_reg(&inst.xedd, 0));
    xed_encoder_request_set_index(&mov,
                                  xed_decoded_inst_get_index_reg(&inst.xedd, 0));
    xed_encoder_request_set_scale(&mov, xed_decoded_inst_get_scale(&inst.xedd, 0));
    // in an unlikely case where base is rsp, disp needs fixing
    // this is because we pushed stuff on the stack
    if ((base_reg == XED_REG_SP) || (base_reg == XED_REG_ESP) ||
        (base_reg == XED_REG_RSP)) {
      // printf("base = sp\n");
      int64_t disp =
          xed_decoded_inst_get_memory_displacement(&inst.xedd, 0) + stack_offset;
      // always use disp width 4 in this case
      xed_encoder_request_set_memory_displacement(&mov, disp, 4);
    } else {
      xed_encoder_request_set_memory_displacement(
          &mov, xed_decoded_inst_get_memory_displacement(&inst.xedd, 0),
          xed_decoded_inst_get_memory_displacement_width(&inst.xedd, 0));
    }
    xed_encoder_request_set_memory_operand_length(
        &mov, xed_decoded_inst_get_memory_operand_length(&inst.xedd, 0));
    xed_encoder_request_set_operand_order(&mov, 1, XED_OPERAND_MEM0);
  } else if (operand_name == XED_OPERAND_REG0) {
    xed_encoder_request_set_reg(
        &mov,
        XED_OPERAND_REG1,
        xed_decoded_inst_get_reg(&inst.xedd, XED_OPERAND_REG0));
    xed_encoder_request_set_operand_order(&mov, 1, XED_OPERAND_REG1);
  } else {
    FATAL("Unexpected operand in indirect jump/call");
  }

  unsigned char encoded[15];
  xed_error = xed_encode(&mov, encoded, sizeof(encoded), &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  if (rip_relative) {
    // fix displacement
    size_t out_instruction_size = olen;
    int64_t fixed_disp =
        (int64_t)mem_address -
        (int64_t)((size_t)module->instrumented_code_remote +
                  module->instrumented_code_allocated +
                  out_instruction_size);
    xed_encoder_request_set_memory_displacement(&mov, fixed_disp, 4);
    xed_error = xed_encode(&mov, encoded, sizeof(encoded), &olen);
    if (xed_error != XED_ERROR_NONE) {
      FATAL("Error encoding instruction");
    }
    if (olen != out_instruction_size) {
      FATAL("Unexpected instruction size");
    }
  }

  tinyinst_.WriteCode(module, encoded, olen);
}

// translates indirect jump or call
// using global jumptable
void X86Assembler::InstrumentGlobalIndirect(ModuleInfo *module,
                                            Instruction &inst,
                                            size_t instruction_address) {
  if (xed_decoded_inst_get_category(&inst.xedd) != XED_CATEGORY_RET) {
    if (tinyinst_.sp_offset) {
      OffsetStack(module, -tinyinst_.sp_offset);
    }

    // push eflags
    // push RAX
    // push RBX
    tinyinst_.WriteCode(module, PUSH_FAB, sizeof(PUSH_FAB));

    int32_t stack_offset = tinyinst_.sp_offset + 3 * tinyinst_.child_ptr_size;

    if (xed_decoded_inst_get_category(&inst.xedd) == XED_CATEGORY_CALL) {
      stack_offset += tinyinst_.child_ptr_size;
    }

    MovIndirectTarget(module, inst, instruction_address, stack_offset);
  } else {
    // stack already set up, just push RBX
    tinyinst_.WriteCode(module, PUSH_B, sizeof(PUSH_B));
  }

  // mov rbx, rax
  // and rbx, (JUMPTABLE_SIZE - 1) * child_ptr_size
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, MOV_RBXRAX, sizeof(MOV_RBXRAX));
    tinyinst_.WriteCode(module, AND_RBX, sizeof(AND_RBX));
  } else {
    tinyinst_.WriteCode(module, MOV_EBXEAX, sizeof(MOV_EBXEAX));
    tinyinst_.WriteCode(module, AND_EBX, sizeof(AND_EBX));
  }
  FixDisp4(module, (int32_t)((JUMPTABLE_SIZE - 1) * tinyinst_.child_ptr_size));

  // add rbx, [jumptable_address]
  if (tinyinst_.child_ptr_size == 8) {
    tinyinst_.WriteCode(module, ADD_RBXRIPRELATIVE, sizeof(ADD_RBXRIPRELATIVE));
    FixDisp4(module, (int32_t)((int64_t)module->jumptable_address_offset -
                               (int64_t)module->instrumented_code_allocated));
  } else {
    tinyinst_.WriteCode(module, ADD_EBXRIPRELATIVE, sizeof(ADD_EBXRIPRELATIVE));
    FixDisp4(module, (int32_t)((size_t)module->instrumented_code_remote +
                               module->jumptable_address_offset));
  }

  // jmp RBX
  tinyinst_.WriteCode(module, JMP_B, sizeof(JMP_B));
}

// translates indirect jump or call
// using local jumptable
void X86Assembler::InstrumentLocalIndirect(ModuleInfo *module,
                                           Instruction &inst,
                                           size_t instruction_address,
                                           size_t bb_address) {
  if (xed_decoded_inst_get_category(&inst.xedd) != XED_CATEGORY_RET) {
    if (tinyinst_.sp_offset) {
      OffsetStack(module, -tinyinst_.sp_offset);
    }

    // push eflags
    // push RAX
    tinyinst_.WriteCode(module, PUSH_FA, sizeof(PUSH_FA));

    int32_t stack_offset = tinyinst_.sp_offset + 2 * tinyinst_.child_ptr_size;

    if (xed_decoded_inst_get_category(&inst.xedd) == XED_CATEGORY_CALL) {
      stack_offset += tinyinst_.child_ptr_size;
    }

    MovIndirectTarget(module, inst, instruction_address, stack_offset);
  } else {
    // stack already set up
  }

  // jmp [breakpoint]
  tinyinst_.WriteCode(module, JMP_MEM, sizeof(JMP_MEM));

  size_t breakpoint_address = tinyinst_.GetCurrentInstrumentedAddress(module);

  if (tinyinst_.child_ptr_size == 8) {
    FixDisp4(module, 1);
  } else {
    FixDisp4(module, (int32_t)(breakpoint_address + 1));
  }

  // int3
  Breakpoint(module);
  module->br_indirect_newtarget_list[breakpoint_address] = {
      module->instrumented_code_allocated, bb_address};

  // breakpoint_address
  if (tinyinst_.child_ptr_size == 8) {
    uint64_t address = (uint64_t)breakpoint_address;
    tinyinst_.WriteCode(module, &address, sizeof(address));
  } else {
    uint32_t address = (uint32_t)breakpoint_address;
    tinyinst_.WriteCode(module, &address, sizeof(address));
  }
}

// pushes return address on the target stack
void X86Assembler::PushReturnAddress(ModuleInfo *module,
                                     uint64_t return_address) {
  // printf("retun address: %llx\n", return_address);
  // write the original return address
  OffsetStack(module, -(int)tinyinst_.child_ptr_size);
  uint32_t return_lo = (uint32_t)(((uint64_t)return_address) & 0xFFFFFFFF);
  uint32_t return_hi = (uint32_t)(((uint64_t)return_address) >> 32);

  // mov dword ptr [sp], return_lo
  tinyinst_.WriteCode(module, WRITE_SP_IMM, sizeof(WRITE_SP_IMM));
  *(uint32_t *)(module->instrumented_code_local +
                module->instrumented_code_allocated - 4) = return_lo;

  if (tinyinst_.child_ptr_size == 8) {
    // mov dword ptr [sp+4], return_hi
    tinyinst_.WriteCode(module, WRITE_SP_4_IMM, sizeof(WRITE_SP_4_IMM));
    *(uint32_t *)(module->instrumented_code_local +
                  module->instrumented_code_allocated - 4) = return_hi;
  }
}

// outputs instruction into the translated code buffer
// fixes stuff like rip-relative addressing
void X86Assembler::FixInstructionAndOutput(
    ModuleInfo *module,
    Instruction &inst,
    const unsigned char *input,
    const unsigned char *input_address_remote,
    bool convert_call_to_jmp) {
  size_t mem_address = 0;
  bool rip_relative =
      IsRipRelative(module, inst, (size_t)input_address_remote, &mem_address);

  size_t original_instruction_size = xed_decoded_inst_get_length(&inst.xedd);

  bool needs_fixing = rip_relative || convert_call_to_jmp;

  // fast path
  // just copy instruction bytes without encoding
  if (!needs_fixing) {
    tinyinst_.WriteCode(module, (void *)input, original_instruction_size);
    return;
  }

  unsigned int olen;
  xed_encoder_request_init_from_decode(&inst.xedd);
  xed_error_enum_t xed_error;
  unsigned char tmp[15];

  if (convert_call_to_jmp) {
    xed_encoder_request_set_iclass(&inst.xedd, XED_ICLASS_JMP);
  }

  if (!rip_relative) {
    xed_error = xed_encode(&inst.xedd, tmp, sizeof(tmp), &olen);
    if (xed_error != XED_ERROR_NONE) {
      FATAL("Error encoding instruction");
    }
    tinyinst_.WriteCode(module, tmp, olen);
    return;
  }

  size_t instruction_end_addr;
  int64_t fixed_disp;

  instruction_end_addr = (size_t)module->instrumented_code_remote +
                         module->instrumented_code_allocated +
                         original_instruction_size;

  // encode an instruction once just to get the instruction size
  // as it needs not be the original size
  fixed_disp = (int64_t)(mem_address) - (int64_t)(instruction_end_addr);

  if (llabs(fixed_disp) > 0x7FFFFFFF) FATAL("Offset larger than 2G");

  xed_encoder_request_set_memory_displacement(&inst.xedd, fixed_disp, 4);
  xed_error = xed_encode(&inst.xedd, tmp, sizeof(tmp), &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  size_t out_instruction_size = olen;
  if ((module->instrumented_code_allocated + out_instruction_size) >
      module->instrumented_code_size) {
    FATAL("Insufficient memory allocated for instrumented code");
  }

  instruction_end_addr = (size_t)module->instrumented_code_remote +
                         module->instrumented_code_allocated +
                         out_instruction_size;

  fixed_disp = (int64_t)(mem_address) - (int64_t)(instruction_end_addr);

  if (llabs(fixed_disp) > 0x7FFFFFFF) FATAL("Offset larger than 2G");

  xed_encoder_request_set_memory_displacement(&inst.xedd, fixed_disp, 4);
  xed_error = xed_encode(&inst.xedd,
                         (unsigned char *)(module->instrumented_code_local +
                                           module->instrumented_code_allocated),
                         (uint32_t)(module->instrumented_code_size -
                                    module->instrumented_code_allocated),
                         &olen);

  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }
  if (olen != out_instruction_size) {
    FATAL("Unexpected instruction size");
  }

  module->instrumented_code_allocated += olen;
}

bool X86Assembler::DecodeInstruction(Instruction &inst,
                                     const unsigned char *buffer,
                                     unsigned int buffer_size) {
  xed_state_t dstate;
  dstate.mmode = (xed_machine_mode_enum_t)tinyinst_.child_ptr_size == 8
                     ? XED_MACHINE_MODE_LONG_64
                     : XED_MACHINE_MODE_LEGACY_32;
  dstate.stack_addr_width = (xed_address_width_enum_t)tinyinst_.child_ptr_size;

  xed_decoded_inst_zero_set_mode(&inst.xedd, &dstate);
  xed_error_enum_t xed_error = xed_decode(&inst.xedd, buffer, buffer_size);

  if (xed_error != XED_ERROR_NONE) return false;

  inst.address = (size_t)buffer;
  inst.length = xed_decoded_inst_get_length(&inst.xedd);
  inst.bbend = false;
  xed_category_enum_t category = xed_decoded_inst_get_category(&inst.xedd);
  xed_iclass_enum_t iclass = xed_decoded_inst_get_iclass(&inst.xedd);

  switch (category) {
    case XED_CATEGORY_CALL:
    case XED_CATEGORY_RET:
    case XED_CATEGORY_UNCOND_BR:
    case XED_CATEGORY_COND_BR:
      inst.bbend = true;
      break;
    default:
      break;
  }

  if (category == XED_CATEGORY_RET && iclass == XED_ICLASS_RET_NEAR) {
    inst.iclass = InstructionClass::RET;
  }
  else if(iclass == XED_ICLASS_JMP) {
    inst.iclass = InstructionClass::IJUMP;
  }
  else if(iclass == XED_ICLASS_CALL_NEAR) {
    inst.iclass = InstructionClass::ICALL;
  }
  else {
    inst.iclass = InstructionClass::OTHER;
  }
  return true;
}

// fixes an offset in the jump instruction (at offset jmp_offset in the
// instrumented code) to jump to the given basic block (at offset bb in the
// original code)
void X86Assembler::FixOffset(ModuleInfo *module,
                             uint32_t jmp_offset,
                             uint32_t target_offset) {
  int32_t jmp_relative_offset =
    (int32_t)target_offset - (int32_t)(jmp_offset + 4);
  *(int32_t *)(module->instrumented_code_local + jmp_offset) =
    jmp_relative_offset;
}

void X86Assembler::HandleBasicBlockEnd(
    const char *address,
    ModuleInfo *module,
    std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
    Instruction &inst,
    const char *code_ptr,
    size_t offset,
    size_t last_offset) {
  xed_error_enum_t xed_error;
  xed_category_enum_t category = xed_decoded_inst_get_category(&inst.xedd);
  if (category == XED_CATEGORY_RET) {
    TinyInst::IndirectInstrumentation ii_mode =
      tinyinst_.ShouldInstrumentIndirect(module,
                                         inst,
                                         (size_t)address + last_offset);

    if (ii_mode != TinyInst::IndirectInstrumentation::II_NONE) {
      InstrumentRet(module, inst, (size_t)address + last_offset, ii_mode,
                    (size_t)address);
    } else {
      FixInstructionAndOutput(
        module,
        inst,
        (unsigned char *)(code_ptr + last_offset),
        (unsigned char *)(address + last_offset));
    }

  } else if (category == XED_CATEGORY_COND_BR) {
    // j* target_address
    // gets instrumented as:
    //   j* label
    //   <edge instrumentation>
    //   jmp continue_address
    // label:
    //   <edge instrumentation>
    //   jmp target_address

    // must have an operand
    const xed_inst_t *xi = xed_decoded_inst_inst(&inst.xedd);
    const xed_operand_t *op = xed_inst_operand(xi, 0);
    xed_operand_enum_t operand_name = xed_operand_name(op);

    if (operand_name != XED_OPERAND_RELBR) {
      FATAL("Error getting branch target");
    }

    int32_t disp = xed_decoded_inst_get_branch_displacement(&inst.xedd);
    uint32_t disp_width =
        xed_decoded_inst_get_branch_displacement_width(&inst.xedd);
    if (disp_width == 0) {
      FATAL("Error getting branch target");
    }

    const char *target_address1 = address + offset;
    const char *target_address2 = address + offset + disp;

    if (tinyinst_.GetModule((size_t)target_address2) != module) {
      WARN("Relative jump to a differen module in bb at %p\n", address);
      tinyinst_.InvalidInstruction(module);
      return;
    }

    // preliminary encode jump instruction
    // displacement might be changed later as we don't know
    // the size of edge instrumentation yet
    // assuming 0 for now
    int32_t fixed_disp = sizeof(JMP);
    unsigned char encoded[15];
    unsigned int olen;
    unsigned int jump_size;
    xed_encoder_request_init_from_decode(&inst.xedd);
    xed_encoder_request_set_branch_displacement(&inst.xedd,
                                                fixed_disp,
                                                disp_width);
    xed_error = xed_encode(&inst.xedd, encoded, sizeof(encoded), &olen);
    if (xed_error != XED_ERROR_NONE) {
      FATAL("Error encoding instruction");
    }
    jump_size = olen;
    size_t jump_start_offset = module->instrumented_code_allocated;
    tinyinst_.WriteCode(module, encoded, jump_size);
    size_t jump_end_offset = module->instrumented_code_allocated;

    // instrument the 1st edge
    tinyinst_.InstrumentEdge(module, module, (size_t)address,
                             (size_t)target_address1);

    // jmp target_address1
    tinyinst_.WriteCode(module, JMP, sizeof(JMP));

    tinyinst_.FixOffsetOrEnqueue(
        module,
        (uint32_t)((size_t)target_address1 - (size_t)(module->min_address)),
        (uint32_t)(module->instrumented_code_allocated - 4), queue,
        offset_fixes);

    // time to fix that conditional jump offset
    if ((module->instrumented_code_allocated - jump_end_offset) != fixed_disp) {
      fixed_disp =
          (int32_t)(module->instrumented_code_allocated - jump_end_offset);
      xed_encoder_request_set_branch_displacement(&inst.xedd,
                                                  fixed_disp,
                                                  disp_width);
      xed_error = xed_encode(&inst.xedd, encoded, sizeof(encoded), &olen);
      if (xed_error != XED_ERROR_NONE) {
        FATAL("Error encoding instruction");
      }
      if (jump_size != olen) {
        FATAL("Instruction size changed?");
      }
      tinyinst_.WriteCodeAtOffset(module, jump_start_offset, encoded,
                                  jump_size);
    }

    // instrument the 2nd edge
    tinyinst_.InstrumentEdge(module, module, (size_t)address,
                             (size_t)target_address2);

    // jmp target_address2
    tinyinst_.WriteCode(module, JMP, sizeof(JMP));

    tinyinst_.FixOffsetOrEnqueue(
        module,
        (uint32_t)((size_t)target_address2 - (size_t)(module->min_address)),
        (uint32_t)(module->instrumented_code_allocated - 4),
        queue,
        offset_fixes);

  } else if (category == XED_CATEGORY_UNCOND_BR) {
    // must have an operand
    const xed_inst_t *xi = xed_decoded_inst_inst(&inst.xedd);
    const xed_operand_t *op = xed_inst_operand(xi, 0);

    xed_operand_enum_t operand_name = xed_operand_name(op);

    if (operand_name == XED_OPERAND_RELBR) {
      // jmp address
      // gets instrumented as:
      // jmp fixed_address

      int32_t disp = xed_decoded_inst_get_branch_displacement(&inst.xedd);
      uint32_t disp_width =
          xed_decoded_inst_get_branch_displacement_width(&inst.xedd);
      if (disp_width == 0) {
        FATAL("Error getting branch target");
      }

      const char *target_address = address + offset + disp;

      if (tinyinst_.GetModule((size_t)target_address) != module) {
        WARN("Relative jump to a differen module in bb at %p\n", address);
        tinyinst_.InvalidInstruction(module);
        return;
      }

      // jmp target_address
      tinyinst_.WriteCode(module, JMP, sizeof(JMP));

      tinyinst_.FixOffsetOrEnqueue(
          module,
          (uint32_t)((size_t)target_address - (size_t)(module->min_address)),
          (uint32_t)(module->instrumented_code_allocated - 4), queue,
          offset_fixes);

    } else {
      TinyInst::IndirectInstrumentation ii_mode =
        tinyinst_.ShouldInstrumentIndirect(module,
                                           inst,
                                           (size_t)address + last_offset);

      if (ii_mode != TinyInst::IndirectInstrumentation::II_NONE) {
        tinyinst_.InstrumentIndirect(module, inst,
                                     (size_t)address + last_offset, ii_mode,
                                     (size_t)address);
      } else {
        FixInstructionAndOutput(
          module,
          inst,
          (unsigned char *)(code_ptr + last_offset),
          (unsigned char *)(address + last_offset));
      }
    }

  } else if (category == XED_CATEGORY_CALL) {
    // must have an operand
    const xed_inst_t *xi = xed_decoded_inst_inst(&inst.xedd);
    const xed_operand_t *op = xed_inst_operand(xi, 0);

    xed_operand_enum_t operand_name = xed_operand_name(op);

    if (operand_name == XED_OPERAND_RELBR) {
      // call target_address
      // gets instrumented as:
      //   call label
      //   jmp return_address
      // label:
      //   jmp target_address

      int32_t disp = xed_decoded_inst_get_branch_displacement(&inst.xedd);
      uint32_t disp_width =
          xed_decoded_inst_get_branch_displacement_width(&inst.xedd);
      if (disp_width == 0) {
        FATAL("Error getting branch target");
      }

      const char *return_address = address + offset;
      const char *call_address = address + offset + disp;

      if (tinyinst_.GetModule((size_t)call_address) != module) {
        WARN("Relative jump to a differen module in bb at %p\n", address);
        tinyinst_.InvalidInstruction(module);
        return;
      }

      // fix the displacement and emit the call
      if (!tinyinst_.patch_return_addresses) {
        unsigned char encoded[15];
        unsigned int olen;
        xed_encoder_request_init_from_decode(&inst.xedd);
        xed_encoder_request_set_branch_displacement(&inst.xedd,
                                                    sizeof(JMP),
                                                    disp_width);
        xed_error = xed_encode(&inst.xedd, encoded, sizeof(encoded), &olen);
        if (xed_error != XED_ERROR_NONE) {
          FATAL("Error encoding instruction");
        }
        tinyinst_.WriteCode(module, encoded, olen);

        size_t translated_return_address = tinyinst_.GetCurrentInstrumentedAddress(module);
        tinyinst_.OnReturnAddress(module, (size_t)return_address, translated_return_address);

        // jmp return_address
        tinyinst_.WriteCode(module, JMP, sizeof(JMP));

        tinyinst_.FixOffsetOrEnqueue(
            module,
            (uint32_t)((size_t)return_address - (size_t)(module->min_address)),
            (uint32_t)(module->instrumented_code_allocated - 4), queue,
            offset_fixes);

        // jmp call_address
        tinyinst_.WriteCode(module, JMP, sizeof(JMP));

        tinyinst_.FixOffsetOrEnqueue(
            module,
            (uint32_t)((size_t)call_address - (size_t)(module->min_address)),
            (uint32_t)(module->instrumented_code_allocated - 4), queue,
            offset_fixes);

      } else {
        PushReturnAddress(module, (uint64_t)return_address);

        // jmp call_address
        tinyinst_.WriteCode(module, JMP, sizeof(JMP));

        tinyinst_.FixOffsetOrEnqueue(
            module,
            (uint32_t)((size_t)call_address - (size_t)(module->min_address)),
            (uint32_t)(module->instrumented_code_allocated - 4), queue,
            offset_fixes);

        // done, we don't need to do anything else as return gets redirected
        // later
      }

    } else /* CALL, operand_name != XED_OPERAND_RELBR */ {
      const char *return_address = address + offset;

      TinyInst::IndirectInstrumentation ii_mode =
        tinyinst_.ShouldInstrumentIndirect(module,
                                           inst,
                                           (size_t)address + last_offset);

      if (ii_mode != TinyInst::IndirectInstrumentation::II_NONE) {
        if (tinyinst_.patch_return_addresses) {
          PushReturnAddress(module, (uint64_t)return_address);

          tinyinst_.InstrumentIndirect(module, inst,
                                       (size_t)address + last_offset,
                                       ii_mode,
                                       (size_t)address);

        } else {
          //   call label
          //   jmp return_address
          //  label:
          //    <indirect instrumentation>

          tinyinst_.WriteCode(module, CALL, sizeof(CALL));
          FixDisp4(module, sizeof(JMP));

          size_t translated_return_address = tinyinst_.GetCurrentInstrumentedAddress(module);
          tinyinst_.OnReturnAddress(module, (size_t)return_address, translated_return_address);

          tinyinst_.WriteCode(module, JMP, sizeof(JMP));

          tinyinst_.FixOffsetOrEnqueue(
              module,
              (uint32_t)((size_t)return_address -
                         (size_t)(module->min_address)),
              (uint32_t)(module->instrumented_code_allocated - 4), queue,
              offset_fixes);

          tinyinst_.InstrumentIndirect(module, inst,
                                       (size_t)address + last_offset, ii_mode,
                                       (size_t)address);
        }

      } else {
        if (tinyinst_.patch_return_addresses) {
          PushReturnAddress(module, (uint64_t)return_address);
          // xed_decoded_inst_t jmp;
          // CallToJmp(&xedd, &jmp);
          FixInstructionAndOutput(
            module,
            inst,
            (unsigned char *)(code_ptr + last_offset),
            (unsigned char *)(address + last_offset), true);
        } else {
          FixInstructionAndOutput(
            module,
            inst,
            (unsigned char *)(code_ptr + last_offset),
            (unsigned char *)(address + last_offset));

          size_t translated_return_address = tinyinst_.GetCurrentInstrumentedAddress(module);
          tinyinst_.OnReturnAddress(module, (size_t)return_address, translated_return_address);

          tinyinst_.WriteCode(module, JMP, sizeof(JMP));

          tinyinst_.FixOffsetOrEnqueue(
              module,
              (uint32_t)((size_t)return_address -
                         (size_t)(module->min_address)),
              (uint32_t)(module->instrumented_code_allocated - 4), queue,
              offset_fixes);
        }
      }
    }
  }
}

void X86Assembler::Init() {
  xed_tables_init();
}

```

`arch/x86/x86_assembler.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ARCH_X86_X86_ASSEMBLER_H
#define ARCH_X86_X86_ASSEMBLER_H

extern "C" {
#include "xed/xed-interface.h"
}

#include "assembler.h"
#include "tinyinst.h"

class X86Assembler : public Assembler {
 public:
  using Assembler::Assembler;
  virtual ~X86Assembler() {}
  void Init() override;

  bool DecodeInstruction(Instruction &inst,
                         const unsigned char *buffer,
                         unsigned int buffer_size) override;
  void FixInstructionAndOutput(ModuleInfo *module,
                               Instruction &inst,
                               const unsigned char *input,
                               const unsigned char *input_address_remote,
                               bool convert_call_to_jmp = false) override;
  void HandleBasicBlockEnd(
      const char *address,
      ModuleInfo *module, std::set<char *> *queue,
      std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
      Instruction &inst,
      const char *code_ptr,
      size_t offset,
      size_t last_offset) override;

  void JmpAddress(ModuleInfo *module, size_t address) override;
  void Nop(ModuleInfo *module) override;
  void Breakpoint(ModuleInfo *module) override;
  void Crash(ModuleInfo *module) override;

  void OffsetStack(ModuleInfo *module, int32_t offset) override;
  bool IsRipRelative(ModuleInfo *module,
                     Instruction &inst,
                     size_t instruction_address,
                     size_t *mem_address) override;
  void TranslateJmp(ModuleInfo *module,
                         ModuleInfo *target_module,
                         size_t original_target,
                         IndirectBreakpoinInfo& breakpoint_info,
                         bool global_indirect,
                         size_t previous_offset) override;
  void InstrumentLocalIndirect(ModuleInfo *module,
                               Instruction &inst,
                               size_t instruction_address,
                               size_t bb_address) override;
  void InstrumentGlobalIndirect(ModuleInfo *module,
                                Instruction &inst,
                                size_t instruction_address) override;
  void FixOffset(ModuleInfo *module,
                 uint32_t jmp_offset,
                 uint32_t target_offset) override;
 private:
  inline void FixDisp4(ModuleInfo *module, int32_t disp);
  void ReadStack(ModuleInfo *module, int32_t offset);
  void WriteStack(ModuleInfo *module, int32_t offset);
  void MovIndirectTarget(ModuleInfo *module,
                         Instruction &inst,
                         size_t original_address,
                         int32_t stack_offset);

  void InstrumentRet(ModuleInfo *module,
                     Instruction &inst,
                     size_t instruction_address,
                     TinyInst::IndirectInstrumentation mode,
                     size_t bb_address);
  void PushReturnAddress(ModuleInfo *module, uint64_t return_address);

  int xed_mmode_;
};

#endif  // ARCH_X86_X86_ASSEMBLER_H

```

`arch/x86/x86_helpers.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "common.h"
#include "x86_helpers.h"

xed_reg_enum_t GetUnusedRegister(xed_reg_enum_t used_register, int operand_width) {
  switch (operand_width) {
  case 16:
    if (used_register == XED_REG_AX) return XED_REG_CX;
    return XED_REG_AX;
  case 32:
    if (used_register == XED_REG_EAX) return XED_REG_ECX;
    return XED_REG_EAX;
  case 64:
    if (used_register == XED_REG_RAX) return XED_REG_RCX;
    return XED_REG_RAX;
  default:
    FATAL("Unexpected operand width");
  }
}

xed_reg_enum_t GetFullSizeRegister(xed_reg_enum_t r, int child_ptr_size) {
  if (child_ptr_size == 8) {
    return xed_get_largest_enclosing_register(r);
  } else {
    return xed_get_largest_enclosing_register32(r);
  }
}

xed_reg_enum_t Get8BitRegister(xed_reg_enum_t r) {
  switch (r) {
  case XED_REG_AX:
  case XED_REG_EAX:
  case XED_REG_RAX:
    return XED_REG_AL;

  case XED_REG_CX:
  case XED_REG_ECX:
  case XED_REG_RCX:
    return XED_REG_CL;

  case XED_REG_DX:
  case XED_REG_EDX:
  case XED_REG_RDX:
    return XED_REG_DL;

  case XED_REG_BX:
  case XED_REG_EBX:
  case XED_REG_RBX:
    return XED_REG_BL;

  case XED_REG_SP:
  case XED_REG_ESP:
  case XED_REG_RSP:
    return XED_REG_SPL;

  case XED_REG_BP:
  case XED_REG_EBP:
  case XED_REG_RBP:
    return XED_REG_BPL;

  case XED_REG_SI:
  case XED_REG_ESI:
  case XED_REG_RSI:
    return XED_REG_SIL;

  case XED_REG_DI:
  case XED_REG_EDI:
  case XED_REG_RDI:
    return XED_REG_DIL;

  case XED_REG_R8W:
  case XED_REG_R8D:
  case XED_REG_R8:
    return XED_REG_R8B;

  case XED_REG_R9W:
  case XED_REG_R9D:
  case XED_REG_R9:
    return XED_REG_R9B;

  case XED_REG_R10W:
  case XED_REG_R10D:
  case XED_REG_R10:
    return XED_REG_R10B;

  case XED_REG_R11W:
  case XED_REG_R11D:
  case XED_REG_R11:
    return XED_REG_R11B;

  case XED_REG_R12W:
  case XED_REG_R12D:
  case XED_REG_R12:
    return XED_REG_R12B;

  case XED_REG_R13W:
  case XED_REG_R13D:
  case XED_REG_R13:
    return XED_REG_R13B;

  case XED_REG_R14W:
  case XED_REG_R14D:
  case XED_REG_R14:
    return XED_REG_R14B;

  case XED_REG_R15W:
  case XED_REG_R15D:
  case XED_REG_R15:
    return XED_REG_R15B;

  default:
    FATAL("Unknown register");
  }
}


uint32_t Push(xed_state_t *dstate, xed_reg_enum_t r, unsigned char *encoded, size_t encoded_size) {
  uint32_t olen;
  xed_error_enum_t xed_error;

  // push destination register
  xed_encoder_request_t push;
  xed_encoder_request_zero_set_mode(&push, dstate);
  xed_encoder_request_set_iclass(&push, XED_ICLASS_PUSH);
  
  xed_encoder_request_set_effective_operand_width(&push, dstate->stack_addr_width * 8);
  xed_encoder_request_set_effective_address_size(&push, dstate->stack_addr_width * 8);

  xed_encoder_request_set_reg(&push, XED_OPERAND_REG0, GetFullSizeRegister(r, dstate->stack_addr_width));
  xed_encoder_request_set_operand_order(&push, 0, XED_OPERAND_REG0);

  xed_error = xed_encode(&push, encoded, (unsigned int)encoded_size, &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  return olen;
}

uint32_t Pop(xed_state_t *dstate, xed_reg_enum_t r, unsigned char *encoded, size_t encoded_size) {
  uint32_t olen;
  xed_error_enum_t xed_error;

  // push destination register
  xed_encoder_request_t pop;
  xed_encoder_request_zero_set_mode(&pop, dstate);
  xed_encoder_request_set_iclass(&pop, XED_ICLASS_POP);

  xed_encoder_request_set_effective_operand_width(&pop, dstate->stack_addr_width * 8);
  xed_encoder_request_set_effective_address_size(&pop, dstate->stack_addr_width * 8);

  xed_encoder_request_set_reg(&pop, XED_OPERAND_REG0, GetFullSizeRegister(r, dstate->stack_addr_width));
  xed_encoder_request_set_operand_order(&pop, 0, XED_OPERAND_REG0);

  xed_error = xed_encode(&pop, encoded, (unsigned int)encoded_size, &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  return olen;
}


void CopyOperandFromInstruction(xed_decoded_inst_t *src,
                                xed_encoder_request_t *dest,
                                xed_operand_enum_t src_operand_name,
                                xed_operand_enum_t dest_operand_name,
                                int dest_operand_index,
                                size_t stack_offset)
{
  if ((src_operand_name >= XED_OPERAND_REG0) && (src_operand_name <= XED_OPERAND_REG8) &&
      (dest_operand_name >= XED_OPERAND_REG0) && (dest_operand_name <= XED_OPERAND_REG8))
  {
    xed_reg_enum_t r = xed_decoded_inst_get_reg(src, src_operand_name);
    xed_encoder_request_set_reg(dest, dest_operand_name, r);
  } else if (src_operand_name == XED_OPERAND_MEM0 && dest_operand_name == XED_OPERAND_MEM0) {
    xed_encoder_request_set_mem0(dest);
    xed_reg_enum_t base_reg = xed_decoded_inst_get_base_reg(src, 0);
    xed_encoder_request_set_base0(dest, base_reg);
    xed_encoder_request_set_seg0(dest, xed_decoded_inst_get_seg_reg(src, 0));
    xed_encoder_request_set_index(dest, xed_decoded_inst_get_index_reg(src, 0));
    xed_encoder_request_set_scale(dest, xed_decoded_inst_get_scale(src, 0));
    // in case where base is rsp, disp needs fixing
    if ((base_reg == XED_REG_SP) || (base_reg == XED_REG_ESP) || (base_reg == XED_REG_RSP)) {
      int64_t disp = xed_decoded_inst_get_memory_displacement(src, 0) + stack_offset;
      // always use disp width 4 in this case
      xed_encoder_request_set_memory_displacement(dest, disp, 4);
    } else {
      xed_encoder_request_set_memory_displacement(dest,
        xed_decoded_inst_get_memory_displacement(src, 0),
        xed_decoded_inst_get_memory_displacement_width(src, 0));
    }
    // int length = xed_decoded_inst_get_memory_operand_length(xedd, 0);
    xed_encoder_request_set_memory_operand_length(dest,
      xed_decoded_inst_get_memory_operand_length(src, 0));
  } else if (src_operand_name == XED_OPERAND_IMM0 && dest_operand_name == XED_OPERAND_IMM0) {
    uint64_t imm = xed_decoded_inst_get_unsigned_immediate(src);
    uint32_t width = xed_decoded_inst_get_immediate_width(src);
    xed_encoder_request_set_uimm0(dest, imm, width);
  } else if (src_operand_name == XED_OPERAND_IMM0SIGNED && dest_operand_name == XED_OPERAND_IMM0SIGNED) {
    int32_t imm = xed_decoded_inst_get_signed_immediate(src);
    uint32_t width = xed_decoded_inst_get_immediate_width(src);
    xed_encoder_request_set_simm(dest, imm, width);
  } else {
    FATAL("Unsupported param");
  }
  xed_encoder_request_set_operand_order(dest, dest_operand_index, dest_operand_name);
}


uint32_t Mov(xed_state_t *dstate, uint32_t operand_width, xed_reg_enum_t base_reg, int32_t displacement, xed_reg_enum_t r2, unsigned char *encoded, size_t encoded_size) {
  uint32_t olen;
  xed_error_enum_t xed_error;

  xed_encoder_request_t mov;
  xed_encoder_request_zero_set_mode(&mov, dstate);
  xed_encoder_request_set_iclass(&mov, XED_ICLASS_MOV);

  xed_encoder_request_set_effective_operand_width(&mov, operand_width);
  xed_encoder_request_set_effective_address_size(&mov, dstate->stack_addr_width * 8);

  xed_encoder_request_set_mem0(&mov);
  xed_encoder_request_set_base0(&mov, base_reg);
  xed_encoder_request_set_memory_displacement(&mov, displacement, 4);
  // int length = xed_decoded_inst_get_memory_operand_length(xedd, 0);
  xed_encoder_request_set_memory_operand_length(&mov, operand_width / 8);
  xed_encoder_request_set_operand_order(&mov, 0, XED_OPERAND_MEM0);

  xed_encoder_request_set_reg(&mov, XED_OPERAND_REG0, r2);
  xed_encoder_request_set_operand_order(&mov, 1, XED_OPERAND_REG0);

  xed_error = xed_encode(&mov, encoded, (unsigned int)encoded_size, &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  return olen;
}

uint32_t Lzcnt(xed_state_t *dstate, uint32_t operand_width, xed_reg_enum_t dest_reg, xed_reg_enum_t src_reg, unsigned char *encoded, size_t encoded_size) {
  uint32_t olen;
  xed_error_enum_t xed_error;

  xed_encoder_request_t lzcnt;
  xed_encoder_request_zero_set_mode(&lzcnt, dstate);
  xed_encoder_request_set_iclass(&lzcnt, XED_ICLASS_LZCNT);

  xed_encoder_request_set_effective_operand_width(&lzcnt, operand_width);
  //xed_encoder_request_set_effective_address_size(&lzcnt, operand_width);

  xed_encoder_request_set_reg(&lzcnt, XED_OPERAND_REG0, dest_reg);
  xed_encoder_request_set_operand_order(&lzcnt, 0, XED_OPERAND_REG0);

  xed_encoder_request_set_reg(&lzcnt, XED_OPERAND_REG1, src_reg);
  xed_encoder_request_set_operand_order(&lzcnt, 1, XED_OPERAND_REG1);

  xed_error = xed_encode(&lzcnt, encoded, (unsigned int)encoded_size, &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  return olen;
}

uint32_t CmpImm8(xed_state_t *dstate, uint32_t operand_width, xed_reg_enum_t dest_reg, uint64_t imm, unsigned char *encoded, size_t encoded_size) {
  uint32_t olen;
  xed_error_enum_t xed_error;

  xed_encoder_request_t cmp;
  xed_encoder_request_zero_set_mode(&cmp, dstate);
  xed_encoder_request_set_iclass(&cmp, XED_ICLASS_CMP);

  xed_encoder_request_set_effective_operand_width(&cmp, operand_width);
  // xed_encoder_request_set_effective_address_size(&lzcnt, operand_width);

  xed_encoder_request_set_reg(&cmp, XED_OPERAND_REG0, dest_reg);
  xed_encoder_request_set_operand_order(&cmp, 0, XED_OPERAND_REG0);

  xed_encoder_request_set_uimm0_bits(&cmp, imm, 8);
  xed_encoder_request_set_operand_order(&cmp, 1, XED_OPERAND_IMM0);

  xed_error = xed_encode(&cmp, encoded, (unsigned int)encoded_size, &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  return olen;
}

uint32_t GetInstructionLength(xed_encoder_request_t *inst) {
  unsigned int olen;
  unsigned char tmp[15];
  xed_error_enum_t xed_error;
  
  xed_error = xed_encode(inst, tmp, sizeof(tmp), &olen);
  if (xed_error != XED_ERROR_NONE) {
    FATAL("Error encoding instruction");
  }

  return olen;

}

void FixRipDisplacement(xed_encoder_request_t *inst, size_t mem_address, size_t fixed_instruction_address) {
  // fake displacement, just to get length
  xed_encoder_request_set_memory_displacement(inst, 0x7777777, 4);
  uint32_t inst_length = GetInstructionLength(inst);
  
  size_t instruction_end_addr = fixed_instruction_address + inst_length;
  int64_t fixed_disp = (int64_t)(mem_address) - (int64_t)(instruction_end_addr);
  if (llabs(fixed_disp) > 0x7FFFFFFF) FATAL("Offset larger than 2G");
  
  xed_encoder_request_set_memory_displacement(inst, fixed_disp, 4);
}

// checks if the instruction uses RSP-relative addressing,
// e.g. mov rax, [rsp+displacement];
// and, if so, returns the displacement
bool IsRspRelative(xed_decoded_inst_t *xedd, size_t* displacement) {
  bool rsp_relative = false;
  int64_t disp;

  uint32_t memops = xed_decoded_inst_number_of_memory_operands(xedd);

  for (uint32_t i = 0; i < memops; i++) {
    xed_reg_enum_t base = xed_decoded_inst_get_base_reg(xedd, i);
    switch (base) {
    case XED_REG_RSP:
    case XED_REG_ESP:
    case XED_REG_SP:
      rsp_relative = true;
      disp = xed_decoded_inst_get_memory_displacement(xedd, i);
      break;
    default:
      break;
    }
  }

  if (!rsp_relative) return false;

  *displacement = (size_t)(disp);

  return rsp_relative;
}

```

`arch/x86/x86_helpers.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ARCH_X86_X86_HELPERS_H
#define ARCH_X86_X86_HELPERS_H

extern "C" {
#include "xed/xed-interface.h"
}

xed_reg_enum_t GetFullSizeRegister(xed_reg_enum_t r, int child_ptr_size);
xed_reg_enum_t GetUnusedRegister(xed_reg_enum_t used_register, int operand_width);
xed_reg_enum_t Get8BitRegister(xed_reg_enum_t r);

uint32_t Push(xed_state_t *dstate, xed_reg_enum_t r, unsigned char *encoded, size_t encoded_size);
uint32_t Pop(xed_state_t *dstate, xed_reg_enum_t r, unsigned char *encoded, size_t encoded_size);

uint32_t Mov(xed_state_t *dstate, uint32_t operand_width,
             xed_reg_enum_t base_reg, int32_t displacement,
             xed_reg_enum_t r2, unsigned char *encoded,
             size_t encoded_size);

uint32_t Lzcnt(xed_state_t *dstate, uint32_t operand_width,
               xed_reg_enum_t dest_reg, xed_reg_enum_t src_reg,
               unsigned char *encoded, size_t encoded_size);

uint32_t CmpImm8(xed_state_t *dstate, uint32_t operand_width,
                 xed_reg_enum_t dest_reg, uint64_t imm,
                 unsigned char *encoded, size_t encoded_size);

void CopyOperandFromInstruction(xed_decoded_inst_t *src,
                                xed_encoder_request_t *dest,
                                xed_operand_enum_t src_operand_name,
                                xed_operand_enum_t dest_operand_name,
                                int dest_operand_index,
                                size_t stack_offset);

uint32_t GetInstructionLength(xed_encoder_request_t *inst);

void FixRipDisplacement(xed_encoder_request_t *inst,
                        size_t mem_address,
                        size_t fixed_instruction_address);

bool IsRspRelative(xed_decoded_inst_t* xedd, size_t* displacement);

#endif  // ARCH_X86_X86_HELPERS_H

```

`arch/x86/x86_litecov.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "litecov.h"

#include "common.h"
#include "instruction.h"

#include "arch/x86/x86_assembler.h"
#include "arch/x86/x86_helpers.h"

// mov byte ptr [rip+offset], 1
// note: does not clobber flags
static unsigned char MOV_ADDR_1[] = {0xC6, 0x05, 0xAA, 0xAA, 0xAA, 0x0A, 0x01};

// same size as instrumentation
// used for clearing the instrumentation
// if the user wants to ignore specific pieces of coverage
// 7-byte nop taken from
// https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/x86/include/asm/nops.h
// thanks @tehjh
static unsigned char NOP7[] = {0x0f, 0x1f, 0x80, 0x00, 0x00, 0x00, 0x00};
static unsigned char NOP5[] = {0x0f, 0x1f, 0x44, 0x00, 0x00};

void LiteCov::NopCovInstructions(ModuleInfo *module, size_t code_offset) {
  WriteCodeAtOffset(module, code_offset, NOP7, sizeof(NOP7));
  // need to commit since this isn't a part of normal instrumentation process
  CommitCode(module, code_offset, sizeof(NOP7));
}

void LiteCov::NopCmpCovInstructions(ModuleInfo *module,
                                    CmpCoverageRecord &cmp_record,
                                    int matched_width) {
  unsigned char JMP[] = {0xe9, 0x00, 0x00, 0x00, 0x00};

  if (matched_width >= cmp_record.width - 8) {
    // ignore everything
    WriteCodeAtOffset(module, cmp_record.instrumentation_offset, JMP,
                               sizeof(JMP));
    *(int32_t *)(module->instrumented_code_local +
                 cmp_record.instrumentation_offset + sizeof(JMP) - 4) =
        (int32_t)(cmp_record.instrumentation_size - sizeof(JMP));
    CommitCode(module, cmp_record.instrumentation_offset, sizeof(JMP));
    cmp_record.ignored = true;
    return;
  }

  if (matched_width >= cmp_record.match_width) {
    cmp_record.match_width = matched_width + 8;
    char new_offset_data = static_cast<char>(cmp_record.match_width);
    WriteCodeAtOffset(module, cmp_record.match_width_offset,
                               &new_offset_data, 1);
    CommitCode(module, cmp_record.instrumentation_offset, 1);
  }
}

void LiteCov::EmitCoverageInstrumentation(ModuleInfo *module,
                                          size_t bit_address,
                                          size_t mov_address) {
  //////////////////////////////////////////////////
  // mov [coverage_buffer + coverage_buffer_next], 1
  //////////////////////////////////////////////////
  WriteCode(module, MOV_ADDR_1, sizeof(MOV_ADDR_1));
  mov_address += sizeof(MOV_ADDR_1);

  // fix the mov address/displacement
  if (child_ptr_size == 8) {
    *(int32_t *)(module->instrumented_code_local +
                 module->instrumented_code_allocated - 5) =
        (int32_t)(bit_address - mov_address);
  } else {
    *(uint32_t *)(module->instrumented_code_local +
                  module->instrumented_code_allocated - 5) =
        (uint32_t)bit_address;
  }
}

bool LiteCov::ShouldInstrumentSub(ModuleInfo *module, Instruction &cmp_instr,
                                     size_t instruction_address) {
  // look after the sub instruction
  // and check if the flags set in it
  // are used for a conditional jump or move
  xed_decoded_inst_t *cmp_xedd = &cmp_instr.xedd;

  instruction_address += xed_decoded_inst_get_length(cmp_xedd);

  AddressRange *range = GetRegion(module, instruction_address);
  if (!range) {
    return false;
  }

  uint32_t range_offset = (uint32_t)(instruction_address - (size_t)range->from);
  size_t code_size = (uint32_t)((size_t)range->to - instruction_address);
  char *code_ptr = range->data + range_offset;

  size_t offset = 0, last_offset = 0;

  xed_decoded_inst_t xedd;
  xed_error_enum_t xed_error;

  xed_state_t dstate;
  dstate.mmode = (xed_machine_mode_enum_t)child_ptr_size == 8
                     ? XED_MACHINE_MODE_LONG_64
                     : XED_MACHINE_MODE_LEGACY_32;
  dstate.stack_addr_width = (xed_address_width_enum_t)child_ptr_size;

  xed_category_enum_t category;

  while (true) {
    xed_decoded_inst_zero_set_mode(&xedd, &dstate);
    xed_error = xed_decode(&xedd, (const unsigned char *)(code_ptr + offset),
                           (unsigned int)(code_size - offset));

    if (xed_error != XED_ERROR_NONE) return false;

    size_t instruction_length = xed_decoded_inst_get_length(&xedd);

    category = xed_decoded_inst_get_category(&xedd);

    switch (category) {
      case XED_CATEGORY_CMOV:
      case XED_CATEGORY_COND_BR:
        return true;

      case XED_CATEGORY_CALL:
      case XED_CATEGORY_RET:
      case XED_CATEGORY_UNCOND_BR:
        return false;

      default:
        if (xed_decoded_inst_uses_rflags(&xedd)) return false;
        break;
    }

    last_offset = offset;
    offset += instruction_length;
  }
}

InstructionResult LiteCov::InstrumentInstruction(ModuleInfo *module,
                                                 Instruction &inst,
                                                 size_t bb_address,
                                                 size_t instruction_address) {
  if (!compare_coverage) {
    return INST_NOTHANDLED;
  }

  // jmp offset
  unsigned char JB[] = {0x0F, 0x82, 0x00, 0x00, 0x00, 0x00};

  xed_iclass_enum_t iclass;
  iclass = xed_decoded_inst_get_iclass(&inst.xedd);

  if ((iclass != XED_ICLASS_CMP) && (iclass != XED_ICLASS_SUB)) {
    return INST_NOTHANDLED;
  }

  int operand_width = xed_decoded_inst_get_operand_width(&inst.xedd);

  // printf("Cmp instruction at %llx, width: %d\n", instruction_address,
  // operand_width);

  if (operand_width <= 8) {
    return INST_NOTHANDLED;
  }

  // copy so we could modify it
  xed_decoded_inst_t cmp_xedd = inst.xedd;
  xed_decoded_inst_t *xedd = &cmp_xedd;

  xed_state_t dstate;
  dstate.mmode = (xed_machine_mode_enum_t)child_ptr_size == 8
                     ? XED_MACHINE_MODE_LONG_64
                     : XED_MACHINE_MODE_LEGACY_32;
  dstate.stack_addr_width = (xed_address_width_enum_t)child_ptr_size;

  xed_error_enum_t xed_error;
  uint32_t olen;
  unsigned char encoded[15];

  // if the 1st operand is NOT a memory operand
  // then we can replace the cmp with xor
  // and restore the operand
  // e.g. cmp eax, foo
  // to:
  // push eax
  // xor eax, foo
  // LZCNT rax, rax
  // cmp rax, #numbits
  // JA end
  // write to coverage buffer
  // end:
  // pop eax
  // original instruction
  // if it is a memory operand, then we need to
  // allocate a register and do
  // push register
  // mov register, memory
  // same as above from xor

  const xed_inst_t *xi = xed_decoded_inst_inst(xedd);

  const xed_operand_t *op1 = xed_inst_operand(xi, 0);
  xed_operand_enum_t operand1_name = xed_operand_name(op1);
  xed_reg_enum_t operand1_register = XED_REG_INVALID;
  if (operand1_name == XED_OPERAND_REG0) {
    operand1_register = xed_decoded_inst_get_reg(xedd, operand1_name);
  }

  const xed_operand_t *op2 = xed_inst_operand(xi, 1);
  xed_operand_enum_t operand2_name = xed_operand_name(op2);
  xed_reg_enum_t operand2_register = XED_REG_INVALID;
  if ((operand2_name == XED_OPERAND_REG0) ||
      (operand2_name == XED_OPERAND_REG1)) {
    operand2_register = xed_decoded_inst_get_reg(xedd, operand2_name);
  }

  // don't do instrument comparisons with RSP
  if ((operand1_register == XED_REG_RSP) ||
      (operand1_register == XED_REG_ESP) || (operand1_register == XED_REG_SP)) {
    return INST_NOTHANDLED;
  }
  if ((operand2_register == XED_REG_RSP) ||
      (operand2_register == XED_REG_ESP) || (operand2_register == XED_REG_SP)) {
    return INST_NOTHANDLED;
  }

  if (iclass == XED_ICLASS_SUB) {
    Instruction instr;
    instr.xedd = cmp_xedd;
    if (!ShouldInstrumentSub(module, instr, instruction_address)) {
      // printf("Not instrumenting SUB at %llx\n", instruction_address);
      return INST_NOTHANDLED;
    } else {
      // printf("Founf a SUB instrumentation candidate at %llx\n",
      // instruction_address);
    }
  }

  ModuleCovData *data = (ModuleCovData *)module->client_data;

  size_t bb_offset = bb_address - module->min_address;
  size_t cmp_offset = instruction_address - bb_address;
  if (cmp_offset >= 0x1000000) {
    // only allow one cmp instrumentation per bb
    WARN("Too large basic block for cmp coverage\n");
    return INST_NOTHANDLED;
  }

  // check what we matched already
  int match_width = operand_width - 8;
  for (; match_width >= 8; match_width -= 8) {
    uint64_t already_matched_code =
        GetCmpCode(bb_offset, cmp_offset, match_width);
    if (data->ignore_coverage.find(already_matched_code) !=
        data->ignore_coverage.end()) {
      break;
    }
  }
  match_width += 8;
  if (match_width == operand_width) {
    // we already have an (almost) full match
    return INST_NOTHANDLED;
  }

  size_t instrumentation_start_offset = module->instrumented_code_allocated;

  bool mov_needed = false;
  xed_reg_enum_t destination_reg;

  // check if the first param is a register
  // (if so, reuse it)
  // otherwise get a temporary register
  if (operand1_name == XED_OPERAND_REG0) {
    destination_reg = operand1_register;
  } else if (operand1_name == XED_OPERAND_MEM0) {
    mov_needed = true;
    destination_reg = GetUnusedRegister(operand2_register, operand_width);
  } else {
    FATAL("Unknown CMP first argument at %zx", instruction_address);
  }

  size_t mem_address = 0;
  bool rip_relative = assembler_->IsRipRelative(
      module, inst, instruction_address, &mem_address);

  size_t rsp_displacement = 0;
  bool rsp_relative = IsRspRelative(xedd, &rsp_displacement);

  // start with NOP that's going to be replaced with
  // JMP when the instrumentation is removed
  WriteCode(module, NOP5, sizeof(NOP5));

  if (sp_offset) {
    assembler_->OffsetStack(module, -sp_offset);
  }

  size_t stack_offset = sp_offset;

  olen = Push(&dstate, destination_reg, encoded, sizeof(encoded));
  WriteCode(module, encoded, olen);

  stack_offset += child_ptr_size;

  // todo don't do this for comparisons with rsp

  if (mov_needed) {
    // mov destination_reg, 1st_param_of_cmp
    xed_encoder_request_t mov;
    xed_encoder_request_zero_set_mode(&mov, &dstate);
    xed_encoder_request_set_iclass(&mov, XED_ICLASS_MOV);

    xed_encoder_request_set_effective_operand_width(&mov, operand_width);
    xed_encoder_request_set_effective_address_size(&mov,
                                                   dstate.stack_addr_width * 8);

    xed_encoder_request_set_reg(&mov, XED_OPERAND_REG0, destination_reg);
    xed_encoder_request_set_operand_order(&mov, 0, XED_OPERAND_REG0);

    CopyOperandFromInstruction(xedd, &mov, operand1_name, operand1_name, 1,
                               stack_offset);

    if (rip_relative) {
      FixRipDisplacement(&mov, mem_address,
                         GetCurrentInstrumentedAddress(module));
    }

    xed_error = xed_encode(&mov, encoded, sizeof(encoded), &olen);
    if (xed_error != XED_ERROR_NONE) {
      FATAL("Error encoding instruction");
    }
    WriteCode(module, encoded, olen);

    // xor destination_reg, 2nd_param_of_cmp
    xed_encoder_request_t xor_inst;
    xed_encoder_request_zero_set_mode(&xor_inst, &dstate);
    xed_encoder_request_set_iclass(&xor_inst, XED_ICLASS_XOR);

    xed_encoder_request_set_effective_operand_width(&xor_inst, operand_width);
    xed_encoder_request_set_effective_address_size(&xor_inst,
                                                   dstate.stack_addr_width * 8);

    xed_encoder_request_set_reg(&xor_inst, XED_OPERAND_REG0, destination_reg);
    xed_encoder_request_set_operand_order(&xor_inst, 0, XED_OPERAND_REG0);

    xed_operand_enum_t dest_operand_name = operand2_name;
    if (dest_operand_name == XED_OPERAND_REG0) {
      // already taken above
      dest_operand_name = XED_OPERAND_REG1;
    }

    CopyOperandFromInstruction(xedd, &xor_inst, operand2_name,
                               dest_operand_name, 1, stack_offset);

    // no need to fix rip displacement here
    // as we know this won't reference memory

    xed_error = xed_encode(&xor_inst, encoded, sizeof(encoded), &olen);
    if (xed_error != XED_ERROR_NONE) {
      FATAL("Error encoding instruction");
    }
    WriteCode(module, encoded, olen);

  } else {
    // just change cmp to xor
    xed_encoder_request_init_from_decode(xedd);
    xed_encoder_request_set_iclass(xedd, XED_ICLASS_XOR);

    if (rip_relative) {
      FixRipDisplacement(xedd, mem_address,
                         GetCurrentInstrumentedAddress(module));
    }

    if (rsp_relative) {
      xed_encoder_request_set_memory_displacement(xedd, rsp_displacement + stack_offset, 4);
    }

    xed_error = xed_encode(xedd, encoded, sizeof(encoded), &olen);
    if (xed_error != XED_ERROR_NONE) {
      FATAL("Error encoding instruction");
    }
    WriteCode(module, encoded, olen);
  }

  olen = Lzcnt(&dstate, operand_width, destination_reg, destination_reg,
               encoded, sizeof(encoded));
  WriteCode(module, encoded, olen);

  olen = CmpImm8(&dstate, operand_width, destination_reg, match_width, encoded,
                 sizeof(encoded));
  // check hat the offset is at the end
  if (*((char *)encoded + olen - 1) != match_width) {
    FATAL("Unexpected instruction encoding");
  }
  WriteCode(module, encoded, olen);

  size_t match_width_offset = module->instrumented_code_allocated - 1;

  WriteCode(module, JB, sizeof(JB));
  size_t jmp_offset = module->instrumented_code_allocated;

  xed_reg_enum_t rip = XED_REG_INVALID;
  if (child_ptr_size == 8) rip = XED_REG_RIP;
  olen = Mov(&dstate, 8, rip, 0x12345678, Get8BitRegister(destination_reg),
             encoded, sizeof(encoded));
  // check hat the offset is at the end
  if (*((int32_t *)((char *)encoded + olen - 4)) != 0x12345678) {
    FATAL("Unexpected instruction encoding");
  }
  WriteCode(module, encoded, olen);

  size_t bit_address =
      (size_t)data->coverage_buffer_remote + data->coverage_buffer_next;
  size_t mov_address = GetCurrentInstrumentedAddress(module);

  // fix the mov address/displacement
  if (child_ptr_size == 8) {
    *(int32_t *)(module->instrumented_code_local +
                 module->instrumented_code_allocated - 4) =
        (int32_t)(bit_address - mov_address);
  } else {
    *(uint32_t *)(module->instrumented_code_local +
                  module->instrumented_code_allocated - 4) =
        (uint32_t)bit_address;
  }

  // fix the jump offset
  *(int32_t *)(module->instrumented_code_local + jmp_offset - 4) =
      (int32_t)(module->instrumented_code_allocated - jmp_offset);

  olen = Pop(&dstate, destination_reg, encoded, sizeof(encoded));
  WriteCode(module, encoded, olen);

  if (sp_offset) {
    assembler_->OffsetStack(module, sp_offset);
  }

  CmpCoverageRecord *cmp_record = new CmpCoverageRecord();
  cmp_record->ignored = false;
  cmp_record->width = operand_width;
  cmp_record->match_width = match_width;
  cmp_record->match_width_offset = match_width_offset;
  cmp_record->instrumentation_offset = instrumentation_start_offset;
  cmp_record->bb_address = bb_address;
  cmp_record->bb_offset = bb_offset;
  cmp_record->cmp_offset = cmp_offset;
  cmp_record->instrumentation_size =
      module->instrumented_code_allocated - instrumentation_start_offset;
  data->coverage_to_cmp[GetCmpCode(bb_offset, cmp_offset, 0)] = cmp_record;
  data->buf_to_cmp[data->coverage_buffer_next] = cmp_record;
  data->coverage_buffer_next++;

  // return INST_NOTHANDLED which causes
  // the original instruction to be repeated
  return INST_NOTHANDLED;
}

```

`assembler.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef ASSEMBLER_H
#define ASSEMBLER_H

#include <cstddef>
#include <list>
#include <set>

#include "instruction.h"

struct IndirectBreakpoinInfo;
class TinyInst;
class ModuleInfo;

class Assembler {
 public:
  Assembler(TinyInst &tinyinst) : tinyinst_(tinyinst) {}
  virtual ~Assembler() = default;

  virtual void Init() = 0;

  virtual bool DecodeInstruction(Instruction &inst,
                                 const unsigned char *address,
                                 unsigned int max_size) = 0;
  virtual void FixInstructionAndOutput(
      ModuleInfo *module,
      Instruction &inst,
      const unsigned char *input,
      const unsigned char *input_address_remote,
      bool convert_call_to_jmp = false) = 0;
  virtual void HandleBasicBlockEnd(
      const char *address, ModuleInfo *module,
      std::set<char *> *queue,
      std::list<std::pair<uint32_t, uint32_t>> *offset_fixes,
      Instruction &inst,
      const char *code_ptr,
      size_t offset,
      size_t last_offset) = 0;

  virtual void JmpAddress(ModuleInfo *module, size_t address) = 0;
  virtual void Nop(ModuleInfo *module) = 0;
  virtual void Breakpoint(ModuleInfo *module) = 0;
  virtual void Crash(ModuleInfo *module) = 0;

  virtual void OffsetStack(ModuleInfo *module, int32_t offset) = 0;
  virtual bool IsRipRelative(ModuleInfo *module,
                             Instruction &inst,
                             size_t instruction_address,
                             size_t *mem_address) = 0;
  virtual void TranslateJmp(ModuleInfo *module,
                            ModuleInfo *target_module,
                            size_t original_target,
                            IndirectBreakpoinInfo& breakpoint_info,
                            bool global_indirect,
                            size_t previous_offset) = 0;
  virtual void InstrumentLocalIndirect(ModuleInfo *module,
                                       Instruction &inst,
                                       size_t instruction_address,
                                       size_t bb_address) = 0;
  virtual void InstrumentGlobalIndirect(ModuleInfo *module,
                                        Instruction &inst,
                                        size_t instruction_address) = 0;
  virtual void FixOffset(ModuleInfo *module,
                 uint32_t jmp_offset,
                 uint32_t target_offset) = 0;

 protected:
  TinyInst &tinyinst_;
};

#endif  // ASSEMBLER_H

```

`common.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include <stdio.h>
#include <inttypes.h>
#include <list>
#include <chrono>

#include "common.h"

uint64_t GetCurTime(void) {
  auto duration =  std::chrono::system_clock::now().time_since_epoch();
  auto millis = std::chrono::duration_cast<std::chrono::milliseconds>(duration).count();
  return millis;
}

bool BoolFromOptionValue(char *value) {
  if (_stricmp(value, "off") == 0) return false;
  if (_stricmp(value, "false") == 0) return false;
  if (_stricmp(value, "0") == 0) return false;
  return true;
}

bool GetBinaryOption(const char *name, int argc, char** argv, bool default_value) {
  for (int i = 0; i < argc; i++) {
    if (strcmp(argv[i], "--") == 0) break;
    if (strcmp(argv[i], name) == 0) {
      if ((i + 1) < argc && strcmp(argv[i + 1], "--")) {
        return BoolFromOptionValue(argv[i + 1]);
      }
      return true;
    }
    if (strncmp(argv[i], name, strlen(name)) == 0) {
      if (argv[i][strlen(name)] == '=') {
        return BoolFromOptionValue(argv[i] + strlen(name) + 1);
      }
    }
  }
  return default_value;
}

char *GetOption(const char *name, int argc, char** argv) {
  for (int i = 0; i < argc; i++) {
    if(strcmp(argv[i], "--") == 0) return NULL;
    if(strcmp(argv[i], name) == 0) {
      if ((i + 1) < argc && strcmp(argv[i + 1], "--")) {
        return argv[i + 1];
      } else {
        return NULL;
      }
    }
    if (strncmp(argv[i], name, strlen(name)) == 0) {
      if (argv[i][strlen(name)] == '=') {
        return argv[i] + strlen(name) + 1;
      }
    }
  }
  return NULL;
}


void GetOptionAll(const char *name, int argc, char** argv, std::list<char *> *results) {
  for (int i = 0; i < argc; i++) {
    if (strcmp(argv[i], "--") == 0) return;
    if (strcmp(argv[i], name) == 0) {
      if ((i + 1) < argc && strcmp(argv[i + 1], "--")) {
        results->push_back(argv[i + 1]);
      } else {
        return;
      }
    }
    if (strncmp(argv[i], name, strlen(name)) == 0) {
      if (argv[i][strlen(name)] == '=') {
        results->push_back(argv[i] + strlen(name) + 1);
      }
    }
  }
}

int GetIntOption(const char *name, int argc, char** argv, int default_value) {
  char *option = GetOption(name, argc, argv);
  if (!option) return default_value;
  return (int)strtol(option, NULL, 0);
}


//quoting on Windows is weird
size_t ArgvEscapeWindows(char *in, char *out) {
  int needs_quoting = 0;
  size_t size = 0;
  char *p = in;
  size_t i;

  //check if quoting is necessary
  if (strchr(in, ' ')) needs_quoting = 1;
  if (strchr(in, '\"')) needs_quoting = 1;
  if (strchr(in, '\t')) needs_quoting = 1;
  if (strchr(in, '\n')) needs_quoting = 1;
  if (strchr(in, '\v')) needs_quoting = 1;
  if (!needs_quoting) {
    size = strlen(in);
    if (out) memcpy(out, in, size);
    return size;
  }

  if (out) out[size] = '\"';
  size++;

  while (*p) {
    size_t num_backslashes = 0;
    while ((*p) && (*p == '\\')) {
      p++;
      num_backslashes++;
    }

    if (*p == 0) {
      for (i = 0; i < (num_backslashes * 2); i++) {
        if (out) out[size] = '\\';
        size++;
      }
      break;
    }
    else if (*p == '\"') {
      for (i = 0; i < (num_backslashes * 2 + 1); i++) {
        if (out) out[size] = '\\';
        size++;
      }
      if (out) out[size] = *p;
      size++;
    }
    else {
      for (i = 0; i < num_backslashes; i++) {
        if (out) out[size] = '\\';
        size++;
      }
      if (out) out[size] = *p;
      size++;
    }

    p++;
  }

  if (out) out[size] = '\"';
  size++;

  return size;
}

size_t ArgvEscapeMacOS(char *in, char *out) {
  size_t size = 0;
  char *p = in;
  while (*p) {
    if (strchr("|&:;()<>~*@?!$#[]{}\\ '\"`\t\n\v\r", *p)) {
      if (out) out[size] = '\\';
      size++;
    }

    if (out) out[size] = *p;
    size++;

    p++;
  }

  return size;
}


char *ArgvToCmd(int argc, char** argv) {
  size_t len = 0;
  int i;
  char* buf, *ret;

  for (i = 0; i < argc; i++)
    len += ArgvEscape(argv[i], NULL) + 1;

  if (!len) FATAL("Error creating command line");

  buf = ret = (char *)malloc(len);

  for (i = 0; i < argc; i++) {
    size_t l = ArgvEscape(argv[i], buf);
    buf += l;
    *(buf++) = ' ';
  }

  ret[len - 1] = 0;

  // printf("%s\n", ret);

  return ret;
}

```

`common.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef COMMON_H
#define COMMON_H

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <inttypes.h>
#include <list>

#if defined(WIN32) || defined(_WIN32) || defined(__WIN32)
    #include <windows.h>
    #define ArgvEscape ArgvEscapeWindows
#else
    #include <limits.h>
    #ifndef MAX_PATH
        #define MAX_PATH PATH_MAX
    #endif

    #include <strings.h>
    #define _stricmp strcasecmp

    #define ArgvEscape ArgvEscapeMacOS
#endif

enum {
  /* 00 */ FAULT_NONE,
  /* 01 */ FAULT_TMOUT,
  /* 02 */ FAULT_CRASH,
  /* 03 */ FAULT_ERROR,
  /* 04 */ FAULT_NOINST,
  /* 05 */ FAULT_NOBITS
};

#define SAY(...)    printf(__VA_ARGS__)

#define WARN(...) do { \
    SAY("[!] WARNING: " __VA_ARGS__); \
    SAY("\n"); \
  } while (0)

#define FATAL(...) do { \
    SAY("[-] PROGRAM ABORT : " __VA_ARGS__); \
    SAY("         Location : %s(), %s:%u\n\n", \
         __FUNCTION__, __FILE__, __LINE__); \
    exit(1); \
  } while (0)

#define USAGE_CHECK(condition, message) if(!(condition)) FATAL("%s\n", message);

struct AddressRange {
  size_t from;
  size_t to;
  char *data;
};

// gets time in milliseconds
uint64_t GetCurTime(void);

char *GetOption(const char *name, int argc, char** argv);
void GetOptionAll(const char *name, int argc, char** argv, std::list<char *> *results);
bool GetBinaryOption(const char *name, int argc, char** argv, bool default_value);
int GetIntOption(const char *name, int argc, char** argv, int default_value);

char *ArgvToCmd(int argc, char** argv);

#endif

```

`coverage.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#define  _CRT_SECURE_NO_WARNINGS

#include "common.h"
#include "coverage.h"
#include <algorithm>

ModuleCoverage::ModuleCoverage() {
  module_name[0] = 0;
}

ModuleCoverage::ModuleCoverage(std::string& name, std::set<uint64_t> offsets) {
  module_name = name;
  this->offsets = offsets;
}

ModuleCoverage *GetModuleCoverage(Coverage &coverage, std::string& name) {
  for (auto iter = coverage.begin(); iter != coverage.end(); iter++) {
    if (_stricmp(iter->module_name.c_str(), name.c_str()) == 0) {
      return &(*iter);
    }
  }
  return NULL;
}

void MergeCoverage(Coverage &coverage, Coverage &toAdd) {
  for (auto iter = toAdd.begin(); iter != toAdd.end(); iter++) {
    ModuleCoverage *module_coverage = GetModuleCoverage(coverage, iter->module_name);
    if (module_coverage) {
      module_coverage->offsets.insert(
        iter->offsets.begin(),
        iter->offsets.end());
    } else {
      coverage.push_back({ iter->module_name, iter->offsets });
    }
  }
}

void CoverageIntersection(Coverage &coverage1,
  Coverage &coverage2,
  Coverage &result)
{
  for (auto iter = coverage1.begin(); iter != coverage1.end(); iter++) {
    ModuleCoverage *module1 = &(*iter);
    ModuleCoverage *module2 = GetModuleCoverage(coverage2, iter->module_name);
    if (!module2) continue;
    std::set<uint64_t> offsets;
    for (auto offset1 = module1->offsets.begin();
      offset1 != module1->offsets.end(); offset1++)
    {
      if (module2->offsets.find(*offset1) != module2->offsets.end()) {
        offsets.insert(*offset1);
      }
    }
    if (!offsets.empty()) {
      result.push_back({ iter->module_name, offsets });
    }
  }
}

void CoverageSymmetricDifference(Coverage &coverage1,
  Coverage &coverage2,
  Coverage &result)
{
  for (auto iter = coverage1.begin(); iter != coverage1.end(); iter++) {
    ModuleCoverage *module1 = &(*iter);
    ModuleCoverage *module2 = GetModuleCoverage(coverage2, iter->module_name);
    if (!module2) {
      result.push_back({ iter->module_name, iter->offsets });
    } else {
      std::set<uint64_t> offsets;
      for (auto offset1 = module1->offsets.begin();
        offset1 != module1->offsets.end(); offset1++)
      {
        if (module2->offsets.find(*offset1) == module2->offsets.end()) {
          offsets.insert(*offset1);
        }
      }
      for (auto offset2 = module2->offsets.begin();
        offset2 != module2->offsets.end(); offset2++)
      {
        if (module1->offsets.find(*offset2) == module1->offsets.end()) {
          offsets.insert(*offset2);
        }
      }
      if (!offsets.empty()) {
        result.push_back({ iter->module_name, offsets });
      }
    }
  }
  // still need to add coverage for modules in coverage2
  // not present in coverage1
  for (auto iter = coverage2.begin(); iter != coverage2.end(); iter++) {
    ModuleCoverage *module2 = &(*iter);
    ModuleCoverage *module1 = GetModuleCoverage(coverage1, iter->module_name);
    if (!module1) {
      result.push_back({ iter->module_name, iter->offsets });
    }
  }
}

// returns coverage2 not present in coverage1
void CoverageDifference(Coverage &coverage1,
  Coverage &coverage2,
  Coverage &result)
{
  for (auto iter = coverage2.begin(); iter != coverage2.end(); iter++) {
    ModuleCoverage *module1 = GetModuleCoverage(coverage1, iter->module_name);
    ModuleCoverage *module2 = &(*iter);
    if (!module1) {
      result.push_back({ iter->module_name, iter->offsets });
    } else {
      std::set<uint64_t> offsets;
      for (auto offset2 = module2->offsets.begin();
        offset2 != module2->offsets.end(); offset2++)
      {
        if (module1->offsets.find(*offset2) == module1->offsets.end()) {
          offsets.insert(*offset2);
        }
      }
      if (!offsets.empty()) {
        result.push_back({ iter->module_name, offsets });
      }
    }
  }
}

bool CoverageContains(Coverage &coverage1, Coverage &coverage2) {
  for (auto iter = coverage2.begin(); iter != coverage2.end(); iter++) {
    ModuleCoverage *module2 = &(*iter);
    ModuleCoverage *module1 = GetModuleCoverage(coverage1, iter->module_name);
    if (!module1) {
      return false;
    }
    for (auto offset_iter = module2->offsets.begin();
         offset_iter != module2->offsets.end(); offset_iter++)
    {
      if (module1->offsets.find(*offset_iter) == module1->offsets.end()) {
        return false;
      }
    }
  }
  return true;
}


void WriteCoverage(Coverage& coverage, char *filename) {
  FILE *fp = fopen(filename, "w");
  if (!fp) {
    printf("Error opening %s\n", filename);
    return;
  }
  for (auto iter = coverage.begin(); iter != coverage.end(); iter++) {
    for (auto offsetiter = iter->offsets.begin();
         offsetiter != iter->offsets.end(); offsetiter++)
    {
      fprintf(fp, "%s+0x%llx\n", iter->module_name.c_str(), *offsetiter);
    }
  }
  fclose(fp);
}

void WriteCoverageBinary(Coverage& coverage, FILE *fp) {
  uint64_t num_modules = coverage.size();
  fwrite(&num_modules, sizeof(num_modules), 1, fp);
  for (auto iter = coverage.begin(); iter != coverage.end(); iter++) {
    uint64_t str_size = iter->module_name.size();
    fwrite(&str_size, sizeof(str_size), 1, fp);
    fwrite(iter->module_name.data(), str_size, 1, fp);
    uint64_t num_offsets = iter->offsets.size();
    fwrite(&num_offsets, sizeof(num_offsets), 1, fp);
    uint64_t *offsets = (uint64_t *)malloc((size_t)num_offsets * sizeof(uint64_t));
    size_t i = 0;
    for (auto iter2 = iter->offsets.begin(); iter2 != iter->offsets.end(); iter2++) {
      offsets[i] = *iter2;
      i++;
    }
    fwrite(offsets, sizeof(uint64_t), (size_t)num_offsets, fp);
    free(offsets);
  }
}

void WriteCoverageBinary(Coverage& coverage, char *filename) {
  FILE *fp = fopen(filename, "wb");
  if (!fp) {
    printf("Error opening %s\n", filename);
    return;
  }
  WriteCoverageBinary(coverage, fp);
  fclose(fp);
}

void ReadCoverageBinary(Coverage& coverage, FILE *fp) {
  uint64_t num_modules;
  fread(&num_modules, sizeof(num_modules), 1, fp);
  for (size_t m = 0; m < num_modules; m++) {
    ModuleCoverage module_coverage;
    uint64_t str_size;
    fread(&str_size, sizeof(str_size), 1, fp);
    char* str_data = (char*)malloc(str_size);
    fread(str_data, str_size, 1, fp);
    module_coverage.module_name = std::string(str_data, str_size);
    free(str_data);
    uint64_t num_offsets;
    fread(&num_offsets, sizeof(num_offsets), 1, fp);
    uint64_t *offsets = (uint64_t *)malloc((size_t)num_offsets * sizeof(uint64_t));
    fread(offsets, sizeof(uint64_t), (size_t)num_offsets, fp);
    for (size_t i = 0; i < num_offsets; i++) {
      module_coverage.offsets.insert(offsets[i]);
    }
    free(offsets);
    coverage.push_back(module_coverage);
  }
}

void ReadCoverageBinary(Coverage& coverage, char *filename) {
  FILE *fp = fopen(filename, "rb");
  if (!fp) {
    printf("Error opening %s\n", filename);
    return;
  }
  ReadCoverageBinary(coverage, fp);
  fclose(fp);
}

void PrintCoverage(Coverage& coverage) {
  for (auto iter = coverage.begin(); iter != coverage.end(); iter++) {
    printf("%s\n", iter->module_name.c_str());
    for (auto offsetiter = iter->offsets.begin();
      offsetiter != iter->offsets.end(); offsetiter++)
    {
      printf("0x%llx ", *offsetiter);
    }
    printf("\n");
  }
}




```

`coverage.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef COVERAGE_H
#define COVERAGE_H

#include <string>
#include <set>
#include <list>

class ModuleCoverage {
public:
  ModuleCoverage();
  ModuleCoverage(std::string& name, std::set<uint64_t> offsets);

  std::string module_name;
  std::set<uint64_t> offsets;
};

typedef std::list<ModuleCoverage> Coverage;

ModuleCoverage *GetModuleCoverage(Coverage &coverage, std::string &name);

void PrintCoverage(Coverage& coverage);
void WriteCoverage(Coverage& coverage, char *filename);

void MergeCoverage(Coverage &coverage, Coverage &toAdd);
void CoverageIntersection(Coverage &coverage1,
                       Coverage &coverage2,
                       Coverage &result);
// returns coverage2 not present in coverage1
void CoverageDifference(Coverage &coverage1,
                        Coverage &coverage2,
                        Coverage &result);
// returns coverage2 not present in coverage1 and vice versa
void CoverageSymmetricDifference(Coverage &coverage1,
                                Coverage &coverage2,
                                Coverage &result);
bool CoverageContains(Coverage &coverage1, Coverage &coverage2);

void ReadCoverageBinary(Coverage& coverage, char *filename);
void ReadCoverageBinary(Coverage& coverage, FILE *fp);
void WriteCoverageBinary(Coverage& coverage, char *filename);
void WriteCoverageBinary(Coverage& coverage, FILE *fp);

#endif // COVERAGE_H
```

`instruction.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef INSTRUCTION_H
#define INSTRUCTION_H

#ifdef ARM64
#include "third_party/reil/reil/aarch64/decoder.h"
#else
extern "C" {
  #include "xed/xed-interface.h"
}
typedef struct xed_decoded_inst_s xed_decoded_inst_t;
#endif

enum InstructionClass {
  INVALID = 0,
  RET,
  IJUMP,
  ICALL,
  OTHER,
};

struct Instruction {
  size_t address;
  size_t length;
  bool bbend;
  InstructionClass iclass;

#ifdef ARM64
  reil::aarch64::decoder::Instruction instr;
#else
  xed_decoded_inst_t xedd;
#endif
  Instruction()
      : address(0),
        length(0),
        bbend(false),
        iclass(InstructionClass::INVALID),
#ifdef ARM64
        instr({})
#else
        xedd({})
#endif
  {}
};

#endif  // INSTRUCTION_H

```

`litecov.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#define _CRT_SECURE_NO_WARNINGS

#include "litecov.h"

#include "common.h"

ModuleCovData::ModuleCovData() { ClearInstrumentationData(); }

// does not clear collected coverage and ignore coverage
void ModuleCovData::ClearInstrumentationData() {
  coverage_buffer_remote = NULL;
  coverage_buffer_size = 0;
  coverage_buffer_next = 0;
  has_remote_coverage = false;
  buf_to_coverage.clear();
  coverage_to_inst.clear();
  ClearCmpCoverageData();
}

void LiteCov::Init(int argc, char **argv) {
  TinyInst::Init(argc, argv);

  coverage_type = COVTYPE_BB;
  char *option = GetOption("-covtype", argc, argv);
  if (option) {
    if (strcmp(option, "bb") == 0)
      coverage_type = COVTYPE_BB;
    else if (strcmp(option, "edge") == 0)
      coverage_type = COVTYPE_EDGE;
    else
      FATAL("Unknown coverage type");
  }

  compare_coverage = GetBinaryOption("-cmp_coverage", argc, argv, false);

  for (ModuleInfo *module : instrumented_modules) {
    module->client_data = new ModuleCovData();
  }
}

void LiteCov::OnModuleInstrumented(ModuleInfo *module) {
  TinyInst::OnModuleInstrumented(module);

  ModuleCovData *data = (ModuleCovData *)module->client_data;

  data->ClearInstrumentationData();

  data->coverage_buffer_size = COVERAGE_SIZE;

  if (!data->coverage_buffer_size) {
    data->coverage_buffer_size = module->code_size;
  }

  // map as readonly initially
  // this causes an exception the first time coverage is written to the buffer
  // this enables us to quickly determine if we had new coverage or not
  data->coverage_buffer_remote =
#ifdef ARM64
    (unsigned char *)RemoteAllocate(data->coverage_buffer_size, READONLY, true);
#else
    (unsigned char *)RemoteAllocateNear(
      (uint64_t)module->instrumented_code_remote,
      (uint64_t)module->instrumented_code_remote +
          module->instrumented_code_size,
      data->coverage_buffer_size, READONLY, true);
#endif

  if (!data->coverage_buffer_remote) {
    FATAL("Could not allocate coverage buffer");
  }
}

void LiteCov::OnModuleUninstrumented(ModuleInfo *module) {
  TinyInst::OnModuleUninstrumented(module);

  ModuleCovData *data = (ModuleCovData *)module->client_data;

  CollectCoverage(data);

  if (data->coverage_buffer_remote && IsTargetAlive()) {
    RemoteFree(data->coverage_buffer_remote, data->coverage_buffer_size);
    data->coverage_buffer_remote = NULL;
  }

  data->ClearInstrumentationData();
}

// just replaces the inserted instructions with NOPs
void LiteCov::ClearCoverageInstrumentation(ModuleInfo *module,
                                           uint64_t coverage_code) {
  ModuleCovData *data = (ModuleCovData *)module->client_data;

  auto iter = data->coverage_to_inst.find(coverage_code);
  if (iter == data->coverage_to_inst.end()) {
    if (compare_coverage) {
      ClearCmpCoverageInstrumentation(module, coverage_code);
    }
    return;
  }

  size_t code_offset = iter->second;

  NopCovInstructions(module, code_offset);

  data->coverage_to_inst.erase(iter);
}

uint64_t LiteCov::GetCmpCode(size_t bb_offset, size_t cmp_offset,
                             int bits_match) {
  // cmp code consists of bb offset in the highest 32 bits
  // cmp instruction offset (from bb start) in the next 24 bits
  // and bits to match in the lowest 8 bits
  uint64_t code = (((uint64_t)bb_offset << 32) +
                   ((cmp_offset << 8) & 0xFFFFFFFFUL) + bits_match);
  // it also has the highest bit set
  code |= 0x8000000000000000ULL;
  return code;
}

bool LiteCov::IsCmpCoverageCode(uint64_t code) {
  return (code & 0x8000000000000000ULL);
}

void LiteCov::EmitCoverageInstrumentation(ModuleInfo *module,
                                          uint64_t coverage_code) {
  ModuleCovData *data = (ModuleCovData *)module->client_data;

  // don't instrument if we are ignoring this bit of coverage
  if (data->ignore_coverage.find(coverage_code) != data->ignore_coverage.end())
    return;

  if (data->coverage_buffer_next == data->coverage_buffer_size) {
    WARN("Coverage buffer full\n");
    return;
  }

  if (data->coverage_to_inst.find(coverage_code) !=
      data->coverage_to_inst.end()) {
    WARN("Edge %llx already exists", coverage_code);
    return;
  }

  data->buf_to_coverage[data->coverage_buffer_next] = coverage_code;
  data->coverage_to_inst[coverage_code] = module->instrumented_code_allocated;

  size_t bit_address =
      (size_t)data->coverage_buffer_remote + data->coverage_buffer_next;
  size_t mov_address = GetCurrentInstrumentedAddress(module);
  data->coverage_buffer_next++;

  EmitCoverageInstrumentation(module, bit_address, mov_address);
}

void LiteCov::InstrumentBasicBlock(ModuleInfo *module, size_t bb_address) {
  if (coverage_type != COVTYPE_BB) return;

  uint64_t coverage_code = GetBBCode(module, bb_address);

  EmitCoverageInstrumentation(module, coverage_code);
}

void LiteCov::InstrumentEdge(ModuleInfo *previous_module,
                             ModuleInfo *next_module, size_t previous_address,
                             size_t next_address) {
  if (coverage_type != COVTYPE_EDGE) return;

  // don't do anything on cross-module edges
  if (previous_module != next_module) return;
  uint64_t coverage_code =
      GetEdgeCode(previous_module, previous_address, next_address);

  EmitCoverageInstrumentation(previous_module, coverage_code);
}

// basic block code is just offset from the start of the module
uint64_t LiteCov::GetBBCode(ModuleInfo *module, size_t bb_address) {
  return ((uint64_t)bb_address - (uint64_t)module->min_address);
}

// edge code has previous offset in higher 32 bits
// and next offset in the lower 32 bits
// note that source address can be 0 if we don't know it
// (module entries, indirect jumps using global jumptable)
uint64_t LiteCov::GetEdgeCode(ModuleInfo *module, size_t edge_address1,
                              size_t edge_address2) {
  uint64_t offset1 = 0;
  if (edge_address1)
    offset1 = ((uint64_t)edge_address1 - (uint64_t)module->min_address);
  uint64_t offset2 = 0;
  if (edge_address2)
    offset2 = ((uint64_t)edge_address2 - (uint64_t)module->min_address);

  return ((offset1 << 32) + (offset2 & 0xFFFFFFFF));
}

void LiteCov::OnModuleEntered(ModuleInfo *module, size_t entry_address) {
  if (coverage_type == COVTYPE_BB) return;

  // if we are in edge coverage mode, record module entries as edges
  // we don't know the source address (it's in another module)
  // so treat it as zero
  ModuleCovData *data = (ModuleCovData *)module->client_data;
  uint64_t coverage_code = GetEdgeCode(module, 0, entry_address);
  if (data->ignore_coverage.count(coverage_code) != 0) return;
  data->collected_coverage.insert(coverage_code);
}

// checks if address is in any of our remote coverage buffers
ModuleCovData *LiteCov::GetDataByRemoteAddress(size_t address) {
  for (ModuleInfo *module : instrumented_modules) {
    ModuleCovData *data = (ModuleCovData *)module->client_data;
    if (!data->coverage_buffer_remote) continue;
    if ((address >= (size_t)data->coverage_buffer_remote) &&
        (address <
         ((size_t)data->coverage_buffer_remote + data->coverage_buffer_size))) {
      return data;
    }
  }
  return NULL;
}

// catches writing to the coverage buffer for the first time
void LiteCov::HandleBufferWriteException(ModuleCovData *data) {
  RemoteProtect(data->coverage_buffer_remote, data->coverage_buffer_size,
                READWRITE);

  data->has_remote_coverage = true;
}

bool LiteCov::OnException(Exception *exception_record) {
  if ((exception_record->type == ACCESS_VIOLATION) &&
      (exception_record->maybe_write_violation)) {
    ModuleCovData *data =
        GetDataByRemoteAddress((size_t)exception_record->access_address);
    if (data) {
      HandleBufferWriteException(data);
      return true;
    }
  }

  return TinyInst::OnException(exception_record);
}

void LiteCov::ClearRemoteBuffer(ModuleCovData *data) {
  if (!IsTargetAlive()) return;
  if (!data->coverage_buffer_remote) return;
  if (!data->has_remote_coverage) return;

  unsigned char *buf = (unsigned char *)malloc(data->coverage_buffer_next);
  memset(buf, 0, data->coverage_buffer_next);

  RemoteWrite(data->coverage_buffer_remote, buf, data->coverage_buffer_next);

  RemoteProtect(data->coverage_buffer_remote, data->coverage_buffer_size,
                READONLY);

  data->has_remote_coverage = false;

  free(buf);
}

void LiteCov::ClearCoverage(ModuleCovData *data) {
  data->collected_coverage.clear();
  ClearRemoteBuffer(data);
}

void LiteCov::ClearCoverage() {
  for (ModuleInfo *module : instrumented_modules) {
    ModuleCovData *data = (ModuleCovData *)module->client_data;
    ClearCoverage(data);
  }
}

// fetches and decodes coverage from the remote buffer
void LiteCov::CollectCoverage(ModuleCovData *data) {
  if (!data->has_remote_coverage) return;

  unsigned char *buf = (unsigned char *)malloc(data->coverage_buffer_next);

  RemoteRead(data->coverage_buffer_remote, buf, data->coverage_buffer_next);

  for (size_t i = 0; i < data->coverage_buffer_next; i++) {
    if (buf[i]) {
      auto iter = data->buf_to_coverage.find(i);
      if (iter == data->buf_to_coverage.end()) {
        if (compare_coverage) {
          CollectCmpCoverage(data, i, buf[i]);
        }
      } else {
        uint64_t coverage_code = iter->second;
        data->collected_coverage.insert(coverage_code);
      }
    }
  }

  free(buf);

  ClearRemoteBuffer(data);
  data->has_remote_coverage = false;
}

void LiteCov::CollectCoverage() {
  for (ModuleInfo *module : instrumented_modules) {
    ModuleCovData *data = (ModuleCovData *)module->client_data;
    CollectCoverage(data);
  }
}

void LiteCov::GetCoverage(Coverage &coverage, bool clear_coverage) {
  CollectCoverage();
  for (ModuleInfo *module : instrumented_modules) {
    ModuleCovData *data = (ModuleCovData *)module->client_data;

    if (data->collected_coverage.empty()) continue;

    // check if that module is already in the coverage list
    // (if the client calls with non-empty initial coverage)
    ModuleCoverage *module_coverage =
        GetModuleCoverage(coverage, module->module_name);
    if (module_coverage) {
      module_coverage->offsets.insert(data->collected_coverage.begin(),
                                      data->collected_coverage.end());
    } else {
      coverage.push_back({module->module_name, data->collected_coverage});
    }
  }
  if (clear_coverage) ClearCoverage();
}

// sets (new) coverage to ignore
void LiteCov::IgnoreCoverage(Coverage &coverage) {
  for (const ModuleCoverage &mod_cov : coverage) {
    ModuleInfo *module = GetModuleByName(mod_cov.module_name.c_str());
    if (!module) continue;
    ModuleCovData *data = (ModuleCovData *)module->client_data;

    // remember the offsets so they don't get instrumented later
    data->ignore_coverage.insert(mod_cov.offsets.begin(),
                                 mod_cov.offsets.end());
    if (!module->instrumented) continue;

    // if we already have instrumentation in place for some of the offsets
    // remove it here
    for (const uint64_t code_off : mod_cov.offsets) {
      ClearCoverageInstrumentation(module, code_off);
    }
  }
}

// quickly checks if we have new coverage
bool LiteCov::HasNewCoverage() {
  for (ModuleInfo *module : instrumented_modules) {
    ModuleCovData *data = (ModuleCovData *)module->client_data;
    if (!data->collected_coverage.empty()) return true;
    if (data->has_remote_coverage) return true;
  }
  return false;
}

void LiteCov::OnProcessExit() {
  CollectCoverage();
  TinyInst::OnProcessExit();
}

void ModuleCovData::ClearCmpCoverageData() {
  for (auto &[buffer_offset, cmp_record] : buf_to_cmp) {
    delete cmp_record;
  }
  buf_to_cmp.clear();
  coverage_to_cmp.clear();
}

void LiteCov::ClearCmpCoverageInstrumentation(ModuleInfo *module,
                                              uint64_t coverage_code) {
  if (!IsCmpCoverageCode(coverage_code)) return;

  ModuleCovData *data = (ModuleCovData *)module->client_data;

  int matched_width = coverage_code & 0xFF;
  coverage_code -= matched_width;

  auto iter = data->coverage_to_cmp.find(coverage_code);
  if (iter == data->coverage_to_cmp.end()) return;

  CmpCoverageRecord *cmp_record = iter->second;

  if (cmp_record->ignored) return;

  NopCmpCovInstructions(module, *cmp_record, matched_width);
}

void LiteCov::CollectCmpCoverage(ModuleCovData *data, size_t buffer_offset,
                                 char buffer_value) {
  auto iter = data->buf_to_cmp.find(buffer_offset);
  if (iter == data->buf_to_cmp.end()) return;

  CmpCoverageRecord *cmp_record = iter->second;

  if (cmp_record->ignored) return;

  if (buffer_value < cmp_record->match_width) return;

  for (int match = cmp_record->match_width; match <= buffer_value; match += 8) {
    // full match, no need to record it
    if (match == cmp_record->width) break;
    uint64_t coverage_code =
        GetCmpCode(cmp_record->bb_offset, cmp_record->cmp_offset, match);
    data->collected_coverage.insert(coverage_code);
  }
}

```

`litecov.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef LITECOV_H
#define LITECOV_H

#include <unordered_map>
#include <set>

#include "coverage.h"
#include "tinyinst.h"
#include "instruction.h"

#define COVERAGE_SIZE 0

enum CovType {
  COVTYPE_BB,
  COVTYPE_EDGE
};

struct CmpCoverageRecord {
  bool ignored;
  int width;
  int match_width;
  size_t bb_address; // for debugging
  size_t bb_offset;
  size_t cmp_offset;
  size_t instrumentation_offset;
  size_t instrumentation_size;
  size_t match_width_offset;
};

class ModuleCovData {
public:
  ModuleCovData();
  void ClearInstrumentationData();

  unsigned char *coverage_buffer_remote;

  size_t coverage_buffer_size;
  size_t coverage_buffer_next;

  std::set<uint64_t> collected_coverage;
  std::set<uint64_t> ignore_coverage;

  // maps offset in the coverage buffer to
  // offset of the basic block / edge code
  std::unordered_map<size_t, uint64_t> buf_to_coverage;

  // maps coverage code (e.g. a bb offset)
  // to offset in the instrumented buffer
  // of the corresponding instrumentation
  std::unordered_map<uint64_t, size_t> coverage_to_inst;

  bool has_remote_coverage;

  void ClearCmpCoverageData();
  std::unordered_map<size_t, CmpCoverageRecord*> buf_to_cmp;
  std::unordered_map<uint64_t, CmpCoverageRecord*> coverage_to_cmp;
};

class LiteCov : public TinyInst {
public:
  virtual void Init(int argc, char **argv) override;

  void GetCoverage(Coverage &coverage, bool clear_coverage);
  void ClearCoverage();

  // note: this does not affect already collected coverage
  void IgnoreCoverage(Coverage &coverage);

  bool HasNewCoverage();

protected:
  virtual void OnModuleInstrumented(ModuleInfo *module) override;
  virtual void OnModuleUninstrumented(ModuleInfo *module) override;

  virtual void OnProcessExit() override;

  virtual void OnModuleEntered(ModuleInfo *module, size_t entry_address) override;
  virtual bool OnException(Exception *exception_record) override;

  virtual void InstrumentBasicBlock(ModuleInfo *module, size_t bb_address) override;
  virtual void InstrumentEdge(ModuleInfo *previous_module,
                              ModuleInfo *next_module,
                              size_t previous_address,
                              size_t next_address) override;
  virtual InstructionResult InstrumentInstruction(ModuleInfo *module,
                                                  Instruction &inst,
                                                  size_t bb_address,
                                                  size_t instruction_address) override;

  void EmitCoverageInstrumentation(ModuleInfo *module, uint64_t coverage_code);
  void EmitCoverageInstrumentation(ModuleInfo *module,
                                    size_t bit_address,
                                    size_t mov_address);
  void ClearCoverageInstrumentation(ModuleInfo *module, uint64_t coverage_code);

  void NopCovInstructions(ModuleInfo *module, size_t code_offset);
  void NopCmpCovInstructions(ModuleInfo *module,
                             CmpCoverageRecord &cmp_record,
                             int matched_width);

  // compute a unique code for a basic block
  // this is just an offset into the module
  uint64_t GetBBCode(ModuleInfo *module, size_t bb_address);

  // compute a unique code for a basic block
  // this has address1 offset in lower 32 bits and
  // address2 offset in higher 32 bits
  uint64_t GetEdgeCode(ModuleInfo *module, size_t edge_address1, size_t edge_address2);

  ModuleCovData *GetDataByRemoteAddress(size_t address);
  void HandleBufferWriteException(ModuleCovData *data);

  void ClearCoverage(ModuleCovData *data);
  void ClearRemoteBuffer(ModuleCovData *data);

  void CollectCoverage(ModuleCovData *data);
  void CollectCoverage();

  uint64_t GetCmpCode(size_t bb_offset, size_t cmp_offset, int bits_match);
  bool IsCmpCoverageCode(uint64_t code);
  void ClearCmpCoverageInstrumentation(ModuleInfo *module, uint64_t coverage_code);
  void CollectCmpCoverage(ModuleCovData *data, size_t buffer_offset, char buffer_value);
  bool ShouldInstrumentSub(ModuleInfo *module,
                           Instruction& cmp_instr,
                           size_t instruction_address);
private:
  CovType coverage_type;
  bool compare_coverage;
  size_t skip_cov_instruction_br_off;
};

#endif // LITECOV_H

```

`macOS/README.md`:

```md
# TinyInst on macOS

```
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

## Limitations on macOS

* TinyInst may not always detect the exact time of target process exit. As a consequence the `OnProcessExit()` callback might have a maximum delay of 100ms. In the future, additional APIs (e.g. kqueue) could be used to detect process exit accurately.
* TinyInst on macOS is affected by the same custom exceptions-handling issues as the Windows version. For the description of the issue and workarounds, see [this section in the readme](https://github.com/googleprojectzero/TinyInst#return-address-patching)
* TinyInst leverages read-only pages to redirect the instruction pointer to the
instrumented code if the original, uninstrumented, code is invoked. On macOS running on ARM chips, the code
section of the modules inside the Dyld cache is aligned to 4k pages, however, ARM uses 16k pages. This makes it more difficult to instrument
individual modules inside the Dyld cache. TinyInst currently solves ths by instrumenting adjacent modules automatically until their code section
aligns to 16k to ensure that not only parts of a module is instrumented. This
behavior is controlled by the `-page_extend_modules` flag which is set to
`true` by default on M1. In some cases it might be possible to turn off this flag resulting in better performance.

## TinyInst and Guard Malloc

On macOS, [Guard Malloc](https://developer.apple.com/library/archive/documentation/Performance/Conceptual/ManagingMemory/Articles/MallocDebug.html) is a special version of the malloc library that makes it easier to catch certain types of memory safety issues. To enable Guard Malloc for a target process running under TinyInst, use the following flag:

```
-target_env DYLD_INSERT_LIBRARIES=/usr/lib/libgmalloc.dylib
```

However, on some targets, additional workarounds might be needed.

An issue was observed with some targets, where the combination of TinyInst and Guard Malloc put a process in a state where calls to (mach_)vm_allocate would fail, even though there was still sufficient free memory in the system and the target process address space (possibly due to an issue in macOS itself). This caused libgmalloc to be stuck in an infinite loop the first time it tried to allocate memory after a module was instrumented. The workaround for this is to have the modules loaded and instrumented before libgmalloc is loaded. This can be accomplished by the following flags:

```
-target_env DYLD_INSERT_LIBRARIES=/path/to/instrumented/module.dylib:/usr/lib/libgmalloc.dylib -instrument_modules_on_load
```

The first part ensures that the instrumented module will be loaded before libgmalloc (the order of libraries in `DYLD_INSERT_LIBRARIES` is important). The `-instrument_modules_on_load` flag ensures that modules will be instrumented as soon as they are loaded (and not when the process entypoint or the target method is reached, as is normally the case in TinyInst.

Additionally, especially if you enconter errors related to stack unwinding, the `-patch_return_addresses` flag might be needed.

```

`macOS/debugger.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include <cstdio>
#include <cstdlib>
#include <string>
#include <thread>
#include <algorithm>

#include <mach/mach.h>
#include <mach/mach_vm.h>

#include <mach-o/dyld.h>
#include <mach-o/dyld_images.h>
#include <mach-o/nlist.h>

#include <dlfcn.h>

#include <spawn.h>
#include <sys/types.h>
#include <sys/ptrace.h>
#include <signal.h>

#include "macOS/debugger.h"
#include "common.h"

#define BREAKPOINT_UNKNOWN 0x0
#define BREAKPOINT_ENTRYPOINT 0x01
#define BREAKPOINT_TARGET 0x02
#define BREAKPOINT_NOTIFICATION 0x04
#define BREAKPOINT_TARGET_END 0x08

#define PERSIST_END_EXCEPTION 0x0F22

#ifndef _POSIX_SPAWN_DISABLE_ASLR
  #define _POSIX_SPAWN_DISABLE_ASLR 0x0100
#endif

extern char **environ;

std::unordered_map<task_t, class Debugger*> Debugger::task_to_debugger_map;
std::mutex Debugger::map_mutex;

vm_prot_t Debugger::MacOSProtectionFlags(MemoryProtection memory_protection) {
  switch (memory_protection) {
    case READONLY:
      return VM_PROT_READ;

    case READWRITE:
      return VM_PROT_READ | VM_PROT_WRITE;

    case READEXECUTE:
      return VM_PROT_READ | VM_PROT_EXECUTE;

    case READWRITEEXECUTE:
      return VM_PROT_ALL;

    default:
      FATAL("Unimplemented memory protection");
  }
}

void Debugger::ClearSharedMemory() {
  for (auto iter = shared_memory.begin(); iter != shared_memory.end(); ) {
    iter = FreeSharedMemory(iter);
  }

  shared_memory.clear();
}

std::list<SharedMemory>::iterator Debugger::FreeSharedMemory(std::list<SharedMemory>::iterator it) {
  if (it->size == 0) {
    WARN("FreeShare is called with size == 0\n");
    return ++it;
  }

  kern_return_t krt = mach_port_destroy(mach_task_self(), it->port);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) destroy port for local shared memory @ 0x%llx\n", mach_error_string(krt), it->local_address);
  }

  krt = mach_vm_deallocate(mach_task_self(), it->local_address, it->size);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) freeing memory @ 0x%llx\n", mach_error_string(krt), it->remote_address);
  }

  return shared_memory.erase(it);
}

void Debugger::RemoteFree(void *address, size_t size) {
  for (auto iter = shared_memory.begin(); iter != shared_memory.end(); iter++) {
    if (iter->remote_address == (mach_vm_address_t)address) {
      FreeSharedMemory(iter);
      break;
    }
  }
  mach_target->FreeMemory((uint64_t)address, size);
}

void Debugger::RemoteRead(void *address, void *buffer, size_t size) {
  mach_vm_address_t shared_memory_address = 0;
  for (auto iter = shared_memory.begin(); iter != shared_memory.end(); ++iter) {
    if (((mach_vm_address_t)address >= iter->remote_address)  &&
        (((mach_vm_address_t)address + size) <= (iter->remote_address + iter->size)))
    {
      shared_memory_address = iter->local_address + ((mach_vm_address_t)address - iter->remote_address);
      break;
    }
  }

  if (shared_memory_address) {
    memcpy(buffer, (void *)shared_memory_address, size);
  } else {
    mach_target->ReadMemory((uint64_t)address, size, buffer);
  }
}

void Debugger::RemoteWrite(void *address, const void *buffer, size_t size) {
  mach_target->WriteMemory((uint64_t)address, buffer, size);
}

void Debugger::RemoteProtect(void *address, size_t size, MemoryProtection protect) {
  RemoteProtect(address, size, MacOSProtectionFlags(protect));
}

void Debugger::RemoteProtect(void *address, size_t size, vm_prot_t protect) {
  mach_target->ProtectMemory((uint64_t)address, size, protect);
}

void Debugger::CreateException(MachException *mach_exception, Exception *exception) {
  exception->ip = (void*)GetRegister(ARCH_PC);

  switch (mach_exception->exception_type) {
    case EXC_BREAKPOINT:
      exception->type = BREAKPOINT;
#ifdef ARM64
      SetRegister(ARCH_PC, GetRegister(ARCH_PC) + 4);
      exception->ip = (void*)((uint64_t)exception->ip);
#else
      exception->ip = (void*)((uint64_t)exception->ip - 1);
#endif
      break;

    case EXC_BAD_ACCESS:
      exception->type = ACCESS_VIOLATION;
      break;

    case EXC_BAD_INSTRUCTION:
      exception->type = ILLEGAL_INSTRUCTION;
      break;

    default:
      exception->type = OTHER;
      break;
  }

  exception->maybe_execute_violation = false;
  exception->maybe_write_violation = false;
  exception->access_address = 0;

  if (mach_exception->exception_type == EXC_BAD_ACCESS) {
    if (mach_exception->code[0] == KERN_PROTECTION_FAILURE) {
      exception->maybe_write_violation = true;
      exception->maybe_execute_violation = true;
    }

    exception->access_address = (void*)mach_exception->code[1];
  }
}

uint64_t* Debugger::GetPointerToRegister(Register r) {
  ARCH_THREAD_STATE_T *state = (ARCH_THREAD_STATE_T*)(mach_exception->new_state);
#ifdef ARM64
  switch(r) {
    case X0:
    case X1:
    case X2:
    case X3:
    case X4:
    case X5:
    case X6:
    case X7:
    case X8:
    case X9:
    case X10:
    case X11:
    case X12:
    case X13:
    case X14:
    case X15:
    case X16:
    case X17:
    case X18:
    case X19:
    case X20:
    case X21:
    case X22:
    case X23:
    case X24:
    case X25:
    case X26:
    case X27:
    case X28:
    case X29:
      return &state->__x[r];
    case PC:
      return &state->__pc;
    case CPSR:
      return (uint64_t*)&state->__cpsr;
    case LR:
      return &state->__lr;
    case SP:
      return &state->__sp;

    default:
      FATAL("Unimplemented register");
    }
#else
  switch (r) {
    case RAX:
      return &state->__rax;
    case RCX:
      return &state->__rcx;
    case RDX:
      return &state->__rdx;
    case RBX:
      return &state->__rbx;
    case RSP:
      return &state->__rsp;
    case RBP:
      return &state->__rbp;
    case RSI:
      return &state->__rsi;
    case RDI:
      return &state->__rdi;
    case R8:
      return &state->__r8;
    case R9:
      return &state->__r9;
    case R10:
      return &state->__r10;
    case R11:
      return &state->__r11;
    case R12:
      return &state->__r12;
    case R13:
      return &state->__r13;
    case R14:
      return &state->__r14;
    case R15:
      return &state->__r15;
    case RIP:
      return &state->__rip;

    default:
      FATAL("Unimplemented register");
  }
#endif
}

size_t Debugger::GetRegister(Register r) {
#ifdef ARM64
  if (r == CPSR) {
    uint32_t *reg_pointer = (uint32_t *)GetPointerToRegister(r);
    return *reg_pointer;
  }
#endif
  uint64_t *reg_pointer = GetPointerToRegister(r);
  return *reg_pointer;
}

void Debugger::SetRegister(Register r, size_t value) {
#ifdef ARM64
  if (r == CPSR) {
    if(value & 0xFFFFFFFF00000000) FATAL("32 bit value required");
    uint32_t *reg_pointer = (uint32_t *)GetPointerToRegister(r);
    *reg_pointer = (uint32_t)(value & 0xFFFFFFFF);
  }
#endif
  uint64_t *reg_pointer = GetPointerToRegister(r);
  *reg_pointer = value;
}

#ifdef ARM64
Register Debugger::ArgumentToRegister(int arg) {
  switch (arg) {
    case 0:
      return X0;

    case 1:
      return X1;

    case 2:
      return X2;

    case 3:
      return X3;

    case 4:
      return X4;

    case 5:
      return X5;

    case 6:
      return X6;

    case 7:
      return X7;

    default:
      FATAL("Argument %d not valid\n", arg);
      break;
  }
}
#else
Register Debugger::ArgumentToRegister(int arg) {
  switch (arg) {
    case 0:
      return RDI;

    case 1:
      return RSI;

    case 2:
      return RDX;

    case 3:
      return RCX;

    case 4:
      return R8;

    case 5:
      return R9;

    default:
      FATAL("Argument %d not valid\n", arg);
      break;
  }
}
#endif

void Debugger::SetReturnAddress(size_t value) {
#ifdef ARM64 
  SetRegister(LR, value);
#else
  RemoteWrite((void*)GetRegister(RSP), &value, child_ptr_size);
#endif
}
size_t Debugger::GetReturnAddress() {
#ifdef ARM64 
  return GetRegister(LR);
#else
  void *ra;
  RemoteRead((void*)GetRegister(RSP), &ra, child_ptr_size);
  return (size_t)ra;
#endif
}

void Debugger::GetMachHeader(void *mach_header_address, mach_header_64 *mach_header) {
  RemoteRead(mach_header_address, (void*)mach_header, sizeof(mach_header_64));
}

void Debugger::GetLoadCommandsBuffer(void *mach_header_address,
                                     const mach_header_64 *mach_header,
                                     void **load_commands) {
  *load_commands = (void*)malloc(mach_header->sizeofcmds);
  RemoteRead((void*)((uint64_t)mach_header_address + sizeof(mach_header_64)),
             *load_commands,
             mach_header->sizeofcmds);
}

template <class TCMD>
bool Debugger::GetLoadCommand(mach_header_64 mach_header,
                              void *load_commands_buffer,
                              uint32_t load_cmd_type,
                              const char *segname,
                              TCMD **ret_command) {
  uint64_t load_cmd_addr = (uint64_t)load_commands_buffer;
  for (uint32_t i = 0; i < mach_header.ncmds; ++i) {
    load_command *load_cmd = (load_command *)load_cmd_addr;
    if (load_cmd->cmd == load_cmd_type) {
      TCMD *t_cmd = (TCMD*)load_cmd;
      if (load_cmd_type != LC_SEGMENT_64
          || !strcmp(((segment_command_64*)t_cmd)->segname, segname)) {
        *ret_command = (TCMD*)load_cmd;
        return true;
      }
    }

    load_cmd_addr += load_cmd->cmdsize;
  }

  return false;
}


bool Debugger::GetSectionAndSlide(void *mach_header_address,
                                 const char *segname,
                                 const char *sectname,
                                 section_64 *ret_section,
                                 size_t *file_vm_slide) {
  mach_header_64 mach_header;
  GetMachHeader(mach_header_address, &mach_header);

  void *load_commands_buffer = NULL;
  GetLoadCommandsBuffer(mach_header_address, &mach_header, &load_commands_buffer);

  segment_command_64 *text_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__TEXT", &text_cmd)) {
    FATAL("Unable to find __TEXT command in GetSectionAndSlide\n");
  }
  *file_vm_slide = (size_t)mach_header_address - text_cmd->vmaddr;

  segment_command_64 *seg_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, segname, &seg_cmd)) {
    return false;
  }

  bool found_section = false;
  size_t section_addr = (size_t)seg_cmd + sizeof(segment_command_64);
  for (uint32_t i = 0; i < seg_cmd->nsects && !found_section; ++i) {
    section_64 *section = (section_64*)section_addr;
    if (!strcmp(section->sectname, sectname)) {
      *ret_section = *section;
      found_section = true;
    }

    section_addr += sizeof(section_64);
  }

  free(load_commands_buffer);
  return found_section;
}

void *Debugger::MakeSharedMemory(mach_vm_address_t address, size_t size, MemoryProtection protection) {
  mach_port_t shm_port;
  if (address == 0)
    return NULL;

  memory_object_size_t memoryObjectSize = round_page(size);
  vm_prot_t prot_flags = MacOSProtectionFlags(protection);
  kern_return_t ret = mach_make_memory_entry_64(mach_target->Task(), &memoryObjectSize, address, prot_flags, &shm_port, MACH_PORT_NULL);
  if (ret != KERN_SUCCESS) {
    FATAL("Error (%s) remote allocate share memory\n", mach_error_string(ret));
  }

  mach_vm_address_t map_address = 0;
  ret = mach_vm_map(mach_task_self(), &map_address, memoryObjectSize, 0, VM_FLAGS_ANYWHERE, shm_port, 0, 0, prot_flags, prot_flags, VM_INHERIT_NONE);
  if (ret != KERN_SUCCESS) {
    FATAL("Error (%s) map memory\n", mach_error_string(ret));
  }

  SharedMemory sm(map_address, address, size, shm_port);
  shared_memory.push_back(sm);

  return (void *)map_address;
}

void *Debugger::RemoteAllocateNear(uint64_t region_min,
				    uint64_t region_max,
				    size_t size,
				    MemoryProtection protection,
				    bool use_shared_memory) {
  uint64_t min_address, max_address;

  //try after first
  min_address = region_max;
  max_address = (UINT64_MAX - region_min < 0x80000000) ? UINT64_MAX : region_min + 0x80000000;
  void *ret_address = RemoteAllocateAfter(min_address, max_address, size, protection);
  if (ret_address != NULL) {
    if (use_shared_memory)
      MakeSharedMemory((mach_vm_address_t)ret_address, size, protection);
    return ret_address;
  }

  //try before second
  min_address = (region_max < 0x80000000) ? 0 : region_max - 0x80000000;
  max_address = (region_min < size) ? 0 : region_min - size;
  ret_address = RemoteAllocateBefore(min_address, max_address, size, protection);
  if (ret_address != NULL) {
    if (use_shared_memory)
      MakeSharedMemory((mach_vm_address_t)ret_address, size, protection);
    return ret_address;
  }

  // if all else fails, try within
  ret_address = RemoteAllocateAfter(region_min, region_max, size, protection);
  if (use_shared_memory)
    MakeSharedMemory((mach_vm_address_t)ret_address, size, protection);
  return ret_address;
}

void *Debugger::RemoteAllocate(size_t size,
                               MemoryProtection protection,
                               bool use_shared_memory) {
  mach_vm_address_t alloc_address = 0;
  vm_prot_t protection_flags = MacOSProtectionFlags(protection);

  kern_return_t krt = mach_vm_allocate(mach_target->Task(),
                                       (mach_vm_address_t*)&alloc_address,
                                       size,
                                       VM_FLAGS_ANYWHERE);

  if (krt != KERN_SUCCESS) {
    FATAL("Unable to allocate memory, size 0x%lx\n", size);
  }
  RemoteProtect((void *)alloc_address, size, protection_flags);

  if (use_shared_memory) {
    MakeSharedMemory(alloc_address, size, protection);
  }

  return (void *)alloc_address;
}

void *Debugger::RemoteAllocateBefore(uint64_t min_address,
                                          uint64_t max_address,
                                          size_t size,
                                          MemoryProtection protection) {
  vm_prot_t protection_flags = MacOSProtectionFlags(protection);

  mach_vm_address_t cur_address = max_address;
  while (cur_address > min_address) {
    size_t step = size;

    mach_vm_address_t region_address = cur_address;
    mach_vm_size_t region_size = 0;
    vm_region_submap_info_data_64_t info;
    mach_target->GetRegionSubmapInfo(&region_address, &region_size, &info);

    if (region_address <= cur_address) { /* cur_address references allocated memory */
      cur_address = region_address;
    } else { /* cur_address references unallocated memory */
      uint64_t free_region_size = region_address - cur_address;
      if (free_region_size >= size) {
        void *ret_address = (void*)(cur_address + (free_region_size - size));
        kern_return_t krt = RemoteAllocateAt(ret_address, size);

        if (krt == KERN_SUCCESS) {
          if (!(min_address <= (uint64_t)ret_address && (uint64_t)ret_address <= max_address)) {
            return NULL;
          }

          RemoteProtect(ret_address, size, protection_flags);
          return ret_address;
        }
      } else {
        step = size - free_region_size;
      }
    }

    if (cur_address < step) break;
    cur_address -= step;
  }

  return NULL;
}

void *Debugger::RemoteAllocateAfter(uint64_t min_address,
                                         uint64_t max_address,
                                         size_t size,
                                         MemoryProtection protection) {
  vm_prot_t protection_flags = MacOSProtectionFlags(protection);

  mach_vm_address_t cur_address = min_address;
  while (cur_address < max_address) {
    mach_vm_address_t region_address = cur_address;
    mach_vm_size_t region_size = 0;
    vm_region_submap_info_data_64_t info;
    mach_target->GetRegionSubmapInfo(&region_address, &region_size, &info);

    if (region_address <= cur_address) { /* cur_address references allocated memory */
      cur_address = region_address + region_size;
      continue;
    }

    /* cur_address references unallocated memory */
    if (region_address > max_address) {
      region_address = max_address;
    }

    uint64_t free_region_size = region_address - cur_address;
    if (free_region_size >= size) {
      void *ret_address = (void*)cur_address;
      kern_return_t krt = RemoteAllocateAt(ret_address, size);

      if (krt == KERN_SUCCESS) {
        if (!(min_address <= (uint64_t)ret_address && (uint64_t)ret_address <= max_address)) {
          return NULL;
        }

        RemoteProtect(ret_address, size, protection_flags);
        return ret_address;
      }
    }

    cur_address = region_address;
  }

  return NULL;
}

void *Debugger::RemoteAllocate(size_t size) {
  kern_return_t krt;
  void *alloc_address = 0;
  krt = mach_vm_allocate(mach_target->Task(),
                        (mach_vm_address_t*)&alloc_address,
                        size,
                        VM_FLAGS_ANYWHERE);
  
  if (krt != KERN_SUCCESS) {
    return NULL;
  }

  return alloc_address;
}

kern_return_t Debugger::RemoteAllocateAt(void *ret_address, int size) {
  kern_return_t krt;
  bool retried = false;

retry_label:
  void *alloc_address = ret_address;
  krt = mach_vm_allocate(mach_target->Task(),
                        (mach_vm_address_t*)&alloc_address,
                        size,
                        VM_FLAGS_FIXED);

  if (krt == KERN_NO_SPACE && !retried) {
    krt = mach_vm_deallocate(mach_target->Task(),
                             (mach_vm_address_t)ret_address,
                             size);
    if (krt != KERN_SUCCESS) {
      FATAL("Unable to deallocate memory region starting @ %p, size 0x%x\n",
            ret_address, size);
    }

    retried = true;
    goto retry_label;
  }

  return krt;
}

void Debugger::DeleteBreakpoints() {
  for (auto iter = breakpoints.begin(); iter != breakpoints.end(); iter++) {
    delete *iter;
  }
  breakpoints.clear();
}


void Debugger::AddBreakpoint(void *address, int type) {
  for (auto it = breakpoints.rbegin(); it != breakpoints.rend(); ++it) {
    if ((*it)->address == address) {
      (*it)->type |= type;
      if (((*it)->type & BREAKPOINT_NOTIFICATION) && ((*it)->type & BREAKPOINT_TARGET)) {
        FATAL("Target method must not be the same as _dyld_debugger_notification");
      }

      return;
    }
  }

  Breakpoint *new_breakpoint = new Breakpoint;
#ifdef ARM64
  uint32_t breakpoint_bytes = 0xd4200020;
#else
  unsigned char breakpoint_bytes = 0xcc;
#endif
  RemoteRead(address, &(new_breakpoint->original_opcode), sizeof(new_breakpoint->original_opcode));
  RemoteWrite(address, (void*)&breakpoint_bytes, sizeof(breakpoint_bytes));

  new_breakpoint->address = address;
  new_breakpoint->type = type;
  breakpoints.push_back(new_breakpoint);
}


void Debugger::HandleTargetReachedInternal() {
  saved_sp = (void*)GetRegister(ARCH_SP);
  saved_return_address = (void*)GetReturnAddress();

  if (loop_mode) {
    for (int arg_index = 0; arg_index < MAX_NUM_REG_ARGS && arg_index < target_num_args; ++arg_index) {
      saved_args[arg_index] = (void*)GetRegister(ArgumentToRegister(arg_index));
    }

    if (target_num_args > MAX_NUM_REG_ARGS) {
      RemoteRead((void*)((uint64_t)saved_sp + child_ptr_size),
                 saved_args + MAX_NUM_REG_ARGS,
                 child_ptr_size * (target_num_args - MAX_NUM_REG_ARGS));
    }
  }

  if (!target_reached) {
    target_reached = true;
    OnTargetMethodReached();
  }

  if (target_end_detection == RETADDR_STACK_OVERWRITE) {
    size_t return_address = PERSIST_END_EXCEPTION;
    RemoteWrite(saved_sp, &return_address, child_ptr_size);
  } else if (target_end_detection == RETADDR_BREAKPOINT) {
    AddBreakpoint((void*)GetTranslatedAddress((size_t)saved_return_address), BREAKPOINT_TARGET_END);
  }
}


void Debugger::HandleTargetEnded() {
  target_return_value = (uint64_t)GetRegister(ARCH_RETURN_VALUE_REGISTER);

  if (loop_mode) {
    SetRegister(ARCH_PC, (size_t)target_address);
    SetRegister(ARCH_SP, (size_t)saved_sp);

    if (target_end_detection == RETADDR_STACK_OVERWRITE) {
      size_t return_address = PERSIST_END_EXCEPTION;
      SetReturnAddress(return_address);
    } else if (target_end_detection == RETADDR_BREAKPOINT) {
      SetReturnAddress((size_t)saved_return_address);
      AddBreakpoint((void*)GetTranslatedAddress((size_t)saved_return_address), BREAKPOINT_TARGET_END);
    }

    for (int arg_index = 0; arg_index < MAX_NUM_REG_ARGS && arg_index < target_num_args; ++arg_index) {
      SetRegister(ArgumentToRegister(arg_index), (size_t)saved_args[arg_index]);
    }

    if (target_num_args > MAX_NUM_REG_ARGS) {
      RemoteWrite((void*)((uint64_t)saved_sp + child_ptr_size),
                  saved_args + MAX_NUM_REG_ARGS,
                  child_ptr_size * (target_num_args - MAX_NUM_REG_ARGS));
    }
  } else {
    SetRegister(ARCH_PC, (size_t)saved_return_address);
    AddBreakpoint((void*)GetTranslatedAddress((size_t)target_address), BREAKPOINT_TARGET);
  }
}

void Debugger::OnEntrypoint() {
  child_entrypoint_reached = true;
  if (trace_debug_events) {
    SAY("Debugger: Process entrypoint reached\n");
  }
}


void Debugger::ExtractCodeRanges(void *base_address,
                                 size_t min_address,
                                 size_t max_address,
                                 std::list<AddressRange> *executable_ranges,
                                 size_t *code_size) {
  mach_header_64 mach_header;
  GetMachHeader(base_address, &mach_header);

  void *load_commands_buffer = NULL;
  GetLoadCommandsBuffer(base_address, &mach_header, &load_commands_buffer);

  segment_command_64 *text_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__TEXT", &text_cmd)) {
    FATAL("Unable to find __TEXT command in ExtractCodeRanges\n");
  }
  uint64_t file_vm_slide = (uint64_t)base_address - text_cmd->vmaddr;

  *code_size = 0;
  for (auto &it: *executable_ranges) {
    free(it.data);
  }
  executable_ranges->clear();

  uint64_t load_cmd_addr = (uint64_t)load_commands_buffer;
  for (uint32_t i = 0; i < mach_header.ncmds; ++i) {
    load_command *load_cmd = (load_command *)load_cmd_addr;
    if (load_cmd->cmd == LC_SEGMENT_64) {
      segment_command_64 *segment_cmd = (segment_command_64*)load_cmd;

      if (!strcmp(segment_cmd->segname, "__PAGEZERO")
          || !strcmp(segment_cmd->segname, "__LINKEDIT")) {
        load_cmd_addr += load_cmd->cmdsize;
        continue;
      }

#ifdef ARM64
      if (strcmp(segment_cmd->segname, "__TEXT") == 0) {
        mach_vm_address_t segment_start_addr = (mach_vm_address_t)segment_cmd->vmaddr + file_vm_slide;
        mach_vm_address_t segment_end_addr = (mach_vm_address_t)segment_cmd->vmaddr + file_vm_slide + segment_cmd->vmsize;
        AddressRange arm_ar;
        arm_ar.from = segment_start_addr;
        arm_ar.to = segment_end_addr;
        size_t range_size = arm_ar.to - arm_ar.from;
        arm_ar.data = (char *)malloc(range_size);
        RemoteRead((void*)arm_ar.from, arm_ar.data, range_size);

        ExtractSegmentCodeRanges(segment_start_addr, segment_end_addr, executable_ranges, code_size);
        for(const auto& er: *executable_ranges) { 
          free(er.data);
        }
        executable_ranges->clear();
        executable_ranges->push_back(arm_ar);
        *code_size = range_size;
        break;
      }
#else
      mach_vm_address_t segment_start_addr = (mach_vm_address_t)segment_cmd->vmaddr + file_vm_slide;
      mach_vm_address_t segment_end_addr = (mach_vm_address_t)segment_cmd->vmaddr + file_vm_slide + segment_cmd->vmsize;

      ExtractSegmentCodeRanges(segment_start_addr, segment_end_addr, executable_ranges, code_size);
#endif
    }

    load_cmd_addr += load_cmd->cmdsize;
  }

  free(load_commands_buffer);
}

void Debugger::ExtractSegmentCodeRanges(mach_vm_address_t segment_start_addr,
                                        mach_vm_address_t segment_end_addr,
                                        std::list<AddressRange> *executable_ranges,
                                        size_t *code_size) {
  mach_vm_address_t cur_address = segment_start_addr;
  while (cur_address < segment_end_addr) {
    mach_vm_size_t region_size = 0;
    vm_region_submap_info_data_64_t info;
    mach_target->GetRegionSubmapInfo(&cur_address, &region_size, &info);
    if (segment_end_addr <= cur_address) {
      break;
    }

    AddressRange new_range;
    new_range.from = cur_address;
    new_range.to = cur_address + region_size;
    if (new_range.from < segment_start_addr) {
      new_range.from = segment_start_addr;
    }
    if (segment_end_addr < new_range.to) {
      new_range.to = segment_end_addr;
    }

    if (info.protection & VM_PROT_EXECUTE) {
      int retried = false;

      size_t range_size = new_range.to - new_range.from;
      new_range.data = (char *)malloc(range_size);
      RemoteRead((void*)new_range.from, new_range.data, range_size);

    retry_label:
      RemoteProtect((void*)new_range.from, range_size, info.protection ^ VM_PROT_EXECUTE);
      mach_vm_address_t region_addr = new_range.from;
      mach_vm_size_t region_sz = range_size;
      vm_region_submap_info_data_64_t region_info;
      mach_target->GetRegionSubmapInfo(&region_addr, (mach_vm_size_t*)&region_sz, &region_info);
      if (region_info.protection & VM_PROT_EXECUTE) {
        if (retried) {
          FATAL("Failed to mark the original code NON-EXECUTABLE\n");
        }

        kern_return_t krt;
        krt = mach_vm_deallocate(mach_target->Task(),
                                 (mach_vm_address_t)new_range.from,
                                 range_size);

        if (krt == KERN_SUCCESS) {
          mach_vm_address_t alloc_address = new_range.from;
          krt = mach_vm_allocate(mach_target->Task(),
                                 (mach_vm_address_t*)&alloc_address,
                                 range_size,
                                 VM_FLAGS_FIXED);

          if (krt == KERN_SUCCESS && alloc_address && new_range.from) {
            RemoteWrite((void*)new_range.from, new_range.data, range_size);
          } else {
            FATAL("Unable to re-allocate memory after deallocate in ExtractSegmentCodeRanges\n");
          }
        }

        retried = true;
        goto retry_label;
      }

      AddressRange *last_range = NULL;
      if(!executable_ranges->empty()) {
        last_range = &executable_ranges->back();
      }
      if(last_range && (last_range->to == new_range.from)) {
        // merge ranges instead of creating new one
        size_t last_range_size = last_range->to - last_range->from;
        size_t merged_size = last_range_size + range_size;
        last_range->data = (char *)realloc(last_range->data, merged_size);
        memcpy(last_range->data + last_range_size, new_range.data, range_size);
        last_range->to = new_range.to;
        free(new_range.data);
      } else {
        executable_ranges->push_back(new_range);
      }
      *code_size += range_size;
    }

    cur_address += region_size;
  }
}


void Debugger::ProtectCodeRanges(std::list<AddressRange> *executable_ranges) {
  WARN("persist_instrumentation_data functionality was not tested on macOS."
       "ProtectCodeRanges might fail");

  for (auto &range: *executable_ranges) {
    mach_vm_address_t region_address = range.from;
    mach_vm_size_t region_size = 0;
    vm_region_submap_info_data_64_t info;
    mach_target->GetRegionSubmapInfo(&region_address, &region_size, &info);

    if (region_address != range.from
        || region_address + region_size != range.to
        || !(info.protection & VM_PROT_EXECUTE)) {
      FATAL("Error in ProtectCodeRanges. Target incompatible with persist_instrumentation_data");
    }

    RemoteProtect((void*)region_address, region_size, info.protection ^ VM_PROT_EXECUTE);
  }
}

void Debugger::PatchPointersRemote(void *base_address, std::unordered_map<size_t, size_t>& search_replace) {
  mach_header_64 mach_header;
  GetMachHeader(base_address, &mach_header);

  void *load_commands_buffer = NULL;
  GetLoadCommandsBuffer(base_address, &mach_header, &load_commands_buffer);

  segment_command_64 *text_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__TEXT", &text_cmd)) {
    FATAL("Unable to find __TEXT command in ExtractCodeRanges\n");
  }
  uint64_t file_vm_slide = (uint64_t)base_address - text_cmd->vmaddr;

  uint64_t load_cmd_addr = (uint64_t)load_commands_buffer;
  for (uint32_t i = 0; i < mach_header.ncmds; ++i) {
    load_command *load_cmd = (load_command *)load_cmd_addr;
    if (load_cmd->cmd == LC_SEGMENT_64) {
      segment_command_64 *segment_cmd = (segment_command_64*)load_cmd;

      if (!strcmp(segment_cmd->segname, "__PAGEZERO")
          || !strcmp(segment_cmd->segname, "__LINKEDIT")) {
        load_cmd_addr += load_cmd->cmdsize;
        continue;
      }

      mach_vm_address_t segment_start_addr = (mach_vm_address_t)segment_cmd->vmaddr + file_vm_slide;
      mach_vm_address_t segment_end_addr = (mach_vm_address_t)segment_cmd->vmaddr + file_vm_slide + segment_cmd->vmsize;

      PatchPointersRemote(segment_start_addr, segment_end_addr, search_replace);
    }

    load_cmd_addr += load_cmd->cmdsize;
  }

  free(load_commands_buffer);
}

void Debugger::PatchPointersRemote(size_t min_address, size_t max_address, std::unordered_map<size_t, size_t>& search_replace) {
  size_t module_size = max_address - min_address;
  char* buf = (char *)malloc(module_size);
  RemoteRead((void *)min_address, buf, module_size);

  size_t remote_address = min_address;
  for (size_t i = 0; i < (module_size - child_ptr_size + 1); i++) {
    size_t ptr = *(size_t *)(buf + i);
    auto iter = search_replace.find(ptr);
    if (iter != search_replace.end()) {
      // printf("patching entry %zx at address %zx\n", (size_t)ptr, remote_address);
      size_t fixed_ptr = (size_t)iter->second;
      RemoteWrite((void *)remote_address, &fixed_ptr, child_ptr_size);
    }
    remote_address += 1;
  }

  free(buf);
}


void Debugger::GetImageSize(void *base_address, size_t *min_address, size_t *max_address) {
  mach_header_64 mach_header;
  GetMachHeader(base_address, &mach_header);

  void *load_commands_buffer = NULL;
  GetLoadCommandsBuffer(base_address, &mach_header, &load_commands_buffer);

  *min_address = SIZE_MAX;
  *max_address = 0;

  uint64_t load_cmd_addr = (uint64_t)load_commands_buffer;
  for (uint32_t i = 0; i < mach_header.ncmds; ++i) {
    load_command *load_cmd = (load_command *)load_cmd_addr;
    if (load_cmd->cmd == LC_SEGMENT_64) {
      segment_command_64 *segment_cmd = (segment_command_64*)load_cmd;

      if (!strcmp(segment_cmd->segname, "__PAGEZERO")
          || !strcmp(segment_cmd->segname, "__LINKEDIT")) {
        load_cmd_addr += load_cmd->cmdsize;
        continue;
      }

      if (segment_cmd->vmaddr < *min_address) {
        *min_address = segment_cmd->vmaddr;
      }

      if (segment_cmd->vmaddr + segment_cmd->vmsize > *max_address) {
        *max_address = segment_cmd->vmaddr + segment_cmd->vmsize;
      }
    }

    load_cmd_addr += load_cmd->cmdsize;
  }

  segment_command_64 *text_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__TEXT", &text_cmd)) {
    FATAL("Unable to find __TEXT command in GetImageSize\n");
  }

  uint64_t file_vm_slide = (uint64_t)base_address - text_cmd->vmaddr;
  *min_address += file_vm_slide;
  *max_address += file_vm_slide;

  free(load_commands_buffer);
}


void *Debugger::GetModuleEntrypoint(void *base_address) {
  mach_header_64 mach_header;
  GetMachHeader(base_address, &mach_header);
  if (mach_header.filetype != MH_EXECUTE) {
    return NULL;
  }

  void *load_commands_buffer = NULL;
  GetLoadCommandsBuffer(base_address, &mach_header, &load_commands_buffer);

  entry_point_command *entry_point_cmd = NULL;
  if (GetLoadCommand(mach_header, load_commands_buffer, LC_MAIN, NULL, &entry_point_cmd)) {
    uint64_t entryoff = entry_point_cmd->entryoff;

    free(load_commands_buffer);
    return (void*)((uint64_t)base_address + entryoff);
  }

  // no LC_MAIN command, probably an older binary.
  // Look up LC_UNIXTHREAD instead

  thread_command *tc;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_UNIXTHREAD, NULL, &tc)) {
    FATAL("Unable to find entry point in the executable module");
  }

  uint32_t flavor = *(uint32_t *)((char *)tc + 2 * sizeof(uint32_t));
  if(flavor != ARCH_THREAD_STATE) {
    FATAL("Unexpected thread state flavor");
  }
  ARCH_THREAD_STATE_T *state = (ARCH_THREAD_STATE_T *)((char *)tc + 4 * sizeof(uint32_t));

  segment_command_64 *text_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__TEXT", &text_cmd)) {
    FATAL("Unable to find __TEXT command in GetModuleEntrypoint\n");
  }
  uint64_t file_vm_slide = (uint64_t)base_address - text_cmd->vmaddr;

  free(load_commands_buffer);
#ifdef ARM64
  return (void*)(state->__pc + file_vm_slide);
#else
  return (void*)(state->__rip + file_vm_slide);
#endif
}

bool Debugger::IsDyld(void *base_address) {
  mach_header_64 mach_header;
  GetMachHeader(base_address, &mach_header);

  return (mach_header.filetype == MH_DYLINKER);
}


void *Debugger::GetSymbolAddress(void *base_address, char *symbol_name) {
  mach_header_64 mach_header;
  GetMachHeader(base_address, &mach_header);
  bool in_shared_cache = (mach_header.filetype == MH_DYLIB)
                         && (mach_header.flags & MH_DYLIB_IN_CACHE);

  void *load_commands_buffer = NULL;
  GetLoadCommandsBuffer(base_address, &mach_header, &load_commands_buffer);

  symtab_command *symtab_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SYMTAB, NULL, &symtab_cmd)) {
    FATAL("Unable to find SYMTAB command in GetSymbolAddress\n");
  }

  segment_command_64 *linkedit_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__LINKEDIT", &linkedit_cmd)) {
    FATAL("Unable to find __LINKEDIT command in GetSymbolAddress\n");
  }

  segment_command_64 *text_cmd = NULL;
  if (!GetLoadCommand(mach_header, load_commands_buffer, LC_SEGMENT_64, "__TEXT", &text_cmd)) {
    FATAL("Unable to find __TEXT command in GetSymbolAddress\n");
  }

  uint64_t file_vm_slide = (uint64_t)base_address - text_cmd->vmaddr;

  char *strtab = NULL;
  uint64_t strtab_addr = linkedit_cmd->vmaddr + file_vm_slide
                         + symtab_cmd->stroff - linkedit_cmd->fileoff;
  if(!in_shared_cache) {
    strtab = (char*)malloc(symtab_cmd->strsize);
    RemoteRead((void*)strtab_addr, strtab, symtab_cmd->strsize);
  }

  char *symtab = (char*)malloc(symtab_cmd->nsyms * sizeof(nlist_64));
  uint64_t symtab_addr = linkedit_cmd->vmaddr + file_vm_slide
                         + symtab_cmd->symoff - linkedit_cmd->fileoff;
  RemoteRead((void*)symtab_addr, symtab, symtab_cmd->nsyms * sizeof(nlist_64));

  void *symbol_address = NULL;

  size_t curr_symbol_address = (size_t)symtab;
  for (int i = 0; i < symtab_cmd->nsyms && !symbol_address; ++i) {
    nlist_64 curr_symbol = *(nlist_64*)curr_symbol_address;
    if ((curr_symbol.n_type & N_TYPE) == N_SECT) {
      char *curr_sym_name = NULL;
      std::string curr_sym_name_string;
      if (!in_shared_cache) {
        curr_sym_name = strtab + curr_symbol.n_un.n_strx;
      } else {
        mach_target->ReadCString(strtab_addr + curr_symbol.n_un.n_strx, curr_sym_name_string);
        curr_sym_name = (char*)curr_sym_name_string.c_str();
      }

      if (!strcmp(curr_sym_name, symbol_name)) {
        symbol_address = (void*)((uint64_t)base_address - text_cmd->vmaddr + curr_symbol.n_value);
        break;
      }
    }

    curr_symbol_address += sizeof(nlist_64);
  }

  free(strtab);
  free(symtab);
  free(load_commands_buffer);
  return symbol_address;
}

void *Debugger::GetTargetAddress(void *base_address) {
  if (!target_offset) {
    void *method_address = GetSymbolAddress(base_address, target_method);
    if (method_address == NULL) {
      FATAL("Unable to find address of target method\n");
    }

    target_offset = (uint64_t)method_address - (uint64_t)base_address;
  }

  return (void*)((uint64_t)base_address + target_offset);
}

void Debugger::OnModuleLoaded(void *module, char *module_name) {
  if (trace_debug_events) {
    SAY("Debugger: Loaded module %s at %p\n", module_name, module);
  }

  if (!attach_mode) {
    void *entrypoint = GetModuleEntrypoint(module);
    if (entrypoint) {
      AddBreakpoint(entrypoint, BREAKPOINT_ENTRYPOINT);
    }
  }

  if (IsDyld(module)) {
    m_dyld_debugger_notification = GetSymbolAddress(module, (char*)"__dyld_debugger_notification");
    AddBreakpoint(m_dyld_debugger_notification, BREAKPOINT_NOTIFICATION);

#ifdef ARM64
    // For arm we just mov pc, lr on BREAKPOINT_NOTIFICATION
#else
    // This save us the recurring TRAP FLAG breakpoint on BREAKPOINT_NOTIFICATION.
    unsigned char ret = 0xC3;
    RemoteWrite((void*)((uint64_t)m_dyld_debugger_notification+1), (void*)&ret, 1);
#endif
  }

  if (target_function_defined && !strcasecmp(module_name, target_module)) {
    target_address = GetTargetAddress(module);
    if (!target_address) {
      FATAL("Error determing target method address\n");
    }

    AddBreakpoint(target_address, BREAKPOINT_TARGET);
  }
}


void Debugger::OnDyldImageNotifier(size_t mode, unsigned long infoCount, uint64_t machHeaders[]) {
  uint64_t *image_info_array = new uint64_t[infoCount];
  size_t image_info_array_size = sizeof(uint64_t) * infoCount;
  RemoteRead(machHeaders, (void*)image_info_array, image_info_array_size);

  if (mode == 1) { /* dyld_image_removing */
    for (unsigned long i = 0; i < infoCount; ++i) {
      OnModuleUnloaded((void*)image_info_array[i]);
    }
  } else {
    dyld_all_image_infos all_image_infos = mach_target->GetAllImageInfos();
    dyld_image_info *all_image_info_array = new dyld_image_info[all_image_infos.infoArrayCount];
    size_t all_image_info_array_size = sizeof(dyld_image_info) * all_image_infos.infoArrayCount;
    RemoteRead((void*)all_image_infos.infoArray, (void*)all_image_info_array, all_image_info_array_size);

    char path[PATH_MAX];
    for (uint32_t i = 0; i < all_image_infos.infoArrayCount; ++i) {
      void *mach_header_addr = (void*)all_image_info_array[i].imageLoadAddress;
      if (mode == 2) { /* dyld_notify_remove_all */
        OnModuleUnloaded(mach_header_addr);
      } else if (std::find(image_info_array, image_info_array + infoCount, (uint64_t)mach_header_addr)
                 != image_info_array + infoCount) {
        /* dyld_image_adding */
        mach_target->ReadCString((uint64_t)all_image_info_array[i].imageFilePath, PATH_MAX, path);
        char *base_name = strrchr((char*)path, '/');
        base_name = (base_name) ? base_name + 1 : (char*)path;
        OnModuleLoaded(mach_header_addr, base_name);
      }
    }

    delete [] all_image_info_array;
  }

  delete [] image_info_array;
}

void Debugger::OnProcessCreated() {
  if (trace_debug_events) {
    SAY("Debugger: Process created or attached\n");
  }

  kern_return_t krt;
  dyld_process_info info = m_dyld_process_info_create(mach_target->Task(), 0, &krt);
  if (krt != KERN_SUCCESS) {
    FATAL("Unable to retrieve dyld_process_info_create information\n");
  }

  if (info) {
    m_dyld_process_info_for_each_image(
      info,
      ^(uint64_t mach_header_addr, const uuid_t uuid, const char *path) {
        if (attach_mode || IsDyld((void*)mach_header_addr)) {
          char *base_name = strrchr((char*)path, '/');
          base_name = (base_name) ? base_name + 1 : (char*)path;
          OnModuleLoaded((void*)mach_header_addr, (char*)base_name);
        }
      });

    m_dyld_process_info_release(info);
  }
}


int Debugger::HandleDebuggerBreakpoint() {
  int ret = BREAKPOINT_UNKNOWN;

  Breakpoint *breakpoint = NULL, *tmp_breakpoint;
  for (auto iter = breakpoints.begin(); iter != breakpoints.end(); iter++) {
    tmp_breakpoint = *iter;
    if (tmp_breakpoint->address == (void*)((uint64_t)last_exception.ip)) {
      breakpoint = tmp_breakpoint;
      if (breakpoint->type & BREAKPOINT_NOTIFICATION) {
        OnDyldImageNotifier(GetRegister(ArgumentToRegister(0)),
                            (unsigned long)GetRegister(ArgumentToRegister(1)),
                            (uint64_t*)GetRegister(ArgumentToRegister(2)));

        return BREAKPOINT_NOTIFICATION;
      }

      breakpoints.erase(iter);
      break;
    }
  }

  if (!breakpoint) {
    return ret;
  }

  RemoteWrite(breakpoint->address, &breakpoint->original_opcode, sizeof(breakpoint->original_opcode));
#ifdef ARM64
  SetRegister(ARCH_PC, GetRegister(ARCH_PC) - 4); // ARM
#else
  SetRegister(ARCH_PC, GetRegister(ARCH_PC) - 1); // INTEL
#endif

  if (breakpoint->type & BREAKPOINT_ENTRYPOINT) {
      OnEntrypoint();
  }

  if (breakpoint->type & BREAKPOINT_TARGET) {
      if (trace_debug_events) {
        SAY("Target method reached\n");
      }
      HandleTargetReachedInternal();
  }
  
  if (breakpoint->type & BREAKPOINT_TARGET_END) {
      if (trace_debug_events) {
        SAY("Target method ended\n");
      }
      HandleTargetEnded();
  }

  ret = breakpoint->type;
  free(breakpoint);

  return ret;
}

bool Debugger::IsTargetAlive() {
  return (mach_target != NULL && mach_target->IsTaskValid() && mach_target->IsExceptionPortValid());
}


void Debugger::HandleExceptionInternal(MachException *raised_mach_exception) {
  mach_exception = raised_mach_exception;
  CreateException(mach_exception, &last_exception);

  dbg_continue_status = KERN_SUCCESS;
  handle_exception_status = DEBUGGER_CONTINUE;

  if (mach_exception->exception_type == EXC_BREAKPOINT) {
    int breakpoint_type = HandleDebuggerBreakpoint();
    if (breakpoint_type & BREAKPOINT_TARGET) {
      handle_exception_status = DEBUGGER_TARGET_START;
    }
    if (breakpoint_type & BREAKPOINT_TARGET_END) {
      handle_exception_status = DEBUGGER_TARGET_END;
    }
#ifdef ARM64
    if (breakpoint_type & BREAKPOINT_NOTIFICATION) {
        SetRegister(ARCH_PC, GetRegister(LR));
        return;
    }
#endif

    if (breakpoint_type != BREAKPOINT_UNKNOWN) {
      return;
    }
  }

  if (OnException(&last_exception)) {
    return;
  }

  if (trace_debug_events) {
    SAY("Debugger: Mach exception (%d) @ address %p\n",
        mach_exception->exception_type, last_exception.ip);
  }

  switch(mach_exception->exception_type) {
    case EXC_SYSCALL:
      handle_exception_status = DEBUGGER_CONTINUE;
      dbg_continue_status = KERN_SUCCESS;
      break;
    case EXC_RESOURCE:
      handle_exception_status = DEBUGGER_HANGED;
      break;

    case EXC_BAD_ACCESS:
    bad_access_label:
      if (target_function_defined && last_exception.ip == (void*)PERSIST_END_EXCEPTION) {
        if (trace_debug_events) {
          SAY("Debugger: Persistence method ended\n");
        }

        HandleTargetEnded();
        handle_exception_status = DEBUGGER_TARGET_END;
      } else {
        dbg_continue_status = KERN_FAILURE;
        handle_exception_status = DEBUGGER_CRASHED;
      }
      break;

    case EXC_BAD_INSTRUCTION:
    case EXC_ARITHMETIC:
    case EXC_CRASH:
    case EXC_GUARD:
    crash_label:
      dbg_continue_status = KERN_FAILURE;
      handle_exception_status = DEBUGGER_CRASHED;
      break;

    case EXC_BREAKPOINT:
      dbg_continue_status = KERN_FAILURE;
      break;

    //Unix signals
    case EXC_SOFTWARE:
      if (mach_exception->code_cnt < 2 || mach_exception->code[0] != EXC_SOFT_SIGNAL) {
        goto default_label;
      }

      switch (mach_exception->code[1]) {
        case SIGSEGV:
        case SIGBUS:
          goto bad_access_label;

        case SIGILL:
        case SIGFPE:
        case SIGABRT:
        case SIGSYS:
        case SIGPIPE:
          goto crash_label;

        /* Handling the Unix soft signal produced by attaching via ptrace
          PT_ATTACHEXC suspends the process by using a SIGSTOP signal */
        case SIGSTOP:
          OnProcessCreated();

          mach_exception->code[1] = 0;
          ptrace(PT_THUPDATE,
                 mach_target->Pid(),
                (caddr_t)(uintptr_t)mach_exception->thread_port,
                (int)mach_exception->code[1]);

          break;

        case SIGCHLD:
          if (!IsTargetAlive()) {
            handle_exception_status = DEBUGGER_PROCESS_EXIT;
          }
          break;

        default:
          goto default_label;
      }

      break;

    default:
    default_label:
      if (trace_debug_events) {
        WARN("Debugger: Unhandled exception, mach exception_type %x at address %p\n",
             mach_exception->exception_type, last_exception.ip);
      }
      dbg_continue_status = KERN_FAILURE;
  }
}

void Debugger::SaveRegisters(SavedRegisters *registers) {
  if((*(mach_exception->new_state_cnt)) * sizeof(mach_exception->new_state[0]) > sizeof(ARCH_THREAD_STATE_T)) {
    FATAL("Unexpected thread state size");
  }
  
  registers->gpr_count = *(mach_exception->new_state_cnt);
  
  memcpy(&registers->gpr_registers,
         mach_exception->new_state,
         registers->gpr_count * sizeof(natural_t));

  registers->fpu_count = sizeof(ARCH_FPU_STATE_T) / sizeof(natural_t);
  kern_return_t ret = thread_get_state(mach_exception->thread_port,
                                       ARCH_FPU_STATE,
                                       (thread_state_t)&registers->fpu_registers,
                                       &registers->fpu_count);
  
  if(ret != KERN_SUCCESS) {
    FATAL("Error getting FPU registers %d", ret);
  }
}

void Debugger::RestoreRegisters(SavedRegisters *registers) {
  if(*mach_exception->new_state_cnt != registers->gpr_count) {
    FATAL("Unexpected thread state size");
  }

  memcpy(mach_exception->new_state,
         &registers->gpr_registers,
         registers->gpr_count * sizeof(natural_t));
  
  kern_return_t ret = thread_set_state(mach_exception->thread_port,
                                       ARCH_FPU_STATE,
                                       (thread_state_t)&registers->fpu_registers,
                                       registers->fpu_count);
  
  if(ret != KERN_SUCCESS) {
    FATAL("Error setting FPU registers");
  }

}

void Debugger::PrintContext() {
  thread_act_t *threads = NULL;
  mach_msg_type_number_t num_threads = 0;
  kern_return_t ret = task_threads(mach_target->Task(), &threads, &num_threads);
  if(ret != KERN_SUCCESS) return;
  for(unsigned i=0;i<num_threads;i++) {
    ARCH_THREAD_STATE_T state;
    unsigned int count = ARCH_THREAD_STATE_COUNT;
    ret = thread_get_state(threads[i], ARCH_THREAD_STATE, (thread_state_t)&state, &count);
    if(ret != KERN_SUCCESS) continue;
#ifdef ARM64
    printf("thread %d\n", i);
    printf("pc: %llx\n", state.__pc);
    printf(" x0: %16llx  x1: %16llx  x2: %16llx  x3: %16llx\n", state.__x[0], state.__x[1], state.__x[2], state.__x[3]);
    printf(" x4: %16llx  x5: %16llx  x6: %16llx  x7: %16llx\n", state.__x[4], state.__x[5], state.__x[6], state.__x[7]);
    printf(" x8: %16llx  x9: %16llx x10: %16llx x11: %16llx\n", state.__x[8], state.__x[9], state.__x[10], state.__x[11]);
    printf("x12: %16llx x13: %16llx x14: %16llx x15: %16llx\n", state.__x[12], state.__x[13], state.__x[14], state.__x[15]);
    printf("x16: %16llx x17: %16llx x18: %16llx x19: %16llx\n", state.__x[16], state.__x[17], state.__x[18], state.__x[19]);
    printf("x20: %16llx x21: %16llx x22: %16llx x23: %16llx\n", state.__x[20], state.__x[21], state.__x[22], state.__x[23]);
    printf("x24: %16llx x25: %16llx x26: %16llx x27: %16llx\n", state.__x[24], state.__x[25], state.__x[26], state.__x[27]);
    printf("x28: %16llx\n", state.__x[28]);
    printf(" sp: %16llx  fp: %16llx  lr: %16llx cpsr: %8x\n\n", state.__sp, state.__fp, state.__lr, state.__cpsr);
    printf("stack:\n");
    uint64_t stack[100];
    mach_target->ReadMemory(state.__sp, sizeof(stack), stack);
#else
    printf("thread %d\n", i);
    printf("rip:%llx\n", state.__rip);
    printf("rax:%llx rbx:%llx rcx:%llx rdx:%llx\n", state.__rax, state.__rbx, state.__rcx, state.__rdx);
    printf("rsi:%llx rdi:%llx rbp:%llx rsp:%llx\n", state.__rsi, state.__rdi, state.__rbp, state.__rsp);
    printf("r8:%llx r9:%llx r10:%llx r11:%llx\n", state.__r8, state.__r9, state.__r10, state.__r11);
    printf("r12:%llx r13:%llx r14:%llx r15:%llx\n", state.__r12, state.__r13, state.__r14, state.__r15);
    printf("stack:\n");
    uint64_t stack[100];
    mach_target->ReadMemory(state.__rsp, sizeof(stack), stack);
#endif
    for(size_t j=0; j<(sizeof(stack)/sizeof(stack[0])); j++) {
      printf("%16llx\n", stack[j]);
    }
  }
  for(unsigned i=0;i<num_threads;i++) {
    mach_port_deallocate(mach_task_self(), threads[i]);
  }
  vm_deallocate(mach_task_self(), (vm_address_t)threads, num_threads * sizeof(thread_act_t));
}

DebuggerStatus Debugger::DebugLoop(uint32_t timeout) {
  if (!IsTargetAlive()) {
    OnProcessExit();
    return DEBUGGER_PROCESS_EXIT;
  }

  if (dbg_continue_needed) {
    task_resume(mach_target->Task());
  }

  if (dbg_reply_needed) {
    mach_target->ReplyToException(reply_buffer);
  }

  bool alive = true;
  while (alive) {
    dbg_continue_needed = false;
    dbg_reply_needed = false;

    if(target_memory_limit && alive && !killing_target) {
      vm_size_t mem_size = mach_target->MemSize();
      if(mem_size > target_memory_limit) {
        WARN("Target exceeded memory limit");
        task_suspend(mach_target->Task());
        dbg_continue_needed = true;
        return DEBUGGER_HANGED;
      }
    }

    uint64_t begin_time = GetCurTime();
    kern_return_t krt = mach_target->WaitForException(std::min(timeout, (uint32_t)100),
                                                      request_buffer,
                                                      sizeof(union __RequestUnion__catch_mach_exc_subsystem));
    uint64_t end_time = GetCurTime();

    uint64_t time_elapsed = end_time - begin_time;
    timeout = ((uint64_t)timeout >= time_elapsed) ? timeout - (uint32_t)time_elapsed : 0;

    switch (krt) {
      case MACH_RCV_TIMED_OUT:
        if (timeout == 0) {
          task_suspend(mach_target->Task());
          dbg_continue_needed = true;
          return DEBUGGER_HANGED;
        }
        //go down into the MACH_RCV_INTERRUPTED case otherwise

      case MACH_RCV_INTERRUPTED:
        if (!IsTargetAlive()) {
          alive = false;
        }

        continue;

      default:
        if (krt != MACH_MSG_SUCCESS) {
          FATAL("Error (%s) returned by mach_msg (%x)\n", mach_error_string(krt), krt);
        }
    }

    task_suspend(mach_target->Task());
    dbg_continue_needed = true;


    /* mach_exc_server calls catch_mach_exception_raise
       HandleExceptionInternal returns in ret_HandleExceptionInternal */
    boolean_t message_parsed_correctly = mach_exc_server(request_buffer, reply_buffer);
    if (!message_parsed_correctly) {
      krt = ((mig_reply_error_t *)reply_buffer)->RetCode;
      FATAL("Error (%s) returned in reply buffer by mach_exc_server\n", mach_error_string(krt));
    }

    dbg_reply_needed = true;

    if (handle_exception_status == DEBUGGER_CRASHED) {
      OnCrashed(&last_exception);
    }

    if (handle_exception_status == DEBUGGER_PROCESS_EXIT) {
      alive = false;
      continue;
    }

    if (handle_exception_status != DEBUGGER_CONTINUE) {
      return handle_exception_status;
    }

    task_resume(mach_target->Task());
    mach_target->ReplyToException(reply_buffer);
  }

  OnProcessExit();
  return DEBUGGER_PROCESS_EXIT;
}

/**
 * Method not used, implementation is needed by the mach_exc_server method.
*/
kern_return_t catch_mach_exception_raise(
    mach_port_t exception_port,
    mach_port_t thread_port,
    mach_port_t task_port,
    exception_type_t exception_type,
    mach_exception_data_t code,
    mach_msg_type_number_t code_cnt) {
  return MACH_RCV_INVALID_TYPE;
}


/**
 * Method not used, implementation is needed by the mach_exc_server method.
 */
kern_return_t catch_mach_exception_raise_state(
    mach_port_t exception_port,
    exception_type_t exception_type,
    const mach_exception_data_t code,
    mach_msg_type_number_t code_cnt,
    int *flavor,
    const thread_state_t old_state,
    mach_msg_type_number_t old_state_cnt,
    thread_state_t new_state,
    mach_msg_type_number_t *new_state_cnt) {
  return MACH_RCV_INVALID_TYPE;
}

/**
 * Called by mach_exc_server
 *
 * @param exception_port the exception_port registered in AttachToProcess() method
 * @param task_port the target_task
*/
kern_return_t catch_mach_exception_raise_state_identity(
    mach_port_t exception_port,
    mach_port_t thread_port,
    mach_port_t task_port,
    exception_type_t exception_type,
    mach_exception_data_t code,
    mach_msg_type_number_t code_cnt,
    int *flavor,
    thread_state_t old_state,
    mach_msg_type_number_t old_state_cnt,
    thread_state_t new_state,
    mach_msg_type_number_t *new_state_cnt) {

  memcpy(new_state, old_state, old_state_cnt * sizeof(old_state[0]));
  *new_state_cnt = old_state_cnt;

  Debugger::MachException *mach_exception = new Debugger::MachException(exception_port,
                                                                        thread_port,
                                                                        task_port,
                                                                        exception_type,
                                                                        code,
                                                                        code_cnt,
                                                                        flavor,
                                                                        new_state,
                                                                        new_state_cnt);


  class Debugger *dbg = NULL;
  Debugger::map_mutex.lock();
  auto it = Debugger::task_to_debugger_map.find(task_port);
  if (it == Debugger::task_to_debugger_map.end() || it->second == NULL) {
    FATAL("Debugger object could not be found in the map, task port = (%d)\n", task_port);
  }
  dbg = it->second;
  Debugger::map_mutex.unlock();

  if (!dbg->killing_target) {
    dbg->HandleExceptionInternal(mach_exception);
  } else {
    dbg->dbg_continue_status = KERN_FAILURE;
    dbg->handle_exception_status = DEBUGGER_CONTINUE;
  }

  kern_return_t krt;
  krt = mach_port_deallocate(mach_task_self(), task_port);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) deallocating the task port\n", mach_error_string(krt));
  }

  krt = mach_port_deallocate(mach_task_self(), thread_port);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) deallocating the thread port\n", mach_error_string(krt));
  }

  delete mach_exception;
  mach_exception = NULL;
  return dbg->dbg_continue_status;
}

void Debugger::OnProcessExit() {
  if (trace_debug_events) {
    SAY("Debugger: Process exit\n");
  }

  if (mach_target != NULL) {
    map_mutex.lock();
    int removed = task_to_debugger_map.erase(mach_target->Task());
    if (removed == 0) {
      WARN("There is no task port (%u) in task_to_debugger_map to be erased", mach_target->Task());
    }
    map_mutex.unlock();

    mach_target->CleanUp();
    delete mach_target;
    mach_target = NULL;

    ClearSharedMemory();
  }

  // collect any zombie processes at this point
  int status;
  while(wait3(&status, WNOHANG, 0) > 0);
}


DebuggerStatus Debugger::Kill() {
  if (mach_target == NULL) {
    return DEBUGGER_PROCESS_EXIT;
  }

  killing_target = true;
  int target_pid = mach_target->Pid();
  kill(target_pid, SIGKILL);

  //SIGKILL is not handled, so DebugLoop must return DEBUGGER_PROCESS_EXIT
  dbg_last_status = DebugLoop(0xffffffff);
  if (dbg_last_status != DEBUGGER_PROCESS_EXIT || IsTargetAlive()) {
    FATAL("Unable to kill the process\n");
  }

  DeleteBreakpoints();
  killing_target = false;

  return dbg_last_status;
}

char **Debugger::GetEnvp() {
  int environ_size = 0;
  char **p = environ;
  while (*p) {
    environ_size += 1;
    p++;
  }

  int envp_size = environ_size + additional_env.size();
  char **envp = (char**)malloc(sizeof(char*)*(envp_size+1));
  int i;
  for (i = 0; i < environ_size; ++i) {
    envp[i] = (char*)malloc(strlen(environ[i])+1);
    strcpy(envp[i], environ[i]);
  }

  for(auto iter = additional_env.begin(); iter != additional_env.end(); iter++) {
    envp[i] = (char*)malloc(iter->size() + 1);
    strcpy(envp[i], iter->c_str());
    i++;
  }

  envp[envp_size] = NULL;

  return envp;
}


void Debugger::StartProcess(int argc, char **argv) {
  if (argc <= 0) {
    FATAL("Number of arguments is not strictly positive");
  }

  pid_t pid;
  int status;
  posix_spawnattr_t attr;

  status = posix_spawnattr_init(&attr);
  if (status != 0) {
    FATAL("Unable to init spawnattr");
  }
  
  short posix_flags = POSIX_SPAWN_START_SUSPENDED;
  if(disable_aslr) {
    posix_flags |= _POSIX_SPAWN_DISABLE_ASLR;
  }
  status = posix_spawnattr_setflags(&attr, posix_flags);
  if (status != 0) {
    FATAL("Unable to set flags in posix_spawnattr_setflags");
  }

  char **envp = GetEnvp();
  status = posix_spawn(&pid, argv[0], NULL, &attr, argv, envp);
  if (status != 0) {
    FATAL("Error (%s) spawning the process\n", strerror(status));
  }

  for (char **p = envp; *p; p++) {
    free(*p);
  }
  free(envp);

  mach_target = new MachTarget(pid);
}


void Debugger::AttachToProcess() {
  killing_target = false;
  dbg_continue_needed = false;
  dbg_reply_needed = false;
  target_reached = false;

  DeleteBreakpoints();

  int ptrace_ret;
  ptrace_ret = ptrace(PT_ATTACHEXC, mach_target->Pid(), 0, 0);
  if (ptrace_ret == -1) {
    FATAL("Unable to ptrace PT_ATTACHEXC to the target process\n");
  }

  map_mutex.lock();
  task_to_debugger_map[mach_target->Task()] = this;
  map_mutex.unlock();

  dbg_last_status = DEBUGGER_ATTACHED;
}


DebuggerStatus Debugger::Attach(unsigned int pid, uint32_t timeout) {
  attach_mode = true;
  mach_target = new MachTarget(pid);
  child_entrypoint_reached = true;

  AttachToProcess();
  return Continue(timeout);
}


DebuggerStatus Debugger::Run(char *cmd, uint32_t timeout) {
  FATAL("Deprecated Run interface on macOS - use Run(int argc, char **argv, uint32_t timeout) instead");
}


DebuggerStatus Debugger::Run(int argc, char **argv, uint32_t timeout) {
  attach_mode = false;
  child_entrypoint_reached = false;

  StartProcess(argc, argv);
  AttachToProcess();
  return Continue(timeout);
}

DebuggerStatus Debugger::Continue(uint32_t timeout) {
  if (loop_mode && (dbg_last_status == DEBUGGER_TARGET_END)) {
    dbg_last_status = DEBUGGER_TARGET_START;
    return dbg_last_status;
  }

  dbg_last_status = DebugLoop(timeout);
  return dbg_last_status;
}


void Debugger::Init(int argc, char **argv) {
  mach_target = NULL;
  killing_target = false;

  attach_mode = false;
  trace_debug_events = false;
  loop_mode = false;
  disable_aslr = false;
  target_function_defined = false;

  target_return_value = 0;

  target_module[0] = 0;
  target_method[0] = 0;
  target_offset = 0;
  saved_args = NULL;
  target_num_args = 0;
  target_address = NULL;
  
#ifdef ARM64
  target_end_detection = RETADDR_BREAKPOINT;
  private_dlyd_cache = true;
#else
  target_end_detection = RETADDR_STACK_OVERWRITE;
  private_dlyd_cache = false;
#endif

  dbg_last_status = DEBUGGER_NONE;
  shared_memory.clear();

  dbg_continue_needed = false;
  dbg_reply_needed = false;
  request_buffer = (mach_msg_header_t *)malloc(sizeof(union __RequestUnion__catch_mach_exc_subsystem));
  reply_buffer = (mach_msg_header_t *)malloc(sizeof(union __ReplyUnion__catch_mach_exc_subsystem));

  std::list<char *> env_options;
  GetOptionAll("-target_env", argc, argv, &env_options);
  for (auto iter = env_options.begin(); iter != env_options.end(); iter++) {
    additional_env.push_back(*iter);
  }
  
  char *option;
  trace_debug_events = GetBinaryOption("-trace_debug_events",
                                       argc, argv,
                                       trace_debug_events);

  option = GetOption("-target_module", argc, argv);
  if (option) strncpy(target_module, option, PATH_MAX);

  option = GetOption("-target_method", argc, argv);
  if (option) strncpy(target_method, option, PATH_MAX);

  loop_mode = GetBinaryOption("-loop", argc, argv, loop_mode);
  disable_aslr = GetBinaryOption("-disable_aslr", argc, argv, disable_aslr);

  option = GetOption("-nargs", argc, argv);
  if (option) target_num_args = atoi(option);

  option = GetOption("-target_offset", argc, argv);
  if (option) target_offset = strtoul(option, NULL, 0);

  // check if we are running in persistence mode
  if (target_module[0] || target_offset || target_method[0]) {
    target_function_defined = true;
    if ((target_module[0] == 0) || ((target_offset == 0) && (target_method[0] == 0))) {
      FATAL("target_module and either target_offset or target_method must be specified together\n");
    }
  }

  if (loop_mode && !target_function_defined) {
    FATAL("Target function needs to be defined to use the loop mode\n");
  }
  
  // avoid overwriting return address in case we have libgmalloc in env
  for (auto iter = additional_env.begin(); iter != additional_env.end(); iter++) {
    if (iter->find("libgmalloc") != std::string::npos) {
      target_end_detection = RETADDR_BREAKPOINT;
    }
  }
  private_dlyd_cache = GetBinaryOption("-private_dlyd_cache", argc, argv, private_dlyd_cache);
  if (private_dlyd_cache) {
    additional_env.push_back("DYLD_SHARED_REGION=private");
  }

  if (target_num_args) {
    saved_args = (void **)malloc(target_num_args * sizeof(void *));
  }

  m_dyld_process_info_create =
      (void *(*)(task_t task, uint64_t timestamp, kern_return_t * kernelError))
          dlsym(RTLD_DEFAULT, "_dyld_process_info_create");
  m_dyld_process_info_for_each_image =
      (void (*)(void *info, void (^)(uint64_t machHeaderAddress,
                                     const uuid_t uuid, const char *path)))
          dlsym(RTLD_DEFAULT, "_dyld_process_info_for_each_image");
  m_dyld_process_info_release =
      (void (*)(void *info))dlsym(RTLD_DEFAULT, "_dyld_process_info_release");

  target_memory_limit = 0;
  option = GetOption("-mem_limit", argc, argv);
  if (option) target_memory_limit = (uint64_t)strtoul(option, NULL, 0) * 1024 * 1024;
}

```

`macOS/debugger.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef DEBUGGER_H
#define DEBUGGER_H

#include <mach-o/loader.h>

#include <limits.h>
#include <unordered_map>
#include <list>
#include <vector>
#include <mutex>

#include "common.h"


#ifdef ARM64
#include "arch/arm64/reg.h"
#else
#include "arch/x86/reg.h"
#endif

#include "macOS/machtarget.h"
extern "C" {
  #include "macOS/mig_server.h"
}

#ifdef ARM64
  #define MAX_NUM_REG_ARGS 8
  #define ARCH_THREAD_STATE ARM_THREAD_STATE64
  #define ARCH_THREAD_STATE_COUNT ARM_THREAD_STATE64_COUNT
  #define ARCH_THREAD_STATE_T arm_thread_state64_t

  #define ARCH_FPU_STATE ARM_NEON_STATE64
  #define ARCH_FPU_STATE_COUNT ARM_NEON_STATE64_COUNT
  #define ARCH_FPU_STATE_T arm_neon_state64_t

#else

  #define MAX_NUM_REG_ARGS 6
  #define ARCH_THREAD_STATE x86_THREAD_STATE64
  #define ARCH_THREAD_STATE_COUNT x86_THREAD_STATE64_COUNT
  #define ARCH_THREAD_STATE_T x86_thread_state64_t

  #define ARCH_FPU_STATE x86_FLOAT_STATE64
  #define ARCH_FPU_STATE_COUNT x86_FLOAT_STATE64_COUNT
  #define ARCH_FPU_STATE_T x86_float_state64_t
#endif

struct SavedRegisters {
  ARCH_THREAD_STATE_T gpr_registers;
  mach_msg_type_number_t gpr_count;
  ARCH_FPU_STATE_T fpu_registers;
  mach_msg_type_number_t fpu_count;
};

enum DebuggerStatus {
  DEBUGGER_NONE,
  DEBUGGER_CONTINUE,
  DEBUGGER_PROCESS_EXIT,
  DEBUGGER_TARGET_START,
  DEBUGGER_TARGET_END,
  DEBUGGER_CRASHED,
  DEBUGGER_HANGED,
  DEBUGGER_ATTACHED,
};

class SharedMemory {
public:
  SharedMemory(mach_vm_address_t la,
		mach_vm_address_t ra,
		mach_vm_size_t s,
		mach_port_t p) : local_address(la), remote_address(ra), size(s), port(p) {}
  SharedMemory(const SharedMemory& other) : local_address(other.local_address),
					    remote_address(other.remote_address),
					    size(other.size),
					    port(other.port) {}
  SharedMemory &operator=(const SharedMemory& other) {
    local_address = other.local_address;
    remote_address = other.remote_address;
    size = other.size;
    port = other.port;
    return *this;
  }

  bool operator==(SharedMemory const& rhs) {
    return local_address == rhs.local_address &&
	  remote_address == rhs.remote_address &&
	  size == rhs.size &&
	  port == rhs.port;
  }

  mach_vm_address_t local_address;
  mach_vm_address_t remote_address;
  mach_vm_size_t size;
  mach_port_t port;
};

// From dyld SPI header dyld_process_info.h
typedef void *dyld_process_info;
struct dyld_process_cache_info {
  // UUID of cache used by process.
  uuid_t cacheUUID;
  // Load address of dyld shared cache.
  uint64_t cacheBaseAddress;
  // Process is running without a dyld cache.
  bool noCache;
  // Process is using a private copy of its dyld cache.
  bool privateCache;
};


class Debugger {
friend kern_return_t catch_mach_exception_raise_state_identity(
  mach_port_t exception_port,
  mach_port_t thread_port,
  mach_port_t task_port,
  exception_type_t exception_type,
  mach_exception_data_t code,
  mach_msg_type_number_t code_cnt,
  int *flavor,
  thread_state_t old_state,
  mach_msg_type_number_t old_state_cnt,
  thread_state_t new_state,
  mach_msg_type_number_t *new_state_cnt);

public:
  virtual void Init(int argc, char **argv);
  DebuggerStatus Run(char *cmd, uint32_t timeout);
  DebuggerStatus Run(int argc, char **argv, uint32_t timeout);
  DebuggerStatus Kill();
  DebuggerStatus Continue(uint32_t timeout);
  DebuggerStatus Attach(unsigned int pid, uint32_t timeout);

  bool IsTargetAlive();
  bool IsTargetFunctionDefined() { return target_function_defined; }

  uint64_t GetTargetReturnValue() { return target_return_value; }
  
  enum ExceptionType {
    BREAKPOINT,
    ACCESS_VIOLATION,
    ILLEGAL_INSTRUCTION,
    STACK_OVERFLOW,
    OTHER
  };

  struct Exception {
    ExceptionType type;
    void *ip;
    bool maybe_write_violation;
    bool maybe_execute_violation;
    void *access_address;
  };

  Exception GetLastException() {
    return last_exception;
  }

protected:
  enum MemoryProtection {
    READONLY,
    READWRITE,
    READEXECUTE,
    READWRITEEXECUTE
  };
  
  enum TargetEndDetection {
    RETADDR_STACK_OVERWRITE,
    RETADDR_BREAKPOINT
  };

  virtual void OnModuleLoaded(void *module, char *module_name);
  virtual void OnModuleUnloaded(void *module) {}

  virtual void OnProcessCreated();
  virtual void OnProcessExit();

  virtual void OnEntrypoint();
  virtual void OnTargetMethodReached() {}

  virtual void OnCrashed(Exception *exception_record) {}

  // should return true if the exception has been handled
  virtual bool OnException(Exception *exception_record) {
    return false;
  }

  size_t GetRegister(Register r);
  void SetRegister(Register r, size_t value);
  void SetReturnAddress(size_t value);
  size_t GetReturnAddress();

  void *GetModuleEntrypoint(void *base_address);
  bool IsDyld(void *base_address);

  void GetImageSize(void *base_address, size_t *min_address, size_t *max_address);

  MachTarget *mach_target;

  void ClearSharedMemory();
  void RemoteFree(void *address, size_t size);
  void RemoteWrite(void *address, const void *buffer, size_t size);
  void RemoteRead(void *address, void *buffer, size_t size);
  void RemoteProtect(void *address, size_t size, MemoryProtection protect);

  bool target_function_defined;
  bool trace_debug_events;
  bool attach_mode;
  bool loop_mode;
  bool disable_aslr;
  bool private_dlyd_cache;

  std::list<std::string> additional_env;
  
  bool child_entrypoint_reached;
  bool target_reached;

  int32_t child_ptr_size = sizeof(void*);

  // helper functions

  void *MakeSharedMemory(mach_vm_address_t address, size_t size, MemoryProtection protection);

  void *RemoteAllocate(size_t size,
                       MemoryProtection protection,
                       bool use_shared_memory = false);
  void *RemoteAllocateNear(uint64_t region_min,
                           uint64_t region_max,
                           size_t size,
                           MemoryProtection protection,
                           bool use_shared_memory = false);
  void *RemoteAllocate(size_t size);

  void ExtractCodeRanges(void *base_address,
                         size_t min_address,
                         size_t max_address,
                         std::list<AddressRange> *executable_ranges,
                         size_t *code_size);

  void ProtectCodeRanges(std::list<AddressRange> *executable_ranges);

  void PatchPointersRemote(void *base_address, std::unordered_map<size_t, size_t>& search_replace);
  void PatchPointersRemote(size_t min_address, size_t max_address, std::unordered_map<size_t, size_t>& search_replace);
  
  // returns address in (potentially) instrumented code
  virtual size_t GetTranslatedAddress(size_t address) { return address; }
  
  void *GetTargetMethodAddress() { return target_address; }

  bool GetSectionAndSlide(void *mach_header_address,
                          const char *segname,
                          const char *sectname,
                          section_64 *ret_section,
                          size_t *file_vm_slide);
  
  void SaveRegisters(SavedRegisters *registers);
  void RestoreRegisters(SavedRegisters *registers);

  void *GetSymbolAddress(void *base_address, char *symbol_name);

private:
  static std::unordered_map<task_t, Debugger*> task_to_debugger_map;
  static std::mutex map_mutex;
  std::list<SharedMemory> shared_memory;

  struct MachException {
    mach_port_t exception_port;
    mach_port_t thread_port;
    mach_port_t task_port;
    exception_type_t exception_type;
    mach_exception_data_t code;
    mach_msg_type_number_t code_cnt;
    int *flavor;
    thread_state_t new_state;
    mach_msg_type_number_t *new_state_cnt;

    MachException();

    MachException(mach_port_t exception_port,
                  mach_port_t thread_port,
                  mach_port_t task_port,
                  exception_type_t exception_type,
                  mach_exception_data_t code,
                  mach_msg_type_number_t code_cnt,
                  int *flavor,
                  thread_state_t new_state,
                  mach_msg_type_number_t *new_state_cnt)
    : exception_port(exception_port),
      thread_port(thread_port),
      task_port(task_port),
      exception_type(exception_type),
      code(code),
      code_cnt(code_cnt),
      flavor(flavor),
      new_state(new_state),
      new_state_cnt(new_state_cnt)
    {}
  };

  char **GetEnvp();

  struct Breakpoint {
    void *address;
    int type;
  #ifdef ARM64
    uint32_t original_opcode;
  #else
    unsigned char original_opcode;
  #endif
  };
  std::list<Breakpoint *> breakpoints;

  MachException *mach_exception;
  Exception last_exception;

  std::list<SharedMemory>::iterator FreeSharedMemory(std::list<SharedMemory>::iterator it);
  void StartProcess(int argc, char **argv);
  DebuggerStatus DebugLoop(uint32_t timeout);
  void AttachToProcess();
  void HandleExceptionInternal(MachException *mach_exception);
  int HandleDebuggerBreakpoint();

  void PrintContext();

  DebuggerStatus handle_exception_status;
  DebuggerStatus dbg_last_status;
  kern_return_t dbg_continue_status;

  bool dbg_continue_needed;
  bool dbg_reply_needed;
  mach_msg_header_t *request_buffer;
  mach_msg_header_t *reply_buffer;

  bool killing_target;

  void GetMachHeader(void *mach_header_axddress, mach_header_64 *mach_header);
  void GetLoadCommandsBuffer(void *mach_header_address, const mach_header_64 *mach_header, void **load_commands);

  template <class TCMD>
  bool GetLoadCommand(mach_header_64 mach_header,
                      void *load_commands_buffer,
                      uint32_t load_cmd_type,
                      const char *segname,
                      TCMD **ret_command);

  void OnDyldImageNotifier(size_t mode, unsigned long infoCount, uint64_t machHeaders[]);

  void AddBreakpoint(void *address, int type);
  void DeleteBreakpoints();

  uint64_t* GetPointerToRegister(Register r);
  Register ArgumentToRegister(int arg);

  void CreateException(MachException *mach_exception, Exception *exception);
  vm_prot_t MacOSProtectionFlags(MemoryProtection memory_protection);

  void *GetTargetAddress(void *base_address);

  void RemoteProtect(void *address, size_t size, vm_prot_t protect);

  void HandleTargetReachedInternal();
  void HandleTargetEnded();

  void *RemoteAllocateBefore(uint64_t min_address,
                             uint64_t max_address,
                             size_t size,
                             MemoryProtection protection);

  void *RemoteAllocateAfter(uint64_t min_address,
                            uint64_t max_address,
                            size_t size,
                            MemoryProtection protection);

  kern_return_t RemoteAllocateAt(void *ret_address, int size);

  void ExtractSegmentCodeRanges(mach_vm_address_t segment_start_addr,
                                mach_vm_address_t segment_end_addr,
                                std::list<AddressRange> *executable_ranges,
                                size_t *code_size);

  char target_module[PATH_MAX];
  char target_method[PATH_MAX];

  int target_num_args;
  uint64_t target_offset;

  void *target_address;
  void *saved_sp;
  void *saved_return_address;
  void **saved_args;
  TargetEndDetection target_end_detection;
  
  uint64_t target_return_value;

  // memory limit in bytes
  uint64_t target_memory_limit;

  //DYLD SPI
  void *(*m_dyld_process_info_create)(task_t task,
                                      uint64_t timestamp,
                                      kern_return_t *kernelError);

  void (*m_dyld_process_info_for_each_image)(void *info,
                                             void (^callback)(uint64_t machHeaderAddress,
                                                              const uuid_t uuid,
                                                              const char *path));

  void (*m_dyld_process_info_release)(void *info);

  void *m_dyld_debugger_notification;
};


#endif /* DEBUGGER_H */

```

`macOS/dyld_cache_map_parser.cpp`:

```cpp
/*
Copyright 2022 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "macOS/dyld_cache_map_parser.h"

#include <iostream>
#include <fstream>
#include <regex>

#include "common.h"

struct Module {
  Module(std::string n, uint64_t s, uint64_t e)
  : name(n), start(s), end(e) {}
  std::string name;
  uint64_t start;
  uint64_t end;
};

static bool is_page_aligned(uint64_t addr, uint64_t page_size = 0x4000) {
  return !(addr & (page_size-1));
}

std::map<std::string, std::vector<std::string>> parse_dyld_map_file(const std::string &path) {
  std::ifstream cache_map(path);

  if(!cache_map.is_open()) {
    FATAL("Unable to open: %s", path.c_str());
  }

  std::string line;

  std::map<std::string, std::vector<std::string>> result;
  std::map<uint64_t, Module> tmp_result;

  std::string regex = "__TEXT 0x([A-F0-9]+) -> 0x([A-F0-9]+)";
  std::smatch m;
  std::regex r(regex);


  bool lib = false;
  int i = 0;
  std::string lib_name;
  while (std::getline(cache_map, line)) {
    if (line.length() > 0 && line[0] == '/') {
      lib = true;
      if (line.rfind("/") == std::string::npos) {
        std::cout << "error\n";
        std::cout << line << "\n";
        return {};
      }
      lib_name = line.substr(line.rfind("/") + 1);
    }

    if (lib && line.length() == 0) {
      lib = false;
    }

    if (lib) {
      if(std::regex_search(line, m, r)) {
        if(m.size() != 3) continue;
        uint64_t start = std::stoul(m[1], nullptr, 16);
        uint64_t end = std::stoul(m[2], nullptr, 16);
        tmp_result.insert({start, Module(lib_name, start, end)});
      }
    }
  }

  uint64_t prev_end_addr = tmp_result.begin()->second.start;
  std::vector<std::string> mod_group;
  for(const auto &[start_address, mod]: tmp_result) {
    mod_group.push_back(mod.name);

    if(is_page_aligned(mod.end)) {
      for(const auto mod_name: mod_group) {
        result.insert({mod_name, mod_group});
      }

      mod_group.clear();
      prev_end_addr = mod.end;  
    }
    else if(prev_end_addr != mod.start && is_page_aligned(mod.start)) {
      mod_group.pop_back();

      for(const auto mod_name: mod_group) {
        result.insert({mod_name, mod_group});
      }

      mod_group.clear();   
      mod_group.push_back(mod.name);
    }
    else {
      prev_end_addr = mod.end;
    }
  }

  cache_map.close();
  return result;
}

```

`macOS/dyld_cache_map_parser.h`:

```h
/*
Copyright 2022 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include <map>
#include <string>
#include <vector>

std::map<std::string, std::vector<std::string>> parse_dyld_map_file(const std::string &path);

```

`macOS/machtarget.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <string>

#include <mach/mach_vm.h>
#include <mach-o/dyld_images.h>

#include "macOS/machtarget.h"
#include "common.h"

#define INVALID_PAGE_SIZE ((vm_size_t)(~0))

#ifdef ARM64
  #define ARCH_THREAD_STATE ARM_THREAD_STATE64
#else
  #define ARCH_THREAD_STATE x86_THREAD_STATE64
#endif

MachTarget::MachTarget(pid_t target_pid): pid(target_pid), m_page_size(INVALID_PAGE_SIZE) {
  kern_return_t krt;

  krt = task_for_pid(mach_task_self(), pid, &task);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) calling task_for_pid\n", mach_error_string(krt));
  }

  krt = task_get_exception_ports(task,
                                  EXC_MASK_ALL,
                                  saved_masks,
                                  &saved_exception_types_count,
                                  saved_ports,
                                  saved_behaviors,
                                  saved_flavors);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) saving the exception ports registered in the process\n", mach_error_string(krt));
  }

  krt = mach_port_allocate(mach_task_self(),
                           MACH_PORT_RIGHT_RECEIVE,
                           &exception_port);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) allocating a new port\n", mach_error_string(krt));
  }

  mach_port_insert_right(mach_task_self(),
                         exception_port,
                         exception_port,
                         MACH_MSG_TYPE_MAKE_SEND);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) authorizing a new exception port\n", mach_error_string(krt));
  }

  /* register the exception port with the target process */
  task_set_exception_ports(task,
                           EXC_MASK_ALL,
                           exception_port,
                           EXCEPTION_STATE_IDENTITY | MACH_EXCEPTION_CODES,
                           ARCH_THREAD_STATE);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) registering the exception port with the target process\n", mach_error_string(krt));
  }

}


kern_return_t MachTarget::BasicInfo(mach_task_basic_info *info) {
  if (info == NULL) {
    return KERN_INVALID_ARGUMENT;
  }

  unsigned int count = MACH_TASK_BASIC_INFO_COUNT;
  return task_info(task, MACH_TASK_BASIC_INFO, (task_info_t)info, &count);
}

bool MachTarget::IsExceptionPortValid() {
  return MACH_PORT_VALID(exception_port);
}


bool MachTarget::IsTaskValid() {
  if (task != TASK_NULL) {
    mach_task_basic_info task_info;
    return BasicInfo(&task_info) == KERN_SUCCESS;
  }

  return false;
}

void MachTarget::GetRegionSubmapInfo(mach_vm_address_t *region_address,
                                     mach_vm_size_t *region_size,
                                     vm_region_submap_info_data_64_t *info) {
  kern_return_t krt;
  uint32_t depth = ~0;
  mach_msg_type_number_t count = VM_REGION_SUBMAP_INFO_COUNT_64;
  krt = mach_vm_region_recurse(task,
                               region_address,
                               region_size,
                               &depth,
                               (vm_region_recurse_info_t)info,
                               &count);

  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) retrieving region information\n", mach_error_string(krt));
  }
}

kern_return_t MachTarget::WaitForException(uint32_t timeout, mach_msg_header_t *req, uint32_t size) {
  kern_return_t krt;
  krt = mach_msg(req,  /* receive buffer */
                 MACH_RCV_MSG | MACH_RCV_TIMEOUT | MACH_RCV_INTERRUPT,
                 0,                         /* size of send buffer */
                 size,                      /* size of receive buffer */
                 exception_port,            /* port to receive on */
                 timeout,                   /* wait for timeout seconds */
                 MACH_PORT_NULL);           /* notify port, unused */

  return krt;
}

void MachTarget::ReplyToException(mach_msg_header_t *rpl) {
  kern_return_t krt;
  krt = mach_msg(rpl,  /* send buffer */
                MACH_SEND_MSG | MACH_SEND_INTERRUPT,             /* send message */
                rpl->msgh_size,            /* size of send buffer */
                0,                         /* size of receive buffer */
                MACH_PORT_NULL,            /* port to receive on */
                MACH_MSG_TIMEOUT_NONE,     /* wait indefinitely */
                MACH_PORT_NULL);           /* notify port, unused */

  if (krt != MACH_MSG_SUCCESS) {
    // the target could be terminated at this point, check if that's the case
    if(!IsTaskValid() || !IsExceptionPortValid()) return;

    FATAL("Error (%s) sending reply to exception port\n", mach_error_string(krt));
  }
}

void MachTarget::CleanUp() {
  /* restore saved exception ports */
  for (uint32_t i = 0; i < saved_exception_types_count; ++i) {
      task_set_exception_ports(task,
                               saved_masks[i],
                               saved_ports[i],
                               saved_behaviors[i],
                               saved_flavors[i]);
  }

  kern_return_t krt;
  krt = mach_port_destroy(mach_task_self(), exception_port);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) destroying exception port\n", mach_error_string(krt));
  }

  krt = mach_port_deallocate(mach_task_self(), task);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) deallocating task port", mach_error_string(krt));
  }

  task = TASK_NULL;
  exception_port = MACH_PORT_NULL;
}

void MachTarget::FreeMemory(uint64_t address, size_t size) {
  if (size == 0) {
    WARN("FreeMemory is called with size == 0\n");
    return;
  }

  kern_return_t krt = mach_vm_deallocate(task, (mach_vm_address_t)address, (mach_vm_size_t)size);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) freeing memory @ 0x%llx\n", mach_error_string(krt), address);
  }
}

void MachTarget::ReadMemory(uint64_t address, size_t size, void *buf) {
  if (buf == NULL) {
    WARN("ReadMemory is called with buf == NULL\n");
    return;
  }

  if (size == 0) {
    WARN("ReadMemory is called with size == 0\n");
    return;
  }

  kern_return_t krt;
  mach_vm_size_t total_bytes_read = 0;
  mach_vm_address_t cur_addr = address;
  uint8_t *cur_buf = (uint8_t*)buf;
  while (total_bytes_read < size) {
    mach_vm_size_t cur_size = MaxBytesLeftInPage(cur_addr, size - total_bytes_read);

    mach_msg_type_number_t cur_bytes_read = 0;
    vm_offset_t vm_buf;
    krt = mach_vm_read(task, cur_addr, cur_size, &vm_buf, &cur_bytes_read);

    if (krt != KERN_SUCCESS) {
      FATAL("Error (%s) reading memory @ address 0x%llx\n", mach_error_string(krt), cur_addr);
    }

    if (cur_bytes_read != cur_size) {
      FATAL("Error reading the entire requested memory @ address 0x%llx\n", cur_addr);
    }

    memcpy(cur_buf, (const void*)vm_buf, cur_bytes_read);
    mach_vm_deallocate(mach_task_self(), vm_buf, cur_bytes_read);

    total_bytes_read += cur_bytes_read;
    cur_addr += cur_bytes_read;
    cur_buf += cur_bytes_read;
  }
}

void MachTarget::WriteMemory(uint64_t address, const void *buf, size_t size) {
  if (buf == NULL) {
    WARN("WriteMemory is called with buf == NULL\n");
    return;
  }

  if (size == 0) {
    WARN("WriteMemory is called with size == 0\n");
    return;
  }

  uint64_t cur_address = address;
  while (cur_address < address + size) {
    mach_vm_address_t region_address = cur_address;
    mach_vm_size_t region_size = 0;
    vm_region_submap_info_data_64_t info;
    GetRegionSubmapInfo(&region_address, &region_size, &info);
    if (cur_address < region_address) {
      FATAL("Unable to write to unmapped memory region\n");
    }

    uint64_t cur_size = region_address + region_size - cur_address;
    if (cur_address + cur_size >= address + size) {
      cur_size = address + size - cur_address;
    }

    if (!(info.protection & VM_PROT_WRITE)) {
      kern_return_t krt = mach_vm_protect(task, cur_address, cur_size, false, VM_PROT_READ | VM_PROT_WRITE);
      if (krt != KERN_SUCCESS) {
        ProtectMemory(cur_address, cur_size, VM_PROT_READ | VM_PROT_WRITE | VM_PROT_COPY);
      }
    }

    kern_return_t krt = mach_vm_write(task,
                                      (mach_vm_address_t)cur_address,
                                      (vm_offset_t)buf,
                                      (mach_msg_type_number_t)cur_size);
    if (krt != KERN_SUCCESS) {
      FATAL("Error (%s) writing memory @ 0x%llx\n", mach_error_string(krt), cur_address);
    }

    if (!(info.protection & VM_PROT_WRITE)) {
      ProtectMemory(cur_address, cur_size, info.protection);
    }

    buf = (void*)((uint64_t)buf + cur_size);
    cur_address += cur_size;
  }

  vm_machine_attribute_val_t mattr_value = MATTR_VAL_CACHE_FLUSH;
  vm_machine_attribute(task, address, size, MATTR_CACHE, &mattr_value);
}

void MachTarget::ProtectMemory(uint64_t address, uint64_t size, vm_prot_t protection) {
  if (size == 0) {
    WARN("ProtectMemory is called with size == 0\n");
    return;
  }

  kern_return_t krt = mach_vm_protect(task, address, size, false, protection);
  if (krt != KERN_SUCCESS) {
    FATAL("Error (%s) applying memory protection @ 0x%llx\n", mach_error_string(krt), address);
  }
}


size_t MachTarget::MaxBytesLeftInPage(mach_vm_address_t address, mach_vm_size_t size) {
  vm_size_t page_size = PageSize();
  if (page_size > 0) {
    mach_vm_size_t page_offset = address % page_size;
    mach_vm_size_t bytes_left_in_page = page_size - page_offset;
    if (size > bytes_left_in_page) {
      size = bytes_left_in_page;
    }
  }

  return size;
}

vm_size_t MachTarget::PageSize() {
  if (m_page_size == INVALID_PAGE_SIZE) {
    kern_return_t krt;

    task_vm_info_data_t vm_info;
    mach_msg_type_number_t info_count = TASK_VM_INFO_COUNT;
    krt = task_info(task, TASK_VM_INFO, (task_info_t)&vm_info, &info_count);

    if (krt != KERN_SUCCESS) {
      FATAL("Error (%s) retrieving target's TASK_VM_INFO\n", mach_error_string(krt));
    }

    m_page_size = vm_info.page_size;
  }

  return m_page_size;
}

vm_size_t MachTarget::MemSize() {
  kern_return_t krt;

  task_vm_info_data_t vm_info;
  mach_msg_type_number_t info_count = TASK_VM_INFO_COUNT;
  krt = task_info(task, TASK_VM_INFO, (task_info_t)&vm_info, &info_count);

  if (krt != KERN_SUCCESS) {
    // if this failed, the target is most likely dead
    return 0;
  }

  return vm_info.resident_size;
}

dyld_all_image_infos MachTarget::GetAllImageInfos() {
  task_dyld_info_data_t task_dyld_info;
  mach_msg_type_number_t count = TASK_DYLD_INFO_COUNT;

  kern_return_t krt;
  krt = task_info(task, TASK_DYLD_INFO, (task_info_t)&task_dyld_info, &count);
  if (krt != KERN_SUCCESS) {
    FATAL("Unable to retrieve task_info of target task, %d\n", krt);
  }

  dyld_all_image_infos all_image_infos;
  ReadMemory((uint64_t)task_dyld_info.all_image_info_addr, task_dyld_info.all_image_info_size, &all_image_infos);
  return all_image_infos;
}

void MachTarget::ReadCString(uint64_t address, size_t max_size, void *string) {
  while (max_size) {
    size_t cur_size = MaxBytesLeftInPage(address, max_size);
    ReadMemory(address, cur_size, string);
    if (memchr((void*)string, '\0', cur_size)) {
      return;
    }

    string = (void*)((uint64_t)string + cur_size);
    max_size -= cur_size;
    address += cur_size;
  }
}

void MachTarget::ReadCString(uint64_t address, std::string &string) {
  size_t page_size = PageSize();
  char *buf = (char *)malloc(page_size);

  while (1) {
    size_t cur_size = MaxBytesLeftInPage(address, page_size);
    ReadMemory(address, cur_size, buf);
    if (memchr((void*)buf, '\0', cur_size)) {
      string.append(buf);
      free(buf);
      return;
    } else {
      string.append(buf, cur_size);
    }

    address += cur_size;
  }
}

```

`macOS/machtarget.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef MACHTARGET_H
#define MACHTARGET_H

#include <mach/mach.h>
#include <mach-o/dyld_images.h>
#include <unordered_map>

class MachTarget {
private:
  pid_t pid;
  task_t task;
  mach_port_t exception_port;
  vm_size_t m_page_size;

  exception_mask_t       saved_masks[EXC_TYPES_COUNT];
  mach_port_t            saved_ports[EXC_TYPES_COUNT];
  exception_behavior_t   saved_behaviors[EXC_TYPES_COUNT];
  thread_state_flavor_t  saved_flavors[EXC_TYPES_COUNT];
  mach_msg_type_number_t saved_exception_types_count;

  size_t MaxBytesLeftInPage(mach_vm_address_t address, mach_vm_size_t size);

public:
  MachTarget(pid_t target_pid);

  pid_t Pid() { return pid; }
  task_t Task() { return task; }
  mach_port_t ExceptionPort() { return exception_port; }

  vm_size_t PageSize();
  vm_size_t MemSize();

  kern_return_t BasicInfo(mach_task_basic_info *info);
  void GetRegionSubmapInfo(mach_vm_address_t *region_address,
                           mach_vm_size_t *region_size,
                           vm_region_submap_info_data_64_t *info);

  bool IsExceptionPortValid();
  bool IsTaskValid();

  dyld_all_image_infos GetAllImageInfos();
  void ReadCString(uint64_t address, size_t max_size, void *string);
  void ReadCString(uint64_t address, std::string &string);

  kern_return_t WaitForException(uint32_t timeout, mach_msg_header_t *req, uint32_t size);
  void ReplyToException(mach_msg_header_t *rpl);

  void FreeMemory(uint64_t address, size_t size);
  void ReadMemory(uint64_t address, size_t size, void *buf);
  void WriteMemory(uint64_t address, const void *buf, size_t size);
  void ProtectMemory(uint64_t address, uint64_t size, vm_prot_t protection);

  void CleanUp();
};

#endif /* MACHTARGET_H */

```

`macOS/mig.defs`:

```defs
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

//Resolve MIG generated files 
#import <mach/mach_exc.defs>

```

`macOS/unwindmacos.cpp`:

```cpp
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#include "unwindmacos.h"
#include "common.h"

#include <mach-o/dyld.h>
#include <mach-o/dyld_images.h>
#include <mach-o/nlist.h>

#include <third_party/llvm/libunwind/dwarf2.h>
#include <third_party/llvm/libunwind/CompactUnwinder.hpp>

#define LOOKUP_TABLE_CHUNK_SIZE (1024*1024)
#define LOOKUP_TABLE_ELEMENT_SIZE (4 * sizeof(void *))
#define LOOKUP_TABLE_BUCKETS 16384 //needs to be a power of two
#ifdef ARM64
#define ARCH_IP_VALUE_REGISTER X0
#define ARCH_PERSONALITY_VALUE_REGISTER X22
#else
#define ARCH_IP_VALUE_REGISTER RAX
#define ARCH_PERSONALITY_VALUE_REGISTER RBX
#endif

#ifdef ARM64
constexpr unsigned char UnwindGeneratorMacOS::register_assembly_arm64[];
#else
constexpr unsigned char UnwindGeneratorMacOS::register_assembly_x86[];
#endif

void UnwindGeneratorMacOS::Init(int argc, char **argv) {
  in_process_lookup = true;
  
  in_process_lookup = GetBinaryOption("-unwind_in_process_lookup",
                                      argc, argv, in_process_lookup);
}

bool UnwindDataMacOS::LookupPersonality(size_t ip, size_t *personality) {
  if((ip >= last_personality_lookup.min_address) &&
     (ip < last_personality_lookup.max_address))
  {
    *personality = last_personality_lookup.personality;
    return last_personality_lookup.found;
  }

  auto it = encoding_map.upper_bound(ip);
  if (it == encoding_map.begin()) {
    last_personality_lookup.Init(false, -1, 0, it->first - 1);
  } else if (it == encoding_map.end()) { // Sentinel entry
    last_personality_lookup.Init(false, -1, prev(it)->first, -1);
  } else {
    compact_unwind_encoding_t encoding = prev(it)->second;
    // TODO(ifratric): If the encoding is a pointer to DWARF,
    // do we need to extract the personality from there
    // or is the personality index valid regardless?
    uint32_t personality_index = EXTRACT_BITS(encoding, UNWIND_PERSONALITY_MASK);
    if(personality_index >= personality_vector.size()) {
      FATAL("personality_index out of bounds");
    }
    last_personality_lookup.Init(true, personality_vector[personality_index],
                                 prev(it)->first, it->first - 1);
  }

  *personality = last_personality_lookup.personality;
  return last_personality_lookup.found;
}

UnwindDataMacOS::UnwindDataMacOS() {
  unwind_section_address = NULL;
  unwind_section_size = 0;
  unwind_section_buffer = NULL;
  unwind_section_header = NULL;
  registered_fde = false;
}

UnwindDataMacOS::~UnwindDataMacOS() {
  free(unwind_section_buffer);
  unwind_section_buffer = NULL;
}

void UnwindGeneratorMacOS::CheckUnwindBufferBounds(ModuleInfo *module, const char *array_description,
                                                   size_t start_address, size_t size) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

  if (start_address < (size_t)unwind_data->unwind_section_buffer
      || (size_t)unwind_data->unwind_section_buffer + unwind_data->unwind_section_size < start_address + size) {
    FATAL("%s is located outside the Unwind Section buffer\n", array_description);
  }
}

void UnwindGeneratorMacOS::SanityCheckUnwindHeader(ModuleInfo *module) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  unwind_info_section_header *unwind_section_header = unwind_data->unwind_section_header;

  if (unwind_section_header->version != UNWIND_SECTION_VERSION) {
    FATAL("Unexpected version (%u) in Unwind Section Header", unwind_section_header->version);
  }

  size_t common_encodings_array_addr = (size_t)unwind_data->unwind_section_buffer
                                       + unwind_section_header->commonEncodingsArraySectionOffset;
  CheckUnwindBufferBounds(module, "Common encodings array", common_encodings_array_addr,
                          unwind_section_header->commonEncodingsArrayCount * sizeof(compact_unwind_encoding_t));

  size_t personality_array_addr = (size_t)unwind_data->unwind_section_buffer
                                  + unwind_section_header->personalityArraySectionOffset;
  CheckUnwindBufferBounds(module, "Personality array", personality_array_addr,
                          unwind_section_header->personalityArrayCount * sizeof(uint32_t));

  size_t first_level_array_addr = (size_t)unwind_data->unwind_section_buffer
                                  + unwind_section_header->indexSectionOffset;
  CheckUnwindBufferBounds(module, "First-level indexSection array", first_level_array_addr,
                          unwind_section_header->indexCount * sizeof(unwind_info_section_header_index_entry));
}

void UnwindGeneratorMacOS::OnModuleInstrumented(ModuleInfo* module) {
  UnwindDataMacOS *unwind_data = new UnwindDataMacOS();

  size_t file_vm_slide = 0;
  section_64 unwind_section;
  if (tinyinst_.GetSectionAndSlide(module->module_header, "__TEXT", "__unwind_info",
                                   &unwind_section, &file_vm_slide)) {
    unwind_data->unwind_section_address = (void*)(file_vm_slide + unwind_section.addr);
    unwind_data->unwind_section_size = unwind_section.size;

    unwind_data->unwind_section_buffer = (void*)malloc(unwind_section.size);
    tinyinst_.RemoteRead(unwind_data->unwind_section_address,
                         unwind_data->unwind_section_buffer,
                         unwind_data->unwind_section_size);

    unwind_data->unwind_section_header =
      (unwind_info_section_header *)unwind_data->unwind_section_buffer;
  } else {
    FATAL("Unable to find __unwind_info section in module %s (0x%lx)\n"
          "Aborting since there is no support for .eh_frame DWARF entries at the moment.\n",
          module->module_name.c_str(), (size_t)module->module_header);
  }

  module->unwind_data = unwind_data;
  SanityCheckUnwindHeader(module);

  ExtractPersonalityArray(module);
  ExtractFirstLevel(module);
}

void UnwindGeneratorMacOS::OnModuleUninstrumented(ModuleInfo *module) {
  delete module->unwind_data;
  module->unwind_data = NULL;
}

void UnwindGeneratorMacOS::OnReturnAddress(ModuleInfo *module,
                                           size_t original_address,
                                           size_t translated_address) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

  size_t personality;
  bool lookup_success = unwind_data->LookupPersonality(original_address - 1,
                                                       &personality);
  // if we are in an area that has no unwinding information,
  // no need to store anything
  if(!lookup_success) return;
  
  unwind_data->return_addresses[translated_address] =
    {original_address, personality};
}

size_t UnwindGeneratorMacOS::WriteCIE(ModuleInfo *module,
                                      const char *augmentation,
                                      size_t personality_addr) {

  ByteStream cie;
  cie.PutValue<uint32_t>(0);                  // CIE id, must be zero
  cie.PutValue<uint8_t>(3);                   // version
  cie.PutString(augmentation);                // augmentation string
  cie.PutULEB128Value(1);                     // code alignment factor, ULEB128 encoded
  cie.PutSLEB128Value(1);                     // data alignment factor, SLEB128 encoded
  cie.PutULEB128Value(16);                    // return address register, ULEB128 encoded

  cie.PutULEB128Value(9);                     // augmentation length
  cie.PutValue<uint8_t>(0);                   // personality encoding
  cie.PutValue<uint64_t>(personality_addr);   // personality address

  cie.PutValueFront<uint32_t>(cie.size());    // CIE length

  size_t cie_address = tinyinst_.GetCurrentInstrumentedAddress(module);
  tinyinst_.WriteCode(module, cie.data(), cie.size());

  return cie_address;
}

void UnwindGeneratorMacOS::ExtractPersonalityArray(ModuleInfo *module) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  unwind_info_section_header *unwind_section_header = unwind_data->unwind_section_header;

  size_t curr_personality_entry_addr = (size_t)unwind_data->unwind_section_buffer
                                       + unwind_section_header->personalityArraySectionOffset;

  unwind_data->personality_vector.clear();
  unwind_data->personality_vector.push_back(0);
  for (int curr_cnt = 0; curr_cnt < unwind_section_header->personalityArrayCount; ++curr_cnt) {
    uint32_t personality_offset = *(uint32_t*)curr_personality_entry_addr;
    size_t personality_address;
    tinyinst_.RemoteRead((void*)((size_t)module->module_header + personality_offset),
                         &personality_address,
                         sizeof(size_t));
    unwind_data->personality_vector.push_back(personality_address);

    curr_personality_entry_addr += sizeof(uint32_t);
  }
}

void UnwindGeneratorMacOS::ExtractFirstLevel(ModuleInfo *module) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  unwind_info_section_header *unwind_section_header = unwind_data->unwind_section_header;

  size_t curr_first_level_entry_addr = (size_t)unwind_data->unwind_section_buffer
                                       + unwind_section_header->indexSectionOffset;

  // last entry is a sentinel entry
  // (secondLevelPagesSectionOffset == 0,
  //  functionOffset == maximum_mapped_address + 1)
  for (int entry_cnt = 0; entry_cnt < unwind_section_header->indexCount; ++entry_cnt) {
    unwind_info_section_header_index_entry *curr_first_level_entry =
      (unwind_info_section_header_index_entry *)curr_first_level_entry_addr;

    if (entry_cnt + 1 == unwind_section_header->indexCount) { // Sentinel entry
      unwind_data->encoding_map[(size_t)module->module_header
                                + curr_first_level_entry->functionOffset] = 0;
    } else {
      ExtractEncodingsSecondLevel(module, curr_first_level_entry);
    }

    curr_first_level_entry_addr += sizeof(unwind_info_section_header_index_entry);
  }
}

void UnwindGeneratorMacOS::ExtractEncodingsSecondLevel(ModuleInfo *module,
                                                       unwind_info_section_header_index_entry *first_level_entry) {
  if (first_level_entry->secondLevelPagesSectionOffset == 0) {
    return;
  }

  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

  size_t second_level_page_addr = (size_t)unwind_data->unwind_section_buffer
                                  + first_level_entry->secondLevelPagesSectionOffset;
  CheckUnwindBufferBounds(module, "second_level_page_header.kind",
                          second_level_page_addr, sizeof(uint32_t));

  uint32_t unwind_second_level_type = *(uint32_t*)second_level_page_addr;
  if (unwind_second_level_type == UNWIND_SECOND_LEVEL_COMPRESSED) {
    ExtractEncodingsCompressed(module, first_level_entry, second_level_page_addr);
  } else if (unwind_second_level_type == UNWIND_SECOND_LEVEL_REGULAR) {
    ExtractEncodingsRegular(module, first_level_entry, second_level_page_addr);
  }
}


compact_unwind_encoding_t UnwindGeneratorMacOS::GetCompactEncoding(ModuleInfo *module,
                                                                   size_t second_level_page_addr,
                                                                   uint32_t curr_entry_encoding_index) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  unwind_info_section_header *unwind_section_header = unwind_data->unwind_section_header;
  unwind_info_compressed_second_level_page_header *second_level_header =
    (unwind_info_compressed_second_level_page_header *)second_level_page_addr;

  if (curr_entry_encoding_index < unwind_section_header->commonEncodingsArrayCount) {
    return *(compact_unwind_encoding_t*)
           ((size_t)unwind_data->unwind_section_buffer
            + unwind_section_header->commonEncodingsArraySectionOffset
            + curr_entry_encoding_index * sizeof(compact_unwind_encoding_t));
  } else if (curr_entry_encoding_index - unwind_section_header->commonEncodingsArrayCount
             < second_level_header->encodingsCount) {
    return *(compact_unwind_encoding_t*)
           (second_level_page_addr
            + second_level_header->encodingsPageOffset
            + (curr_entry_encoding_index - unwind_section_header->commonEncodingsArrayCount)
                * sizeof(compact_unwind_encoding_t));
  }

  FATAL("The compressed encoding index is invalid\n");
}

void UnwindGeneratorMacOS::ExtractEncodingsCompressed(ModuleInfo *module,
                                                      unwind_info_section_header_index_entry *first_level_entry,
                                                      size_t second_level_page_addr) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

  CheckUnwindBufferBounds(module, "Compressed second_level_page_header", second_level_page_addr,
                          sizeof(unwind_info_compressed_second_level_page_header));

  unwind_info_compressed_second_level_page_header *second_level_header =
    (unwind_info_compressed_second_level_page_header *)second_level_page_addr;

  CheckUnwindBufferBounds(module, "Second-level local encodings array",
                          second_level_page_addr + second_level_header->encodingsPageOffset,
                          second_level_header->encodingsCount * sizeof(compact_unwind_encoding_t));

  size_t curr_second_level_entry_addr = second_level_page_addr + second_level_header->entryPageOffset;
  CheckUnwindBufferBounds(module, "Compressed second-level array", curr_second_level_entry_addr,
                          second_level_header->entryCount * sizeof(uint32_t));

  for (int curr_cnt = 0; curr_cnt < second_level_header->entryCount; ++curr_cnt) {
    uint32_t curr_second_level_entry = *(uint32_t*)curr_second_level_entry_addr;
    uint32_t curr_entry_encoding_index =
      UNWIND_INFO_COMPRESSED_ENTRY_ENCODING_INDEX(curr_second_level_entry);
    uint32_t curr_entry_func_offset =
      UNWIND_INFO_COMPRESSED_ENTRY_FUNC_OFFSET(curr_second_level_entry);

    compact_unwind_encoding_t encoding = GetCompactEncoding(module,
                                                            second_level_page_addr,
                                                            curr_entry_encoding_index);

    unwind_data->encoding_map[(uint64_t)module->module_header
                              + first_level_entry->functionOffset
                              + curr_entry_func_offset] = encoding;

    curr_second_level_entry_addr += sizeof(uint32_t);
  }
}

void UnwindGeneratorMacOS::ExtractEncodingsRegular(ModuleInfo *module,
                                                   unwind_info_section_header_index_entry *first_level_entry,
                                                   size_t second_level_page_addr) {
  WARN("ExtractEncodingsRegular() function was never tested");
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

  CheckUnwindBufferBounds(module, "Regular second_level_page_header", second_level_page_addr,
                          sizeof(unwind_info_regular_second_level_page_header));

  unwind_info_regular_second_level_page_header *second_level_header =
    (unwind_info_regular_second_level_page_header *)second_level_page_addr;

  size_t curr_second_level_entry_addr = second_level_page_addr + second_level_header->entryPageOffset;
  CheckUnwindBufferBounds(module, "Regular second-level array", curr_second_level_entry_addr,
                          second_level_header->entryCount * sizeof(unwind_info_regular_second_level_entry));

  for (int curr_cnt = 0; curr_cnt < second_level_header->entryCount; ++curr_cnt) {
    unwind_info_regular_second_level_entry *curr_second_level_entry =
      (unwind_info_regular_second_level_entry *)curr_second_level_entry_addr;

    unwind_data->encoding_map[(size_t)module->module_header
                              + curr_second_level_entry->functionOffset] = curr_second_level_entry->encoding;

    curr_second_level_entry_addr += sizeof(unwind_info_regular_second_level_entry);
  }
}

void UnwindGeneratorMacOS::OnModuleLoaded(void *module, char *module_name) {
  if(strcmp(module_name, "libunwind.dylib") == 0) {
    register_frame_addr = (size_t)tinyinst_.GetSymbolAddress(module, (char*)"___register_frame");
    if(!register_frame_addr) {
      FATAL("Error locating __register_frame\n");
    }

    unwind_getip = (size_t)tinyinst_.GetSymbolAddress(module, (char*)"__Unwind_GetIP");
    if(!unwind_getip) {
      FATAL("Error locating __Unwind_GetIP\n");
    }

#ifdef ARM64
    unwind_cursor_getReg = (size_t)tinyinst_.GetSymbolAddress(module, (char*)"__ZN9libunwind12UnwindCursorINS_17LocalAddressSpaceENS_15Registers_arm64EE6getRegEi");
    unwind_cursor_setReg = (size_t)tinyinst_.GetSymbolAddress(module, (char*)"__ZN9libunwind12UnwindCursorINS_17LocalAddressSpaceENS_15Registers_arm64EE6setRegEim");
    unwind_cursor_setInfoBasedOnIPRegister = (size_t)tinyinst_.GetSymbolAddress(module, (char*)"__ZN9libunwind12UnwindCursorINS_17LocalAddressSpaceENS_15Registers_arm64EE24setInfoBasedOnIPRegisterEb");
    if(!unwind_cursor_getReg) {
      FATAL("Error locating unwind_cursor_setReg\n");
    }
    if(!unwind_cursor_setReg) {
      FATAL("Error locating unwind_cursor_setReg\n");
    }
    if(!unwind_cursor_setInfoBasedOnIPRegister) {
      FATAL("Error locating unwind_cursor_setInfoBasedOnIPRegister\n");
    }
#else
    unwind_setip = (size_t)tinyinst_.GetSymbolAddress(module, (char*)"__Unwind_SetIP");
    if(!unwind_setip) {
      FATAL("Error locating __Unwind_SetIP\n");
    }
#endif
  }
}

bool UnwindGeneratorMacOS::HandleBreakpoint(ModuleInfo* module, void *address) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

  if(in_process_lookup) {
    if((size_t)address == unwind_data->personality_breakpoint) {
      size_t ip = tinyinst_.GetRegister(ARCH_IP_VALUE_REGISTER);
      WARN("Unwinding lookup failed for IP %zx", ip);
      return true;
    }
  } else {
    if((size_t)address == unwind_data->personality_breakpoint) {
      size_t ip = tinyinst_.GetRegister(ARCH_IP_VALUE_REGISTER);

      auto it = unwind_data->return_addresses.find(ip);
      if (it != unwind_data->return_addresses.end()) {
#ifdef ARM64
        ip = it->second.original_return_address;
#else
        ip = it->second.original_return_address - 1;
#endif
        size_t personality = it->second.personality;
        tinyinst_.SetRegister(ARCH_IP_VALUE_REGISTER, ip);
        tinyinst_.SetRegister(ARCH_PERSONALITY_VALUE_REGISTER, personality);
        // printf("Set personality to %zx\n", personality);
      } else {
        WARN("Unwinding lookup failed for IP %zx", ip);
      }
      return true;
    }
  }
  
  if((size_t)address == unwind_data->register_breakpoint) {
    tinyinst_.RestoreRegisters(&unwind_data->register_breakpoint_data.saved_registers);
    tinyinst_.SetRegister(ARCH_PC, unwind_data->register_breakpoint_data.continue_ip);
    // printf("Registration done\n");
    return true;
  }
  
  return false;
}

size_t UnwindGeneratorMacOS::WriteFDE(ModuleInfo *module,
                                      size_t cie_address,
                                      size_t min_address,
                                      size_t max_address)
{
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  size_t fde_address = tinyinst_.GetCurrentInstrumentedAddress(module);

  ByteStream fde;
  fde.PutValue<uint32_t>(fde_address - cie_address + 4); // CIE pointer
  fde.PutValue<uint64_t>(min_address);                   // PC start
  fde.PutValue<uint64_t>(max_address - min_address);     // PC range
  fde.PutULEB128Value(0);                                // aug length

  fde.PutValueFront<uint32_t>(fde.size());               // length

  tinyinst_.WriteCode(module, fde.data(), fde.size());
  return fde_address;
}

size_t UnwindGeneratorMacOS::MaybeRedirectExecution(ModuleInfo* module, size_t IP) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  
  if(in_process_lookup) WriteLookupTable(module);
  
  if(unwind_data->registered_fde) {
    return IP;
  }

#ifdef ARM64
  if(!register_frame_addr || !unwind_getip || !unwind_cursor_getReg ||
     !unwind_cursor_setReg || !unwind_cursor_setInfoBasedOnIPRegister) {
#else
  if(!register_frame_addr || !unwind_getip || !unwind_setip) {
#endif
    FATAL("Need to register unwinding data, but the addresses of libunwind functions are still unknown\n");
  }
  
  size_t code_size_before = module->instrumented_code_allocated;

#if ARM64
  AlignCodeMemory(module);
#endif

  size_t personality = WriteCustomPersonality(module);
  size_t cie_address = WriteCIE(module, "zP", personality);
  
  std::vector<size_t> fde_addresses;
  size_t fde_address = WriteFDE(module, cie_address,
                                (size_t)module->instrumented_code_remote,
                                (size_t)module->instrumented_code_remote +
                                module->instrumented_code_size);
  fde_addresses.push_back(fde_address);
  
  size_t fde_array_start = tinyinst_.GetCurrentInstrumentedAddress(module);
  for(auto it = fde_addresses.begin(); it != fde_addresses.end(); it++) {
    tinyinst_.WritePointer(module, *it);
  }
  size_t fde_array_end = tinyinst_.GetCurrentInstrumentedAddress(module);

#if ARM64
  AlignCodeMemory(module);
#endif
 
  // address from which the target will continue execution
  // now it's the same as fde_array_end, but that might change in the future
  // if other stuff gets written before the next line
  size_t continue_address = tinyinst_.GetCurrentInstrumentedAddress(module);

  size_t assembly_offset = module->instrumented_code_allocated;
  
  // write the assembly snippet that calls __register_frame
#ifdef ARM64
  tinyinst_.WriteCode(module,
                      (void*)register_assembly_arm64,
                      sizeof(register_assembly_arm64));
#else
  tinyinst_.WriteCode(module,
                      (void*)register_assembly_x86,
                      sizeof(register_assembly_x86));
#endif
  
  // fill out the missing pieces in the assembly snippet
#ifdef ARM64
  size_t register_assembly_data_offset = register_assembly_arm64_data_offset;
#else
  size_t register_assembly_data_offset = register_assembly_x86_data_offset;
#endif
  tinyinst_.WritePointerAtOffset(module,
                                 fde_array_start,
                                 assembly_offset +
                                 register_assembly_data_offset);
  tinyinst_.WritePointerAtOffset(module,
                                 fde_array_end,
                                 assembly_offset +
                                 register_assembly_data_offset + 8);
  tinyinst_.WritePointerAtOffset(module,
                                 register_frame_addr,
                                 assembly_offset +
                                 register_assembly_data_offset + 16);

  // insert a breakpoint instruction
  size_t breakpoint_address = tinyinst_.GetCurrentInstrumentedAddress(module);
  tinyinst_.assembler_->Breakpoint(module);
  
  // save all registers and register a breakpoint
  // the breakpoint is handled by UnwindGeneratorMacOS::HandleBreakpoint
  SavedRegisters saved_registers;
  tinyinst_.SaveRegisters(&saved_registers);
  unwind_data->register_breakpoint = breakpoint_address;
  unwind_data->register_breakpoint_data = {saved_registers, IP};
  
  // compute how much data we wrote and commit it all to the target process
  size_t code_size_after = module->instrumented_code_allocated;
  tinyinst_.CommitCode(module, code_size_before, (code_size_after - code_size_before));

  // we registered everything we have so far
  unwind_data->registered_fde = true;
  
  // give the target process the address to continue from
  return continue_address;
}

// The custom personality routines invoke the original routines, but before
// doing so, they modify the IP value to point to the original code (instead
// of the instrumented code). This way, the IP is found within the LSDA
// table and the stack unwinding process succeeds.
size_t UnwindGeneratorMacOS::WriteCustomPersonality(ModuleInfo* module) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;
  
  if(in_process_lookup && !unwind_data->lookup_table.header_remote) {
    FATAL("Unwind lookup table not initialized");
  }

  size_t new_personality_addr = tinyinst_.GetCurrentInstrumentedAddress(module);

#ifdef ARM64
  unsigned char assembly_part1[] = {
    0xff, 0x43, 0x02, 0xd1, // sub sp, sp, #0x90
    0xfd, 0x7b, 0x08, 0xa9, // stp fp, lr, [sp, #0x80]
    0xfd, 0x03, 0x00, 0x91, // mov fp, sp
    0xf3, 0x53, 0x07, 0xa9, // stp x19, x20, [sp, #0x70]
    0xf5, 0x5b, 0x06, 0xa9, // stp x21, x22, [sp, #0x60]
    0xf7, 0x63, 0x05, 0xa9, // stp x23, x24, [sp, #0x50]
    0xf9, 0x6b, 0x04, 0xa9, // stp x25, x26, [sp, #0x40]

    // push personality parameters on stack
    0xe0, 0x07, 0x03, 0xa9, // stp x0, x1, [sp, #0x30]
    0xe2, 0x0f, 0x02, 0xa9, // stp x2, x3, [sp, #0x20]
    0xe4, 0x17, 0x01, 0xa9, // stp x4, x5, [sp, #0x10]
    0xe6, 0x1f, 0x00, 0xa9, // stp x6, x7, [sp, #0x00]

    0xd6, 0x02, 0x16, 0xca, // eor x22, x22, x22

    0xd3, 0x00, 0x00, 0x58, // ldr x19, #24; x19 becomes hashtable ptr
    0xf4, 0x00, 0x00, 0x58, // ldr x20, #28; x20 becomes _Unwind_GetIP
    0x15, 0x01, 0x00, 0x58, // ldr x21, #32; x21 becomes libunwind::UnwindCursor::setReg
    0x39, 0x01, 0x00, 0x58, // ldr x25, #36; x25 becomes libunwind::UnwindCursor::getReg
    0x5a, 0x01, 0x00, 0x58, // ldr x26, #40; x26 becomes libunwind::UnwindCursor::setInfoBasedOnIPRegister
    0x0b, 0x00, 0x00, 0x14, // b #0x2c
  };
#else
  unsigned char assembly_part1[] = {
    // function prologue
    0x55, // push rbp
    0x48, 0x89, 0xE5, // mov rbp, rsp
    // save registers we're modifying
    0x53, // push rbx
    0x41, 0x54, // push r12
    0x41, 0x55, // push r13
    0x41, 0x56, // push r14
    0x41, 0x57, // push r15
    0x41, 0x57, // push r15, twice for alignment
    // push personality parameters on stack
    0x57, // push rdi
    0x56, // push rsi
    0x52, // push rdx
    0x51, // push rcx
    0x41, 0x50, // push r8
    0x41, 0x51,  // push r9
    // set up registers we'll need
    0x48, 0x31, 0xDB, // xor rbx, rbx
    0x4C, 0x8B, 0x3D, 0x13, 0x00, 0x00, 0x00, // mov r15, [rip + offset]; r15 becomes hashtable ptr
    0x4C, 0x8B, 0x25, 0x14, 0x00, 0x00, 0x00, // mov r12, [rip + offset]; r12 becomes _Unwind_GetIP
    0x4C, 0x8B, 0x2D, 0x15, 0x00, 0x00, 0x00, // mov r13, [rip + offset]; r13 becomes _Unwind_SetIP
    0xE9, 0x18, 0x00, 0x00, 0x00 // jmp 0x18
  };
#endif

  tinyinst_.WriteCode(module, assembly_part1, sizeof(assembly_part1));
  tinyinst_.WritePointer(module, unwind_data->lookup_table.header_remote);
  tinyinst_.WritePointer(module, unwind_getip);
#ifdef ARM64
  tinyinst_.WritePointer(module, unwind_cursor_setReg);
  tinyinst_.WritePointer(module, unwind_cursor_getReg);
  tinyinst_.WritePointer(module, unwind_cursor_setInfoBasedOnIPRegister);
#else
  tinyinst_.WritePointer(module, unwind_setip);
#endif

#ifdef ARM64
  unsigned char assembly_part2[] = {
    // save the unwinding context in x23 for later
    0xf7, 0x03, 0x04, 0xaa, // mov x23, x4
    0xe0, 0x03, 0x04, 0xaa, // mov x0, x4
    // _Unwind_GetIP(context)
    0x80, 0x02, 0x3f, 0xd6, // blr x20
  };
#else
  unsigned char assembly_part2[] = {
    // save the unwinding context in r14 for later
    0x4D, 0x89, 0xC6, // mov    r14,r8
    // _Unwind_GetIP(context)
    0x4C, 0x89, 0xC7, // mov    rdi,r8
    0x41, 0xFF, 0xD4  // call   r12
  };
#endif
  
  tinyinst_.WriteCode(module, assembly_part2, sizeof(assembly_part2));

  if(!in_process_lookup) {
    size_t breakpoint_address = tinyinst_.GetCurrentInstrumentedAddress(module);
    tinyinst_.assembler_->Breakpoint(module);
    unwind_data->personality_breakpoint = breakpoint_address;
  } else {
    WritePersonalityLookup(module);
  }

#ifdef ARM64
  unsigned char assembly_part3[] = {
    // x0 contains IP
    // x22 contains PERSONALITY_VALUE
    // x23 contains ptr to unwinding context

    // save IP in tmp reg
      0xf8, 0x03, 0x00, 0xaa, // mov x24, x0

    // libunwind::UnwindCursor::getReg(contex, UNW_REG_SP)
      0x21, 0x00, 0x80, 0x12, // mov w1, -2
      0xe0, 0x03, 0x17, 0xaa, // mov x0, x23
      0x20, 0x03, 0x3f, 0xd6, // blr x25

    // sign UNW_REG_IP with UNW_REG_SP as ctx
      0xe2, 0x03, 0x18, 0xaa, // mov x2, x24
      0x02, 0x04, 0xc1, 0xda, // pacib x2, x0

    // libunwind::UnwindCursor::setReg(contex, UNW_REG_IP, value)
      0x01, 0x00, 0x80, 0x12, // mov x1, -1
      0xe0, 0x03, 0x17, 0xaa, // mov x0, x23
      0xa0, 0x02, 0x3f, 0xd6, // blr x21

    // libunwind::UnwindCursor::setInfoBasedOnIPRegister(context, true)
      0x21, 0x00, 0x80, 0xd2, // mov x1, 1
      0xe0, 0x03, 0x17, 0xaa, // mov x0, x23
      0x40, 0x03, 0x3f, 0xd6, // blr x26

    // restore original personality parameters
      0xbf, 0x03, 0x00, 0x91, // mov sp, fp
      0xe0, 0x07, 0x43, 0xa9, // ldp x0, x1, [sp, #0x30]
      0xe2, 0x0f, 0x42, 0xa9, // ldp x2, x3, [sp, #0x20]
      0xe4, 0x17, 0x41, 0xa9, // ldp x4, x5, [sp, #0x10]
      0xe6, 0x1f, 0x40, 0xa9, // ldp x6, x7, [sp, #0x00]

      0x76, 0x00, 0x00, 0xb4, // cbz x22, no_original_personality
      0xc0, 0x02, 0x3f, 0xd6, // blr x22
      0x02, 0x00, 0x00, 0x14, // b end

    // no_original_personality:
      0x00, 0x01, 0x80, 0xd2, // mov x0, 8 (_URC_CONTINUE_UNWIND)

    // end:
      0xbf, 0x03, 0x00, 0x91, // mov sp, fp
      0xf9, 0x6b, 0x44, 0xa9, // ldp x25, x26, [sp, #0x40]
      0xf7, 0x63, 0x45, 0xa9, // ldp x23, x24, [sp, #0x50]
      0xf5, 0x5b, 0x46, 0xa9, // ldp x21, x22, [sp, #0x60]
      0xf3, 0x53, 0x47, 0xa9, // ldp x19, x20, [sp, #0x70]
      0xfd, 0x7b, 0x48, 0xa9, // ldp fp, lr, [sp, #0x80]
      0xff, 0x43, 0x02, 0x91, // add sp, sp, #0x90
      0xc0, 0x03, 0x5f, 0xd6, // ret
  };
#else
  unsigned char assembly_part3[] = {
    // _Unwind_SetIP(context, modified_ip)
    0x4C, 0x89, 0xF7, // mov    rdi,r14
    0x48, 0x89, 0xC6, // mov    rsi,rax
    0x41, 0xFF, 0xD5, // call   r13
    // restore original personality parameters
    0x41, 0x59, // pop r9
    0x41, 0x58, // pop r8
    0x59, // pop rcx
    0x5A, // pop rdx
    0x5E, // pop rsi
    0x5F, // pop rdi
    0x48, 0x85, 0xDB, // test   rbx,rbx
    0x0F, 0x84, 0x07, 0x00, 0x00, 0x00, // je no_original_personality
    // call original personality function
    0xFF, 0xD3, // call rbx
    0xE9, 0x07, 0x00, 0x00, 0x00, // jmp end
    // no_original_personality:
    0x48, 0xC7, 0xC0, 0x08, 0x00, 0x00, 0x00, // mov rax,8 (_URC_CONTINUE_UNWIND )
    // end:
    //restore registers
    0x41, 0x5F, // pop r15
    0x41, 0x5F, // pop r15
    0x41, 0x5E, // pop r14
    0x41, 0x5D, // pop r13
    0x41, 0x5C, // pop r12
    0x5B, // pop rbx
    //function epilogue
    0x48, 0x89, 0xEC, // mov    rsp,rbp
    0x5D, // pop rbp
    0xC3 // ret
  };
#endif

  tinyinst_.WriteCode(module, assembly_part3, sizeof(assembly_part3));

  return new_personality_addr;
}

void UnwindGeneratorMacOS::WritePersonalityLookup(ModuleInfo* module) {
  UnwindDataMacOS *unwind_data = (UnwindDataMacOS *)module->unwind_data;

#ifdef ARM64
  unsigned char arch_specific_assembly[] = {
      0xb8, 0x01, 0x00, 0x18, // ldr w24, bucket_mask
      0x18, 0x03, 0x00, 0x8a, // and x24, x24, x0
      0x73, 0x7a, 0x78, 0xf8, // ldr x19, [x19, x24, LSL#3]
    // loop_start:
      0x33, 0x01, 0x00, 0xb4, // cbz x19, not_found
      0x76, 0x02, 0x40, 0xf9, // ldr x22, [x19]
      0x1f, 0x00, 0x16, 0xeb, // cmp x0, x22
      0x60, 0x00, 0x00, 0x54, // b.eq found
      0x73, 0x0e, 0x40, 0xf9, // ldr x19, [x19, #0x18]
      0xfb, 0xff, 0xff, 0x17, // b loop_start
    // found:
      0x60, 0x06, 0x40, 0xf9, // ldr x0, [x19, #0x8]
      0x76, 0x0a, 0x40, 0xf9, // ldr x22, [x19, #0x10]
      0x03, 0x00, 0x00, 0x14, // b end
    // not_found:
      0x60, 0x00, 0x20, 0xd4, // brk #3
    // bucket_mask:
      0x1f, 0x20, 0x03, 0xd5, // nop -> to be replaced with bucket number mask
    // end:
  };
  size_t mask_offset = sizeof(arch_specific_assembly) - 4;
#else
  unsigned char arch_specific_assembly[] = {
    0x48, 0x89, 0xC1, //mov rcx, rax
    0x48, 0x81, 0xE1, 0xAA, 0xAA, 0xAA, 0x0A, // and rcx,0xaaaaaaa, to be replaced
    0x4D, 0x8B, 0x3C, 0xCF, // mov r15,QWORD PTR [r15+rcx*8]
    // loop_start:
    0x4D, 0x85, 0xFF, // test r15,r15
    0x74, 0x15, //je not_found
    0x49, 0x3B, 0x07, // cmp rax,QWORD PTR [r15]
    0x74, 0x06, // je found
    0x4D, 0x8B, 0x7F, 0x18, // mov r15,QWORD PTR [r15+0x18]
    0xEB, 0xF0, // jmp loop_start
    // found:
    0x49, 0x8B, 0x47, 0x08, // mov rax, QWORD PTR [r15+0x8]
    0x49, 0x8B, 0x5F, 0x10, // mov rbx, QWORD PTR [r15+0x10]
    0xEB, 0x01, // jmp end
    // not_found:
    0xCC // int3
  };
  size_t mask_offset = 6;
#endif
  *(uint32_t *)(&arch_specific_assembly[mask_offset]) = (LOOKUP_TABLE_BUCKETS - 1);
  tinyinst_.WriteCode(module, arch_specific_assembly, sizeof(arch_specific_assembly));
  
  size_t breakpoint_address = (size_t)tinyinst_.GetCurrentInstrumentedAddress(module) - 1;
  unwind_data->personality_breakpoint = breakpoint_address;
}

UnwindDataMacOS::LookupTable::~LookupTable() {
  if(header_local) free(header_local);
}

size_t UnwindGeneratorMacOS::AllocateLookupTableChunk() {
  size_t ret = (size_t)tinyinst_.RemoteAllocate(LOOKUP_TABLE_CHUNK_SIZE);
  if(!ret) {
    FATAL("Error allocating unwinding lookup table. Please run with -unwind_in_process_lookup=0");
  }
  return ret;
}

void UnwindGeneratorMacOS::WriteLookupTable(ModuleInfo* module) {
  UnwindDataMacOS *data = (UnwindDataMacOS *)module->unwind_data;
  UnwindDataMacOS::LookupTable *lookup_table = &data->lookup_table;

  if(!in_process_lookup) return;

  // init if needed
  if(!lookup_table->header_remote) {
    lookup_table->header_remote = AllocateLookupTableChunk();
    lookup_table->header_local = (size_t *)malloc(LOOKUP_TABLE_BUCKETS * sizeof(size_t));
    memset(lookup_table->header_local, 0, LOOKUP_TABLE_BUCKETS * sizeof(size_t));
    lookup_table->buffer_end = lookup_table->header_remote + LOOKUP_TABLE_CHUNK_SIZE;
    lookup_table->buffer_cur = lookup_table->header_remote + LOOKUP_TABLE_BUCKETS * sizeof(size_t);
  }

  // nothing to write
  if(data->return_addresses.empty()) return;
  
  size_t space_left = lookup_table->buffer_end - lookup_table->buffer_cur;
  if(space_left < LOOKUP_TABLE_ELEMENT_SIZE) {
    lookup_table->buffer_cur = AllocateLookupTableChunk();
    lookup_table->buffer_end = lookup_table->buffer_cur + LOOKUP_TABLE_CHUNK_SIZE;
    space_left = LOOKUP_TABLE_CHUNK_SIZE;
  }
  
  unsigned char *remote_buf = (unsigned char *)lookup_table->buffer_cur;
  unsigned char *local_buf = (unsigned char *)malloc(space_left);
  unsigned char *local_buf_cur = local_buf;
  
  for(auto iter = data->return_addresses.begin();
      iter != data->return_addresses.end(); iter++)
  {
    if(space_left < LOOKUP_TABLE_ELEMENT_SIZE) {
      tinyinst_.RemoteWrite((void *)remote_buf,
                            (void *)local_buf,
                            (size_t)(local_buf_cur - local_buf));
      lookup_table->buffer_cur = AllocateLookupTableChunk();
      lookup_table->buffer_end = lookup_table->buffer_cur + LOOKUP_TABLE_CHUNK_SIZE;
      space_left = LOOKUP_TABLE_CHUNK_SIZE;
      free(local_buf);
      remote_buf = (unsigned char *)lookup_table->buffer_cur;
      local_buf = (unsigned char *)malloc(space_left);
      local_buf_cur = local_buf;
    }
    
    size_t instrumented_ip = iter->first;
#ifdef ARM64
    size_t original_ip = iter->second.original_return_address;
#else
    size_t original_ip = iter->second.original_return_address - 1;
#endif
    size_t personality = iter->second.personality;
    size_t hash_bucket = instrumented_ip % LOOKUP_TABLE_BUCKETS;
    size_t previous_head = lookup_table->header_local[hash_bucket];
    
    size_t new_head = lookup_table->buffer_cur;
    lookup_table->header_local[hash_bucket] = new_head;

    // printf("%zx -> %zx\n", instrumented_ip, original_ip);
    
    *((size_t *)local_buf_cur) = instrumented_ip;
    *(((size_t *)local_buf_cur) + 1) = original_ip;
    *(((size_t *)local_buf_cur) + 2) = personality;
    *(((size_t *)local_buf_cur) + 3) = previous_head;
    local_buf_cur += LOOKUP_TABLE_ELEMENT_SIZE;
    lookup_table->buffer_cur += LOOKUP_TABLE_ELEMENT_SIZE;
    space_left -= LOOKUP_TABLE_ELEMENT_SIZE;
  }
  
  // header
  tinyinst_.RemoteWrite((void *)lookup_table->header_remote,
                        (void *)lookup_table->header_local,
                        LOOKUP_TABLE_BUCKETS * sizeof(size_t));
  
  tinyinst_.RemoteWrite((void *)remote_buf,
                        (void *)local_buf,
                        (size_t)(local_buf_cur - local_buf));
  
  // printf("Wrote %zd lookup table entries\n", data->return_addresses.size());
  data->return_addresses.clear();
  free(local_buf);
}


#ifdef ARM64
void UnwindGeneratorMacOS::AlignCodeMemory(ModuleInfo *module) {
  size_t ls2b = module->instrumented_code_allocated & 0x3;
  if(ls2b) {
    uint32_t padding = 0xcccccccc;
    tinyinst_.WriteCode(module, (void*)&padding, 4 - ls2b);
  }
}
#endif
```

`macOS/unwindmacos.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef unwindmacos_h
#define unwindmacos_h

#include <vector>
#include <map>
#include <unordered_map>

#include <stdio.h>
#include "unwind.h"
#include "tinyinst.h"
#include <mach-o/compact_unwind_encoding.h>

#include <third_party/llvm/LEB128.h>

class UnwindDataMacOS: public UnwindData {
public:
  UnwindDataMacOS();
  ~UnwindDataMacOS();

  void *unwind_section_address;
  uint64_t unwind_section_size;
  void *unwind_section_buffer;
  unwind_info_section_header *unwind_section_header;

  std::vector<size_t> personality_vector;
  
  bool registered_fde;

  bool LookupPersonality(size_t ip, size_t *personality);

  struct PersonalityLookup {
    PersonalityLookup() {
      found = false;
      personality = (size_t)(-1);
      min_address = 0;
      max_address = 0;
    }
 
    void Init(bool found,
              size_t personality,
              size_t min_address,
              size_t max_address)
    {
      this->found = found;
      this->personality = personality;
      this->min_address = min_address;
      this->max_address = max_address;
    }

    bool found;
    size_t personality;
    size_t min_address;
    size_t max_address;
  };
  
  PersonalityLookup last_personality_lookup;

  std::map<size_t, compact_unwind_encoding_t> encoding_map;
  
  struct BreakpointData {
    SavedRegisters saved_registers;
    size_t continue_ip;
  };
  
  size_t register_breakpoint;
  BreakpointData register_breakpoint_data;

  size_t personality_breakpoint;

  struct ReturnAddressInfo {
    size_t original_return_address;
    size_t personality;
  };
  
  // Maps the return addresses in the instrumented code (the keys)
  // to the return addresses in the original code (the values).
  std::unordered_map<size_t, ReturnAddressInfo> return_addresses;
  
  class LookupTable {
  public:
    LookupTable() {
      header_local = NULL;
      header_remote = 0;
      buffer_cur = 0;
      buffer_end = 0;
    }
    
    ~LookupTable();

    size_t *header_local;
    size_t header_remote;
    size_t buffer_cur;
    size_t buffer_end;
  };
  
  LookupTable lookup_table;
};

class ByteStream {
private:
  std::vector<uint8_t> byte_stream;

public:
  size_t size() {
    return byte_stream.size();
  }

  uint8_t *data() {
    return byte_stream.data();
  }

  template<typename T>
  void PutValue(T value) {
    for (int i = 0; i < sizeof(T); ++i) {
      byte_stream.push_back((value >> (i * 8)) & 0xff);
    }
  }

  template<typename T>
  void PutValueFront(T value) {
    PutValue(value);
    std::rotate(byte_stream.begin(), byte_stream.end() - sizeof(T), byte_stream.end());
  }

  void PutString(const char *s) {
    for (char *p = (char *)s; *p; p++) {
      byte_stream.push_back(*p);
    }
    byte_stream.push_back(0);
  }

  void PutULEB128Value(uint64_t value) {
    encodeULEB128(value, byte_stream);
  }

  void PutSLEB128Value(int64_t value) {
    encodeSLEB128(value, byte_stream);
  }
};

class UnwindGeneratorMacOS : public UnwindGenerator {
public:
  UnwindGeneratorMacOS(TinyInst& tinyinst) : UnwindGenerator(tinyinst),
                                             register_frame_addr(0),
                                             unwind_getip(0),
#ifdef ARM64
                                             unwind_cursor_setReg(0),
                                             unwind_cursor_setInfoBasedOnIPRegister(0) {}
#else
                                             unwind_setip(0) {}
#endif
  ~UnwindGeneratorMacOS() = default;
  
  void Init(int argc, char **argv) override;

  void OnModuleInstrumented(ModuleInfo* module) override;
  void OnModuleUninstrumented(ModuleInfo* module) override;

  size_t MaybeRedirectExecution(ModuleInfo* module, size_t IP) override;

  void OnModuleLoaded(void *module, char *module_name) override;

  void OnReturnAddress(ModuleInfo *module,
                       size_t original_address,
                       size_t translated_address) override;
  
  bool HandleBreakpoint(ModuleInfo* module, void *address) override;

private:
  void SanityCheckUnwindHeader(ModuleInfo *module);
  void CheckUnwindBufferBounds(ModuleInfo *module, const char *array_description,
                               size_t start_address, size_t end_address);

  void ExtractFirstLevel(ModuleInfo *module);
  void ExtractEncodingsSecondLevel(ModuleInfo *module,
                                   unwind_info_section_header_index_entry *first_level_entry);
  void ExtractEncodingsCompressed(ModuleInfo *module,
                                  unwind_info_section_header_index_entry *first_level_entry,
                                  size_t second_level_page_addr);
  void ExtractEncodingsRegular(ModuleInfo *module,
                               unwind_info_section_header_index_entry *first_level_entry,
                               size_t second_level_page_addr);

  compact_unwind_encoding_t GetCompactEncoding(ModuleInfo *module,
                                               size_t second_level_page_addr,
                                               uint32_t curr_entry_encoding_index);

  void ExtractPersonalityArray(ModuleInfo *module);

  size_t WriteCIE(ModuleInfo *module,
                  const char *augmentation,
                  size_t personality_addr);
  size_t WriteFDE(ModuleInfo *module,
                  size_t cie_address,
                  size_t min_address,
                  size_t max_address);
  
  size_t WriteCustomPersonality(ModuleInfo* module);
  void WritePersonalityLookup(ModuleInfo* module);

  size_t AllocateLookupTableChunk();
  void WriteLookupTable(ModuleInfo* module);

#ifdef ARM64
  void AlignCodeMemory(ModuleInfo *module);
#endif

  size_t register_frame_addr;
  size_t unwind_getip;
#ifdef ARM64
  size_t unwind_cursor_getReg;
  size_t unwind_cursor_setReg;
  size_t unwind_cursor_setInfoBasedOnIPRegister;
#else
  size_t unwind_setip;
#endif
  
  bool in_process_lookup;

#ifdef ARM64
  static constexpr unsigned char register_assembly_arm64[] = {
    // save registers
      0xff, 0xc3, 0x00, 0xd1, // sub sp, sp, #48
      0xe0, 0x4f, 0x02, 0xa9, // stp x0, x19, [sp, #32]
      0xf4, 0x57, 0x01, 0xa9, // stp x20, x21, [sp, #16]
      0xfd, 0x7b, 0x00, 0xa9, // stp fp, lr, [sp, #0]
      0xfd, 0x03, 0x00, 0x91, // mov fp, sp
      0xa0, 0x0f, 0x40, 0x92, // and x0, fp, #0xf
      0x40, 0x00, 0x00, 0xb4, // cbz x0, skip_alignment
      0xff, 0x23, 0x00, 0xd1, // sub sp, sp, #8
    // skip_alignment:
      0x93, 0x00, 0x00, 0x58, // ldr x19, #16; x19 becomes the current array pointer
      0xb4, 0x00, 0x00, 0x58, // ldr x20, #20; x20 becomes the end array pointer
      0xd5, 0x00, 0x00, 0x58, // ldr x21, #24; x21 becomes __register_frame address
      0x09, 0x00, 0x00, 0x14, // b #36; loop
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // array start addr goes here
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // array end addr goes here
      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // __register_frame addr goes here
    // loop:
      0x7f, 0x02, 0x14, 0xeb, // cmp x19, x20
      0xaa, 0x00, 0x00, 0x54, // b.ge loop_end
      0x60, 0x02, 0x40, 0xf9, // ldr x0, [x19]
      0xa0, 0x02, 0x3f, 0xd6, // blr x21
      0x73, 0x22, 0x00, 0x91, // add x19, x19, #8
      0xfb, 0xff, 0xff, 0x17, // b loop
    // loop_end:
      0xbf, 0x03, 0x00, 0x91, // mov sp, fp
      0xfd, 0x7b, 0x40, 0xa9, // ldp fp, lr, [sp, #0]
      0xf4, 0x57, 0x41, 0xa9, // ldp x20, x21, [sp, #16]
      0xe0, 0x4f, 0x42, 0xa9, // ldp x0, x19, [sp, #32]
      0xff, 0xc3, 0x00, 0x91, // add sp, sp, #48
  };
  static const size_t register_assembly_arm64_data_offset = 48;
#else
  static constexpr unsigned char register_assembly_x86[] = {
    // save registers
    0x53, // push   rbx
    0x41, 0x54, // push   r12
    0x41, 0x55, // push   r13
    // save rbp, rsp
    0x55, // push rbp
    0x48, 0x89, 0xE5, // mov rbp, rsp
    // fix stack alignment
    0x48, 0xF7, 0xC4, 0x0F, 0x00, 0x00, 0x00, // test   rsp,0xf
    0x0F, 0x84, 0x02, 0x00, 0x00, 0x00, // je skip_alignment
    //0x0F, 0x85, 0x02, 0x00, 0x00, 0x00, // jne skip_alignment
    0x6A, 0x00, // push 0
    // load parameters
    0x48, 0x8B, 0x1D, 0x13, 0x00, 0x00, 0x00, // mov rbx, [rip + offset]; rbx becomes the current array pointer
    0x4C, 0x8B, 0x25, 0x14, 0x00, 0x00, 0x00, // mov r12, [rip + offset]; r12 becomes the end array pointer
    0x4C, 0x8B, 0x2D, 0x15, 0x00, 0x00, 0x00, // mov r13, [rip + offset]; r13 becomes __register_frame address
    0xE9, 0x18, 0x00, 0x00, 0x00, // jmp 0x18
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // array start addr goes here
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // array end addr goes here
    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // __register_frame addr goes here
    // loop start
    0x4C, 0x39, 0xE3, // cmp rbx, r12
    0x0F, 0x83, 0x0F, 0x00, 0x00, 0x00, // JAE 0x0F (loop end)
    0x48, 0x8B, 0x3B, // mov rdi, [rbx]
    0x41, 0xFF, 0xD5, // call r13
    0x48, 0x83, 0xC3, 0x08, // add rbx, 8
    0xE9, 0xe8, 0xff, 0xff, 0xff, // jmp to loop start
    //restore rsp, rbp
    0x48, 0x89, 0xEC, // mov    rsp,rbp
    0x5D, // pop rbp
    // restore registers
    0x41, 0x5D, // pop    r13
    0x41, 0x5C, // pop    r12
    0x5B, // pop    rbx
  };

  static const size_t register_assembly_x86_data_offset = 50;
#endif
};

#endif /* unwindmacos_h */

```

`third_party/CMakeLists.txt`:

```txt
# Copyright 2020 Google LLC
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     https://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

cmake_minimum_required(VERSION "3.1")
set (CMAKE_CXX_STANDARD 17)

if (${ARCHITECTURE} MATCHES arm64)
project("reil")
add_library(reil STATIC
    reil/reil/aarch64/decoder.cpp
    reil/reil/aarch64/printer.cpp
    reil/reil/aarch64/decoder.h
)
target_include_directories(reil PUBLIC
  reil/
)

else()
project("xed")

find_package (Python3 REQUIRED)

set(XED_INTERFACE_H ${CMAKE_CURRENT_BINARY_DIR}/obj/wkit/include/xed/xed-interface.h)

if (WIN32) 
  set(XED_LIB ${CMAKE_CURRENT_BINARY_DIR}/obj/wkit/lib/xed.lib)
elseif (APPLE)
  set(XED_LIB ${CMAKE_CURRENT_BINARY_DIR}/obj/wkit/lib/libxed.a)
endif()

if("${CMAKE_SIZEOF_VOID_P}" STREQUAL "4")
  set(XED_HOST_CPU "--host-cpu=ia32")
else()
  set(XED_HOST_CPU "")
endif()

# Attempt to fix building XED on VS2022 and later
# Because having a custom build system is just awesome :-/
if(MSVC_VERSION AND (MSVC_VERSION GREATER 1929))
  get_filename_component(VS_BIN_PATH "${CMAKE_C_COMPILER}" DIRECTORY)
  set(VS_LIB_EXE "${VS_BIN_PATH}/lib.exe")
  set(XED_ADDITONAL_FLAGS --cc ${CMAKE_C_COMPILER} --cxx ${CMAKE_CXX_COMPILER} --linker ${CMAKE_LINKER} --ar ${VS_LIB_EXE})
else()
  set(XED_ADDITONAL_FLAGS "")
endif()

set (BUILD_XED_COMMAND
     ${Python3_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/xed/mfile.py ${XED_HOST_CPU} ${XED_ADDITONAL_FLAGS}
)

if (WIN32)
  add_custom_command(
    OUTPUT ${XED_LIB} ${XED_INTERFACE_H}
    COMMAND ${BUILD_XED_COMMAND}
    COMMENT "Building Xed"
  )
elseif (APPLE)
  add_custom_command(
    OUTPUT ${XED_LIB} ${XED_INTERFACE_H}
    COMMAND ${BUILD_XED_COMMAND}
    COMMAND ranlib ${XED_LIB}
    COMMENT "Building Xed"
  )
endif()

add_custom_target(
  xed
  DEPENDS ${XED_LIB} ${XED_INTERFACE_H}
)
endif()

```

`third_party/llvm/LEB128.h`:

```h
//===- llvm/Support/LEB128.h - [SU]LEB128 utility functions -----*- C++ -*-===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
//
// This file declares some utility functions for encoding SLEB128 and
// ULEB128 values.
//
//===----------------------------------------------------------------------===//

#ifndef LLVM_SUPPORT_LEB128_H
#define LLVM_SUPPORT_LEB128_H

#include <vector>

/// Utility function to encode a value into SLEB128 and store it in a byte stream.
inline void encodeSLEB128(int64_t Value, std::vector<uint8_t> &byte_stream,
                              unsigned PadTo = 0) {
  unsigned Count = 0;
  bool More;
  do {
    uint8_t Byte = Value & 0x7f;
    // NOTE: this assumes that this signed shift is an arithmetic right shift.
    Value >>= 7;
    More = !((((Value == 0 ) && ((Byte & 0x40) == 0)) ||
              ((Value == -1) && ((Byte & 0x40) != 0))));
    Count++;
    if (More || Count < PadTo)
      Byte |= 0x80; // Mark this byte to show that more bytes will follow.
    byte_stream.push_back(Byte);
  } while (More);

  // Pad with 0x80 and emit a terminating byte at the end.
  if (Count < PadTo) {
    uint8_t PadValue = Value < 0 ? 0x7f : 0x00;
    for (; Count < PadTo - 1; ++Count)
      byte_stream.push_back(PadValue | 0x80);
    byte_stream.push_back(PadValue);
  }
}

/// Utility function to encode a value into ULEB128 and store it in a byte stream.
inline void encodeULEB128(uint64_t Value, std::vector<uint8_t> &byte_stream,
                              unsigned PadTo = 0) {
  unsigned Count = 0;
  do {
    uint8_t Byte = Value & 0x7f;
    Value >>= 7;
    Count++;
    if (Value != 0 || Count < PadTo)
      Byte |= 0x80; // Mark this byte to show that more bytes will follow.
    byte_stream.push_back(Byte);
  } while (Value != 0);

  // Pad with 0x80 and emit a null byte at the end.
  if (Count < PadTo) {
    for (; Count < PadTo - 1; ++Count)
      byte_stream.push_back('\x80');
    byte_stream.push_back('\x00');
  }
}

#endif // LLVM_SUPPORT_LEB128_H

```

`third_party/llvm/LICENSE.TXT`:

```TXT
==============================================================================
The LLVM Project is under the Apache License v2.0 with LLVM Exceptions:
==============================================================================

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

    1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

    2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

    3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

    4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

    5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

    6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

    7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

    8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

    9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

    END OF TERMS AND CONDITIONS

    APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

    Copyright [yyyy] [name of copyright owner]

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.


---- LLVM Exceptions to the Apache 2.0 License ----

As an exception, if, as a result of your compiling your source code, portions
of this Software are embedded into an Object form of such source code, you
may redistribute such embedded portions in such Object form without complying
with the conditions of Sections 4(a), 4(b) and 4(d) of the License.

In addition, if you combine or link compiled forms of this Software with
software that is licensed under the GPLv2 ("Combined Software") and if a
court of competent jurisdiction determines that the patent provision (Section
3), the indemnity provision (Section 9) or other Section of the License
conflicts with the conditions of the GPLv2, you may retroactively and
prospectively choose to deem waived or otherwise exclude such Section(s) of
the License, but only in their entirety and only with respect to the Combined
Software.

==============================================================================
Software from third parties included in the LLVM Project:
==============================================================================
The LLVM Project contains third party software which is under different license
terms. All such code will be identified clearly using at least one of two
mechanisms:
1) It will be in a separate directory tree with its own `LICENSE.txt` or
   `LICENSE` file at the top containing the specific license and restrictions
   which apply to that software, or
2) It will contain specific license and restriction terms at the top of every
   file.

==============================================================================
Legacy LLVM License (https://llvm.org/docs/DeveloperPolicy.html#legacy):
==============================================================================

The libunwind library is dual licensed under both the University of Illinois
"BSD-Like" license and the MIT license.  As a user of this code you may choose
to use it under either license.  As a contributor, you agree to allow your code
to be used under both.

Full text of the relevant licenses is included below.

==============================================================================

University of Illinois/NCSA
Open Source License

Copyright (c) 2009-2019 by the contributors listed in CREDITS.TXT

All rights reserved.

Developed by:

    LLVM Team

    University of Illinois at Urbana-Champaign

    http://llvm.org

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal with
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

    * Redistributions of source code must retain the above copyright notice,
      this list of conditions and the following disclaimers.

    * Redistributions in binary form must reproduce the above copyright notice,
      this list of conditions and the following disclaimers in the
      documentation and/or other materials provided with the distribution.

    * Neither the names of the LLVM Team, University of Illinois at
      Urbana-Champaign, nor the names of its contributors may be used to
      endorse or promote products derived from this Software without specific
      prior written permission.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE
SOFTWARE.

==============================================================================

Copyright (c) 2009-2014 by the contributors listed in CREDITS.TXT

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
```

`third_party/llvm/libunwind/CompactUnwinder.hpp`:

```hpp
//===-------------------------- CompactUnwinder.hpp -----------------------===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//
//  Does runtime stack unwinding using compact unwind encodings.
//
//===----------------------------------------------------------------------===//

#ifndef __COMPACT_UNWINDER_HPP__
#define __COMPACT_UNWINDER_HPP__

#define EXTRACT_BITS(value, mask)                                              \
  ((value >> __builtin_ctz(mask)) & (((1 << __builtin_popcount(mask))) - 1))

#endif // __COMPACT_UNWINDER_HPP__

```

`third_party/llvm/libunwind/dwarf2.h`:

```h
//===------------------------------- dwarf2.h -----------------------------===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//


/*
   These constants were taken from version 3 of the DWARF standard,
   which is Copyright (c) 2005 Free Standards Group, and
   Copyright (c) 1992, 1993 UNIX International, Inc.
*/

#ifndef __DWARF2__
#define __DWARF2__

// DWARF unwind instructions
enum {
  DW_CFA_nop                 = 0x0,
  DW_CFA_set_loc             = 0x1,
  DW_CFA_advance_loc1        = 0x2,
  DW_CFA_advance_loc2        = 0x3,
  DW_CFA_advance_loc4        = 0x4,
  DW_CFA_offset_extended     = 0x5,
  DW_CFA_restore_extended    = 0x6,
  DW_CFA_undefined           = 0x7,
  DW_CFA_same_value          = 0x8,
  DW_CFA_register            = 0x9,
  DW_CFA_remember_state      = 0xA,
  DW_CFA_restore_state       = 0xB,
  DW_CFA_def_cfa             = 0xC,
  DW_CFA_def_cfa_register    = 0xD,
  DW_CFA_def_cfa_offset      = 0xE,
  DW_CFA_def_cfa_expression  = 0xF,
  DW_CFA_expression         = 0x10,
  DW_CFA_offset_extended_sf = 0x11,
  DW_CFA_def_cfa_sf         = 0x12,
  DW_CFA_def_cfa_offset_sf  = 0x13,
  DW_CFA_val_offset         = 0x14,
  DW_CFA_val_offset_sf      = 0x15,
  DW_CFA_val_expression     = 0x16,
  DW_CFA_advance_loc        = 0x40, // high 2 bits are 0x1, lower 6 bits are delta
  DW_CFA_offset             = 0x80, // high 2 bits are 0x2, lower 6 bits are register
  DW_CFA_restore            = 0xC0, // high 2 bits are 0x3, lower 6 bits are register

  // GNU extensions
  DW_CFA_GNU_window_save              = 0x2D,
  DW_CFA_GNU_args_size                = 0x2E,
  DW_CFA_GNU_negative_offset_extended = 0x2F,

  // AARCH64 extensions
  DW_CFA_AARCH64_negate_ra_state      = 0x2D
};


// FSF exception handling Pointer-Encoding constants
// Used in CFI augmentation by GCC
enum {
  DW_EH_PE_ptr       = 0x00,
  DW_EH_PE_uleb128   = 0x01,
  DW_EH_PE_udata2    = 0x02,
  DW_EH_PE_udata4    = 0x03,
  DW_EH_PE_udata8    = 0x04,
  DW_EH_PE_signed    = 0x08,
  DW_EH_PE_sleb128   = 0x09,
  DW_EH_PE_sdata2    = 0x0A,
  DW_EH_PE_sdata4    = 0x0B,
  DW_EH_PE_sdata8    = 0x0C,
  DW_EH_PE_absptr    = 0x00,
  DW_EH_PE_pcrel     = 0x10,
  DW_EH_PE_textrel   = 0x20,
  DW_EH_PE_datarel   = 0x30,
  DW_EH_PE_funcrel   = 0x40,
  DW_EH_PE_aligned   = 0x50,
  DW_EH_PE_indirect  = 0x80,
  DW_EH_PE_omit      = 0xFF
};


// DWARF expressions
enum {
  DW_OP_addr               = 0x03, // constant address (size target specific)
  DW_OP_deref              = 0x06,
  DW_OP_const1u            = 0x08, // 1-byte constant
  DW_OP_const1s            = 0x09, // 1-byte constant
  DW_OP_const2u            = 0x0A, // 2-byte constant
  DW_OP_const2s            = 0x0B, // 2-byte constant
  DW_OP_const4u            = 0x0C, // 4-byte constant
  DW_OP_const4s            = 0x0D, // 4-byte constant
  DW_OP_const8u            = 0x0E, // 8-byte constant
  DW_OP_const8s            = 0x0F, // 8-byte constant
  DW_OP_constu             = 0x10, // ULEB128 constant
  DW_OP_consts             = 0x11, // SLEB128 constant
  DW_OP_dup                = 0x12,
  DW_OP_drop               = 0x13,
  DW_OP_over               = 0x14,
  DW_OP_pick               = 0x15, // 1-byte stack index
  DW_OP_swap               = 0x16,
  DW_OP_rot                = 0x17,
  DW_OP_xderef             = 0x18,
  DW_OP_abs                = 0x19,
  DW_OP_and                = 0x1A,
  DW_OP_div                = 0x1B,
  DW_OP_minus              = 0x1C,
  DW_OP_mod                = 0x1D,
  DW_OP_mul                = 0x1E,
  DW_OP_neg                = 0x1F,
  DW_OP_not                = 0x20,
  DW_OP_or                 = 0x21,
  DW_OP_plus               = 0x22,
  DW_OP_plus_uconst        = 0x23, // ULEB128 addend
  DW_OP_shl                = 0x24,
  DW_OP_shr                = 0x25,
  DW_OP_shra               = 0x26,
  DW_OP_xor                = 0x27,
  DW_OP_skip               = 0x2F, // signed 2-byte constant
  DW_OP_bra                = 0x28, // signed 2-byte constant
  DW_OP_eq                 = 0x29,
  DW_OP_ge                 = 0x2A,
  DW_OP_gt                 = 0x2B,
  DW_OP_le                 = 0x2C,
  DW_OP_lt                 = 0x2D,
  DW_OP_ne                 = 0x2E,
  DW_OP_lit0               = 0x30, // Literal 0
  DW_OP_lit1               = 0x31, // Literal 1
  DW_OP_lit2               = 0x32, // Literal 2
  DW_OP_lit3               = 0x33, // Literal 3
  DW_OP_lit4               = 0x34, // Literal 4
  DW_OP_lit5               = 0x35, // Literal 5
  DW_OP_lit6               = 0x36, // Literal 6
  DW_OP_lit7               = 0x37, // Literal 7
  DW_OP_lit8               = 0x38, // Literal 8
  DW_OP_lit9               = 0x39, // Literal 9
  DW_OP_lit10              = 0x3A, // Literal 10
  DW_OP_lit11              = 0x3B, // Literal 11
  DW_OP_lit12              = 0x3C, // Literal 12
  DW_OP_lit13              = 0x3D, // Literal 13
  DW_OP_lit14              = 0x3E, // Literal 14
  DW_OP_lit15              = 0x3F, // Literal 15
  DW_OP_lit16              = 0x40, // Literal 16
  DW_OP_lit17              = 0x41, // Literal 17
  DW_OP_lit18              = 0x42, // Literal 18
  DW_OP_lit19              = 0x43, // Literal 19
  DW_OP_lit20              = 0x44, // Literal 20
  DW_OP_lit21              = 0x45, // Literal 21
  DW_OP_lit22              = 0x46, // Literal 22
  DW_OP_lit23              = 0x47, // Literal 23
  DW_OP_lit24              = 0x48, // Literal 24
  DW_OP_lit25              = 0x49, // Literal 25
  DW_OP_lit26              = 0x4A, // Literal 26
  DW_OP_lit27              = 0x4B, // Literal 27
  DW_OP_lit28              = 0x4C, // Literal 28
  DW_OP_lit29              = 0x4D, // Literal 29
  DW_OP_lit30              = 0x4E, // Literal 30
  DW_OP_lit31              = 0x4F, // Literal 31
  DW_OP_reg0               = 0x50, // Contents of reg0
  DW_OP_reg1               = 0x51, // Contents of reg1
  DW_OP_reg2               = 0x52, // Contents of reg2
  DW_OP_reg3               = 0x53, // Contents of reg3
  DW_OP_reg4               = 0x54, // Contents of reg4
  DW_OP_reg5               = 0x55, // Contents of reg5
  DW_OP_reg6               = 0x56, // Contents of reg6
  DW_OP_reg7               = 0x57, // Contents of reg7
  DW_OP_reg8               = 0x58, // Contents of reg8
  DW_OP_reg9               = 0x59, // Contents of reg9
  DW_OP_reg10              = 0x5A, // Contents of reg10
  DW_OP_reg11              = 0x5B, // Contents of reg11
  DW_OP_reg12              = 0x5C, // Contents of reg12
  DW_OP_reg13              = 0x5D, // Contents of reg13
  DW_OP_reg14              = 0x5E, // Contents of reg14
  DW_OP_reg15              = 0x5F, // Contents of reg15
  DW_OP_reg16              = 0x60, // Contents of reg16
  DW_OP_reg17              = 0x61, // Contents of reg17
  DW_OP_reg18              = 0x62, // Contents of reg18
  DW_OP_reg19              = 0x63, // Contents of reg19
  DW_OP_reg20              = 0x64, // Contents of reg20
  DW_OP_reg21              = 0x65, // Contents of reg21
  DW_OP_reg22              = 0x66, // Contents of reg22
  DW_OP_reg23              = 0x67, // Contents of reg23
  DW_OP_reg24              = 0x68, // Contents of reg24
  DW_OP_reg25              = 0x69, // Contents of reg25
  DW_OP_reg26              = 0x6A, // Contents of reg26
  DW_OP_reg27              = 0x6B, // Contents of reg27
  DW_OP_reg28              = 0x6C, // Contents of reg28
  DW_OP_reg29              = 0x6D, // Contents of reg29
  DW_OP_reg30              = 0x6E, // Contents of reg30
  DW_OP_reg31              = 0x6F, // Contents of reg31
  DW_OP_breg0              = 0x70, // base register 0 + SLEB128 offset
  DW_OP_breg1              = 0x71, // base register 1 + SLEB128 offset
  DW_OP_breg2              = 0x72, // base register 2 + SLEB128 offset
  DW_OP_breg3              = 0x73, // base register 3 + SLEB128 offset
  DW_OP_breg4              = 0x74, // base register 4 + SLEB128 offset
  DW_OP_breg5              = 0x75, // base register 5 + SLEB128 offset
  DW_OP_breg6              = 0x76, // base register 6 + SLEB128 offset
  DW_OP_breg7              = 0x77, // base register 7 + SLEB128 offset
  DW_OP_breg8              = 0x78, // base register 8 + SLEB128 offset
  DW_OP_breg9              = 0x79, // base register 9 + SLEB128 offset
  DW_OP_breg10             = 0x7A, // base register 10 + SLEB128 offset
  DW_OP_breg11             = 0x7B, // base register 11 + SLEB128 offset
  DW_OP_breg12             = 0x7C, // base register 12 + SLEB128 offset
  DW_OP_breg13             = 0x7D, // base register 13 + SLEB128 offset
  DW_OP_breg14             = 0x7E, // base register 14 + SLEB128 offset
  DW_OP_breg15             = 0x7F, // base register 15 + SLEB128 offset
  DW_OP_breg16             = 0x80, // base register 16 + SLEB128 offset
  DW_OP_breg17             = 0x81, // base register 17 + SLEB128 offset
  DW_OP_breg18             = 0x82, // base register 18 + SLEB128 offset
  DW_OP_breg19             = 0x83, // base register 19 + SLEB128 offset
  DW_OP_breg20             = 0x84, // base register 20 + SLEB128 offset
  DW_OP_breg21             = 0x85, // base register 21 + SLEB128 offset
  DW_OP_breg22             = 0x86, // base register 22 + SLEB128 offset
  DW_OP_breg23             = 0x87, // base register 23 + SLEB128 offset
  DW_OP_breg24             = 0x88, // base register 24 + SLEB128 offset
  DW_OP_breg25             = 0x89, // base register 25 + SLEB128 offset
  DW_OP_breg26             = 0x8A, // base register 26 + SLEB128 offset
  DW_OP_breg27             = 0x8B, // base register 27 + SLEB128 offset
  DW_OP_breg28             = 0x8C, // base register 28 + SLEB128 offset
  DW_OP_breg29             = 0x8D, // base register 29 + SLEB128 offset
  DW_OP_breg30             = 0x8E, // base register 30 + SLEB128 offset
  DW_OP_breg31             = 0x8F, // base register 31 + SLEB128 offset
  DW_OP_regx               = 0x90, // ULEB128 register
  DW_OP_fbreg              = 0x91, // SLEB128 offset
  DW_OP_bregx              = 0x92, // ULEB128 register followed by SLEB128 offset
  DW_OP_piece              = 0x93, // ULEB128 size of piece addressed
  DW_OP_deref_size         = 0x94, // 1-byte size of data retrieved
  DW_OP_xderef_size        = 0x95, // 1-byte size of data retrieved
  DW_OP_nop                = 0x96,
  DW_OP_push_object_addres = 0x97,
  DW_OP_call2              = 0x98, // 2-byte offset of DIE
  DW_OP_call4              = 0x99, // 4-byte offset of DIE
  DW_OP_call_ref           = 0x9A, // 4- or 8-byte offset of DIE
  DW_OP_lo_user            = 0xE0,
  DW_OP_APPLE_uninit       = 0xF0,
  DW_OP_hi_user            = 0xFF
};


#endif

```

`third_party/reil/reil/aarch64/decoder.cpp`:

```cpp
// Copyright 2018 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include "reil/aarch64/decoder.h"

#include <cstdint>
#include <tuple>

namespace reil {
namespace aarch64 {
namespace decoder {

static constexpr uint32_t bits(uint32_t opcode, uint8_t lsb, uint8_t msb) {
  return (opcode & ((0xffffffffu >> (32 - (msb - lsb + 1))) << lsb)) >> lsb;
}

static constexpr uint32_t bit(uint32_t opcode, uint8_t lsb) {
  return (opcode >> lsb) & 1;
}

static uint64_t sign_extend_bits(uint32_t opcode, uint8_t lsb, uint8_t msb) {
  uint32_t mask = (0xffffffffu >> (32 - (msb - lsb + 1))) << lsb;
  uint64_t sign_mask = 0;
  if ((opcode >> msb) & 1) {
    sign_mask = (0xffffffffffffffffull << (msb - lsb + 1));
  }
  return sign_mask | ((opcode & mask) >> lsb);
}

static Register v(uint8_t size, uint32_t opcode, uint8_t lsb, uint8_t msb) {
  return Register(size, static_cast<Register::Name>(Register::kV0 +
                                                    bits(opcode, lsb, msb)));
}

static Register x(uint8_t size, uint32_t opcode, uint8_t lsb, uint8_t msb) {
  return Register(size, static_cast<Register::Name>(bits(opcode, lsb, msb)));
}

static Register x_or_sp(uint8_t size, uint32_t opcode, uint8_t lsb,
                        uint8_t msb) {
  if (bits(opcode, lsb, msb) == 31) {
    return Register(size, Register::Name::kSp);
  } else {
    return Register(size, static_cast<Register::Name>(bits(opcode, lsb, msb)));
  }
}

static std::tuple<uint64_t, uint64_t> decode_bit_masks(uint64_t immN,
                                                       uint64_t imms,
                                                       uint64_t immr,
                                                       bool immediate) {
  // imms + 1 bits of 1, rotated by immr, then replicated to the target size.

  uint64_t element_size = 0;
  uint64_t element_mask = 0;
  if (immN) {
    element_size = 64;
    element_mask = 0xffffffffffffffffull;
  } else {
    element_size = 32;
    while (element_size >= 2 && !(element_size & (~imms))) {
      element_size >>= 1;
    }
    element_mask = (1ull << element_size) - 1;
  }

  uint64_t s = imms & (element_size - 1);
  uint64_t r = immr & (element_size - 1);
  uint64_t d = (s - r) & (element_size - 1);

  // TODO: validation for valid values?

  uint64_t welement = 0xffffffffffffffffull >> (64 - (s + 1));
  if (r != 0) {
    uint64_t welement_left = (welement << (element_size - r)) & element_mask;
    uint64_t welement_right = welement >> r;
    welement = welement_left | welement_right;
  }
  uint64_t telement = 0xffffffffffffffffull >> (64 - (d + 1));

  // always replicate to 64-bits and truncate later.
  uint64_t wmask = welement;
  uint64_t tmask = telement;
  while (element_size && element_size < 64) {
    wmask |= (wmask << element_size);
    tmask |= (tmask << element_size);
    element_size <<= 1;
  }

  return {wmask, tmask};
}

static Instruction UnallocatedEncoding() {
  Instruction insn;
  insn.opcode = kUnallocated;
  return insn;
}

static Instruction DecodePcRelativeAddressing(uint32_t opcode);
static Instruction DecodeAddSubtractImmediate(uint32_t opcode);
static Instruction DecodeLogicalImmediate(uint32_t opcode);
static Instruction DecodeMoveWideImmediate(uint32_t opcode);
static Instruction DecodeBitfield(uint32_t opcode);
static Instruction DecodeExtract(uint32_t opcode);

inline Instruction DecodeDataProcessingImmediate(uint32_t opcode) {
  uint32_t op0 = bits(opcode, 23, 25);
  if ((op0 & 0b110) == 0b000) {
    return DecodePcRelativeAddressing(opcode);
  } else if ((op0 & 0b110) == 0b010) {
    return DecodeAddSubtractImmediate(opcode);
  } else if (op0 == 0b100) {
    return DecodeLogicalImmediate(opcode);
  } else if (op0 == 0b101) {
    return DecodeMoveWideImmediate(opcode);
  } else if (op0 == 0b110) {
    return DecodeBitfield(opcode);
  } else if (op0 == 0b111) {
    return DecodeExtract(opcode);
  }

  return UnallocatedEncoding();
}

static Instruction DecodePcRelativeAddressing(uint32_t opcode) {
  Instruction insn;

  if (bit(opcode, 31)) {
    insn.opcode = kAdrp;
  } else {
    insn.opcode = kAdr;
  }

  insn.operands.push_back(x(64, opcode, 0, 4));
  insn.operands.push_back(Immediate(
      64, (sign_extend_bits(opcode, 5, 23) << 2) | bits(opcode, 29, 30)));

  Shift shift(Shift::kNone, 0);
  if (insn.opcode == kAdrp) {
    shift.type = Shift::kLsl;
    shift.count = 12;
  }

  insn.operands.push_back(shift);

  return insn;
}

static Instruction DecodeAddSubtractImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  insn.set_flags = bit(opcode, 29);
  if (bit(opcode, 30)) {
    insn.opcode = kSubImmediate;
  } else {
    insn.opcode = kAddImmediate;
  }

  if (insn.set_flags) {
    insn.operands.push_back(x(size, opcode, 0, 4));
  } else {
    insn.operands.push_back(x_or_sp(size, opcode, 0, 4));
  }

  insn.operands.push_back(x_or_sp(size, opcode, 5, 9));
  insn.operands.push_back(Immediate(size, bits(opcode, 10, 21)));

  Shift shift(Shift::kNone, 0);
  if (bits(opcode, 22, 23) == 1) {
    shift.type = Shift::kLsl;
    shift.count = 12;
  }

  insn.operands.push_back(shift);

  return insn;
}

static Instruction DecodeLogicalImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  switch (bits(opcode, 29, 30)) {
    case 0b00: {
      insn.opcode = kAndImmediate;
    } break;

    case 0b01: {
      insn.opcode = kOrrImmediate;
    } break;

    case 0b10: {
      insn.opcode = kEorImmediate;
    } break;

    case 0b11: {
      insn.opcode = kAndImmediate;
      insn.set_flags = true;
    } break;
  }

  if (insn.set_flags) {
    insn.operands.push_back(x(size, opcode, 0, 4));
  } else {
    insn.operands.push_back(x_or_sp(size, opcode, 0, 4));
  }

  insn.operands.push_back(x(size, opcode, 5, 9));

  uint64_t value, _;
  std::tie(value, _) = decode_bit_masks(bit(opcode, 22), bits(opcode, 10, 15),
                                        bits(opcode, 16, 21), true);

  insn.operands.push_back(Immediate(size, value));

  return insn;
}

static Instruction DecodeMoveWideImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  // check that the shift value is in range
  if (bits(opcode, 21, 22) << 4 >= size) {
    return UnallocatedEncoding();
  }

  switch (bits(opcode, 29, 30)) {
    case 0b00: {
      insn.opcode = kMovn;
    } break;

    case 0b10: {
      insn.opcode = kMovz;
    } break;

    case 0b11: {
      insn.opcode = kMovk;
    } break;

    default:
      return UnallocatedEncoding();
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(Immediate(size, bits(opcode, 5, 20)));
  insn.operands.push_back(Shift(Shift::kLsl, bits(opcode, 21, 22) << 4));

  return insn;
}

static Instruction DecodeBitfield(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bit(opcode, 22) != bit(opcode, 31)) {
    return UnallocatedEncoding();
  }

  switch (bits(opcode, 29, 30)) {
    case 0b00: {
      insn.opcode = kSbfm;
    } break;

    case 0b01: {
      insn.opcode = kBfm;
    } break;

    case 0b10: {
      insn.opcode = kUbfm;
    } break;

    default:
      return UnallocatedEncoding();
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  insn.operands.push_back(Immediate(size, bits(opcode, 16, 21)));
  insn.operands.push_back(Immediate(size, bits(opcode, 10, 15)));

  return insn;
}

static Instruction DecodeExtract(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bit(opcode, 22) != bit(opcode, 31)) {
    return UnallocatedEncoding();
  }

  insn.opcode = kExtr;

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  insn.operands.push_back(x(size, opcode, 16, 20));
  insn.operands.push_back(Immediate(8, bits(opcode, 10, 15)));

  return insn;
}

static Instruction DecodeConditionalBranch(uint32_t opcode);
static Instruction DecodeExceptionGeneration(uint32_t opcode);
static Instruction DecodeSystem(uint32_t opcode);
static Instruction DecodeBranchRegister(uint32_t opcode);
static Instruction DecodeBranchImmediate(uint32_t opcode);
static Instruction DecodeCompareAndBranch(uint32_t opcode);
static Instruction DecodeTestAndBranch(uint32_t opcode);

static Instruction DecodeBranchExceptionGeneratingSystem(uint32_t opcode) {
  uint32_t op0 = bits(opcode, 29, 31);
  uint32_t op1 = bits(opcode, 22, 25);
  if (op0 == 0b010) {
    if ((op1 & 0b1000) == 0b0000) {
      return DecodeConditionalBranch(opcode);
    }
  } else if (op0 == 0b110) {
    if ((op1 & 0b1100) == 0b0000) {
      return DecodeExceptionGeneration(opcode);
    } else if (op1 == 0b0100) {
      return DecodeSystem(opcode);
    } else if ((op1 & 0b1000) == 0b1000) {
      return DecodeBranchRegister(opcode);
    }
  } else if ((op0 & 0b011) == 0b000) {
    return DecodeBranchImmediate(opcode);
  } else if ((op0 & 0b011) == 0b001) {
    if ((op1 & 0b1000) == 0b0000) {
      return DecodeCompareAndBranch(opcode);
    } else {
      return DecodeTestAndBranch(opcode);
    }
  }

  return UnallocatedEncoding();
}

static Instruction DecodeConditionalBranch(uint32_t opcode) {
  Instruction insn;

  insn.opcode = kBCond;
  insn.cc = (ConditionCode)bits(opcode, 0, 3);

  if (bit(opcode, 24) || bit(opcode, 4)) {
    return UnallocatedEncoding();
  }

  insn.operands.push_back(Immediate(64, sign_extend_bits(opcode, 5, 23) << 2));

  return insn;
}

static Instruction DecodeExceptionGeneration(uint32_t opcode) {
  Instruction insn;

  uint8_t opc = bits(opcode, 21, 23);
  uint8_t ll = bits(opcode, 0, 1);

  if (bits(opcode, 2, 4)) {
    return UnallocatedEncoding();
  }

  if (opc == 0b000) {
    if (ll == 0b01) {  // SVC
      insn.opcode = kSvc;
    } else if (ll == 0b10) {  // HVC
      insn.opcode = kHvc;
    } else if (ll == 0b11) {  // SMC
      insn.opcode = kSmc;
    } else {
      return UnallocatedEncoding();
    }
  } else if (opc == 0b001) {
    if (ll == 0b00) {  // BRK
      insn.opcode = kBrk;
    } else {
      return UnallocatedEncoding();
    }
  } else if (opc == 0b010) {
    if (ll == 0b00) {  // HLT
      insn.opcode = kHlt;
    } else {
      return UnallocatedEncoding();
    }
  } else if (opc == 0b101) {
    if (ll == 0b01) {  // DCPS1
      insn.opcode = kDcps1;
    } else if (ll == 0b10) {  // DCPS2
      insn.opcode = kDcps2;
    } else if (ll == 0b11) {  // DCPS3
      insn.opcode = kDcps3;
    } else {
      return UnallocatedEncoding();
    }
  } else {
    return UnallocatedEncoding();
  }

  insn.operands.push_back(Immediate(32, bits(opcode, 5, 20)));

  return insn;
}

static Instruction DecodeSystem(uint32_t opcode) {
  Instruction insn;

  uint8_t l = bit(opcode, 21);
  uint8_t op0 = bits(opcode, 19, 20);
  uint8_t op1 = bits(opcode, 16, 18);
  uint8_t op2 = bits(opcode, 5, 7);
  uint8_t crn = bits(opcode, 12, 15);
  uint8_t crm = bits(opcode, 8, 11);
  uint8_t rt = bits(opcode, 0, 4);

  uint8_t imm = bits(opcode, 5, 11);

  if (!l) {
    if (op0 == 0b00) {
      if (crn == 0b0100 && rt == 0b11111) {  // MSR (immediate)
        insn.opcode = kMsr;
        switch (op1 << 3 | op2) {
          case 0b000101: {
            insn.operands.push_back(SystemRegister(SystemRegister::kSPSel));
          } break;

          case 0b011110: {
            insn.operands.push_back(SystemRegister(SystemRegister::kDAIFSet));
          } break;

          case 0b011111: {
            insn.operands.push_back(SystemRegister(SystemRegister::kDAIFClr));
          } break;

          case 0b000011: {
            insn.operands.push_back(SystemRegister(SystemRegister::kUAO));
          } break;

          case 0b000100: {
            insn.operands.push_back(SystemRegister(SystemRegister::kPAN));
          } break;

          default:
            return UnallocatedEncoding();
        }
        insn.operands.push_back(Immediate(8, crm));
      } else if (op1 == 0b011) {
        if (crn == 0b0010) {
          switch (imm) {
            case 0b0000000: {  // NOP
              insn.opcode = kNop;
            } break;

            case 0b0000001: {  // YIELD
              insn.opcode = kYield;
            } break;

            case 0b0000010: {  // WFE
              insn.opcode = kWfe;
            } break;

            case 0b0000011: {  // WFI
              insn.opcode = kWfi;
            } break;

            case 0b0000100: {  // SEV
              insn.opcode = kSev;
            } break;

            case 0b0000101: {  // SEVL
              insn.opcode = kSevl;
            } break;

            case 0b0000111: {  // XPACLRI
              insn.opcode = kXpaclri;
            } break;

            case 0b0001000: {  // PACIA1716
              insn.opcode = kPacia1716;
            } break;

            case 0b0001010: {  // PACIB1716
              insn.opcode = kPacib1716;
            } break;

            case 0b0001100: {  // AUTIA1716
              insn.opcode = kAutia1716;
            } break;

            case 0b0001110: {  // AUTIA1716
              insn.opcode = kAutib1716;
            } break;

            case 0b0010000: {  // ESB
              insn.opcode = kEsb;
            } break;

            case 0b0010001: {  // PSB CSYNC
              insn.opcode = kPsbCsync;
            } break;

            case 0b0011000: {  // PACIAZ
              insn.opcode = kPaciaz;
            } break;

            case 0b0011001: {  // PACIASP
              insn.opcode = kPaciasp;
            } break;

            case 0b0011010: {  // PACIBZ
              insn.opcode = kPacibz;
            } break;

            case 0b0011011: {  // PACIBSP
              insn.opcode = kPacibsp;
            } break;

            case 0b0011100: {  // AUTIAZ
              insn.opcode = kAutiaz;
            } break;

            case 0b0011101: {  // AUTIASP
              insn.opcode = kAutiasp;
            } break;

            case 0b0011110: {  // AUTIBZ
              insn.opcode = kAutibz;
            } break;

            case 0b0011111: {  // AUTIBSP
              insn.opcode = kAutibsp;
            } break;

            default: {  // HINT
              insn.opcode = kHint;
              insn.operands.push_back(Immediate(8, crm));
            } break;
          }
        } else if (crn == 0b0011) {
          if (op2 == 0b010) {  // CLREX
            insn.opcode = kClrex;
          } else if (op2 == 0b100) {  // DSB
            insn.opcode = kDsb;
            insn.operands.push_back(Immediate(8, crm));
          } else if (op2 == 0b101) {  // DMB
            insn.opcode = kDmb;
            insn.operands.push_back(Immediate(8, crm));
          } else if (op2 == 0b110) {  // ISB
            insn.opcode = kIsb;
            insn.operands.push_back(Immediate(8, crm));
          } else {
            return UnallocatedEncoding();
          }
        }
      }
    } else if (op0 == 0b01) {  // SYS
      insn.opcode = kSys;
      insn.operands.push_back(Immediate(8, op1));
      insn.operands.push_back(Immediate(8, crn));
      insn.operands.push_back(Immediate(8, crm));
      insn.operands.push_back(Immediate(8, op2));
      insn.operands.push_back(x(64, opcode, 0, 4));
    } else if (op0) {  // MSR (register)
      insn.opcode = kMsr;
      insn.operands.push_back(SystemRegister(op0, op1, op2, crn, crm));
      insn.operands.push_back(x(64, opcode, 0, 4));
    }
  } else {
    if (op0 == 0b01) {  // SYSL
      insn.opcode = kSysl;
      insn.operands.push_back(x(64, opcode, 0, 4));
      insn.operands.push_back(Immediate(8, op1));
      insn.operands.push_back(Immediate(8, crn));
      insn.operands.push_back(Immediate(8, crm));
      insn.operands.push_back(Immediate(8, op2));
    } else if (op0) {  // MRS
      insn.opcode = kMrs;
      insn.operands.push_back(x(64, opcode, 0, 4));
      insn.operands.push_back(SystemRegister(op0, op1, op2, crn, crm));
    } else {
      return UnallocatedEncoding();
    }
  }
  return insn;
}

static Instruction DecodeBranchRegister(uint32_t opcode) {
  Instruction insn;

  uint8_t opc = bits(opcode, 21, 24);
  uint8_t op2 = bits(opcode, 16, 20);
  uint8_t op3 = bits(opcode, 10, 15);
  uint8_t op4 = bits(opcode, 0, 4);

  insn.operands.push_back(x(64, opcode, 5, 9));

  if (op2 != 0b11111 ||
      (op3 != 0b000000 && op3 != 0b000010 && op3 != 0b000011)) {
    return UnallocatedEncoding();
  }

  if (opc == 0b0000) {  // BR
    if (op3) {
      if (op3 == 0b000010 && op4 == 0b11111) {
        insn.opcode = kBraaz;
      } else if (op3 == 0b000011 && op4 == 0b11111) {
        insn.opcode = kBrabz;
      } else {
        return UnallocatedEncoding();
      }
    } else {
      insn.opcode = kBr;
    }
  } else if (opc == 0b0001) {  // BLR
    if (op3) {
      if (op3 == 0b000010 && op4 == 0b11111) {
        insn.opcode = kBlraaz;
      } else if (op3 == 0b000011 && op4 == 0b11111) {
        insn.opcode = kBlrabz;
      } else {
        return UnallocatedEncoding();
      }
    }
    insn.opcode = kBlr;
  } else if (opc == 0b0010) {  // RET
    if (op3) {
      if (op3 == 0b000010 && op4 == 0b11111) {
        insn.opcode = kRetaa;
      } else if (op3 == 0b000011 && op4 == 0b11111) {
        insn.opcode = kRetab;
      } else {
        return UnallocatedEncoding();
      }
    } else {
      insn.opcode = kRet;
    }
  } else if (opc == 0b0100) {  // ERET
    if (op3) {
      if (op3 == 0b000010 && op4 == 0b11111) {
        insn.opcode = kEretaa;
      } else if (op3 == 0b000011 && op4 == 0b11111) {
        insn.opcode = kEretab;
      } else {
        return UnallocatedEncoding();
      }
    } else {
      insn.opcode = kEret;
    }
  } else if (opc == 0b0101) {  // DRPS
    insn.opcode = kDrps;
  } else if (opc == 0b1000) {  // BRA*
    if (op3 == 0b000010) {
      insn.opcode = kBraa;
    } else if (op3 == 0b000011) {
      insn.opcode = kBrab;
    } else {
      return UnallocatedEncoding();
    }
    insn.operands.push_back(x_or_sp(64, opcode, 0, 4));
  } else if (opc == 0b1001) {  // BLRA*
    if (op3 == 0b000010) {
      insn.opcode = kBlraa;
    } else if (op3 == 0b000011) {
      insn.opcode = kBlrab;
    } else {
      return UnallocatedEncoding();
    }
    insn.operands.push_back(x_or_sp(64, opcode, 0, 4));
  } else {
    return UnallocatedEncoding();
  }

  return insn;
}

static Instruction DecodeBranchImmediate(uint32_t opcode) {
  Instruction insn;

  insn.operands.push_back(Immediate(64, sign_extend_bits(opcode, 0, 25) << 2));

  if (bit(opcode, 31)) {
    insn.opcode = kBl;
  } else {
    insn.opcode = kB;
  }

  return insn;
}

static Instruction DecodeCompareAndBranch(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (!bit(opcode, 24)) {
    insn.opcode = kCbz;
  } else {
    insn.opcode = kCbnz;
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(Immediate(64, sign_extend_bits(opcode, 5, 23) << 2));

  return insn;
}

static Instruction DecodeTestAndBranch(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (!bit(opcode, 24)) {
    insn.opcode = kTbz;
  } else {
    insn.opcode = kTbnz;
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(
      Immediate(64, (bit(opcode, 31) << 5) | bits(opcode, 19, 23)));
  insn.operands.push_back(Immediate(64, sign_extend_bits(opcode, 5, 18) << 2));

  return insn;
}

static Instruction DecodeSIMDLoadLiteral(uint32_t opcode);
static Instruction DecodeSIMDLoadStorePair(uint32_t opcode);
static Instruction DecodeSIMDLoadStoreUnscaledImmediate(uint32_t opcode);
static Instruction DecodeSIMDLoadStoreRegisterOffset(uint32_t opcode);
static Instruction DecodeSIMDLoadStoreUnsignedImmediate(uint32_t opcode);

static Instruction DecodeLoadStoreExclusive(uint32_t opcode);
static Instruction DecodeLoadLiteral(uint32_t opcode);
static Instruction DecodeLoadStorePair(uint32_t opcode);
static Instruction DecodeLoadStoreUnscaledImmediate(uint32_t opcode);
static Instruction DecodeLoadStoreRegisterOffset(uint32_t opcode);
static Instruction DecodeLoadStoreUnsignedImmediate(uint32_t opcode);

static Instruction DecodeLoadStore(uint32_t opcode) {
  // uint8_t op0 = bit(opcode, 31);
  uint8_t op1 = bits(opcode, 28, 29);
  uint8_t op2 = bit(opcode, 26);
  uint8_t op3 = bits(opcode, 23, 24);
  uint8_t op4 = bits(opcode, 16, 21);
  uint8_t op5 = bits(opcode, 10, 11);

  if (op2 == 0b1) {
    // SIMD instructions
    if (op1 == 0b01 && ((op3 & 0b10) == 0b00)) {
      return DecodeSIMDLoadLiteral(opcode);
    } else if (op1 == 0b10) {
      return DecodeSIMDLoadStorePair(opcode);
    } else if (op1 == 0b11) {
      if ((op3 & 0b10) == 0b00) {
        if ((op4 & 0b100000) == 0b000000) {
          return DecodeSIMDLoadStoreUnscaledImmediate(opcode);
        } else if ((op4 & 0b100000) == 0b100000 && op5 == 0b10) {
          return DecodeSIMDLoadStoreRegisterOffset(opcode);
        }
      } else {
        return DecodeSIMDLoadStoreUnsignedImmediate(opcode);
      }
    }
  } else {
    // Scalar instructions
    if (op1 == 0b00 && op2 == 0b0 && ((op3 & 0b10) == 0b00)) {
      return DecodeLoadStoreExclusive(opcode);
    } else if (op1 == 0b01 && ((op3 & 0b10) == 0b00)) {
      return DecodeLoadLiteral(opcode);
    } else if (op1 == 0b10) {
      return DecodeLoadStorePair(opcode);
    } else if (op1 == 0b11) {
      if ((op3 & 0b10) == 0b00) {
        if ((op4 & 0b100000) == 0b000000) {
          return DecodeLoadStoreUnscaledImmediate(opcode);
        } else if ((op4 & 0b100000) == 0b100000 && op5 == 0b10) {
          return DecodeLoadStoreRegisterOffset(opcode);
        }
      } else {
        return DecodeLoadStoreUnsignedImmediate(opcode);
      }
    }
  }

  return UnallocatedEncoding();
}

static Instruction DecodeSIMDLoadLiteral(uint32_t opcode) {
  Instruction insn;
  insn.opcode = kSimdLdrLiteral;

  uint8_t opc = bits(opcode, 30, 31);
  uint8_t size = 32 << opc;

  if (opc == 0b11) {
    return UnallocatedEncoding();
  }

  insn.operands.push_back(v(size, opcode, 0, 4));
  Register base = Register(64, Register::kPc);
  Immediate offset = Immediate(64, sign_extend_bits(opcode, 5, 23) << 2);
  Shift shift = Shift(Shift::kNone, 0);

  insn.operands.push_back(ImmediateOffset(base, offset, shift, size));

  return insn;
}

static Instruction DecodeSIMDLoadStorePair(uint32_t opcode) {
  Instruction insn;

  uint8_t opc = bits(opcode, 30, 31);
  uint8_t size = 32 << opc;
  uint8_t op3 = bits(opcode, 23, 24);
  uint8_t load = bit(opcode, 22);

  if (opc == 0b11) {
    return UnallocatedEncoding();
  }

  insn.operands.push_back(v(size, opcode, 0, 4));
  insn.operands.push_back(v(size, opcode, 10, 14));

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset =
      Immediate(64, sign_extend_bits(opcode, 15, 21) << (2 + bit(opcode, 31)));
  Shift shift(Shift::kNone, 0);

  ImmediateOffset address(base, offset, shift, size * 2);

  if (load) {
    insn.opcode = kSimdLdp;

    if (op3 == 0b00) {  // LDNP
      insn.opcode = kSimdLdnp;
    } else if (op3 == 0b01) {  // LDP (post-indexed)
      address.writeback = true;
      address.post_index = true;
    } else if (op3 == 0b10) {  // LDP (offset)
      address.writeback = false;
      address.post_index = false;
    } else if (op3 == 0b11) {  // LDP (pre-indexed)
      address.writeback = true;
      address.post_index = false;
    }
  } else {
    insn.opcode = kSimdStp;

    if (op3 == 0b00) {  // STNP
      insn.opcode = kSimdStnp;
    } else if (op3 == 0b01) {  // STP (post-indexed)
      address.writeback = true;
      address.post_index = true;
    } else if (op3 == 0b10) {  // STP (offset)
      address.writeback = false;
      address.post_index = false;
    } else if (op3 == 0b11) {  // STP (pre-indexed)
      address.writeback = true;
      address.post_index = false;
    }
  }

  insn.operands.push_back(address);

  return insn;
}

static Instruction DecodeSIMDLoadStoreUnscaledImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 8 << ((bit(opcode, 23) << 2) | bits(opcode, 30, 31));

  if (bit(opcode, 22)) {
    insn.opcode = kSimdLdr;
  } else {
    insn.opcode = kSimdStr;
  }

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset = Immediate(64, sign_extend_bits(opcode, 12, 20));
  Shift shift(Shift::kNone, 0);

  ImmediateOffset address(base, offset, shift, size);

  switch (bits(opcode, 10, 11)) {
    case 0b00: {  // unscaled immediate
      if (insn.opcode == kSimdStr) {
        insn.opcode = kSimdStur;
      } else if (insn.opcode == kSimdLdr) {
        insn.opcode = kSimdLdur;
      }
    } break;

    case 0b01: {  // immediate post-indexed
      address.writeback = true;
      address.post_index = true;
    } break;

    case 0b10: {  // unprivileged
      if (insn.opcode == kStr) {
        insn.opcode = kSttr;
      } else if (insn.opcode == kLdr) {
        insn.opcode = kLdtr;
      }
    } break;

    case 0b11: {  // immediate pre-indexed
      address.writeback = true;
      address.post_index = false;
    } break;
  }

  insn.operands.push_back(v(size, opcode, 0, 4));
  insn.operands.push_back(address);

  return insn;
}

static Instruction DecodeSIMDLoadStoreRegisterOffset(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 8 << ((bit(opcode, 23) << 2) | bits(opcode, 30, 31));

  if (bit(opcode, 22)) {
    insn.opcode = kSimdLdr;
  } else {
    insn.opcode = kSimdStr;
  }

  Register base = x_or_sp(64, opcode, 5, 9);
  Register offset = x(64, opcode, 16, 20);
  Extend extend(Extend::kNone, bit(opcode, 12) ? bits(opcode, 30, 31) : 0);

  switch (bits(opcode, 13, 15)) {
    case 0b010: {  // UXTW
      extend.type = Extend::kUxtw;
    } break;

    case 0b011: {  // LSL
      extend.type = Extend::kLsl;
    } break;

    case 0b110: {  // SXTW
      extend.type = Extend::kSxtw;
    } break;

    case 0b111: {  // SXTX
      extend.type = Extend::kSxtx;
    } break;

    default:
      return UnallocatedEncoding();
  }

  insn.operands.push_back(v(size, opcode, 0, 4));
  insn.operands.push_back(RegisterOffset(base, offset, extend, size));

  return insn;
}

static Instruction DecodeSIMDLoadStoreUnsignedImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 8 << ((bit(opcode, 23) << 2) | bits(opcode, 30, 31));

  if (bit(opcode, 22)) {
    insn.opcode = kSimdLdr;
  } else {
    insn.opcode = kSimdStr;
  }

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset =
      Immediate(64, bits(opcode, 10, 21) << bits(opcode, 30, 31));
  Shift shift(Shift::kNone, 0);

  insn.operands.push_back(v(size, opcode, 0, 4));
  insn.operands.push_back(ImmediateOffset(base, offset, shift, size));

  return insn;
}

static Instruction DecodeLoadStoreExclusive(uint32_t opcode) {
  Instruction insn;

  uint8_t size = 8 << bits(opcode, 30, 31);

  uint8_t o2_1_o1_o0 = (bits(opcode, 21, 23) << 1) | bit(opcode, 15);

  // TODO: fix these UnallocatedEncodings - need to test on hardware, seems to
  // be a difference between documentation and assembler...
  // uint8_t rt = bits(opcode, 16, 20);
  // if (o1 && o2 && rt != 0b11111) {
  //   return UnallocatedEncoding();
  // }
  // if (size < 32 && o1 && rt != 0b11111) {
  //   return UnallocatedEncoding();
  // }

  switch (o2_1_o1_o0) {
    case 0b0000: {
      insn.opcode = kStxr;
    } break;

    case 0b0001: {
      insn.opcode = kStlxr;
    } break;

    case 0b0010: {
      if (size < 32) {
        insn.opcode = kCasp;
        size <<= 1;
      } else {
        insn.opcode = kStxp;
      }
    } break;

    case 0b0011: {
      if (size < 32) {
        insn.opcode = kCaspl;
        size <<= 1;
      } else {
        insn.opcode = kStlxp;
      }
    } break;

    case 0b0100: {
      insn.opcode = kLdxr;
    } break;

    case 0b0101: {
      insn.opcode = kLdaxr;
    } break;

    case 0b0110: {
      if (size < 32) {
        insn.opcode = kCaspa;
        size <<= 1;
      } else {
        insn.opcode = kLdxp;
      }
    } break;

    case 0b0111: {
      if (size < 32) {
        insn.opcode = kCaspal;
        size <<= 1;
      } else {
        insn.opcode = kLdaxp;
      }
    } break;

    case 0b1000: {
      insn.opcode = kStllr;
    } break;

    case 0b1001: {
      insn.opcode = kStlr;
    } break;

    case 0b1010: {
      insn.opcode = kCas;
    } break;

    case 0b1011: {
      insn.opcode = kCasl;
    } break;

    case 0b1100: {
      insn.opcode = kLdlar;
    } break;

    case 0b1101: {
      insn.opcode = kLdar;
    } break;

    case 0b1110: {
      insn.opcode = kCasa;
    } break;

    case 0b1111: {
      insn.opcode = kCasal;
    } break;
  }

  if (insn.opcode == kStxr || insn.opcode == kStxp || insn.opcode == kStlxp ||
      insn.opcode == kStlxr) {
    insn.operands.push_back(x(32, opcode, 16, 20));
  } else if (insn.opcode == kCas || insn.opcode == kCasa ||
             insn.opcode == kCasal || insn.opcode == kCasl) {
    insn.operands.push_back(x(size, opcode, 16, 20));
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  if (insn.opcode == kCasp || insn.opcode == kCaspa || insn.opcode == kCaspal ||
      insn.opcode == kCaspal) {
    // TODO: duplicate w(s+1) and w(t+1)
  }
  if (insn.opcode == kLdxp || insn.opcode == kLdaxp || insn.opcode == kStxp ||
      insn.opcode == kStlxp) {
    insn.operands.push_back(x(size, opcode, 10, 14));
  }

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset = Immediate(64, 0);
  Shift shift = Shift(Shift::kNone, 0);

  if (insn.opcode == kLdxp || insn.opcode == kLdaxp || insn.opcode == kStxp ||
      insn.opcode == kStlxp) {
    insn.operands.push_back(ImmediateOffset(base, offset, shift, size * 2));
  } else {
    insn.operands.push_back(ImmediateOffset(base, offset, shift, size));
  }

  return insn;
}

static Instruction DecodeLoadLiteral(uint32_t opcode) {
  Instruction insn;

  uint8_t size = 64;
  uint8_t opc = bits(opcode, 30, 31);

  if (opc == 0b00) {  // LDR (literal) 32-bit
    insn.opcode = kLdrLiteral;
    size = 32;
  } else if (opc == 0b01) {  // LDR (literal) 64-bit
    insn.opcode = kLdrLiteral;
  } else if (opc == 0b10) {  // LDRSW (literal)
    insn.opcode = kLdrsLiteral;
    size = 32;
  } else if (opc == 0b11) {  // PRFM (literal)
    insn.opcode = kPrfmLiteral;
  }

  if (insn.opcode == kPrfmLiteral) {
    insn.operands.push_back(Immediate(8, bits(opcode, 0, 4)));
  } else if (insn.opcode == kLdrLiteral && size == 32) {
    insn.operands.push_back(x(32, opcode, 0, 4));
  } else {
    insn.operands.push_back(x(64, opcode, 0, 4));
  }

  Register base = Register(64, Register::kPc);
  Immediate offset = Immediate(64, sign_extend_bits(opcode, 5, 23) << 2);
  Shift shift = Shift(Shift::kNone, 0);

  insn.operands.push_back(ImmediateOffset(base, offset, shift, size));

  return insn;
}

static Instruction DecodeLoadStorePair(uint32_t opcode) {
  Instruction insn;

  uint8_t size = 32 << bit(opcode, 31);
  uint8_t opc = bits(opcode, 30, 31);
  uint8_t op3 = bits(opcode, 23, 24);
  uint8_t load = bit(opcode, 22);

  if (opc == 0b11) {
    return UnallocatedEncoding();
  }

  if ((opc & 0b01) == 0b01 && !load) {
    return UnallocatedEncoding();
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 10, 14));

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset =
      Immediate(64, sign_extend_bits(opcode, 15, 21) << (2 + bit(opcode, 31)));
  Shift shift(Shift::kNone, 0);

  ImmediateOffset address(base, offset, shift, size * 2);

  if (load) {
    if ((opc & 0b01) == 0b01) {  // LDPSW
      insn.opcode = kLdpsw;
    } else {
      insn.opcode = kLdp;
    }

    if (op3 == 0b00) {  // LDNP
      insn.opcode = kLdnp;
    } else if (op3 == 0b01) {  // LDP (post-indexed)
      address.writeback = true;
      address.post_index = true;
    } else if (op3 == 0b10) {  // LDP (offset)
      address.writeback = false;
      address.post_index = false;
    } else if (op3 == 0b11) {  // LDP (pre-indexed)
      address.writeback = true;
      address.post_index = false;
    }
  } else {
    insn.opcode = kStp;

    if (op3 == 0b00) {  // STNP
      insn.opcode = kStnp;
    } else if (op3 == 0b01) {  // STP (post-indexed)
      address.writeback = true;
      address.post_index = true;
    } else if (op3 == 0b10) {  // STP (offset)
      address.writeback = false;
      address.post_index = false;
    } else if (op3 == 0b11) {  // STP (pre-indexed)
      address.writeback = true;
      address.post_index = false;
    }
  }

  insn.operands.push_back(address);

  return insn;
}

static void DecodeLoadStoreOpcode(uint32_t opcode, Instruction& insn) {
  uint8_t size = 8 << bits(opcode, 30, 31);

  switch (bits(opcode, 22, 23)) {
    case 0b00: {  // ST*R/B/H
      insn.opcode = kStr;
      insn.operands.push_back(x(size < 64 ? 32 : 64, opcode, 0, 4));
    } break;

    case 0b01: {  // LD*R/B/H
      insn.opcode = kLdr;
      insn.operands.push_back(x(size < 64 ? 32 : 64, opcode, 0, 4));
    } break;

    case 0b10: {         // LD*RS/B/H 64-bit variant
      if (size == 64) {  // PRFM
        insn.opcode = kPrfm;
        insn.operands.push_back(Immediate(8, bits(opcode, 0, 4)));
      } else {
        insn.opcode = kLdrs;
        insn.operands.push_back(x(64, opcode, 0, 4));
      }
    } break;

    case 0b11: {  // LD*RS/B/H 32-bit variant
      insn.opcode = kLdrs;
      insn.operands.push_back(x(32, opcode, 0, 4));
    } break;
  }
}

static Instruction DecodeLoadStoreUnscaledImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 8 << bits(opcode, 30, 31);

  DecodeLoadStoreOpcode(opcode, insn);

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset = Immediate(64, sign_extend_bits(opcode, 12, 20));
  Shift shift(Shift::kNone, 0);

  ImmediateOffset address(base, offset, shift, size);

  switch (bits(opcode, 10, 11)) {
    case 0b00: {  // unscaled immediate
      if (insn.opcode == kStr) {
        insn.opcode = kStur;
      } else if (insn.opcode == kLdr) {
        insn.opcode = kLdur;
      } else if (insn.opcode == kLdrs) {
        insn.opcode = kLdurs;
      }
    } break;

    case 0b01: {  // immediate post-indexed
      address.writeback = true;
      address.post_index = true;
    } break;

    case 0b10: {  // unprivileged
      if (insn.opcode == kStr) {
        insn.opcode = kSttr;
      } else if (insn.opcode == kLdr) {
        insn.opcode = kLdtr;
      } else if (insn.opcode == kLdrs) {
        insn.opcode = kLdtrs;
      }
    } break;

    case 0b11: {  // immediate pre-indexed
      address.writeback = true;
      address.post_index = false;
    } break;
  }

  insn.operands.push_back(address);

  return insn;
}

static Instruction DecodeLoadStoreRegisterOffset(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 8 << bits(opcode, 30, 31);

  DecodeLoadStoreOpcode(opcode, insn);

  Register base = x_or_sp(64, opcode, 5, 9);
  Register offset = x(64, opcode, 16, 20);
  Extend extend(Extend::kNone, bit(opcode, 12) ? bits(opcode, 30, 31) : 0);

  switch (bits(opcode, 13, 15)) {
    case 0b010: {  // UXTW
      extend.type = Extend::kUxtw;
    } break;

    case 0b011: {  // LSL
      extend.type = Extend::kLsl;
    } break;

    case 0b110: {  // SXTW
      extend.type = Extend::kSxtw;
    } break;

    case 0b111: {  // SXTX
      extend.type = Extend::kSxtx;
    } break;

    default:
      return UnallocatedEncoding();
  }

  insn.operands.push_back(RegisterOffset(base, offset, extend, size));

  return insn;
}

static Instruction DecodeLoadStoreUnsignedImmediate(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 8 << bits(opcode, 30, 31);

  DecodeLoadStoreOpcode(opcode, insn);

  Register base = x_or_sp(64, opcode, 5, 9);
  Immediate offset =
      Immediate(64, bits(opcode, 10, 21) << bits(opcode, 30, 31));
  Shift shift(Shift::kNone, 0);

  insn.operands.push_back(ImmediateOffset(base, offset, shift, size));

  return insn;
}

static Instruction DecodeDataProcessingTwoSource(uint32_t opcode);
static Instruction DecodeDataProcessingOneSource(uint32_t opcode);
static Instruction DecodeLogicalShiftedRegister(uint32_t opcode);
static Instruction DecodeAddSubtractShiftedRegister(uint32_t opcode);
static Instruction DecodeAddSubtractExtendedRegister(uint32_t opcode);
static Instruction DecodeAddSubtractWithCarry(uint32_t opcode);
static Instruction DecodeConditionalCompare(uint32_t opcode);
static Instruction DecodeConditionalSelect(uint32_t opcode);
static Instruction DecodeDataProcessingThreeSource(uint32_t opcode);

static Instruction DecodeDataProcessingRegister(uint32_t opcode) {
  uint8_t op0 = bit(opcode, 30);
  uint8_t op1 = bit(opcode, 28);
  uint8_t op2 = bits(opcode, 21, 24);
  // uint8_t op3 = bit(opcode, 11);

  if (op1) {
    if (op2 == 0b0000) {
      return DecodeAddSubtractWithCarry(opcode);
    } else if (op2 == 0b0010) {
      return DecodeConditionalCompare(opcode);
    } else if (op2 == 0b0100) {
      return DecodeConditionalSelect(opcode);
    } else if (op2 == 0b0110) {
      if (!op0) {
        return DecodeDataProcessingTwoSource(opcode);
      } else {
        return DecodeDataProcessingOneSource(opcode);
      }
    } else if ((op2 & 0b1000) == 0b1000) {
      return DecodeDataProcessingThreeSource(opcode);
    }
  } else {
    if ((op2 & 0b1000) == 0b0000) {
      return DecodeLogicalShiftedRegister(opcode);
    } else if ((op2 & 0b1001) == 0b1000) {
      return DecodeAddSubtractShiftedRegister(opcode);
    } else {
      return DecodeAddSubtractExtendedRegister(opcode);
    }
  }

  return UnallocatedEncoding();
}

static Instruction DecodeDataProcessingTwoSource(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);
  uint8_t opc = bits(opcode, 10, 15);

  if (bit(opcode, 29)) {
    return UnallocatedEncoding();
  }

  switch (opc) {
    case 0b000010: {
      insn.opcode = kUdiv;
    } break;

    case 0b000011: {
      insn.opcode = kSdiv;
    } break;

    case 0b001000: {
      insn.opcode = kLsl;
    } break;

    case 0b001001: {
      insn.opcode = kLsr;
    } break;

    case 0b001010: {
      insn.opcode = kAsr;
    } break;

    case 0b001011: {
      insn.opcode = kRor;
    } break;

    case 0b001100: {
      insn.opcode = kPacga;
    } break;

    case 0b010000: {
      insn.opcode = kCrc32b;
    } break;

    case 0b010001: {
      insn.opcode = kCrc32h;
    } break;

    case 0b010010: {
      insn.opcode = kCrc32w;
    } break;

    case 0b010011: {
      insn.opcode = kCrc32x;
    } break;

    case 0b010100: {
      insn.opcode = kCrc32cb;
    } break;

    case 0b010101: {
      insn.opcode = kCrc32ch;
    } break;

    case 0b010110: {
      insn.opcode = kCrc32cw;
    } break;

    case 0b010111: {
      insn.opcode = kCrc32cx;
    } break;

    default: { return UnallocatedEncoding(); }
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  if (insn.opcode != kPacga) {
    insn.operands.push_back(x(size, opcode, 16, 20));
  } else {
    insn.operands.push_back(x_or_sp(size, opcode, 16, 20));
  }

  return insn;
}

static Instruction DecodeDataProcessingOneSource(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  uint8_t opc = bits(opcode, 10, 15);
  uint8_t opc2 = bits(opcode, 16, 20);

  if (bit(opcode, 29) || opc2 > 1) {
    return UnallocatedEncoding();
  }

  if (opc2 == 0) {
    switch (opc) {
      case 0b000000: {
        insn.opcode = kRbit;
      } break;

      case 0b000001: {
        insn.opcode = kRev16;
      } break;

      case 0b000010: {
        if (size == 64) {
          insn.opcode = kRev32;
        } else {
          insn.opcode = kRev;
        }
      } break;

      case 0b000011: {
        if (size == 32) {
          return UnallocatedEncoding();
        }
        insn.opcode = kRev;
      } break;

      case 0b000100: {
        insn.opcode = kClz;
      } break;

      case 0b000101: {
        insn.opcode = kCls;
      } break;

      default:
        return UnallocatedEncoding();
    }

    insn.operands.push_back(x(size, opcode, 0, 4));
    insn.operands.push_back(x(size, opcode, 5, 9));
  } else {
    if (size != 64) {
      return UnallocatedEncoding();
    }

    insn.operands.push_back(x(size, opcode, 0, 4));
    if (opc & 0b011000) {
      if (bits(opcode, 5, 9) != 0b11111) {
        return UnallocatedEncoding();
      }
      insn.operands.push_back(x(size, opcode, 5, 9));
    } else {
      insn.operands.push_back(x_or_sp(size, opcode, 5, 9));
    }

    if (opc > 0b010001) {
      return UnallocatedEncoding();
    } else if (opc == 0b010000) {
      insn.opcode = kXpaci;
    } else if (opc == 0b010001) {
      insn.opcode = kXpacd;
    } else {
      switch (opc & 0b000111) {
        case 0b000: {
          insn.opcode = kPacia;
        } break;

        case 0b001: {
          insn.opcode = kPacib;
        } break;

        case 0b010: {
          insn.opcode = kPacda;
        } break;

        case 0b011: {
          insn.opcode = kPacdb;
        } break;

        case 0b100: {
          insn.opcode = kAutia;
        } break;

        case 0b101: {
          insn.opcode = kAutib;
        } break;

        case 0b110: {
          insn.opcode = kAutda;
        } break;

        case 0b111: {
          insn.opcode = kAutdb;
        } break;
      }
    }
  }

  return insn;
}

static Instruction DecodeLogicalShiftedRegister(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  switch ((bits(opcode, 29, 30) << 1) | bit(opcode, 21)) {
    case 0b000: {
      insn.opcode = kAndShiftedRegister;
    } break;

    case 0b001: {
      insn.opcode = kBicShiftedRegister;
    } break;

    case 0b010: {
      insn.opcode = kOrrShiftedRegister;
    } break;

    case 0b011: {
      insn.opcode = kOrnShiftedRegister;
    } break;

    case 0b100: {
      insn.opcode = kEorShiftedRegister;
    } break;

    case 0b101: {
      insn.opcode = kEonShiftedRegister;
    } break;

    case 0b110: {
      insn.opcode = kAndShiftedRegister;
      insn.set_flags = true;
    } break;

    case 0b111: {
      insn.opcode = kBicShiftedRegister;
      insn.set_flags = true;
    } break;
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  insn.operands.push_back(x(size, opcode, 16, 20));

  Shift shift(Shift::kNone, bits(opcode, 10, 15));
  switch (bits(opcode, 22, 23)) {
    case 0b00: {
      shift.type = Shift::kLsl;
    } break;

    case 0b01: {
      shift.type = Shift::kLsr;
    } break;

    case 0b10: {
      shift.type = Shift::kAsr;
    } break;

    case 0b11: {
      shift.type = Shift::kRor;
    } break;
  }

  insn.operands.push_back(shift);

  return insn;
}

static Instruction DecodeAddSubtractShiftedRegister(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bit(opcode, 30)) {
    insn.opcode = kSubShiftedRegister;
  } else {
    insn.opcode = kAddShiftedRegister;
  }

  if (bit(opcode, 29)) {
    insn.set_flags = true;
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  insn.operands.push_back(x(size, opcode, 16, 20));

  Shift shift(Shift::kNone, bits(opcode, 10, 15));
  switch (bits(opcode, 22, 23)) {
    case 0b00: {
      shift.type = Shift::kLsl;
    } break;

    case 0b01: {
      shift.type = Shift::kLsr;
    } break;

    case 0b10: {
      shift.type = Shift::kAsr;
    } break;

    case 0b11: {
      return UnallocatedEncoding();
    } break;
  }

  if (shift.count > size) {
    return UnallocatedEncoding();
  }

  insn.operands.push_back(shift);

  return insn;
}

static Instruction DecodeAddSubtractExtendedRegister(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bits(opcode, 22, 23) || bits(opcode, 10, 12) > 0b100) {
    return UnallocatedEncoding();
  }

  if (bit(opcode, 30)) {
    insn.opcode = kSubExtendedRegister;
  } else {
    insn.opcode = kAddExtendedRegister;
  }

  if (bit(opcode, 29)) {
    insn.set_flags = true;
  }

  Register rd = x_or_sp(size, opcode, 0, 4);
  if (insn.set_flags) {
    rd = x(size, opcode, 0, 4);
  }

  Register rn = x_or_sp(size, opcode, 5, 9);
  Register rm = x(size, opcode, 16, 20);

  Extend extend(Extend::kNone, bits(opcode, 10, 12));

  switch (bits(opcode, 13, 15)) {
    case 0b000: {
      extend.type = Extend::kUxtb;
      rm.size = 32;
    } break;

    case 0b001: {
      extend.type = Extend::kUxth;
      rm.size = 32;
    } break;

    case 0b010: {
      if (rd.name == Register::kSp || rn.name == Register::kSp) {
        extend.type = Extend::kLsl;
      } else {
        extend.type = Extend::kUxtw;
      }
      rm.size = 32;
    } break;

    case 0b011: {
      extend.type = Extend::kUxtx;
    } break;

    case 0b100: {
      extend.type = Extend::kSxtb;
      rm.size = 32;
    } break;

    case 0b101: {
      extend.type = Extend::kSxth;
      rm.size = 32;
    } break;

    case 0b110: {
      extend.type = Extend::kSxtw;
      rm.size = 32;
    } break;

    case 0b111: {
      extend.type = Extend::kSxtx;
    } break;
  }

  insn.operands.push_back(rd);
  insn.operands.push_back(rn);
  insn.operands.push_back(rm);
  insn.operands.push_back(extend);

  return insn;
}

static Instruction DecodeAddSubtractWithCarry(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bits(opcode, 10, 15)) {
    return UnallocatedEncoding();
  }

  if (bit(opcode, 30)) {
    insn.opcode = kSbc;
  } else {
    insn.opcode = kAdc;
  }

  if (bit(opcode, 29)) {
    insn.set_flags = true;
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  insn.operands.push_back(x(size, opcode, 16, 20));

  return insn;
}

static Instruction DecodeConditionalCompare(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bit(opcode, 30)) {
    insn.opcode = kCcmn;
  } else {
    insn.opcode = kCcmp;
  }

  insn.operands.push_back(x(size, opcode, 5, 9));

  if (bit(opcode, 11)) {  // (immediate)
    insn.operands.push_back(Immediate(size, bits(opcode, 16, 20)));
  } else {  // (register)
    insn.operands.push_back(x(size, opcode, 16, 20));
  }

  insn.operands.push_back(Immediate(8, bits(opcode, 0, 3)));

  insn.cc = (ConditionCode)bits(opcode, 12, 15);

  return insn;
}

static Instruction DecodeConditionalSelect(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bit(opcode, 29)) {
    return UnallocatedEncoding();
  }

  switch (((bit(opcode, 30) << 2) | bits(opcode, 10, 11))) {
    case 0b000: {
      insn.opcode = kCsel;
    } break;

    case 0b001: {
      insn.opcode = kCsinc;
    } break;

    case 0b100: {
      insn.opcode = kCsinv;
    } break;

    case 0b101: {
      insn.opcode = kCsneg;
    } break;

    default:
      return UnallocatedEncoding();
  }

  insn.operands.push_back(x(size, opcode, 0, 4));
  insn.operands.push_back(x(size, opcode, 5, 9));
  insn.operands.push_back(x(size, opcode, 16, 20));

  insn.cc = (ConditionCode)bits(opcode, 12, 15);

  return insn;
}

static Instruction DecodeDataProcessingThreeSource(uint32_t opcode) {
  Instruction insn;
  uint8_t size = 32 << bit(opcode, 31);

  if (bits(opcode, 29, 30)) {
    return UnallocatedEncoding();
  }

  switch ((bits(opcode, 21, 23) << 1) | bit(opcode, 15)) {
    case 0b0000: {
      insn.opcode = kMadd;
    } break;

    case 0b0001: {
      insn.opcode = kMsub;
    } break;

    case 0b0010: {
      insn.opcode = kSmaddl;
    } break;

    case 0b0011: {
      insn.opcode = kSmsubl;
    } break;

    case 0b0100:
    case 0b0101: {
      if (size != 64) {
        return UnallocatedEncoding();
      }
      insn.opcode = kSmulh;
    } break;

    case 0b1010: {
      insn.opcode = kUmaddl;
    } break;

    case 0b1011: {
      insn.opcode = kUmsubl;
    } break;

    case 0b1100:
    case 0b1101: {
      if (size != 64) {
        return UnallocatedEncoding();
      }
      insn.opcode = kUmulh;
    } break;

    default:
      return UnallocatedEncoding();
  }

  if (insn.opcode == kMadd || insn.opcode == kMsub || insn.opcode == kSmulh ||
      insn.opcode == kUmulh) {
    insn.operands.push_back(x(size, opcode, 0, 4));
    insn.operands.push_back(x(size, opcode, 5, 9));
    insn.operands.push_back(x(size, opcode, 16, 20));
    insn.operands.push_back(x(size, opcode, 10, 14));
  } else {
    insn.operands.push_back(x(64, opcode, 0, 4));
    insn.operands.push_back(x(32, opcode, 5, 9));
    insn.operands.push_back(x(32, opcode, 16, 20));
    insn.operands.push_back(x(64, opcode, 10, 14));
  }

  return insn;
}

std::tuple<uint64_t, uint64_t> DecodeBitMasks(uint8_t size, Immediate imms,
                                              Immediate immr) {
  return decode_bit_masks(size == 64 ? 1 : 0, imms.value, immr.value, false);
}

Instruction DecodeInstruction(uint64_t address, uint32_t opcode) {
  Instruction insn;
  uint32_t op0 = bits(opcode, 25, 28);
  if ((op0 & 0b1110) == 0b1000) {
    insn = DecodeDataProcessingImmediate(opcode);
  } else if ((op0 & 0b1110) == 0b1010) {
    insn = DecodeBranchExceptionGeneratingSystem(opcode);
  } else if ((op0 & 0b0101) == 0b0100) {
    insn = DecodeLoadStore(opcode);
  } else if ((op0 & 0b0111) == 0b0101) {
    insn = DecodeDataProcessingRegister(opcode);
  } /* else if (op0 == 0b0111 || op0 == 0b1111) {
    // Data processing - SIMD and floating point
  } */
  else {
    insn = UnallocatedEncoding();
  }

  insn.address = address;
  return insn;
}
}  // namespace decoder
}  // namespace aarch64
}  // namespace reil

```

`third_party/reil/reil/aarch64/decoder.h`:

```h
// Copyright 2018 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef REIL_AARCH64_DECODER_H_

#include <cstdint>
#include <iostream>
#include <tuple>
#include <vector>

#include <variant>
#if 0
#include "absl/types/variant.h"
#endif

namespace reil {
namespace aarch64 {
namespace decoder {
enum Opcode {
  // PC-relative addressing
  kAdr,
  kAdrp,

  // Add/subtract immediate
  kAddImmediate,
  kSubImmediate,

  // Logical immediate
  kAndImmediate,
  kOrrImmediate,
  kEorImmediate,

  // Move wide immediate
  kMovk,
  kMovn,
  kMovz,

  // Bitfield
  kBfm,
  kSbfm,
  kUbfm,

  // Extract
  kExtr,

  // Conditional branch
  kBCond,

  // Exception generation
  kBrk,
  kDcps1,
  kDcps2,
  kDcps3,
  kHlt,
  kHvc,
  kSmc,
  kSvc,

  // System
  kAutia1716,
  kAutiasp,
  kAutiaz,
  kAutib1716,
  kAutibsp,
  kAutibz,
  kClrex,
  kDmb,
  kDsb,
  kEsb,
  kHint,
  kIsb,
  kMrs,
  kMsr,
  kNop,
  kPacia1716,
  kPaciasp,
  kPaciaz,
  kPacib1716,
  kPacibsp,
  kPacibz,
  kPsbCsync,
  kSev,
  kSevl,
  kSys,
  kSysl,
  kWfe,
  kWfi,
  kXpaclri,
  kYield,

  // Unconditional branch register
  kBlr,
  kBlraa,
  kBlraaz,
  kBlrab,
  kBlrabz,
  kBr,
  kBraa,
  kBraaz,
  kBrab,
  kBrabz,
  kDrps,
  kEret,
  kEretaa,
  kEretaaz,
  kEretab,
  kEretabz,
  kRet,
  kRetaa,
  kRetaaz,
  kRetab,
  kRetabz,

  // Unconditional branch immediate
  kB,
  kBl,

  // Compare and branch
  kCbnz,
  kCbz,

  // Test and branch
  kTbnz,
  kTbz,

  // Load/store exclusive
  kCas,
  kCasa,
  kCasal,
  kCasl,
  kCasp,
  kCaspa,
  kCaspal,
  kCaspl,
  kLdar,
  kLdaxp,
  kLdaxr,
  kLdlar,
  kLdxp,
  kLdxr,
  kStllr,
  kStlr,
  kStlxp,
  kStlxr,
  kStxp,
  kStxr,

  // Load literal
  kSimdLdrLiteral,
  kLdrLiteral,
  kLdrsLiteral,
  kPrfmLiteral,

  // Load/store pair
  kSimdLdnp,
  kSimdLdp,
  kSimdStnp,
  kSimdStp,
  kLdnp,
  kLdp,
  kLdpsw,
  kStnp,
  kStp,

  // Load/store
  kSimdLdr,
  kSimdLdur,
  kSimdStr,
  kSimdStur,
  kLdr,
  kLdrs,
  kLdtr,
  kLdtrs,
  kLdur,
  kLdurs,
  kPrfm,
  kStr,
  kSttr,
  kStur,

  // Data-processing (2 source)
  kAsr,
  kCrc32b,
  kCrc32cb,
  kCrc32ch,
  kCrc32cw,
  kCrc32cx,
  kCrc32h,
  kCrc32w,
  kCrc32x,
  kLsl,
  kLsr,
  kPacga,
  kRor,
  kSdiv,
  kUdiv,

  // Data-processing (1 source)
  kAutda,
  kAutdb,
  kAutia,
  kAutib,
  kClz,
  kCls,
  kPacda,
  kPacdb,
  kPacia,
  kPacib,
  kRbit,
  kRev,
  kRev16,
  kRev32,
  kXpacd,
  kXpaci,

  // Logical (shifted register)
  kAndShiftedRegister,
  kBicShiftedRegister,
  kOrrShiftedRegister,
  kOrnShiftedRegister,
  kEorShiftedRegister,
  kEonShiftedRegister,

  // Add/subtract (shifted register)
  kAddShiftedRegister,
  kSubShiftedRegister,

  // Add/subtract (extended register)
  kAddExtendedRegister,
  kSubExtendedRegister,

  // Add/subtract with carry
  kAdc,
  kSbc,

  // Conditional compare
  kCcmn,
  kCcmp,

  // Conditional select
  kCsel,
  kCsinc,
  kCsinv,
  kCsneg,

  // Data processing (3 source)
  kMadd,
  kMsub,
  kSmaddl,
  kSmulh,
  kSmsubl,
  kUmaddl,
  kUmulh,
  kUmsubl,

  // Unallocated encodings
  kUnallocated,
};

enum ConditionCode {
  kEq = 0b0000,
  kNe = 0b0001,
  kCs = 0b0010,
  kCc = 0b0011,
  kMi = 0b0100,
  kPl = 0b0101,
  kVs = 0b0110,
  kVc = 0b0111,
  kHi = 0b1000,
  kLs = 0b1001,
  kGe = 0b1010,
  kLt = 0b1011,
  kGt = 0b1100,
  kLe = 0b1101,
  kAl = 0b1110,
};

enum OperandType {
  kImmediate,
  kRegister,
  kSystemRegister,
  kShift,
  kExtend,
  kImmediateOffset,
  kRegisterOffset
};

struct Immediate {
  uint8_t size;
  uint64_t value;

  explicit Immediate(uint8_t size_, uint64_t value_)
      : size(size_), value(value_ & (0xffffffffffffffffull >> (64 - size_))) {}
};

struct Register {
  uint8_t size;
  enum Name {
    kX0 = 0,
    kX1,
    kX2,
    kX3,
    kX4,
    kX5,
    kX6,
    kX7,
    kX8,
    kX9,
    kX10,
    kX11,
    kX12,
    kX13,
    kX14,
    kX15,
    kX16,
    kX17,
    kX18,
    kX19,
    kX20,
    kX21,
    kX22,
    kX23,
    kX24,
    kX25,
    kX26,
    kX27,
    kX28,
    kX29,
    kX30,
    kXzr,

    kSp,
    kPc,

    kV0,
    kV1,
    kV2,
    kV3,
    kV4,
    kV5,
    kV6,
    kV7,
    kV8,
    kV9,
    kV10,
    kV11,
    kV12,
    kV13,
    kV14,
    kV15,
    kV16,
    kV17,
    kV18,
    kV19,
    kV20,
    kV21,
    kV22,
    kV23,
    kV24,
    kV25,
    kV26,
    kV27,
    kV28,
    kV29,
    kV30,
    kV31,

    kN,
    kZ,
    kC,
    kV,
  } name;

  explicit Register(uint8_t size_, enum Name name_)
      : size(size_), name(name_) {}
};

struct SystemRegister {
  enum Name {
    kUnknown = 0,
    kSPSel,
    kDAIFSet,
    kDAIFClr,
    kUAO,
    kPAN,
  } name;

  uint8_t op0;
  uint8_t op1;
  uint8_t op2;
  uint8_t crn;
  uint8_t crm;

  explicit SystemRegister(enum Name name_) : name(name_) {}

  explicit SystemRegister(uint8_t op0_, uint8_t op1_, uint8_t op2_,
                          uint8_t crn_, uint8_t crm_)
      : name(kUnknown), op0(op0_), op1(op1_), op2(op2_), crn(crn_), crm(crm_) {}
};

struct Shift {
  enum Type {
    kNone = 0,
    kLsl,
    kLsr,
    kAsr,
    kRol,
    kRor,
  } type;

  uint8_t count;

  explicit Shift(enum Type type_, uint8_t count_)
      : type(type_), count(count_) {}
};

struct Extend {
  enum Type {
    kNone,
    kUxtb,
    kUxth,
    kUxtw,
    kUxtx,
    kLsl,
    kSxtb,
    kSxth,
    kSxtw,
    kSxtx,
  } type;

  uint8_t count;

  explicit Extend(enum Type type_, uint8_t count_)
      : type(type_), count(count_) {}
};

struct ImmediateOffset {
  uint8_t size;
  Register base;
  Immediate offset;
  Shift shift;

  bool writeback;
  bool post_index;

  explicit ImmediateOffset(Register base_, Immediate offset_, Shift shift_,
                           uint8_t size_, bool writeback_ = false,
                           bool post_index_ = false)
      : size(size_),
        base(base_),
        offset(offset_),
        shift(shift_),
        writeback(writeback_),
        post_index(post_index_) {}
};

struct RegisterOffset {
  uint8_t size;
  Register base;
  Register offset;
  Extend extend;

  bool writeback;
  bool post_index;

  explicit RegisterOffset(Register base_, Register offset_, Extend extend_,
                          uint8_t size_, bool writeback_ = false,
                          bool post_index_ = false)
      : size(size_),
        base(base_),
        offset(offset_),
        extend(extend_),
        writeback(writeback_),
        post_index(post_index_) {}
};

typedef std::variant<Immediate, Register, SystemRegister, Shift, Extend,
                      ImmediateOffset, RegisterOffset>
    Operand;
#if 0
typedef absl::variant<Immediate, Register, SystemRegister, Shift, Extend,
                      ImmediateOffset, RegisterOffset>
    Operand;
#endif

struct Instruction {
  uint64_t address;
  enum Opcode opcode;

  std::vector<Operand> operands;

  ConditionCode cc;
  bool set_flags;

  Instruction() : address(0), opcode(kUnallocated), set_flags(false) {}
};

std::tuple<uint64_t, uint64_t> DecodeBitMasks(uint8_t size, Immediate imms,
                                              Immediate immr);
Instruction DecodeInstruction(uint64_t address, uint32_t opcode);

std::ostream &operator<<(std::ostream &stream, const Operand &opnd);
std::ostream &operator<<(std::ostream &stream, const Instruction &insn);
}  // namespace decoder
}  // namespace aarch64
}  // namespace reil

#define REIL_AARCH64_DECODER_H_
#endif  // REIL_AARCH64_DECODER_H_

```

`third_party/reil/reil/aarch64/printer.cpp`:

```cpp
// Copyright 2018 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include "reil/aarch64/decoder.h"

#include <cassert>

namespace reil {
namespace aarch64 {
namespace decoder {

static void PrintImmediate(std::ostream& stream, const Immediate& opnd) {
  stream << "#0x" << std::hex << opnd.value;
}

static void PrintSignedImmediate(std::ostream& stream, const Immediate& opnd) {
  if (opnd.value & (1ull << (opnd.size - 1))) {
    stream << "#-0x" << std::hex << (~opnd.value) + 1ull;
  } else {
    stream << "#0x" << std::hex << opnd.value;
  }
}

static void PrintPcRelativeOffset(std::ostream& stream, const Instruction& insn,
                                  const Immediate& opnd) {
  if (opnd.value & (1ull << (opnd.size - 1))) {
    stream << "#0x" << std::hex << insn.address - ((~opnd.value) + 1ull);
  } else {
    stream << "#0x" << std::hex << insn.address + opnd.value;
  }
}

static void PrintRegister(std::ostream& stream, const Register& opnd) {
  if (Register::kX0 <= opnd.name && opnd.name <= Register::kXzr) {
    if (opnd.size <= 32) {
      stream << "w";
    } else {
      stream << "x";
    }

    if (opnd.name == Register::kXzr) {
      stream << "zr";
    } else {
      stream << std::dec << (unsigned)(opnd.name - Register::kX0);
    }
  } else if (opnd.name == Register::kSp) {
    if (opnd.size <= 32) {
      stream << "wsp";
    } else {
      stream << "sp";
    }
  } else if (opnd.name == Register::kPc) {
    stream << "pc";
  } else if (Register::kV0 <= opnd.name && opnd.name <= Register::kV31) {
    if (opnd.size == 8) {
      stream << "b";
    } else if (opnd.size == 16) {
      stream << "h";
    } else if (opnd.size == 32) {
      stream << "s";
    } else if (opnd.size == 64) {
      stream << "d";
    } else if (opnd.size == 128) {
      stream << "q";
    }

    stream << std::dec << (unsigned)(opnd.name - Register::kV0);
  } else {
    stream << "<unsupported_reg>";
  }
}

static void PrintSystemRegister(std::ostream& stream,
                                const SystemRegister& opnd) {
  if (opnd.name == SystemRegister::kUnknown) {
    stream << "S" << std::dec << (int)opnd.op0;
    stream << "_" << std::dec << (int)opnd.op1;
    stream << "_C" << std::dec << (int)opnd.crn;
    stream << "_C" << std::dec << (int)opnd.crm;
    stream << "_" << std::dec << (int)opnd.op2;
  } else if (opnd.name == SystemRegister::kSPSel) {
    stream << "SPSel";
  } else if (opnd.name == SystemRegister::kDAIFSet) {
    stream << "DAIFSet";
  } else if (opnd.name == SystemRegister::kDAIFClr) {
    stream << "DAIFClr";
  } else if (opnd.name == SystemRegister::kUAO) {
    stream << "UAO";
  } else if (opnd.name == SystemRegister::kPAN) {
    stream << "PAN";
  }
}

static void PrintShift(std::ostream& stream, const Shift& opnd) {
  if (opnd.type != Shift::kNone) {
    switch (opnd.type) {
      case Shift::kLsl: {
        if (opnd.count) {
          stream << ", lsl ";
        } else {
          return;
        }
      } break;

      case Shift::kLsr: {
        stream << ", lsr ";
      } break;

      case Shift::kAsr: {
        stream << ", asr ";
      } break;

      case Shift::kRor: {
        stream << ", ror ";
      } break;

      default:
        abort();
    }

    stream << "#0x" << std::hex << (unsigned)opnd.count;
  }
}

static void PrintExtend(std::ostream& stream, const Extend& opnd) {
  if (opnd.type != Extend::kNone) {
    switch (opnd.type) {
      case Extend::kUxtb: {
        stream << ", uxtb";
      } break;

      case Extend::kUxth: {
        stream << ", uxth";
      } break;

      case Extend::kUxtw: {
        stream << ", uxtw";
      } break;

      case Extend::kUxtx: {
        stream << ", uxtx";
      } break;

      case Extend::kLsl: {
        if (opnd.count) {
          stream << ", lsl";
        }
      } break;

      case Extend::kSxtb: {
        stream << ", sxtb";
      } break;

      case Extend::kSxth: {
        stream << ", sxth";
      } break;

      case Extend::kSxtw: {
        stream << ", sxtw";
      } break;

      case Extend::kSxtx: {
        stream << ", sxtx";
      } break;

      default:
        abort();
    }

    if (opnd.count) {
      stream << ", #" << std::dec << (unsigned)opnd.count;
    }
  }
}

static void PrintImmediateOffset(std::ostream& stream,
                                 const ImmediateOffset& opnd) {
  stream << "[" << opnd.base;
  if (opnd.writeback && opnd.post_index) {
    stream << "]";
  }

  if (opnd.offset.value) {
    stream << ", ";
    PrintSignedImmediate(stream, opnd.offset);
    stream << opnd.shift;
  }

  if (!opnd.writeback || !opnd.post_index) {
    stream << "]";
    if (opnd.writeback) {
      stream << "!";
    }
  }
}

static void PrintRegisterOffset(std::ostream& stream,
                                const RegisterOffset& opnd) {
  stream << "[" << opnd.base;
  if (opnd.writeback && opnd.post_index) {
    stream << "]";
  }

  stream << ", " << opnd.offset << opnd.extend;

  if (!opnd.writeback || !opnd.post_index) {
    stream << "]";
    if (opnd.writeback) {
      stream << "!";
    }
  }
}

static void PrintOperands(std::ostream& stream,
                          const std::vector<Operand>& opnds) {
  for (size_t i = 0; i < opnds.size(); ++i) {
    if (i != 0 && !std::holds_alternative<Shift>(opnds[i])) {
      stream << ", ";
    }
    stream << opnds[i];
  }
}

static void PrintConditionCode(std::ostream& stream, ConditionCode cc) {
  static std::vector<std::string> condition_codes = {
      "eq", "ne", "cs", "cc", "mi", "pl", "vs", "vc",
      "hi", "ls", "ge", "lt", "gt", "le", "al", "al"};

  stream << condition_codes[cc];
}

static void PrintPrefetchOp(std::ostream& stream, uint8_t prfop) {
  if (((prfop & 0b11000) == 0b11000) || ((prfop & 0b00110) == 0b00110)) {
    stream << "#" << std::dec << (int)prfop;
  } else {
    switch (prfop & 0b11000) {
      case 0b00000: {
        stream << "PLD";
      } break;

      case 0b01000: {
        stream << "PLI";
      } break;

      case 0b10000: {
        stream << "PST";
      } break;

      default:
        abort();
    }

    switch (prfop & 0b00110) {
      case 0b00000: {
        stream << "L1";
      } break;

      case 0b00010: {
        stream << "L2";
      } break;

      case 0b00100: {
        stream << "L3";
      } break;

      default:
        abort();
    }

    switch (prfop & 0b1) {
      case 0: {
        stream << "KEEP";
      } break;

      case 1: {
        stream << "STRM";
      } break;
    }
  }
}

static void PrintBarrierType(std::ostream& stream, uint8_t option) {
  if (((option & 0b10) >> 1) == (option & 0b01)) {
    stream << "#" << std::dec << (int)option;
  } else {
    switch (option >> 2) {
      case 0b00: {
        stream << "os";
      } break;

      case 0b01: {
        stream << "nsh";
      } break;

      case 0b10: {
        stream << "ish";
      } break;

      case 0b11: {
        if (option == 0b1111) {
          stream << "sy";
        }
      } break;
    }

    switch (option & 0b11) {
      case 0b01: {
        stream << "ld";
      } break;

      case 0b10: {
        stream << "st";
      } break;

      default:
        abort();
    }
  }
}

static void PrintPcRelativeAddressing(std::ostream& stream,
                                      const Instruction& insn) {
  assert(insn.operands.size() == 3);

  Register rd = std::get<Register>(insn.operands[0]);
  Immediate imm = std::get<Immediate>(insn.operands[1]);
  Shift shift = std::get<Shift>(insn.operands[2]);

  if (insn.opcode == kAdr) {
    stream << "adr ";
  } else {
    stream << "adrp ";

    assert(shift.type == Shift::kLsl);
    assert(shift.count == 12);

    imm.value <<= 12;
  }

  stream << rd << ", " << imm;
}

static void PrintAddSubtractImmediate(std::ostream& stream,
                                      const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Immediate imm = std::get<Immediate>(insn.operands[2]);
  Shift shift = std::get<Shift>(insn.operands[3]);

  if ((imm.value == 0 && !insn.set_flags && rd.name == Register::kSp) ||
      (imm.value == 0 && rn.name == Register::kSp)) {
    stream << "mov " << rd << ", " << rn;
  } else if (rd.name == Register::kXzr) {
    if (insn.opcode == kSubImmediate) {
      stream << "cmp ";
    } else {
      stream << "cmn ";
    }

    stream << rn << ", " << imm << shift;
  } else {
    if (insn.opcode == kSubImmediate) {
      stream << "sub";
    } else {
      stream << "add";
    }

    if (insn.set_flags) {
      stream << "s ";
    } else {
      stream << " ";
    }

    stream << rd << ", " << rn << ", " << imm << shift;
  }
}

static void PrintLogicalImmediate(std::ostream& stream,
                                  const Instruction& insn) {
  assert(insn.operands.size() == 3);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Immediate imm = std::get<Immediate>(insn.operands[2]);

  switch (insn.opcode) {
    case kAndImmediate: {
      if (!insn.set_flags) {
        stream << "and ";
      } else if (rd.name == Register::kXzr) {
        stream << "tst ";
      } else {
        stream << "ands ";
      }
    } break;

    case kOrrImmediate: {
      if (rn.name == Register::kXzr) {
        stream << "mov ";
      } else {
        stream << "orr ";
      }
    } break;

    case kEorImmediate: {
      stream << "eor ";
    } break;

    default:
      abort();
  }

  if (insn.opcode != kAndImmediate || rd.name != Register::kXzr) {
    stream << rd << ", ";
  }

  if (insn.opcode != kOrrImmediate || rn.name != Register::kXzr) {
    stream << rn << ", ";
  }

  stream << imm;
}

static void PrintMoveWideImmediate(std::ostream& stream,
                                   const Instruction& insn) {
  assert(insn.operands.size() == 3);

  Immediate imm = std::get<Immediate>(insn.operands[1]);
  Shift shift = std::get<Shift>(insn.operands[2]);

  switch (insn.opcode) {
    case kMovn: {
      stream << "mov ";
      imm.value <<= shift.count;
      imm.value = ~imm.value;
    } break;

    case kMovz: {
      stream << "mov ";
      imm.value <<= shift.count;
    } break;

    case kMovk: {
      stream << "movk ";
    } break;

    default:
      abort();
  }

  if (imm.size == 32) {
    imm.value &= 0xfffffffful;
  }

  stream << insn.operands[0] << ", " << imm;
  if (insn.opcode == kMovk) {
    stream << shift;
  }
}

static void PrintBitfield(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Immediate immr = std::get<Immediate>(insn.operands[2]);
  Immediate imms = std::get<Immediate>(insn.operands[3]);

  if (insn.opcode == kBfm) {
    if (rn.name == Register::kXzr && imms.value < immr.value) {
      stream << "bfc " << rd;
    } else if (imms.value < immr.value) {
      stream << "bfi " << rd << ", " << rn;
    } else {
      stream << "bfxil " << rd << ", " << rn;
    }

    stream << ", #" << immr.size - immr.value << ", #" << imms.value + 1;
  } else if (insn.opcode == kSbfm) {
    if ((imms.size == 32 && imms.value == 0b011111) ||
        (imms.size == 64 && imms.value == 0b111111)) {
      stream << "asr " << rd << ", " << rn << ", #" << immr.value;
    } else if (imms.value < immr.value) {
      stream << "sbfiz " << rd << ", " << rn;
      stream << ", #" << immr.size - immr.value << ", #" << imms.value + 1;
    } else if (immr.value == 0 && imms.value == 0b000111) {
      stream << "sxtb " << rd << ", " << rn;
    } else if (immr.value == 0 && imms.value == 0b001111) {
      stream << "sxth " << rd << ", " << rn;
    } else if (immr.value == 0 && imms.value == 0b011111) {
      stream << "sxtw " << rd << ", " << rn;
    } else {
      stream << "sbfx " << rd << ", " << rn;
      stream << ", #" << immr.value << ", #" << imms.value - immr.value + 1;
    }
  } else if (insn.opcode == kUbfm) {
    if ((imms.value + 1 == immr.value) &&
        (imms.value != 0b011111 && imms.value != 0b111111)) {
      stream << "lsl " << rd << ", " << rn << ", #" << immr.size - immr.value;
    } else if (imms.value == 0b011111 || imms.value == 0b111111) {
      stream << "lsr " << rd << ", " << rn << ", #" << immr.value;
    } else if (imms.value < immr.value) {
      stream << "ubfiz " << rd << ", " << rn;
      stream << ", #" << immr.size - immr.value << ", #" << imms.value + 1;
    } else if (immr.value == 0 && imms.value == 0b000111) {
      stream << "uxtb " << rd << ", " << rn;
    } else if (immr.value == 0 && imms.value == 0b001111) {
      stream << "uxth " << rd << ", " << rn;
    } else if (immr.value == 0 && imms.value == 0b011111) {
      stream << "uxtw " << rd << ", " << rn;
    } else {
      stream << "ubfx " << rd << ", " << rn;
      stream << ", #" << immr.value << ", #" << imms.value - immr.value + 1;
    }
  }
}

static void PrintExtract(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);
  Immediate imm = std::get<Immediate>(insn.operands[3]);

  if (rn.name == rm.name) {
    stream << "ror ";
    stream << rd << ", " << rn;
  } else {
    stream << "extr ";
    stream << rd << ", " << rn << ", " << rm;
  }

  stream << ", #" << std::dec << imm.value;
}

static void PrintConditionalBranch(std::ostream& stream,
                                   const Instruction& insn) {
  assert(insn.operands.size() == 1);

  Immediate offset = std::get<Immediate>(insn.operands[0]);
  stream << "b.";
  PrintConditionCode(stream, insn.cc);
  stream << " ";
  PrintPcRelativeOffset(stream, insn, offset);
}

static void PrintExceptionGeneration(std::ostream& stream,
                                     const Instruction& insn) {
  assert(insn.operands.size() == 1);

  Immediate imm = std::get<Immediate>(insn.operands[0]);
  switch (insn.opcode) {
    case kSvc: {
      stream << "svc #" << std::dec << imm.value;
    } break;

    case kHvc: {
      stream << "hvc #" << std::dec << imm.value;
    } break;

    case kSmc: {
      stream << "smc #" << std::dec << imm.value;
    } break;

    case kBrk: {
      stream << "brk #" << std::dec << imm.value;
    } break;

    case kHlt: {
      stream << "hlt #" << std::dec << imm.value;
    } break;

    case kDcps1: {
      stream << "dcps1";
    } break;

    case kDcps2: {
      stream << "dcps2";
    } break;

    case kDcps3: {
      stream << "dcps3";
    } break;

    default:
      abort();
  }
}

static void PrintSystem(std::ostream& stream, const Instruction& insn) {
  switch (insn.opcode) {
    case kNop: {
      stream << "nop";
    } break;

    case kYield: {
      stream << "yield";
    } break;

    case kWfe: {
      stream << "wfe";
    } break;

    case kWfi: {
      stream << "wfi";
    } break;

    case kSev: {
      stream << "sev";
    } break;

    case kSevl: {
      stream << "sevl";
    } break;

    case kXpaclri: {
      stream << "xapclri";
    } break;

    case kPacia1716: {
      stream << "pacia1716";
    } break;

    case kPacib1716: {
      stream << "pacib1716";
    } break;

    case kAutia1716: {
      stream << "autia1716";
    } break;

    case kAutib1716: {
      stream << "autib1716";
    } break;

    case kEsb: {
      stream << "esb";
    } break;

    case kPsbCsync: {
      stream << "psb csync";
    } break;

    case kPaciaz: {
      stream << "paciaz";
    } break;

    case kPaciasp: {
      stream << "paciasp";
    } break;

    case kPacibz: {
      stream << "pacibz";
    } break;

    case kPacibsp: {
      stream << "pacibsp";
    } break;

    case kAutiaz: {
      stream << "autiaz";
    } break;

    case kAutiasp: {
      stream << "autiasp";
    } break;

    case kAutibz: {
      stream << "autibz";
    } break;

    case kAutibsp: {
      stream << "autibsp";
    } break;

    case kHint: {
      stream << "hint " << insn.operands[0];
    } break;

    case kClrex: {
      stream << "clrex";
    } break;

    case kDsb: {
      Immediate imm = std::get<Immediate>(insn.operands[0]);
      stream << "dsb ";
      PrintBarrierType(stream, imm.value);
    } break;

    case kDmb: {
      Immediate imm = std::get<Immediate>(insn.operands[0]);
      stream << "dmb ";
      PrintBarrierType(stream, imm.value);
    } break;

    case kIsb: {
      Immediate imm = std::get<Immediate>(insn.operands[0]);
      stream << "isb";
      if (imm.value != 0b1111) {
        stream << " #" << std::dec << imm.value;
      }
    } break;

    case kSys: {
      // TODO: handle AT etc.
      Immediate op1 = std::get<Immediate>(insn.operands[0]);
      Immediate crn = std::get<Immediate>(insn.operands[1]);
      Immediate crm = std::get<Immediate>(insn.operands[2]);
      Immediate op2 = std::get<Immediate>(insn.operands[3]);
      Register rt = std::get<Register>(insn.operands[4]);

      stream << "sys ";
      stream << "#" << std::dec << op1.value;
      stream << ", C" << std::dec << crn.value;
      stream << ", C" << std::dec << crm.value;
      stream << ", #" << std::dec << op2.value;
      if (rt.name != Register::kXzr) {
        stream << ", " << rt;
      }
    } break;

    case kMsr: {
      stream << "msr ";
      PrintOperands(stream, insn.operands);
    } break;

    case kSysl: {
      Register rt = std::get<Register>(insn.operands[0]);
      Immediate op1 = std::get<Immediate>(insn.operands[1]);
      Immediate crn = std::get<Immediate>(insn.operands[2]);
      Immediate crm = std::get<Immediate>(insn.operands[3]);
      Immediate op2 = std::get<Immediate>(insn.operands[4]);

      stream << "sysl ";
      stream << rt;
      stream << ", #" << std::dec << op1.value;
      stream << ", C" << std::dec << crn.value;
      stream << ", C" << std::dec << crm.value;
      stream << ", #" << std::dec << op2.value;
    } break;

    case kMrs: {
      stream << "mrs ";
      PrintOperands(stream, insn.operands);
    } break;

    default:
      abort();
  }
}

static void PrintBranchRegister(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() >= 1);

  Register rn = std::get<Register>(insn.operands[0]);

  switch (insn.opcode) {
    case kBr: {
      stream << "br " << rn;
    } break;

    case kBraaz: {
      stream << "braaz " << rn;
    } break;

    case kBrabz: {
      stream << "brabz" << rn;
    } break;

    case kBlr: {
      stream << "blr " << rn;
    } break;

    case kBlraaz: {
      stream << "blraaz " << rn;
    } break;

    case kBlrabz: {
      stream << "blrabz " << rn;
    } break;

    case kRet: {
      stream << "ret";
      if (rn.name != Register::kX30) {
        stream << " " << rn;
      }
    } break;

    case kRetaa: {
      stream << "retaa";
    } break;

    case kRetab: {
      stream << "retab";
    } break;

    case kEret: {
      stream << "eret";
    } break;

    case kEretaa: {
      stream << "eretaa";
    } break;

    case kEretab: {
      stream << "eretab";
    } break;

    case kDrps: {
      stream << "drps";
    } break;

    case kBraa: {
      stream << "braa " << rn << ", " << insn.operands[1];
    } break;

    case kBrab: {
      stream << "brab " << rn << ", " << insn.operands[1];
    } break;

    case kBlraa: {
      stream << "blraa " << rn << ", " << insn.operands[1];
    } break;

    case kBlrab: {
      stream << "blrab " << rn << ", " << insn.operands[1];
    } break;

    default:
      abort();
  }
}

static void PrintBranchImmediate(std::ostream& stream,
                                 const Instruction& insn) {
  assert(insn.operands.size() == 1);

  Immediate offset = std::get<Immediate>(insn.operands[0]);

  if (insn.opcode == kBl) {
    stream << "bl ";
  } else {
    stream << "b ";
  }

  PrintPcRelativeOffset(stream, insn, offset);
}

static void PrintCompareAndBranch(std::ostream& stream,
                                  const Instruction& insn) {
  assert(insn.operands.size() == 2);

  Immediate offset = std::get<Immediate>(insn.operands[1]);

  if (insn.opcode == kCbz) {
    stream << "cbz ";
  } else {
    stream << "cbnz ";
  }

  stream << insn.operands[0] << ", ";
  PrintPcRelativeOffset(stream, insn, offset);
}

static void PrintTestAndBranch(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() == 3);

  Immediate bit = std::get<Immediate>(insn.operands[1]);
  Immediate offset = std::get<Immediate>(insn.operands[2]);

  if (insn.opcode == kTbz) {
    stream << "tbz ";
  } else {
    stream << "tbnz ";
  }

  stream << insn.operands[0] << ", #" << std::dec << bit.value << ", ";
  PrintPcRelativeOffset(stream, insn, offset);
}

static void PrintLoadStoreExclusive(std::ostream& stream,
                                    const Instruction& insn) {
  bool pair = false;
  uint8_t size = 64;

  if (insn.opcode <= kLdxr) {
    if (insn.opcode == kCas) {
      stream << "cas";
    } else if (insn.opcode == kCasa) {
      stream << "casa";
    } else if (insn.opcode == kCasal) {
      stream << "casal";
    } else if (insn.opcode == kCasl) {
      stream << "casl";
    } else if (insn.opcode == kCasp) {
      stream << "casp ";
      pair = true;
    } else if (insn.opcode == kCaspa) {
      stream << "caspa ";
      pair = true;
    } else if (insn.opcode == kCaspal) {
      stream << "caspal ";
      pair = true;
    } else if (insn.opcode == kCaspl) {
      stream << "caspl ";
      pair = true;
    } else if (insn.opcode == kLdxr) {
      stream << "ldxr";
    } else if (insn.opcode == kLdxp) {
      stream << "ldxp ";
      pair = true;
    } else if (insn.opcode == kLdaxr) {
      stream << "ldaxr";
    } else if (insn.opcode == kLdaxp) {
      stream << "ldaxp ";
      pair = true;
    } else if (insn.opcode == kLdlar) {
      stream << "ldlar";
    } else {
      stream << "ldar";
    }

    size = std::get<Register>(insn.operands[0]).size;
  } else if (insn.opcode <= kStxr) {
    if (insn.opcode == kStxr) {
      stream << "stxr";
    } else if (insn.opcode == kStxp) {
      stream << "stxp ";
      pair = true;
    } else if (insn.opcode == kStlxr) {
      stream << "stlxr";
    } else if (insn.opcode == kStlxp) {
      stream << "stlxp ";
      pair = true;
    } else if (insn.opcode == kStllr) {
      stream << "stllr";
    } else if (insn.opcode == kStlr) {
      stream << "stlr";
    }

    if (insn.opcode != kStlr && insn.opcode != kStllr) {
      size = std::get<Register>(insn.operands[1]).size;
    } else {
      size = std::get<Register>(insn.operands[0]).size;
    }
  }

  if (!pair) {
    if (size == 8) {
      stream << "b ";
    } else if (size == 16) {
      stream << "h ";
    } else {
      stream << " ";
    }
  }

  PrintOperands(stream, insn.operands);
}

static void PrintLoadLiteral(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() == 2);

  ImmediateOffset imm_off = std::get<ImmediateOffset>(insn.operands[1]);

  if (insn.opcode == kSimdLdrLiteral || insn.opcode == kLdrLiteral) {
    stream << "ldr ";
  } else if (insn.opcode == kLdrsLiteral) {
    stream << "ldrsw ";
  } else if (insn.opcode == kPrfmLiteral) {
    stream << "prfm ";
  } else {
    abort();
  }

  if (insn.opcode == kPrfmLiteral) {
    Immediate prfop = std::get<Immediate>(insn.operands[0]);
    PrintPrefetchOp(stream, prfop.value);
  } else {
    stream << insn.operands[0] << ", ";
  }
  PrintSignedImmediate(stream, imm_off.offset);
}

static void PrintLoadStorePair(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() == 3);

  if (insn.opcode == kSimdLdp || insn.opcode == kLdp) {
    stream << "ldp ";
  } else if (insn.opcode == kLdpsw) {
    stream << "ldpsw ";
  } else if (insn.opcode == kSimdLdnp || insn.opcode == kLdnp) {
    stream << "ldnp ";
  } else if (insn.opcode == kSimdStp || insn.opcode == kStp) {
    stream << "stp ";
  } else if (insn.opcode == kSimdStnp || insn.opcode == kStnp) {
    stream << "stnp ";
  } else {
    abort();
  }

  PrintOperands(stream, insn.operands);
}

static void PrintLoadStore(std::ostream& stream, const Instruction& insn) {
  assert(insn.operands.size() == 2);
  uint8_t size = 0;

  if (std::holds_alternative<ImmediateOffset>(insn.operands[1])) {
    ImmediateOffset address = std::get<ImmediateOffset>(insn.operands[1]);
    size = address.size;
  } else if (std::holds_alternative<RegisterOffset>(insn.operands[1])) {
    RegisterOffset address = std::get<RegisterOffset>(insn.operands[1]);
    size = address.size;
  } else {
    abort();
  }

  if (insn.opcode == kPrfm) {
    Immediate prfop = std::get<Immediate>(insn.operands[0]);
    stream << "prfm ";
    PrintPrefetchOp(stream, prfop.value);
    stream << ", " << insn.operands[1];
  } else {
    if (insn.opcode == kSimdLdr || insn.opcode == kLdr) {
      stream << "ldr";
    } else if (insn.opcode == kSimdLdur || insn.opcode == kLdur) {
      stream << "ldur";
    } else if (insn.opcode == kLdtr) {
      stream << "ldtr";
    } else if (insn.opcode == kLdrs) {
      stream << "ldrs";
    } else if (insn.opcode == kLdurs) {
      stream << "ldurs";
    } else if (insn.opcode == kLdtrs) {
      stream << "ldtrs";
    } else if (insn.opcode == kSimdStr || insn.opcode == kStr) {
      stream << "str";
    } else if (insn.opcode == kSimdStur || insn.opcode == kStur) {
      stream << "stur";
    } else if (insn.opcode == kSttr) {
      stream << "sttr";
    } else {
      abort();
    }

    if (insn.opcode >= kLdr) {
      if (size == 8) {
        stream << "b ";
      } else if (size == 16) {
        stream << "h ";
      } else if (size == 32 && (insn.opcode == kLdrs || insn.opcode == kLdurs ||
                                insn.opcode == kLdtrs)) {
        stream << "w ";
      } else {
        stream << " ";
      }
    } else {
      stream << " ";
    }

    PrintOperands(stream, insn.operands);
  }
}

static void PrintDataProcessingTwoSource(std::ostream& stream,
                                         const Instruction& insn) {
  assert(insn.operands.size() == 3);

  switch (insn.opcode) {
    case kAsr: {
      stream << "asr ";
    } break;

    case kLsl: {
      stream << "lsl ";
    } break;

    case kLsr: {
      stream << "lsr ";
    } break;

    case kRor: {
      stream << "ror ";
    } break;

    case kSdiv: {
      stream << "sdiv ";
    } break;

    case kUdiv: {
      stream << "udiv ";
    } break;

    case kPacga: {
      stream << "pacga ";
    } break;

    case kCrc32b: {
      stream << "crc32b ";
    } break;

    case kCrc32h: {
      stream << "crc32h ";
    } break;

    case kCrc32w: {
      stream << "crc32w ";
    } break;

    case kCrc32x: {
      stream << "crc32x ";
    } break;

    case kCrc32cb: {
      stream << "crc32cb ";
    } break;

    case kCrc32ch: {
      stream << "crc32ch ";
    } break;

    case kCrc32cw: {
      stream << "crc32cw ";
    } break;

    case kCrc32cx: {
      stream << "crc32cx ";
    } break;

    default:
      abort();
  }

  PrintOperands(stream, insn.operands);
}

static void PrintDataProcessingOneSource(std::ostream& stream,
                                         const Instruction& insn) {
  assert(insn.operands.size() == 2);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);

  switch (insn.opcode) {
    case kRbit: {
      stream << "rbit " << rd << ", " << rn;
    } break;

    case kRev16: {
      stream << "rev16 " << rd << ", " << rn;
    } break;

    case kRev32: {
      stream << "rev32 " << rd << ", " << rn;
    } break;

    case kRev: {
      stream << "rev " << rd << ", " << rn;
    } break;

    case kClz: {
      stream << "clz " << rd << ", " << rn;
    } break;

    case kCls: {
      stream << "cls " << rd << ", " << rn;
    } break;

    case kPacia: {
      if (rn.name == Register::kXzr) {
        stream << "paciza " << rd;
      } else {
        stream << "pacia " << rd << ", " << rn;
      }
    } break;

    case kPacib: {
      if (rn.name == Register::kXzr) {
        stream << "pacizb " << rd;
      } else {
        stream << "pacib " << rd << ", " << rn;
      }
    } break;

    case kPacda: {
      if (rn.name == Register::kXzr) {
        stream << "pacdza " << rd;
      } else {
        stream << "pacda " << rd << ", " << rn;
      }
    } break;

    case kPacdb: {
      if (rn.name == Register::kXzr) {
        stream << "pacdzb " << rd;
      } else {
        stream << "pacdb " << rd << ", " << rn;
      }
    } break;

    case kAutia: {
      if (rn.name == Register::kXzr) {
        stream << "autiza " << rd;
      } else {
        stream << "autia " << rd << ", " << rn;
      }
    } break;

    case kAutib: {
      if (rn.name == Register::kXzr) {
        stream << "autizb " << rd;
      } else {
        stream << "autib " << rd << ", " << rn;
      }
    } break;

    case kAutda: {
      if (rn.name == Register::kXzr) {
        stream << "autdza " << rd;
      } else {
        stream << "autda " << rd << ", " << rn;
      }
    } break;

    case kAutdb: {
      if (rn.name == Register::kXzr) {
        stream << "autdzb " << rd;
      } else {
        stream << "autda " << rd << ", " << rn;
      }
    } break;

    case kXpaci: {
      stream << "xpaci " << rd;
    } break;

    case kXpacd: {
      stream << "xpacd " << rd;
    } break;

    default:
      abort();
  }
}

static void PrintLogicalShiftedRegister(std::ostream& stream,
                                        const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);
  Shift shift = std::get<Shift>(insn.operands[3]);

  switch (insn.opcode) {
    case kAndShiftedRegister: {
      if (insn.set_flags) {
        stream << "ands ";
      } else {
        stream << "and ";
      }
    } break;

    case kBicShiftedRegister: {
      if (insn.set_flags) {
        stream << "bics ";
      } else {
        stream << "bic ";
      }
    } break;

    case kOrrShiftedRegister: {
      if (rn.name == Register::kXzr) {
        stream << "mov " << rd << ", " << rm << shift;
        return;
      } else {
        stream << "orr ";
      }
    } break;

    case kOrnShiftedRegister: {
      if (rn.name == Register::kXzr) {
        stream << "mvn " << rd << ", " << rm << shift;
        return;
      } else {
        stream << "orn ";
      }
    } break;

    case kEorShiftedRegister: {
      stream << "eor ";
    } break;

    case kEonShiftedRegister: {
      stream << "eon ";
    } break;

    default:
      abort();
  }

  PrintOperands(stream, insn.operands);
}

static void PrintAddSubtractShiftedRegister(std::ostream& stream,
                                            const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);
  Shift shift = std::get<Shift>(insn.operands[3]);

  if (insn.opcode == kSubShiftedRegister) {
    if (insn.set_flags) {
      if (rd.name == Register::kXzr) {
        stream << "cmp " << rn << ", " << rm << shift;
      } else if (rn.name == Register::kXzr) {
        stream << "negs " << rd << ", " << rm << shift;
      } else {
        stream << "subs " << rd << ", " << rn << ", " << rm << shift;
      }
    } else {
      if (rn.name == Register::kXzr) {
        stream << "neg " << rd << ", " << rm << shift;
      } else {
        stream << "sub " << rd << ", " << rn << ", " << rm << shift;
      }
    }
  } else {
    if (insn.set_flags) {
      if (rd.name == Register::kXzr) {
        stream << "cmn " << rn << ", " << rm << shift;
      } else {
        stream << "adds " << rd << ", " << rn << ", " << rm << shift;
      }
    } else {
      stream << "add " << rd << ", " << rn << ", " << rm << shift;
    }
  }
}

static void PrintAddSubtractExtendedRegister(std::ostream& stream,
                                             const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);
  Extend extend = std::get<Extend>(insn.operands[3]);

  if (insn.opcode == kSubExtendedRegister) {
    if (insn.set_flags) {
      if (rd.name == Register::kXzr) {
        stream << "cmp " << rn << ", " << rm << extend;
      } else {
        stream << "subs " << rd << ", " << rn << ", " << rm << extend;
      }
    } else {
      stream << "sub " << rd << ", " << rn << ", " << rm << extend;
    }
  } else {
    if (insn.set_flags) {
      if (rd.name == Register::kXzr) {
        stream << "cmn " << rn << ", " << rm << extend;
      } else {
        stream << "adds " << rd << ", " << rn << ", " << rm << extend;
      }
    } else {
      stream << "add " << rd << ", " << rn << ", " << rm << extend;
    }
  }
}

static void PrintAddSubtractWithCarry(std::ostream& stream,
                                      const Instruction& insn) {
  assert(insn.operands.size() == 3);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);

  if (insn.opcode == kSbc) {
    if (insn.set_flags) {
      if (rn.name == Register::kXzr) {
        stream << "ngcs " << rd << ", " << rm;
      } else {
        stream << "sbcs " << rd << ", " << rn << ", " << rm;
      }
    } else {
      if (rn.name == Register::kXzr) {
        stream << "ngc " << rd << ", " << rm;
      } else {
        stream << "sbc " << rd << ", " << rn << ", " << rm;
      }
    }
  } else {
    if (insn.set_flags) {
      stream << "adcs " << rd << ", " << rn << ", " << rm;
    } else {
      stream << "adc " << rd << ", " << rn << ", " << rm;
    }
  }
}

static void PrintConditionalCompare(std::ostream& stream,
                                    const Instruction& insn) {
  assert(insn.operands.size() == 3);

  if (insn.opcode == kCcmn) {
    stream << "ccmn ";
  } else {
    stream << "ccmp ";
  }

  PrintOperands(stream, insn.operands);
  stream << ", ";
  PrintConditionCode(stream, insn.cc);
}

static void PrintConditionalSelect(std::ostream& stream,
                                   const Instruction& insn) {
  assert(insn.operands.size() == 3);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);

  if (insn.opcode == kCsel) {
    stream << "csel " << rd << ", " << rn << ", " << rm;
  } else if (insn.opcode == kCsinc) {
    if (rn.name == Register::kXzr && rm.name == Register::kXzr) {
      stream << "cset " << rd;
    } else if (rn.name == rm.name) {
      stream << "cinc " << rd << ", " << rn;
    } else {
      stream << "csinc " << rd << ", " << rn << ", " << rm;
    }
  } else if (insn.opcode == kCsinv) {
    if (rn.name == Register::kXzr && rm.name == Register::kXzr) {
      stream << "csetm " << rd;
    } else if (rn.name == rm.name) {
      stream << "cinv " << rd << ", " << rn;
    } else {
      stream << "csinv " << rd << ", " << rn << ", " << rm;
    }
  } else if (insn.opcode == kCsneg) {
    if (rn.name == rm.name) {
      stream << "cneg " << rd << ", " << rn;
    } else {
      stream << "csneg " << rd << ", " << rn << ", " << rm;
    }
  } else {
    abort();
  }

  stream << ", ";
  PrintConditionCode(stream, insn.cc);
}

static void PrintDataProcessingThreeSource(std::ostream& stream,
                                           const Instruction& insn) {
  assert(insn.operands.size() == 4);

  Register rd = std::get<Register>(insn.operands[0]);
  Register rn = std::get<Register>(insn.operands[1]);
  Register rm = std::get<Register>(insn.operands[2]);
  Register ra = std::get<Register>(insn.operands[3]);

  switch (insn.opcode) {
    case kMadd: {
      if (ra.name == Register::kXzr) {
        stream << "mul " << rd << ", " << rn << ", " << rm;
      } else {
        stream << "madd " << rd << ", " << rn << ", " << rm << ", " << ra;
      }
    } break;

    case kMsub: {
      if (ra.name == Register::kXzr) {
        stream << "mneg " << rd << ", " << rn << ", " << rm;
      } else {
        stream << "msub " << rd << ", " << rn << ", " << rm << ", " << ra;
      }
    } break;

    case kSmaddl: {
      if (ra.name == Register::kXzr) {
        stream << "smull " << rd << ", " << rn << ", " << rm;
      } else {
        stream << "smaddl " << rd << ", " << rn << ", " << rm << ", " << ra;
      }
    } break;

    case kSmsubl: {
      if (ra.name == Register::kXzr) {
        stream << "smnegl " << rd << ", " << rn << ", " << rm;
      } else {
        stream << "smsubl " << rd << ", " << rn << ", " << rm << ", " << ra;
      }
    } break;

    case kSmulh: {
      stream << "smulh " << rd << ", " << rn << ", " << rm;
    } break;

    case kUmaddl: {
      if (ra.name == Register::kXzr) {
        stream << "umull " << rd << ", " << rn << ", " << rm;
      } else {
        stream << "umaddl " << rd << ", " << rn << ", " << rm << ", " << ra;
      }
    } break;

    case kUmsubl: {
      if (ra.name == Register::kXzr) {
        stream << "umnegl " << rd << ", " << rn << ", " << rm;
      } else {
        stream << "umsubl " << rd << ", " << rn << ", " << rm << ", " << ra;
      }
    } break;

    case kUmulh: {
      stream << "umulh " << rd << ", " << rn << ", " << rm;
    } break;

    default:
      abort();
  }
}

std::ostream& operator<<(std::ostream& stream, const Instruction& insn) {
  if (insn.opcode <= kAdrp) {
    PrintPcRelativeAddressing(stream, insn);
  } else if (insn.opcode <= kSubImmediate) {
    PrintAddSubtractImmediate(stream, insn);
  } else if (insn.opcode <= kEorImmediate) {
    PrintLogicalImmediate(stream, insn);
  } else if (insn.opcode <= kMovz) {
    PrintMoveWideImmediate(stream, insn);
  } else if (insn.opcode <= kUbfm) {
    PrintBitfield(stream, insn);
  } else if (insn.opcode <= kExtr) {
    PrintExtract(stream, insn);
  } else if (insn.opcode <= kBCond) {
    PrintConditionalBranch(stream, insn);
  } else if (insn.opcode <= kSvc) {
    PrintExceptionGeneration(stream, insn);
  } else if (insn.opcode <= kYield) {
    PrintSystem(stream, insn);
  } else if (insn.opcode <= kRetabz) {
    PrintBranchRegister(stream, insn);
  } else if (insn.opcode <= kBl) {
    PrintBranchImmediate(stream, insn);
  } else if (insn.opcode <= kCbz) {
    PrintCompareAndBranch(stream, insn);
  } else if (insn.opcode <= kTbz) {
    PrintTestAndBranch(stream, insn);
  } else if (insn.opcode <= kStxr) {
    PrintLoadStoreExclusive(stream, insn);
  } else if (insn.opcode <= kPrfmLiteral) {
    PrintLoadLiteral(stream, insn);
  } else if (insn.opcode <= kStp) {
    PrintLoadStorePair(stream, insn);
  } else if (insn.opcode <= kStur) {
    PrintLoadStore(stream, insn);
  } else if (insn.opcode <= kUdiv) {
    PrintDataProcessingTwoSource(stream, insn);
  } else if (insn.opcode <= kXpaci) {
    PrintDataProcessingOneSource(stream, insn);
  } else if (insn.opcode <= kEonShiftedRegister) {
    PrintLogicalShiftedRegister(stream, insn);
  } else if (insn.opcode <= kSubShiftedRegister) {
    PrintAddSubtractShiftedRegister(stream, insn);
  } else if (insn.opcode <= kSubExtendedRegister) {
    PrintAddSubtractExtendedRegister(stream, insn);
  } else if (insn.opcode <= kSbc) {
    PrintAddSubtractWithCarry(stream, insn);
  } else if (insn.opcode <= kCcmp) {
    PrintConditionalCompare(stream, insn);
  } else if (insn.opcode <= kCsneg) {
    PrintConditionalSelect(stream, insn);
  } else if (insn.opcode <= kUmsubl) {
    PrintDataProcessingThreeSource(stream, insn);
  } else {
    stream << "invalid";
  }

  return stream;
}

std::ostream& operator<<(std::ostream& stream, const Operand& opnd) {
  switch (opnd.index()) {
    case kImmediate: {
      PrintImmediate(stream, std::get<Immediate>(opnd));
    } break;

    case kRegister: {
      PrintRegister(stream, std::get<Register>(opnd));
    } break;

    case kSystemRegister: {
      PrintSystemRegister(stream, std::get<SystemRegister>(opnd));
    } break;

    case kShift: {
      PrintShift(stream, std::get<Shift>(opnd));
    } break;

    case kExtend: {
      PrintExtend(stream, std::get<Extend>(opnd));
    } break;

    case kImmediateOffset: {
      PrintImmediateOffset(stream, std::get<ImmediateOffset>(opnd));
    } break;

    case kRegisterOffset: {
      PrintRegisterOffset(stream, std::get<RegisterOffset>(opnd));
    } break;

    default:
      stream << "invalid";
  }

  return stream;
}
}  // namespace decoder
}  // namespace aarch64
}  // namespace reil

```

`tinyinst-coverage.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#define  _CRT_SECURE_NO_WARNINGS

#include <stdio.h>
#include <inttypes.h>
#include <stdbool.h>

#include "common.h"
#include "litecov.h"

uint8_t *trace_bits;

LiteCov *instrumentation;
bool persist;
int num_iterations;
int cur_iteration;

// run a single iteration over the target process
// whether it's the whole process or target method
// and regardless if the target is persistent or not
// (should know what to do in pretty much all cases)
void RunTarget(int argc, char **argv, unsigned int pid, uint32_t timeout) {
  DebuggerStatus status;

  if (instrumentation->IsTargetFunctionDefined()) {
    if (cur_iteration == num_iterations) {
      instrumentation->Kill();
      cur_iteration = 0;
    }
  }

  // else clear only when the target function is reached
  if (!instrumentation->IsTargetFunctionDefined()) {
    instrumentation->ClearCoverage();
  }

  if (instrumentation->IsTargetAlive() && persist) {
    status = instrumentation->Continue(timeout);
  } else {
    instrumentation->Kill();
    cur_iteration = 0;
    if (argc) {
      status = instrumentation->Run(argc, argv, timeout);
    } else {
      status = instrumentation->Attach(pid, timeout);
    }
  }

  // if target function is defined,
  // we should wait until it is hit
  if (instrumentation->IsTargetFunctionDefined()) {
    if ((status != DEBUGGER_TARGET_START) && argc) {
      // try again with a clean process
      WARN("Target function not reached, retrying with a clean process\n");
      instrumentation->Kill();
      cur_iteration = 0;
      status = instrumentation->Run(argc, argv, timeout);
    }

    if (status != DEBUGGER_TARGET_START) {
      switch (status) {
      case DEBUGGER_CRASHED:
        FATAL("Process crashed before reaching the target method\n");
        break;
      case DEBUGGER_HANGED:
        FATAL("Process hanged before reaching the target method\n");
        break;
      case DEBUGGER_PROCESS_EXIT:
        FATAL("Process exited before reaching the target method\n");
        break;
      default:
        FATAL("An unknown problem occured before reaching the target method\n");
        break;
      }
    }

    instrumentation->ClearCoverage();

    status = instrumentation->Continue(timeout);
  }

  switch (status) {
  case DEBUGGER_CRASHED:
    printf("Process crashed\n");
    instrumentation->Kill();
    break;
  case DEBUGGER_HANGED:
    printf("Process hanged\n");
    instrumentation->Kill();
    break;
  case DEBUGGER_PROCESS_EXIT:
    if (instrumentation->IsTargetFunctionDefined()) {
      printf("Process exit during target function\n");
    } else {
      printf("Process finished normally\n");
    }
    break;
  case DEBUGGER_TARGET_END:
    if (instrumentation->IsTargetFunctionDefined()) {
      printf("Target function returned normally\n");
      cur_iteration++;
    } else {
      FATAL("Unexpected status received from the debugger\n");
    }
    break;
  default:
    FATAL("Unexpected status received from the debugger\n");
    break;
  }
}

int main(int argc, char **argv)
{
  instrumentation = new LiteCov();
  instrumentation->Init(argc, argv);

  int target_opt_ind = 0;
  for (int i = 1; i < argc; i++) {
    if (strcmp(argv[i], "--") == 0) {
      target_opt_ind = i + 1;
      break;
    }
  }

  int target_argc = (target_opt_ind) ? argc - target_opt_ind : 0;
  char **target_argv = (target_opt_ind) ? argv + target_opt_ind : NULL;

  unsigned int pid = GetIntOption("-pid", argc, argv, 0);
  persist = GetBinaryOption("-persist", argc, argv, false);
  num_iterations = GetIntOption("-iterations", argc, argv, 1);
  char *outfile = GetOption("-coverage_file", argc, argv);

  if (!target_argc && !pid) {
    printf("Usage:\n");
    printf("%s <options> -- <target command line>\n", argv[0]);
    printf("Or:\n");
    printf("%s <options> -pid <pid to attach to>\n", argv[0]);
    return 0;
  }

  Coverage coverage, newcoverage;

  for (int i = 0; i < num_iterations; i++) {
    RunTarget(target_argc, target_argv, pid, 0xFFFFFFFF);

    Coverage newcoverage;

    instrumentation->GetCoverage(newcoverage, true);

    for (auto iter = newcoverage.begin(); iter != newcoverage.end(); iter++) {
      printf("Found %zd new offsets in %s\n", iter->offsets.size(), iter->module_name.c_str());
    }

    instrumentation->IgnoreCoverage(newcoverage);

    MergeCoverage(coverage, newcoverage);
  }
 
  if (outfile) WriteCoverage(coverage, outfile);

  instrumentation->Kill();

  return 0;
}

```

`tinyinst.cpp`:

```cpp
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#define  _CRT_SECURE_NO_WARNINGS

#include <stdio.h>
#include <stdbool.h>
#include <inttypes.h>
#include <algorithm>

#include <list>

#include "tinyinst.h"

#ifdef ARM64
  #include "arch/arm64/arm64_assembler.h"
#else
  #include "arch/x86/x86_assembler.h"
#endif
#if defined(__APPLE__) && defined(ARM64)
  #include <set>
  #include "macOS/dyld_cache_map_parser.h"
  #define DYLD_MAP_FILE "/System/Library/dyld/dyld_shared_cache_arm64e.map"
#endif

ModuleInfo::ModuleInfo() {
  module_name[0] = 0;
  module_header = NULL;
  min_address = 0;
  max_address = 0;
  loaded = false;
  instrumented = false;
  instrumented_code_local = NULL;
  instrumented_code_remote = NULL;
  instrumented_code_remote_previous = NULL;
  instrumented_code_size = 0;
  unwind_data = NULL;
}

void ModuleInfo::ClearInstrumentation() {
  instrumented = false;

  for (auto iter = executable_ranges.begin(); iter != executable_ranges.end(); iter++) {
    if (iter->data) free(iter->data);
  }
  executable_ranges.clear();
  code_size = 0;

  if (instrumented_code_local) free(instrumented_code_local);

  instrumented_code_local = NULL;
  instrumented_code_remote = NULL;
  instrumented_code_remote_previous = NULL;

  instrumented_code_size = 0;
  instrumented_code_allocated = 0;

  basic_blocks.clear();
  address_map.clear();

  br_indirect_newtarget_global = 0;
  br_indirect_newtarget_list.clear();

  jumptable_offset = 0;
  jumptable_address_offset = 0;

  invalid_instructions.clear();
  tracepoints.clear();
}

void TinyInst::InvalidateCrossModuleLink(CrossModuleLink *link) {
  ModuleInfo *module1 = link->module1;
  size_t original_value = ReadPointer(module1, link->offset1);
  WritePointerAtOffset(module1, original_value, link->offset1 + child_ptr_size);
  CommitCode(module1, link->offset1 + child_ptr_size, child_ptr_size);
}

void TinyInst::FixCrossModuleLink(CrossModuleLink *link) {
  ModuleInfo *module1 = link->module1;
  ModuleInfo *module2 = link->module2;

  size_t original_value = (size_t)module2->min_address + link->offset2;
  size_t translated_value = GetTranslatedAddress(module2, original_value);

  WritePointerAtOffset(module1, original_value, link->offset1);
  WritePointerAtOffset(module1, translated_value, link->offset1 + child_ptr_size);

  CommitCode(module1, link->offset1, 2 * child_ptr_size);
}

void TinyInst::InvalidateCrossModuleLinks(ModuleInfo *module) {
  for (auto iter = cross_module_links.begin(); iter != cross_module_links.end(); iter++) {
    if (iter->module2 == module) {
      InvalidateCrossModuleLink(&(*iter));
    }
  }
}

void TinyInst::InvalidateCrossModuleLinks() {
  for (auto iter = cross_module_links.begin(); iter != cross_module_links.end(); iter++) {
    InvalidateCrossModuleLink(&(*iter));
  }
}

void TinyInst::FixCrossModuleLinks(ModuleInfo *module) {
  for (auto iter = cross_module_links.begin(); iter != cross_module_links.end(); iter++) {
    if (iter->module2 == module) {
      FixCrossModuleLink(&(*iter));
    }
  }
}

void TinyInst::ClearCrossModuleLinks(ModuleInfo *module) {
  auto iter = cross_module_links.begin();
  while (iter != cross_module_links.end()) {
    if (iter->module1 == module) {
      iter = cross_module_links.erase(iter);
    } else {
      iter++;
    }
  }
}

void TinyInst::ClearCrossModuleLinks() {
  cross_module_links.clear();
}

// Global jumptable for indirect jumps/calls.
// This is an array of size JUMPTABLE_SIZE where each entry initially
// points to indirect_breakpoint_address.
// When a new indirect jump/call target is detected, this will cause a breakpoint
// which will be resolved by adding a new entry into this hashtable.
void TinyInst::InitGlobalJumptable(ModuleInfo *module) {
  size_t code_size_before = module->instrumented_code_allocated;

  module->jumptable_offset = module->instrumented_code_allocated;

  module->br_indirect_newtarget_global =
    (size_t)module->instrumented_code_remote +
    module->instrumented_code_allocated +
    JUMPTABLE_SIZE * child_ptr_size +
    child_ptr_size;

  for (size_t i = 0; i < JUMPTABLE_SIZE; i++) {
    WritePointer(module, module->br_indirect_newtarget_global);
  }

  module->jumptable_address_offset = module->instrumented_code_allocated;
  WritePointer(module, (size_t)module->instrumented_code_remote + module->jumptable_offset);

  assembler_->Breakpoint(module);

  size_t code_size_after = module->instrumented_code_allocated;

  CommitCode(module, code_size_before, (code_size_after - code_size_before));
}

// gets the current code address in the instrumented code
// *in the child process*
size_t TinyInst::GetCurrentInstrumentedAddress(ModuleInfo *module) {
  return (size_t)module->instrumented_code_remote + module->instrumented_code_allocated;
}

// Writes the modified code from the debugger process into the target process
void TinyInst::CommitCode(ModuleInfo *module, size_t start_offset, size_t size) {
  if (!module->instrumented_code_remote) return;

  RemoteWrite(module->instrumented_code_remote + start_offset,
              module->instrumented_code_local + start_offset,
              size);
}

// Checks if there is sufficient space and writes code at the current offset
void TinyInst::WriteCode(ModuleInfo *module, void *data, size_t size) {
  if (module->instrumented_code_allocated + size > module->instrumented_code_size) {
    FATAL("Insufficient memory allocated for instrumented code");
  }

  memcpy(module->instrumented_code_local + module->instrumented_code_allocated, data, size);
  module->instrumented_code_allocated += size;
}

// Checks if there is sufficient space and writes code at the chosen offset
void TinyInst::WriteCodeAtOffset(ModuleInfo *module, size_t offset, void *data, size_t size) {
  if (offset + size > module->instrumented_code_size) {
    FATAL("Insufficient memory allocated for instrumented code");
  }

  memcpy(module->instrumented_code_local + offset, data, size);

  if (offset + size > module->instrumented_code_allocated) {
    module->instrumented_code_allocated = offset + size;
  }
}

// writes a pointer to the instrumented code
void TinyInst::WritePointer(ModuleInfo *module, size_t value) {
  if (module->instrumented_code_allocated + child_ptr_size > module->instrumented_code_size) {
    FATAL("Insufficient memory allocated for instrumented code");
  }

  if (child_ptr_size == 8) {
    *(uint64_t *)(module->instrumented_code_local + module->instrumented_code_allocated) =
      (uint64_t)value;
  } else {
    *(uint32_t *)(module->instrumented_code_local + module->instrumented_code_allocated) =
      (uint32_t)value;
  }

  module->instrumented_code_allocated += child_ptr_size;
}

// writes a pointer to the instrumented code
void TinyInst::WritePointerAtOffset(ModuleInfo *module, size_t value, size_t offset) {
  if (offset + child_ptr_size > module->instrumented_code_size) {
    FATAL("Insufficient memory allocated for instrumented code");
  }

  if (child_ptr_size == 8) {
    *(uint64_t *)(module->instrumented_code_local + offset) = (uint64_t)value;
  } else {
    *(uint32_t *)(module->instrumented_code_local + offset) = (uint32_t)value;
  }

  if (offset + child_ptr_size > module->instrumented_code_allocated) {
    module->instrumented_code_allocated += offset + child_ptr_size;
  }
}

// reads a pointer from the instrumented code
size_t TinyInst::ReadPointer(ModuleInfo *module, size_t offset) {
  if (child_ptr_size == 8) {
    return (size_t)(*(uint64_t *)(module->instrumented_code_local + offset));
  } else {
    return (size_t)(*(uint32_t *)(module->instrumented_code_local + offset));
  }
}

// fixes an offset in the jump instruction (at offset jmp_offset in the
// instrumented code) to jump to the given basic block (at offset bb in the
// original code) in case the basic block hasn't been instrumented yet, queues
// it for instrumentation
void TinyInst::FixOffsetOrEnqueue(
    ModuleInfo *module,
    uint32_t bb,
    uint32_t jmp_offset,
    std::set<char *> *queue,
    std::list<std::pair<uint32_t, uint32_t>> *offset_fixes) {
  auto iter = module->basic_blocks.find(bb);
  if (iter == module->basic_blocks.end()) {
    char *address = (char *)module->min_address + bb;
    if (queue->find(address) == queue->end()) {
      queue->insert(address);
    }
    offset_fixes->push_back({bb, jmp_offset});
  } else {
    assembler_->FixOffset(module, jmp_offset, iter->second);
  }
}

// various breakpoints
bool TinyInst::HandleBreakpoint(void *address) {
  ModuleInfo *module = GetModuleFromInstrumented((size_t)address);
  if (!module) return false;

  // bb tracing
  if (trace_basic_blocks) {
    auto iter = module->tracepoints.find((size_t)address);
    if (iter != module->tracepoints.end()) {

      printf("TRACE: Executing basic block, original at %p, instrumented at %p\n",
             (void *)iter->second, (void *)iter->first);
      return true;
    } else {
      printf("TRACE: Breakpoint\n");
    }
  }

  // indirect jump new target
  if (HandleIndirectJMPBreakpoint(address)) return true;

  // invalid instruction
  if (module->invalid_instructions.find((size_t)address) != module->invalid_instructions.end()) {
    WARN("Attempting to execute an instruction TinyInst couldn't translate");
    WARN("This could be either due to a bug in the target or the bug/incompatibility in TinyInst");
    WARN("The target will crash now");
    return true;
  }

  if(unwind_generator->HandleBreakpoint(module, address)) {
    return true;
  }

  return false;
}

// handles a breakpoint that occurs
// when an indirect jump or call wants to go to a previously
// unseen target
bool TinyInst::HandleIndirectJMPBreakpoint(void *address) {
  if (indirect_instrumentation_mode == II_NONE) return false;

  ModuleInfo *module = GetModuleFromInstrumented((size_t)address);
  if (!module) return false;

  bool is_indirect_breakpoint = false;
  bool global_indirect;

  size_t list_head_offset;

  IndirectBreakpoinInfo bp_info = {};
  if ((size_t)address == module->br_indirect_newtarget_global) {
    is_indirect_breakpoint = true;
    global_indirect = true;
  } else {
    auto iter = module->br_indirect_newtarget_list.find((size_t)address);
    if (iter != module->br_indirect_newtarget_list.end()) {
      is_indirect_breakpoint = true;
      global_indirect = false;
      bp_info = iter->second;
      list_head_offset = iter->second.list_head;
    }
  }
  if (!is_indirect_breakpoint) return false;

  size_t original_address = GetRegister(ORIG_ADDR_REG);

  // if it's a global indirect, list head must be calculated from target
  // otherwise it's a per-callsite indirect and the list head was set earlier
  if (global_indirect) {
    list_head_offset = module->jumptable_offset +
                       original_address & ((JUMPTABLE_SIZE - 1) * child_ptr_size);
  }

  size_t translated_address;
  ModuleInfo *target_module = GetModule((size_t)original_address);

  if (target_module == module) {
    translated_address = GetTranslatedAddress(module, original_address);
  } else if (target_module && instrument_cross_module_calls) {
    translated_address = GetTranslatedAddress(target_module, original_address);
  } else {
    translated_address = original_address;
  }

  // printf("Adding jumptable entry, %p -> %p\n",
  //        (void *)original_address, (void *)translated_address);

  size_t entry_offset = AddTranslatedJump(module,
                                          target_module,
                                          original_address,
                                          translated_address,
                                          list_head_offset,
                                          bp_info,
                                          global_indirect);

  size_t continue_address = (size_t)module->instrumented_code_remote + entry_offset;

  if (target_module) {
    continue_address = unwind_generator->MaybeRedirectExecution(target_module, continue_address);
  }

  // redirect execution to just created entry which should handle it immediately
  SetRegister(ARCH_PC, continue_address);
  return true;
}


// adds another observed original_target -> actual_target pair
// to the golbal jumptable at the appropriate location
size_t TinyInst::AddTranslatedJump(ModuleInfo *module,
                                   ModuleInfo *target_module,
                                   size_t original_target,
                                   size_t actual_target,
                                   size_t list_head_offset,
                                   IndirectBreakpoinInfo& breakpoint_info,
                                   bool global_indirect) {
  size_t entry_offset = module->instrumented_code_allocated;

  size_t previous;
  size_t previous_offset;

  // gets the previous list head
  if (child_ptr_size == 8) {
    previous = (size_t)
      (*(uint64_t *)(module->instrumented_code_local + list_head_offset));
  } else {
    previous =
        *(uint32_t *)(module->instrumented_code_local + list_head_offset);
  }
  previous_offset = previous - (size_t)module->instrumented_code_remote;

  assembler_->TranslateJmp(module,
                           target_module,
                           original_target,
                           breakpoint_info,
                           global_indirect,
                           previous_offset);

  if (target_module && (module != target_module)) {
    CrossModuleLink link;
    link.module1 = module;
    link.module2 = target_module;
    link.offset1 = module->instrumented_code_allocated;
    link.offset2 = original_target - (size_t)target_module->min_address;
    // printf("Cross module link to %p\n", (void *)original_target);
    cross_module_links.push_back(link);
  }

  WritePointer(module, original_target);
  WritePointer(module, actual_target);

  // add to the head of the linked list
  if (child_ptr_size == 8) {
    *(uint64_t *)(module->instrumented_code_local + list_head_offset) =
      (uint64_t)((size_t)module->instrumented_code_remote + entry_offset);
  } else {
    *(uint32_t *)(module->instrumented_code_local + list_head_offset) =
      (uint32_t)((size_t)module->instrumented_code_remote + entry_offset);
  }

  CommitCode(module, list_head_offset, child_ptr_size);
  CommitCode(module,
             entry_offset,
             module->instrumented_code_allocated - entry_offset);

  return entry_offset;
}

TinyInst::IndirectInstrumentation TinyInst::ShouldInstrumentIndirect(
  ModuleInfo *module,
  Instruction& inst,
  size_t instruction_address) {

  if (inst.iclass == InstructionClass::RET) {
    if (!patch_return_addresses) {
      return II_NONE;
    }
  } else {
    if ((inst.iclass != InstructionClass::IJUMP) &&
        (inst.iclass != InstructionClass::ICALL))
      return II_NONE;
  }

  if (indirect_instrumentation_mode != II_AUTO) {
    return indirect_instrumentation_mode;
  } else {
    // default to the most performant mode which is II_GLOBAL
#ifdef ARM64
    return II_LOCAL;
#else
    return II_GLOBAL;
#endif
  }
}

// when an invalid instruction is encountered
// emit a breakpoint followed by crashing the process
void TinyInst::InvalidInstruction(ModuleInfo *module) {
  size_t breakpoint_address = (size_t)module->instrumented_code_remote +
                              module->instrumented_code_allocated;
  assembler_->Breakpoint(module);
  module->invalid_instructions.insert(breakpoint_address);
  assembler_->Crash(module);
}

void TinyInst::InstrumentIndirect(ModuleInfo *module,
                                  Instruction& inst,
                                  size_t instruction_address,
                                  IndirectInstrumentation mode,
                                  size_t bb_address)
{
  if (mode == II_GLOBAL) {
    assembler_->InstrumentGlobalIndirect(module, inst, instruction_address);
  } else if (mode == II_LOCAL) {
    assembler_->InstrumentLocalIndirect(module, inst, instruction_address, bb_address);
  } else {
    FATAL("Unexpected IndirectInstrumentation value");
  }
}

void TinyInst::TranslateBasicBlock(char *address,
                                   ModuleInfo *module,
                                   std::set<char *> *queue,
                                   std::list<std::pair<uint32_t, uint32_t>> *offset_fixes) {
  uint32_t original_offset = (uint32_t)((size_t)address - (size_t)(module->min_address));
  uint32_t translated_offset = (uint32_t)module->instrumented_code_allocated;

  unwind_generator->OnBasicBlockStart(module,
    (size_t)address,
    GetCurrentInstrumentedAddress(module));

  // printf("Instrumenting bb, original at %p, instrumented at %p\n",
  //        address, module->instrumented_code_remote + translated_offset);

  module->basic_blocks.insert({ original_offset, translated_offset });

  AddressRange *range = GetRegion(module, (size_t)address);
  if (!range) {
    // just insert a jump to address
    assembler_->JmpAddress(module, (size_t)address);
    return;
  }

  uint32_t range_offset = (uint32_t)((size_t)address - (size_t)range->from);
  size_t code_size = (uint32_t)((size_t)range->to - (size_t)address);
  char *code_ptr = range->data + range_offset;

  size_t offset = 0, last_offset = 0;

  if (trace_basic_blocks) {
    size_t breakpoint_address = GetCurrentInstrumentedAddress(module);
    assembler_->Breakpoint(module);
    module->tracepoints[breakpoint_address] = (size_t)address;
  } else if (GetTargetMethodAddress()) {
    // hack, allow 1 or 4 byte of unused space at the beginning
    // of the target method. This is needed because we
    // are setting a brekpoint here. If this breakpoint falls
    // into code inserted by the client, and the client modifies
    // that code later, we loose the breakpoint.
    if(GetTargetMethodAddress() == address) {
      assembler_->Nop(module);
    }
  }

  // write pre-bb instrumentation
  InstrumentBasicBlock(module, (size_t)address);

  Instruction inst;
  while (true) {
    bool success =
      assembler_->DecodeInstruction(
        inst,
        (const unsigned char *)(code_ptr + offset),
        (unsigned int)(code_size - offset));

    if (!success) break;

    unwind_generator->OnInstruction(module,
      (size_t)address + offset,
      GetCurrentInstrumentedAddress(module));

    if(full_address_map) {
      size_t original_address = (size_t)address + offset;
      size_t instrumented_address = GetCurrentInstrumentedAddress(module);
      module->address_map[instrumented_address] = original_address;
    }
    
    // instruction-level-instrumentation
    InstructionResult instrumentation_result =
      InstrumentInstruction(module, inst, (size_t)address, (size_t)address + offset);

    switch (instrumentation_result) {
    case INST_HANDLED:
      offset += inst.length;
      continue;
    case INST_STOPBB:
      unwind_generator->OnBasicBlockEnd(module,
        (size_t)address + offset + inst.length,
        GetCurrentInstrumentedAddress(module));
      return;
    case INST_NOTHANDLED:
    default:
      break;
    }

    last_offset = offset;
    offset += inst.length;

    if (inst.bbend) break;

    assembler_->FixInstructionAndOutput(module, inst, (const unsigned char *)(code_ptr + last_offset), (const unsigned char *)(address + last_offset));
  }

  if (!inst.bbend) {
    // WARN("Could not find end of bb at %p.\n", address);
    InvalidInstruction(module);
    unwind_generator->OnBasicBlockEnd(module,
      (size_t)address + offset,
      GetCurrentInstrumentedAddress(module));
    return;
  }

  assembler_->HandleBasicBlockEnd(address, module, queue, offset_fixes, inst, code_ptr, offset, last_offset);
  unwind_generator->OnBasicBlockEnd(module,
    (size_t)address + offset,
    GetCurrentInstrumentedAddress(module));
}

// starting from address, starts instrumenting code in the module
// any other basic blocks detected during instrumentation
// (e.g. jump, call targets) get added to the queue
// and instrumented as well
void TinyInst::TranslateBasicBlockRecursive(char *address, ModuleInfo *module) {
  std::set<char *> queue;
  std::list<std::pair<uint32_t, uint32_t>> offset_fixes;

  size_t code_size_before = module->instrumented_code_allocated;

  TranslateBasicBlock(address, module, &queue, &offset_fixes);

  while (!queue.empty()) {
    address = *queue.begin();
    TranslateBasicBlock(address, module, &queue, &offset_fixes);
    queue.erase(address);
  }

  for (auto iter = offset_fixes.begin(); iter != offset_fixes.end(); iter++) {
    uint32_t bb = iter->first;
    uint32_t jmp_offset = iter->second;

    auto bb_iter = module->basic_blocks.find(bb);
    if (bb_iter == module->basic_blocks.end()) {
      FATAL("Couldn't fix jump offset\n");
    }

    assembler_->FixOffset(module, jmp_offset, bb_iter->second);
  }

  size_t code_size_after = module->instrumented_code_allocated;

  // Commit everything in one go here
  CommitCode(module, code_size_before, (code_size_after - code_size_before));
}

// gets ModuleInfo for the module specified by name
ModuleInfo *TinyInst::GetModuleByName(const char *name) {
  for (auto iter = instrumented_modules.begin(); iter != instrumented_modules.end(); iter++) {
    ModuleInfo *cur_module = *iter;
    if (_stricmp(cur_module->module_name.c_str(), name) == 0) {
      return cur_module;
    }
  }

  return NULL;
}

// gets module corresponding to address
ModuleInfo *TinyInst::GetModule(size_t address) {
  for (auto iter = instrumented_modules.begin(); iter != instrumented_modules.end(); iter++) {
    ModuleInfo *cur_module = *iter;
    if (!cur_module->loaded) continue;
    if (!cur_module->instrumented) continue;
    if ((address >= (size_t)cur_module->min_address) &&
        (address < (size_t)cur_module->max_address))
    {
      if (GetRegion(cur_module, address)) {
        return cur_module;
      }
    }
  }

  return NULL;
}

// gets a memory region corresponding to address
AddressRange *TinyInst::GetRegion(ModuleInfo *module, size_t address) {
  for (auto iter = module->executable_ranges.begin();
       iter != module->executable_ranges.end(); iter++)
  {
    AddressRange *cur_range = &(*iter);
    if (((size_t)address >= cur_range->from) && ((size_t)address < cur_range->to)) {
      return cur_range;
      break;
    }
  }

  return NULL;
}

// gets module where address falls into instrumented code buffer
ModuleInfo *TinyInst::GetModuleFromInstrumented(size_t address) {
  for (auto iter = instrumented_modules.begin(); iter != instrumented_modules.end(); iter++) {
    ModuleInfo *cur_module = *iter;
    if (!cur_module->loaded) continue;
    if (!cur_module->instrumented) continue;
    if ((address >= (size_t)cur_module->instrumented_code_remote) &&
        (address < ((size_t)cur_module->instrumented_code_remote +
                    cur_module->instrumented_code_allocated)))
    {
      return cur_module;
      break;
    }
  }

  return NULL;
}

void TinyInst::OnCrashed(Exception *exception_record) {
  // clear known entries on crash
  for (auto module : instrumented_modules) {
    module->entry_offsets.clear();
  }
  
  char *address = (char *)exception_record->ip;

  printf("Exception at address %p\n", static_cast<void*>(address));
  if (exception_record->type == ACCESS_VIOLATION) {
    // printf("Access type: %d\n", (int)exception_record->ExceptionInformation[0]);
    printf("Access address: %p\n", exception_record->access_address);
  }

  ModuleInfo *module = GetModuleFromInstrumented((size_t)address);
  if (!module) return;

  printf("Exception in instrumented module %s %p\n", module->module_name.c_str(), module->module_header);
  size_t offset = (size_t)address - (size_t)module->instrumented_code_remote;

  if(full_address_map && !module->address_map.empty()) {
    auto iter = module->address_map.upper_bound((size_t)address);
    if(iter != module->address_map.begin()) {
      --iter;
      printf("Original exception address (could be incorrect): %p\n", (void *)iter->second);
    }
  }
  
  printf("Code before:\n");
  size_t offset_from;
  if (offset < 10) offset_from = 0;
  else offset_from = offset - 10;
  for (size_t i = offset_from; i < offset; i++) {
    printf("%02x ", (unsigned char)(module->instrumented_code_local[i]));
  }
  printf("\n");
  printf("Code after:\n");
  size_t offset_to = offset + 0x10;
  if (offset_to > module->instrumented_code_size)
    offset_to = module->instrumented_code_size;
  for (size_t i = offset; i < offset_to; i++) {
    printf("%02x ", (unsigned char)(module->instrumented_code_local[i]));
  }
  printf("\n");
}

// gets the address in the instrumented code corresponding to
// address in the original module
size_t TinyInst::GetTranslatedAddress(ModuleInfo *module, size_t address) {
  uint32_t offset = (uint32_t)(address - (size_t)module->min_address);
  uint32_t translated_offset;

  if (!GetRegion(module, address)) return address;

  auto iter = module->basic_blocks.find(offset);
  if (iter == module->basic_blocks.end()) {
    TranslateBasicBlockRecursive((char *)address, module);

    iter = module->basic_blocks.find(offset);
    if (iter == module->basic_blocks.end()) {
      FATAL("Can't find translated basic block");
    }
  }

  translated_offset = iter->second;

  return (size_t)module->instrumented_code_remote + translated_offset;
}

size_t TinyInst::GetTranslatedAddress(size_t address) {
  ModuleInfo *module = GetModule(address);
  if (!module) return address;
  if (!module->instrumented) return address;
  return GetTranslatedAddress(module, address);
}

// checks if address falls into one of the instrumented modules
// and if so, redirects execution to the translated code
bool TinyInst::TryExecuteInstrumented(char *address) {
  ModuleInfo *module = GetModule((size_t)address);

  if (!module) return false;
  if (!GetRegion(module, (size_t)address)) return false;

  if (trace_module_entries) {
    printf("TRACE: Entered module %s at address %p\n", module->module_name.c_str(), static_cast<void*>(address));
  }
  if (patch_module_entries) {
    size_t entry_offset = (size_t)address - module->min_address;
    module->entry_offsets.insert(entry_offset);
  }

  size_t translated_address = GetTranslatedAddress(module, (size_t)address);
  OnModuleEntered(module, (size_t)address);

  translated_address = unwind_generator->MaybeRedirectExecution(module, translated_address);

  SetRegister(ARCH_PC, translated_address);

  return true;
}

void TinyInst::OnReturnAddress(ModuleInfo *module, size_t original_address, size_t translated_address) {
  unwind_generator->OnReturnAddress(module, original_address, translated_address);
}

void TinyInst::OnModuleInstrumented(ModuleInfo* module) {
  unwind_generator->OnModuleInstrumented(module);
}

void TinyInst::OnModuleUninstrumented(ModuleInfo* module) {
  unwind_generator->OnModuleUninstrumented(module);
}

// clears all instrumentation data from module locally
// and if clear_remote_data is set, also in the remote process
void TinyInst::ClearInstrumentation(ModuleInfo *module) {
  if (module->instrumented_code_remote) {
    RemoteFree(module->instrumented_code_remote,
               module->instrumented_code_size);
    module->instrumented_code_remote = NULL;
  }
  module->ClearInstrumentation();
  OnModuleUninstrumented(module);
  ClearCrossModuleLinks(module);
}

void TinyInst::InstrumentModule(ModuleInfo *module) {
  if (instrumentation_disabled) return;

  // if the module was previously instrumented
  // just reuse the same data
  if (persist_instrumentation_data && module->instrumented) {
    ProtectCodeRanges(&module->executable_ranges);
    FixCrossModuleLinks(module);
    printf("Module %s already instrumented, "
           "reusing instrumentation data\n",
           module->module_name.c_str());
    return;
  }

  ExtractCodeRanges(module->module_header,
                    module->min_address,
                    module->max_address,
                    &module->executable_ranges,
                    &module->code_size);

  // allocate buffer for instrumented code
  module->instrumented_code_size = module->code_size * CODE_SIZE_MULTIPLIER;
  if ((indirect_instrumentation_mode == II_GLOBAL) ||
      (indirect_instrumentation_mode == II_AUTO))
  {
    module->instrumented_code_size += child_ptr_size * JUMPTABLE_SIZE;
  }

  module->instrumented_code_allocated = 0;
  module->instrumented_code_local =
    (char *)malloc(module->instrumented_code_size);
  if (!module->instrumented_code_local) {
    FATAL("Error allocating local code buffer\n");
  }

  module->instrumented_code_remote =
#ifdef ARM64
    (char *)RemoteAllocate(module->instrumented_code_size,
                           READEXECUTE);
#else
    (char *)RemoteAllocateNear((uint64_t)module->min_address,
                               (uint64_t)module->max_address,
                               module->instrumented_code_size,
                               READEXECUTE);
#endif

  if (!module->instrumented_code_remote) {
    // TODO also try allocating after the module
    FATAL("Error allocating remote code buffer\n");
  }

  if ((indirect_instrumentation_mode == II_GLOBAL) ||
      (indirect_instrumentation_mode == II_AUTO))
  {
    InitGlobalJumptable(module);
  }

  module->instrumented = true;
  FixCrossModuleLinks(module);

  printf("Instrumented module %s, code size: %zd\n",
         module->module_name.c_str(), module->code_size);

  OnModuleInstrumented(module);

  if (patch_module_entries) PatchModuleEntries(module);
}

void TinyInst::PatchPointersLocal(char* buf, size_t size, std::unordered_map<size_t, size_t>& search_replace, bool commit_code, ModuleInfo* module) {
  if (child_ptr_size == 4) {
    PatchPointersLocalT<uint32_t>(buf, size, search_replace, commit_code, module);
  } else {
    PatchPointersLocalT<uint64_t>(buf, size, search_replace, commit_code, module);
  }
}

template<typename T>
void TinyInst::PatchPointersLocalT(char* buf, size_t size, std::unordered_map<size_t, size_t>& search_replace, bool commit_code, ModuleInfo* module) {
  size -= child_ptr_size - 1;
  for (size_t i = 0; i < size; i++) {
    T ptr = *(T*)(buf);
    auto iter = search_replace.find(ptr);
    if (iter != search_replace.end()) {
      // printf("patching entry %zx at address %zx\n", (size_t)ptr, (size_t)buf);
      // if (commit_code) printf("The address is in translated code\n");
      T fixed_ptr = (T)iter->second;
      *(T*)(buf) = fixed_ptr;
      if (commit_code) {
        CommitCode(module, i, child_ptr_size);
      }
    }
    buf += 1;
  }
}

void TinyInst::PatchModuleEntries(ModuleInfo* module) {
  if (!patch_module_entries) return;

  if (module->entry_offsets.empty()) return;

  std::unordered_map<size_t, size_t> search_replace;
  for (size_t offset : module->entry_offsets) {
    size_t original_address = offset + module->min_address;
    size_t translated_address = GetTranslatedAddress(module, original_address);
    search_replace[original_address] = translated_address;
  }

#if defined(WIN32) || defined(_WIN32) || defined(__WIN32)

  // patching exception handler addresses on x86 windows
  // interferes with SafeSEH. A simple way around it for now
  // is to simply remove exception handlers from the list
  // of entrypoints
  std::unordered_set<size_t> exception_handlers;
  GetExceptionHandlers(module->min_address, exception_handlers);
  for (size_t handler : exception_handlers) {
    auto iter = search_replace.find(handler);
    if (iter != search_replace.end()) {
      // printf("Removing exception handler %zx from list of entrypoints to patch\n", handler);
      search_replace.erase(iter);
    }
  }

  // since at this point, we already read the code and the target can't
  // execute it anymore, patching the entire library in the remote
  // process is equivalent to patching data only
  if (patch_module_entries & PatchModuleEntriesValue::DATA) {
    PatchPointersRemote(module->min_address, module->max_address, search_replace);
  }

#elif defined(__APPLE__)
  if (patch_module_entries & PatchModuleEntriesValue::DATA) {
    PatchPointersRemote(module->module_header,search_replace);
  }
#endif

  if (patch_module_entries & PatchModuleEntriesValue::CODE) {
    // we need to patch the local copy as the code has been
    // copied to TinyInst process alredy
    for (AddressRange& range : module->executable_ranges) {
      PatchPointersLocal(range.data, (range.to - range.from), search_replace, false, NULL);
    }
    // some of that code could have been translated already
    // while translating entrypoints themselves
    PatchPointersLocal(module->instrumented_code_local, module->instrumented_code_allocated, search_replace, true, module);
  }

}

// walks the list of modules and instruments
// all loaded so far
void TinyInst::InstrumentAllLoadedModules() {
  for (auto iter = instrumented_modules.begin();
       iter != instrumented_modules.end(); iter++) {
    ModuleInfo *cur_module = *iter;
    if (cur_module->module_header && cur_module->max_address) {
      if (!cur_module->loaded) continue;
      InstrumentModule(cur_module);
    }
  }
}

// should we instrument coverage for this module
ModuleInfo *TinyInst::IsInstrumentModule(char *module_name) {
  for (auto iter = instrumented_modules.begin();
       iter != instrumented_modules.end(); iter++)
  {
    ModuleInfo *cur_module = *iter;
    if (_stricmp(module_name, cur_module->module_name.c_str()) == 0) {
      return cur_module;
    }
  }
  return NULL;
}

void TinyInst::OnInstrumentModuleLoaded(void *module, ModuleInfo *target_module) {
  if (target_module->instrumented &&
      target_module->module_header &&
      (target_module->module_header != (void *)module))
  {
    WARN("Instrumented module loaded on a different address than seen previously\n"
         "Module will need to be re-instrumented. Expect a drop in performance.");
    ClearInstrumentation(target_module);
  }

  target_module->module_header = (void *)module;
  GetImageSize(target_module->module_header,
               &target_module->min_address,
               &target_module->max_address);
  target_module->loaded = true;

  if(instrument_modules_on_load) {
    InstrumentModule(target_module);
  } else if (target_function_defined) {
    if (target_reached) InstrumentModule(target_module);
  } else if (child_entrypoint_reached) {
    InstrumentModule(target_module);
  }
}

// called when a potentialy interesting module gets loaded
void TinyInst::OnModuleLoaded(void *module, char *module_name) {
  Debugger::OnModuleLoaded(module, module_name);

  unwind_generator->OnModuleLoaded(module, module_name);
  
  ModuleInfo *instrument_module = IsInstrumentModule(module_name);
  if (instrument_module) {
    OnInstrumentModuleLoaded(module, instrument_module);
  }
}

// called when a potentialy interesting module gets loaded
void TinyInst::OnModuleUnloaded(void *module) {
  Debugger::OnModuleUnloaded(module);

  for (auto iter = instrumented_modules.begin();
       iter != instrumented_modules.end(); iter++)
  {
    ModuleInfo *cur_module = *iter;
    if (cur_module->module_header == (void *)module) {
      cur_module->loaded = false;
      if (!persist_instrumentation_data) {
        ClearInstrumentation(cur_module);
      }
      InvalidateCrossModuleLinks(cur_module);
    }
  }
}

void TinyInst::OnTargetMethodReached() {
  Debugger::OnTargetMethodReached();

  if (target_function_defined && !instrument_modules_on_load) InstrumentAllLoadedModules();
}

void TinyInst::OnEntrypoint() {
  Debugger::OnEntrypoint();

  if(!target_function_defined && !instrument_modules_on_load) InstrumentAllLoadedModules();
}


bool TinyInst::OnException(Exception *exception_record) {
  switch (exception_record->type)
  {
  case BREAKPOINT:
    if (HandleBreakpoint(exception_record->ip)) {
      return true;
    }
  case ACCESS_VIOLATION:
    if (exception_record->maybe_execute_violation) {
      // possibly we are trying to executed code in an instrumented module
      if (TryExecuteInstrumented((char *)exception_record->access_address)) {
        return true;
      }
    }
  default:
    break;
  }

  return false;
}

void TinyInst::OnProcessCreated() {
  Debugger::OnProcessCreated();

  if ((child_ptr_size == 4) && unwind_generator->Is64BitOnly()) {
    WARN("generate_unwind used with 32-bit process. Disabling.");
    delete unwind_generator;
    unwind_generator = new UnwindGenerator(*this);
  }
}

void TinyInst::OnProcessExit() {
  Debugger::OnProcessExit();

  // clear all instrumentation data
  for (auto iter = instrumented_modules.begin();
       iter != instrumented_modules.end(); iter++)
  {
    ModuleInfo *cur_module = *iter;
    cur_module->loaded = false;
    cur_module->ClearInstrumentation();
    OnModuleUninstrumented(cur_module);
  }
  // clear cross-module links
  ClearCrossModuleLinks();
}

// initializes instrumentation from command line options
void TinyInst::Init(int argc, char **argv) {
  // init the debugger first
  Debugger::Init(argc, argv);

#ifdef ARM64
  assembler_ = new Arm64Assembler(*this);
#else
  assembler_ = new X86Assembler(*this);
#endif
  assembler_->Init();

  instrumentation_disabled = false;

  instrument_modules_on_load = GetBinaryOption("-instrument_modules_on_load", argc, argv, false);
  patch_return_addresses = GetBinaryOption("-patch_return_addresses", argc, argv, false);
  instrument_cross_module_calls = GetBinaryOption("-instrument_cross_module_calls", argc, argv, true);
  persist_instrumentation_data = GetBinaryOption("-persist_instrumentation_data", argc, argv, true);

  trace_basic_blocks = GetBinaryOption("-trace_basic_blocks", argc, argv, false);
  trace_module_entries = GetBinaryOption("-trace_module_entries", argc, argv, false);
  
  full_address_map = GetBinaryOption("-full_address_map", argc, argv, false);

#if defined(ARM64) && defined(__APPLE__)
  page_extend_modules = GetBinaryOption("-page_extend_modules", argc, argv, true);
#else
  page_extend_modules = false;
#endif

#if defined(WIN32) || defined(_WIN32) || defined(__WIN32) || defined(ARM64)
  sp_offset = 0;
#else
  // According to System V AMD64 ABI:
  // "For leaf-node functions a 128-byte space is stored just beneath
  // the stack pointer of the function. The space is called the red zone.
  // This zone will not be clobbered by any signal or interrupt handlers.
  // Compilers can thus utilize this zone to save local variables."
  // We set sp_offset to more than that just to be on the safe side.
  sp_offset = 256;
#endif
  
  sp_offset = GetIntOption("-stack_offset", argc, argv, sp_offset);

  std::list <char *> module_names;
  GetOptionAll("-instrument_module", argc, argv, &module_names);

#if defined(__APPLE__) && defined(ARM64)
  std::set <std::string> orig_uniq_mod_names;
  std::set <std::string> new_uniq_mod_names;
  if(page_extend_modules) {
    std::map<std::string, std::vector<std::string>> mod_grp =
      parse_dyld_map_file(DYLD_MAP_FILE);

    if (mod_grp.empty()) {
      FATAL("Module group is expected to have entries.");
    }

    // Store modules, specified by user, in set for faster lookup.
    orig_uniq_mod_names.insert(module_names.begin(), module_names.end());

    // Generate list of additionally needed modules.
    for(auto* mod_name: module_names) {
      auto it = mod_grp.find(mod_name);
      if(it != mod_grp.end()) {
        for(const auto &m: it->second) {
          // Only add if not specified by user (to keep track of newly added
          // modules).
          if(orig_uniq_mod_names.count(m) == 0) {
            new_uniq_mod_names.insert(m);
          }
        }
      }
    }

    SAY("Additionally added modules to align to pages:\n");
    for (const auto &m : new_uniq_mod_names) {
      SAY("  %s\n", m.c_str());
      module_names.emplace_back((char*)m.c_str());
    }
  }
#endif

  for (const auto module_name: module_names) {
    ModuleInfo *new_module = new ModuleInfo();
    new_module->module_name = module_name;
    instrumented_modules.push_back(new_module);
    // SAY("--- %s\n", module_name);
  }

  char *option;

  indirect_instrumentation_mode = II_AUTO;
  option = GetOption("-indirect_instrumentation", argc, argv);
  if (option) {
    if (strcmp(option, "none") == 0)
      indirect_instrumentation_mode = II_NONE;
    else if (strcmp(option, "local") == 0)
      indirect_instrumentation_mode = II_LOCAL;
    else if (strcmp(option, "global") == 0)
      indirect_instrumentation_mode = II_GLOBAL;
    else if (strcmp(option, "auto") == 0)
      indirect_instrumentation_mode = II_AUTO;
    else
      FATAL("Unknown indirect instrumentation mode");
  }

  patch_module_entries = PatchModuleEntriesValue::OFF;
  option = GetOption("-patch_module_entries", argc, argv);
  if (option) {
    if (strcmp(option, "off") == 0)
      patch_module_entries = PatchModuleEntriesValue::OFF;
    else if (strcmp(option, "data") == 0)
      patch_module_entries = PatchModuleEntriesValue::DATA;
    else if (strcmp(option, "code") == 0)
      patch_module_entries = PatchModuleEntriesValue::CODE;
    else if (strcmp(option, "all") == 0)
      patch_module_entries = PatchModuleEntriesValue::ALL;
    else
      FATAL("Unknown -patch_module_entries value");
  }

  generate_unwind = GetBinaryOption("-generate_unwind", argc, argv, false);

  // if patch_return_addresses is on, disable generate_unwind
  // regardless of the flag
  if (patch_return_addresses) generate_unwind = false;

  if (!generate_unwind) {
    unwind_generator = new UnwindGenerator(*this);
  } else {
#ifdef __APPLE__
    unwind_generator = new UnwindGeneratorMacOS(*this);
#elif defined(_WIN64)
    unwind_generator = new WinUnwindGenerator(*this);
#else
    WARN("Unwind generator not implemented for the current platform");
    unwind_generator = new UnwindGenerator(*this);
#endif
  }
  unwind_generator->Init(argc, argv);
}

```

`tinyinst.h`:

```h
/*
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef TINYINST_H
#define TINYINST_H

#include <list>
#include <set>
#include <map>
#include <unordered_map>
#include <unordered_set>

#if defined(WIN32) || defined(_WIN32) || defined(__WIN32)
  #include "Windows/debugger.h"
#elif __APPLE__
  #include "macOS/debugger.h"
#endif

#include "common.h"
#include "assembler.h"
#include "instruction.h"
#include "unwind.h"

#if defined(_WIN64)

#include "Windows/winunwind.h"

#elif __APPLE__

#include "macOS/unwindmacos.h"
class UnwindGeneratorMacOS;

#endif

// must be a power of two
#define JUMPTABLE_SIZE 0x2000

// we will allocate
// original_code_size * CODE_SIZE_MULTIPLIER +
// JUMPTABLE_SIZE * child_ptr_size
// for instrumented code
#ifdef ARM64
#define CODE_SIZE_MULTIPLIER 8
#else
#define CODE_SIZE_MULTIPLIER 4
#endif

typedef struct xed_decoded_inst_s xed_decoded_inst_t;

class ModuleInfo;


enum InstructionResult {
  INST_HANDLED,
  INST_NOTHANDLED,
  INST_STOPBB
};

class TinyInst : public Debugger {
public:
  virtual void Init(int argc, char **argv) override;

  void EnableInstrumentation() {
    instrumentation_disabled = false;
  }

  void DisableInstrumentation() {
    instrumentation_disabled = true;
  }

protected:

  enum IndirectInstrumentation {
    II_NONE,
    II_GLOBAL,
    II_LOCAL,
    II_AUTO
  };

  enum PatchModuleEntriesValue {
    OFF = 0,
    DATA = 1,
    CODE = 2,
    ALL = DATA | CODE
  };

  std::list<ModuleInfo *> instrumented_modules;

  struct CrossModuleLink {
    ModuleInfo *module1;
    ModuleInfo *module2;
    size_t offset1;
    size_t offset2;
  };

  virtual void OnEntrypoint() override;
  virtual void OnProcessCreated() override;
  virtual void OnProcessExit() override;
  virtual void OnModuleLoaded(void *module, char *module_name) override;
  virtual void OnModuleUnloaded(void *module) override;
  virtual bool OnException(Exception *exception_record) override;
  virtual void OnTargetMethodReached() override;
  virtual void OnCrashed(Exception *exception_record) override;

  virtual size_t GetTranslatedAddress(size_t address) override;

  void WriteCode(ModuleInfo *module, void *data, size_t size);
  void WriteCodeAtOffset(ModuleInfo *module, size_t offset, void *data, size_t size);
  void WritePointer(ModuleInfo *module, size_t value);
  void WritePointerAtOffset(ModuleInfo *module, size_t value, size_t offset);
  size_t ReadPointer(ModuleInfo *module, size_t offset);

  inline void FixDisp4(ModuleInfo *module, int32_t disp); 

  size_t GetCurrentInstrumentedAddress(ModuleInfo *module);
  void CommitCode(ModuleInfo *module, size_t start_offset, size_t size);

  ModuleInfo *GetModuleByName(const char *name);
  ModuleInfo *GetModule(size_t address);
  ModuleInfo *GetModuleFromInstrumented(size_t address);
  AddressRange *GetRegion(ModuleInfo *module, size_t address);

  // instrumentation API
  virtual void OnModuleEntered(ModuleInfo *module, size_t entry_address) {}
  virtual void InstrumentBasicBlock(ModuleInfo *module, size_t bb_address) {}
  virtual void InstrumentEdge(ModuleInfo *previous_module,
                              ModuleInfo *next_module,
                              size_t previous_address,
                              size_t next_address) {}

  virtual InstructionResult InstrumentInstruction(ModuleInfo *module,
                                                  Instruction& inst,
                                                  size_t bb_address,
                                                  size_t instruction_address)
  {
    return INST_NOTHANDLED;
  }

  virtual void OnModuleInstrumented(ModuleInfo* module);
  virtual void OnModuleUninstrumented(ModuleInfo* module);

  int32_t sp_offset;
  Assembler* assembler_;

  UnwindGenerator* unwind_generator;
  virtual void OnReturnAddress(ModuleInfo *module, size_t original_address, size_t translated_address);

private:
  bool HandleBreakpoint(void *address);
  void OnInstrumentModuleLoaded(void *module, ModuleInfo *target_module);
  ModuleInfo *IsInstrumentModule(char *module_name);
  void InstrumentAllLoadedModules();
  void InstrumentModule(ModuleInfo *module);
  void ClearInstrumentation(ModuleInfo *module);
  bool TryExecuteInstrumented(char * address);
  size_t GetTranslatedAddress(ModuleInfo *module, size_t address);
  void TranslateBasicBlock(char *address,
                           ModuleInfo *module,
                           std::set<char *> *queue,
                           std::list<std::pair<uint32_t, uint32_t>> *offset_fixes);
  void TranslateBasicBlockRecursive(char *address, ModuleInfo *module);
  void FixOffsetOrEnqueue(ModuleInfo *module,
                          uint32_t bb,
                          uint32_t jmp_offset,
                          std::set<char *> *queue,
                          std::list<std::pair<uint32_t, uint32_t>> *offset_fixes);
  void InvalidInstruction(ModuleInfo *module);

  // needed to support cross-module linking
  // on module unloads / reloads
  void InvalidateCrossModuleLink(CrossModuleLink *link);
  void FixCrossModuleLink(CrossModuleLink *link);
  void FixCrossModuleLinks(ModuleInfo *module);
  void InvalidateCrossModuleLinks(ModuleInfo *module);
  void InvalidateCrossModuleLinks();
  void ClearCrossModuleLinks(ModuleInfo *module);
  void ClearCrossModuleLinks();

  void PatchModuleEntries(ModuleInfo* module);

  // functions related to indirect jump/call instrumentation
  void InitGlobalJumptable(ModuleInfo *module);
  void InstrumentIndirect(ModuleInfo *module,
                          Instruction& inst,
                          size_t instruction_address,
                          IndirectInstrumentation mode,
                          size_t bb_address);

  // returns the indirect instrumentation mode that should be used for a particular call
  // can be overriden
  virtual IndirectInstrumentation ShouldInstrumentIndirect(ModuleInfo *module,
                                                           Instruction& inst,
                                                           size_t instruction_address);

  size_t AddTranslatedJump(ModuleInfo *module,
                           ModuleInfo *target_module,
                           size_t original_target,
                           size_t actual_target,
                           size_t list_head_offset,
                           IndirectBreakpoinInfo& breakpoint_info,
                           bool global_indirect);
  bool HandleIndirectJMPBreakpoint(void *address);

  void PatchPointersLocal(char* buf, size_t size,
                          std::unordered_map<size_t, size_t>& search_replace,
                          bool commit_code, ModuleInfo* module);
  template<typename T>
  void PatchPointersLocalT(char* buf, size_t size,
                           std::unordered_map<size_t, size_t>& search_replace,
                           bool commit_code, ModuleInfo* module);

  IndirectInstrumentation indirect_instrumentation_mode;

  bool instrument_cross_module_calls;
  bool patch_return_addresses;
  bool persist_instrumentation_data;

  bool trace_basic_blocks;
  bool trace_module_entries;

  bool generate_unwind;

  bool page_extend_modules;

  // these could be indexed by module1 and module2 for performance
  // but the assumption for now is that there won't be too many of
  // them so a flat structure shoudl be ok for now
  std::list<CrossModuleLink> cross_module_links;

  bool instrumentation_disabled;
  bool instrument_modules_on_load;
  
  bool full_address_map;

  PatchModuleEntriesValue patch_module_entries;

  friend class Asssembler;
  friend class X86Assembler;
  friend class Arm64Assembler;
  friend class ModuleInfo;
  friend class UnwindGenerator;
#if defined(_WIN64)
  friend class WinUnwindGenerator;
#elif __APPLE__
  friend class UnwindGeneratorMacOS;
#endif
};

struct IndirectBreakpoinInfo {
  size_t list_head;
  size_t source_bb;
#ifdef ARM64
  uint8_t branch_register;
#endif
};

class ModuleInfo {
 public:
  ModuleInfo();
  void ClearInstrumentation();

  std::string module_name;
  void *module_header;
  size_t min_address;
  size_t max_address;
  size_t code_size;
  bool loaded;
  bool instrumented;
  std::list<AddressRange> executable_ranges;

  size_t instrumented_code_size;
  size_t instrumented_code_allocated;
  char *instrumented_code_local;
  char *instrumented_code_remote;
  char *instrumented_code_remote_previous;

  std::unordered_map<uint32_t, uint32_t> basic_blocks;

  // instrumented address to original address
  std::map<size_t, size_t> address_map;

  size_t br_indirect_newtarget_global;

  // per callsite jumplist breakpoint
  // from breakpoint address to list head offset
  std::unordered_map<size_t, IndirectBreakpoinInfo> br_indirect_newtarget_list;

  size_t jumptable_offset;
  size_t jumptable_address_offset;

  std::unordered_set<size_t> invalid_instructions;
  std::unordered_map<size_t, size_t> tracepoints;

  std::unordered_set<size_t> entry_offsets;

  UnwindData *unwind_data;

  // clients can use this to store additional data
  // about the module
  void *client_data;
};

#endif // TINYINST_H

```

`unwind.h`:

```h
/*
Copyright 2021 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

https ://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

#ifndef UNWIND_H
#define UNWIND_H

class TinyInst;
class ModuleInfo;

class UnwindData {
public:
  virtual ~UnwindData() = default;
};

class UnwindGenerator {
public:
  UnwindGenerator(TinyInst& tinyinst) : tinyinst_(tinyinst) {}
  virtual ~UnwindGenerator() = default;
  
  virtual void Init(int argc, char **argv) {}

  virtual void OnModuleInstrumented(ModuleInfo* module) { }
  virtual void OnModuleUninstrumented(ModuleInfo* module) { }

  virtual size_t MaybeRedirectExecution(ModuleInfo* module, size_t IP) {
    return IP;
  }

  virtual void OnBasicBlockStart(ModuleInfo* module,
                         size_t original_address,
                         size_t translated_address)
  { }

  virtual void OnInstruction(ModuleInfo* module,
                     size_t original_address,
                     size_t translated_address)
  { }

  virtual void OnBasicBlockEnd(ModuleInfo* module,
                       size_t original_address,
                       size_t translated_address)
  { }
  
  virtual void OnModuleLoaded(void *module, char *module_name) { }

  virtual void OnReturnAddress(ModuleInfo *module, size_t original_address, size_t translated_address) { }
  
  virtual bool HandleBreakpoint(ModuleInfo* module, void *address) { return false; }

  virtual bool Is64BitOnly() { return false; }

protected:
	TinyInst& tinyinst_;
};

#endif // UNWIND_H

```