Project Path: arc_gmh5225_Android_boot_image_editor_q_50nlyp

Source Tree:

```txt
arc_gmh5225_Android_boot_image_editor_q_50nlyp
├── LICENSE.md
├── README.md
├── aosp
│   ├── avb
│   │   ├── avbtool.diff
│   │   ├── avbtool.v1.1.py
│   │   ├── avbtool.v1.2.py
│   │   └── data
│   │       ├── testkey_atx_pik.pem
│   │       ├── testkey_atx_prk.pem
│   │       ├── testkey_atx_psk.pem
│   │       ├── testkey_rsa2048.pem
│   │       ├── testkey_rsa2048.pk8
│   │       ├── testkey_rsa4096.pem
│   │       ├── testkey_rsa4096.pk8
│   │       ├── testkey_rsa4096_pub.bin
│   │       ├── testkey_rsa4096_pub.pem
│   │       ├── testkey_rsa8192.pem
│   │       └── testkey_rsa8192.pk8
│   ├── boot_signer
│   │   ├── build.gradle.kts
│   │   └── src
│   │       └── main
│   │           └── java
│   │               ├── BootSignature.java
│   │               ├── Utils.java
│   │               └── VeritySigner.java
│   ├── dispol
│   │   ├── Makefile
│   │   └── README.md
│   ├── dracut
│   │   ├── README.md
│   │   └── skipcpio.c
│   ├── libavb1.1
│   │   ├── build.gradle
│   │   └── src
│   │       └── avb
│   │           ├── c
│   │           │   ├── avb_chain_partition_descriptor.c
│   │           │   ├── avb_cmdline.c
│   │           │   ├── avb_crc32.c
│   │           │   ├── avb_crypto.c
│   │           │   ├── avb_descriptor.c
│   │           │   ├── avb_footer.c
│   │           │   ├── avb_hash_descriptor.c
│   │           │   ├── avb_hashtree_descriptor.c
│   │           │   ├── avb_kernel_cmdline_descriptor.c
│   │           │   ├── avb_property_descriptor.c
│   │           │   ├── avb_rsa.c
│   │           │   ├── avb_sha256.c
│   │           │   ├── avb_sha512.c
│   │           │   ├── avb_slot_verify.c
│   │           │   ├── avb_sysdeps_posix.c
│   │           │   ├── avb_util.c
│   │           │   ├── avb_vbmeta_image.c
│   │           │   └── avb_version.c
│   │           └── headers
│   │               ├── avb_chain_partition_descriptor.h
│   │               ├── avb_cmdline.h
│   │               ├── avb_crypto.h
│   │               ├── avb_descriptor.h
│   │               ├── avb_footer.h
│   │               ├── avb_hash_descriptor.h
│   │               ├── avb_hashtree_descriptor.h
│   │               ├── avb_kernel_cmdline_descriptor.h
│   │               ├── avb_ops.h
│   │               ├── avb_property_descriptor.h
│   │               ├── avb_rsa.h
│   │               ├── avb_sha.h
│   │               ├── avb_slot_verify.h
│   │               ├── avb_sysdeps.h
│   │               ├── avb_util.h
│   │               ├── avb_vbmeta_image.h
│   │               ├── avb_version.h
│   │               └── libavb.h
│   ├── libavb1.2
│   │   ├── build.gradle
│   │   └── src
│   │       └── avb
│   │           ├── c
│   │           │   ├── avb_chain_partition_descriptor.c
│   │           │   ├── avb_cmdline.c
│   │           │   ├── avb_crc32.c
│   │           │   ├── avb_crypto.c
│   │           │   ├── avb_descriptor.c
│   │           │   ├── avb_footer.c
│   │           │   ├── avb_hash_descriptor.c
│   │           │   ├── avb_hashtree_descriptor.c
│   │           │   ├── avb_kernel_cmdline_descriptor.c
│   │           │   ├── avb_property_descriptor.c
│   │           │   ├── avb_rsa.c
│   │           │   ├── avb_slot_verify.c
│   │           │   ├── avb_sysdeps_posix.c
│   │           │   ├── avb_util.c
│   │           │   ├── avb_vbmeta_image.c
│   │           │   ├── avb_version.c
│   │           │   ├── sha256_impl.c
│   │           │   └── sha512_impl.c
│   │           └── headers
│   │               ├── avb_chain_partition_descriptor.h
│   │               ├── avb_cmdline.h
│   │               ├── avb_crypto.h
│   │               ├── avb_crypto_ops_impl.h
│   │               ├── avb_descriptor.h
│   │               ├── avb_footer.h
│   │               ├── avb_hash_descriptor.h
│   │               ├── avb_hashtree_descriptor.h
│   │               ├── avb_kernel_cmdline_descriptor.h
│   │               ├── avb_ops.h
│   │               ├── avb_property_descriptor.h
│   │               ├── avb_rsa.h
│   │               ├── avb_sha.h
│   │               ├── avb_slot_verify.h
│   │               ├── avb_sysdeps.h
│   │               ├── avb_util.h
│   │               ├── avb_vbmeta_image.h
│   │               ├── avb_version.h
│   │               └── libavb.h
│   ├── libsparse
│   │   ├── append2simg
│   │   │   ├── build.gradle.kts
│   │   │   └── src
│   │   │       └── main
│   │   │           └── cpp
│   │   │               └── append2simg.cpp
│   │   ├── base
│   │   │   ├── build.gradle.kts
│   │   │   └── src
│   │   │       ├── main
│   │   │       │   ├── cpp
│   │   │       │   │   ├── mapped_file.cpp
│   │   │       │   │   └── stringprintf.cpp
│   │   │       │   └── public
│   │   │       │       └── android-base
│   │   │       │           ├── macros.h
│   │   │       │           ├── mapped_file.h
│   │   │       │           ├── off64_t.h
│   │   │       │           ├── stringprintf.h
│   │   │       │           └── unique_fd.h
│   │   │       └── test
│   │   │           └── cpp
│   │   │               └── hello_test.cpp
│   │   ├── img2simg
│   │   │   ├── build.gradle.kts
│   │   │   └── src
│   │   │       └── main
│   │   │           └── cpp
│   │   │               └── img2simg.cpp
│   │   ├── simg2img
│   │   │   ├── build.gradle.kts
│   │   │   └── src
│   │   │       └── main
│   │   │           └── cpp
│   │   │               └── simg2img.cpp
│   │   ├── simg2simg
│   │   │   ├── build.gradle.kts
│   │   │   └── src
│   │   │       └── main
│   │   │           └── cpp
│   │   │               └── simg2simg.cpp
│   │   └── sparse
│   │       ├── build.gradle.kts
│   │       └── src
│   │           └── main
│   │               ├── cpp
│   │               │   ├── Android.bp
│   │               │   ├── backed_block.cpp
│   │               │   ├── defs.h
│   │               │   ├── output_file.cpp
│   │               │   ├── output_file.h
│   │               │   ├── simg_dump.py
│   │               │   ├── sparse.cpp
│   │               │   ├── sparse_crc32.cpp
│   │               │   ├── sparse_crc32.h
│   │               │   ├── sparse_defs.h
│   │               │   ├── sparse_err.cpp
│   │               │   ├── sparse_format.h
│   │               │   └── sparse_read.cpp
│   │               └── public
│   │                   ├── backed_block.h
│   │                   ├── sparse
│   │                   │   └── sparse.h
│   │                   └── sparse_file.h
│   ├── libxbc
│   │   ├── COPYING
│   │   ├── libxbc.c
│   │   ├── libxbc.h
│   │   ├── main.cpp
│   │   └── meson.build
│   ├── make
│   │   ├── target
│   │   │   └── product
│   │   │       └── gsi
│   │   │           └── testkey_rsa2048.pem
│   │   └── tools
│   │       └── extract_kernel.py
│   ├── mkbootfs.10
│   │   ├── build.gradle
│   │   └── src
│   │       └── mkbootfs
│   │           ├── cpp
│   │           │   ├── fs_config.cpp
│   │           │   └── mkbootfs.c
│   │           └── headers
│   │               ├── log
│   │               │   └── log.h
│   │               ├── private
│   │               │   ├── android_filesystem_capability.h
│   │               │   ├── android_filesystem_config.h
│   │               │   └── fs_config.h
│   │               └── utils
│   │                   └── Compat.h
│   ├── mkbootfs.11
│   │   ├── build.gradle
│   │   └── src
│   │       └── mkbootfs
│   │           ├── cpp
│   │           │   ├── fs_config.cpp
│   │           │   ├── mkbootfs.c
│   │           │   └── strings.cpp
│   │           └── headers
│   │               ├── android-base
│   │               │   └── strings.h
│   │               ├── fs_config.h
│   │               ├── log
│   │               │   └── log.h
│   │               ├── private
│   │               │   ├── android_filesystem_capability.h
│   │               │   ├── android_filesystem_config.h
│   │               │   └── fs_config.h
│   │               └── utils
│   │                   └── Compat.h
│   ├── security
│   │   ├── README
│   │   ├── media.pk8
│   │   ├── media.x509.pem
│   │   ├── platform.pk8
│   │   ├── platform.x509.pem
│   │   ├── shared.pk8
│   │   ├── shared.x509.pem
│   │   ├── testkey.pk8
│   │   ├── testkey.x509.pem
│   │   ├── verity.pk8
│   │   ├── verity.x509.pem
│   │   └── verity_key
│   └── system
│       ├── libufdt
│       │   └── utils
│       │       └── src
│       │           └── mkdtboimg.py
│       └── tools
│           └── mkbootimg
│               ├── gki
│               │   ├── Android.bp
│               │   ├── boot_signature_info.sh
│               │   ├── certify_bootimg.py
│               │   ├── certify_bootimg_test.py
│               │   ├── generate_gki_certificate.py
│               │   └── testdata
│               │       ├── testkey_rsa2048.pem
│               │       └── testkey_rsa4096.pem
│               └── mkbootimg.py
├── avbImpl
│   ├── build.gradle
│   ├── config
│   │   └── pubkey
│   └── src
│       ├── avbVerifier
│       │   └── cpp
│       │       └── main.cpp
│       └── avbx
│           ├── cpp
│           │   ├── CfigAvbOps.cpp
│           │   └── helper.cpp
│           └── headers
│               ├── CfigAvbOps.h
│               └── helper.hpp
├── bbootimg
│   ├── build.gradle.kts
│   ├── gradle.properties
│   └── src
│       ├── main
│       │   ├── java
│       │   │   └── chromeos_update_engine
│       │   │       └── UpdateMetadata.java
│       │   ├── kotlin
│       │   │   ├── avb
│       │   │   │   ├── AVBInfo.kt
│       │   │   │   ├── Avb.kt
│       │   │   │   ├── alg
│       │   │   │   │   ├── Algorithm.kt
│       │   │   │   │   └── Algorithms.kt
│       │   │   │   ├── blob
│       │   │   │   │   ├── AuthBlob.kt
│       │   │   │   │   ├── AuxBlob.kt
│       │   │   │   │   ├── Footer.kt
│       │   │   │   │   └── Header.kt
│       │   │   │   └── desc
│       │   │   │       ├── ChainPartitionDescriptor.kt
│       │   │   │       ├── Descriptor.kt
│       │   │   │       ├── HashDescriptor.kt
│       │   │   │       ├── HashTreeDescriptor.kt
│       │   │   │       ├── KernelCmdlineDescriptor.kt
│       │   │   │       ├── PropertyDescriptor.kt
│       │   │   │       └── UnknownDescriptor.kt
│       │   │   ├── bootimg
│       │   │   │   ├── Common.kt
│       │   │   │   ├── Signer.kt
│       │   │   │   ├── cpio
│       │   │   │   │   ├── AndroidCpio.kt
│       │   │   │   │   ├── AndroidCpioEntry.kt
│       │   │   │   │   └── NewAsciiCpio.kt
│       │   │   │   ├── v2
│       │   │   │   │   ├── BootHeaderV2.kt
│       │   │   │   │   ├── BootV2.kt
│       │   │   │   │   └── BootV2Dialects.kt
│       │   │   │   └── v3
│       │   │   │       ├── BootHeaderV3.kt
│       │   │   │       ├── BootV3.kt
│       │   │   │       ├── VendorBoot.kt
│       │   │   │       └── VendorBootHeader.kt
│       │   │   ├── init
│       │   │   │   ├── BootReason.kt
│       │   │   │   └── Reboot.kt
│       │   │   ├── miscimg
│       │   │   │   ├── BootControl.kt
│       │   │   │   └── MiscImage.kt
│       │   │   ├── ota
│       │   │   │   ├── BrilloProp.kt
│       │   │   │   ├── BrilloPropString.kt
│       │   │   │   ├── Common.kt
│       │   │   │   ├── DeltaGenerator.kt
│       │   │   │   ├── OtaOptions.kt
│       │   │   │   ├── Payload.kt
│       │   │   │   ├── PayloadGenerator.kt
│       │   │   │   └── PayloadSigner.kt
│       │   │   ├── packable
│       │   │   │   ├── BootImgParser.kt
│       │   │   │   ├── DtboParser.kt
│       │   │   │   ├── IPackable.kt
│       │   │   │   ├── MiscImgParser.kt
│       │   │   │   ├── PackableLauncher.kt
│       │   │   │   ├── PayloadBinParser.kt
│       │   │   │   ├── VBMetaParser.kt
│       │   │   │   └── VendorBootParser.kt
│       │   │   └── utils
│       │   │       ├── DTC.kt
│       │   │       ├── Dtbo.kt
│       │   │       ├── EnvironmentVerifier.kt
│       │   │       ├── KernelExtractor.kt
│       │   │       └── SparseImgParser.kt
│       │   └── resources
│       │       ├── fsconfig.txt
│       │       ├── general.cfg
│       │       ├── known_keys.json
│       │       └── logback.xml
│       └── test
│           ├── kotlin
│           │   ├── AvbTest.kt
│           │   ├── CVEtest.kt
│           │   ├── EnvironmentVerifierTest.kt
│           │   ├── KeyUtilTest.kt
│           │   ├── ReadTest.kt
│           │   ├── avb
│           │   │   ├── BlobTest.kt
│           │   │   ├── FooterTest.kt
│           │   │   ├── HeaderTest.kt
│           │   │   ├── alg
│           │   │   │   └── AlgorithmsTest.kt
│           │   │   └── desc
│           │   │       ├── HashDescriptorTest.kt
│           │   │       ├── HashTreeDescriptorTest.kt
│           │   │       ├── KernelCmdlineDescriptorTest.kt
│           │   │       └── UnknownDescriptorTest.kt
│           │   ├── bootimg
│           │   │   └── AndroidCpioEntryTest.kt
│           │   └── init
│           │       └── RebootTest.kt
│           └── resources
│               ├── data
│               ├── filemode_000_ramdisk.img
│               ├── taimen.avbfooter
│               └── testkey.pk8
├── build.gradle.kts
├── doc
│   ├── Pixel6_vbmeta.puml
│   ├── Struct3.md
│   ├── additional_tricks.md
│   ├── apple24.png
│   ├── eth0_up.puml
│   ├── hidl_boot_control.puml
│   ├── layout.md
│   ├── linux24.png
│   ├── misc_image_layout.md
│   ├── op.gif
│   ├── reboot.puml
│   ├── reboot_states.puml
│   ├── recovery_adb.md
│   ├── short.md
│   ├── shutdown.puml
│   └── system_core_libs.puml
├── gradle
│   └── wrapper
│       ├── gradle-wrapper.jar
│       └── gradle-wrapper.properties
├── gradlew
├── gradlew.bat
├── helper
│   ├── build.gradle.kts
│   └── src
│       ├── main
│       │   ├── kotlin
│       │   │   └── cfig
│       │   │       └── helper
│       │   │           ├── AndroidHelper.kt
│       │   │           ├── CryptoHelper.kt
│       │   │           ├── Dumpling.kt
│       │   │           ├── Helper.kt
│       │   │           ├── Launcher.kt
│       │   │           ├── OpenSslHelper.kt
│       │   │           └── ZipHelper.kt
│       │   └── resources
│       │       └── general.cfg
│       └── test
│           ├── kotlin
│           │   └── cfig
│           │       └── helper
│           │           ├── CryptoHelperTest.kt
│           │           ├── OpenSslHelperTest.kt
│           │           └── ZipHelperTest.kt
│           └── resources
│               ├── appcompat.zip
│               ├── general.cfg
│               ├── platform.pk8
│               ├── platform.x509.pem
│               ├── testkey.pk8
│               ├── testkey.pub
│               └── testkey.x509.pem
├── integrationTest.py
├── settings.gradle.kts
├── src
│   ├── integrationTest
│   │   ├── resources
│   │   └── resources_2
│   ├── resources
│   │   ├── console.rc
│   │   └── init.debug.rc
│   └── test
│       └── resources
│           └── boot.img
└── tools
    ├── 1.kts
    ├── avb_print_property_desc.diff
    ├── bin
    │   └── lz4.exe
    ├── debug.kts
    ├── extract_kernel.py.diff
    ├── free.py
    ├── mkdtboimg.diff
    ├── port.mk
    ├── pull.py
    ├── release.mk
    ├── remove_projects.diff
    ├── syncCode.sh
    ├── temp.txt
    └── work_from_China.diff

```

`LICENSE.md`:

```md
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "{}"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright {yyyy} {name of copyright owner}

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

```

`README.md`:

```md
# Android_boot_image_editor
[![CI](https://github.com/cfig/Android_boot_image_editor/actions/workflows/main.yml/badge.svg)](https://github.com/cfig/Android_boot_image_editor/actions/workflows/main.yml)
[![License](http://img.shields.io/:license-apache-blue.svg?style=flat-square)](http://www.apache.org/licenses/LICENSE-2.0.html)

A tool for reverse engineering Android ROM images.

## Getting Started

#### install required packages

Linux: `sudo apt install git device-tree-compiler lz4 xz-utils zlib1g-dev openjdk-17-jdk gcc g++ python3 python-is-python3 p7zip-full`

Mac: `brew install lz4 xz dtc`

Mac: Make sure you have `JDK9+` properly installed. JDK 17 is recommended.

Windows Subsystem for Linux(WSL): `sudo apt install git device-tree-compiler lz4 xz-utils zlib1g-dev openjdk-17-jdk gcc g++ python`

Windows: Make sure you have `python3`, `JDK9+` and `openssl` properly installed.
An easy way is to install [Anaconda](https://www.anaconda.com/products/individual#windows) and [Oracle JDK 17](https://www.oracle.com/java/technologies/downloads/#java17), then run the program under anaconda PowerShell.
Or install them with chocolate: `choco install openssl dtc-msys2`

#### Parsing and packing

Put your boot.img to current directory, then start gradle 'unpack' task:

```bash
cp <original_boot_image> boot.img
./gradlew unpack
```

Your get the flattened kernel and /root filesystem under **./build/unzip\_boot**:

    build/unzip_boot/
    ├── boot.json     (boot image info)
    ├── boot.avb.json (AVB only)
    ├── kernel
    ├── second        (2nd bootloader, if exists)
    ├── dtb           (dtb, if exists)
    ├── dtbo          (dtbo, if exists)
    └── root          (extracted initramfs)

Then you can edit the actual file contents, like rootfs or kernel.
Now, pack the boot.img again

    ./gradlew pack

You get the repacked boot.img at $(CURDIR):

    boot.img.signed

Well done you did it! The last step is to star this repo :smile


### live demo
<!-- ![](doc/op.gif) -->
<p align="center">
    <img src=doc/op.gif width="615" height="492">
</p>

## Supported ROM image types

| Image Type      | file names                              |  platforms    | note |
| --------------- | -----------------------------------     | ----------    | ---- |
| boot images     | boot.img, vendor_boot.img, init_boot.img|  all          | |
| recovery images | recovery.img, recovery-two-step.img     |  all          | |
| vbmeta images   | vbmeta.img, vbmeta_system.img etc.      |  all          | |
| dtbo images     | dtbo.img                                | linux & mac   | |
| sparse images   | system.img, vendor.img, product.img etc.| linux & mac   | need **hacking mode**\* |
| OTA payload     | payload.bin                             | linux & mac   | |

Please note that the boot.img MUST follows AOSP verified boot flow, either [Boot image signature](https://source.android.com/security/verifiedboot/verified-boot#signature_format) in VBoot 1.0 or [AVB HASH footer](https://android.googlesource.com/platform/external/avb/+/master/README.md#The-VBMeta-struct) (a.k.a. AVB) in VBoot 2.0.

**hacking mode**\*:

Open build.gradle.kts, Line #8, change
```
val bHackingMode = false
```
to
```
val bHackingMode = true
```
This will enable c++ modules, which is necessary for working with sparse images.

## compatible devices

| Device Model                   | Manufacturer | Compatible           | Android Version          | Note |
|--------------------------------|--------------|----------------------|--------------------------|------|
| ADT-3 (adt3)                   | Askey/Google | Y                    | 12 (spp2.210219.010)     | amlogic inside, <Br>Android TV |
| Pixel 3 (blueline)             | Google       | Y                    | 12 (spp2.210219.008, <Br>2021)| |
| Pixel 3 (blueline)             | Google       | Y                    | 11 (RP1A.200720.009, <Br>2020)| [more ...](doc/additional_tricks.md#pixel-3-blueline) |
| Pixel 3 (blueline)             | Google       | Y                    | Q preview (qpp2.190228.023, <Br>2019)| [more ...](doc/additional_tricks.md#pixel-3-blueline) |
| Redmi K30 4G (phoenix[n])      | XiaoMi       | Y                    | 10 | [verified](https://github.com/cfig/Android_boot_image_editor/issues/17#issuecomment-817169307) by @eebssk1 |
| TS10                           | Topway       | Y                    | 10                       | car headunit, @mariodantas |
| Pixel XL (marlin)              | HTC          | Y                    | 9.0.0 (PPR2.180905.006, <Br>Sep 2018)| [more ...](doc/additional_tricks.md#pixel-xl-marlin) |
| K3 (CPH1955)                   | OPPO         | Y for recovery.img<Br> N for boot.img  | Pie    | [more](doc/additional_tricks.md#k3-cph1955) |
| Z18 (NX606J)                   | ZTE          | Y                    | 8.1.0                    | [more...](doc/additional_tricks.md#nx606j) |
| Nexus 9 (volantis/flounder)    | HTC          | Y(with some tricks)  | 7.1.1 (N9F27M, Oct 2017) | [tricks](doc/additional_tricks.md#tricks-for-nexus-9volantis)|
| Nexus 5x (bullhead)            | LG           | Y                    | 6.0.0_r12 (MDA89E)       |      |
| Moto X (2013) T-Mobile         | Motorola     | N                    |                          |      |
| X7 (PD1602_A_3.12.8)           | VIVO         | N                    | ?                        | [Issue 35](https://github.com/cfig/Android_boot_image_editor/issues/35) |
| Realme GT Neo 3                | Realme       | N                    | 12                       | [Issue 105](https://github.com/cfig/Android_boot_image_editor/issues/105) |

## more examples
<details>
  <summary>working with recovery.img</summary>

Please remember to clean the work directory first.

```bash
rm *.img
cp <your_recovery_image> recovery.img
./gradlew unpack
./gradlew pack
```

</details>

<details>
  <summary>working with vbmeta.img</summary>


```bash
rm *.img
cp <your_vbmeta_image> vbmeta.img
./gradlew unpack
./gradlew pack
```

</details>

<details>
  <summary>clean workspace</summary>
When you finished current work and need to clean the workspace for next image, it's a good idea to call the `clear` command:

```bash
./gradlew clear
```

</details>

<details>
  <summary>working with boot.img and vbmeta.img</summary>

If your vbmeta.img contains hash of boot.img, you MUST update vbmeta image together.

```bash
rm *.img
cp <your_boot_image> boot.img
cp <your_vbmeta_image> vbmeta.img
./gradlew unpack
./gradlew pack
```
Your boot.img.signed and vbmeta.img.signd will be updated together, then you can flash them to your device.

</details>

<details>
  <summary>working with vendor_boot.img + vbmeta.img (Pixel 5 etc.)</summary>
Most devices include hash descriptor of vendor_boot.img in vbmeta.img, so if you need to modify vendor_boot.img, you need to update vbmeta.img together.

```bash
rm *.img
cp <your_vendor_boot_image> vendor_boot.img
cp <your_vbmeta_image> vbmeta.img
./gradlew unpack
./gradlew pack
./gradlew flash
```

Please note that to use 'gradle flash', your host machine must be connectted to your DUT with adb, and you already 'adb root'.

</details>

<details>
  <summary>edit device-tree blob(dtb) inside vendor_boot.img</summary>

If you want to edit the device-tree blob in place:

```bash
cp <your_vendor_boot_image> vendor_boot.img
cp <your_vbmeta_image> vbmeta.img
./gradlew unpack
==> now you can edit build/unzip_boot/dtb.dts directly
./gradlew pack
```

During unpack stage, dtb will be dumped to file `build/unzip_boot/dtb`, dts will be decompiled to `build/unzip_boot/dtb.dts`.
You can edit `dtb.dts` directly, and it will be compiled to dtb duing repack stage.

If you just want to replace the dtb with the one that is compiled outside this tool, please

```bash
cp <your_vendor_boot_image> vendor_boot.img
cp <your_vbmeta_image> vbmeta.img
./gradlew unpack
rm build/unzip_boot/dtb.dts
cp <your_dtb> build/unzip_boot/dtb
./gradlew pack
```

</details>

<details>
  <summary>working with system.img</summary>

First enable **hacking mode** by setting `bHackingMode = true` in file `build.gradle.kts`, then
```bash
cp <your_system_image> system.img
./gradlew unpack
```
You get `system.img.unsparse`, that's a plain ext4 filesystem data.

</details>

<details>
  <summary>How to disable AVB verification</summary>

The idea is to set flag=2 in main vbmeta.

```bash
rm *.img
cp <your_vbmeta_image> vbmeta.img
./gradlew unpack
vim -u NONE -N build/unzip_boot/vbmeta.avb.json  -c ":19s/0/2/g" -c ":wq"
./gradlew pack
```
Then flash vbmeta.img.signed to your device.

</details>

<details>

  <summary>How to merge init_boot.img into boot.img</summary>

* unpack init_boot.img and copy out "build/unzip_boot/root".
* clear workspace by `gradle clear`, then unpack boot.img
* copy back the "build/unzip_boot/root"
* edit build/unzip_boot/boot.json
- change `ramdisk.size` to 1
- change `ramdisk.file` from "build/unzip_boot/ramdisk.img" to "build/unzip_boot/ramdisk.img.lz4"

</details>

## boot.img layout
Read [boot layout](doc/layout.md) of Android boot.img and vendor\_boot.img.
Read [miac layout](doc/misc_image_layout.md) of misc\.img

## References and Acknowledgement
<details>
  <summary>more ...</summary>

Android version list https://source.android.com/source/build-numbers.html<br/>
Android build-numbers https://source.android.com/setup/start/build-numbers

cpio & fs\_config<br>
https://android.googlesource.com/platform/system/core<br/>
https://www.kernel.org/doc/Documentation/early-userspace/buffer-format.txt<br/>
AVB<br/>
https://android.googlesource.com/platform/external/avb/<br/>
boot\_signer<br/>
https://android.googlesource.com/platform/system/extras<br/>
mkbootimg<br/>
https://android.googlesource.com/platform/system/tools/mkbootimg/+/refs/heads/master/<br/>
boot header definition<br/>
https://android.googlesource.com/platform/system/tools/mkbootimg/+/refs/heads/master/include/bootimg/bootimg.h<br/>
kernel info extractor<br/>
https://android.googlesource.com/platform/build/+/refs/heads/master/tools/extract_kernel.py<br/>
mkdtboimg<br/>
https://android.googlesource.com/platform/system/libufdt/<br/>
libsparse<br/>
https://android.googlesource.com/platform/system/core/+/refs/heads/master/libsparse/<br/>
Android Nexus/Pixle factory images<br/>
https://developers.google.cn/android/images<br/>

This project is developed with products by Jetbrains.


<a href="https://jb.gg/OpenSource">
  <img src="https://user-images.githubusercontent.com/1133314/116802621-c076be80-ab46-11eb-8a14-9454a933de7d.png" alt="drawing" width="80">
</a>

</details>

```

`aosp/avb/avbtool.diff`:

```diff
diff --git a/avb/avbtool b/avb/avbtool
index 8732024..5f62948 100755
--- a/avb/avbtool
+++ b/avb/avbtool
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/env python2.7
 
 # Copyright 2016, The Android Open Source Project
 #
@@ -2159,7 +2159,8 @@ class Avb(object):
         expected_chain_partitions_map[partition_name] = (rollback_index_location, pk_blob)
 
     image_dir = os.path.dirname(image_filename)
-    image_ext = os.path.splitext(image_filename)[1]
+    #image_ext = os.path.splitext(image_filename)[1]
+    image_ext = image_filename[image_filename.index('.'):]
 
     key_blob = None
     if key_path:

```

`aosp/avb/avbtool.v1.1.py`:

```py
#!/usr/bin/env python2

# Copyright 2016, The Android Open Source Project
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without
# restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
"""Command-line tool for working with Android Verified Boot images."""

from __future__ import print_function

import argparse
import binascii
import bisect
import hashlib
import math
import os
import struct
import subprocess
import sys
import tempfile
import time

# Keep in sync with libavb/avb_version.h.
AVB_VERSION_MAJOR = 1
AVB_VERSION_MINOR = 1
AVB_VERSION_SUB = 0

# Keep in sync with libavb/avb_footer.h.
AVB_FOOTER_VERSION_MAJOR = 1
AVB_FOOTER_VERSION_MINOR = 0

AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED = 1


class AvbError(Exception):
  """Application-specific errors.

  These errors represent issues for which a stack-trace should not be
  presented.

  Attributes:
    message: Error message.
  """

  def __init__(self, message):
    Exception.__init__(self, message)


class Algorithm(object):
  """Contains details about an algorithm.

  See the avb_vbmeta_image.h file for more details about algorithms.

  The constant |ALGORITHMS| is a dictionary from human-readable
  names (e.g 'SHA256_RSA2048') to instances of this class.

  Attributes:
    algorithm_type: Integer code corresponding to |AvbAlgorithmType|.
    hash_name: Empty or a name from |hashlib.algorithms|.
    hash_num_bytes: Number of bytes used to store the hash.
    signature_num_bytes: Number of bytes used to store the signature.
    public_key_num_bytes: Number of bytes used to store the public key.
    padding: Padding used for signature, if any.
  """

  def __init__(self, algorithm_type, hash_name, hash_num_bytes,
               signature_num_bytes, public_key_num_bytes, padding):
    self.algorithm_type = algorithm_type
    self.hash_name = hash_name
    self.hash_num_bytes = hash_num_bytes
    self.signature_num_bytes = signature_num_bytes
    self.public_key_num_bytes = public_key_num_bytes
    self.padding = padding


# This must be kept in sync with the avb_crypto.h file.
#
# The PKC1-v1.5 padding is a blob of binary DER of ASN.1 and is
# obtained from section 5.2.2 of RFC 4880.
ALGORITHMS = {
    'NONE': Algorithm(
        algorithm_type=0,        # AVB_ALGORITHM_TYPE_NONE
        hash_name='',
        hash_num_bytes=0,
        signature_num_bytes=0,
        public_key_num_bytes=0,
        padding=[]),
    'SHA256_RSA2048': Algorithm(
        algorithm_type=1,        # AVB_ALGORITHM_TYPE_SHA256_RSA2048
        hash_name='sha256',
        hash_num_bytes=32,
        signature_num_bytes=256,
        public_key_num_bytes=8 + 2*2048//8,
        padding=[
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*202 + [0x00] + [
                # ASN.1 header
                0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                0x00, 0x04, 0x20,
            ]),
    'SHA256_RSA4096': Algorithm(
        algorithm_type=2,        # AVB_ALGORITHM_TYPE_SHA256_RSA4096
        hash_name='sha256',
        hash_num_bytes=32,
        signature_num_bytes=512,
        public_key_num_bytes=8 + 2*4096//8,
        padding=[
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*458 + [0x00] + [
                # ASN.1 header
                0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                0x00, 0x04, 0x20,
            ]),
    'SHA256_RSA8192': Algorithm(
        algorithm_type=3,        # AVB_ALGORITHM_TYPE_SHA256_RSA8192
        hash_name='sha256',
        hash_num_bytes=32,
        signature_num_bytes=1024,
        public_key_num_bytes=8 + 2*8192//8,
        padding=[
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*970 + [0x00] + [
                # ASN.1 header
                0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                0x00, 0x04, 0x20,
            ]),
    'SHA512_RSA2048': Algorithm(
        algorithm_type=4,        # AVB_ALGORITHM_TYPE_SHA512_RSA2048
        hash_name='sha512',
        hash_num_bytes=64,
        signature_num_bytes=256,
        public_key_num_bytes=8 + 2*2048//8,
        padding=[
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*170 + [0x00] + [
                # ASN.1 header
                0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                0x00, 0x04, 0x40
            ]),
    'SHA512_RSA4096': Algorithm(
        algorithm_type=5,        # AVB_ALGORITHM_TYPE_SHA512_RSA4096
        hash_name='sha512',
        hash_num_bytes=64,
        signature_num_bytes=512,
        public_key_num_bytes=8 + 2*4096//8,
        padding=[
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*426 + [0x00] + [
                # ASN.1 header
                0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                0x00, 0x04, 0x40
            ]),
    'SHA512_RSA8192': Algorithm(
        algorithm_type=6,        # AVB_ALGORITHM_TYPE_SHA512_RSA8192
        hash_name='sha512',
        hash_num_bytes=64,
        signature_num_bytes=1024,
        public_key_num_bytes=8 + 2*8192//8,
        padding=[
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*938 + [0x00] + [
                # ASN.1 header
                0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                0x00, 0x04, 0x40
            ]),
}


def get_release_string():
  """Calculates the release string to use in the VBMeta struct."""
  # Keep in sync with libavb/avb_version.c:avb_version_string().
  return 'avbtool {}.{}.{}'.format(AVB_VERSION_MAJOR,
                                   AVB_VERSION_MINOR,
                                   AVB_VERSION_SUB)


def round_to_multiple(number, size):
  """Rounds a number up to nearest multiple of another number.

  Arguments:
    number: The number to round up.
    size: The multiple to round up to.

  Returns:
    If |number| is a multiple of |size|, returns |number|, otherwise
    returns |number| + |size|.
  """
  remainder = number % size
  if remainder == 0:
    return number
  return number + size - remainder


def round_to_pow2(number):
  """Rounds a number up to the next power of 2.

  Arguments:
    number: The number to round up.

  Returns:
    If |number| is already a power of 2 then |number| is
    returned. Otherwise the smallest power of 2 greater than |number|
    is returned.
  """
  return 2**((number - 1).bit_length())


def encode_long(num_bits, value):
  """Encodes a long to a bytearray() using a given amount of bits.

  This number is written big-endian, e.g. with the most significant
  bit first.

  This is the reverse of decode_long().

  Arguments:
    num_bits: The number of bits to write, e.g. 2048.
    value: The value to write.

  Returns:
    A bytearray() with the encoded long.
  """
  ret = bytearray()
  for bit_pos in range(num_bits, 0, -8):
    octet = (value >> (bit_pos - 8)) & 0xff
    ret.extend(struct.pack('!B', octet))
  return ret


def decode_long(blob):
  """Decodes a long from a bytearray() using a given amount of bits.

  This number is expected to be in big-endian, e.g. with the most
  significant bit first.

  This is the reverse of encode_long().

  Arguments:
    blob: A bytearray() with the encoded long.

  Returns:
    The decoded value.
  """
  ret = 0
  for b in bytearray(blob):
    ret *= 256
    ret += b
  return ret


def egcd(a, b):
  """Calculate greatest common divisor of two numbers.

  This implementation uses a recursive version of the extended
  Euclidian algorithm.

  Arguments:
    a: First number.
    b: Second number.

  Returns:
    A tuple (gcd, x, y) that where |gcd| is the greatest common
    divisor of |a| and |b| and |a|*|x| + |b|*|y| = |gcd|.
  """
  if a == 0:
    return (b, 0, 1)
  g, y, x = egcd(b % a, a)
  return (g, x - (b // a) * y, y)


def modinv(a, m):
  """Calculate modular multiplicative inverse of |a| modulo |m|.

  This calculates the number |x| such that |a| * |x| == 1 (modulo
  |m|). This number only exists if |a| and |m| are co-prime - |None|
  is returned if this isn't true.

  Arguments:
    a: The number to calculate a modular inverse of.
    m: The modulo to use.

  Returns:
    The modular multiplicative inverse of |a| and |m| or |None| if
    these numbers are not co-prime.
  """
  gcd, x, _ = egcd(a, m)
  if gcd != 1:
    return None  # modular inverse does not exist
  return x % m


def parse_number(string):
  """Parse a string as a number.

  This is just a short-hand for int(string, 0) suitable for use in the
  |type| parameter of |ArgumentParser|'s add_argument() function. An
  improvement to just using type=int is that this function supports
  numbers in other bases, e.g. "0x1234".

  Arguments:
    string: The string to parse.

  Returns:
    The parsed integer.

  Raises:
    ValueError: If the number could not be parsed.
  """
  return int(string, 0)


class RSAPublicKey(object):
  """Data structure used for a RSA public key.

  Attributes:
    exponent: The key exponent.
    modulus: The key modulus.
    num_bits: The key size.
  """

  MODULUS_PREFIX = 'modulus='

  def __init__(self, key_path):
    """Loads and parses an RSA key from either a private or public key file.

    Arguments:
      key_path: The path to a key file.

    Raises:
      AvbError: If RSA key parameters could not be read from file.
    """
    # We used to have something as simple as this:
    #
    #  key = Crypto.PublicKey.RSA.importKey(open(key_path).read())
    #  self.exponent = key.e
    #  self.modulus = key.n
    #  self.num_bits = key.size() + 1
    #
    # but unfortunately PyCrypto is not available in the builder. So
    # instead just parse openssl(1) output to get this
    # information. It's ugly but...
    args = ['openssl', 'rsa', '-in', key_path, '-modulus', '-noout']
    p = subprocess.Popen(args,
                         stdin=subprocess.PIPE,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE)
    (pout, perr) = p.communicate()
    if p.wait() != 0:
      # Could be just a public key is passed, try that.
      args.append('-pubin')
      p = subprocess.Popen(args,
                           stdin=subprocess.PIPE,
                           stdout=subprocess.PIPE,
                           stderr=subprocess.PIPE)
      (pout, perr) = p.communicate()
      if p.wait() != 0:
        raise AvbError('Error getting public key: {}'.format(perr))

    if not pout.lower().startswith(self.MODULUS_PREFIX):
      raise AvbError('Unexpected modulus output')

    modulus_hexstr = pout[len(self.MODULUS_PREFIX):]

    # The exponent is assumed to always be 65537 and the number of
    # bits can be derived from the modulus by rounding up to the
    # nearest power of 2.
    self.modulus = int(modulus_hexstr, 16)
    self.num_bits = round_to_pow2(int(math.ceil(math.log(self.modulus, 2))))
    self.exponent = 65537


# TODO(danielaustin): Should this be moved into the RSAPublicKey class?
def rsa_key_read_pem_bytes(key_path):
  """Reads the bytes out of the passed in PEM file.

  Arguments:
    key_path: A string containing the path to the PEM file.

  Returns:
    A bytearray containing the bytes in the PEM file.

  Raises:
    AvbError: If openssl cannot decode the PEM file.
  """
  # Use openssl to decode the PEM file.
  args = ['openssl', 'rsa', '-in', key_path, '-pubout', '-outform', 'DER']
  p = subprocess.Popen(args,
                       stdin=subprocess.PIPE,
                       stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE)
  (pout, perr) = p.communicate()
  retcode = p.wait()
  if retcode != 0:
    raise AvbError('Error decoding: {}'.format(perr))
  return bytearray(pout)


def encode_rsa_key(key_path):
  """Encodes a public RSA key in |AvbRSAPublicKeyHeader| format.

  This creates a |AvbRSAPublicKeyHeader| as well as the two large
  numbers (|key_num_bits| bits long) following it.

  Arguments:
    key_path: The path to a key file.

  Returns:
    A bytearray() with the |AvbRSAPublicKeyHeader|.

  Raises:
    AvbError: If given RSA key exponent is not 65537.
  """
  key = RSAPublicKey(key_path)
  if key.exponent != 65537:
    raise AvbError('Only RSA keys with exponent 65537 are supported.')
  ret = bytearray()
  # Calculate n0inv = -1/n[0] (mod 2^32)
  b = 2L**32  # pylint: disable=long-suffix
  n0inv = b - modinv(key.modulus, b)
  # Calculate rr = r^2 (mod N), where r = 2^(# of key bits)
  r = 2L**key.modulus.bit_length()  # pylint: disable=long-suffix
  rrmodn = r * r % key.modulus
  ret.extend(struct.pack('!II', key.num_bits, n0inv))
  ret.extend(encode_long(key.num_bits, key.modulus))
  ret.extend(encode_long(key.num_bits, rrmodn))
  return ret


def lookup_algorithm_by_type(alg_type):
  """Looks up algorithm by type.

  Arguments:
    alg_type: The integer representing the type.

  Returns:
    A tuple with the algorithm name and an |Algorithm| instance.

  Raises:
    Exception: If the algorithm cannot be found
  """
  for alg_name in ALGORITHMS:
    alg_data = ALGORITHMS[alg_name]
    if alg_data.algorithm_type == alg_type:
      return (alg_name, alg_data)
  raise AvbError('Unknown algorithm type {}'.format(alg_type))


def lookup_hash_size_by_type(alg_type):
  """Looks up hash size by type.

  Arguments:
    alg_type: The integer representing the type.

  Returns:
    The corresponding hash size.

  Raises:
    AvbError: If the algorithm cannot be found.
  """
  for alg_name in ALGORITHMS:
    alg_data = ALGORITHMS[alg_name]
    if alg_data.algorithm_type == alg_type:
      return alg_data.hash_num_bytes
  raise AvbError('Unsupported algorithm type {}'.format(alg_type))


def raw_sign(signing_helper, signing_helper_with_files,
             algorithm_name, signature_num_bytes, key_path,
             raw_data_to_sign):
  """Computes a raw RSA signature using |signing_helper| or openssl.

  Arguments:
    signing_helper: Program which signs a hash and returns the signature.
    signing_helper_with_files: Same as signing_helper but uses files instead.
    algorithm_name: The algorithm name as per the ALGORITHMS dict.
    signature_num_bytes: Number of bytes used to store the signature.
    key_path: Path to the private key file. Must be PEM format.
    raw_data_to_sign: Data to sign (bytearray or str expected).

  Returns:
    A bytearray containing the signature.

  Raises:
    Exception: If an error occurs.
  """
  p = None
  if signing_helper_with_files is not None:
    signing_file = tempfile.NamedTemporaryFile()
    signing_file.write(str(raw_data_to_sign))
    signing_file.flush()
    p = subprocess.Popen([
        signing_helper_with_files, algorithm_name, key_path, signing_file.name])
    retcode = p.wait()
    if retcode != 0:
      raise AvbError('Error signing')
    signing_file.seek(0)
    signature = bytearray(signing_file.read())
  else:
    if signing_helper is not None:
      p = subprocess.Popen(
          [signing_helper, algorithm_name, key_path],
          stdin=subprocess.PIPE,
          stdout=subprocess.PIPE,
          stderr=subprocess.PIPE)
    else:
      p = subprocess.Popen(
          ['openssl', 'rsautl', '-sign', '-inkey', key_path, '-raw'],
          stdin=subprocess.PIPE,
          stdout=subprocess.PIPE,
          stderr=subprocess.PIPE)
    (pout, perr) = p.communicate(str(raw_data_to_sign))
    retcode = p.wait()
    if retcode != 0:
      raise AvbError('Error signing: {}'.format(perr))
    signature = bytearray(pout)
  if len(signature) != signature_num_bytes:
    raise AvbError('Error signing: Invalid length of signature')
  return signature


def verify_vbmeta_signature(vbmeta_header, vbmeta_blob):
  """Checks that signature in a vbmeta blob was made by the embedded public key.

  Arguments:
    vbmeta_header: A AvbVBMetaHeader.
    vbmeta_blob: The whole vbmeta blob, including the header.

  Returns:
    True if the signature is valid and corresponds to the embedded
    public key. Also returns True if the vbmeta blob is not signed.

  Raises:
    AvbError: If there errors calling out to openssl command during
        signature verification.
  """
  (_, alg) = lookup_algorithm_by_type(vbmeta_header.algorithm_type)
  if not alg.hash_name:
    return True
  header_blob = vbmeta_blob[0:256]
  auth_offset = 256
  aux_offset = auth_offset + vbmeta_header.authentication_data_block_size
  aux_size = vbmeta_header.auxiliary_data_block_size
  aux_blob = vbmeta_blob[aux_offset:aux_offset + aux_size]
  pubkey_offset = aux_offset + vbmeta_header.public_key_offset
  pubkey_size = vbmeta_header.public_key_size
  pubkey_blob = vbmeta_blob[pubkey_offset:pubkey_offset + pubkey_size]

  digest_offset = auth_offset + vbmeta_header.hash_offset
  digest_size = vbmeta_header.hash_size
  digest_blob = vbmeta_blob[digest_offset:digest_offset + digest_size]

  sig_offset = auth_offset + vbmeta_header.signature_offset
  sig_size = vbmeta_header.signature_size
  sig_blob = vbmeta_blob[sig_offset:sig_offset + sig_size]

  # Now that we've got the stored digest, public key, and signature
  # all we need to do is to verify. This is the exactly the same
  # steps as performed in the avb_vbmeta_image_verify() function in
  # libavb/avb_vbmeta_image.c.

  ha = hashlib.new(alg.hash_name)
  ha.update(header_blob)
  ha.update(aux_blob)
  computed_digest = ha.digest()

  if computed_digest != digest_blob:
    return False

  padding_and_digest = bytearray(alg.padding)
  padding_and_digest.extend(computed_digest)

  (num_bits,) = struct.unpack('!I', pubkey_blob[0:4])
  modulus_blob = pubkey_blob[8:8 + num_bits//8]
  modulus = decode_long(modulus_blob)
  exponent = 65537

  # We used to have this:
  #
  #  import Crypto.PublicKey.RSA
  #  key = Crypto.PublicKey.RSA.construct((modulus, long(exponent)))
  #  if not key.verify(decode_long(padding_and_digest),
  #                    (decode_long(sig_blob), None)):
  #    return False
  #  return True
  #
  # but since 'avbtool verify_image' is used on the builders we don't want
  # to rely on Crypto.PublicKey.RSA. Instead just use openssl(1) to verify.
  asn1_str = ('asn1=SEQUENCE:pubkeyinfo\n'
              '\n'
              '[pubkeyinfo]\n'
              'algorithm=SEQUENCE:rsa_alg\n'
              'pubkey=BITWRAP,SEQUENCE:rsapubkey\n'
              '\n'
              '[rsa_alg]\n'
              'algorithm=OID:rsaEncryption\n'
              'parameter=NULL\n'
              '\n'
              '[rsapubkey]\n'
              'n=INTEGER:%s\n'
              'e=INTEGER:%s\n' % (hex(modulus).rstrip('L'),
                                  hex(exponent).rstrip('L')))
  asn1_tmpfile = tempfile.NamedTemporaryFile()
  asn1_tmpfile.write(asn1_str)
  asn1_tmpfile.flush()
  der_tmpfile = tempfile.NamedTemporaryFile()
  p = subprocess.Popen(
      ['openssl', 'asn1parse', '-genconf', asn1_tmpfile.name, '-out',
       der_tmpfile.name, '-noout'])
  retcode = p.wait()
  if retcode != 0:
    raise AvbError('Error generating DER file')

  p = subprocess.Popen(
      ['openssl', 'rsautl', '-verify', '-pubin', '-inkey', der_tmpfile.name,
       '-keyform', 'DER', '-raw'],
      stdin=subprocess.PIPE,
      stdout=subprocess.PIPE,
      stderr=subprocess.PIPE)
  (pout, perr) = p.communicate(str(sig_blob))
  retcode = p.wait()
  if retcode != 0:
    raise AvbError('Error verifying data: {}'.format(perr))
  recovered_data = bytearray(pout)
  if recovered_data != padding_and_digest:
    sys.stderr.write('Signature not correct\n')
    return False
  return True


class ImageChunk(object):
  """Data structure used for representing chunks in Android sparse files.

  Attributes:
    chunk_type: One of TYPE_RAW, TYPE_FILL, or TYPE_DONT_CARE.
    chunk_offset: Offset in the sparse file where this chunk begins.
    output_offset: Offset in de-sparsified file where output begins.
    output_size: Number of bytes in output.
    input_offset: Offset in sparse file for data if TYPE_RAW otherwise None.
    fill_data: Blob with data to fill if TYPE_FILL otherwise None.
  """

  FORMAT = '<2H2I'
  TYPE_RAW = 0xcac1
  TYPE_FILL = 0xcac2
  TYPE_DONT_CARE = 0xcac3
  TYPE_CRC32 = 0xcac4

  def __init__(self, chunk_type, chunk_offset, output_offset, output_size,
               input_offset, fill_data):
    """Initializes an ImageChunk object.

    Arguments:
      chunk_type: One of TYPE_RAW, TYPE_FILL, or TYPE_DONT_CARE.
      chunk_offset: Offset in the sparse file where this chunk begins.
      output_offset: Offset in de-sparsified file.
      output_size: Number of bytes in output.
      input_offset: Offset in sparse file if TYPE_RAW otherwise None.
      fill_data: Blob with data to fill if TYPE_FILL otherwise None.

    Raises:
      ValueError: If data is not well-formed.
    """
    self.chunk_type = chunk_type
    self.chunk_offset = chunk_offset
    self.output_offset = output_offset
    self.output_size = output_size
    self.input_offset = input_offset
    self.fill_data = fill_data
    # Check invariants.
    if self.chunk_type == self.TYPE_RAW:
      if self.fill_data is not None:
        raise ValueError('RAW chunk cannot have fill_data set.')
      if not self.input_offset:
        raise ValueError('RAW chunk must have input_offset set.')
    elif self.chunk_type == self.TYPE_FILL:
      if self.fill_data is None:
        raise ValueError('FILL chunk must have fill_data set.')
      if self.input_offset:
        raise ValueError('FILL chunk cannot have input_offset set.')
    elif self.chunk_type == self.TYPE_DONT_CARE:
      if self.fill_data is not None:
        raise ValueError('DONT_CARE chunk cannot have fill_data set.')
      if self.input_offset:
        raise ValueError('DONT_CARE chunk cannot have input_offset set.')
    else:
      raise ValueError('Invalid chunk type')


class ImageHandler(object):
  """Abstraction for image I/O with support for Android sparse images.

  This class provides an interface for working with image files that
  may be using the Android Sparse Image format. When an instance is
  constructed, we test whether it's an Android sparse file. If so,
  operations will be on the sparse file by interpreting the sparse
  format, otherwise they will be directly on the file. Either way the
  operations do the same.

  For reading, this interface mimics a file object - it has seek(),
  tell(), and read() methods. For writing, only truncation
  (truncate()) and appending is supported (append_raw() and
  append_dont_care()). Additionally, data can only be written in units
  of the block size.

  Attributes:
    filename: Name of file.
    is_sparse: Whether the file being operated on is sparse.
    block_size: The block size, typically 4096.
    image_size: The size of the unsparsified file.
  """
  # See system/core/libsparse/sparse_format.h for details.
  MAGIC = 0xed26ff3a
  HEADER_FORMAT = '<I4H4I'

  # These are formats and offset of just the |total_chunks| and
  # |total_blocks| fields.
  NUM_CHUNKS_AND_BLOCKS_FORMAT = '<II'
  NUM_CHUNKS_AND_BLOCKS_OFFSET = 16

  def __init__(self, image_filename):
    """Initializes an image handler.

    Arguments:
      image_filename: The name of the file to operate on.

    Raises:
      ValueError: If data in the file is invalid.
    """
    self.filename = image_filename
    self._num_total_blocks = 0
    self._num_total_chunks = 0
    self._file_pos = 0
    self._read_header()

  def _read_header(self):
    """Initializes internal data structures used for reading file.

    This may be called multiple times and is typically called after
    modifying the file (e.g. appending, truncation).

    Raises:
      ValueError: If data in the file is invalid.
    """
    self.is_sparse = False
    self.block_size = 4096
    self._file_pos = 0
    self._image = open(self.filename, 'r+b')
    self._image.seek(0, os.SEEK_END)
    self.image_size = self._image.tell()

    self._image.seek(0, os.SEEK_SET)
    header_bin = self._image.read(struct.calcsize(self.HEADER_FORMAT))
    (magic, major_version, minor_version, file_hdr_sz, chunk_hdr_sz,
     block_size, self._num_total_blocks, self._num_total_chunks,
     _) = struct.unpack(self.HEADER_FORMAT, header_bin)
    if magic != self.MAGIC:
      # Not a sparse image, our job here is done.
      return
    if not (major_version == 1 and minor_version == 0):
      raise ValueError('Encountered sparse image format version {}.{} but '
                       'only 1.0 is supported'.format(major_version,
                                                      minor_version))
    if file_hdr_sz != struct.calcsize(self.HEADER_FORMAT):
      raise ValueError('Unexpected file_hdr_sz value {}.'.
                       format(file_hdr_sz))
    if chunk_hdr_sz != struct.calcsize(ImageChunk.FORMAT):
      raise ValueError('Unexpected chunk_hdr_sz value {}.'.
                       format(chunk_hdr_sz))

    self.block_size = block_size

    # Build an list of chunks by parsing the file.
    self._chunks = []

    # Find the smallest offset where only "Don't care" chunks
    # follow. This will be the size of the content in the sparse
    # image.
    offset = 0
    output_offset = 0
    for _ in range(1, self._num_total_chunks + 1):
      chunk_offset = self._image.tell()

      header_bin = self._image.read(struct.calcsize(ImageChunk.FORMAT))
      (chunk_type, _, chunk_sz, total_sz) = struct.unpack(ImageChunk.FORMAT,
                                                          header_bin)
      data_sz = total_sz - struct.calcsize(ImageChunk.FORMAT)

      if chunk_type == ImageChunk.TYPE_RAW:
        if data_sz != (chunk_sz * self.block_size):
          raise ValueError('Raw chunk input size ({}) does not match output '
                           'size ({})'.
                           format(data_sz, chunk_sz*self.block_size))
        self._chunks.append(ImageChunk(ImageChunk.TYPE_RAW,
                                       chunk_offset,
                                       output_offset,
                                       chunk_sz*self.block_size,
                                       self._image.tell(),
                                       None))
        self._image.seek(data_sz, os.SEEK_CUR)

      elif chunk_type == ImageChunk.TYPE_FILL:
        if data_sz != 4:
          raise ValueError('Fill chunk should have 4 bytes of fill, but this '
                           'has {}'.format(data_sz))
        fill_data = self._image.read(4)
        self._chunks.append(ImageChunk(ImageChunk.TYPE_FILL,
                                       chunk_offset,
                                       output_offset,
                                       chunk_sz*self.block_size,
                                       None,
                                       fill_data))
      elif chunk_type == ImageChunk.TYPE_DONT_CARE:
        if data_sz != 0:
          raise ValueError('Don\'t care chunk input size is non-zero ({})'.
                           format(data_sz))
        self._chunks.append(ImageChunk(ImageChunk.TYPE_DONT_CARE,
                                       chunk_offset,
                                       output_offset,
                                       chunk_sz*self.block_size,
                                       None,
                                       None))
      elif chunk_type == ImageChunk.TYPE_CRC32:
        if data_sz != 4:
          raise ValueError('CRC32 chunk should have 4 bytes of CRC, but '
                           'this has {}'.format(data_sz))
        self._image.read(4)
      else:
        raise ValueError('Unknown chunk type {}'.format(chunk_type))

      offset += chunk_sz
      output_offset += chunk_sz*self.block_size

    # Record where sparse data end.
    self._sparse_end = self._image.tell()

    # Now that we've traversed all chunks, sanity check.
    if self._num_total_blocks != offset:
      raise ValueError('The header said we should have {} output blocks, '
                       'but we saw {}'.format(self._num_total_blocks, offset))
    junk_len = len(self._image.read())
    if junk_len > 0:
      raise ValueError('There were {} bytes of extra data at the end of the '
                       'file.'.format(junk_len))

    # Assign |image_size|.
    self.image_size = output_offset

    # This is used when bisecting in read() to find the initial slice.
    self._chunk_output_offsets = [i.output_offset for i in self._chunks]

    self.is_sparse = True

  def _update_chunks_and_blocks(self):
    """Helper function to update the image header.

    The the |total_chunks| and |total_blocks| fields in the header
    will be set to value of the |_num_total_blocks| and
    |_num_total_chunks| attributes.

    """
    self._image.seek(self.NUM_CHUNKS_AND_BLOCKS_OFFSET, os.SEEK_SET)
    self._image.write(struct.pack(self.NUM_CHUNKS_AND_BLOCKS_FORMAT,
                                  self._num_total_blocks,
                                  self._num_total_chunks))

  def append_dont_care(self, num_bytes):
    """Appends a DONT_CARE chunk to the sparse file.

    The given number of bytes must be a multiple of the block size.

    Arguments:
      num_bytes: Size in number of bytes of the DONT_CARE chunk.
    """
    assert num_bytes % self.block_size == 0

    if not self.is_sparse:
      self._image.seek(0, os.SEEK_END)
      # This is more efficient that writing NUL bytes since it'll add
      # a hole on file systems that support sparse files (native
      # sparse, not Android sparse).
      self._image.truncate(self._image.tell() + num_bytes)
      self._read_header()
      return

    self._num_total_chunks += 1
    self._num_total_blocks += num_bytes // self.block_size
    self._update_chunks_and_blocks()

    self._image.seek(self._sparse_end, os.SEEK_SET)
    self._image.write(struct.pack(ImageChunk.FORMAT,
                                  ImageChunk.TYPE_DONT_CARE,
                                  0,  # Reserved
                                  num_bytes // self.block_size,
                                  struct.calcsize(ImageChunk.FORMAT)))
    self._read_header()

  def append_raw(self, data):
    """Appends a RAW chunk to the sparse file.

    The length of the given data must be a multiple of the block size.

    Arguments:
      data: Data to append.
    """
    assert len(data) % self.block_size == 0

    if not self.is_sparse:
      self._image.seek(0, os.SEEK_END)
      self._image.write(data)
      self._read_header()
      return

    self._num_total_chunks += 1
    self._num_total_blocks += len(data) // self.block_size
    self._update_chunks_and_blocks()

    self._image.seek(self._sparse_end, os.SEEK_SET)
    self._image.write(struct.pack(ImageChunk.FORMAT,
                                  ImageChunk.TYPE_RAW,
                                  0,  # Reserved
                                  len(data) // self.block_size,
                                  len(data) +
                                  struct.calcsize(ImageChunk.FORMAT)))
    self._image.write(data)
    self._read_header()

  def append_fill(self, fill_data, size):
    """Appends a fill chunk to the sparse file.

    The total length of the fill data must be a multiple of the block size.

    Arguments:
      fill_data: Fill data to append - must be four bytes.
      size: Number of chunk - must be a multiple of four and the block size.
    """
    assert len(fill_data) == 4
    assert size % 4 == 0
    assert size % self.block_size == 0

    if not self.is_sparse:
      self._image.seek(0, os.SEEK_END)
      self._image.write(fill_data * (size//4))
      self._read_header()
      return

    self._num_total_chunks += 1
    self._num_total_blocks += size // self.block_size
    self._update_chunks_and_blocks()

    self._image.seek(self._sparse_end, os.SEEK_SET)
    self._image.write(struct.pack(ImageChunk.FORMAT,
                                  ImageChunk.TYPE_FILL,
                                  0,  # Reserved
                                  size // self.block_size,
                                  4 + struct.calcsize(ImageChunk.FORMAT)))
    self._image.write(fill_data)
    self._read_header()

  def seek(self, offset):
    """Sets the cursor position for reading from unsparsified file.

    Arguments:
      offset: Offset to seek to from the beginning of the file.

    Raises:
      RuntimeError: If the given offset is negative.
    """
    if offset < 0:
      raise RuntimeError('Seeking with negative offset: %d' % offset)
    self._file_pos = offset

  def read(self, size):
    """Reads data from the unsparsified file.

    This method may return fewer than |size| bytes of data if the end
    of the file was encountered.

    The file cursor for reading is advanced by the number of bytes
    read.

    Arguments:
      size: Number of bytes to read.

    Returns:
      The data.

    """
    if not self.is_sparse:
      self._image.seek(self._file_pos)
      data = self._image.read(size)
      self._file_pos += len(data)
      return data

    # Iterate over all chunks.
    chunk_idx = bisect.bisect_right(self._chunk_output_offsets,
                                    self._file_pos) - 1
    data = bytearray()
    to_go = size
    while to_go > 0:
      chunk = self._chunks[chunk_idx]
      chunk_pos_offset = self._file_pos - chunk.output_offset
      chunk_pos_to_go = min(chunk.output_size - chunk_pos_offset, to_go)

      if chunk.chunk_type == ImageChunk.TYPE_RAW:
        self._image.seek(chunk.input_offset + chunk_pos_offset)
        data.extend(self._image.read(chunk_pos_to_go))
      elif chunk.chunk_type == ImageChunk.TYPE_FILL:
        all_data = chunk.fill_data*(chunk_pos_to_go // len(chunk.fill_data) + 2)
        offset_mod = chunk_pos_offset % len(chunk.fill_data)
        data.extend(all_data[offset_mod:(offset_mod + chunk_pos_to_go)])
      else:
        assert chunk.chunk_type == ImageChunk.TYPE_DONT_CARE
        data.extend('\0' * chunk_pos_to_go)

      to_go -= chunk_pos_to_go
      self._file_pos += chunk_pos_to_go
      chunk_idx += 1
      # Generate partial read in case of EOF.
      if chunk_idx >= len(self._chunks):
        break

    return data

  def tell(self):
    """Returns the file cursor position for reading from unsparsified file.

    Returns:
      The file cursor position for reading.
    """
    return self._file_pos

  def truncate(self, size):
    """Truncates the unsparsified file.

    Arguments:
      size: Desired size of unsparsified file.

    Raises:
      ValueError: If desired size isn't a multiple of the block size.
    """
    if not self.is_sparse:
      self._image.truncate(size)
      self._read_header()
      return

    if size % self.block_size != 0:
      raise ValueError('Cannot truncate to a size which is not a multiple '
                       'of the block size')

    if size == self.image_size:
      # Trivial where there's nothing to do.
      return
    elif size < self.image_size:
      chunk_idx = bisect.bisect_right(self._chunk_output_offsets, size) - 1
      chunk = self._chunks[chunk_idx]
      if chunk.output_offset != size:
        # Truncation in the middle of a trunk - need to keep the chunk
        # and modify it.
        chunk_idx_for_update = chunk_idx + 1
        num_to_keep = size - chunk.output_offset
        assert num_to_keep % self.block_size == 0
        if chunk.chunk_type == ImageChunk.TYPE_RAW:
          truncate_at = (chunk.chunk_offset +
                         struct.calcsize(ImageChunk.FORMAT) + num_to_keep)
          data_sz = num_to_keep
        elif chunk.chunk_type == ImageChunk.TYPE_FILL:
          truncate_at = (chunk.chunk_offset +
                         struct.calcsize(ImageChunk.FORMAT) + 4)
          data_sz = 4
        else:
          assert chunk.chunk_type == ImageChunk.TYPE_DONT_CARE
          truncate_at = chunk.chunk_offset + struct.calcsize(ImageChunk.FORMAT)
          data_sz = 0
        chunk_sz = num_to_keep // self.block_size
        total_sz = data_sz + struct.calcsize(ImageChunk.FORMAT)
        self._image.seek(chunk.chunk_offset)
        self._image.write(struct.pack(ImageChunk.FORMAT,
                                      chunk.chunk_type,
                                      0,  # Reserved
                                      chunk_sz,
                                      total_sz))
        chunk.output_size = num_to_keep
      else:
        # Truncation at trunk boundary.
        truncate_at = chunk.chunk_offset
        chunk_idx_for_update = chunk_idx

      self._num_total_chunks = chunk_idx_for_update
      self._num_total_blocks = 0
      for i in range(0, chunk_idx_for_update):
        self._num_total_blocks += self._chunks[i].output_size // self.block_size
      self._update_chunks_and_blocks()
      self._image.truncate(truncate_at)

      # We've modified the file so re-read all data.
      self._read_header()
    else:
      # Truncating to grow - just add a DONT_CARE section.
      self.append_dont_care(size - self.image_size)


class AvbDescriptor(object):
  """Class for AVB descriptor.

  See the |AvbDescriptor| C struct for more information.

  Attributes:
    tag: The tag identifying what kind of descriptor this is.
    data: The data in the descriptor.
  """

  SIZE = 16
  FORMAT_STRING = ('!QQ')  # tag, num_bytes_following (descriptor header)

  def __init__(self, data):
    """Initializes a new property descriptor.

    Arguments:
      data: If not None, must be a bytearray().

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.tag, num_bytes_following) = (
          struct.unpack(self.FORMAT_STRING, data[0:self.SIZE]))
      self.data = data[self.SIZE:self.SIZE + num_bytes_following]
    else:
      self.tag = None
      self.data = None

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Unknown descriptor:\n')
    o.write('      Tag:  {}\n'.format(self.tag))
    if len(self.data) < 256:
      o.write('      Data: {} ({} bytes)\n'.format(
          repr(str(self.data)), len(self.data)))
    else:
      o.write('      Data: {} bytes\n'.format(len(self.data)))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    num_bytes_following = len(self.data)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.tag, nbf_with_padding)
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + self.data + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    # Deletes unused parameters to prevent pylint warning unused-argument.
    del image_dir, image_ext, expected_chain_partitions_map
    del image_containing_descriptor, accept_zeroed_hashtree

    # Nothing to do.
    return True


class AvbPropertyDescriptor(AvbDescriptor):
  """A class for property descriptors.

  See the |AvbPropertyDescriptor| C struct for more information.

  Attributes:
    key: The key.
    value: The key.
  """

  TAG = 0
  SIZE = 32
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'Q'  # key size (bytes)
                   'Q')  # value size (bytes)

  def __init__(self, data=None):
    """Initializes a new property descriptor.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    AvbDescriptor.__init__(self, None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, key_size,
       value_size) = struct.unpack(self.FORMAT_STRING, data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + key_size + 1 + value_size + 1, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a property '
                          'descriptor.')
      self.key = data[self.SIZE:(self.SIZE + key_size)]
      self.value = data[(self.SIZE + key_size + 1):(self.SIZE + key_size + 1 +
                                                    value_size)]
    else:
      self.key = ''
      self.value = ''

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    if len(self.value) < 256:
      o.write('    Prop: {} -> {}\n'.format(self.key, repr(str(self.value))))
    else:
      o.write('    Prop: {} -> ({} bytes)\n'.format(self.key, len(self.value)))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    num_bytes_following = self.SIZE + len(self.key) + len(self.value) + 2 - 16
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       len(self.key), len(self.value))
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + self.key + '\0' + self.value + '\0' + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    # Nothing to do.
    return True


class AvbHashtreeDescriptor(AvbDescriptor):
  """A class for hashtree descriptors.

  See the |AvbHashtreeDescriptor| C struct for more information.

  Attributes:
    dm_verity_version: dm-verity version used.
    image_size: Size of the image, after rounding up to |block_size|.
    tree_offset: Offset of the hash tree in the file.
    tree_size: Size of the tree.
    data_block_size: Data block size
    hash_block_size: Hash block size
    fec_num_roots: Number of roots used for FEC (0 if FEC is not used).
    fec_offset: Offset of FEC data (0 if FEC is not used).
    fec_size: Size of FEC data (0 if FEC is not used).
    hash_algorithm: Hash algorithm used.
    partition_name: Partition name.
    salt: Salt used.
    root_digest: Root digest.
    flags: Descriptor flags (see avb_hashtree_descriptor.h).
  """

  TAG = 1
  RESERVED = 60
  SIZE = 120 + RESERVED
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'L'  # dm-verity version used
                   'Q'  # image size (bytes)
                   'Q'  # tree offset (bytes)
                   'Q'  # tree size (bytes)
                   'L'  # data block size (bytes)
                   'L'  # hash block size (bytes)
                   'L'  # FEC number of roots
                   'Q'  # FEC offset (bytes)
                   'Q'  # FEC size (bytes)
                   '32s'  # hash algorithm used
                   'L'  # partition name (bytes)
                   'L'  # salt length (bytes)
                   'L'  # root digest length (bytes)
                   'L' +  # flags
                   str(RESERVED) + 's')  # reserved

  def __init__(self, data=None):
    """Initializes a new hashtree descriptor.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    AvbDescriptor.__init__(self, None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.dm_verity_version, self.image_size,
       self.tree_offset, self.tree_size, self.data_block_size,
       self.hash_block_size, self.fec_num_roots, self.fec_offset, self.fec_size,
       self.hash_algorithm, partition_name_len, salt_len,
       root_digest_len, self.flags, _) = struct.unpack(self.FORMAT_STRING,
                                                       data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + partition_name_len + salt_len + root_digest_len, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a hashtree '
                          'descriptor.')
      # Nuke NUL-bytes at the end.
      self.hash_algorithm = self.hash_algorithm.split('\0', 1)[0]
      o = 0
      self.partition_name = str(data[(self.SIZE + o):(self.SIZE + o +
                                                      partition_name_len)])
      # Validate UTF-8 - decode() raises UnicodeDecodeError if not valid UTF-8.
      self.partition_name.decode('utf-8')
      o += partition_name_len
      self.salt = data[(self.SIZE + o):(self.SIZE + o + salt_len)]
      o += salt_len
      self.root_digest = data[(self.SIZE + o):(self.SIZE + o + root_digest_len)]
      if root_digest_len != len(hashlib.new(name=self.hash_algorithm).digest()):
        if root_digest_len != 0:
          raise LookupError('root_digest_len doesn\'t match hash algorithm')

    else:
      self.dm_verity_version = 0
      self.image_size = 0
      self.tree_offset = 0
      self.tree_size = 0
      self.data_block_size = 0
      self.hash_block_size = 0
      self.fec_num_roots = 0
      self.fec_offset = 0
      self.fec_size = 0
      self.hash_algorithm = ''
      self.partition_name = ''
      self.salt = bytearray()
      self.root_digest = bytearray()
      self.flags = 0

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Hashtree descriptor:\n')
    o.write('      Version of dm-verity:  {}\n'.format(self.dm_verity_version))
    o.write('      Image Size:            {} bytes\n'.format(self.image_size))
    o.write('      Tree Offset:           {}\n'.format(self.tree_offset))
    o.write('      Tree Size:             {} bytes\n'.format(self.tree_size))
    o.write('      Data Block Size:       {} bytes\n'.format(
        self.data_block_size))
    o.write('      Hash Block Size:       {} bytes\n'.format(
        self.hash_block_size))
    o.write('      FEC num roots:         {}\n'.format(self.fec_num_roots))
    o.write('      FEC offset:            {}\n'.format(self.fec_offset))
    o.write('      FEC size:              {} bytes\n'.format(self.fec_size))
    o.write('      Hash Algorithm:        {}\n'.format(self.hash_algorithm))
    o.write('      Partition Name:        {}\n'.format(self.partition_name))
    o.write('      Salt:                  {}\n'.format(str(self.salt).encode(
        'hex')))
    o.write('      Root Digest:           {}\n'.format(str(
        self.root_digest).encode('hex')))
    o.write('      Flags:                 {}\n'.format(self.flags))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    encoded_name = self.partition_name.encode('utf-8')
    num_bytes_following = (self.SIZE + len(encoded_name) + len(self.salt) +
                           len(self.root_digest) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.dm_verity_version, self.image_size,
                       self.tree_offset, self.tree_size, self.data_block_size,
                       self.hash_block_size, self.fec_num_roots,
                       self.fec_offset, self.fec_size, self.hash_algorithm,
                       len(encoded_name), len(self.salt), len(self.root_digest),
                       self.flags, self.RESERVED*'\0')
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + encoded_name + self.salt + self.root_digest + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    if not self.partition_name:
      image_filename = image_containing_descriptor.filename
      image = image_containing_descriptor
    else:
      image_filename = os.path.join(image_dir, self.partition_name + image_ext)
      image = ImageHandler(image_filename)
    # Generate the hashtree and checks that it matches what's in the file.
    digest_size = len(hashlib.new(name=self.hash_algorithm).digest())
    digest_padding = round_to_pow2(digest_size) - digest_size
    (hash_level_offsets, tree_size) = calc_hash_level_offsets(
        self.image_size, self.data_block_size, digest_size + digest_padding)
    root_digest, hash_tree = generate_hash_tree(image, self.image_size,
                                                self.data_block_size,
                                                self.hash_algorithm, self.salt,
                                                digest_padding,
                                                hash_level_offsets,
                                                tree_size)
    # The root digest must match unless it is not embedded in the descriptor.
    if self.root_digest and root_digest != self.root_digest:
      sys.stderr.write('hashtree of {} does not match descriptor\n'.
                       format(image_filename))
      return False
    # ... also check that the on-disk hashtree matches
    image.seek(self.tree_offset)
    hash_tree_ondisk = image.read(self.tree_size)
    is_zeroed = (self.tree_size == 0) or (hash_tree_ondisk[0:8] == 'ZeRoHaSH')
    if is_zeroed and accept_zeroed_hashtree:
      print('{}: skipping verification since hashtree is zeroed and '
            '--accept_zeroed_hashtree was given'
            .format(self.partition_name))
    else:
      if hash_tree != hash_tree_ondisk:
        sys.stderr.write('hashtree of {} contains invalid data\n'.
                         format(image_filename))
        return False
      print('{}: Successfully verified {} hashtree of {} for image of {} bytes'
            .format(self.partition_name, self.hash_algorithm, image.filename,
                    self.image_size))
    # TODO(zeuthen): we could also verify that the FEC stored in the image is
    # correct but this a) currently requires the 'fec' binary; and b) takes a
    # long time; and c) is not strictly needed for verification purposes as
    # we've already verified the root hash.
    return True


class AvbHashDescriptor(AvbDescriptor):
  """A class for hash descriptors.

  See the |AvbHashDescriptor| C struct for more information.

  Attributes:
    image_size: Image size, in bytes.
    hash_algorithm: Hash algorithm used.
    partition_name: Partition name.
    salt: Salt used.
    digest: The hash value of salt and data combined.
    flags: The descriptor flags (see avb_hash_descriptor.h).
  """

  TAG = 2
  RESERVED = 60
  SIZE = 72 + RESERVED
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'Q'  # image size (bytes)
                   '32s'  # hash algorithm used
                   'L'  # partition name (bytes)
                   'L'  # salt length (bytes)
                   'L'  # digest length (bytes)
                   'L' +  # flags
                   str(RESERVED) + 's')  # reserved

  def __init__(self, data=None):
    """Initializes a new hash descriptor.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    AvbDescriptor.__init__(self, None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.image_size, self.hash_algorithm,
       partition_name_len, salt_len,
       digest_len, self.flags, _) = struct.unpack(self.FORMAT_STRING,
                                                  data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + partition_name_len + salt_len + digest_len, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a hash ' 'descriptor.')
      # Nuke NUL-bytes at the end.
      self.hash_algorithm = self.hash_algorithm.split('\0', 1)[0]
      o = 0
      self.partition_name = str(data[(self.SIZE + o):(self.SIZE + o +
                                                      partition_name_len)])
      # Validate UTF-8 - decode() raises UnicodeDecodeError if not valid UTF-8.
      self.partition_name.decode('utf-8')
      o += partition_name_len
      self.salt = data[(self.SIZE + o):(self.SIZE + o + salt_len)]
      o += salt_len
      self.digest = data[(self.SIZE + o):(self.SIZE + o + digest_len)]
      if digest_len != len(hashlib.new(name=self.hash_algorithm).digest()):
        if digest_len != 0:
          raise LookupError('digest_len doesn\'t match hash algorithm')

    else:
      self.image_size = 0
      self.hash_algorithm = ''
      self.partition_name = ''
      self.salt = bytearray()
      self.digest = bytearray()
      self.flags = 0

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Hash descriptor:\n')
    o.write('      Image Size:            {} bytes\n'.format(self.image_size))
    o.write('      Hash Algorithm:        {}\n'.format(self.hash_algorithm))
    o.write('      Partition Name:        {}\n'.format(self.partition_name))
    o.write('      Salt:                  {}\n'.format(str(self.salt).encode(
        'hex')))
    o.write('      Digest:                {}\n'.format(str(self.digest).encode(
        'hex')))
    o.write('      Flags:                 {}\n'.format(self.flags))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    encoded_name = self.partition_name.encode('utf-8')
    num_bytes_following = (
        self.SIZE + len(encoded_name) + len(self.salt) + len(self.digest) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.image_size, self.hash_algorithm, len(encoded_name),
                       len(self.salt), len(self.digest), self.flags,
                       self.RESERVED*'\0')
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + encoded_name + self.salt + self.digest + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    if not self.partition_name:
      image_filename = image_containing_descriptor.filename
      image = image_containing_descriptor
    else:
      image_filename = os.path.join(image_dir, self.partition_name + image_ext)
      image = ImageHandler(image_filename)
    data = image.read(self.image_size)
    ha = hashlib.new(self.hash_algorithm)
    ha.update(self.salt)
    ha.update(data)
    digest = ha.digest()
    # The digest must match unless there is no digest in the descriptor.
    if self.digest and digest != self.digest:
      sys.stderr.write('{} digest of {} does not match digest in descriptor\n'.
                       format(self.hash_algorithm, image_filename))
      return False
    print('{}: Successfully verified {} hash of {} for image of {} bytes'
          .format(self.partition_name, self.hash_algorithm, image.filename,
                  self.image_size))
    return True


class AvbKernelCmdlineDescriptor(AvbDescriptor):
  """A class for kernel command-line descriptors.

  See the |AvbKernelCmdlineDescriptor| C struct for more information.

  Attributes:
    flags: Flags.
    kernel_cmdline: The kernel command-line.
  """

  TAG = 3
  SIZE = 24
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'L'  # flags
                   'L')  # cmdline length (bytes)

  FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED = (1 << 0)
  FLAGS_USE_ONLY_IF_HASHTREE_DISABLED = (1 << 1)

  def __init__(self, data=None):
    """Initializes a new kernel cmdline descriptor.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    AvbDescriptor.__init__(self, None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.flags, kernel_cmdline_length) = (
          struct.unpack(self.FORMAT_STRING, data[0:self.SIZE]))
      expected_size = round_to_multiple(self.SIZE - 16 + kernel_cmdline_length,
                                        8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a kernel cmdline '
                          'descriptor.')
      # Nuke NUL-bytes at the end.
      self.kernel_cmdline = str(data[self.SIZE:(self.SIZE +
                                                kernel_cmdline_length)])
      # Validate UTF-8 - decode() raises UnicodeDecodeError if not valid UTF-8.
      self.kernel_cmdline.decode('utf-8')
    else:
      self.flags = 0
      self.kernel_cmdline = ''

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Kernel Cmdline descriptor:\n')
    o.write('      Flags:                 {}\n'.format(self.flags))
    o.write('      Kernel Cmdline:        {}\n'.format(repr(
        self.kernel_cmdline)))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    encoded_str = self.kernel_cmdline.encode('utf-8')
    num_bytes_following = (self.SIZE + len(encoded_str) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.flags, len(encoded_str))
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + encoded_str + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    # Nothing to verify.
    return True


class AvbChainPartitionDescriptor(AvbDescriptor):
  """A class for chained partition descriptors.

  See the |AvbChainPartitionDescriptor| C struct for more information.

  Attributes:
    rollback_index_location: The rollback index location to use.
    partition_name: Partition name.
    public_key: Bytes for the public key.
  """

  TAG = 4
  RESERVED = 64
  SIZE = 28 + RESERVED
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'L'  # rollback_index_location
                   'L'  # partition_name_size (bytes)
                   'L' +  # public_key_size (bytes)
                   str(RESERVED) + 's')  # reserved

  def __init__(self, data=None):
    """Initializes a new chain partition descriptor.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    AvbDescriptor.__init__(self, None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.rollback_index_location,
       partition_name_len,
       public_key_len, _) = struct.unpack(self.FORMAT_STRING, data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + partition_name_len + public_key_len, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a chain partition '
                          'descriptor.')
      o = 0
      self.partition_name = str(data[(self.SIZE + o):(self.SIZE + o +
                                                      partition_name_len)])
      # Validate UTF-8 - decode() raises UnicodeDecodeError if not valid UTF-8.
      self.partition_name.decode('utf-8')
      o += partition_name_len
      self.public_key = data[(self.SIZE + o):(self.SIZE + o + public_key_len)]

    else:
      self.rollback_index_location = 0
      self.partition_name = ''
      self.public_key = bytearray()

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Chain Partition descriptor:\n')
    o.write('      Partition Name:          {}\n'.format(self.partition_name))
    o.write('      Rollback Index Location: {}\n'.format(
        self.rollback_index_location))
    # Just show the SHA1 of the key, for size reasons.
    hexdig = hashlib.sha1(self.public_key).hexdigest()
    o.write('      Public key (sha1):       {}\n'.format(hexdig))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    encoded_name = self.partition_name.encode('utf-8')
    num_bytes_following = (
        self.SIZE + len(encoded_name) + len(self.public_key) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.rollback_index_location, len(encoded_name),
                       len(self.public_key), self.RESERVED*'\0')
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + encoded_name + self.public_key + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    value = expected_chain_partitions_map.get(self.partition_name)
    if not value:
      sys.stderr.write('No expected chain partition for partition {}. Use '
                       '--expected_chain_partition to specify expected '
                       'contents or --follow_chain_partitions.\n'.
                       format(self.partition_name))
      return False
    rollback_index_location, pk_blob = value

    if self.rollback_index_location != rollback_index_location:
      sys.stderr.write('Expected rollback_index_location {} does not '
                       'match {} in descriptor for partition {}\n'.
                       format(rollback_index_location,
                              self.rollback_index_location,
                              self.partition_name))
      return False

    if self.public_key != pk_blob:
      sys.stderr.write('Expected public key blob does not match public '
                       'key blob in descriptor for partition {}\n'.
                       format(self.partition_name))
      return False

    print('{}: Successfully verified chain partition descriptor matches '
          'expected data'.format(self.partition_name))

    return True

DESCRIPTOR_CLASSES = [
    AvbPropertyDescriptor, AvbHashtreeDescriptor, AvbHashDescriptor,
    AvbKernelCmdlineDescriptor, AvbChainPartitionDescriptor
]


def parse_descriptors(data):
  """Parses a blob of data into descriptors.

  Arguments:
    data: A bytearray() with encoded descriptors.

  Returns:
    A list of instances of objects derived from AvbDescriptor. For
    unknown descriptors, the class AvbDescriptor is used.
  """
  o = 0
  ret = []
  while o < len(data):
    tag, nb_following = struct.unpack('!2Q', data[o:o + 16])
    if tag < len(DESCRIPTOR_CLASSES):
      c = DESCRIPTOR_CLASSES[tag]
    else:
      c = AvbDescriptor
    ret.append(c(bytearray(data[o:o + 16 + nb_following])))
    o += 16 + nb_following
  return ret


class AvbFooter(object):
  """A class for parsing and writing footers.

  Footers are stored at the end of partitions and point to where the
  AvbVBMeta blob is located. They also contain the original size of
  the image before AVB information was added.

  Attributes:
    magic: Magic for identifying the footer, see |MAGIC|.
    version_major: The major version of avbtool that wrote the footer.
    version_minor: The minor version of avbtool that wrote the footer.
    original_image_size: Original image size.
    vbmeta_offset: Offset of where the AvbVBMeta blob is stored.
    vbmeta_size: Size of the AvbVBMeta blob.
  """

  MAGIC = 'AVBf'
  SIZE = 64
  RESERVED = 28
  FOOTER_VERSION_MAJOR = AVB_FOOTER_VERSION_MAJOR
  FOOTER_VERSION_MINOR = AVB_FOOTER_VERSION_MINOR
  FORMAT_STRING = ('!4s2L'  # magic, 2 x version.
                   'Q'  # Original image size.
                   'Q'  # Offset of VBMeta blob.
                   'Q' +  # Size of VBMeta blob.
                   str(RESERVED) + 'x')  # padding for reserved bytes

  def __init__(self, data=None):
    """Initializes a new footer object.

    Arguments:
      data: If not None, must be a bytearray of size 4096.

    Raises:
      LookupError: If the given footer is malformed.
      struct.error: If the given data has no footer.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.magic, self.version_major, self.version_minor,
       self.original_image_size, self.vbmeta_offset,
       self.vbmeta_size) = struct.unpack(self.FORMAT_STRING, data)
      if self.magic != self.MAGIC:
        raise LookupError('Given data does not look like a AVB footer.')
    else:
      self.magic = self.MAGIC
      self.version_major = self.FOOTER_VERSION_MAJOR
      self.version_minor = self.FOOTER_VERSION_MINOR
      self.original_image_size = 0
      self.vbmeta_offset = 0
      self.vbmeta_size = 0

  def encode(self):
    """Gets a string representing the binary encoding of the footer.

    Returns:
      A bytearray() with a binary representation of the footer.
    """
    return struct.pack(self.FORMAT_STRING, self.magic, self.version_major,
                       self.version_minor, self.original_image_size,
                       self.vbmeta_offset, self.vbmeta_size)


# Android Firmware Transparency Log Data Structures


class AvbIcpHeader(object):
  """A class for the transparency log inclusion proof header.

  Attributes:
    magic: Magic for identifying the ICP header.
    required_icp_version_major: The major version of AVB that wrote the entry.
    required_icp_version_minor: The minor version of AVB that wrote the entry.
    algorithm: Hash algorithm used. ID is defined in ALGORITHMS.
    icp_count: Number of inclusion proofs represented in this structure.
  """

  SIZE = 18  # The size of the structure, in bytes
  MAGIC = 'AFTL'
  FORMAT_STRING = ('!4s2L'  # magic, major & minor version
                   'L'      # algorithm type for transparency log
                   'H')     # number of inclusion proof entries

  def __init__(self, data=None):
    """Initializes a new transparency header object.

    Arguments:
      data: If not None, must be a bytearray of size == 18.

    Raises:
      AvbError: If invalid structure for AvbIcpHeader.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.magic, self.required_icp_version_major,
       self.required_icp_version_minor, self.algorithm,
       self.icp_count) = struct.unpack(self.FORMAT_STRING, data)
    else:
      self.magic = self.MAGIC
      self.required_icp_version_major = AVB_VERSION_MAJOR
      self.required_icp_version_minor = AVB_VERSION_MINOR
      self.algorithm = 0
      self.icp_count = 0
    if not self.is_valid():
      raise AvbError('Invalid structure for AvbIcpHeader')

  def save(self, output):
    """Serializes the transparency header (18) to disk.

    Arguments:
      output: The object to write the header to.

    Raises:
      AvbError if invalid structure for AvbIcpHeader.
    """
    output.write(self.encode())

  def encode(self):
    """Serializes the header (18) to a bytearray().

    Returns:
      A bytearray() with the encoded header.

    Raises:
      AvbError: If invalid structure for AvbIcpHeader.
    """
    if not self.is_valid():
      raise AvbError('Invalid structure for AvbIcpHeader')
    return struct.pack(self.FORMAT_STRING, self.magic,
                       self.required_icp_version_major,
                       self.required_icp_version_minor,
                       self.algorithm, self.icp_count)

  def is_valid(self):
    """Ensures that values in an AvbIcpHeader structure are sane.

    Returns:
      True if the values in the AvbIcpHeader are sane, False otherwise.
    """
    if self.magic != AvbIcpHeader.MAGIC:
      sys.stderr.write(
          'ICP Header: magic value mismatch: {}\n'.format(self.magic))
      return False

    if self.required_icp_version_major > AVB_VERSION_MAJOR:
      sys.stderr.write('ICP header: major version mismatch: {}\n'.format(
          self.required_icp_version_major))
      return False

    if self.required_icp_version_minor > AVB_VERSION_MINOR:
      sys.stderr.write('ICP header: minor version mismatch: {}\n'.format(
          self.required_icp_version_minor))
      return False

    if self.algorithm < 0 or self.algorithm >= len(ALGORITHMS):
      sys.stderr.write(
          'ICP header: algorithm identifier out of range: {}\n'.format(
              self.algorithm))
      return False

    if self.icp_count < 0:
      sys.stderr.write(
          'ICP header: ICP entry count out of range: {}\n'.format(
              self.icp_count))
      return False
    return True

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Major version:      {}\n'.format(
        self.required_icp_version_major))
    o.write('    Minor version:      {}\n'.format(
        self.required_icp_version_minor))
    o.write('    Algorithm:          {}\n'.format(
        lookup_algorithm_by_type(self.algorithm)[0]))
    o.write('    ICP entries count:  {}\n'.format(
        self.icp_count))


def check_signature(log_root, log_root_sig,
                    transparency_log_pub_key):
  """Validates the signature provided by the transparency log.

  Arguments:
    log_root: The transparency log_root data structure.
    log_root_sig: The signature of the transparency log_root data structure.
    transparency_log_pub_key: The trusted public key of the transparency log.

  Returns:
    True if the signature check passes, otherwise False.
  """

  logsig_tmp = tempfile.NamedTemporaryFile()
  logsig_tmp.write(log_root_sig)
  logsig_tmp.flush()
  logroot_tmp = tempfile.NamedTemporaryFile()
  logroot_tmp.write(log_root)
  logroot_tmp.flush()

  p = subprocess.Popen(['openssl', 'dgst', '-sha256', '-verify',
                        transparency_log_pub_key,
                        '-signature', logsig_tmp.name, logroot_tmp.name],
                       stdin=subprocess.PIPE,
                       stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE)

  (_, openssl_err) = p.communicate()
  retcode = p.wait()
  if not retcode:
    return True
  sys.stderr.write('openssl status {}'.format(openssl_err))
  return False


class AvbIcpSignedRootBlob(object):
  """A class for the components required to validate the incusion proof.

  This class contains the signed tree root components required to verify
  an inclusion proof given a list of hashes.

  Attributes:
    leaf_hash: The hash of the leaf corresponding with this log entry.
    tree_size: The size of the Merkle tree.
    log_root: The transparency log_root data structure.
    root_hash: The calculated root hash of the Merkle tree.
    log_root_sig: The signed root hash. Used to verify the ICP.
  """
  # TODO(danielaustin): Match hash and signature size to algorithm value.
  SIZE = 645
  FORMAT_STRING = ('!32s'   # The leaf hash corresponding to this vbmeta.
                   'Q'      # The Merkle tree size
                   '61s'    # The log_root structure that is signed
                   '32s'    # The Merkle tree root hash.
                   '512s')  # The log_root signed with the transparency log key.

  def __init__(self, data=None):
    """Initializes a new signed_root_blob structure.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      AvbError: If data does not represent a well-formed AvbIcpSignedRootBlob.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.leaf_hash, self.tree_size, self.log_root,
       self.root_hash, self.log_root_sig) = struct.unpack(
           self.FORMAT_STRING, data)
    else:
      self.leaf_hash = bytearray()
      self.tree_size = 0
      self.log_root = bytearray()
      self.root_hash = bytearray()
      self.log_root_sig = ''

    if not self.is_valid():
      raise AvbError('Invalid structure for AvbIcpSignedBlob')

  def translate_afi_response(self, afi_response):
    """Translates an AddFirmwareImageResponse message to AvbIcpSignedRootBlob.

    Arguments:
      afi_response: An AddFirmwareImageResponse proto message.

    Raises:
      AvbError: If unsupported hash size is detected.
    """
    # Do the hash calculation
    self.leaf_hash = rfc6962_hash_leaf(afi_response.vbmeta_leaf)
    self.log_root = afi_response.vbmeta_proof.sth.log_root
    self.log_root_sig = str(afi_response.vbmeta_proof.sth.log_root_signature)
    # Partial format string to extract the tree_size and root_hash from
    # the log_root. THis structure is defined:
    # https://github.com/google/trillian/blob/master/trillian.proto#L255

    # TODO(danielaustin): Make this into a class.
    partial_log_format_string = ('!H'    # Version
                                 'Q'     # tree_size
                                 'B'     # hash_size, verify this is 32 for now
                                 '32s')  # The root_hash

    (log_root_version, self.tree_size, root_hash_size,
     self.root_hash) = struct.unpack(partial_log_format_string,
                                     self.log_root[0:43])
    if log_root_version != 1:
      raise AvbError('Unsupported log root version: {}'.format(
          log_root_version))
    if len(self.root_hash) != root_hash_size:
      raise AvbError('Unsupported hash size.')

  def encode(self):
    """Serializes the AvbSignedRootBlob structure (584) to a bytearray.

    Returns:
      A bytearray with the AvbSignedRootBlob.

    Raises:
      AvbError: If data does not represent a well-formed AvbIcpSignedRootBlob.
    """
    if not self.is_valid():
      raise AvbError('Invalid structure for AvbIcpSignedRootBlob')

    return struct.pack(self.FORMAT_STRING,
                       str(self.leaf_hash),
                       self.tree_size,
                       str(self.log_root),
                       str(self.root_hash),
                       str(self.log_root_sig))

  def is_valid(self):
    """Ensures that values in the AvbIcpSignedRootBlob are sane.

    Returns:
      True if the values in the AvbIcpSignedRootBlob are sane, False otherwise.
    """
    # TODO(danielaustin): match these up with algorithm instead of defaults.
    # All structures being of size 0 is valid
    if (not self.leaf_hash and self.tree_size == 0 and
        not self.root_hash and not self.log_root_sig):
      return True
    if len(self.leaf_hash) != 32:
      sys.stderr.write('AvbIcpSignedRootBlob: Bad leaf_hash size {}'.format(
          len(self.leaf_hash)))
      return False
    if self.tree_size < 0:
      sys.stderr.write('AvbIcpSignedRootBlob: Bad tree_size value {}'.format(
          self.tree_size))
      return False
    if len(self.root_hash) != 32:
      sys.stderr.write('AvbIcpSignedRootBlob: Bad root_hash size {}'.format(
          len(self.root_hash)))
      return False
    if len(self.log_root_sig) != 512:
      sys.stderr.write('AvbIcpSignedRootBlob: Bad log_root_sig size {}'.format(
          len(self.log_root_sig)))
      return False
    return True

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('      Leaf hash:        {}\n'.format(
        binascii.hexlify(self.leaf_hash)))
    o.write('      Tree size:        {}\n'.format(
        self.tree_size))
    o.write('      Log root:         {}\n'.format(
        binascii.hexlify(self.log_root)))
    o.write('      Root hash:        {}\n'.format(
        binascii.hexlify(self.root_hash)))


class AvbIcpEntry(object):
  """A class for the transparency log inclusion proof entries.

  The data that represents each of the components of the ICP entry are stored
  immediately following the ICP entry header. The format is log_url,
  SignedLogRoot, and inclusion proof hashes.

  Attributes:
    log_url_size: Length of the string representing the transparency log URL.
    leaf_index: Leaf index in the transparency log representing this entry.
    signed_root_blob_size: Size of the SignedLogRoot for the transparency log;
        treat as an opaque blob for now.
    proof_hash_count: Number of hashes comprising the inclusion proof.
    proof_size: The total size of the inclusion proof, in bytes.
    next_entry: 1 if there is a next entry, 0 otherwise.
    log_url: The URL for the transparency log that generated this inclusion
        proof.
    signed_root_blob: The data comprising the signed tree head structure.
    proofs: The hashes comprising the inclusion proof.

  """
  SIZE = 22  # The size of the structure, in bytes
  FORMAT_STRING = ('!L'   # transparency log server url size
                   'Q'    # leaf index
                   'L'    # signed tree root blob size
                   'B'    # number of hashes in the inclusion proof
                   'L'    # size of the inclusion proof in bytes
                   'B')   # next entry marker
  # These are used to capture the log_url, signed_root_blob,
  # and the proofs elements for the encode & save function.

  def __init__(self, data=None):
    """Initializes a new ICP entry object.

    Arguments:
      data: If not None, must be a bytearray of size >= 22.

    Raises:
      AvbError: If data does not represent a well-formed AvbIcpEntry.
    """
    # Assert the header structure is of a sane size.
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      # Deserialize the header from the data blob.
      (self.log_url_size, self.leaf_index, self.signed_root_blob_size,
       self.proof_hash_count, self.proof_size, self.next_entry) = struct.unpack(
           self.FORMAT_STRING, data[0:self.SIZE])
      if len(data) >= self.SIZE:
        # There's more data. Ensure the data entry size is valid.
        if len(data) != self.get_expected_size():
          if self.next_entry == 0:
            raise AvbError('ICP entry size is not valid {}/{}.'
                           .format(len(data), self.get_expected_size()))
      # Deserialize ICP entry components from the data blob.
      expected_format_string = '{}s{}s{}s'.format(
          self.log_url_size,
          AvbIcpSignedRootBlob.SIZE,
          self.proof_size)

      (self.log_url, signed_root_blob_bytes, proof_bytes) = struct.unpack(
          expected_format_string, data[self.SIZE:self.get_expected_size()])
      self.signed_root_blob = AvbIcpSignedRootBlob(signed_root_blob_bytes)
      self.proofs = []
      if self.proof_hash_count > 0:
        proof_idx = 0
        hash_size = self.proof_size // self.proof_hash_count
        for _ in range(self.proof_hash_count):
          proof = proof_bytes[proof_idx:(proof_idx+hash_size)]
          self.proofs.append(proof)
          proof_idx += hash_size
    else:
      self.log_url_size = 0
      self.leaf_index = 0
      self.signed_root_blob_size = 0
      self.proof_hash_count = 0
      self.proof_size = 0
      self.next_entry = 0
      self.log_url = ''
      self.signed_root_blob = AvbIcpSignedRootBlob()
      self.proofs = []
    if not self.is_valid():
      raise AvbError('Invalid structure for AvbIcpEntry')

  def set_log_url(self, log_url):
    """Sets the log_url and log_url_size elements in the AvbIcpEntry.

    Arguments:
      log_url: The string representing the transparency log URL.
    """
    self.log_url = log_url
    self.log_url_size = len(log_url)

  def set_signed_root_blob(self, signed_root_blob):
    """Sets signed_root_blob and signed_root_blob_size.

    Arguments:
      signed_root_blob: An AvbIcpSignedRootBlob containing the SignedLogRoot
          for the transparency log.
    """
    self.signed_root_blob = signed_root_blob
    self.signed_root_blob_size = signed_root_blob.SIZE

  def set_proofs(self, proofs):
    """Sets the proof_hash_count, proofs, and proof_size.

    Arguments:
      proofs: A bytearray of concatenated hashes comprising the inclusion proof.
    """
    self.proof_hash_count = 0
    self.proofs = proofs
    proof_size = 0
    for proof in proofs:
      proof_size += len(proof)
      self.proof_hash_count += 1
    self.proof_size = proof_size

  def verify_icp(self, transparency_log_pub_key):
    """Verifies the contained inclusion proof given the public log key.

    Arguments:
      transparency_log_pub_key: The trusted public key for the log.

    Returns:
      True if the calculated signature matches AvbIcpEntry's. False otherwise.
    """
    calc_root = root_from_icp(self.leaf_index, self.signed_root_blob.tree_size,
                              self.proofs, self.signed_root_blob.leaf_hash)
    if (calc_root == self.signed_root_blob.root_hash) and check_signature(
        self.signed_root_blob.log_root, self.signed_root_blob.log_root_sig,
        transparency_log_pub_key):
      return True
    return False

  def save(self, output):
    """Serializes the transparency header (22) and data to disk.

    Arguments:
      output: The object to write the header to.

    Raises:
      AvbError: If invalid entry structure.
    """
    output.write(self.encode())

  def encode(self):
    """Serializes the header (22) and data to a bytearray().

    Returns:
      A bytearray() with the encoded header.

    Raises:
      AvbError: If invalid entry structure.
    """
    proof_bytes = bytearray()
    if not self.is_valid():
      raise AvbError('Invalid AvbIcpEntry structure')
    expected_format_string = '{}{}s{}s{}s'.format(
        self.FORMAT_STRING, self.log_url_size,
        self.signed_root_blob.SIZE,
        self.proof_size)

    for proof in self.proofs:
      proof_bytes.extend(proof)

    return struct.pack(expected_format_string,
                       self.log_url_size, self.leaf_index,
                       self.signed_root_blob_size, self.proof_hash_count,
                       self.proof_size, self.next_entry, self.log_url,
                       self.signed_root_blob.encode(),
                       str(proof_bytes))

  # TODO(danielaustin): Add unit test.
  def translate_response(self, transparency_log, afi_response):
    """Takes an AddFirmwareInfoResponse object and translates to an AvbIcpEntry.

    Arguments:
      transparency_log: String representing the transparency log URL.
      afi_response: The AddFirmwareResponse object to translate.
    """
    self.set_log_url(transparency_log)
    self.leaf_index = afi_response.vbmeta_proof.proof.leaf_index
    self.signed_root_blob = AvbIcpSignedRootBlob()
    self.signed_root_blob.translate_afi_response(afi_response)
    self.signed_root_blob_size = self.signed_root_blob.SIZE
    # Calculate the number of hashes.
    proof_hashes = afi_response.vbmeta_proof.proof.hashes
    self.set_proofs(proof_hashes)

  def get_expected_size(self):
    """Gets the expected size of the full entry out of the header.

    Returns:
      The expected size of the AvbIcpEntry from the header.
    """
    return (self.SIZE + self.log_url_size +
            self.signed_root_blob_size + self.proof_size)

  def is_valid(self):
    """Ensures that values in an AvbIcpEntry structure are sane.

    Returns:
      True if the values in the AvbIcpEntry are sane, False otherwise.
    """
    if ((self.log_url and self.log_url_size != len(self.log_url))
        or (not self.log_url and self.log_url_size != 0)):
      sys.stderr.write('ICP entry: invalid URL size: {}\n'
                       .format(self.log_url_size))
      return False

    if self.leaf_index < 0:
      sys.stderr.write('ICP entry: leaf index out of range: '
                       '{}\n'.format(self.leaf_index))
      return False

    if not self.signed_root_blob or not self.signed_root_blob.is_valid():
      sys.stderr.write('ICP entry: invalid AvbIcpSignedRootBlob\n')
      return False

    if (self.signed_root_blob_size != 0) and (
        self.signed_root_blob_size != self.signed_root_blob.SIZE):
      sys.stderr.write('ICP entry: invalid signed root blob size: '
                       '{}, should be {}\n'.format(
                           self.signed_root_blob_size,
                           self.signed_root_blob.SIZE))
      return False

    if self.proof_hash_count < 0:
      sys.stderr.write('ICP entry: invalid proof count: {}\n'.format(
          self.proof_hash_count))
      return False

    proof_size = 0
    if self.proofs:
      for proof in self.proofs:
        proof_size += len(proof)
      if self.proof_size != proof_size:
        sys.stderr.write('ICP entry: invalid transparency log proof size: ')
        sys.stderr.write('{}, calculated {}\n'.format(self.proof_size,
                                                      proof_size))
        return False
    elif self.proof_size != 0:
      sys.stderr.write('ICP entry: invalid transparency log proof size '
                       '(should be 0): {}'.format(self.proof_size))
      return False
    if self.next_entry != 0 and self.next_entry != 1:
      sys.stderr.write('ICP entry: invalid next entry value: {}\n'.format(
          self.next_entry))
      return False
    return True

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Transparency Log:   {}\n'.format(self.log_url))
    o.write('    Leaf index:         {}\n'.format(self.leaf_index))
    o.write('    Next entry:         {}\n'.format(self.next_entry))
    o.write('    ICP hashes:         ')
    for i, proof_hash in enumerate(self.proofs):
      if i != 0:
        o.write(' ' * 24)
      o.write('{}\n'.format(binascii.hexlify(proof_hash)))


class AvbIcpBlob(object):
  """A class for the transparency log inclusion proof blob.

  This encapsulates an AFTL ICP section with all information required to
  validate an inclusion proof.

  Attributes:
    icp_header: A header for the section.
    icp_entries: A list of AvbIcpEntry objects representing the inclusion
        proofs.
  """

  def __init__(self, data=None):
    """Initializes a new AvbIcpBlob section.

    Arguments:
      data: If not None, must be a bytearray representing an AvbIcpBlob.

    Raises:
      AvbError: If the data does not represent a well-formed AvbIcpBlob.
    """
    if data:
      icp_header_bytes = data[0:AvbIcpHeader.SIZE]
      self.icp_header = AvbIcpHeader(icp_header_bytes)
      if not self.icp_header.is_valid():
        raise AvbError('Invalid ICP header.')
      icp_count = self.icp_header.icp_count
      algorithm_id = self.icp_header.algorithm
      # TODO(danielaustin): make use of proof_hash_size.
      # pylint: disable=unused-variable
      proof_hash_size = lookup_hash_size_by_type(algorithm_id)

      # Jump past the header for entry deserialization.
      icp_index = AvbIcpHeader.SIZE
      # Validate each entry.
      self.icp_entries = []
      # Add_icp_entry updates entries and header, so set header count to
      # compensate.
      self.icp_header.icp_count = 0
      for i in range(icp_count):
        # Get the entry header from the ICP blob.
        cur_icp_entry = AvbIcpEntry(data[icp_index:])
        cur_icp_entry_size = cur_icp_entry.get_expected_size()
        # Now validate the entry structure.
        if not cur_icp_entry.is_valid():
          raise AvbError('Validation of ICP entry failed.')
        self.add_icp_entry(cur_icp_entry)
        # Check if there is a next entry.
        if cur_icp_entry.next_entry == 0:
          if i != icp_count - 1:
            raise AvbError('ICP entry count mismatch')
          break
        icp_index += cur_icp_entry_size
    else:
      self.icp_header = AvbIcpHeader()
      self.icp_entries = []
    if not self.is_valid():
      raise AvbError('Malformed ICP blob')

  def set_algorithm(self, algorithm_id):
    """Sets algorithm to be used by the inclusion proofs in AvbIcpBlob."""
    self.icp_header.algorithm = algorithm_id

  def add_icp_entry(self, avb_icp_entry):
    """Adds a new AvbIcpEntry to the AvbIcpBlob, updating fields as necessary.

    Arguments:
      avb_icp_entry: An AvbIcpEntry structure.
    """

    # Set the next entry field to denote that a new ICP entry will follow.
    if self.icp_entries:
      self.icp_entries[-1].next_entry = 1
    self.icp_entries.append(avb_icp_entry)
    self.icp_header.icp_count += 1

  def save(self, output):
    """Serializes the AvbIcpBlob to disk.

    Arguments:
      output: The object to write the blob to.

    Raises:
      AvbError: If invalid blob structure.
    """
    output.write(self.encode())

  def encode(self):
    """Serialize the AvbIcpBlob to a bytearray().

    Returns:
      A bytearray() with the encoded header.

    Raises:
      AvbError: If invalid blob structure.
    """
    # The header and entries are guaranteed to be valid when encode is called.
    # Check the entire structure as a whole.
    if not self.is_valid():
      raise AvbError('Invalid AvbIcpBlob structure.')

    icp_blob = bytearray()
    icp_blob.extend(self.icp_header.encode())
    for icp_entry in self.icp_entries:
      icp_blob.extend(icp_entry.encode())
    return icp_blob

  def is_valid(self):
    """Ensures that values in the AvbIcpBlob are sane.

    Returns:
      True if the values in the AvbIcpBlob are sane, False otherwise.
    """
    if not self.icp_header.is_valid():
      return False

    if self.icp_header.icp_count != len(self.icp_entries):
      return False

    for icp_entry in self.icp_entries:
      if not icp_entry.is_valid():
        return False
    return True


# AFTL Merkle Tree Functionality
# TODO(danielaustin): Encapsulate this behavior in a class.
def rfc6962_hash_leaf(leaf):
  """RFC6962 hashing function for hashing leaves of a Merkle tree.

  Arguments:
    leaf: A bytearray containing the Merkle tree leaf to be hashed.

  Returns:
    A bytearray containing the RFC6962 SHA256 hash of the leaf.
  """
  hasher = hashlib.sha256()
  # RFC6962 states a '0' byte should be prepended to the data.
  # This is done in conjunction with the '1' byte for non-leaf
  # nodes for 2nd preimage attack resistance.
  hasher.update(b'\x00')
  hasher.update(leaf)
  return hasher.digest()


def rfc6962_hash_children(l, r):
  """Calculates the inner Merkle tree node hash of child nodes l and r.

  Arguments:
    l: A bytearray containing the left child node to be hashed.
    r: A bytearray containing the right child node to be hashed.

  Returns:
    A bytearray containing the RFC6962 SHA256 hash of 1|l|r.
  """
  hasher = hashlib.sha256()
  # RFC6962 states a '1' byte should be prepended to the concatenated data.
  # This is done in conjunction with the '0' byte for leaf
  # nodes for 2nd preimage attack resistance.
  hasher.update(b'\x01')
  hasher.update(l)
  hasher.update(r)
  return hasher.digest()


def chain_border_right(seed, proof):
  """Computes a subtree hash along the left-side tree border.

  Arguments:
    seed: A bytearray containing the starting hash.
    proof: A list of bytearrays representing the hashes in the inclusion proof.

  Returns:
    A bytearray containing the left-side subtree hash.
  """
  for h in proof:
    seed = rfc6962_hash_children(h, seed)
  return seed


def chain_inner(seed, proof, leaf_index):
  """Computes a subtree hash on or below the tree's right border.

  Arguments:
    seed: A bytearray containing the starting hash.
    proof: A list of bytearrays representing the hashes in the inclusion proof.
    leaf_index: The current leaf index.

  Returns:
    A bytearray containing the subtree hash.
  """
  for i, h in enumerate(proof):
    if leaf_index >> i & 1 == 0:
      seed = rfc6962_hash_children(seed, h)
    else:
      seed = rfc6962_hash_children(h, seed)
  return seed


def root_from_icp(leaf_index, tree_size, proof, leaf_hash):
  """Calculates the expected Merkle tree root hash.

  Arguments:
    leaf_index: The current leaf index.
    tree_size: The number of nodes in the Merkle tree.
    proof: A list of bytearrays containing the inclusion proof.
    leaf_hash: A bytearray containing the initial leaf hash.

  Returns:
    A bytearray containing the calculated Merkle tree root hash.

  Raises:
    AvbError: If invalid parameters are passed in.
  """
  if leaf_index < 0:
    raise AvbError('Invalid leaf_index value: {}'.format(leaf_index))
  if tree_size < 0:
    raise AvbError('Invalid tree_size value: {}'.format(tree_size))
  if leaf_index >= tree_size:
    err_str = 'leaf_index cannot be equal or larger than tree_size: {}, {}'
    raise AvbError(err_str.format(leaf_index, tree_size))

  # Calculate the point to split the proof into two parts.
  # The split is where the paths to leaves diverge.
  inner = (leaf_index ^ (tree_size - 1)).bit_length()
  result = chain_inner(leaf_hash, proof[:inner], leaf_index)
  result = chain_border_right(result, proof[inner:])
  return result


class AvbVBMetaHeader(object):
  """A class for parsing and writing AVB vbmeta images.

  The attributes correspond to the |AvbVBMetaImageHeader| struct defined in
  avb_vbmeta_image.h.

  Attributes:
    magic: Four bytes equal to "AVB0" (AVB_MAGIC).
    required_libavb_version_major: The major version of libavb required for this
        header.
    required_libavb_version_minor: The minor version of libavb required for this
        header.
    authentication_data_block_size: The size of the signature block.
    auxiliary_data_block_size: The size of the auxiliary data block.
    algorithm_type: The verification algorithm used, see |AvbAlgorithmType|
        enum.
    hash_offset: Offset into the "Authentication data" block of hash data.
    hash_size: Length of the hash data.
    signature_offset: Offset into the "Authentication data" block of signature
        data.
    signature_size: Length of the signature data.
    public_key_offset: Offset into the "Auxiliary data" block of public key
        data.
    public_key_size: Length of the public key data.
    public_key_metadata_offset: Offset into the "Auxiliary data" block of public
        key metadata.
    public_key_metadata_size: Length of the public key metadata. Must be set to
        zero if there is no public key metadata.
    descriptors_offset: Offset into the "Auxiliary data" block of descriptor
        data.
    descriptors_size: Length of descriptor data.
    rollback_index: The rollback index which can be used to prevent rollback to
        older versions.
    flags: Flags from the AvbVBMetaImageFlags enumeration. This must be set to
        zero if the vbmeta image is not a top-level image.
    release_string: The release string from avbtool, e.g. "avbtool 1.0.0" or
        "avbtool 1.0.0 xyz_board Git-234abde89". Is guaranteed to be NUL
        terminated. Applications must not make assumptions about how this
        string is formatted.
  """

  SIZE = 256

  # Keep in sync with |reserved0| and |reserved| field of
  # |AvbVBMetaImageHeader|.
  RESERVED0 = 4
  RESERVED = 80

  # Keep in sync with |AvbVBMetaImageHeader|.
  FORMAT_STRING = ('!4s2L'  # magic, 2 x version
                   '2Q'  # 2 x block size
                   'L'  # algorithm type
                   '2Q'  # offset, size (hash)
                   '2Q'  # offset, size (signature)
                   '2Q'  # offset, size (public key)
                   '2Q'  # offset, size (public key metadata)
                   '2Q'  # offset, size (descriptors)
                   'Q'  # rollback_index
                   'L' +  # flags
                   str(RESERVED0) + 'x' +  # padding for reserved bytes
                   '47sx' +  # NUL-terminated release string
                   str(RESERVED) + 'x')  # padding for reserved bytes

  def __init__(self, data=None):
    """Initializes a new header object.

    Arguments:
      data: If not None, must be a bytearray of size 8192.

    Raises:
      Exception: If the given data is malformed.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.magic, self.required_libavb_version_major,
       self.required_libavb_version_minor,
       self.authentication_data_block_size, self.auxiliary_data_block_size,
       self.algorithm_type, self.hash_offset, self.hash_size,
       self.signature_offset, self.signature_size, self.public_key_offset,
       self.public_key_size, self.public_key_metadata_offset,
       self.public_key_metadata_size, self.descriptors_offset,
       self.descriptors_size,
       self.rollback_index,
       self.flags,
       self.release_string) = struct.unpack(self.FORMAT_STRING, data)
      # Nuke NUL-bytes at the end of the string.
      if self.magic != 'AVB0':
        raise AvbError('Given image does not look like a vbmeta image.')
    else:
      self.magic = 'AVB0'
      # Start by just requiring version 1.0. Code that adds features
      # in a future version can use bump_required_libavb_version_minor() to
      # bump the minor.
      self.required_libavb_version_major = AVB_VERSION_MAJOR
      self.required_libavb_version_minor = 0
      self.authentication_data_block_size = 0
      self.auxiliary_data_block_size = 0
      self.algorithm_type = 0
      self.hash_offset = 0
      self.hash_size = 0
      self.signature_offset = 0
      self.signature_size = 0
      self.public_key_offset = 0
      self.public_key_size = 0
      self.public_key_metadata_offset = 0
      self.public_key_metadata_size = 0
      self.descriptors_offset = 0
      self.descriptors_size = 0
      self.rollback_index = 0
      self.flags = 0
      self.release_string = get_release_string()

  def bump_required_libavb_version_minor(self, minor):
    """Function to bump required_libavb_version_minor.

    Call this when writing data that requires a specific libavb
    version to parse it.

    Arguments:
      minor: The minor version of libavb that has support for the feature.
    """
    self.required_libavb_version_minor = (
        max(self.required_libavb_version_minor, minor))

  def save(self, output):
    """Serializes the header (256 bytes) to disk.

    Arguments:
      output: The object to write the output to.
    """
    output.write(struct.pack(
        self.FORMAT_STRING, self.magic, self.required_libavb_version_major,
        self.required_libavb_version_minor, self.authentication_data_block_size,
        self.auxiliary_data_block_size, self.algorithm_type, self.hash_offset,
        self.hash_size, self.signature_offset, self.signature_size,
        self.public_key_offset, self.public_key_size,
        self.public_key_metadata_offset, self.public_key_metadata_size,
        self.descriptors_offset, self.descriptors_size, self.rollback_index,
        self.flags, self.release_string))

  def encode(self):
    """Serializes the header (256) to a bytearray().

    Returns:
      A bytearray() with the encoded header.
    """
    return struct.pack(self.FORMAT_STRING, self.magic,
                       self.required_libavb_version_major,
                       self.required_libavb_version_minor,
                       self.authentication_data_block_size,
                       self.auxiliary_data_block_size, self.algorithm_type,
                       self.hash_offset, self.hash_size, self.signature_offset,
                       self.signature_size, self.public_key_offset,
                       self.public_key_size, self.public_key_metadata_offset,
                       self.public_key_metadata_size, self.descriptors_offset,
                       self.descriptors_size, self.rollback_index, self.flags,
                       self.release_string)


class Avb(object):
  """Business logic for avbtool command-line tool."""

  # Keep in sync with avb_ab_flow.h.
  AB_FORMAT_NO_CRC = '!4sBB2xBBBxBBBx12x'
  AB_MAGIC = '\0AB0'
  AB_MAJOR_VERSION = 1
  AB_MINOR_VERSION = 0
  AB_MISC_METADATA_OFFSET = 2048

  # Constants for maximum metadata size. These are used to give
  # meaningful errors if the value passed in via --partition_size is
  # too small and when --calc_max_image_size is used. We use
  # conservative figures.
  MAX_VBMETA_SIZE = 64 * 1024
  MAX_FOOTER_SIZE = 4096

  def extract_vbmeta_image(self, output, image_filename, padding_size):
    """Implements the 'extract_vbmeta_image' command.

    Arguments:
      output: Write vbmeta struct to this file.
      image_filename: File to extract vbmeta data from (with a footer).
      padding_size: If not 0, pads output so size is a multiple of the number.

    Raises:
      AvbError: If there's no footer in the image.
    """
    image = ImageHandler(image_filename)

    (footer, _, _, _) = self._parse_image(image)

    if not footer:
      raise AvbError('Given image does not have a footer.')

    image.seek(footer.vbmeta_offset)
    vbmeta_blob = image.read(footer.vbmeta_size)
    output.write(vbmeta_blob)

    if padding_size > 0:
      padded_size = round_to_multiple(len(vbmeta_blob), padding_size)
      padding_needed = padded_size - len(vbmeta_blob)
      output.write('\0' * padding_needed)

  def erase_footer(self, image_filename, keep_hashtree):
    """Implements the 'erase_footer' command.

    Arguments:
      image_filename: File to erase a footer from.
      keep_hashtree: If True, keep the hashtree and FEC around.

    Raises:
      AvbError: If there's no footer in the image.
    """

    image = ImageHandler(image_filename)

    (footer, _, descriptors, _) = self._parse_image(image)

    if not footer:
      raise AvbError('Given image does not have a footer.')

    new_image_size = None
    if not keep_hashtree:
      new_image_size = footer.original_image_size
    else:
      # If requested to keep the hashtree, search for a hashtree
      # descriptor to figure out the location and size of the hashtree
      # and FEC.
      for desc in descriptors:
        if isinstance(desc, AvbHashtreeDescriptor):
          # The hashtree is always just following the main data so the
          # new size is easily derived.
          new_image_size = desc.tree_offset + desc.tree_size
          # If the image has FEC codes, also keep those.
          if desc.fec_offset > 0:
            fec_end = desc.fec_offset + desc.fec_size
            new_image_size = max(new_image_size, fec_end)
          break
      if not new_image_size:
        raise AvbError('Requested to keep hashtree but no hashtree '
                       'descriptor was found.')

    # And cut...
    image.truncate(new_image_size)

  def zero_hashtree(self, image_filename):
    """Implements the 'zero_hashtree' command.

    Arguments:
      image_filename: File to zero hashtree and FEC data from.

    Raises:
      AvbError: If there's no footer in the image.
    """

    image = ImageHandler(image_filename)

    (footer, _, descriptors, _) = self._parse_image(image)

    if not footer:
      raise AvbError('Given image does not have a footer.')

    # Search for a hashtree descriptor to figure out the location and
    # size of the hashtree and FEC.
    ht_desc = None
    for desc in descriptors:
      if isinstance(desc, AvbHashtreeDescriptor):
        ht_desc = desc
        break

    if not ht_desc:
      raise AvbError('No hashtree descriptor was found.')

    zero_ht_start_offset = ht_desc.tree_offset
    zero_ht_num_bytes = ht_desc.tree_size
    zero_fec_start_offset = None
    zero_fec_num_bytes = 0
    if ht_desc.fec_offset > 0:
      if ht_desc.fec_offset != ht_desc.tree_offset + ht_desc.tree_size:
        raise AvbError('Hash-tree and FEC data must be adjacent.')
      zero_fec_start_offset = ht_desc.fec_offset
      zero_fec_num_bytes = ht_desc.fec_size
    zero_end_offset = (zero_ht_start_offset + zero_ht_num_bytes
                       + zero_fec_num_bytes)
    image.seek(zero_end_offset)
    data = image.read(image.image_size - zero_end_offset)

    # Write zeroes all over hashtree and FEC, except for the first eight bytes
    # where a magic marker - ZeroHaSH - is placed. Place these markers in the
    # beginning of both hashtree and FEC. (That way, in the future we can add
    # options to 'avbtool zero_hashtree' so as to zero out only either/or.)
    #
    # Applications can use these markers to detect that the hashtree and/or
    # FEC needs to be recomputed.
    image.truncate(zero_ht_start_offset)
    data_zeroed_firstblock = 'ZeRoHaSH' + '\0'*(image.block_size - 8)
    image.append_raw(data_zeroed_firstblock)
    image.append_fill('\0\0\0\0', zero_ht_num_bytes - image.block_size)
    if zero_fec_start_offset:
      image.append_raw(data_zeroed_firstblock)
      image.append_fill('\0\0\0\0', zero_fec_num_bytes - image.block_size)
    image.append_raw(data)

  def resize_image(self, image_filename, partition_size):
    """Implements the 'resize_image' command.

    Arguments:
      image_filename: File with footer to resize.
      partition_size: The new size of the image.

    Raises:
      AvbError: If there's no footer in the image.
    """

    image = ImageHandler(image_filename)

    if partition_size % image.block_size != 0:
      raise AvbError('Partition size of {} is not a multiple of the image '
                     'block size {}.'.format(partition_size,
                                             image.block_size))

    (footer, _, _, _) = self._parse_image(image)

    if not footer:
      raise AvbError('Given image does not have a footer.')

    # The vbmeta blob is always at the end of the data so resizing an
    # image amounts to just moving the footer around.

    vbmeta_end_offset = footer.vbmeta_offset + footer.vbmeta_size
    if vbmeta_end_offset % image.block_size != 0:
      vbmeta_end_offset += image.block_size - (vbmeta_end_offset
                                               % image.block_size)

    if partition_size < vbmeta_end_offset + 1*image.block_size:
      raise AvbError('Requested size of {} is too small for an image '
                     'of size {}.'
                     .format(partition_size,
                             vbmeta_end_offset + 1*image.block_size))

    # Cut at the end of the vbmeta blob and insert a DONT_CARE chunk
    # with enough bytes such that the final Footer block is at the end
    # of partition_size.
    image.truncate(vbmeta_end_offset)
    image.append_dont_care(partition_size - vbmeta_end_offset -
                           1*image.block_size)

    # Just reuse the same footer - only difference is that we're
    # writing it in a different place.
    footer_blob = footer.encode()
    footer_blob_with_padding = ('\0'*(image.block_size - AvbFooter.SIZE) +
                                footer_blob)
    image.append_raw(footer_blob_with_padding)

  def set_ab_metadata(self, misc_image, slot_data):
    """Implements the 'set_ab_metadata' command.

    The |slot_data| argument must be of the form 'A_priority:A_tries_remaining:
    A_successful_boot:B_priority:B_tries_remaining:B_successful_boot'.

    Arguments:
      misc_image: The misc image to write to.
      slot_data: Slot data as a string

    Raises:
      AvbError: If slot data is malformed.
    """
    tokens = slot_data.split(':')
    if len(tokens) != 6:
      raise AvbError('Malformed slot data "{}".'.format(slot_data))
    a_priority = int(tokens[0])
    a_tries_remaining = int(tokens[1])
    a_success = True if int(tokens[2]) != 0 else False
    b_priority = int(tokens[3])
    b_tries_remaining = int(tokens[4])
    b_success = True if int(tokens[5]) != 0 else False

    ab_data_no_crc = struct.pack(self.AB_FORMAT_NO_CRC,
                                 self.AB_MAGIC,
                                 self.AB_MAJOR_VERSION, self.AB_MINOR_VERSION,
                                 a_priority, a_tries_remaining, a_success,
                                 b_priority, b_tries_remaining, b_success)
    # Force CRC to be unsigned, see https://bugs.python.org/issue4903 for why.
    crc_value = binascii.crc32(ab_data_no_crc) & 0xffffffff
    ab_data = ab_data_no_crc + struct.pack('!I', crc_value)
    misc_image.seek(self.AB_MISC_METADATA_OFFSET)
    misc_image.write(ab_data)

  def info_image(self, image_filename, output):
    """Implements the 'info_image' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      output: Output file to write human-readable information to (file object).
    """

    image = ImageHandler(image_filename)

    o = output

    (footer, header, descriptors, image_size) = self._parse_image(image)

    if footer:
      o.write('Footer version:           {}.{}\n'.format(footer.version_major,
                                                         footer.version_minor))
      o.write('Image size:               {} bytes\n'.format(image_size))
      o.write('Original image size:      {} bytes\n'.format(
          footer.original_image_size))
      o.write('VBMeta offset:            {}\n'.format(footer.vbmeta_offset))
      o.write('VBMeta size:              {} bytes\n'.format(footer.vbmeta_size))
      o.write('--\n')

    (alg_name, _) = lookup_algorithm_by_type(header.algorithm_type)

    o.write('Minimum libavb version:   {}.{}{}\n'.format(
        header.required_libavb_version_major,
        header.required_libavb_version_minor,
        ' (Sparse)' if image.is_sparse else ''))
    o.write('Header Block:             {} bytes\n'.format(AvbVBMetaHeader.SIZE))
    o.write('Authentication Block:     {} bytes\n'.format(
        header.authentication_data_block_size))
    o.write('Auxiliary Block:          {} bytes\n'.format(
        header.auxiliary_data_block_size))
    o.write('Algorithm:                {}\n'.format(alg_name))
    o.write('Rollback Index:           {}\n'.format(header.rollback_index))
    o.write('Flags:                    {}\n'.format(header.flags))
    o.write('Release String:           \'{}\'\n'.format(
        header.release_string.rstrip('\0')))

    # Print descriptors.
    num_printed = 0
    o.write('Descriptors:\n')
    for desc in descriptors:
      desc.print_desc(o)
      num_printed += 1
    if num_printed == 0:
      o.write('    (none)\n')

  def info_image_icp(self, image_filename, output):
    """Implements the 'info_image_icp' command.

    Arguments:
      image_filename: Image file to get information from.
      output: Output file to write human-readable information to (file object).
    """
    image = ImageHandler(image_filename)
    o = output
    (footer, header, _, _) = self._parse_image(image)

    offset = 0
    if footer:
      offset = footer.vbmeta_offset
    image.seek(offset +
               header.SIZE +
               header.authentication_data_block_size +
               header.auxiliary_data_block_size)

    # TODO(jpm): Fix up AvbIcp* records so the length of data to be read
    # can be determined more easily.
    icp_bytes = image.read(100000)
    if not icp_bytes or len(icp_bytes) < 4 or icp_bytes[0:4] != AvbIcpHeader.MAGIC:
      sys.stderr.write('Image does not contain AFTL inclusion proofs.\n')
      return

    icp_blob = AvbIcpBlob(icp_bytes)
    o.write('Android Firmware Transparency Descriptor:\n')
    o.write('  Header:\n')
    icp_blob.icp_header.print_desc(o)
    for i, icp_entry in enumerate(icp_blob.icp_entries):
      o.write('  Entry #{}:\n'.format(i + 1))
      icp_entry.print_desc(o)
      o.write('    Signed Root Blob:\n')
      icp_entry.signed_root_blob.print_desc(o)

  def verify_image(self, image_filename, key_path, expected_chain_partitions,
                   follow_chain_partitions, accept_zeroed_hashtree):
    """Implements the 'verify_image' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      key_path: None or check that embedded public key matches key at given
          path.
      expected_chain_partitions: List of chain partitions to check or None.
      follow_chain_partitions:
          If True, will follows chain partitions even when not specified with
          the --expected_chain_partition option
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Raises:
      AvbError: If verification of the image fails.
    """
    expected_chain_partitions_map = {}
    if expected_chain_partitions:
      for cp in expected_chain_partitions:
        cp_tokens = cp.split(':')
        if len(cp_tokens) != 3:
          raise AvbError('Malformed chained partition "{}".'.format(cp))
        partition_name = cp_tokens[0]
        rollback_index_location = int(cp_tokens[1])
        file_path = cp_tokens[2]
        pk_blob = open(file_path).read()
        expected_chain_partitions_map[partition_name] = (
            rollback_index_location, pk_blob)

    image_dir = os.path.dirname(image_filename)
    #image_ext = os.path.splitext(image_filename)[1]
    image_ext = image_filename[image_filename.index('.'):]

    key_blob = None
    if key_path:
      print('Verifying image {} using key at {}'.format(image_filename,
                                                        key_path))
      key_blob = encode_rsa_key(key_path)
    else:
      print('Verifying image {} using embedded public key'.format(
          image_filename))

    image = ImageHandler(image_filename)
    (footer, header, descriptors, _) = self._parse_image(image)
    offset = 0
    if footer:
      offset = footer.vbmeta_offset

    image.seek(offset)
    vbmeta_blob = image.read(header.SIZE
                             + header.authentication_data_block_size
                             + header.auxiliary_data_block_size)

    alg_name, _ = lookup_algorithm_by_type(header.algorithm_type)
    if not verify_vbmeta_signature(header, vbmeta_blob):
      raise AvbError('Signature check failed for {} vbmeta struct {}'
                     .format(alg_name, image_filename))

    if key_blob:
      # The embedded public key is in the auxiliary block at an offset.
      key_offset = AvbVBMetaHeader.SIZE
      key_offset += header.authentication_data_block_size
      key_offset += header.public_key_offset
      key_blob_in_vbmeta = vbmeta_blob[key_offset:key_offset
                                       + header.public_key_size]
      if key_blob != key_blob_in_vbmeta:
        raise AvbError('Embedded public key does not match given key.')

    if footer:
      print('vbmeta: Successfully verified footer and {} vbmeta struct in {}'
            .format(alg_name, image.filename))
    else:
      print('vbmeta: Successfully verified {} vbmeta struct in {}'
            .format(alg_name, image.filename))

    for desc in descriptors:
      if (isinstance(desc, AvbChainPartitionDescriptor)
          and follow_chain_partitions
          and expected_chain_partitions_map.get(desc.partition_name) is None):
        # In this case we're processing a chain descriptor but don't have a
        # --expect_chain_partition ... however --follow_chain_partitions was
        # specified so we shouldn't error out in desc.verify().
        print('{}: Chained but ROLLBACK_SLOT (which is {}) '
              'and KEY (which has sha1 {}) not specified'
              .format(desc.partition_name, desc.rollback_index_location,
                      hashlib.sha1(desc.public_key).hexdigest()))
      elif not desc.verify(image_dir, image_ext, expected_chain_partitions_map,
                           image, accept_zeroed_hashtree):
        raise AvbError('Error verifying descriptor.')
      # Honor --follow_chain_partitions - add '--' to make the output more
      # readable.
      if (isinstance(desc, AvbChainPartitionDescriptor)
          and follow_chain_partitions):
        print('--')
        chained_image_filename = os.path.join(image_dir,
                                              desc.partition_name + image_ext)
        self.verify_image(chained_image_filename, key_path, None, False,
                          accept_zeroed_hashtree)

  def calculate_vbmeta_digest(self, image_filename, hash_algorithm, output):
    """Implements the 'calculate_vbmeta_digest' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      hash_algorithm: Hash algorithm used.
      output: Output file to write human-readable information to (file object).
    """

    image_dir = os.path.dirname(image_filename)
    image_ext = os.path.splitext(image_filename)[1]

    image = ImageHandler(image_filename)
    (footer, header, descriptors, _) = self._parse_image(image)
    offset = 0
    if footer:
      offset = footer.vbmeta_offset
    size = (header.SIZE + header.authentication_data_block_size +
            header.auxiliary_data_block_size)
    image.seek(offset)
    vbmeta_blob = image.read(size)

    hasher = hashlib.new(name=hash_algorithm)
    hasher.update(vbmeta_blob)

    for desc in descriptors:
      if isinstance(desc, AvbChainPartitionDescriptor):
        ch_image_filename = os.path.join(image_dir,
                                         desc.partition_name + image_ext)
        ch_image = ImageHandler(ch_image_filename)
        (ch_footer, ch_header, _, _) = self._parse_image(ch_image)
        ch_offset = 0
        ch_size = (ch_header.SIZE + ch_header.authentication_data_block_size +
                   ch_header.auxiliary_data_block_size)
        if ch_footer:
          ch_offset = ch_footer.vbmeta_offset
        ch_image.seek(ch_offset)
        ch_vbmeta_blob = ch_image.read(ch_size)
        hasher.update(ch_vbmeta_blob)

    digest = hasher.digest()
    output.write('{}\n'.format(binascii.hexlify(digest)))

  def calculate_kernel_cmdline(self, image_filename, hashtree_disabled, output):
    """Implements the 'calculate_kernel_cmdline' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      hashtree_disabled: If True, returns the cmdline for hashtree disabled.
      output: Output file to write human-readable information to (file object).
    """

    image = ImageHandler(image_filename)
    _, _, descriptors, _ = self._parse_image(image)

    image_dir = os.path.dirname(image_filename)
    image_ext = os.path.splitext(image_filename)[1]

    cmdline_descriptors = []
    for desc in descriptors:
      if isinstance(desc, AvbChainPartitionDescriptor):
        ch_image_filename = os.path.join(image_dir,
                                         desc.partition_name + image_ext)
        ch_image = ImageHandler(ch_image_filename)
        _, _, ch_descriptors, _ = self._parse_image(ch_image)
        for ch_desc in ch_descriptors:
          if isinstance(ch_desc, AvbKernelCmdlineDescriptor):
            cmdline_descriptors.append(ch_desc)
      elif isinstance(desc, AvbKernelCmdlineDescriptor):
        cmdline_descriptors.append(desc)

    kernel_cmdline_snippets = []
    for desc in cmdline_descriptors:
      use_cmdline = True
      if ((desc.flags &
           AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED)
          != 0):
        if hashtree_disabled:
          use_cmdline = False
      if (desc.flags &
          AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_DISABLED) != 0:
        if not hashtree_disabled:
          use_cmdline = False
      if use_cmdline:
        kernel_cmdline_snippets.append(desc.kernel_cmdline)
    output.write(' '.join(kernel_cmdline_snippets))

  def _parse_image(self, image):
    """Gets information about an image.

    The image can either be a vbmeta or an image with a footer.

    Arguments:
      image: An ImageHandler (vbmeta or footer) with a hashtree descriptor.

    Returns:
      A tuple where the first argument is a AvbFooter (None if there
      is no footer on the image), the second argument is a
      AvbVBMetaHeader, the third argument is a list of
      AvbDescriptor-derived instances, and the fourth argument is the
      size of |image|.
    """
    assert isinstance(image, ImageHandler)
    footer = None
    image.seek(image.image_size - AvbFooter.SIZE)
    try:
      footer = AvbFooter(image.read(AvbFooter.SIZE))
    except (LookupError, struct.error):
      # Nope, just seek back to the start.
      image.seek(0)

    vbmeta_offset = 0
    if footer:
      vbmeta_offset = footer.vbmeta_offset

    image.seek(vbmeta_offset)
    h = AvbVBMetaHeader(image.read(AvbVBMetaHeader.SIZE))

    auth_block_offset = vbmeta_offset + AvbVBMetaHeader.SIZE
    aux_block_offset = auth_block_offset + h.authentication_data_block_size
    desc_start_offset = aux_block_offset + h.descriptors_offset
    image.seek(desc_start_offset)
    descriptors = parse_descriptors(image.read(h.descriptors_size))

    return footer, h, descriptors, image.image_size

  def _load_vbmeta_blob(self, image):
    """Gets the vbmeta struct and associated sections.

    The image can either be a vbmeta.img or an image with a footer.

    Arguments:
      image: An ImageHandler (vbmeta or footer).

    Returns:
      A blob with the vbmeta struct and other sections.
    """
    assert isinstance(image, ImageHandler)
    footer = None
    image.seek(image.image_size - AvbFooter.SIZE)
    try:
      footer = AvbFooter(image.read(AvbFooter.SIZE))
    except (LookupError, struct.error):
      # Nope, just seek back to the start.
      image.seek(0)

    vbmeta_offset = 0
    if footer:
      vbmeta_offset = footer.vbmeta_offset

    image.seek(vbmeta_offset)
    h = AvbVBMetaHeader(image.read(AvbVBMetaHeader.SIZE))

    image.seek(vbmeta_offset)
    data_size = AvbVBMetaHeader.SIZE
    data_size += h.authentication_data_block_size
    data_size += h.auxiliary_data_block_size
    return image.read(data_size)

  def _get_cmdline_descriptors_for_hashtree_descriptor(self, ht):
    """Generate kernel cmdline descriptors for dm-verity.

    Arguments:
      ht: A AvbHashtreeDescriptor

    Returns:
      A list with two AvbKernelCmdlineDescriptor with dm-verity kernel cmdline
      instructions. There is one for when hashtree is not disabled and one for
      when it is.

    """

    c = 'dm="1 vroot none ro 1,'
    c += '0'  # start
    c += ' {}'.format((ht.image_size // 512))  # size (# sectors)
    c += ' verity {}'.format(ht.dm_verity_version)  # type and version
    c += ' PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'  # data_dev
    c += ' PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'  # hash_dev
    c += ' {}'.format(ht.data_block_size)  # data_block
    c += ' {}'.format(ht.hash_block_size)  # hash_block
    c += ' {}'.format(ht.image_size // ht.data_block_size)  # #blocks
    c += ' {}'.format(ht.image_size // ht.data_block_size)  # hash_offset
    c += ' {}'.format(ht.hash_algorithm)  # hash_alg
    c += ' {}'.format(str(ht.root_digest).encode('hex'))  # root_digest
    c += ' {}'.format(str(ht.salt).encode('hex'))  # salt
    if ht.fec_num_roots > 0:
      c += ' 10'  # number of optional args
      c += ' $(ANDROID_VERITY_MODE)'
      c += ' ignore_zero_blocks'
      c += ' use_fec_from_device PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'
      c += ' fec_roots {}'.format(ht.fec_num_roots)
      # Note that fec_blocks is the size that FEC covers, *not* the
      # size of the FEC data. Since we use FEC for everything up until
      # the FEC data, it's the same as the offset.
      c += ' fec_blocks {}'.format(ht.fec_offset // ht.data_block_size)
      c += ' fec_start {}'.format(ht.fec_offset // ht.data_block_size)
    else:
      c += ' 2'  # number of optional args
      c += ' $(ANDROID_VERITY_MODE)'
      c += ' ignore_zero_blocks'
    c += '" root=/dev/dm-0'

    # Now that we have the command-line, generate the descriptor.
    desc = AvbKernelCmdlineDescriptor()
    desc.kernel_cmdline = c
    desc.flags = (
        AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED)

    # The descriptor for when hashtree verification is disabled is a lot
    # simpler - we just set the root to the partition.
    desc_no_ht = AvbKernelCmdlineDescriptor()
    desc_no_ht.kernel_cmdline = 'root=PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'
    desc_no_ht.flags = (
        AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_DISABLED)

    return [desc, desc_no_ht]

  def _get_cmdline_descriptors_for_dm_verity(self, image):
    """Generate kernel cmdline descriptors for dm-verity.

    Arguments:
      image: An ImageHandler (vbmeta or footer) with a hashtree descriptor.

    Returns:
      A list with two AvbKernelCmdlineDescriptor with dm-verity kernel cmdline
      instructions. There is one for when hashtree is not disabled and one for
      when it is.

    Raises:
      AvbError: If  |image| doesn't have a hashtree descriptor.

    """

    (_, _, descriptors, _) = self._parse_image(image)

    ht = None
    for desc in descriptors:
      if isinstance(desc, AvbHashtreeDescriptor):
        ht = desc
        break

    if not ht:
      raise AvbError('No hashtree descriptor in given image')

    return self._get_cmdline_descriptors_for_hashtree_descriptor(ht)

  # TODO(danielaustin): Add unit tests.
  def request_inclusion_proof(self, transparency_log, vbmeta_blob,
                              version_inc, manufacturer_key_path):
    """Packages and sends a request to the specified transparency log.

    Arguments:
      transparency_log: String containing the URL of a transparency log server.
      vbmeta_blob: A bytearray with the vbmeta blob.
      version_inc: Subcomponent of the build fingerprint.
      manufacturer_key_path: Path to key used to sign messages sent to the
         transparency log servers.

    Returns:
      An AvbIcpEntry with the inclusion proof for the log entry.

    Raises:
      AvbError: If grpc or the proto modules cannot be loaded, if there is an
         error communicating with the log or if the manufacturer_key_path
         cannot be decoded.
    """
    # Import grpc and proto.api_pb2_grpc now to avoid global dependencies.
    try:
      import grpc
      import proto.api_pb2_grpc
    except ImportError as e:
      err_str = 'grpc can be installed with python pip install grpcio.\n'
      raise AvbError('Failed to import module: ({}).\n{}'.format(e, err_str))

    # Set up the gRPC channel with the transparency log.
    sys.stdout.write('Preparing to request inclusion proof from {}. This could '
                     'take ~30 seconds for the process to complete.\n'.format(
                         transparency_log))
    channel = grpc.insecure_channel(transparency_log)
    stub = proto.api_pb2_grpc.AFTLogStub(channel)

    # Calculate the hash of the vbmeta image.
    hasher = hashlib.sha256()
    hasher.update(vbmeta_blob)
    vbmeta_hash = hasher.digest()
    # Extract the key data from the PEM file.
    manufacturer_key_data = rsa_key_read_pem_bytes(manufacturer_key_path)
    # Calculate the hash of the manufacturer key data.
    hasher = hashlib.sha256()
    hasher.update(manufacturer_key_data)
    m_key_hash = hasher.digest()
    # Create an AddFirmwareInfoRequest protobuf for transmission to the
    # transparency log.
    fw_info = proto.aftl_pb2.FirmwareInfo(vbmeta_hash=vbmeta_hash,
                                          version_incremental=version_inc,
                                          manufacturer_key_hash=m_key_hash)
    # TODO(danielaustin): Sign the message with the manufacturer key.
    sfw_info = proto.aftl_pb2.SignedFirmwareInfo(info=fw_info)
    request = proto.api_pb2.AddFirmwareInfoRequest(vbmeta=bytes(
        str(vbmeta_blob)), fw_info=sfw_info)
    # Attempt to transmit to the transparency log.
    try:
      # TODO(danielaustin): Set a reasonable timeout deadline here.
      sys.stdout.write('ICP is about to be requested from transparency log '
                       'with domain {}.\n'.format(transparency_log))
      response = stub.AddFirmwareInfo(request)
    except grpc.RpcError as e:
      raise AvbError('Error: grpc failure ({})'.format(e))
    # Return an AvbIcpEntry representing this response.
    icp_entry = AvbIcpEntry()
    icp_entry.translate_response(transparency_log, response)
    return icp_entry

  def make_vbmeta_image(self, output, chain_partitions, algorithm_name,
                        key_path, public_key_metadata_path, rollback_index,
                        flags, props, props_from_file, kernel_cmdlines,
                        setup_rootfs_from_kernel,
                        include_descriptors_from_image,
                        signing_helper,
                        signing_helper_with_files,
                        release_string,
                        append_to_release_string,
                        print_required_libavb_version,
                        padding_size):
    """Implements the 'make_vbmeta_image' command.

    Arguments:
      output: File to write the image to.
      chain_partitions: List of partitions to chain or None.
      algorithm_name: Name of algorithm to use.
      key_path: Path to key to use or None.
      public_key_metadata_path: Path to public key metadata or None.
      rollback_index: The rollback index to use.
      flags: Flags value to use in the image.
      props: Properties to insert (list of strings of the form 'key:value').
      props_from_file: Properties to insert (list of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate from.
      include_descriptors_from_image: List of file objects with descriptors.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string to use instead of default.
      append_to_release_string: None or string to append.
      print_required_libavb_version: True to only print required libavb version.
      padding_size: If not 0, pads output so size is a multiple of the number.

    Raises:
      AvbError: If a chained partition is malformed.
    """

    # If we're asked to calculate minimum required libavb version, we're done.
    if print_required_libavb_version:
      if include_descriptors_from_image:
        # Use the bump logic in AvbVBMetaHeader to calculate the max required
        # version of all included descriptors.
        tmp_header = AvbVBMetaHeader()
        for image in include_descriptors_from_image:
          (_, image_header, _, _) = self._parse_image(ImageHandler(image.name))
          tmp_header.bump_required_libavb_version_minor(
              image_header.required_libavb_version_minor)
        print('1.{}'.format(tmp_header.required_libavb_version_minor))
      else:
        # Descriptors aside, all vbmeta features are supported in 1.0.
        print('1.0')
      return

    if not output:
      raise AvbError('No output file given')

    descriptors = []
    ht_desc_to_setup = None
    vbmeta_blob = self._generate_vbmeta_blob(
        algorithm_name, key_path, public_key_metadata_path, descriptors,
        chain_partitions, rollback_index, flags, props, props_from_file,
        kernel_cmdlines, setup_rootfs_from_kernel, ht_desc_to_setup,
        include_descriptors_from_image, signing_helper,
        signing_helper_with_files, release_string,
        append_to_release_string, 0)

    # Write entire vbmeta blob (header, authentication, auxiliary).
    output.seek(0)
    output.write(vbmeta_blob)

    if padding_size > 0:
      padded_size = round_to_multiple(len(vbmeta_blob), padding_size)
      padding_needed = padded_size - len(vbmeta_blob)
      output.write('\0' * padding_needed)

  def make_icp_from_vbmeta(self, vbmeta_image_path, output, algorithm,
                           signing_helper, signing_helper_with_files,
                           version_incremental, transparency_log_servers,
                           transparency_log_pub_keys, manufacturer_key,
                           padding_size):
    """Generates a vbmeta image with inclusion proof given a vbmeta image.

    This blob (struct AvbIcpBlob) contains the information required to
    validate an inclusion proof for a specific vbmeta image. It consists
    of a header (struct AvbIcpHeader) and zero or more entry structures
    (struct AvbIcpEntry) that contain the vbmeta leaf hash, tree size,
    root hash, inclusion proof hashes, and the signature for the root hash.

    The vbmeta image, its hash, the version_incremental part of the build
    fingerprint, and the hash of the manufacturer key are sent to the
    transparency log, with the message signed by the manufacturer key.
    An inclusion proof is calculated and returned. This inclusion proof is
    then packaged in a AvbIcpBlob structure. The existing vbmeta data is
    copied to a new file, appended with the AvbIcpBlob data, and written to
    output. Validation of the inclusion proof does not require
    communication with the transparency log.

    Arguments:
      vbmeta_image_path: Path to a vbmeta image file.
      output: File to write the results to.
      algorithm: The algorithm ID for signing and hashing (see ALGORITHMS). This
        will be used for hash and signature size calculation and padding.
      signing_helper: Program which signs a hash and returns a signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      version_incremental: A string representing the subcomponent of the
        build fingerprint used to identify the vbmeta in the transparency log.
      transparency_log_servers: List of strings containing URLs of transparency
        log servers where inclusion proofs are requested from.
      transparency_log_pub_keys: List of paths to PEM files containing trusted
        public keys that correspond with the transparency_logs. There must be
        the same number of keys as log servers and they must be in the same
        order, that is, transparency_log_pub_keys[n] corresponds to
        transparency_log_servers[n].
      manufacturer_key: Path to PEM file containting the key file used to sign
        messages sent to the transparency log servers.
      padding_size: If not 0, pads output so size is a multiple of the number.

    Returns:
      True if the inclusion proofs could be fetched from the transparency log
      servers and could be successfully validated, False otherwise.

    Raises:
      AvbError: If any parameters are invalid, communication with the log
      fails or the structures are malformed.
    """
    # TODO(danielaustin): Determine the best way to handle chained vbmeta
    # structures. Currently, we only put the main one in the transparency
    # log.

    # Validates command line parameters.
    if not vbmeta_image_path:
      raise AvbError('No vbmeta image path found.')
    if not transparency_log_servers:
      raise AvbError('No transparency log servers given.')
    if not transparency_log_pub_keys:
      raise AvbError('No transparency log public keys given.')
    if len(transparency_log_servers) != len(transparency_log_pub_keys):
      raise AvbError('Transparency log count and public key count mismatch: '
                     '{} servers and {} public keys'.format(
                         len(transparency_log_servers),
                         len(transparency_log_pub_keys)))
    if not manufacturer_key:
      raise AvbError('No manufacturer key path given.')

    # TODO(danielaustin): add support for signing_helper and
    # signing_helper_with_files
    if signing_helper is not None or signing_helper_with_files is not None:
      raise AvbError('signing_helper support not yet implemented for ICP.')

    try:
      algorithm_id = ALGORITHMS[algorithm].algorithm_type
    except KeyError:
      raise AvbError('Unknown algorithm with name {}'.format(algorithm))

    # Retrieves vbmeta structure from given partition image.
    image = ImageHandler(vbmeta_image_path)
    (footer, header, _, _) = self._parse_image(image)
    offset = 0
    if footer:
      offset = footer.vbmeta_offset
    image.seek(offset)
    vbmeta_blob = image.read(header.SIZE +
                             header.authentication_data_block_size +
                             header.auxiliary_data_block_size)

    #  Fetches inclusion proofs for vbmeta structure from all transparency logs.
    icp_entries = []
    for i, transparency_log in enumerate(transparency_log_servers):
      try:
        icp_entry = self.request_inclusion_proof(transparency_log, vbmeta_blob,
                                                 version_incremental,
                                                 manufacturer_key)
        if not icp_entry.verify_icp(transparency_log_pub_keys[i]):
          sys.stderr.write('The ICP from {} could not be verified\n'.format(
              transparency_log))
        icp_entries.append(icp_entry)
      except AvbError as e:
        sys.stderr.write('AvbError: {}'.format(e))
        # The inclusion proof request failed.
        # Continue and see if another will succeed.
        continue
    if not icp_entries:
      sys.stderr.write('No inclusion proofs could be validated from any log.\n')
      return False

    # Prepares the inclusion proof blob to be appended to the vbmeta image.
    icp_blob = AvbIcpBlob()
    icp_blob.set_algorithm(algorithm_id)
    for icp_entry in icp_entries:
      icp_blob.add_icp_entry(icp_entry)
    if not icp_blob.is_valid():
      sys.stderr.write('Resulting AvbIcpBlob structure is malformed\n.')
      return False

    # Write the original vbmeta blob, followed by the AvbIcpBlob.
    if footer:  # Checks if it is a chained partition.
      # TODO(danielaustin): Add support for chained partitions like system.img
      # using similar functionality as implemented in append_vbmeta_image().
      sys.stderr.write('Image has a footer and ICP for this format is not '
                       'implemented.')
      return False

    # Writes vbmeta image with inclusion proof into a new vbmeta image.
    output.seek(0)
    output.write(vbmeta_blob)
    encoded_icp_blob = icp_blob.encode()
    output.write(encoded_icp_blob)

    if padding_size > 0:
      blob_size = len(vbmeta_blob) + len(encoded_icp_blob)
      padded_size = round_to_multiple(blob_size, padding_size)
      padding_needed = padded_size - blob_size
      output.write('\0' * padding_needed)

    return True

  def _generate_vbmeta_blob(self, algorithm_name, key_path,
                            public_key_metadata_path, descriptors,
                            chain_partitions,
                            rollback_index, flags, props, props_from_file,
                            kernel_cmdlines,
                            setup_rootfs_from_kernel,
                            ht_desc_to_setup,
                            include_descriptors_from_image, signing_helper,
                            signing_helper_with_files,
                            release_string, append_to_release_string,
                            required_libavb_version_minor):
    """Generates a VBMeta blob.

    This blob contains the header (struct AvbVBMetaHeader), the
    authentication data block (which contains the hash and signature
    for the header and auxiliary block), and the auxiliary block
    (which contains descriptors, the public key used, and other data).

    The |key| parameter can |None| only if the |algorithm_name| is
    'NONE'.

    Arguments:
      algorithm_name: The algorithm name as per the ALGORITHMS dict.
      key_path: The path to the .pem file used to sign the blob.
      public_key_metadata_path: Path to public key metadata or None.
      descriptors: A list of descriptors to insert or None.
      chain_partitions: List of partitions to chain or None.
      rollback_index: The rollback index to use.
      flags: Flags to use in the image.
      props: Properties to insert (List of strings of the form 'key:value').
      props_from_file: Properties to insert (List of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate
        dm-verity kernel cmdline from.
      ht_desc_to_setup: If not None, an AvbHashtreeDescriptor to
        generate dm-verity kernel cmdline descriptors from.
      include_descriptors_from_image: List of file objects for which
        to insert descriptors from.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string.
      append_to_release_string: None or string to append.
      required_libavb_version_minor: Use at least this required minor version.

    Returns:
      A bytearray() with the VBMeta blob.

    Raises:
      Exception: If the |algorithm_name| is not found, if no key has
        been given and the given algorithm requires one, or the key is
        of the wrong size.

    """
    try:
      alg = ALGORITHMS[algorithm_name]
    except KeyError:
      raise AvbError('Unknown algorithm with name {}'.format(algorithm_name))

    if not descriptors:
      descriptors = []

    h = AvbVBMetaHeader()
    h.bump_required_libavb_version_minor(required_libavb_version_minor)

    # Insert chained partition descriptors, if any
    if chain_partitions:
      used_locations = {}
      for cp in chain_partitions:
        cp_tokens = cp.split(':')
        if len(cp_tokens) != 3:
          raise AvbError('Malformed chained partition "{}".'.format(cp))
        partition_name = cp_tokens[0]
        rollback_index_location = int(cp_tokens[1])
        file_path = cp_tokens[2]
        # Check that the same rollback location isn't being used by
        # multiple chained partitions.
        if used_locations.get(rollback_index_location):
          raise AvbError('Rollback Index Location {} is already in use.'.format(
              rollback_index_location))
        used_locations[rollback_index_location] = True
        desc = AvbChainPartitionDescriptor()
        desc.partition_name = partition_name
        desc.rollback_index_location = rollback_index_location
        if desc.rollback_index_location < 1:
          raise AvbError('Rollback index location must be 1 or larger.')
        desc.public_key = open(file_path, 'rb').read()
        descriptors.append(desc)

    # Descriptors.
    encoded_descriptors = bytearray()
    for desc in descriptors:
      encoded_descriptors.extend(desc.encode())

    # Add properties.
    if props:
      for prop in props:
        idx = prop.find(':')
        if idx == -1:
          raise AvbError('Malformed property "{}".'.format(prop))
        # pylint: disable=redefined-variable-type
        desc = AvbPropertyDescriptor()
        desc.key = prop[0:idx]
        desc.value = prop[(idx + 1):]
        encoded_descriptors.extend(desc.encode())
    if props_from_file:
      for prop in props_from_file:
        idx = prop.find(':')
        if idx == -1:
          raise AvbError('Malformed property "{}".'.format(prop))
        desc = AvbPropertyDescriptor()
        desc.key = prop[0:idx]
        desc.value = prop[(idx + 1):]
        file_path = prop[(idx + 1):]
        desc.value = open(file_path, 'rb').read()
        encoded_descriptors.extend(desc.encode())

    # Add AvbKernelCmdline descriptor for dm-verity from an image, if requested.
    if setup_rootfs_from_kernel:
      image_handler = ImageHandler(
          setup_rootfs_from_kernel.name)
      cmdline_desc = self._get_cmdline_descriptors_for_dm_verity(image_handler)
      encoded_descriptors.extend(cmdline_desc[0].encode())
      encoded_descriptors.extend(cmdline_desc[1].encode())

    # Add AvbKernelCmdline descriptor for dm-verity from desc, if requested.
    if ht_desc_to_setup:
      cmdline_desc = self._get_cmdline_descriptors_for_hashtree_descriptor(
          ht_desc_to_setup)
      encoded_descriptors.extend(cmdline_desc[0].encode())
      encoded_descriptors.extend(cmdline_desc[1].encode())

    # Add kernel command-lines.
    if kernel_cmdlines:
      for i in kernel_cmdlines:
        desc = AvbKernelCmdlineDescriptor()
        desc.kernel_cmdline = i
        encoded_descriptors.extend(desc.encode())

    # Add descriptors from other images.
    if include_descriptors_from_image:
      descriptors_dict = dict()
      for image in include_descriptors_from_image:
        image_handler = ImageHandler(image.name)
        (_, image_vbmeta_header, image_descriptors, _) = self._parse_image(
            image_handler)
        # Bump the required libavb version to support all included descriptors.
        h.bump_required_libavb_version_minor(
            image_vbmeta_header.required_libavb_version_minor)
        for desc in image_descriptors:
          # The --include_descriptors_from_image option is used in some setups
          # with images A and B where both A and B contain a descriptor
          # for a partition with the same name. Since it's not meaningful
          # to include both descriptors, only include the last seen descriptor.
          # See bug 76386656 for details.
          if hasattr(desc, 'partition_name'):
            key = type(desc).__name__ + '_' + desc.partition_name
            descriptors_dict[key] = desc.encode()
          else:
            encoded_descriptors.extend(desc.encode())
      for key in sorted(descriptors_dict):
        encoded_descriptors.extend(descriptors_dict[key])

    # Load public key metadata blob, if requested.
    pkmd_blob = []
    if public_key_metadata_path:
      with open(public_key_metadata_path) as f:
        pkmd_blob = f.read()

    key = None
    encoded_key = bytearray()
    if alg.public_key_num_bytes > 0:
      if not key_path:
        raise AvbError('Key is required for algorithm {}'.format(
            algorithm_name))
      encoded_key = encode_rsa_key(key_path)
      if len(encoded_key) != alg.public_key_num_bytes:
        raise AvbError('Key is wrong size for algorithm {}'.format(
            algorithm_name))

    # Override release string, if requested.
    # pylint: disable=unicode-builtin
    if isinstance(release_string, (str, unicode)):
      h.release_string = release_string

    # Append to release string, if requested. Also insert a space before.
    if isinstance(append_to_release_string, (str, unicode)):
      h.release_string += ' ' + append_to_release_string

    # For the Auxiliary data block, descriptors are stored at offset 0,
    # followed by the public key, followed by the public key metadata blob.
    h.auxiliary_data_block_size = round_to_multiple(
        len(encoded_descriptors) + len(encoded_key) + len(pkmd_blob), 64)
    h.descriptors_offset = 0
    h.descriptors_size = len(encoded_descriptors)
    h.public_key_offset = h.descriptors_size
    h.public_key_size = len(encoded_key)
    h.public_key_metadata_offset = h.public_key_offset + h.public_key_size
    h.public_key_metadata_size = len(pkmd_blob)

    # For the Authentication data block, the hash is first and then
    # the signature.
    h.authentication_data_block_size = round_to_multiple(
        alg.hash_num_bytes + alg.signature_num_bytes, 64)
    h.algorithm_type = alg.algorithm_type
    h.hash_offset = 0
    h.hash_size = alg.hash_num_bytes
    # Signature offset and size - it's stored right after the hash
    # (in Authentication data block).
    h.signature_offset = alg.hash_num_bytes
    h.signature_size = alg.signature_num_bytes

    h.rollback_index = rollback_index
    h.flags = flags

    # Generate Header data block.
    header_data_blob = h.encode()

    # Generate Auxiliary data block.
    aux_data_blob = bytearray()
    aux_data_blob.extend(encoded_descriptors)
    aux_data_blob.extend(encoded_key)
    aux_data_blob.extend(pkmd_blob)
    padding_bytes = h.auxiliary_data_block_size - len(aux_data_blob)
    aux_data_blob.extend('\0' * padding_bytes)

    # Calculate the hash.
    binary_hash = bytearray()
    binary_signature = bytearray()
    if algorithm_name != 'NONE':
      ha = hashlib.new(alg.hash_name)
      ha.update(header_data_blob)
      ha.update(aux_data_blob)
      binary_hash.extend(ha.digest())

      # Calculate the signature.
      padding_and_hash = str(bytearray(alg.padding)) + binary_hash
      binary_signature.extend(raw_sign(signing_helper,
                                       signing_helper_with_files,
                                       algorithm_name,
                                       alg.signature_num_bytes, key_path,
                                       padding_and_hash))

    # Generate Authentication data block.
    auth_data_blob = bytearray()
    auth_data_blob.extend(binary_hash)
    auth_data_blob.extend(binary_signature)
    padding_bytes = h.authentication_data_block_size - len(auth_data_blob)
    auth_data_blob.extend('\0' * padding_bytes)

    return header_data_blob + auth_data_blob + aux_data_blob

  def extract_public_key(self, key_path, output):
    """Implements the 'extract_public_key' command.

    Arguments:
      key_path: The path to a RSA private key file.
      output: The file to write to.
    """
    output.write(encode_rsa_key(key_path))

  def append_vbmeta_image(self, image_filename, vbmeta_image_filename,
                          partition_size):
    """Implementation of the append_vbmeta_image command.

    Arguments:
      image_filename: File to add the footer to.
      vbmeta_image_filename: File to get vbmeta struct from.
      partition_size: Size of partition.

    Raises:
      AvbError: If an argument is incorrect.
    """
    image = ImageHandler(image_filename)

    if partition_size % image.block_size != 0:
      raise AvbError('Partition size of {} is not a multiple of the image '
                     'block size {}.'.format(partition_size,
                                             image.block_size))

    # If there's already a footer, truncate the image to its original
    # size. This way 'avbtool append_vbmeta_image' is idempotent.
    if image.image_size >= AvbFooter.SIZE:
      image.seek(image.image_size - AvbFooter.SIZE)
      try:
        footer = AvbFooter(image.read(AvbFooter.SIZE))
        # Existing footer found. Just truncate.
        original_image_size = footer.original_image_size
        image.truncate(footer.original_image_size)
      except (LookupError, struct.error):
        original_image_size = image.image_size
    else:
      # Image size is too small to possibly contain a footer.
      original_image_size = image.image_size

    # If anything goes wrong from here-on, restore the image back to
    # its original size.
    try:
      vbmeta_image_handler = ImageHandler(vbmeta_image_filename)
      vbmeta_blob = self._load_vbmeta_blob(vbmeta_image_handler)

      # If the image isn't sparse, its size might not be a multiple of
      # the block size. This will screw up padding later so just grow it.
      if image.image_size % image.block_size != 0:
        assert not image.is_sparse
        padding_needed = image.block_size - (image.image_size%image.block_size)
        image.truncate(image.image_size + padding_needed)

      # The append_raw() method requires content with size being a
      # multiple of |block_size| so add padding as needed. Also record
      # where this is written to since we'll need to put that in the
      # footer.
      vbmeta_offset = image.image_size
      padding_needed = (round_to_multiple(len(vbmeta_blob), image.block_size) -
                        len(vbmeta_blob))
      vbmeta_blob_with_padding = vbmeta_blob + '\0'*padding_needed

      # Append vbmeta blob and footer
      image.append_raw(vbmeta_blob_with_padding)
      vbmeta_end_offset = vbmeta_offset + len(vbmeta_blob_with_padding)

      # Now insert a DONT_CARE chunk with enough bytes such that the
      # final Footer block is at the end of partition_size..
      image.append_dont_care(partition_size - vbmeta_end_offset -
                             1*image.block_size)

      # Generate the Footer that tells where the VBMeta footer
      # is. Also put enough padding in the front of the footer since
      # we'll write out an entire block.
      footer = AvbFooter()
      footer.original_image_size = original_image_size
      footer.vbmeta_offset = vbmeta_offset
      footer.vbmeta_size = len(vbmeta_blob)
      footer_blob = footer.encode()
      footer_blob_with_padding = ('\0'*(image.block_size - AvbFooter.SIZE) +
                                  footer_blob)
      image.append_raw(footer_blob_with_padding)

    except:
      # Truncate back to original size, then re-raise
      image.truncate(original_image_size)
      raise

  def add_hash_footer(self, image_filename, partition_size, partition_name,
                      hash_algorithm, salt, chain_partitions, algorithm_name,
                      key_path,
                      public_key_metadata_path, rollback_index, flags, props,
                      props_from_file, kernel_cmdlines,
                      setup_rootfs_from_kernel,
                      include_descriptors_from_image, calc_max_image_size,
                      signing_helper, signing_helper_with_files,
                      release_string, append_to_release_string,
                      output_vbmeta_image, do_not_append_vbmeta_image,
                      print_required_libavb_version, use_persistent_digest,
                      do_not_use_ab):
    """Implementation of the add_hash_footer on unsparse images.

    Arguments:
      image_filename: File to add the footer to.
      partition_size: Size of partition.
      partition_name: Name of partition (without A/B suffix).
      hash_algorithm: Hash algorithm to use.
      salt: Salt to use as a hexadecimal string or None to use /dev/urandom.
      chain_partitions: List of partitions to chain.
      algorithm_name: Name of algorithm to use.
      key_path: Path to key to use or None.
      public_key_metadata_path: Path to public key metadata or None.
      rollback_index: Rollback index.
      flags: Flags value to use in the image.
      props: Properties to insert (List of strings of the form 'key:value').
      props_from_file: Properties to insert (List of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate
        dm-verity kernel cmdline from.
      include_descriptors_from_image: List of file objects for which
        to insert descriptors from.
      calc_max_image_size: Don't store the footer - instead calculate the
        maximum image size leaving enough room for metadata with the
        given |partition_size|.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string.
      append_to_release_string: None or string to append.
      output_vbmeta_image: If not None, also write vbmeta struct to this file.
      do_not_append_vbmeta_image: If True, don't append vbmeta struct.
      print_required_libavb_version: True to only print required libavb version.
      use_persistent_digest: Use a persistent digest on device.
      do_not_use_ab: This partition does not use A/B.

    Raises:
      AvbError: If an argument is incorrect.
    """

    required_libavb_version_minor = 0
    if use_persistent_digest or do_not_use_ab:
      required_libavb_version_minor = 1

    # If we're asked to calculate minimum required libavb version, we're done.
    if print_required_libavb_version:
      print('1.{}'.format(required_libavb_version_minor))
      return

    # First, calculate the maximum image size such that an image
    # this size + metadata (footer + vbmeta struct) fits in
    # |partition_size|.
    max_metadata_size = self.MAX_VBMETA_SIZE + self.MAX_FOOTER_SIZE
    if partition_size < max_metadata_size:
      raise AvbError('Parition size of {} is too small. '
                     'Needs to be at least {}'.format(
                         partition_size, max_metadata_size))
    max_image_size = partition_size - max_metadata_size

    # If we're asked to only calculate the maximum image size, we're done.
    if calc_max_image_size:
      print('{}'.format(max_image_size))
      return

    image = ImageHandler(image_filename)

    if partition_size % image.block_size != 0:
      raise AvbError('Partition size of {} is not a multiple of the image '
                     'block size {}.'.format(partition_size,
                                             image.block_size))

    # If there's already a footer, truncate the image to its original
    # size. This way 'avbtool add_hash_footer' is idempotent (modulo
    # salts).
    if image.image_size >= AvbFooter.SIZE:
      image.seek(image.image_size - AvbFooter.SIZE)
      try:
        footer = AvbFooter(image.read(AvbFooter.SIZE))
        # Existing footer found. Just truncate.
        original_image_size = footer.original_image_size
        image.truncate(footer.original_image_size)
      except (LookupError, struct.error):
        original_image_size = image.image_size
    else:
      # Image size is too small to possibly contain a footer.
      original_image_size = image.image_size

    # If anything goes wrong from here-on, restore the image back to
    # its original size.
    try:
      # If image size exceeds the maximum image size, fail.
      if image.image_size > max_image_size:
        raise AvbError('Image size of {} exceeds maximum image '
                       'size of {} in order to fit in a partition '
                       'size of {}.'.format(image.image_size, max_image_size,
                                            partition_size))

      digest_size = len(hashlib.new(name=hash_algorithm).digest())
      if salt:
        salt = binascii.unhexlify(salt)
      elif salt is None and not use_persistent_digest:
        # If salt is not explicitly specified, choose a hash that's the same
        # size as the hash size. Don't populate a random salt if this
        # descriptor is being created to use a persistent digest on device.
        hash_size = digest_size
        salt = open('/dev/urandom').read(hash_size)
      else:
        salt = ''

      hasher = hashlib.new(name=hash_algorithm, string=salt)
      # TODO(zeuthen): might want to read this in chunks to avoid
      # memory pressure, then again, this is only supposed to be used
      # on kernel/initramfs partitions. Possible optimization.
      image.seek(0)
      hasher.update(image.read(image.image_size))
      digest = hasher.digest()

      h_desc = AvbHashDescriptor()
      h_desc.image_size = image.image_size
      h_desc.hash_algorithm = hash_algorithm
      h_desc.partition_name = partition_name
      h_desc.salt = salt
      h_desc.flags = 0
      if do_not_use_ab:
        h_desc.flags |= 1  # AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB
      if not use_persistent_digest:
        h_desc.digest = digest

      # Generate the VBMeta footer.
      ht_desc_to_setup = None
      vbmeta_blob = self._generate_vbmeta_blob(
          algorithm_name, key_path, public_key_metadata_path, [h_desc],
          chain_partitions, rollback_index, flags, props, props_from_file,
          kernel_cmdlines, setup_rootfs_from_kernel, ht_desc_to_setup,
          include_descriptors_from_image, signing_helper,
          signing_helper_with_files, release_string,
          append_to_release_string, required_libavb_version_minor)

      # Write vbmeta blob, if requested.
      if output_vbmeta_image:
        output_vbmeta_image.write(vbmeta_blob)

      # Append vbmeta blob and footer, unless requested not to.
      if not do_not_append_vbmeta_image:
        # If the image isn't sparse, its size might not be a multiple of
        # the block size. This will screw up padding later so just grow it.
        if image.image_size % image.block_size != 0:
          assert not image.is_sparse
          padding_needed = image.block_size - (
              image.image_size % image.block_size)
          image.truncate(image.image_size + padding_needed)

        # The append_raw() method requires content with size being a
        # multiple of |block_size| so add padding as needed. Also record
        # where this is written to since we'll need to put that in the
        # footer.
        vbmeta_offset = image.image_size
        padding_needed = (
            round_to_multiple(len(vbmeta_blob), image.block_size) -
            len(vbmeta_blob))
        vbmeta_blob_with_padding = vbmeta_blob + '\0' * padding_needed

        image.append_raw(vbmeta_blob_with_padding)
        vbmeta_end_offset = vbmeta_offset + len(vbmeta_blob_with_padding)

        # Now insert a DONT_CARE chunk with enough bytes such that the
        # final Footer block is at the end of partition_size..
        image.append_dont_care(partition_size - vbmeta_end_offset -
                               1*image.block_size)

        # Generate the Footer that tells where the VBMeta footer
        # is. Also put enough padding in the front of the footer since
        # we'll write out an entire block.
        footer = AvbFooter()
        footer.original_image_size = original_image_size
        footer.vbmeta_offset = vbmeta_offset
        footer.vbmeta_size = len(vbmeta_blob)
        footer_blob = footer.encode()
        footer_blob_with_padding = ('\0'*(image.block_size - AvbFooter.SIZE) +
                                    footer_blob)
        image.append_raw(footer_blob_with_padding)

    except:
      # Truncate back to original size, then re-raise
      image.truncate(original_image_size)
      raise

  def add_hashtree_footer(self, image_filename, partition_size, partition_name,
                          generate_fec, fec_num_roots, hash_algorithm,
                          block_size, salt, chain_partitions, algorithm_name,
                          key_path,
                          public_key_metadata_path, rollback_index, flags,
                          props, props_from_file, kernel_cmdlines,
                          setup_rootfs_from_kernel,
                          setup_as_rootfs_from_kernel,
                          include_descriptors_from_image,
                          calc_max_image_size, signing_helper,
                          signing_helper_with_files,
                          release_string, append_to_release_string,
                          output_vbmeta_image, do_not_append_vbmeta_image,
                          print_required_libavb_version,
                          use_persistent_root_digest, do_not_use_ab,
                          no_hashtree):
    """Implements the 'add_hashtree_footer' command.

    See https://gitlab.com/cryptsetup/cryptsetup/wikis/DMVerity for
    more information about dm-verity and these hashes.

    Arguments:
      image_filename: File to add the footer to.
      partition_size: Size of partition or 0 to put it right at the end.
      partition_name: Name of partition (without A/B suffix).
      generate_fec: If True, generate FEC codes.
      fec_num_roots: Number of roots for FEC.
      hash_algorithm: Hash algorithm to use.
      block_size: Block size to use.
      salt: Salt to use as a hexadecimal string or None to use /dev/urandom.
      chain_partitions: List of partitions to chain.
      algorithm_name: Name of algorithm to use.
      key_path: Path to key to use or None.
      public_key_metadata_path: Path to public key metadata or None.
      rollback_index: Rollback index.
      flags: Flags value to use in the image.
      props: Properties to insert (List of strings of the form 'key:value').
      props_from_file: Properties to insert (List of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate
        dm-verity kernel cmdline from.
      setup_as_rootfs_from_kernel: If True, generate dm-verity kernel
        cmdline to set up rootfs.
      include_descriptors_from_image: List of file objects for which
        to insert descriptors from.
      calc_max_image_size: Don't store the hashtree or footer - instead
        calculate the maximum image size leaving enough room for hashtree
        and metadata with the given |partition_size|.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string.
      append_to_release_string: None or string to append.
      output_vbmeta_image: If not None, also write vbmeta struct to this file.
      do_not_append_vbmeta_image: If True, don't append vbmeta struct.
      print_required_libavb_version: True to only print required libavb version.
      use_persistent_root_digest: Use a persistent root digest on device.
      do_not_use_ab: The partition does not use A/B.
      no_hashtree: Do not append hashtree. Set size in descriptor as zero.

    Raises:
      AvbError: If an argument is incorrect.
    """

    required_libavb_version_minor = 0
    if use_persistent_root_digest or do_not_use_ab:
      required_libavb_version_minor = 1

    # If we're asked to calculate minimum required libavb version, we're done.
    if print_required_libavb_version:
      print('1.{}'.format(required_libavb_version_minor))
      return

    digest_size = len(hashlib.new(name=hash_algorithm).digest())
    digest_padding = round_to_pow2(digest_size) - digest_size

    # If |partition_size| is given (e.g. not 0), calculate the maximum image
    # size such that an image this size + the hashtree + metadata (footer +
    # vbmeta struct) fits in |partition_size|. We use very conservative figures
    # for metadata.
    if partition_size > 0:
      max_tree_size = 0
      max_fec_size = 0
      if not no_hashtree:
        (_, max_tree_size) = calc_hash_level_offsets(
            partition_size, block_size, digest_size + digest_padding)
        if generate_fec:
          max_fec_size = calc_fec_data_size(partition_size, fec_num_roots)
      max_metadata_size = (max_fec_size + max_tree_size +
                           self.MAX_VBMETA_SIZE +
                           self.MAX_FOOTER_SIZE)
      max_image_size = partition_size - max_metadata_size
    else:
      max_image_size = 0

    # If we're asked to only calculate the maximum image size, we're done.
    if calc_max_image_size:
      print('{}'.format(max_image_size))
      return

    image = ImageHandler(image_filename)

    if partition_size > 0:
      if partition_size % image.block_size != 0:
        raise AvbError('Partition size of {} is not a multiple of the image '
                       'block size {}.'.format(partition_size,
                                               image.block_size))
    elif image.image_size % image.block_size != 0:
      raise AvbError('File size of {} is not a multiple of the image '
                     'block size {}.'.format(image.image_size,
                                             image.block_size))

    # If there's already a footer, truncate the image to its original
    # size. This way 'avbtool add_hashtree_footer' is idempotent
    # (modulo salts).
    if image.image_size >= AvbFooter.SIZE:
      image.seek(image.image_size - AvbFooter.SIZE)
      try:
        footer = AvbFooter(image.read(AvbFooter.SIZE))
        # Existing footer found. Just truncate.
        original_image_size = footer.original_image_size
        image.truncate(footer.original_image_size)
      except (LookupError, struct.error):
        original_image_size = image.image_size
    else:
      # Image size is too small to possibly contain a footer.
      original_image_size = image.image_size

    # If anything goes wrong from here-on, restore the image back to
    # its original size.
    try:
      # Ensure image is multiple of block_size.
      rounded_image_size = round_to_multiple(image.image_size, block_size)
      if rounded_image_size > image.image_size:
        image.append_raw('\0' * (rounded_image_size - image.image_size))

      # If image size exceeds the maximum image size, fail.
      if partition_size > 0:
        if image.image_size > max_image_size:
          raise AvbError('Image size of {} exceeds maximum image '
                         'size of {} in order to fit in a partition '
                         'size of {}.'.format(image.image_size, max_image_size,
                                              partition_size))

      if salt:
        salt = binascii.unhexlify(salt)
      elif salt is None and not use_persistent_root_digest:
        # If salt is not explicitly specified, choose a hash that's the same
        # size as the hash size. Don't populate a random salt if this
        # descriptor is being created to use a persistent digest on device.
        hash_size = digest_size
        salt = open('/dev/urandom').read(hash_size)
      else:
        salt = ''

      # Hashes are stored upside down so we need to calculate hash
      # offsets in advance.
      (hash_level_offsets, tree_size) = calc_hash_level_offsets(
          image.image_size, block_size, digest_size + digest_padding)

      # If the image isn't sparse, its size might not be a multiple of
      # the block size. This will screw up padding later so just grow it.
      if image.image_size % image.block_size != 0:
        assert not image.is_sparse
        padding_needed = image.block_size - (image.image_size%image.block_size)
        image.truncate(image.image_size + padding_needed)

      # Generate the tree and add padding as needed.
      tree_offset = image.image_size
      root_digest, hash_tree = generate_hash_tree(image, image.image_size,
                                                  block_size,
                                                  hash_algorithm, salt,
                                                  digest_padding,
                                                  hash_level_offsets,
                                                  tree_size)

      # Generate HashtreeDescriptor with details about the tree we
      # just generated.
      if no_hashtree:
        tree_size = 0
        hash_tree = bytearray()
      ht_desc = AvbHashtreeDescriptor()
      ht_desc.dm_verity_version = 1
      ht_desc.image_size = image.image_size
      ht_desc.tree_offset = tree_offset
      ht_desc.tree_size = tree_size
      ht_desc.data_block_size = block_size
      ht_desc.hash_block_size = block_size
      ht_desc.hash_algorithm = hash_algorithm
      ht_desc.partition_name = partition_name
      ht_desc.salt = salt
      if do_not_use_ab:
        ht_desc.flags |= 1  # AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB
      if not use_persistent_root_digest:
        ht_desc.root_digest = root_digest

      # Write the hash tree
      padding_needed = (round_to_multiple(len(hash_tree), image.block_size) -
                        len(hash_tree))
      hash_tree_with_padding = hash_tree + '\0'*padding_needed
      image.append_raw(hash_tree_with_padding)
      len_hashtree_and_fec = len(hash_tree_with_padding)

      # Generate FEC codes, if requested.
      if generate_fec:
        if no_hashtree:
          fec_data = bytearray()
        else:
          fec_data = generate_fec_data(image_filename, fec_num_roots)
        padding_needed = (round_to_multiple(len(fec_data), image.block_size) -
                          len(fec_data))
        fec_data_with_padding = fec_data + '\0'*padding_needed
        fec_offset = image.image_size
        image.append_raw(fec_data_with_padding)
        len_hashtree_and_fec += len(fec_data_with_padding)
        # Update the hashtree descriptor.
        ht_desc.fec_num_roots = fec_num_roots
        ht_desc.fec_offset = fec_offset
        ht_desc.fec_size = len(fec_data)

      ht_desc_to_setup = None
      if setup_as_rootfs_from_kernel:
        ht_desc_to_setup = ht_desc

      # Generate the VBMeta footer and add padding as needed.
      vbmeta_offset = tree_offset + len_hashtree_and_fec
      vbmeta_blob = self._generate_vbmeta_blob(
          algorithm_name, key_path, public_key_metadata_path, [ht_desc],
          chain_partitions, rollback_index, flags, props, props_from_file,
          kernel_cmdlines, setup_rootfs_from_kernel, ht_desc_to_setup,
          include_descriptors_from_image, signing_helper,
          signing_helper_with_files, release_string,
          append_to_release_string, required_libavb_version_minor)
      padding_needed = (round_to_multiple(len(vbmeta_blob), image.block_size) -
                        len(vbmeta_blob))
      vbmeta_blob_with_padding = vbmeta_blob + '\0'*padding_needed

      # Write vbmeta blob, if requested.
      if output_vbmeta_image:
        output_vbmeta_image.write(vbmeta_blob)

      # Append vbmeta blob and footer, unless requested not to.
      if not do_not_append_vbmeta_image:
        image.append_raw(vbmeta_blob_with_padding)

        # Now insert a DONT_CARE chunk with enough bytes such that the
        # final Footer block is at the end of partition_size..
        if partition_size > 0:
          image.append_dont_care(partition_size - image.image_size -
                                 1*image.block_size)

        # Generate the Footer that tells where the VBMeta footer
        # is. Also put enough padding in the front of the footer since
        # we'll write out an entire block.
        footer = AvbFooter()
        footer.original_image_size = original_image_size
        footer.vbmeta_offset = vbmeta_offset
        footer.vbmeta_size = len(vbmeta_blob)
        footer_blob = footer.encode()
        footer_blob_with_padding = ('\0'*(image.block_size - AvbFooter.SIZE) +
                                    footer_blob)
        image.append_raw(footer_blob_with_padding)

    except:
      # Truncate back to original size, then re-raise.
      image.truncate(original_image_size)
      raise

  def make_atx_certificate(self, output, authority_key_path, subject_key_path,
                           subject_key_version, subject,
                           is_intermediate_authority, usage, signing_helper,
                           signing_helper_with_files):
    """Implements the 'make_atx_certificate' command.

    Android Things certificates are required for Android Things public key
    metadata. They chain the vbmeta signing key for a particular product back to
    a fused, permanent root key. These certificates are fixed-length and fixed-
    format with the explicit goal of not parsing ASN.1 in bootloader code.

    Arguments:
      output: Certificate will be written to this file on success.
      authority_key_path: A PEM file path with the authority private key.
                          If None, then a certificate will be created without a
                          signature. The signature can be created out-of-band
                          and appended.
      subject_key_path: Path to a PEM or DER subject public key.
      subject_key_version: A 64-bit version value. If this is None, the number
                           of seconds since the epoch is used.
      subject: A subject identifier. For Product Signing Key certificates this
               should be the same Product ID found in the permanent attributes.
      is_intermediate_authority: True if the certificate is for an intermediate
                                 authority.
      usage: If not empty, overrides the cert usage with a hash of this value.
      signing_helper: Program which signs a hash and returns the signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
    """
    signed_data = bytearray()
    signed_data.extend(struct.pack('<I', 1))  # Format Version
    signed_data.extend(encode_rsa_key(subject_key_path))
    hasher = hashlib.sha256()
    hasher.update(subject)
    signed_data.extend(hasher.digest())
    if not usage:
      usage = 'com.google.android.things.vboot'
      if is_intermediate_authority:
        usage += '.ca'
    hasher = hashlib.sha256()
    hasher.update(usage)
    signed_data.extend(hasher.digest())
    if subject_key_version is None:
      subject_key_version = int(time.time())
    signed_data.extend(struct.pack('<Q', subject_key_version))
    signature = bytearray()
    if authority_key_path:
      padding_and_hash = bytearray()
      algorithm_name = 'SHA512_RSA4096'
      alg = ALGORITHMS[algorithm_name]
      hasher = hashlib.sha512()  # pylint: disable=redefined-variable-type
      padding_and_hash.extend(alg.padding)
      hasher.update(signed_data)
      padding_and_hash.extend(hasher.digest())
      signature.extend(raw_sign(signing_helper, signing_helper_with_files,
                                algorithm_name,
                                alg.signature_num_bytes, authority_key_path,
                                padding_and_hash))
    output.write(signed_data)
    output.write(signature)

  def make_atx_permanent_attributes(self, output, root_authority_key_path,
                                    product_id):
    """Implements the 'make_atx_permanent_attributes' command.

    Android Things permanent attributes are designed to be permanent for a
    particular product and a hash of these attributes should be fused into
    hardware to enforce this.

    Arguments:
      output: Attributes will be written to this file on success.
      root_authority_key_path: Path to a PEM or DER public key for
        the root authority.
      product_id: A 16-byte Product ID.

    Raises:
      AvbError: If an argument is incorrect.
    """
    EXPECTED_PRODUCT_ID_SIZE = 16  # pylint: disable=invalid-name
    if len(product_id) != EXPECTED_PRODUCT_ID_SIZE:
      raise AvbError('Invalid Product ID length.')
    output.write(struct.pack('<I', 1))  # Format Version
    output.write(encode_rsa_key(root_authority_key_path))
    output.write(product_id)

  def make_atx_metadata(self, output, intermediate_key_certificate,
                        product_key_certificate):
    """Implements the 'make_atx_metadata' command.

    Android Things metadata are included in vbmeta images to facilitate
    verification. The output of this command can be used as the
    public_key_metadata argument to other commands.

    Arguments:
      output: Metadata will be written to this file on success.
      intermediate_key_certificate: A certificate file as output by
                                    make_atx_certificate with
                                    is_intermediate_authority set to true.
      product_key_certificate: A certificate file as output by
                               make_atx_certificate with
                               is_intermediate_authority set to false.

    Raises:
      AvbError: If an argument is incorrect.
    """
    EXPECTED_CERTIFICATE_SIZE = 1620  # pylint: disable=invalid-name
    if len(intermediate_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid intermediate key certificate length.')
    if len(product_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid product key certificate length.')
    output.write(struct.pack('<I', 1))  # Format Version
    output.write(intermediate_key_certificate)
    output.write(product_key_certificate)

  def make_atx_unlock_credential(self, output, intermediate_key_certificate,
                                 unlock_key_certificate, challenge_path,
                                 unlock_key_path, signing_helper,
                                 signing_helper_with_files):
    """Implements the 'make_atx_unlock_credential' command.

    Android Things unlock credentials can be used to authorize the unlock of AVB
    on a device. These credentials are presented to an Android Things bootloader
    via the fastboot interface in response to a 16-byte challenge. This method
    creates all fields of the credential except the challenge signature field
    (which is the last field) and can optionally create the challenge signature
    field as well if a challenge and the unlock_key_path is provided.

    Arguments:
      output: The credential will be written to this file on success.
      intermediate_key_certificate: A certificate file as output by
                                    make_atx_certificate with
                                    is_intermediate_authority set to true.
      unlock_key_certificate: A certificate file as output by
                              make_atx_certificate with
                              is_intermediate_authority set to false and the
                              usage set to
                              'com.google.android.things.vboot.unlock'.
      challenge_path: [optional] A path to the challenge to sign.
      unlock_key_path: [optional] A PEM file path with the unlock private key.
      signing_helper: Program which signs a hash and returns the signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.

    Raises:
      AvbError: If an argument is incorrect.
    """
    EXPECTED_CERTIFICATE_SIZE = 1620  # pylint: disable=invalid-name
    EXPECTED_CHALLENGE_SIZE = 16  # pylint: disable=invalid-name
    if len(intermediate_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid intermediate key certificate length.')
    if len(unlock_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid product key certificate length.')
    challenge = bytearray()
    if challenge_path:
      with open(challenge_path, 'r') as f:
        challenge = f.read()
      if len(challenge) != EXPECTED_CHALLENGE_SIZE:
        raise AvbError('Invalid unlock challenge length.')
    output.write(struct.pack('<I', 1))  # Format Version
    output.write(intermediate_key_certificate)
    output.write(unlock_key_certificate)
    if challenge_path and unlock_key_path:
      signature = bytearray()
      padding_and_hash = bytearray()
      algorithm_name = 'SHA512_RSA4096'
      alg = ALGORITHMS[algorithm_name]
      hasher = hashlib.sha512()
      padding_and_hash.extend(alg.padding)
      hasher.update(challenge)
      padding_and_hash.extend(hasher.digest())
      signature.extend(raw_sign(signing_helper, signing_helper_with_files,
                                algorithm_name,
                                alg.signature_num_bytes, unlock_key_path,
                                padding_and_hash))
      output.write(signature)


def calc_hash_level_offsets(image_size, block_size, digest_size):
  """Calculate the offsets of all the hash-levels in a Merkle-tree.

  Arguments:
    image_size: The size of the image to calculate a Merkle-tree for.
    block_size: The block size, e.g. 4096.
    digest_size: The size of each hash, e.g. 32 for SHA-256.

  Returns:
    A tuple where the first argument is an array of offsets and the
    second is size of the tree, in bytes.
  """
  level_offsets = []
  level_sizes = []
  tree_size = 0

  num_levels = 0
  size = image_size
  while size > block_size:
    num_blocks = (size + block_size - 1) // block_size
    level_size = round_to_multiple(num_blocks * digest_size, block_size)

    level_sizes.append(level_size)
    tree_size += level_size
    num_levels += 1

    size = level_size

  for n in range(0, num_levels):
    offset = 0
    for m in range(n + 1, num_levels):
      offset += level_sizes[m]
    level_offsets.append(offset)

  return level_offsets, tree_size


# See system/extras/libfec/include/fec/io.h for these definitions.
FEC_FOOTER_FORMAT = '<LLLLLQ32s'
FEC_MAGIC = 0xfecfecfe


def calc_fec_data_size(image_size, num_roots):
  """Calculates how much space FEC data will take.

  Arguments:
    image_size: The size of the image.
    num_roots: Number of roots.

  Returns:
    The number of bytes needed for FEC for an image of the given size
    and with the requested number of FEC roots.

  Raises:
    ValueError: If output from the 'fec' tool is invalid.

  """
  p = subprocess.Popen(
      ['fec', '--print-fec-size', str(image_size), '--roots', str(num_roots)],
      stdout=subprocess.PIPE,
      stderr=subprocess.PIPE)
  (pout, perr) = p.communicate()
  retcode = p.wait()
  if retcode != 0:
    raise ValueError('Error invoking fec: {}'.format(perr))
  return int(pout)


def generate_fec_data(image_filename, num_roots):
  """Generate FEC codes for an image.

  Arguments:
    image_filename: The filename of the image.
    num_roots: Number of roots.

  Returns:
    The FEC data blob.

  Raises:
    ValueError: If output from the 'fec' tool is invalid.
  """
  fec_tmpfile = tempfile.NamedTemporaryFile()
  subprocess.check_call(
      ['fec', '--encode', '--roots', str(num_roots), image_filename,
       fec_tmpfile.name],
      stderr=open(os.devnull))
  fec_data = fec_tmpfile.read()
  footer_size = struct.calcsize(FEC_FOOTER_FORMAT)
  footer_data = fec_data[-footer_size:]
  (magic, _, _, num_roots, fec_size, _, _) = struct.unpack(FEC_FOOTER_FORMAT,
                                                           footer_data)
  if magic != FEC_MAGIC:
    raise ValueError('Unexpected magic in FEC footer')
  return fec_data[0:fec_size]


def generate_hash_tree(image, image_size, block_size, hash_alg_name, salt,
                       digest_padding, hash_level_offsets, tree_size):
  """Generates a Merkle-tree for a file.

  Arguments:
    image: The image, as a file.
    image_size: The size of the image.
    block_size: The block size, e.g. 4096.
    hash_alg_name: The hash algorithm, e.g. 'sha256' or 'sha1'.
    salt: The salt to use.
    digest_padding: The padding for each digest.
    hash_level_offsets: The offsets from calc_hash_level_offsets().
    tree_size: The size of the tree, in number of bytes.

  Returns:
    A tuple where the first element is the top-level hash and the
    second element is the hash-tree.
  """
  hash_ret = bytearray(tree_size)
  hash_src_offset = 0
  hash_src_size = image_size
  level_num = 0
  while hash_src_size > block_size:
    level_output = ''
    remaining = hash_src_size
    while remaining > 0:
      hasher = hashlib.new(name=hash_alg_name, string=salt)
      # Only read from the file for the first level - for subsequent
      # levels, access the array we're building.
      if level_num == 0:
        image.seek(hash_src_offset + hash_src_size - remaining)
        data = image.read(min(remaining, block_size))
      else:
        offset = hash_level_offsets[level_num - 1] + hash_src_size - remaining
        data = hash_ret[offset:offset + block_size]
      hasher.update(data)

      remaining -= len(data)
      if len(data) < block_size:
        hasher.update('\0' * (block_size - len(data)))
      level_output += hasher.digest()
      if digest_padding > 0:
        level_output += '\0' * digest_padding

    padding_needed = (round_to_multiple(
        len(level_output), block_size) - len(level_output))
    level_output += '\0' * padding_needed

    # Copy level-output into resulting tree.
    offset = hash_level_offsets[level_num]
    hash_ret[offset:offset + len(level_output)] = level_output

    # Continue on to the next level.
    hash_src_size = len(level_output)
    level_num += 1

  hasher = hashlib.new(name=hash_alg_name, string=salt)
  hasher.update(level_output)
  return hasher.digest(), hash_ret


class AvbTool(object):
  """Object for avbtool command-line tool."""

  def __init__(self):
    """Initializer method."""
    self.avb = Avb()

  def _add_common_args(self, sub_parser):
    """Adds arguments used by several sub-commands.

    Arguments:
      sub_parser: The parser to add arguments to.
    """
    sub_parser.add_argument('--algorithm',
                            help='Algorithm to use (default: NONE)',
                            metavar='ALGORITHM',
                            default='NONE')
    sub_parser.add_argument('--key',
                            help='Path to RSA private key file',
                            metavar='KEY',
                            required=False)
    sub_parser.add_argument('--signing_helper',
                            help='Path to helper used for signing',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--signing_helper_with_files',
                            help='Path to helper used for signing using files',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--public_key_metadata',
                            help='Path to public key metadata file',
                            metavar='KEY_METADATA',
                            required=False)
    sub_parser.add_argument('--rollback_index',
                            help='Rollback Index',
                            type=parse_number,
                            default=0)
    # This is used internally for unit tests. Do not include in --help output.
    sub_parser.add_argument('--internal_release_string',
                            help=argparse.SUPPRESS)
    sub_parser.add_argument('--append_to_release_string',
                            help='Text to append to release string',
                            metavar='STR')
    sub_parser.add_argument('--prop',
                            help='Add property',
                            metavar='KEY:VALUE',
                            action='append')
    sub_parser.add_argument('--prop_from_file',
                            help='Add property from file',
                            metavar='KEY:PATH',
                            action='append')
    sub_parser.add_argument('--kernel_cmdline',
                            help='Add kernel cmdline',
                            metavar='CMDLINE',
                            action='append')
    # TODO(zeuthen): the --setup_rootfs_from_kernel option used to be called
    # --generate_dm_verity_cmdline_from_hashtree. Remove support for the latter
    # at some future point.
    sub_parser.add_argument('--setup_rootfs_from_kernel',
                            '--generate_dm_verity_cmdline_from_hashtree',
                            metavar='IMAGE',
                            help='Adds kernel cmdline to set up IMAGE',
                            type=argparse.FileType('rb'))
    sub_parser.add_argument('--include_descriptors_from_image',
                            help='Include descriptors from image',
                            metavar='IMAGE',
                            action='append',
                            type=argparse.FileType('rb'))
    sub_parser.add_argument('--print_required_libavb_version',
                            help=('Don\'t store the footer - '
                                  'instead calculate the required libavb '
                                  'version for the given options.'),
                            action='store_true')
    # These are only allowed from top-level vbmeta and boot-in-lieu-of-vbmeta.
    sub_parser.add_argument('--chain_partition',
                            help='Allow signed integrity-data for partition',
                            metavar='PART_NAME:ROLLBACK_SLOT:KEY_PATH',
                            action='append')
    sub_parser.add_argument('--flags',
                            help='VBMeta flags',
                            type=parse_number,
                            default=0)
    sub_parser.add_argument('--set_hashtree_disabled_flag',
                            help='Set the HASHTREE_DISABLED flag',
                            action='store_true')

  def _add_common_footer_args(self, sub_parser):
    """Adds arguments used by add_*_footer sub-commands.

    Arguments:
      sub_parser: The parser to add arguments to.
    """
    sub_parser.add_argument('--use_persistent_digest',
                            help='Use a persistent digest on device instead of '
                                 'storing the digest in the descriptor. This '
                                 'cannot be used with A/B so must be combined '
                                 'with --do_not_use_ab when an A/B suffix is '
                                 'expected at runtime.',
                            action='store_true')
    sub_parser.add_argument('--do_not_use_ab',
                            help='The partition does not use A/B even when an '
                                 'A/B suffix is present. This must not be used '
                                 'for vbmeta or chained partitions.',
                            action='store_true')

  def _fixup_common_args(self, args):
    """Common fixups needed by subcommands.

    Arguments:
      args: Arguments to modify.

    Returns:
      The modified arguments.
    """
    if args.set_hashtree_disabled_flag:
      args.flags |= AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED
    return args

  def run(self, argv):
    """Command-line processor.

    Arguments:
      argv: Pass sys.argv from main.
    """
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(title='subcommands')

    sub_parser = subparsers.add_parser('version',
                                       help='Prints version of avbtool.')
    sub_parser.set_defaults(func=self.version)

    sub_parser = subparsers.add_parser('extract_public_key',
                                       help='Extract public key.')
    sub_parser.add_argument('--key',
                            help='Path to RSA private key file',
                            required=True)
    sub_parser.add_argument('--output',
                            help='Output file name',
                            type=argparse.FileType('wb'),
                            required=True)
    sub_parser.set_defaults(func=self.extract_public_key)

    sub_parser = subparsers.add_parser('make_vbmeta_image',
                                       help='Makes a vbmeta image.')
    sub_parser.add_argument('--output',
                            help='Output file name',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--padding_size',
                            metavar='NUMBER',
                            help='If non-zero, pads output with NUL bytes so '
                                 'its size is a multiple of NUMBER '
                                 '(default: 0)',
                            type=parse_number,
                            default=0)
    self._add_common_args(sub_parser)
    sub_parser.set_defaults(func=self.make_vbmeta_image)

    sub_parser = subparsers.add_parser('make_icp_from_vbmeta',
                                       help='Makes an ICP enhanced vbmeta image'
                                       ' from an existing vbmeta image.')
    sub_parser.add_argument('--output',
                            help='Output file name.',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--vbmeta_image_path',
                            help='Path to a generate vbmeta image file.')
    sub_parser.add_argument('--version_incremental', help='Current build ID.')
    sub_parser.add_argument('--manufacturer_key',
                            help='Path to the PEM file containing the '
                            'manufacturer key for use with the log.')
    sub_parser.add_argument('--transparency_log_servers',
                            help='List of transparency log servers in '
                            'host:port format. This must not be None and must '
                            'be the same size as transparency_log_pub_keys. '
                            'Also, transparency_log_servers[n] must correspond '
                            'to transparency_log_pub_keys[n] for all values n.',
                            nargs='*')
    sub_parser.add_argument('--transparency_log_pub_keys',
                            help='Paths to PEM files containing transparency '
                            'log server key(s). This must not be None and must '
                            'be the same size as transparency_log_servers. '
                            'Also, transparency_log_pub_keys[n] must '
                            'correspond to transparency_log_servers[n] for all '
                            'values n.', nargs='*')
    sub_parser.add_argument('--padding_size',
                            metavar='NUMBER',
                            help='If non-zero, pads output with NUL bytes so '
                            'its size is a multiple of NUMBER '
                            '(default: 0)',
                            type=parse_number,
                            default=0)
    self._add_common_args(sub_parser)
    sub_parser.set_defaults(func=self.make_icp_from_vbmeta)

    sub_parser = subparsers.add_parser('add_hash_footer',
                                       help='Add hashes and footer to image.')
    sub_parser.add_argument('--image',
                            help='Image to add hashes to',
                            type=argparse.FileType('rab+'))
    sub_parser.add_argument('--partition_size',
                            help='Partition size',
                            type=parse_number)
    sub_parser.add_argument('--partition_name',
                            help='Partition name',
                            default=None)
    sub_parser.add_argument('--hash_algorithm',
                            help='Hash algorithm to use (default: sha256)',
                            default='sha256')
    sub_parser.add_argument('--salt',
                            help='Salt in hex (default: /dev/urandom)')
    sub_parser.add_argument('--calc_max_image_size',
                            help=('Don\'t store the footer - '
                                  'instead calculate the maximum image size '
                                  'leaving enough room for metadata with '
                                  'the given partition size.'),
                            action='store_true')
    sub_parser.add_argument('--output_vbmeta_image',
                            help='Also write vbmeta struct to file',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--do_not_append_vbmeta_image',
                            help=('Do not append vbmeta struct or footer '
                                  'to the image'),
                            action='store_true')
    self._add_common_args(sub_parser)
    self._add_common_footer_args(sub_parser)
    sub_parser.set_defaults(func=self.add_hash_footer)

    sub_parser = subparsers.add_parser('append_vbmeta_image',
                                       help='Append vbmeta image to image.')
    sub_parser.add_argument('--image',
                            help='Image to append vbmeta blob to',
                            type=argparse.FileType('rab+'))
    sub_parser.add_argument('--partition_size',
                            help='Partition size',
                            type=parse_number,
                            required=True)
    sub_parser.add_argument('--vbmeta_image',
                            help='Image with vbmeta blob to append',
                            type=argparse.FileType('rb'))
    sub_parser.set_defaults(func=self.append_vbmeta_image)

    sub_parser = subparsers.add_parser(
        'add_hashtree_footer',
        help='Add hashtree and footer to image.')
    sub_parser.add_argument('--image',
                            help='Image to add hashtree to',
                            type=argparse.FileType('rab+'))
    sub_parser.add_argument('--partition_size',
                            help='Partition size',
                            default=0,
                            type=parse_number)
    sub_parser.add_argument('--partition_name',
                            help='Partition name',
                            default='')
    sub_parser.add_argument('--hash_algorithm',
                            help='Hash algorithm to use (default: sha1)',
                            default='sha1')
    sub_parser.add_argument('--salt',
                            help='Salt in hex (default: /dev/urandom)')
    sub_parser.add_argument('--block_size',
                            help='Block size (default: 4096)',
                            type=parse_number,
                            default=4096)
    # TODO(zeuthen): The --generate_fec option was removed when we
    # moved to generating FEC by default. To avoid breaking existing
    # users needing to transition we simply just print a warning below
    # in add_hashtree_footer(). Remove this option and the warning at
    # some point in the future.
    sub_parser.add_argument('--generate_fec',
                            help=argparse.SUPPRESS,
                            action='store_true')
    sub_parser.add_argument(
        '--do_not_generate_fec',
        help='Do not generate forward-error-correction codes',
        action='store_true')
    sub_parser.add_argument('--fec_num_roots',
                            help='Number of roots for FEC (default: 2)',
                            type=parse_number,
                            default=2)
    sub_parser.add_argument('--calc_max_image_size',
                            help=('Don\'t store the hashtree or footer - '
                                  'instead calculate the maximum image size '
                                  'leaving enough room for hashtree '
                                  'and metadata with the given partition '
                                  'size.'),
                            action='store_true')
    sub_parser.add_argument('--output_vbmeta_image',
                            help='Also write vbmeta struct to file',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--do_not_append_vbmeta_image',
                            help=('Do not append vbmeta struct or footer '
                                  'to the image'),
                            action='store_true')
    # This is different from --setup_rootfs_from_kernel insofar that
    # it doesn't take an IMAGE, the generated cmdline will be for the
    # hashtree we're adding.
    sub_parser.add_argument('--setup_as_rootfs_from_kernel',
                            action='store_true',
                            help='Adds kernel cmdline for setting up rootfs')
    sub_parser.add_argument('--no_hashtree',
                            action='store_true',
                            help='Do not append hashtree')
    self._add_common_args(sub_parser)
    self._add_common_footer_args(sub_parser)
    sub_parser.set_defaults(func=self.add_hashtree_footer)

    sub_parser = subparsers.add_parser('erase_footer',
                                       help='Erase footer from an image.')
    sub_parser.add_argument('--image',
                            help='Image with a footer',
                            type=argparse.FileType('rwb+'),
                            required=True)
    sub_parser.add_argument('--keep_hashtree',
                            help='Keep the hashtree and FEC in the image',
                            action='store_true')
    sub_parser.set_defaults(func=self.erase_footer)

    sub_parser = subparsers.add_parser('zero_hashtree',
                                       help='Zero out hashtree and FEC data.')
    sub_parser.add_argument('--image',
                            help='Image with a footer',
                            type=argparse.FileType('rwb+'),
                            required=True)
    sub_parser.set_defaults(func=self.zero_hashtree)

    sub_parser = subparsers.add_parser(
        'extract_vbmeta_image',
        help='Extracts vbmeta from an image with a footer.')
    sub_parser.add_argument('--image',
                            help='Image with footer',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--output',
                            help='Output file name',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--padding_size',
                            metavar='NUMBER',
                            help='If non-zero, pads output with NUL bytes so '
                                 'its size is a multiple of NUMBER '
                                 '(default: 0)',
                            type=parse_number,
                            default=0)
    sub_parser.set_defaults(func=self.extract_vbmeta_image)

    sub_parser = subparsers.add_parser('resize_image',
                                       help='Resize image with a footer.')
    sub_parser.add_argument('--image',
                            help='Image with a footer',
                            type=argparse.FileType('rwb+'),
                            required=True)
    sub_parser.add_argument('--partition_size',
                            help='New partition size',
                            type=parse_number)
    sub_parser.set_defaults(func=self.resize_image)

    sub_parser = subparsers.add_parser(
        'info_image',
        help='Show information about vbmeta or footer.')
    sub_parser.add_argument('--image',
                            help='Image to show information about',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--output',
                            help='Write info to file',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.info_image)

    sub_parser = subparsers.add_parser(
        'info_image_icp',
        help='Show information about AFTL ICPs in vbmeta or footer.')
    sub_parser.add_argument('--image',
                            help='Image to show information about',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--output',
                            help='Write info to file',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.info_image_icp)

    sub_parser = subparsers.add_parser(
        'verify_image',
        help='Verify an image.')
    sub_parser.add_argument('--image',
                            help='Image to verify',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--key',
                            help='Check embedded public key matches KEY',
                            metavar='KEY',
                            required=False)
    sub_parser.add_argument('--expected_chain_partition',
                            help='Expected chain partition',
                            metavar='PART_NAME:ROLLBACK_SLOT:KEY_PATH',
                            action='append')
    sub_parser.add_argument(
        '--follow_chain_partitions',
        help=('Follows chain partitions even when not '
              'specified with the --expected_chain_partition option'),
        action='store_true')
    sub_parser.add_argument(
        '--accept_zeroed_hashtree',
        help=('Accept images where the hashtree or FEC data is zeroed out'),
        action='store_true')
    sub_parser.set_defaults(func=self.verify_image)

    sub_parser = subparsers.add_parser(
        'calculate_vbmeta_digest',
        help='Calculate vbmeta digest.')
    sub_parser.add_argument('--image',
                            help='Image to calculate digest for',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--hash_algorithm',
                            help='Hash algorithm to use (default: sha256)',
                            default='sha256')
    sub_parser.add_argument('--output',
                            help='Write hex digest to file (default: stdout)',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.calculate_vbmeta_digest)

    sub_parser = subparsers.add_parser(
        'calculate_kernel_cmdline',
        help='Calculate kernel cmdline.')
    sub_parser.add_argument('--image',
                            help='Image to calculate kernel cmdline for',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--hashtree_disabled',
                            help='Return the cmdline for hashtree disabled',
                            action='store_true')
    sub_parser.add_argument('--output',
                            help='Write cmdline to file (default: stdout)',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.calculate_kernel_cmdline)

    sub_parser = subparsers.add_parser('set_ab_metadata',
                                       help='Set A/B metadata.')
    sub_parser.add_argument('--misc_image',
                            help=('The misc image to modify. If the image does '
                                  'not exist, it will be created.'),
                            type=argparse.FileType('r+b'),
                            required=True)
    sub_parser.add_argument('--slot_data',
                            help=('Slot data of the form "priority", '
                                  '"tries_remaining", "sucessful_boot" for '
                                  'slot A followed by the same for slot B, '
                                  'separated by colons. The default value '
                                  'is 15:7:0:14:7:0.'),
                            default='15:7:0:14:7:0')
    sub_parser.set_defaults(func=self.set_ab_metadata)

    sub_parser = subparsers.add_parser(
        'make_atx_certificate',
        help='Create an Android Things eXtension (ATX) certificate.')
    sub_parser.add_argument('--output',
                            help='Write certificate to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--subject',
                            help=('Path to subject file'),
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--subject_key',
                            help=('Path to subject RSA public key file'),
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--subject_key_version',
                            help=('Version of the subject key'),
                            type=parse_number,
                            required=False)
    sub_parser.add_argument('--subject_is_intermediate_authority',
                            help=('Generate an intermediate authority '
                                  'certificate'),
                            action='store_true')
    sub_parser.add_argument('--usage',
                            help=('Override usage with a hash of the provided '
                                  'string'),
                            required=False)
    sub_parser.add_argument('--authority_key',
                            help='Path to authority RSA private key file',
                            required=False)
    sub_parser.add_argument('--signing_helper',
                            help='Path to helper used for signing',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--signing_helper_with_files',
                            help='Path to helper used for signing using files',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.set_defaults(func=self.make_atx_certificate)

    sub_parser = subparsers.add_parser(
        'make_atx_permanent_attributes',
        help='Create Android Things eXtension (ATX) permanent attributes.')
    sub_parser.add_argument('--output',
                            help='Write attributes to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--root_authority_key',
                            help='Path to authority RSA public key file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--product_id',
                            help=('Path to Product ID file'),
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.set_defaults(func=self.make_atx_permanent_attributes)

    sub_parser = subparsers.add_parser(
        'make_atx_metadata',
        help='Create Android Things eXtension (ATX) metadata.')
    sub_parser.add_argument('--output',
                            help='Write metadata to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--intermediate_key_certificate',
                            help='Path to intermediate key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--product_key_certificate',
                            help='Path to product key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.set_defaults(func=self.make_atx_metadata)

    sub_parser = subparsers.add_parser(
        'make_atx_unlock_credential',
        help='Create an Android Things eXtension (ATX) unlock credential.')
    sub_parser.add_argument('--output',
                            help='Write credential to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--intermediate_key_certificate',
                            help='Path to intermediate key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--unlock_key_certificate',
                            help='Path to unlock key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--challenge',
                            help='Path to the challenge to sign (optional). If '
                                 'this is not provided the challenge signature '
                                 'field is omitted and can be concatenated '
                                 'later.',
                            required=False)
    sub_parser.add_argument('--unlock_key',
                            help='Path to unlock key (optional). Must be '
                                 'provided if using --challenge.',
                            required=False)
    sub_parser.add_argument('--signing_helper',
                            help='Path to helper used for signing',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--signing_helper_with_files',
                            help='Path to helper used for signing using files',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.set_defaults(func=self.make_atx_unlock_credential)

    args = parser.parse_args(argv[1:])
    try:
      args.func(args)
    except AvbError as e:
      sys.stderr.write('{}: {}\n'.format(argv[0], str(e)))
      sys.exit(1)

  def version(self, _):
    """Implements the 'version' sub-command."""
    print(get_release_string())

  def extract_public_key(self, args):
    """Implements the 'extract_public_key' sub-command."""
    self.avb.extract_public_key(args.key, args.output)

  def make_vbmeta_image(self, args):
    """Implements the 'make_vbmeta_image' sub-command."""
    args = self._fixup_common_args(args)
    self.avb.make_vbmeta_image(args.output, args.chain_partition,
                               args.algorithm, args.key,
                               args.public_key_metadata, args.rollback_index,
                               args.flags, args.prop, args.prop_from_file,
                               args.kernel_cmdline,
                               args.setup_rootfs_from_kernel,
                               args.include_descriptors_from_image,
                               args.signing_helper,
                               args.signing_helper_with_files,
                               args.internal_release_string,
                               args.append_to_release_string,
                               args.print_required_libavb_version,
                               args.padding_size)

  def make_icp_from_vbmeta(self, args):
    """Implements the 'make_icp_from_vbmeta' sub-command."""
    args = self._fixup_common_args(args)
    self.avb.make_icp_from_vbmeta(args.vbmeta_image_path,
                                  args.output, args.algorithm,
                                  args.signing_helper,
                                  args.signing_helper_with_files,
                                  args.version_incremental,
                                  args.transparency_log_servers,
                                  args.transparency_log_pub_keys,
                                  args.manufacturer_key,
                                  args.padding_size)

  def append_vbmeta_image(self, args):
    """Implements the 'append_vbmeta_image' sub-command."""
    self.avb.append_vbmeta_image(args.image.name, args.vbmeta_image.name,
                                 args.partition_size)

  def add_hash_footer(self, args):
    """Implements the 'add_hash_footer' sub-command."""
    args = self._fixup_common_args(args)
    self.avb.add_hash_footer(args.image.name if args.image else None,
                             args.partition_size,
                             args.partition_name, args.hash_algorithm,
                             args.salt, args.chain_partition, args.algorithm,
                             args.key,
                             args.public_key_metadata, args.rollback_index,
                             args.flags, args.prop, args.prop_from_file,
                             args.kernel_cmdline,
                             args.setup_rootfs_from_kernel,
                             args.include_descriptors_from_image,
                             args.calc_max_image_size,
                             args.signing_helper,
                             args.signing_helper_with_files,
                             args.internal_release_string,
                             args.append_to_release_string,
                             args.output_vbmeta_image,
                             args.do_not_append_vbmeta_image,
                             args.print_required_libavb_version,
                             args.use_persistent_digest,
                             args.do_not_use_ab)

  def add_hashtree_footer(self, args):
    """Implements the 'add_hashtree_footer' sub-command."""
    args = self._fixup_common_args(args)
    # TODO(zeuthen): Remove when removing support for the
    # '--generate_fec' option above.
    if args.generate_fec:
      sys.stderr.write('The --generate_fec option is deprecated since FEC '
                       'is now generated by default. Use the option '
                       '--do_not_generate_fec to not generate FEC.\n')
    self.avb.add_hashtree_footer(
        args.image.name if args.image else None,
        args.partition_size,
        args.partition_name,
        not args.do_not_generate_fec, args.fec_num_roots,
        args.hash_algorithm, args.block_size,
        args.salt, args.chain_partition, args.algorithm,
        args.key, args.public_key_metadata,
        args.rollback_index, args.flags, args.prop,
        args.prop_from_file,
        args.kernel_cmdline,
        args.setup_rootfs_from_kernel,
        args.setup_as_rootfs_from_kernel,
        args.include_descriptors_from_image,
        args.calc_max_image_size,
        args.signing_helper,
        args.signing_helper_with_files,
        args.internal_release_string,
        args.append_to_release_string,
        args.output_vbmeta_image,
        args.do_not_append_vbmeta_image,
        args.print_required_libavb_version,
        args.use_persistent_digest,
        args.do_not_use_ab,
        args.no_hashtree)

  def erase_footer(self, args):
    """Implements the 'erase_footer' sub-command."""
    self.avb.erase_footer(args.image.name, args.keep_hashtree)

  def zero_hashtree(self, args):
    """Implements the 'zero_hashtree' sub-command."""
    self.avb.zero_hashtree(args.image.name)

  def extract_vbmeta_image(self, args):
    """Implements the 'extract_vbmeta_image' sub-command."""
    self.avb.extract_vbmeta_image(args.output, args.image.name,
                                  args.padding_size)

  def resize_image(self, args):
    """Implements the 'resize_image' sub-command."""
    self.avb.resize_image(args.image.name, args.partition_size)

  def set_ab_metadata(self, args):
    """Implements the 'set_ab_metadata' sub-command."""
    self.avb.set_ab_metadata(args.misc_image, args.slot_data)

  def info_image(self, args):
    """Implements the 'info_image' sub-command."""
    self.avb.info_image(args.image.name, args.output)

  def info_image_icp(self, args):
    """Implements the 'info_image_icp' sub-command."""
    self.avb.info_image_icp(args.image.name, args.output)

  def verify_image(self, args):
    """Implements the 'verify_image' sub-command."""
    self.avb.verify_image(args.image.name, args.key,
                          args.expected_chain_partition,
                          args.follow_chain_partitions,
                          args.accept_zeroed_hashtree)

  def calculate_vbmeta_digest(self, args):
    """Implements the 'calculate_vbmeta_digest' sub-command."""
    self.avb.calculate_vbmeta_digest(args.image.name, args.hash_algorithm,
                                     args.output)

  def calculate_kernel_cmdline(self, args):
    """Implements the 'calculate_kernel_cmdline' sub-command."""
    self.avb.calculate_kernel_cmdline(args.image.name, args.hashtree_disabled,
                                      args.output)

  def make_atx_certificate(self, args):
    """Implements the 'make_atx_certificate' sub-command."""
    self.avb.make_atx_certificate(args.output, args.authority_key,
                                  args.subject_key.name,
                                  args.subject_key_version,
                                  args.subject.read(),
                                  args.subject_is_intermediate_authority,
                                  args.usage,
                                  args.signing_helper,
                                  args.signing_helper_with_files)

  def make_atx_permanent_attributes(self, args):
    """Implements the 'make_atx_permanent_attributes' sub-command."""
    self.avb.make_atx_permanent_attributes(args.output,
                                           args.root_authority_key.name,
                                           args.product_id.read())

  def make_atx_metadata(self, args):
    """Implements the 'make_atx_metadata' sub-command."""
    self.avb.make_atx_metadata(args.output,
                               args.intermediate_key_certificate.read(),
                               args.product_key_certificate.read())

  def make_atx_unlock_credential(self, args):
    """Implements the 'make_atx_unlock_credential' sub-command."""
    self.avb.make_atx_unlock_credential(
        args.output,
        args.intermediate_key_certificate.read(),
        args.unlock_key_certificate.read(),
        args.challenge,
        args.unlock_key,
        args.signing_helper,
        args.signing_helper_with_files)


if __name__ == '__main__':
  tool = AvbTool()
  tool.run(sys.argv)

```

`aosp/avb/avbtool.v1.2.py`:

```py
#!/usr/bin/env python3

# Copyright 2016, The Android Open Source Project
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without
# restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
"""Command-line tool for working with Android Verified Boot images."""

import argparse
import binascii
import bisect
import hashlib
import json
import math
import os
import struct
import subprocess
import sys
import tempfile
import time

# Keep in sync with libavb/avb_version.h.
AVB_VERSION_MAJOR = 1
AVB_VERSION_MINOR = 2
AVB_VERSION_SUB = 0

# Keep in sync with libavb/avb_footer.h.
AVB_FOOTER_VERSION_MAJOR = 1
AVB_FOOTER_VERSION_MINOR = 0

AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED = 1

# Configuration for enabling logging of calls to avbtool.
AVB_INVOCATION_LOGFILE = os.environ.get('AVB_INVOCATION_LOGFILE')


class AvbError(Exception):
  """Application-specific errors.

  These errors represent issues for which a stack-trace should not be
  presented.

  Attributes:
    message: Error message.
  """

  def __init__(self, message):
    Exception.__init__(self, message)


class Algorithm(object):
  """Contains details about an algorithm.

  See the avb_vbmeta_image.h file for more details about algorithms.

  The constant |ALGORITHMS| is a dictionary from human-readable
  names (e.g 'SHA256_RSA2048') to instances of this class.

  Attributes:
    algorithm_type: Integer code corresponding to |AvbAlgorithmType|.
    hash_name: Empty or a name from |hashlib.algorithms|.
    hash_num_bytes: Number of bytes used to store the hash.
    signature_num_bytes: Number of bytes used to store the signature.
    public_key_num_bytes: Number of bytes used to store the public key.
    padding: Padding used for signature as bytes, if any.
  """

  def __init__(self, algorithm_type, hash_name, hash_num_bytes,
               signature_num_bytes, public_key_num_bytes, padding):
    self.algorithm_type = algorithm_type
    self.hash_name = hash_name
    self.hash_num_bytes = hash_num_bytes
    self.signature_num_bytes = signature_num_bytes
    self.public_key_num_bytes = public_key_num_bytes
    self.padding = padding


# This must be kept in sync with the avb_crypto.h file.
#
# The PKC1-v1.5 padding is a blob of binary DER of ASN.1 and is
# obtained from section 5.2.2 of RFC 4880.
ALGORITHMS = {
    'NONE': Algorithm(
        algorithm_type=0,        # AVB_ALGORITHM_TYPE_NONE
        hash_name='',
        hash_num_bytes=0,
        signature_num_bytes=0,
        public_key_num_bytes=0,
        padding=b''),
    'SHA256_RSA2048': Algorithm(
        algorithm_type=1,        # AVB_ALGORITHM_TYPE_SHA256_RSA2048
        hash_name='sha256',
        hash_num_bytes=32,
        signature_num_bytes=256,
        public_key_num_bytes=8 + 2*2048//8,
        padding=bytes(bytearray([
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*202 + [0x00] + [
                # ASN.1 header
                0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                0x00, 0x04, 0x20,
            ]))),
    'SHA256_RSA4096': Algorithm(
        algorithm_type=2,        # AVB_ALGORITHM_TYPE_SHA256_RSA4096
        hash_name='sha256',
        hash_num_bytes=32,
        signature_num_bytes=512,
        public_key_num_bytes=8 + 2*4096//8,
        padding=bytes(bytearray([
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*458 + [0x00] + [
                # ASN.1 header
                0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                0x00, 0x04, 0x20,
            ]))),
    'SHA256_RSA8192': Algorithm(
        algorithm_type=3,        # AVB_ALGORITHM_TYPE_SHA256_RSA8192
        hash_name='sha256',
        hash_num_bytes=32,
        signature_num_bytes=1024,
        public_key_num_bytes=8 + 2*8192//8,
        padding=bytes(bytearray([
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*970 + [0x00] + [
                # ASN.1 header
                0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                0x00, 0x04, 0x20,
            ]))),
    'SHA512_RSA2048': Algorithm(
        algorithm_type=4,        # AVB_ALGORITHM_TYPE_SHA512_RSA2048
        hash_name='sha512',
        hash_num_bytes=64,
        signature_num_bytes=256,
        public_key_num_bytes=8 + 2*2048//8,
        padding=bytes(bytearray([
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*170 + [0x00] + [
                # ASN.1 header
                0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                0x00, 0x04, 0x40
            ]))),
    'SHA512_RSA4096': Algorithm(
        algorithm_type=5,        # AVB_ALGORITHM_TYPE_SHA512_RSA4096
        hash_name='sha512',
        hash_num_bytes=64,
        signature_num_bytes=512,
        public_key_num_bytes=8 + 2*4096//8,
        padding=bytes(bytearray([
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*426 + [0x00] + [
                # ASN.1 header
                0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                0x00, 0x04, 0x40
            ]))),
    'SHA512_RSA8192': Algorithm(
        algorithm_type=6,        # AVB_ALGORITHM_TYPE_SHA512_RSA8192
        hash_name='sha512',
        hash_num_bytes=64,
        signature_num_bytes=1024,
        public_key_num_bytes=8 + 2*8192//8,
        padding=bytes(bytearray([
            # PKCS1-v1_5 padding
            0x00, 0x01] + [0xff]*938 + [0x00] + [
                # ASN.1 header
                0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                0x00, 0x04, 0x40
            ]))),
}


def get_release_string():
  """Calculates the release string to use in the VBMeta struct."""
  # Keep in sync with libavb/avb_version.c:avb_version_string().
  return 'avbtool {}.{}.{}'.format(AVB_VERSION_MAJOR,
                                   AVB_VERSION_MINOR,
                                   AVB_VERSION_SUB)


def round_to_multiple(number, size):
  """Rounds a number up to nearest multiple of another number.

  Arguments:
    number: The number to round up.
    size: The multiple to round up to.

  Returns:
    If |number| is a multiple of |size|, returns |number|, otherwise
    returns |number| + |size|.
  """
  remainder = number % size
  if remainder == 0:
    return number
  return number + size - remainder


def round_to_pow2(number):
  """Rounds a number up to the next power of 2.

  Arguments:
    number: The number to round up.

  Returns:
    If |number| is already a power of 2 then |number| is
    returned. Otherwise the smallest power of 2 greater than |number|
    is returned.
  """
  return 2**((number - 1).bit_length())


def encode_long(num_bits, value):
  """Encodes a long to a bytearray() using a given amount of bits.

  This number is written big-endian, e.g. with the most significant
  bit first.

  This is the reverse of decode_long().

  Arguments:
    num_bits: The number of bits to write, e.g. 2048.
    value: The value to write.

  Returns:
    A bytearray() with the encoded long.
  """
  ret = bytearray()
  for bit_pos in range(num_bits, 0, -8):
    octet = (value >> (bit_pos - 8)) & 0xff
    ret.extend(struct.pack('!B', octet))
  return ret


def decode_long(blob):
  """Decodes a long from a bytearray() using a given amount of bits.

  This number is expected to be in big-endian, e.g. with the most
  significant bit first.

  This is the reverse of encode_long().

  Arguments:
    blob: A bytearray() with the encoded long.

  Returns:
    The decoded value.
  """
  ret = 0
  for b in bytearray(blob):
    ret *= 256
    ret += b
  return ret


def egcd(a, b):
  """Calculate greatest common divisor of two numbers.

  This implementation uses a recursive version of the extended
  Euclidian algorithm.

  Arguments:
    a: First number.
    b: Second number.

  Returns:
    A tuple (gcd, x, y) that where |gcd| is the greatest common
    divisor of |a| and |b| and |a|*|x| + |b|*|y| = |gcd|.
  """
  if a == 0:
    return (b, 0, 1)
  g, y, x = egcd(b % a, a)
  return (g, x - (b // a) * y, y)


def modinv(a, m):
  """Calculate modular multiplicative inverse of |a| modulo |m|.

  This calculates the number |x| such that |a| * |x| == 1 (modulo
  |m|). This number only exists if |a| and |m| are co-prime - |None|
  is returned if this isn't true.

  Arguments:
    a: The number to calculate a modular inverse of.
    m: The modulo to use.

  Returns:
    The modular multiplicative inverse of |a| and |m| or |None| if
    these numbers are not co-prime.
  """
  gcd, x, _ = egcd(a, m)
  if gcd != 1:
    return None  # modular inverse does not exist
  return x % m


def parse_number(string):
  """Parse a string as a number.

  This is just a short-hand for int(string, 0) suitable for use in the
  |type| parameter of |ArgumentParser|'s add_argument() function. An
  improvement to just using type=int is that this function supports
  numbers in other bases, e.g. "0x1234".

  Arguments:
    string: The string to parse.

  Returns:
    The parsed integer.

  Raises:
    ValueError: If the number could not be parsed.
  """
  return int(string, 0)


class RSAPublicKey(object):
  """Data structure used for a RSA public key.

  Attributes:
    exponent: The key exponent.
    modulus: The key modulus.
    num_bits: The key size.
    key_path: The path to a key file.
  """

  MODULUS_PREFIX = b'modulus='

  def __init__(self, key_path):
    """Loads and parses an RSA key from either a private or public key file.

    Arguments:
      key_path: The path to a key file.

    Raises:
      AvbError: If RSA key parameters could not be read from file.
    """
    # We used to have something as simple as this:
    #
    #  key = Crypto.PublicKey.RSA.importKey(open(key_path).read())
    #  self.exponent = key.e
    #  self.modulus = key.n
    #  self.num_bits = key.size() + 1
    #
    # but unfortunately PyCrypto is not available in the builder. So
    # instead just parse openssl(1) output to get this
    # information. It's ugly but...
    args = ['openssl', 'rsa', '-in', key_path, '-modulus', '-noout']
    p = subprocess.Popen(args,
                         stdin=subprocess.PIPE,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE)
    (pout, perr) = p.communicate()
    if p.wait() != 0:
      # Could be just a public key is passed, try that.
      args.append('-pubin')
      p = subprocess.Popen(args,
                           stdin=subprocess.PIPE,
                           stdout=subprocess.PIPE,
                           stderr=subprocess.PIPE)
      (pout, perr) = p.communicate()
      if p.wait() != 0:
        raise AvbError('Error getting public key: {}'.format(perr))

    if not pout.lower().startswith(self.MODULUS_PREFIX):
      raise AvbError('Unexpected modulus output')

    modulus_hexstr = pout[len(self.MODULUS_PREFIX):]

    # The exponent is assumed to always be 65537 and the number of
    # bits can be derived from the modulus by rounding up to the
    # nearest power of 2.
    self.key_path = key_path
    self.modulus = int(modulus_hexstr, 16)
    self.num_bits = round_to_pow2(int(math.ceil(math.log(self.modulus, 2))))
    self.exponent = 65537

  def encode(self):
    """Encodes the public RSA key in |AvbRSAPublicKeyHeader| format.

    This creates a |AvbRSAPublicKeyHeader| as well as the two large
    numbers (|key_num_bits| bits long) following it.

    Returns:
      The |AvbRSAPublicKeyHeader| followed by two large numbers as bytes.

    Raises:
      AvbError: If given RSA key exponent is not 65537.
    """
    if self.exponent != 65537:
      raise AvbError('Only RSA keys with exponent 65537 are supported.')
    ret = bytearray()
    # Calculate n0inv = -1/n[0] (mod 2^32)
    b = 2 ** 32
    n0inv = b - modinv(self.modulus, b)
    # Calculate rr = r^2 (mod N), where r = 2^(# of key bits)
    r = 2 ** self.modulus.bit_length()
    rrmodn = r * r % self.modulus
    ret.extend(struct.pack('!II', self.num_bits, n0inv))
    ret.extend(encode_long(self.num_bits, self.modulus))
    ret.extend(encode_long(self.num_bits, rrmodn))
    return bytes(ret)

  def sign(self, algorithm_name, data_to_sign, signing_helper=None,
           signing_helper_with_files=None):
    """Sign given data using |signing_helper| or openssl.

    openssl is used if neither the parameters signing_helper nor
    signing_helper_with_files are given.

    Arguments:
      algorithm_name: The algorithm name as per the ALGORITHMS dict.
      data_to_sign: Data to sign as bytes or bytearray.
      signing_helper: Program which signs a hash and returns the signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.

    Returns:
      The signature as bytes.

    Raises:
      AvbError: If an error occurred during signing.
    """
    # Checks requested algorithm for validity.
    algorithm = ALGORITHMS.get(algorithm_name)
    if not algorithm:
      raise AvbError('Algorithm with name {} is not supported.'
                     .format(algorithm_name))

    if self.num_bits != (algorithm.signature_num_bytes * 8):
      raise AvbError('Key size of key ({} bits) does not match key size '
                     '({} bits) of given algorithm {}.'
                     .format(self.num_bits, algorithm.signature_num_bytes * 8,
                             algorithm_name))

    # Hashes the data.
    hasher = hashlib.new(algorithm.hash_name)
    hasher.update(data_to_sign)
    digest = hasher.digest()

    # Calculates the signature.
    padding_and_hash = algorithm.padding + digest
    p = None
    if signing_helper_with_files is not None:
      with tempfile.NamedTemporaryFile() as signing_file:
        signing_file.write(padding_and_hash)
        signing_file.flush()
        p = subprocess.Popen([signing_helper_with_files, algorithm_name,
                              self.key_path, signing_file.name])
        retcode = p.wait()
        if retcode != 0:
          raise AvbError('Error signing')
        signing_file.seek(0)
        signature = signing_file.read()
    else:
      if signing_helper is not None:
        p = subprocess.Popen(
            [signing_helper, algorithm_name, self.key_path],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE)
      else:
        p = subprocess.Popen(
            ['openssl', 'rsautl', '-sign', '-inkey', self.key_path, '-raw'],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE)
      (pout, perr) = p.communicate(padding_and_hash)
      retcode = p.wait()
      if retcode != 0:
        raise AvbError('Error signing: {}'.format(perr))
      signature = pout
    if len(signature) != algorithm.signature_num_bytes:
      raise AvbError('Error signing: Invalid length of signature')
    return signature


def lookup_algorithm_by_type(alg_type):
  """Looks up algorithm by type.

  Arguments:
    alg_type: The integer representing the type.

  Returns:
    A tuple with the algorithm name and an |Algorithm| instance.

  Raises:
    Exception: If the algorithm cannot be found
  """
  for alg_name in ALGORITHMS:
    alg_data = ALGORITHMS[alg_name]
    if alg_data.algorithm_type == alg_type:
      return (alg_name, alg_data)
  raise AvbError('Unknown algorithm type {}'.format(alg_type))


def lookup_hash_size_by_type(alg_type):
  """Looks up hash size by type.

  Arguments:
    alg_type: The integer representing the type.

  Returns:
    The corresponding hash size.

  Raises:
    AvbError: If the algorithm cannot be found.
  """
  for alg_name in ALGORITHMS:
    alg_data = ALGORITHMS[alg_name]
    if alg_data.algorithm_type == alg_type:
      return alg_data.hash_num_bytes
  raise AvbError('Unsupported algorithm type {}'.format(alg_type))


def verify_vbmeta_signature(vbmeta_header, vbmeta_blob):
  """Checks that signature in a vbmeta blob was made by the embedded public key.

  Arguments:
    vbmeta_header: A AvbVBMetaHeader.
    vbmeta_blob: The whole vbmeta blob, including the header as bytes or
        bytearray.

  Returns:
    True if the signature is valid and corresponds to the embedded
    public key. Also returns True if the vbmeta blob is not signed.

  Raises:
    AvbError: If there errors calling out to openssl command during
        signature verification.
  """
  (_, alg) = lookup_algorithm_by_type(vbmeta_header.algorithm_type)
  if not alg.hash_name:
    return True
  header_blob = vbmeta_blob[0:256]
  auth_offset = 256
  aux_offset = auth_offset + vbmeta_header.authentication_data_block_size
  aux_size = vbmeta_header.auxiliary_data_block_size
  aux_blob = vbmeta_blob[aux_offset:aux_offset + aux_size]
  pubkey_offset = aux_offset + vbmeta_header.public_key_offset
  pubkey_size = vbmeta_header.public_key_size
  pubkey_blob = vbmeta_blob[pubkey_offset:pubkey_offset + pubkey_size]

  digest_offset = auth_offset + vbmeta_header.hash_offset
  digest_size = vbmeta_header.hash_size
  digest_blob = vbmeta_blob[digest_offset:digest_offset + digest_size]

  sig_offset = auth_offset + vbmeta_header.signature_offset
  sig_size = vbmeta_header.signature_size
  sig_blob = vbmeta_blob[sig_offset:sig_offset + sig_size]

  # Now that we've got the stored digest, public key, and signature
  # all we need to do is to verify. This is the exactly the same
  # steps as performed in the avb_vbmeta_image_verify() function in
  # libavb/avb_vbmeta_image.c.

  ha = hashlib.new(alg.hash_name)
  ha.update(header_blob)
  ha.update(aux_blob)
  computed_digest = ha.digest()

  if computed_digest != digest_blob:
    return False

  padding_and_digest = alg.padding + computed_digest

  (num_bits,) = struct.unpack('!I', pubkey_blob[0:4])
  modulus_blob = pubkey_blob[8:8 + num_bits//8]
  modulus = decode_long(modulus_blob)
  exponent = 65537

  # We used to have this:
  #
  #  import Crypto.PublicKey.RSA
  #  key = Crypto.PublicKey.RSA.construct((modulus, long(exponent)))
  #  if not key.verify(decode_long(padding_and_digest),
  #                    (decode_long(sig_blob), None)):
  #    return False
  #  return True
  #
  # but since 'avbtool verify_image' is used on the builders we don't want
  # to rely on Crypto.PublicKey.RSA. Instead just use openssl(1) to verify.
  asn1_str = ('asn1=SEQUENCE:pubkeyinfo\n'
              '\n'
              '[pubkeyinfo]\n'
              'algorithm=SEQUENCE:rsa_alg\n'
              'pubkey=BITWRAP,SEQUENCE:rsapubkey\n'
              '\n'
              '[rsa_alg]\n'
              'algorithm=OID:rsaEncryption\n'
              'parameter=NULL\n'
              '\n'
              '[rsapubkey]\n'
              'n=INTEGER:{}\n'
              'e=INTEGER:{}\n').format(hex(modulus).rstrip('L'),
                                       hex(exponent).rstrip('L'))

  with tempfile.NamedTemporaryFile() as asn1_tmpfile:
    asn1_tmpfile.write(asn1_str.encode('ascii'))
    asn1_tmpfile.flush()

    with tempfile.NamedTemporaryFile() as der_tmpfile:
      p = subprocess.Popen(
          ['openssl', 'asn1parse', '-genconf', asn1_tmpfile.name, '-out',
           der_tmpfile.name, '-noout'])
      retcode = p.wait()
      if retcode != 0:
        raise AvbError('Error generating DER file')

      p = subprocess.Popen(
          ['openssl', 'rsautl', '-verify', '-pubin', '-inkey', der_tmpfile.name,
           '-keyform', 'DER', '-raw'],
          stdin=subprocess.PIPE,
          stdout=subprocess.PIPE,
          stderr=subprocess.PIPE)
      (pout, perr) = p.communicate(sig_blob)
      retcode = p.wait()
      if retcode != 0:
        raise AvbError('Error verifying data: {}'.format(perr))
      if pout != padding_and_digest:
        sys.stderr.write('Signature not correct\n')
        return False
  return True


def create_avb_hashtree_hasher(algorithm, salt):
  """Create the hasher for AVB hashtree based on the input algorithm."""

  if algorithm.lower() == 'blake2b-256':
    return hashlib.new('blake2b', salt, digest_size=32)

  return hashlib.new(algorithm, salt)


class ImageChunk(object):
  """Data structure used for representing chunks in Android sparse files.

  Attributes:
    chunk_type: One of TYPE_RAW, TYPE_FILL, or TYPE_DONT_CARE.
    chunk_offset: Offset in the sparse file where this chunk begins.
    output_offset: Offset in de-sparsified file where output begins.
    output_size: Number of bytes in output.
    input_offset: Offset in sparse file for data if TYPE_RAW otherwise None.
    fill_data: Blob with data to fill if TYPE_FILL otherwise None.
  """

  FORMAT = '<2H2I'
  TYPE_RAW = 0xcac1
  TYPE_FILL = 0xcac2
  TYPE_DONT_CARE = 0xcac3
  TYPE_CRC32 = 0xcac4

  def __init__(self, chunk_type, chunk_offset, output_offset, output_size,
               input_offset, fill_data):
    """Initializes an ImageChunk object.

    Arguments:
      chunk_type: One of TYPE_RAW, TYPE_FILL, or TYPE_DONT_CARE.
      chunk_offset: Offset in the sparse file where this chunk begins.
      output_offset: Offset in de-sparsified file.
      output_size: Number of bytes in output.
      input_offset: Offset in sparse file if TYPE_RAW otherwise None.
      fill_data: Blob as bytes with data to fill if TYPE_FILL otherwise None.

    Raises:
      ValueError: If given chunk parameters are invalid.
    """
    self.chunk_type = chunk_type
    self.chunk_offset = chunk_offset
    self.output_offset = output_offset
    self.output_size = output_size
    self.input_offset = input_offset
    self.fill_data = fill_data
    # Check invariants.
    if self.chunk_type == self.TYPE_RAW:
      if self.fill_data is not None:
        raise ValueError('RAW chunk cannot have fill_data set.')
      if not self.input_offset:
        raise ValueError('RAW chunk must have input_offset set.')
    elif self.chunk_type == self.TYPE_FILL:
      if self.fill_data is None:
        raise ValueError('FILL chunk must have fill_data set.')
      if self.input_offset:
        raise ValueError('FILL chunk cannot have input_offset set.')
    elif self.chunk_type == self.TYPE_DONT_CARE:
      if self.fill_data is not None:
        raise ValueError('DONT_CARE chunk cannot have fill_data set.')
      if self.input_offset:
        raise ValueError('DONT_CARE chunk cannot have input_offset set.')
    else:
      raise ValueError('Invalid chunk type')


class ImageHandler(object):
  """Abstraction for image I/O with support for Android sparse images.

  This class provides an interface for working with image files that
  may be using the Android Sparse Image format. When an instance is
  constructed, we test whether it's an Android sparse file. If so,
  operations will be on the sparse file by interpreting the sparse
  format, otherwise they will be directly on the file. Either way the
  operations do the same.

  For reading, this interface mimics a file object - it has seek(),
  tell(), and read() methods. For writing, only truncation
  (truncate()) and appending is supported (append_raw() and
  append_dont_care()). Additionally, data can only be written in units
  of the block size.

  Attributes:
    filename: Name of file.
    is_sparse: Whether the file being operated on is sparse.
    block_size: The block size, typically 4096.
    image_size: The size of the unsparsified file.
  """
  # See system/core/libsparse/sparse_format.h for details.
  MAGIC = 0xed26ff3a
  HEADER_FORMAT = '<I4H4I'

  # These are formats and offset of just the |total_chunks| and
  # |total_blocks| fields.
  NUM_CHUNKS_AND_BLOCKS_FORMAT = '<II'
  NUM_CHUNKS_AND_BLOCKS_OFFSET = 16

  def __init__(self, image_filename, read_only=False):
    """Initializes an image handler.

    Arguments:
      image_filename: The name of the file to operate on.
      read_only: True if file is only opened for read-only operations.

    Raises:
      ValueError: If data in the file is invalid.
    """
    self.filename = image_filename
    self._num_total_blocks = 0
    self._num_total_chunks = 0
    self._file_pos = 0
    self._read_only = read_only
    self._read_header()

  def _read_header(self):
    """Initializes internal data structures used for reading file.

    This may be called multiple times and is typically called after
    modifying the file (e.g. appending, truncation).

    Raises:
      ValueError: If data in the file is invalid.
    """
    self.is_sparse = False
    self.block_size = 4096
    self._file_pos = 0
    if self._read_only:
      self._image = open(self.filename, 'rb')
    else:
      self._image = open(self.filename, 'r+b')
    self._image.seek(0, os.SEEK_END)
    self.image_size = self._image.tell()

    self._image.seek(0, os.SEEK_SET)
    header_bin = self._image.read(struct.calcsize(self.HEADER_FORMAT))
    (magic, major_version, minor_version, file_hdr_sz, chunk_hdr_sz,
     block_size, self._num_total_blocks, self._num_total_chunks,
     _) = struct.unpack(self.HEADER_FORMAT, header_bin)
    if magic != self.MAGIC:
      # Not a sparse image, our job here is done.
      return
    if not (major_version == 1 and minor_version == 0):
      raise ValueError('Encountered sparse image format version {}.{} but '
                       'only 1.0 is supported'.format(major_version,
                                                      minor_version))
    if file_hdr_sz != struct.calcsize(self.HEADER_FORMAT):
      raise ValueError('Unexpected file_hdr_sz value {}.'.
                       format(file_hdr_sz))
    if chunk_hdr_sz != struct.calcsize(ImageChunk.FORMAT):
      raise ValueError('Unexpected chunk_hdr_sz value {}.'.
                       format(chunk_hdr_sz))

    self.block_size = block_size

    # Build an list of chunks by parsing the file.
    self._chunks = []

    # Find the smallest offset where only "Don't care" chunks
    # follow. This will be the size of the content in the sparse
    # image.
    offset = 0
    output_offset = 0
    for _ in range(1, self._num_total_chunks + 1):
      chunk_offset = self._image.tell()

      header_bin = self._image.read(struct.calcsize(ImageChunk.FORMAT))
      (chunk_type, _, chunk_sz, total_sz) = struct.unpack(ImageChunk.FORMAT,
                                                          header_bin)
      data_sz = total_sz - struct.calcsize(ImageChunk.FORMAT)

      if chunk_type == ImageChunk.TYPE_RAW:
        if data_sz != (chunk_sz * self.block_size):
          raise ValueError('Raw chunk input size ({}) does not match output '
                           'size ({})'.
                           format(data_sz, chunk_sz*self.block_size))
        self._chunks.append(ImageChunk(ImageChunk.TYPE_RAW,
                                       chunk_offset,
                                       output_offset,
                                       chunk_sz*self.block_size,
                                       self._image.tell(),
                                       None))
        self._image.seek(data_sz, os.SEEK_CUR)

      elif chunk_type == ImageChunk.TYPE_FILL:
        if data_sz != 4:
          raise ValueError('Fill chunk should have 4 bytes of fill, but this '
                           'has {}'.format(data_sz))
        fill_data = self._image.read(4)
        self._chunks.append(ImageChunk(ImageChunk.TYPE_FILL,
                                       chunk_offset,
                                       output_offset,
                                       chunk_sz*self.block_size,
                                       None,
                                       fill_data))
      elif chunk_type == ImageChunk.TYPE_DONT_CARE:
        if data_sz != 0:
          raise ValueError('Don\'t care chunk input size is non-zero ({})'.
                           format(data_sz))
        self._chunks.append(ImageChunk(ImageChunk.TYPE_DONT_CARE,
                                       chunk_offset,
                                       output_offset,
                                       chunk_sz*self.block_size,
                                       None,
                                       None))
      elif chunk_type == ImageChunk.TYPE_CRC32:
        if data_sz != 4:
          raise ValueError('CRC32 chunk should have 4 bytes of CRC, but '
                           'this has {}'.format(data_sz))
        self._image.read(4)
      else:
        raise ValueError('Unknown chunk type {}'.format(chunk_type))

      offset += chunk_sz
      output_offset += chunk_sz*self.block_size

    # Record where sparse data end.
    self._sparse_end = self._image.tell()

    # Now that we've traversed all chunks, sanity check.
    if self._num_total_blocks != offset:
      raise ValueError('The header said we should have {} output blocks, '
                       'but we saw {}'.format(self._num_total_blocks, offset))
    junk_len = len(self._image.read())
    if junk_len > 0:
      raise ValueError('There were {} bytes of extra data at the end of the '
                       'file.'.format(junk_len))

    # Assign |image_size|.
    self.image_size = output_offset

    # This is used when bisecting in read() to find the initial slice.
    self._chunk_output_offsets = [i.output_offset for i in self._chunks]

    self.is_sparse = True

  def _update_chunks_and_blocks(self):
    """Helper function to update the image header.

    The the |total_chunks| and |total_blocks| fields in the header
    will be set to value of the |_num_total_blocks| and
    |_num_total_chunks| attributes.

    """
    self._image.seek(self.NUM_CHUNKS_AND_BLOCKS_OFFSET, os.SEEK_SET)
    self._image.write(struct.pack(self.NUM_CHUNKS_AND_BLOCKS_FORMAT,
                                  self._num_total_blocks,
                                  self._num_total_chunks))

  def append_dont_care(self, num_bytes):
    """Appends a DONT_CARE chunk to the sparse file.

    The given number of bytes must be a multiple of the block size.

    Arguments:
      num_bytes: Size in number of bytes of the DONT_CARE chunk.

    Raises:
      OSError: If ImageHandler was initialized in read-only mode.
    """
    assert num_bytes % self.block_size == 0

    if self._read_only:
      raise OSError('ImageHandler is in read-only mode.')

    if not self.is_sparse:
      self._image.seek(0, os.SEEK_END)
      # This is more efficient that writing NUL bytes since it'll add
      # a hole on file systems that support sparse files (native
      # sparse, not Android sparse).
      self._image.truncate(self._image.tell() + num_bytes)
      self._read_header()
      return

    self._num_total_chunks += 1
    self._num_total_blocks += num_bytes // self.block_size
    self._update_chunks_and_blocks()

    self._image.seek(self._sparse_end, os.SEEK_SET)
    self._image.write(struct.pack(ImageChunk.FORMAT,
                                  ImageChunk.TYPE_DONT_CARE,
                                  0,  # Reserved
                                  num_bytes // self.block_size,
                                  struct.calcsize(ImageChunk.FORMAT)))
    self._read_header()

  def append_raw(self, data, multiple_block_size=True):
    """Appends a RAW chunk to the sparse file.

    The length of the given data must be a multiple of the block size,
    unless |multiple_block_size| is False.

    Arguments:
      data: Data to append as bytes.
      multiple_block_size: whether to check the length of the
        data is a multiple of the block size.

    Raises:
      OSError: If ImageHandler was initialized in read-only mode.
    """
    if multiple_block_size:
      assert len(data) % self.block_size == 0

    if self._read_only:
      raise OSError('ImageHandler is in read-only mode.')

    if not self.is_sparse:
      self._image.seek(0, os.SEEK_END)
      self._image.write(data)
      self._read_header()
      return

    self._num_total_chunks += 1
    self._num_total_blocks += len(data) // self.block_size
    self._update_chunks_and_blocks()

    self._image.seek(self._sparse_end, os.SEEK_SET)
    self._image.write(struct.pack(ImageChunk.FORMAT,
                                  ImageChunk.TYPE_RAW,
                                  0,  # Reserved
                                  len(data) // self.block_size,
                                  len(data) +
                                  struct.calcsize(ImageChunk.FORMAT)))
    self._image.write(data)
    self._read_header()

  def append_fill(self, fill_data, size):
    """Appends a fill chunk to the sparse file.

    The total length of the fill data must be a multiple of the block size.

    Arguments:
      fill_data: Fill data to append - must be four bytes.
      size: Number of chunk - must be a multiple of four and the block size.

    Raises:
      OSError: If ImageHandler was initialized in read-only mode.
    """
    assert len(fill_data) == 4
    assert size % 4 == 0
    assert size % self.block_size == 0

    if self._read_only:
      raise OSError('ImageHandler is in read-only mode.')

    if not self.is_sparse:
      self._image.seek(0, os.SEEK_END)
      self._image.write(fill_data * (size//4))
      self._read_header()
      return

    self._num_total_chunks += 1
    self._num_total_blocks += size // self.block_size
    self._update_chunks_and_blocks()

    self._image.seek(self._sparse_end, os.SEEK_SET)
    self._image.write(struct.pack(ImageChunk.FORMAT,
                                  ImageChunk.TYPE_FILL,
                                  0,  # Reserved
                                  size // self.block_size,
                                  4 + struct.calcsize(ImageChunk.FORMAT)))
    self._image.write(fill_data)
    self._read_header()

  def seek(self, offset):
    """Sets the cursor position for reading from unsparsified file.

    Arguments:
      offset: Offset to seek to from the beginning of the file.

    Raises:
      RuntimeError: If the given offset is negative.
    """
    if offset < 0:
      raise RuntimeError('Seeking with negative offset: {}'.format(offset))
    self._file_pos = offset

  def read(self, size):
    """Reads data from the unsparsified file.

    This method may return fewer than |size| bytes of data if the end
    of the file was encountered.

    The file cursor for reading is advanced by the number of bytes
    read.

    Arguments:
      size: Number of bytes to read.

    Returns:
      The data as bytes.
    """
    if not self.is_sparse:
      self._image.seek(self._file_pos)
      data = self._image.read(size)
      self._file_pos += len(data)
      return data

    # Iterate over all chunks.
    chunk_idx = bisect.bisect_right(self._chunk_output_offsets,
                                    self._file_pos) - 1
    data = bytearray()
    to_go = size
    while to_go > 0:
      chunk = self._chunks[chunk_idx]
      chunk_pos_offset = self._file_pos - chunk.output_offset
      chunk_pos_to_go = min(chunk.output_size - chunk_pos_offset, to_go)

      if chunk.chunk_type == ImageChunk.TYPE_RAW:
        self._image.seek(chunk.input_offset + chunk_pos_offset)
        data.extend(self._image.read(chunk_pos_to_go))
      elif chunk.chunk_type == ImageChunk.TYPE_FILL:
        all_data = chunk.fill_data*(chunk_pos_to_go // len(chunk.fill_data) + 2)
        offset_mod = chunk_pos_offset % len(chunk.fill_data)
        data.extend(all_data[offset_mod:(offset_mod + chunk_pos_to_go)])
      else:
        assert chunk.chunk_type == ImageChunk.TYPE_DONT_CARE
        data.extend(b'\0' * chunk_pos_to_go)

      to_go -= chunk_pos_to_go
      self._file_pos += chunk_pos_to_go
      chunk_idx += 1
      # Generate partial read in case of EOF.
      if chunk_idx >= len(self._chunks):
        break

    return bytes(data)

  def tell(self):
    """Returns the file cursor position for reading from unsparsified file.

    Returns:
      The file cursor position for reading.
    """
    return self._file_pos

  def truncate(self, size):
    """Truncates the unsparsified file.

    Arguments:
      size: Desired size of unsparsified file.

    Raises:
      ValueError: If desired size isn't a multiple of the block size.
      OSError: If ImageHandler was initialized in read-only mode.
    """
    if self._read_only:
      raise OSError('ImageHandler is in read-only mode.')

    if not self.is_sparse:
      self._image.truncate(size)
      self._read_header()
      return

    if size % self.block_size != 0:
      raise ValueError('Cannot truncate to a size which is not a multiple '
                       'of the block size')

    if size == self.image_size:
      # Trivial where there's nothing to do.
      return

    if size < self.image_size:
      chunk_idx = bisect.bisect_right(self._chunk_output_offsets, size) - 1
      chunk = self._chunks[chunk_idx]
      if chunk.output_offset != size:
        # Truncation in the middle of a trunk - need to keep the chunk
        # and modify it.
        chunk_idx_for_update = chunk_idx + 1
        num_to_keep = size - chunk.output_offset
        assert num_to_keep % self.block_size == 0
        if chunk.chunk_type == ImageChunk.TYPE_RAW:
          truncate_at = (chunk.chunk_offset +
                         struct.calcsize(ImageChunk.FORMAT) + num_to_keep)
          data_sz = num_to_keep
        elif chunk.chunk_type == ImageChunk.TYPE_FILL:
          truncate_at = (chunk.chunk_offset +
                         struct.calcsize(ImageChunk.FORMAT) + 4)
          data_sz = 4
        else:
          assert chunk.chunk_type == ImageChunk.TYPE_DONT_CARE
          truncate_at = chunk.chunk_offset + struct.calcsize(ImageChunk.FORMAT)
          data_sz = 0
        chunk_sz = num_to_keep // self.block_size
        total_sz = data_sz + struct.calcsize(ImageChunk.FORMAT)
        self._image.seek(chunk.chunk_offset)
        self._image.write(struct.pack(ImageChunk.FORMAT,
                                      chunk.chunk_type,
                                      0,  # Reserved
                                      chunk_sz,
                                      total_sz))
        chunk.output_size = num_to_keep
      else:
        # Truncation at trunk boundary.
        truncate_at = chunk.chunk_offset
        chunk_idx_for_update = chunk_idx

      self._num_total_chunks = chunk_idx_for_update
      self._num_total_blocks = 0
      for i in range(0, chunk_idx_for_update):
        self._num_total_blocks += self._chunks[i].output_size // self.block_size
      self._update_chunks_and_blocks()
      self._image.truncate(truncate_at)

      # We've modified the file so re-read all data.
      self._read_header()
    else:
      # Truncating to grow - just add a DONT_CARE section.
      self.append_dont_care(size - self.image_size)


class AvbDescriptor(object):
  """Class for AVB descriptor.

  See the |AvbDescriptor| C struct for more information.

  Attributes:
    tag: The tag identifying what kind of descriptor this is.
    data: The data in the descriptor.
  """

  SIZE = 16
  FORMAT_STRING = ('!QQ')  # tag, num_bytes_following (descriptor header)

  def __init__(self, data):
    """Initializes a new property descriptor.

    Arguments:
      data: If not None, must be a bytearray().

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.tag, num_bytes_following) = (
          struct.unpack(self.FORMAT_STRING, data[0:self.SIZE]))
      self.data = data[self.SIZE:self.SIZE + num_bytes_following]
    else:
      self.tag = None
      self.data = None

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Unknown descriptor:\n')
    o.write('      Tag:  {}\n'.format(self.tag))
    if len(self.data) < 256:
      o.write('      Data: {} ({} bytes)\n'.format(
          repr(str(self.data)), len(self.data)))
    else:
      o.write('      Data: {} bytes\n'.format(len(self.data)))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      A bytearray() with the descriptor data.
    """
    num_bytes_following = len(self.data)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.tag, nbf_with_padding)
    padding = struct.pack(str(padding_size) + 'x')
    ret = desc + self.data + padding
    return bytearray(ret)

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    # Deletes unused parameters to prevent pylint warning unused-argument.
    del image_dir, image_ext, expected_chain_partitions_map
    del image_containing_descriptor, accept_zeroed_hashtree

    # Nothing to do.
    return True


class AvbPropertyDescriptor(AvbDescriptor):
  """A class for property descriptors.

  See the |AvbPropertyDescriptor| C struct for more information.

  Attributes:
    key: The key as string.
    value: The value as bytes.
  """

  TAG = 0
  SIZE = 32
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'Q'    # key size (bytes)
                   'Q')   # value size (bytes)

  def __init__(self, data=None):
    """Initializes a new property descriptor.

    Arguments:
      data: If not None, must be as bytes of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    super().__init__(None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, key_size,
       value_size) = struct.unpack(self.FORMAT_STRING, data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + key_size + 1 + value_size + 1, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a property '
                          'descriptor.')
      try:
        self.key = data[self.SIZE:(self.SIZE + key_size)].decode('utf-8')
      except UnicodeDecodeError as e:
        raise LookupError('Key cannot be decoded as UTF-8: {}.'
                          .format(e)) from e
      self.value = data[(self.SIZE + key_size + 1):(self.SIZE + key_size + 1 +
                                                    value_size)]
    else:
      self.key = ''
      self.value = b''

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    # Go forward with python 3, bytes are represented with the 'b' prefix,
    # e.g. b'foobar'. Thus, we trim off the 'b' to keep the print output
    # the same between python 2 and python 3.
    printable_value = repr(self.value)
    if printable_value.startswith('b\''):
      printable_value = printable_value[1:]

    if len(self.value) < 256:
      o.write('    Prop: {} -> {}\n'.format(self.key, printable_value))
    else:
      o.write('    Prop: {} -> ({} bytes)\n'.format(self.key, len(self.value)))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      The descriptor data as bytes.
    """
    key_encoded = self.key.encode('utf-8')
    num_bytes_following = (
        self.SIZE + len(key_encoded) + len(self.value) + 2 - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       len(key_encoded), len(self.value))
    ret = (desc + key_encoded + b'\0' + self.value + b'\0' +
           padding_size * b'\0')
    return ret

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    # Nothing to do.
    return True


class AvbHashtreeDescriptor(AvbDescriptor):
  """A class for hashtree descriptors.

  See the |AvbHashtreeDescriptor| C struct for more information.

  Attributes:
    dm_verity_version: dm-verity version used.
    image_size: Size of the image, after rounding up to |block_size|.
    tree_offset: Offset of the hash tree in the file.
    tree_size: Size of the tree.
    data_block_size: Data block size.
    hash_block_size: Hash block size.
    fec_num_roots: Number of roots used for FEC (0 if FEC is not used).
    fec_offset: Offset of FEC data (0 if FEC is not used).
    fec_size: Size of FEC data (0 if FEC is not used).
    hash_algorithm: Hash algorithm used as string.
    partition_name: Partition name as string.
    salt: Salt used as bytes.
    root_digest: Root digest as bytes.
    flags: Descriptor flags (see avb_hashtree_descriptor.h).
  """

  TAG = 1
  RESERVED = 60
  SIZE = 120 + RESERVED
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'L'    # dm-verity version used
                   'Q'    # image size (bytes)
                   'Q'    # tree offset (bytes)
                   'Q'    # tree size (bytes)
                   'L'    # data block size (bytes)
                   'L'    # hash block size (bytes)
                   'L'    # FEC number of roots
                   'Q'    # FEC offset (bytes)
                   'Q'    # FEC size (bytes)
                   '32s'  # hash algorithm used
                   'L'    # partition name (bytes)
                   'L'    # salt length (bytes)
                   'L'    # root digest length (bytes)
                   'L' +  # flags
                   str(RESERVED) + 's')  # reserved

  FLAGS_DO_NOT_USE_AB = (1 << 0)
  FLAGS_CHECK_AT_MOST_ONCE = (1 << 1)

  def __init__(self, data=None):
    """Initializes a new hashtree descriptor.

    Arguments:
      data: If not None, must be bytes of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    super().__init__(None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.dm_verity_version, self.image_size,
       self.tree_offset, self.tree_size, self.data_block_size,
       self.hash_block_size, self.fec_num_roots, self.fec_offset, self.fec_size,
       self.hash_algorithm, partition_name_len, salt_len,
       root_digest_len, self.flags, _) = struct.unpack(self.FORMAT_STRING,
                                                       data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + partition_name_len + salt_len + root_digest_len, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a hashtree '
                          'descriptor.')
      # Nuke NUL-bytes at the end.
      self.hash_algorithm = self.hash_algorithm.rstrip(b'\0').decode('ascii')
      o = 0
      try:
        self.partition_name = data[
            (self.SIZE + o):(self.SIZE + o + partition_name_len)
        ].decode('utf-8')
      except UnicodeDecodeError as e:
        raise LookupError('Partition name cannot be decoded as UTF-8: {}.'
                          .format(e)) from e
      o += partition_name_len
      self.salt = data[(self.SIZE + o):(self.SIZE + o + salt_len)]
      o += salt_len
      self.root_digest = data[(self.SIZE + o):(self.SIZE + o + root_digest_len)]

      if root_digest_len != self._hashtree_digest_size():
        if root_digest_len != 0:
          raise LookupError('root_digest_len doesn\'t match hash algorithm')

    else:
      self.dm_verity_version = 0
      self.image_size = 0
      self.tree_offset = 0
      self.tree_size = 0
      self.data_block_size = 0
      self.hash_block_size = 0
      self.fec_num_roots = 0
      self.fec_offset = 0
      self.fec_size = 0
      self.hash_algorithm = ''
      self.partition_name = ''
      self.salt = b''
      self.root_digest = b''
      self.flags = 0

  def _hashtree_digest_size(self):
    return len(create_avb_hashtree_hasher(self.hash_algorithm, b'').digest())

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Hashtree descriptor:\n')
    o.write('      Version of dm-verity:  {}\n'.format(self.dm_verity_version))
    o.write('      Image Size:            {} bytes\n'.format(self.image_size))
    o.write('      Tree Offset:           {}\n'.format(self.tree_offset))
    o.write('      Tree Size:             {} bytes\n'.format(self.tree_size))
    o.write('      Data Block Size:       {} bytes\n'.format(
        self.data_block_size))
    o.write('      Hash Block Size:       {} bytes\n'.format(
        self.hash_block_size))
    o.write('      FEC num roots:         {}\n'.format(self.fec_num_roots))
    o.write('      FEC offset:            {}\n'.format(self.fec_offset))
    o.write('      FEC size:              {} bytes\n'.format(self.fec_size))
    o.write('      Hash Algorithm:        {}\n'.format(self.hash_algorithm))
    o.write('      Partition Name:        {}\n'.format(self.partition_name))
    o.write('      Salt:                  {}\n'.format(self.salt.hex()))
    o.write('      Root Digest:           {}\n'.format(self.root_digest.hex()))
    o.write('      Flags:                 {}\n'.format(self.flags))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      The descriptor data as bytes.
    """
    hash_algorithm_encoded = self.hash_algorithm.encode('ascii')
    partition_name_encoded = self.partition_name.encode('utf-8')
    num_bytes_following = (self.SIZE + len(partition_name_encoded)
                           + len(self.salt) + len(self.root_digest) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.dm_verity_version, self.image_size,
                       self.tree_offset, self.tree_size, self.data_block_size,
                       self.hash_block_size, self.fec_num_roots,
                       self.fec_offset, self.fec_size, hash_algorithm_encoded,
                       len(partition_name_encoded), len(self.salt),
                       len(self.root_digest), self.flags, self.RESERVED * b'\0')
    ret = (desc + partition_name_encoded + self.salt + self.root_digest +
           padding_size * b'\0')
    return ret

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    if not self.partition_name:
      image_filename = image_containing_descriptor.filename
      image = image_containing_descriptor
    else:
      image_filename = os.path.join(image_dir, self.partition_name + image_ext)
      image = ImageHandler(image_filename, read_only=True)
    # Generate the hashtree and checks that it matches what's in the file.
    digest_size = self._hashtree_digest_size()
    digest_padding = round_to_pow2(digest_size) - digest_size
    (hash_level_offsets, tree_size) = calc_hash_level_offsets(
        self.image_size, self.data_block_size, digest_size + digest_padding)
    root_digest, hash_tree = generate_hash_tree(image, self.image_size,
                                                self.data_block_size,
                                                self.hash_algorithm, self.salt,
                                                digest_padding,
                                                hash_level_offsets,
                                                tree_size)
    # The root digest must match unless it is not embedded in the descriptor.
    if self.root_digest and root_digest != self.root_digest:
      sys.stderr.write('hashtree of {} does not match descriptor\n'.
                       format(image_filename))
      return False
    # ... also check that the on-disk hashtree matches
    image.seek(self.tree_offset)
    hash_tree_ondisk = image.read(self.tree_size)
    is_zeroed = (self.tree_size == 0) or (hash_tree_ondisk[0:8] == b'ZeRoHaSH')
    if is_zeroed and accept_zeroed_hashtree:
      print('{}: skipping verification since hashtree is zeroed and '
            '--accept_zeroed_hashtree was given'
            .format(self.partition_name))
    else:
      if hash_tree != hash_tree_ondisk:
        sys.stderr.write('hashtree of {} contains invalid data\n'.
                         format(image_filename))
        return False
      print('{}: Successfully verified {} hashtree of {} for image of {} bytes'
            .format(self.partition_name, self.hash_algorithm, image.filename,
                    self.image_size))
    # TODO(zeuthen): we could also verify that the FEC stored in the image is
    # correct but this a) currently requires the 'fec' binary; and b) takes a
    # long time; and c) is not strictly needed for verification purposes as
    # we've already verified the root hash.
    return True


class AvbHashDescriptor(AvbDescriptor):
  """A class for hash descriptors.

  See the |AvbHashDescriptor| C struct for more information.

  Attributes:
    image_size: Image size, in bytes.
    hash_algorithm: Hash algorithm used as string.
    partition_name: Partition name as string.
    salt: Salt used as bytes.
    digest: The hash value of salt and data combined as bytes.
    flags: The descriptor flags (see avb_hash_descriptor.h).
  """

  TAG = 2
  RESERVED = 60
  SIZE = 72 + RESERVED
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'Q'    # image size (bytes)
                   '32s'  # hash algorithm used
                   'L'    # partition name (bytes)
                   'L'    # salt length (bytes)
                   'L'    # digest length (bytes)
                   'L' +  # flags
                   str(RESERVED) + 's')  # reserved

  def __init__(self, data=None):
    """Initializes a new hash descriptor.

    Arguments:
      data: If not None, must be bytes of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    super().__init__(None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.image_size, self.hash_algorithm,
       partition_name_len, salt_len,
       digest_len, self.flags, _) = struct.unpack(self.FORMAT_STRING,
                                                  data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + partition_name_len + salt_len + digest_len, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a hash descriptor.')
      # Nuke NUL-bytes at the end.
      self.hash_algorithm = self.hash_algorithm.rstrip(b'\0').decode('ascii')
      o = 0
      try:
        self.partition_name = data[
            (self.SIZE + o):(self.SIZE + o + partition_name_len)
        ].decode('utf-8')
      except UnicodeDecodeError as e:
        raise LookupError('Partition name cannot be decoded as UTF-8: {}.'
                          .format(e)) from e
      o += partition_name_len
      self.salt = data[(self.SIZE + o):(self.SIZE + o + salt_len)]
      o += salt_len
      self.digest = data[(self.SIZE + o):(self.SIZE + o + digest_len)]
      if digest_len != len(hashlib.new(self.hash_algorithm).digest()):
        if digest_len != 0:
          raise LookupError('digest_len doesn\'t match hash algorithm')

    else:
      self.image_size = 0
      self.hash_algorithm = ''
      self.partition_name = ''
      self.salt = b''
      self.digest = b''
      self.flags = 0

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Hash descriptor:\n')
    o.write('      Image Size:            {} bytes\n'.format(self.image_size))
    o.write('      Hash Algorithm:        {}\n'.format(self.hash_algorithm))
    o.write('      Partition Name:        {}\n'.format(self.partition_name))
    o.write('      Salt:                  {}\n'.format(self.salt.hex()))
    o.write('      Digest:                {}\n'.format(self.digest.hex()))
    o.write('      Flags:                 {}\n'.format(self.flags))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      The descriptor data as bytes.
    """
    hash_algorithm_encoded = self.hash_algorithm.encode('ascii')
    partition_name_encoded = self.partition_name.encode('utf-8')
    num_bytes_following = (self.SIZE + len(partition_name_encoded) +
                           len(self.salt) + len(self.digest) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.image_size, hash_algorithm_encoded,
                       len(partition_name_encoded), len(self.salt),
                       len(self.digest), self.flags, self.RESERVED * b'\0')
    ret = (desc + partition_name_encoded + self.salt + self.digest +
           padding_size * b'\0')
    return ret

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    if not self.partition_name:
      image_filename = image_containing_descriptor.filename
      image = image_containing_descriptor
    else:
      image_filename = os.path.join(image_dir, self.partition_name + image_ext)
      image = ImageHandler(image_filename, read_only=True)
    data = image.read(self.image_size)
    ha = hashlib.new(self.hash_algorithm)
    ha.update(self.salt)
    ha.update(data)
    digest = ha.digest()
    # The digest must match unless there is no digest in the descriptor.
    if self.digest and digest != self.digest:
      sys.stderr.write('{} digest of {} does not match digest in descriptor\n'.
                       format(self.hash_algorithm, image_filename))
      return False
    print('{}: Successfully verified {} hash of {} for image of {} bytes'
          .format(self.partition_name, self.hash_algorithm, image.filename,
                  self.image_size))
    return True


class AvbKernelCmdlineDescriptor(AvbDescriptor):
  """A class for kernel command-line descriptors.

  See the |AvbKernelCmdlineDescriptor| C struct for more information.

  Attributes:
    flags: Flags.
    kernel_cmdline: The kernel command-line as string.
  """

  TAG = 3
  SIZE = 24
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'L'    # flags
                   'L')   # cmdline length (bytes)

  FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED = (1 << 0)
  FLAGS_USE_ONLY_IF_HASHTREE_DISABLED = (1 << 1)

  def __init__(self, data=None):
    """Initializes a new kernel cmdline descriptor.

    Arguments:
      data: If not None, must be bytes of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    super().__init__(None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.flags, kernel_cmdline_length) = (
          struct.unpack(self.FORMAT_STRING, data[0:self.SIZE]))
      expected_size = round_to_multiple(self.SIZE - 16 + kernel_cmdline_length,
                                        8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a kernel cmdline '
                          'descriptor.')
      # Nuke NUL-bytes at the end.
      try:
        self.kernel_cmdline = data[
            self.SIZE:(self.SIZE + kernel_cmdline_length)].decode('utf-8')
      except UnicodeDecodeError as e:
        raise LookupError('Kernel command-line cannot be decoded as UTF-8: {}.'
                          .format(e)) from e
    else:
      self.flags = 0
      self.kernel_cmdline = ''

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Kernel Cmdline descriptor:\n')
    o.write('      Flags:                 {}\n'.format(self.flags))
    o.write('      Kernel Cmdline:        \'{}\'\n'.format(self.kernel_cmdline))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      The descriptor data as bytes.
    """
    kernel_cmd_encoded = self.kernel_cmdline.encode('utf-8')
    num_bytes_following = (self.SIZE + len(kernel_cmd_encoded) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.flags, len(kernel_cmd_encoded))
    ret = desc + kernel_cmd_encoded + padding_size * b'\0'
    return ret

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    # Nothing to verify.
    return True


class AvbChainPartitionDescriptor(AvbDescriptor):
  """A class for chained partition descriptors.

  See the |AvbChainPartitionDescriptor| C struct for more information.

  Attributes:
    rollback_index_location: The rollback index location to use.
    partition_name: Partition name as string.
    public_key: The public key as bytes.
  """

  TAG = 4
  RESERVED = 64
  SIZE = 28 + RESERVED
  FORMAT_STRING = ('!QQ'  # tag, num_bytes_following (descriptor header)
                   'L'    # rollback_index_location
                   'L'    # partition_name_size (bytes)
                   'L' +  # public_key_size (bytes)
                   str(RESERVED) + 's')  # reserved

  def __init__(self, data=None):
    """Initializes a new chain partition descriptor.

    Arguments:
      data: If not None, must be a bytearray of size |SIZE|.

    Raises:
      LookupError: If the given descriptor is malformed.
    """
    AvbDescriptor.__init__(self, None)
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (tag, num_bytes_following, self.rollback_index_location,
       partition_name_len,
       public_key_len, _) = struct.unpack(self.FORMAT_STRING, data[0:self.SIZE])
      expected_size = round_to_multiple(
          self.SIZE - 16 + partition_name_len + public_key_len, 8)
      if tag != self.TAG or num_bytes_following != expected_size:
        raise LookupError('Given data does not look like a chain partition '
                          'descriptor.')
      o = 0
      try:
        self.partition_name = data[
            (self.SIZE + o):(self.SIZE + o + partition_name_len)
        ].decode('utf-8')
      except UnicodeDecodeError as e:
        raise LookupError('Partition name cannot be decoded as UTF-8: {}.'
                          .format(e)) from e
      o += partition_name_len
      self.public_key = data[(self.SIZE + o):(self.SIZE + o + public_key_len)]

    else:
      self.rollback_index_location = 0
      self.partition_name = ''
      self.public_key = b''

  def print_desc(self, o):
    """Print the descriptor.

    Arguments:
      o: The object to write the output to.
    """
    o.write('    Chain Partition descriptor:\n')
    o.write('      Partition Name:          {}\n'.format(self.partition_name))
    o.write('      Rollback Index Location: {}\n'.format(
        self.rollback_index_location))
    # Just show the SHA1 of the key, for size reasons.
    pubkey_digest = hashlib.sha1(self.public_key).hexdigest()
    o.write('      Public key (sha1):       {}\n'.format(pubkey_digest))

  def encode(self):
    """Serializes the descriptor.

    Returns:
      The descriptor data as bytes.
    """
    partition_name_encoded = self.partition_name.encode('utf-8')
    num_bytes_following = (
        self.SIZE + len(partition_name_encoded) + len(self.public_key) - 16)
    nbf_with_padding = round_to_multiple(num_bytes_following, 8)
    padding_size = nbf_with_padding - num_bytes_following
    desc = struct.pack(self.FORMAT_STRING, self.TAG, nbf_with_padding,
                       self.rollback_index_location,
                       len(partition_name_encoded), len(self.public_key),
                       self.RESERVED * b'\0')
    ret = desc + partition_name_encoded + self.public_key + padding_size * b'\0'
    return ret

  def verify(self, image_dir, image_ext, expected_chain_partitions_map,
             image_containing_descriptor, accept_zeroed_hashtree):
    """Verifies contents of the descriptor - used in verify_image sub-command.

    Arguments:
      image_dir: The directory of the file being verified.
      image_ext: The extension of the file being verified (e.g. '.img').
      expected_chain_partitions_map: A map from partition name to the
          tuple (rollback_index_location, key_blob).
      image_containing_descriptor: The image the descriptor is in.
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Returns:
      True if the descriptor verifies, False otherwise.
    """
    value = expected_chain_partitions_map.get(self.partition_name)
    if not value:
      sys.stderr.write('No expected chain partition for partition {}. Use '
                       '--expected_chain_partition to specify expected '
                       'contents or --follow_chain_partitions.\n'.
                       format(self.partition_name))
      return False
    rollback_index_location, pk_blob = value

    if self.rollback_index_location != rollback_index_location:
      sys.stderr.write('Expected rollback_index_location {} does not '
                       'match {} in descriptor for partition {}\n'.
                       format(rollback_index_location,
                              self.rollback_index_location,
                              self.partition_name))
      return False

    if self.public_key != pk_blob:
      sys.stderr.write('Expected public key blob does not match public '
                       'key blob in descriptor for partition {}\n'.
                       format(self.partition_name))
      return False

    print('{}: Successfully verified chain partition descriptor matches '
          'expected data'.format(self.partition_name))

    return True

DESCRIPTOR_CLASSES = [
    AvbPropertyDescriptor, AvbHashtreeDescriptor, AvbHashDescriptor,
    AvbKernelCmdlineDescriptor, AvbChainPartitionDescriptor
]


def parse_descriptors(data):
  """Parses a blob of data into descriptors.

  Arguments:
    data: Encoded descriptors as bytes.

  Returns:
    A list of instances of objects derived from AvbDescriptor. For
    unknown descriptors, the class AvbDescriptor is used.
  """
  o = 0
  ret = []
  while o < len(data):
    tag, nb_following = struct.unpack('!2Q', data[o:o + 16])
    if tag < len(DESCRIPTOR_CLASSES):
      clazz = DESCRIPTOR_CLASSES[tag]
    else:
      clazz = AvbDescriptor
    ret.append(clazz(data[o:o + 16 + nb_following]))
    o += 16 + nb_following
  return ret


class AvbFooter(object):
  """A class for parsing and writing footers.

  Footers are stored at the end of partitions and point to where the
  AvbVBMeta blob is located. They also contain the original size of
  the image before AVB information was added.

  Attributes:
    magic: Magic for identifying the footer, see |MAGIC|.
    version_major: The major version of avbtool that wrote the footer.
    version_minor: The minor version of avbtool that wrote the footer.
    original_image_size: Original image size.
    vbmeta_offset: Offset of where the AvbVBMeta blob is stored.
    vbmeta_size: Size of the AvbVBMeta blob.
  """

  MAGIC = b'AVBf'
  SIZE = 64
  RESERVED = 28
  FOOTER_VERSION_MAJOR = AVB_FOOTER_VERSION_MAJOR
  FOOTER_VERSION_MINOR = AVB_FOOTER_VERSION_MINOR
  FORMAT_STRING = ('!4s2L'  # magic, 2 x version.
                   'Q'      # Original image size.
                   'Q'      # Offset of VBMeta blob.
                   'Q' +    # Size of VBMeta blob.
                   str(RESERVED) + 'x')  # padding for reserved bytes

  def __init__(self, data=None):
    """Initializes a new footer object.

    Arguments:
      data: If not None, must be bytes of size 4096.

    Raises:
      LookupError: If the given footer is malformed.
      struct.error: If the given data has no footer.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.magic, self.version_major, self.version_minor,
       self.original_image_size, self.vbmeta_offset,
       self.vbmeta_size) = struct.unpack(self.FORMAT_STRING, data)
      if self.magic != self.MAGIC:
        raise LookupError('Given data does not look like a AVB footer.')
    else:
      self.magic = self.MAGIC
      self.version_major = self.FOOTER_VERSION_MAJOR
      self.version_minor = self.FOOTER_VERSION_MINOR
      self.original_image_size = 0
      self.vbmeta_offset = 0
      self.vbmeta_size = 0

  def encode(self):
    """Serializes the footer.

    Returns:
      The footer as bytes.
    """
    return struct.pack(self.FORMAT_STRING, self.magic, self.version_major,
                       self.version_minor, self.original_image_size,
                       self.vbmeta_offset, self.vbmeta_size)


class AvbVBMetaHeader(object):
  """A class for parsing and writing AVB vbmeta images.

  The attributes correspond to the |AvbVBMetaImageHeader| struct defined in
  avb_vbmeta_image.h.

  Attributes:
    magic: Four bytes equal to "AVB0" (AVB_MAGIC).
    required_libavb_version_major: The major version of libavb required for this
        header.
    required_libavb_version_minor: The minor version of libavb required for this
        header.
    authentication_data_block_size: The size of the signature block.
    auxiliary_data_block_size: The size of the auxiliary data block.
    algorithm_type: The verification algorithm used, see |AvbAlgorithmType|
        enum.
    hash_offset: Offset into the "Authentication data" block of hash data.
    hash_size: Length of the hash data.
    signature_offset: Offset into the "Authentication data" block of signature
        data.
    signature_size: Length of the signature data.
    public_key_offset: Offset into the "Auxiliary data" block of public key
        data.
    public_key_size: Length of the public key data.
    public_key_metadata_offset: Offset into the "Auxiliary data" block of public
        key metadata.
    public_key_metadata_size: Length of the public key metadata. Must be set to
        zero if there is no public key metadata.
    descriptors_offset: Offset into the "Auxiliary data" block of descriptor
        data.
    descriptors_size: Length of descriptor data.
    rollback_index: The rollback index which can be used to prevent rollback to
        older versions.
    flags: Flags from the AvbVBMetaImageFlags enumeration. This must be set to
        zero if the vbmeta image is not a top-level image.
    rollback_index_location: The location of the rollback index defined in this
        header. Only valid for the main vbmeta. For chained partitions, the
        rollback index location must be specified in the
        AvbChainPartitionDescriptor and this value must be set to 0.
    release_string: The release string from avbtool, e.g. "avbtool 1.0.0" or
        "avbtool 1.0.0 xyz_board Git-234abde89". Is guaranteed to be NUL
        terminated. Applications must not make assumptions about how this
        string is formatted.
  """
  MAGIC = b'AVB0'
  SIZE = 256

  # Keep in sync with |reserved| field of |AvbVBMetaImageHeader|.
  RESERVED = 80

  # Keep in sync with |AvbVBMetaImageHeader|.
  FORMAT_STRING = ('!4s2L'   # magic, 2 x version
                   '2Q'      # 2 x block size
                   'L'       # algorithm type
                   '2Q'      # offset, size (hash)
                   '2Q'      # offset, size (signature)
                   '2Q'      # offset, size (public key)
                   '2Q'      # offset, size (public key metadata)
                   '2Q'      # offset, size (descriptors)
                   'Q'       # rollback_index
                   'L'       # flags
                   'L'       # rollback_index_location
                   '47sx' +  # NUL-terminated release string
                   str(RESERVED) + 'x')  # padding for reserved bytes

  def __init__(self, data=None):
    """Initializes a new header object.

    Arguments:
      data: If not None, must be a bytearray of size 8192.

    Raises:
      Exception: If the given data is malformed.
    """
    assert struct.calcsize(self.FORMAT_STRING) == self.SIZE

    if data:
      (self.magic, self.required_libavb_version_major,
       self.required_libavb_version_minor,
       self.authentication_data_block_size, self.auxiliary_data_block_size,
       self.algorithm_type, self.hash_offset, self.hash_size,
       self.signature_offset, self.signature_size, self.public_key_offset,
       self.public_key_size, self.public_key_metadata_offset,
       self.public_key_metadata_size, self.descriptors_offset,
       self.descriptors_size,
       self.rollback_index,
       self.flags,
       self.rollback_index_location,
       release_string) = struct.unpack(self.FORMAT_STRING, data)
      # Nuke NUL-bytes at the end of the string.
      if self.magic != self.MAGIC:
        raise AvbError('Given image does not look like a vbmeta image.')
      self.release_string = release_string.rstrip(b'\0').decode('utf-8')
    else:
      self.magic = self.MAGIC
      # Start by just requiring version 1.0. Code that adds features
      # in a future version can use bump_required_libavb_version_minor() to
      # bump the minor.
      self.required_libavb_version_major = AVB_VERSION_MAJOR
      self.required_libavb_version_minor = 0
      self.authentication_data_block_size = 0
      self.auxiliary_data_block_size = 0
      self.algorithm_type = 0
      self.hash_offset = 0
      self.hash_size = 0
      self.signature_offset = 0
      self.signature_size = 0
      self.public_key_offset = 0
      self.public_key_size = 0
      self.public_key_metadata_offset = 0
      self.public_key_metadata_size = 0
      self.descriptors_offset = 0
      self.descriptors_size = 0
      self.rollback_index = 0
      self.flags = 0
      self.rollback_index_location = 0
      self.release_string = get_release_string()

  def bump_required_libavb_version_minor(self, minor):
    """Function to bump required_libavb_version_minor.

    Call this when writing data that requires a specific libavb
    version to parse it.

    Arguments:
      minor: The minor version of libavb that has support for the feature.
    """
    self.required_libavb_version_minor = (
        max(self.required_libavb_version_minor, minor))

  def encode(self):
    """Serializes the header.

    Returns:
      The header as bytes.
    """
    release_string_encoded = self.release_string.encode('utf-8')
    return struct.pack(self.FORMAT_STRING, self.magic,
                       self.required_libavb_version_major,
                       self.required_libavb_version_minor,
                       self.authentication_data_block_size,
                       self.auxiliary_data_block_size, self.algorithm_type,
                       self.hash_offset, self.hash_size, self.signature_offset,
                       self.signature_size, self.public_key_offset,
                       self.public_key_size, self.public_key_metadata_offset,
                       self.public_key_metadata_size, self.descriptors_offset,
                       self.descriptors_size, self.rollback_index, self.flags,
                       self.rollback_index_location, release_string_encoded)


class Avb(object):
  """Business logic for avbtool command-line tool."""

  # Keep in sync with avb_ab_flow.h.
  AB_FORMAT_NO_CRC = '!4sBB2xBBBxBBBx12x'
  AB_MAGIC = b'\0AB0'
  AB_MAJOR_VERSION = 1
  AB_MINOR_VERSION = 0
  AB_MISC_METADATA_OFFSET = 2048

  # Constants for maximum metadata size. These are used to give
  # meaningful errors if the value passed in via --partition_size is
  # too small and when --calc_max_image_size is used. We use
  # conservative figures.
  MAX_VBMETA_SIZE = 64 * 1024
  MAX_FOOTER_SIZE = 4096

  def generate_test_image(self, output, image_size, start_byte):
    """Generates a test image for testing avbtool with known content.

    The content has following pattern: 0x00 0x01 0x02 .. 0xff 0x00 0x01 ..).

    Arguments:
      output: Write test image to this file.
      image_size: The size of the requested file in bytes.
      start_byte: The integer value of the start byte to use for pattern
          generation.
    """
    pattern = bytearray([x & 0xFF for x in range(start_byte, start_byte + 256)])
    buf = bytearray()
    c = int(math.ceil(image_size / 256.0))
    for _ in range(0, c):
      buf.extend(pattern)
    output.write(buf[0:image_size])

  def extract_vbmeta_image(self, output, image_filename, padding_size):
    """Implements the 'extract_vbmeta_image' command.

    Arguments:
      output: Write vbmeta struct to this file.
      image_filename: File to extract vbmeta data from (with a footer).
      padding_size: If not 0, pads output so size is a multiple of the number.

    Raises:
      AvbError: If there's no footer in the image.
    """
    image = ImageHandler(image_filename, read_only=True)
    (footer, _, _, _) = self._parse_image(image)
    if not footer:
      raise AvbError('Given image does not have a footer.')

    image.seek(footer.vbmeta_offset)
    vbmeta_blob = image.read(footer.vbmeta_size)
    output.write(vbmeta_blob)

    if padding_size > 0:
      padded_size = round_to_multiple(len(vbmeta_blob), padding_size)
      padding_needed = padded_size - len(vbmeta_blob)
      output.write(b'\0' * padding_needed)

  def erase_footer(self, image_filename, keep_hashtree):
    """Implements the 'erase_footer' command.

    Arguments:
      image_filename: File to erase a footer from.
      keep_hashtree: If True, keep the hashtree and FEC around.

    Raises:
      AvbError: If there's no footer in the image.
    """
    image = ImageHandler(image_filename)
    (footer, _, descriptors, _) = self._parse_image(image)
    if not footer:
      raise AvbError('Given image does not have a footer.')

    new_image_size = None
    if not keep_hashtree:
      new_image_size = footer.original_image_size
    else:
      # If requested to keep the hashtree, search for a hashtree
      # descriptor to figure out the location and size of the hashtree
      # and FEC.
      for desc in descriptors:
        if isinstance(desc, AvbHashtreeDescriptor):
          # The hashtree is always just following the main data so the
          # new size is easily derived.
          new_image_size = desc.tree_offset + desc.tree_size
          # If the image has FEC codes, also keep those.
          if desc.fec_offset > 0:
            fec_end = desc.fec_offset + desc.fec_size
            new_image_size = max(new_image_size, fec_end)
          break
      if not new_image_size:
        raise AvbError('Requested to keep hashtree but no hashtree '
                       'descriptor was found.')

    # And cut...
    image.truncate(new_image_size)

  def zero_hashtree(self, image_filename):
    """Implements the 'zero_hashtree' command.

    Arguments:
      image_filename: File to zero hashtree and FEC data from.

    Raises:
      AvbError: If there's no footer in the image.
    """
    image = ImageHandler(image_filename)
    (footer, _, descriptors, _) = self._parse_image(image)
    if not footer:
      raise AvbError('Given image does not have a footer.')

    # Search for a hashtree descriptor to figure out the location and
    # size of the hashtree and FEC.
    ht_desc = None
    for desc in descriptors:
      if isinstance(desc, AvbHashtreeDescriptor):
        ht_desc = desc
        break

    if not ht_desc:
      raise AvbError('No hashtree descriptor was found.')

    zero_ht_start_offset = ht_desc.tree_offset
    zero_ht_num_bytes = ht_desc.tree_size
    zero_fec_start_offset = None
    zero_fec_num_bytes = 0
    if ht_desc.fec_offset > 0:
      if ht_desc.fec_offset != ht_desc.tree_offset + ht_desc.tree_size:
        raise AvbError('Hash-tree and FEC data must be adjacent.')
      zero_fec_start_offset = ht_desc.fec_offset
      zero_fec_num_bytes = ht_desc.fec_size
    zero_end_offset = (zero_ht_start_offset + zero_ht_num_bytes
                       + zero_fec_num_bytes)
    image.seek(zero_end_offset)
    data = image.read(image.image_size - zero_end_offset)

    # Write zeroes all over hashtree and FEC, except for the first eight bytes
    # where a magic marker - ZeroHaSH - is placed. Place these markers in the
    # beginning of both hashtree and FEC. (That way, in the future we can add
    # options to 'avbtool zero_hashtree' so as to zero out only either/or.)
    #
    # Applications can use these markers to detect that the hashtree and/or
    # FEC needs to be recomputed.
    image.truncate(zero_ht_start_offset)
    data_zeroed_firstblock = b'ZeRoHaSH' + b'\0' * (image.block_size - 8)
    image.append_raw(data_zeroed_firstblock)
    image.append_fill(b'\0\0\0\0', zero_ht_num_bytes - image.block_size)
    if zero_fec_start_offset:
      image.append_raw(data_zeroed_firstblock)
      image.append_fill(b'\0\0\0\0', zero_fec_num_bytes - image.block_size)
    image.append_raw(data)

  def resize_image(self, image_filename, partition_size):
    """Implements the 'resize_image' command.

    Arguments:
      image_filename: File with footer to resize.
      partition_size: The new size of the image.

    Raises:
      AvbError: If there's no footer in the image.
    """

    image = ImageHandler(image_filename)
    if partition_size % image.block_size != 0:
      raise AvbError('Partition size of {} is not a multiple of the image '
                     'block size {}.'.format(partition_size,
                                             image.block_size))
    (footer, _, _, _) = self._parse_image(image)
    if not footer:
      raise AvbError('Given image does not have a footer.')

    # The vbmeta blob is always at the end of the data so resizing an
    # image amounts to just moving the footer around.
    vbmeta_end_offset = footer.vbmeta_offset + footer.vbmeta_size
    if vbmeta_end_offset % image.block_size != 0:
      vbmeta_end_offset += image.block_size - (vbmeta_end_offset
                                               % image.block_size)

    if partition_size < vbmeta_end_offset + 1 * image.block_size:
      raise AvbError('Requested size of {} is too small for an image '
                     'of size {}.'
                     .format(partition_size,
                             vbmeta_end_offset + 1 * image.block_size))

    # Cut at the end of the vbmeta blob and insert a DONT_CARE chunk
    # with enough bytes such that the final Footer block is at the end
    # of partition_size.
    image.truncate(vbmeta_end_offset)
    image.append_dont_care(partition_size - vbmeta_end_offset -
                           1 * image.block_size)

    # Just reuse the same footer - only difference is that we're
    # writing it in a different place.
    footer_blob = footer.encode()
    footer_blob_with_padding = (b'\0' * (image.block_size - AvbFooter.SIZE) +
                                footer_blob)
    image.append_raw(footer_blob_with_padding)

  def set_ab_metadata(self, misc_image, slot_data):
    """Implements the 'set_ab_metadata' command.

    The |slot_data| argument must be of the form 'A_priority:A_tries_remaining:
    A_successful_boot:B_priority:B_tries_remaining:B_successful_boot'.

    Arguments:
      misc_image: The misc image to write to.
      slot_data: Slot data as a string

    Raises:
      AvbError: If slot data is malformed.
    """
    tokens = slot_data.split(':')
    if len(tokens) != 6:
      raise AvbError('Malformed slot data "{}".'.format(slot_data))
    a_priority = int(tokens[0])
    a_tries_remaining = int(tokens[1])
    a_success = int(tokens[2]) != 0
    b_priority = int(tokens[3])
    b_tries_remaining = int(tokens[4])
    b_success = int(tokens[5]) != 0

    ab_data_no_crc = struct.pack(self.AB_FORMAT_NO_CRC,
                                 self.AB_MAGIC,
                                 self.AB_MAJOR_VERSION, self.AB_MINOR_VERSION,
                                 a_priority, a_tries_remaining, a_success,
                                 b_priority, b_tries_remaining, b_success)
    # Force CRC to be unsigned, see https://bugs.python.org/issue4903 for why.
    crc_value = binascii.crc32(ab_data_no_crc) & 0xffffffff
    ab_data = ab_data_no_crc + struct.pack('!I', crc_value)
    misc_image.seek(self.AB_MISC_METADATA_OFFSET)
    misc_image.write(ab_data)

  def info_image(self, image_filename, output, atx):
    """Implements the 'info_image' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      output: Output file to write human-readable information to (file object).
      atx: If True, show information about Android Things eXtension (ATX).
    """
    image = ImageHandler(image_filename, read_only=True)
    o = output
    (footer, header, descriptors, image_size) = self._parse_image(image)

    # To show the SHA1 of the public key.
    vbmeta_blob = self._load_vbmeta_blob(image)
    key_offset = (header.SIZE +
                  header.authentication_data_block_size +
                  header.public_key_offset)
    key_blob = vbmeta_blob[key_offset:key_offset + header.public_key_size]

    if footer:
      o.write('Footer version:           {}.{}\n'.format(footer.version_major,
                                                         footer.version_minor))
      o.write('Image size:               {} bytes\n'.format(image_size))
      o.write('Original image size:      {} bytes\n'.format(
          footer.original_image_size))
      o.write('VBMeta offset:            {}\n'.format(footer.vbmeta_offset))
      o.write('VBMeta size:              {} bytes\n'.format(footer.vbmeta_size))
      o.write('--\n')

    (alg_name, _) = lookup_algorithm_by_type(header.algorithm_type)

    o.write('Minimum libavb version:   {}.{}{}\n'.format(
        header.required_libavb_version_major,
        header.required_libavb_version_minor,
        ' (Sparse)' if image.is_sparse else ''))
    o.write('Header Block:             {} bytes\n'.format(AvbVBMetaHeader.SIZE))
    o.write('Authentication Block:     {} bytes\n'.format(
        header.authentication_data_block_size))
    o.write('Auxiliary Block:          {} bytes\n'.format(
        header.auxiliary_data_block_size))
    if key_blob:
      hexdig = hashlib.sha1(key_blob).hexdigest()
      o.write('Public key (sha1):        {}\n'.format(hexdig))
    o.write('Algorithm:                {}\n'.format(alg_name))
    o.write('Rollback Index:           {}\n'.format(header.rollback_index))
    o.write('Flags:                    {}\n'.format(header.flags))
    o.write('Rollback Index Location:  {}\n'.format(
        header.rollback_index_location))
    o.write('Release String:           \'{}\'\n'.format(header.release_string))

    # Print descriptors.
    num_printed = 0
    o.write('Descriptors:\n')
    for desc in descriptors:
      desc.print_desc(o)
      num_printed += 1
    if num_printed == 0:
      o.write('    (none)\n')

    if atx and header.public_key_metadata_size:
      o.write('Android Things eXtension (ATX):\n')
      key_metadata_offset = (header.SIZE +
                             header.authentication_data_block_size +
                             header.public_key_metadata_offset)
      key_metadata_blob = vbmeta_blob[key_metadata_offset: key_metadata_offset
                                      + header.public_key_metadata_size]
      version, pik, psk = struct.unpack('<I1620s1620s', key_metadata_blob)
      o.write('    Metadata version:        {}\n'.format(version))

      def print_atx_certificate(cert):
        version, public_key, subject, usage, key_version, _ = (
            struct.unpack('<I1032s32s32sQ512s', cert))
        o.write('      Version:               {}\n'.format(version))
        o.write('      Public key (sha1):     {}\n'.format(
            hashlib.sha1(public_key).hexdigest()))
        o.write('      Subject:               {}\n'.format(subject.hex()))
        o.write('      Usage:                 {}\n'.format(usage.hex()))
        o.write('      Key version:           {}\n'.format(key_version))

      o.write('    Product Intermediate Key:\n')
      print_atx_certificate(pik)
      o.write('    Product Signing Key:\n')
      print_atx_certificate(psk)

  def verify_image(self, image_filename, key_path, expected_chain_partitions,
                   follow_chain_partitions, accept_zeroed_hashtree):
    """Implements the 'verify_image' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      key_path: None or check that embedded public key matches key at given
          path.
      expected_chain_partitions: List of chain partitions to check or None.
      follow_chain_partitions:
          If True, will follows chain partitions even when not specified with
          the --expected_chain_partition option
      accept_zeroed_hashtree: If True, don't fail if hashtree or FEC data is
          zeroed out.

    Raises:
      AvbError: If verification of the image fails.
    """
    expected_chain_partitions_map = {}
    if expected_chain_partitions:
      for cp in expected_chain_partitions:
        cp_tokens = cp.split(':')
        if len(cp_tokens) != 3:
          raise AvbError('Malformed chained partition "{}".'.format(cp))
        partition_name = cp_tokens[0]
        rollback_index_location = int(cp_tokens[1])
        file_path = cp_tokens[2]
        with open(file_path, 'rb') as f:
          pk_blob = f.read()
        expected_chain_partitions_map[partition_name] = (
            rollback_index_location, pk_blob)

    image_dir = os.path.dirname(image_filename)
    image_ext = os.path.splitext(image_filename)[1]

    key_blob = None
    if key_path:
      print('Verifying image {} using key at {}'.format(image_filename,
                                                        key_path))
      key_blob = RSAPublicKey(key_path).encode()
    else:
      print('Verifying image {} using embedded public key'.format(
          image_filename))

    image = ImageHandler(image_filename, read_only=True)
    (footer, header, descriptors, _) = self._parse_image(image)
    offset = 0
    if footer:
      offset = footer.vbmeta_offset

    image.seek(offset)
    vbmeta_blob = image.read(header.SIZE
                             + header.authentication_data_block_size
                             + header.auxiliary_data_block_size)

    alg_name, _ = lookup_algorithm_by_type(header.algorithm_type)
    if not verify_vbmeta_signature(header, vbmeta_blob):
      raise AvbError('Signature check failed for {} vbmeta struct {}'
                     .format(alg_name, image_filename))

    if key_blob:
      # The embedded public key is in the auxiliary block at an offset.
      key_offset = AvbVBMetaHeader.SIZE
      key_offset += header.authentication_data_block_size
      key_offset += header.public_key_offset
      key_blob_in_vbmeta = vbmeta_blob[key_offset:key_offset
                                       + header.public_key_size]
      if key_blob != key_blob_in_vbmeta:
        raise AvbError('Embedded public key does not match given key.')

    if footer:
      print('vbmeta: Successfully verified footer and {} vbmeta struct in {}'
            .format(alg_name, image.filename))
    else:
      print('vbmeta: Successfully verified {} vbmeta struct in {}'
            .format(alg_name, image.filename))

    for desc in descriptors:
      if (isinstance(desc, AvbChainPartitionDescriptor)
          and follow_chain_partitions
          and expected_chain_partitions_map.get(desc.partition_name) is None):
        # In this case we're processing a chain descriptor but don't have a
        # --expect_chain_partition ... however --follow_chain_partitions was
        # specified so we shouldn't error out in desc.verify().
        print('{}: Chained but ROLLBACK_SLOT (which is {}) '
              'and KEY (which has sha1 {}) not specified'
              .format(desc.partition_name, desc.rollback_index_location,
                      hashlib.sha1(desc.public_key).hexdigest()))
      elif not desc.verify(image_dir, image_ext, expected_chain_partitions_map,
                           image, accept_zeroed_hashtree):
        raise AvbError('Error verifying descriptor.')
      # Honor --follow_chain_partitions - add '--' to make the output more
      # readable.
      if (isinstance(desc, AvbChainPartitionDescriptor)
          and follow_chain_partitions):
        print('--')
        chained_image_filename = os.path.join(image_dir,
                                              desc.partition_name + image_ext)
        self.verify_image(chained_image_filename, key_path, None, False,
                          accept_zeroed_hashtree)

  def print_partition_digests(self, image_filename, output, as_json):
    """Implements the 'print_partition_digests' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      output: Output file to write human-readable information to (file object).
      as_json: If True, print information as JSON

    Raises:
      AvbError: If getting the partition digests from the image fails.
    """
    image_dir = os.path.dirname(image_filename)
    image_ext = os.path.splitext(image_filename)[1]
    json_partitions = None
    if as_json:
      json_partitions = []
    self._print_partition_digests(
        image_filename, output, json_partitions, image_dir, image_ext)
    if as_json:
      output.write(json.dumps({'partitions': json_partitions}, indent=2))

  def _print_partition_digests(self, image_filename, output, json_partitions,
                               image_dir, image_ext):
    """Helper for printing partitions.

    Arguments:
      image_filename: Image file to get information from (file object).
      output: Output file to write human-readable information to (file object).
      json_partitions: If not None, don't print to output, instead add partition
          information to this list.
      image_dir: The directory to use when looking for chained partition files.
      image_ext: The extension to use for chained partition files.

    Raises:
      AvbError: If getting the partition digests from the image fails.
    """
    image = ImageHandler(image_filename, read_only=True)
    (_, _, descriptors, _) = self._parse_image(image)

    for desc in descriptors:
      if isinstance(desc, AvbHashDescriptor):
        digest = desc.digest.hex()
        if json_partitions is not None:
          json_partitions.append({'name': desc.partition_name,
                                  'digest': digest})
        else:
          output.write('{}: {}\n'.format(desc.partition_name, digest))
      elif isinstance(desc, AvbHashtreeDescriptor):
        digest = desc.root_digest.hex()
        if json_partitions is not None:
          json_partitions.append({'name': desc.partition_name,
                                  'digest': digest})
        else:
          output.write('{}: {}\n'.format(desc.partition_name, digest))
      elif isinstance(desc, AvbChainPartitionDescriptor):
        chained_image_filename = os.path.join(image_dir,
                                              desc.partition_name + image_ext)
        self._print_partition_digests(
            chained_image_filename, output, json_partitions, image_dir,
            image_ext)

  def calculate_vbmeta_digest(self, image_filename, hash_algorithm, output):
    """Implements the 'calculate_vbmeta_digest' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      hash_algorithm: Hash algorithm used.
      output: Output file to write human-readable information to (file object).
    """

    image_dir = os.path.dirname(image_filename)
    image_ext = os.path.splitext(image_filename)[1]

    image = ImageHandler(image_filename, read_only=True)
    (footer, header, descriptors, _) = self._parse_image(image)
    offset = 0
    if footer:
      offset = footer.vbmeta_offset
    size = (header.SIZE + header.authentication_data_block_size +
            header.auxiliary_data_block_size)
    image.seek(offset)
    vbmeta_blob = image.read(size)

    hasher = hashlib.new(hash_algorithm)
    hasher.update(vbmeta_blob)

    for desc in descriptors:
      if isinstance(desc, AvbChainPartitionDescriptor):
        ch_image_filename = os.path.join(image_dir,
                                         desc.partition_name + image_ext)
        ch_image = ImageHandler(ch_image_filename, read_only=True)
        (ch_footer, ch_header, _, _) = self._parse_image(ch_image)
        ch_offset = 0
        ch_size = (ch_header.SIZE + ch_header.authentication_data_block_size +
                   ch_header.auxiliary_data_block_size)
        if ch_footer:
          ch_offset = ch_footer.vbmeta_offset
        ch_image.seek(ch_offset)
        ch_vbmeta_blob = ch_image.read(ch_size)
        hasher.update(ch_vbmeta_blob)

    digest = hasher.digest()
    output.write('{}\n'.format(digest.hex()))

  def calculate_kernel_cmdline(self, image_filename, hashtree_disabled, output):
    """Implements the 'calculate_kernel_cmdline' command.

    Arguments:
      image_filename: Image file to get information from (file object).
      hashtree_disabled: If True, returns the cmdline for hashtree disabled.
      output: Output file to write human-readable information to (file object).
    """

    image = ImageHandler(image_filename, read_only=True)
    _, _, descriptors, _ = self._parse_image(image)

    image_dir = os.path.dirname(image_filename)
    image_ext = os.path.splitext(image_filename)[1]

    cmdline_descriptors = []
    for desc in descriptors:
      if isinstance(desc, AvbChainPartitionDescriptor):
        ch_image_filename = os.path.join(image_dir,
                                         desc.partition_name + image_ext)
        ch_image = ImageHandler(ch_image_filename, read_only=True)
        _, _, ch_descriptors, _ = self._parse_image(ch_image)
        for ch_desc in ch_descriptors:
          if isinstance(ch_desc, AvbKernelCmdlineDescriptor):
            cmdline_descriptors.append(ch_desc)
      elif isinstance(desc, AvbKernelCmdlineDescriptor):
        cmdline_descriptors.append(desc)

    kernel_cmdline_snippets = []
    for desc in cmdline_descriptors:
      use_cmdline = True
      if ((desc.flags &
           AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED)
          != 0):
        if hashtree_disabled:
          use_cmdline = False
      if (desc.flags &
          AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_DISABLED) != 0:
        if not hashtree_disabled:
          use_cmdline = False
      if use_cmdline:
        kernel_cmdline_snippets.append(desc.kernel_cmdline)
    output.write(' '.join(kernel_cmdline_snippets))

  def _parse_image(self, image):
    """Gets information about an image.

    The image can either be a vbmeta or an image with a footer.

    Arguments:
      image: An ImageHandler (vbmeta or footer) with a hashtree descriptor.

    Returns:
      A tuple where the first argument is a AvbFooter (None if there
      is no footer on the image), the second argument is a
      AvbVBMetaHeader, the third argument is a list of
      AvbDescriptor-derived instances, and the fourth argument is the
      size of |image|.

    Raises:
      AvbError: In case the image cannot be parsed.
    """
    assert isinstance(image, ImageHandler)
    footer = None
    image.seek(image.image_size - AvbFooter.SIZE)
    try:
      footer = AvbFooter(image.read(AvbFooter.SIZE))
    except (LookupError, struct.error):
      # Nope, just seek back to the start.
      image.seek(0)

    vbmeta_offset = 0
    if footer:
      vbmeta_offset = footer.vbmeta_offset

    image.seek(vbmeta_offset)
    h = AvbVBMetaHeader(image.read(AvbVBMetaHeader.SIZE))

    auth_block_offset = vbmeta_offset + AvbVBMetaHeader.SIZE
    aux_block_offset = auth_block_offset + h.authentication_data_block_size
    desc_start_offset = aux_block_offset + h.descriptors_offset
    image.seek(desc_start_offset)
    descriptors = parse_descriptors(image.read(h.descriptors_size))

    return footer, h, descriptors, image.image_size

  def _load_vbmeta_blob(self, image):
    """Gets the vbmeta struct and associated sections.

    The image can either be a vbmeta.img or an image with a footer.

    Arguments:
      image: An ImageHandler (vbmeta or footer).

    Returns:
      A blob with the vbmeta struct and other sections.
    """
    assert isinstance(image, ImageHandler)
    footer = None
    image.seek(image.image_size - AvbFooter.SIZE)
    try:
      footer = AvbFooter(image.read(AvbFooter.SIZE))
    except (LookupError, struct.error):
      # Nope, just seek back to the start.
      image.seek(0)

    vbmeta_offset = 0
    if footer:
      vbmeta_offset = footer.vbmeta_offset

    image.seek(vbmeta_offset)
    h = AvbVBMetaHeader(image.read(AvbVBMetaHeader.SIZE))

    image.seek(vbmeta_offset)
    data_size = AvbVBMetaHeader.SIZE
    data_size += h.authentication_data_block_size
    data_size += h.auxiliary_data_block_size
    return image.read(data_size)

  def _get_cmdline_descriptors_for_hashtree_descriptor(self, ht):
    """Generate kernel cmdline descriptors for dm-verity.

    Arguments:
      ht: A AvbHashtreeDescriptor

    Returns:
      A list with two AvbKernelCmdlineDescriptor with dm-verity kernel cmdline
      instructions. There is one for when hashtree is not disabled and one for
      when it is.

    """
    c = 'dm="1 vroot none ro 1,'
    c += '0'                                                # start
    c += ' {}'.format((ht.image_size // 512))               # size (# sectors)
    c += ' verity {}'.format(ht.dm_verity_version)          # type and version
    c += ' PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'             # data_dev
    c += ' PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'             # hash_dev
    c += ' {}'.format(ht.data_block_size)                   # data_block
    c += ' {}'.format(ht.hash_block_size)                   # hash_block
    c += ' {}'.format(ht.image_size // ht.data_block_size)  # #blocks
    c += ' {}'.format(ht.image_size // ht.data_block_size)  # hash_offset
    c += ' {}'.format(ht.hash_algorithm)                    # hash_alg
    c += ' {}'.format(ht.root_digest.hex())                 # root_digest
    c += ' {}'.format(ht.salt.hex())                        # salt
    if ht.fec_num_roots > 0:
      if ht.flags & AvbHashtreeDescriptor.FLAGS_CHECK_AT_MOST_ONCE:
        c += ' 11'  # number of optional args
        c += ' check_at_most_once'
      else:
        c += ' 10'  # number of optional args
      c += ' $(ANDROID_VERITY_MODE)'
      c += ' ignore_zero_blocks'
      c += ' use_fec_from_device PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'
      c += ' fec_roots {}'.format(ht.fec_num_roots)
      # Note that fec_blocks is the size that FEC covers, *not* the
      # size of the FEC data. Since we use FEC for everything up until
      # the FEC data, it's the same as the offset.
      c += ' fec_blocks {}'.format(ht.fec_offset // ht.data_block_size)
      c += ' fec_start {}'.format(ht.fec_offset // ht.data_block_size)
    else:
      if ht.flags & AvbHashtreeDescriptor.FLAGS_CHECK_AT_MOST_ONCE:
        c += ' 3'  # number of optional args
        c += ' check_at_most_once'
      else:
        c += ' 2'  # number of optional args
      c += ' $(ANDROID_VERITY_MODE)'
      c += ' ignore_zero_blocks'
    c += '" root=/dev/dm-0'

    # Now that we have the command-line, generate the descriptor.
    desc = AvbKernelCmdlineDescriptor()
    desc.kernel_cmdline = c
    desc.flags = (
        AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED)

    # The descriptor for when hashtree verification is disabled is a lot
    # simpler - we just set the root to the partition.
    desc_no_ht = AvbKernelCmdlineDescriptor()
    desc_no_ht.kernel_cmdline = 'root=PARTUUID=$(ANDROID_SYSTEM_PARTUUID)'
    desc_no_ht.flags = (
        AvbKernelCmdlineDescriptor.FLAGS_USE_ONLY_IF_HASHTREE_DISABLED)

    return [desc, desc_no_ht]

  def _get_cmdline_descriptors_for_dm_verity(self, image):
    """Generate kernel cmdline descriptors for dm-verity.

    Arguments:
      image: An ImageHandler (vbmeta or footer) with a hashtree descriptor.

    Returns:
      A list with two AvbKernelCmdlineDescriptor with dm-verity kernel cmdline
      instructions. There is one for when hashtree is not disabled and one for
      when it is.

    Raises:
      AvbError: If  |image| doesn't have a hashtree descriptor.

    """
    (_, _, descriptors, _) = self._parse_image(image)

    ht = None
    for desc in descriptors:
      if isinstance(desc, AvbHashtreeDescriptor):
        ht = desc
        break

    if not ht:
      raise AvbError('No hashtree descriptor in given image')

    return self._get_cmdline_descriptors_for_hashtree_descriptor(ht)

  def make_vbmeta_image(self, output, chain_partitions, algorithm_name,
                        key_path, public_key_metadata_path, rollback_index,
                        flags, rollback_index_location,
                        props, props_from_file, kernel_cmdlines,
                        setup_rootfs_from_kernel,
                        include_descriptors_from_image,
                        signing_helper,
                        signing_helper_with_files,
                        release_string,
                        append_to_release_string,
                        print_required_libavb_version,
                        padding_size):
    """Implements the 'make_vbmeta_image' command.

    Arguments:
      output: File to write the image to.
      chain_partitions: List of partitions to chain or None.
      algorithm_name: Name of algorithm to use.
      key_path: Path to key to use or None.
      public_key_metadata_path: Path to public key metadata or None.
      rollback_index: The rollback index to use.
      flags: Flags value to use in the image.
      rollback_index_location: Location of the main vbmeta rollback index.
      props: Properties to insert (list of strings of the form 'key:value').
      props_from_file: Properties to insert (list of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate from.
      include_descriptors_from_image: List of file objects with descriptors.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string to use instead of default.
      append_to_release_string: None or string to append.
      print_required_libavb_version: True to only print required libavb version.
      padding_size: If not 0, pads output so size is a multiple of the number.

    Raises:
      AvbError: If a chained partition is malformed.
    """
    # If we're asked to calculate minimum required libavb version, we're done.
    tmp_header = AvbVBMetaHeader()
    if rollback_index_location > 0:
      tmp_header.bump_required_libavb_version_minor(2)
    if include_descriptors_from_image:
      # Use the bump logic in AvbVBMetaHeader to calculate the max required
      # version of all included descriptors.
      for image in include_descriptors_from_image:
        (_, image_header, _, _) = self._parse_image(ImageHandler(
            image.name, read_only=True))
        tmp_header.bump_required_libavb_version_minor(
            image_header.required_libavb_version_minor)

    if print_required_libavb_version:
      print('1.{}'.format(tmp_header.required_libavb_version_minor))
      return

    if not output:
      raise AvbError('No output file given')

    descriptors = []
    ht_desc_to_setup = None
    vbmeta_blob = self._generate_vbmeta_blob(
        algorithm_name, key_path, public_key_metadata_path, descriptors,
        chain_partitions, rollback_index, flags, rollback_index_location,
        props, props_from_file,
        kernel_cmdlines, setup_rootfs_from_kernel, ht_desc_to_setup,
        include_descriptors_from_image, signing_helper,
        signing_helper_with_files, release_string,
        append_to_release_string, tmp_header.required_libavb_version_minor)

    # Write entire vbmeta blob (header, authentication, auxiliary).
    output.seek(0)
    output.write(vbmeta_blob)

    if padding_size > 0:
      padded_size = round_to_multiple(len(vbmeta_blob), padding_size)
      padding_needed = padded_size - len(vbmeta_blob)
      output.write(b'\0' * padding_needed)

  def _generate_vbmeta_blob(self, algorithm_name, key_path,
                            public_key_metadata_path, descriptors,
                            chain_partitions,
                            rollback_index, flags, rollback_index_location,
                            props, props_from_file,
                            kernel_cmdlines,
                            setup_rootfs_from_kernel,
                            ht_desc_to_setup,
                            include_descriptors_from_image, signing_helper,
                            signing_helper_with_files,
                            release_string, append_to_release_string,
                            required_libavb_version_minor):
    """Generates a VBMeta blob.

    This blob contains the header (struct AvbVBMetaHeader), the
    authentication data block (which contains the hash and signature
    for the header and auxiliary block), and the auxiliary block
    (which contains descriptors, the public key used, and other data).

    The |key| parameter can |None| only if the |algorithm_name| is
    'NONE'.

    Arguments:
      algorithm_name: The algorithm name as per the ALGORITHMS dict.
      key_path: The path to the .pem file used to sign the blob.
      public_key_metadata_path: Path to public key metadata or None.
      descriptors: A list of descriptors to insert or None.
      chain_partitions: List of partitions to chain or None.
      rollback_index: The rollback index to use.
      flags: Flags to use in the image.
      rollback_index_location: Location of the main vbmeta rollback index.
      props: Properties to insert (List of strings of the form 'key:value').
      props_from_file: Properties to insert (List of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate
        dm-verity kernel cmdline from.
      ht_desc_to_setup: If not None, an AvbHashtreeDescriptor to
        generate dm-verity kernel cmdline descriptors from.
      include_descriptors_from_image: List of file objects for which
        to insert descriptors from.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string.
      append_to_release_string: None or string to append.
      required_libavb_version_minor: Use at least this required minor version.

    Returns:
      The VBMeta blob as bytes.

    Raises:
      Exception: If the |algorithm_name| is not found, if no key has
        been given and the given algorithm requires one, or the key is
        of the wrong size.
    """
    try:
      alg = ALGORITHMS[algorithm_name]
    except KeyError as e:
      raise AvbError('Unknown algorithm with name {}'
                     .format(algorithm_name)) from e

    if not descriptors:
      descriptors = []

    h = AvbVBMetaHeader()
    h.bump_required_libavb_version_minor(required_libavb_version_minor)

    # Insert chained partition descriptors, if any
    if chain_partitions:
      used_locations = {rollback_index_location: True}
      for cp in chain_partitions:
        cp_tokens = cp.split(':')
        if len(cp_tokens) != 3:
          raise AvbError('Malformed chained partition "{}".'.format(cp))
        partition_name = cp_tokens[0]
        chained_rollback_index_location = int(cp_tokens[1])
        file_path = cp_tokens[2]
        # Check that the same rollback location isn't being used by
        # multiple chained partitions.
        if used_locations.get(chained_rollback_index_location):
          raise AvbError('Rollback Index Location {} is already in use.'.format(
              chained_rollback_index_location))
        used_locations[chained_rollback_index_location] = True
        desc = AvbChainPartitionDescriptor()
        desc.partition_name = partition_name
        desc.rollback_index_location = chained_rollback_index_location
        if desc.rollback_index_location < 1:
          raise AvbError('Rollback index location must be 1 or larger.')
        with open(file_path, 'rb') as f:
          desc.public_key = f.read()
        descriptors.append(desc)

    # Descriptors.
    encoded_descriptors = bytearray()
    for desc in descriptors:
      encoded_descriptors.extend(desc.encode())

    # Add properties.
    if props:
      for prop in props:
        idx = prop.find(':')
        if idx == -1:
          raise AvbError('Malformed property "{}".'.format(prop))
        # pylint: disable=redefined-variable-type
        desc = AvbPropertyDescriptor()
        desc.key = prop[0:idx]
        desc.value = prop[(idx + 1):].encode('utf-8')
        encoded_descriptors.extend(desc.encode())
    if props_from_file:
      for prop in props_from_file:
        idx = prop.find(':')
        if idx == -1:
          raise AvbError('Malformed property "{}".'.format(prop))
        desc = AvbPropertyDescriptor()
        desc.key = prop[0:idx]
        file_path = prop[(idx + 1):]
        with open(file_path, 'rb') as f:
          # pylint: disable=attribute-defined-outside-init
          desc.value = f.read()
        encoded_descriptors.extend(desc.encode())

    # Add AvbKernelCmdline descriptor for dm-verity from an image, if requested.
    if setup_rootfs_from_kernel:
      image_handler = ImageHandler(
          setup_rootfs_from_kernel.name)
      cmdline_desc = self._get_cmdline_descriptors_for_dm_verity(image_handler)
      encoded_descriptors.extend(cmdline_desc[0].encode())
      encoded_descriptors.extend(cmdline_desc[1].encode())

    # Add AvbKernelCmdline descriptor for dm-verity from desc, if requested.
    if ht_desc_to_setup:
      cmdline_desc = self._get_cmdline_descriptors_for_hashtree_descriptor(
          ht_desc_to_setup)
      encoded_descriptors.extend(cmdline_desc[0].encode())
      encoded_descriptors.extend(cmdline_desc[1].encode())

    # Add kernel command-lines.
    if kernel_cmdlines:
      for i in kernel_cmdlines:
        desc = AvbKernelCmdlineDescriptor()
        desc.kernel_cmdline = i
        encoded_descriptors.extend(desc.encode())

    # Add descriptors from other images.
    if include_descriptors_from_image:
      descriptors_dict = dict()
      for image in include_descriptors_from_image:
        image_handler = ImageHandler(image.name, read_only=True)
        (_, image_vbmeta_header, image_descriptors, _) = self._parse_image(
            image_handler)
        # Bump the required libavb version to support all included descriptors.
        h.bump_required_libavb_version_minor(
            image_vbmeta_header.required_libavb_version_minor)
        for desc in image_descriptors:
          # The --include_descriptors_from_image option is used in some setups
          # with images A and B where both A and B contain a descriptor
          # for a partition with the same name. Since it's not meaningful
          # to include both descriptors, only include the last seen descriptor.
          # See bug 76386656 for details.
          if hasattr(desc, 'partition_name'):
            key = type(desc).__name__ + '_' + desc.partition_name
            descriptors_dict[key] = desc.encode()
          else:
            encoded_descriptors.extend(desc.encode())
      for key in sorted(descriptors_dict):
        encoded_descriptors.extend(descriptors_dict[key])

    # Load public key metadata blob, if requested.
    pkmd_blob = b''
    if public_key_metadata_path:
      with open(public_key_metadata_path, 'rb') as f:
        pkmd_blob = f.read()

    key = None
    encoded_key = b''
    if alg.public_key_num_bytes > 0:
      if not key_path:
        raise AvbError('Key is required for algorithm {}'.format(
            algorithm_name))
      encoded_key = RSAPublicKey(key_path).encode()
      if len(encoded_key) != alg.public_key_num_bytes:
        raise AvbError('Key is wrong size for algorithm {}'.format(
            algorithm_name))

    # Override release string, if requested.
    if isinstance(release_string, str):
      h.release_string = release_string

    # Append to release string, if requested. Also insert a space before.
    if isinstance(append_to_release_string, str):
      h.release_string += ' ' + append_to_release_string

    # For the Auxiliary data block, descriptors are stored at offset 0,
    # followed by the public key, followed by the public key metadata blob.
    h.auxiliary_data_block_size = round_to_multiple(
        len(encoded_descriptors) + len(encoded_key) + len(pkmd_blob), 64)
    h.descriptors_offset = 0
    h.descriptors_size = len(encoded_descriptors)
    h.public_key_offset = h.descriptors_size
    h.public_key_size = len(encoded_key)
    h.public_key_metadata_offset = h.public_key_offset + h.public_key_size
    h.public_key_metadata_size = len(pkmd_blob)

    # For the Authentication data block, the hash is first and then
    # the signature.
    h.authentication_data_block_size = round_to_multiple(
        alg.hash_num_bytes + alg.signature_num_bytes, 64)
    h.algorithm_type = alg.algorithm_type
    h.hash_offset = 0
    h.hash_size = alg.hash_num_bytes
    # Signature offset and size - it's stored right after the hash
    # (in Authentication data block).
    h.signature_offset = alg.hash_num_bytes
    h.signature_size = alg.signature_num_bytes

    h.rollback_index = rollback_index
    h.flags = flags
    h.rollback_index_location = rollback_index_location

    # Generate Header data block.
    header_data_blob = h.encode()

    # Generate Auxiliary data block.
    aux_data_blob = bytearray()
    aux_data_blob.extend(encoded_descriptors)
    aux_data_blob.extend(encoded_key)
    aux_data_blob.extend(pkmd_blob)
    padding_bytes = h.auxiliary_data_block_size - len(aux_data_blob)
    aux_data_blob.extend(b'\0' * padding_bytes)

    # Calculate the hash.
    binary_hash = b''
    binary_signature = b''
    if algorithm_name != 'NONE':
      ha = hashlib.new(alg.hash_name)
      ha.update(header_data_blob)
      ha.update(aux_data_blob)
      binary_hash = ha.digest()

      # Calculate the signature.
      rsa_key = RSAPublicKey(key_path)
      data_to_sign = header_data_blob + bytes(aux_data_blob)
      binary_signature = rsa_key.sign(algorithm_name, data_to_sign,
                                      signing_helper, signing_helper_with_files)

    # Generate Authentication data block.
    auth_data_blob = bytearray()
    auth_data_blob.extend(binary_hash)
    auth_data_blob.extend(binary_signature)
    padding_bytes = h.authentication_data_block_size - len(auth_data_blob)
    auth_data_blob.extend(b'\0' * padding_bytes)

    return header_data_blob + bytes(auth_data_blob) + bytes(aux_data_blob)

  def extract_public_key(self, key_path, output):
    """Implements the 'extract_public_key' command.

    Arguments:
      key_path: The path to a RSA private key file.
      output: The file to write to.

    Raises:
      AvbError: If the public key could not be extracted.
    """
    output.write(RSAPublicKey(key_path).encode())

  def append_vbmeta_image(self, image_filename, vbmeta_image_filename,
                          partition_size):
    """Implementation of the append_vbmeta_image command.

    Arguments:
      image_filename: File to add the footer to.
      vbmeta_image_filename: File to get vbmeta struct from.
      partition_size: Size of partition.

    Raises:
      AvbError: If an argument is incorrect or if appending VBMeta image fialed.
    """
    image = ImageHandler(image_filename)

    if partition_size % image.block_size != 0:
      raise AvbError('Partition size of {} is not a multiple of the image '
                     'block size {}.'.format(partition_size,
                                             image.block_size))

    # If there's already a footer, truncate the image to its original
    # size. This way 'avbtool append_vbmeta_image' is idempotent.
    if image.image_size >= AvbFooter.SIZE:
      image.seek(image.image_size - AvbFooter.SIZE)
      try:
        footer = AvbFooter(image.read(AvbFooter.SIZE))
        # Existing footer found. Just truncate.
        original_image_size = footer.original_image_size
        image.truncate(footer.original_image_size)
      except (LookupError, struct.error):
        original_image_size = image.image_size
    else:
      # Image size is too small to possibly contain a footer.
      original_image_size = image.image_size

    # If anything goes wrong from here-on, restore the image back to
    # its original size.
    try:
      vbmeta_image_handler = ImageHandler(vbmeta_image_filename)
      vbmeta_blob = self._load_vbmeta_blob(vbmeta_image_handler)

      # If the image isn't sparse, its size might not be a multiple of
      # the block size. This will screw up padding later so just grow it.
      if image.image_size % image.block_size != 0:
        assert not image.is_sparse
        padding_needed = image.block_size - (image.image_size%image.block_size)
        image.truncate(image.image_size + padding_needed)

      # The append_raw() method requires content with size being a
      # multiple of |block_size| so add padding as needed. Also record
      # where this is written to since we'll need to put that in the
      # footer.
      vbmeta_offset = image.image_size
      padding_needed = (round_to_multiple(len(vbmeta_blob), image.block_size) -
                        len(vbmeta_blob))
      vbmeta_blob_with_padding = vbmeta_blob + b'\0' * padding_needed

      # Append vbmeta blob and footer
      image.append_raw(vbmeta_blob_with_padding)
      vbmeta_end_offset = vbmeta_offset + len(vbmeta_blob_with_padding)

      # Now insert a DONT_CARE chunk with enough bytes such that the
      # final Footer block is at the end of partition_size..
      image.append_dont_care(partition_size - vbmeta_end_offset -
                             1 * image.block_size)

      # Generate the Footer that tells where the VBMeta footer
      # is. Also put enough padding in the front of the footer since
      # we'll write out an entire block.
      footer = AvbFooter()
      footer.original_image_size = original_image_size
      footer.vbmeta_offset = vbmeta_offset
      footer.vbmeta_size = len(vbmeta_blob)
      footer_blob = footer.encode()
      footer_blob_with_padding = (b'\0' * (image.block_size - AvbFooter.SIZE) +
                                  footer_blob)
      image.append_raw(footer_blob_with_padding)

    except Exception as e:
      # Truncate back to original size, then re-raise.
      image.truncate(original_image_size)
      raise AvbError('Appending VBMeta image failed: {}.'.format(e)) from e

  def add_hash_footer(self, image_filename, partition_size,
                      dynamic_partition_size, partition_name,
                      hash_algorithm, salt, chain_partitions, algorithm_name,
                      key_path,
                      public_key_metadata_path, rollback_index, flags,
                      rollback_index_location, props,
                      props_from_file, kernel_cmdlines,
                      setup_rootfs_from_kernel,
                      include_descriptors_from_image, calc_max_image_size,
                      signing_helper, signing_helper_with_files,
                      release_string, append_to_release_string,
                      output_vbmeta_image, do_not_append_vbmeta_image,
                      print_required_libavb_version, use_persistent_digest,
                      do_not_use_ab):
    """Implementation of the add_hash_footer on unsparse images.

    Arguments:
      image_filename: File to add the footer to.
      partition_size: Size of partition.
      dynamic_partition_size: Calculate partition size based on image size.
      partition_name: Name of partition (without A/B suffix).
      hash_algorithm: Hash algorithm to use.
      salt: Salt to use as a hexadecimal string or None to use /dev/urandom.
      chain_partitions: List of partitions to chain.
      algorithm_name: Name of algorithm to use.
      key_path: Path to key to use or None.
      public_key_metadata_path: Path to public key metadata or None.
      rollback_index: Rollback index.
      flags: Flags value to use in the image.
      rollback_index_location: Location of the main vbmeta rollback index.
      props: Properties to insert (List of strings of the form 'key:value').
      props_from_file: Properties to insert (List of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate
        dm-verity kernel cmdline from.
      include_descriptors_from_image: List of file objects for which
        to insert descriptors from.
      calc_max_image_size: Don't store the footer - instead calculate the
        maximum image size leaving enough room for metadata with the
        given |partition_size|.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string.
      append_to_release_string: None or string to append.
      output_vbmeta_image: If not None, also write vbmeta struct to this file.
      do_not_append_vbmeta_image: If True, don't append vbmeta struct.
      print_required_libavb_version: True to only print required libavb version.
      use_persistent_digest: Use a persistent digest on device.
      do_not_use_ab: This partition does not use A/B.

    Raises:
      AvbError: If an argument is incorrect of if adding of hash_footer failed.
    """
    if not partition_size and not dynamic_partition_size:
      raise AvbError('--dynamic_partition_size required when not specifying a '
                     'partition size')

    if dynamic_partition_size and calc_max_image_size:
      raise AvbError('--calc_max_image_size not supported with '
                     '--dynamic_partition_size')

    required_libavb_version_minor = 0
    if use_persistent_digest or do_not_use_ab:
      required_libavb_version_minor = 1
    if rollback_index_location > 0:
      required_libavb_version_minor = 2

    # If we're asked to calculate minimum required libavb version, we're done.
    if print_required_libavb_version:
      print('1.{}'.format(required_libavb_version_minor))
      return

    # First, calculate the maximum image size such that an image
    # this size + metadata (footer + vbmeta struct) fits in
    # |partition_size|.
    max_metadata_size = self.MAX_VBMETA_SIZE + self.MAX_FOOTER_SIZE
    if not dynamic_partition_size and partition_size < max_metadata_size:
      raise AvbError('Parition size of {} is too small. '
                     'Needs to be at least {}'.format(
                         partition_size, max_metadata_size))

    # If we're asked to only calculate the maximum image size, we're done.
    if calc_max_image_size:
      print('{}'.format(partition_size - max_metadata_size))
      return

    image = ImageHandler(image_filename)

    # If there's already a footer, truncate the image to its original
    # size. This way 'avbtool add_hash_footer' is idempotent (modulo
    # salts).
    if image.image_size >= AvbFooter.SIZE:
      image.seek(image.image_size - AvbFooter.SIZE)
      try:
        footer = AvbFooter(image.read(AvbFooter.SIZE))
        # Existing footer found. Just truncate.
        original_image_size = footer.original_image_size
        image.truncate(footer.original_image_size)
      except (LookupError, struct.error):
        original_image_size = image.image_size
    else:
      # Image size is too small to possibly contain a footer.
      original_image_size = image.image_size

    if dynamic_partition_size:
      partition_size = round_to_multiple(
          original_image_size + max_metadata_size, image.block_size)

    max_image_size = partition_size - max_metadata_size
    if partition_size % image.block_size != 0:
      raise AvbError('Partition size of {} is not a multiple of the image '
                     'block size {}.'.format(partition_size,
                                             image.block_size))

    # If anything goes wrong from here-on, restore the image back to
    # its original size.
    try:
      # If image size exceeds the maximum image size, fail.
      if image.image_size > max_image_size:
        raise AvbError('Image size of {} exceeds maximum image '
                       'size of {} in order to fit in a partition '
                       'size of {}.'.format(image.image_size, max_image_size,
                                            partition_size))

      digest_size = len(hashlib.new(hash_algorithm).digest())
      if salt:
        salt = binascii.unhexlify(salt)
      elif salt is None and not use_persistent_digest:
        # If salt is not explicitly specified, choose a hash that's the same
        # size as the hash size. Don't populate a random salt if this
        # descriptor is being created to use a persistent digest on device.
        hash_size = digest_size
        with open('/dev/urandom', 'rb') as f:
          salt = f.read(hash_size)
      else:
        salt = b''

      hasher = hashlib.new(hash_algorithm, salt)
      # TODO(zeuthen): might want to read this in chunks to avoid
      # memory pressure, then again, this is only supposed to be used
      # on kernel/initramfs partitions. Possible optimization.
      image.seek(0)
      hasher.update(image.read(image.image_size))
      digest = hasher.digest()

      h_desc = AvbHashDescriptor()
      h_desc.image_size = image.image_size
      h_desc.hash_algorithm = hash_algorithm
      h_desc.partition_name = partition_name
      h_desc.salt = salt
      h_desc.flags = 0
      if do_not_use_ab:
        h_desc.flags |= 1  # AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB
      if not use_persistent_digest:
        h_desc.digest = digest

      # Generate the VBMeta footer.
      ht_desc_to_setup = None
      vbmeta_blob = self._generate_vbmeta_blob(
          algorithm_name, key_path, public_key_metadata_path, [h_desc],
          chain_partitions, rollback_index, flags, rollback_index_location,
          props, props_from_file,
          kernel_cmdlines, setup_rootfs_from_kernel, ht_desc_to_setup,
          include_descriptors_from_image, signing_helper,
          signing_helper_with_files, release_string,
          append_to_release_string, required_libavb_version_minor)

      # Write vbmeta blob, if requested.
      if output_vbmeta_image:
        output_vbmeta_image.write(vbmeta_blob)

      # Append vbmeta blob and footer, unless requested not to.
      if not do_not_append_vbmeta_image:
        # If the image isn't sparse, its size might not be a multiple of
        # the block size. This will screw up padding later so just grow it.
        if image.image_size % image.block_size != 0:
          assert not image.is_sparse
          padding_needed = image.block_size - (
              image.image_size % image.block_size)
          image.truncate(image.image_size + padding_needed)

        # The append_raw() method requires content with size being a
        # multiple of |block_size| so add padding as needed. Also record
        # where this is written to since we'll need to put that in the
        # footer.
        vbmeta_offset = image.image_size
        padding_needed = (
            round_to_multiple(len(vbmeta_blob), image.block_size) -
            len(vbmeta_blob))
        vbmeta_blob_with_padding = vbmeta_blob + b'\0' * padding_needed

        image.append_raw(vbmeta_blob_with_padding)
        vbmeta_end_offset = vbmeta_offset + len(vbmeta_blob_with_padding)

        # Now insert a DONT_CARE chunk with enough bytes such that the
        # final Footer block is at the end of partition_size..
        image.append_dont_care(partition_size - vbmeta_end_offset -
                               1 * image.block_size)

        # Generate the Footer that tells where the VBMeta footer
        # is. Also put enough padding in the front of the footer since
        # we'll write out an entire block.
        footer = AvbFooter()
        footer.original_image_size = original_image_size
        footer.vbmeta_offset = vbmeta_offset
        footer.vbmeta_size = len(vbmeta_blob)
        footer_blob = footer.encode()
        footer_blob_with_padding = (
            b'\0' * (image.block_size - AvbFooter.SIZE) + footer_blob)
        image.append_raw(footer_blob_with_padding)
    except Exception as e:
      # Truncate back to original size, then re-raise.
      image.truncate(original_image_size)
      raise AvbError('Adding hash_footer failed: {}.'.format(e)) from e

  def add_hashtree_footer(self, image_filename, partition_size, partition_name,
                          generate_fec, fec_num_roots, hash_algorithm,
                          block_size, salt, chain_partitions, algorithm_name,
                          key_path,
                          public_key_metadata_path, rollback_index, flags,
                          rollback_index_location,
                          props, props_from_file, kernel_cmdlines,
                          setup_rootfs_from_kernel,
                          setup_as_rootfs_from_kernel,
                          include_descriptors_from_image,
                          calc_max_image_size, signing_helper,
                          signing_helper_with_files,
                          release_string, append_to_release_string,
                          output_vbmeta_image, do_not_append_vbmeta_image,
                          print_required_libavb_version,
                          use_persistent_root_digest, do_not_use_ab,
                          no_hashtree, check_at_most_once):
    """Implements the 'add_hashtree_footer' command.

    See https://gitlab.com/cryptsetup/cryptsetup/wikis/DMVerity for
    more information about dm-verity and these hashes.

    Arguments:
      image_filename: File to add the footer to.
      partition_size: Size of partition or 0 to put it right at the end.
      partition_name: Name of partition (without A/B suffix).
      generate_fec: If True, generate FEC codes.
      fec_num_roots: Number of roots for FEC.
      hash_algorithm: Hash algorithm to use.
      block_size: Block size to use.
      salt: Salt to use as a hexadecimal string or None to use /dev/urandom.
      chain_partitions: List of partitions to chain.
      algorithm_name: Name of algorithm to use.
      key_path: Path to key to use or None.
      public_key_metadata_path: Path to public key metadata or None.
      rollback_index: Rollback index.
      flags: Flags value to use in the image.
      rollback_index_location: Location of the main vbmeta rollback index.
      props: Properties to insert (List of strings of the form 'key:value').
      props_from_file: Properties to insert (List of strings 'key:<path>').
      kernel_cmdlines: Kernel cmdlines to insert (list of strings).
      setup_rootfs_from_kernel: None or file to generate
        dm-verity kernel cmdline from.
      setup_as_rootfs_from_kernel: If True, generate dm-verity kernel
        cmdline to set up rootfs.
      include_descriptors_from_image: List of file objects for which
        to insert descriptors from.
      calc_max_image_size: Don't store the hashtree or footer - instead
        calculate the maximum image size leaving enough room for hashtree
        and metadata with the given |partition_size|.
      signing_helper: Program which signs a hash and return signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.
      release_string: None or avbtool release string.
      append_to_release_string: None or string to append.
      output_vbmeta_image: If not None, also write vbmeta struct to this file.
      do_not_append_vbmeta_image: If True, don't append vbmeta struct.
      print_required_libavb_version: True to only print required libavb version.
      use_persistent_root_digest: Use a persistent root digest on device.
      do_not_use_ab: The partition does not use A/B.
      no_hashtree: Do not append hashtree. Set size in descriptor as zero.
      check_at_most_once: Set to verify data blocks only the first time they
        are read from the data device.

    Raises:
      AvbError: If an argument is incorrect or adding the hashtree footer
          failed.
    """
    required_libavb_version_minor = 0
    if use_persistent_root_digest or do_not_use_ab or check_at_most_once:
      required_libavb_version_minor = 1
    if rollback_index_location > 0:
      required_libavb_version_minor = 2

    # If we're asked to calculate minimum required libavb version, we're done.
    if print_required_libavb_version:
      print('1.{}'.format(required_libavb_version_minor))
      return

    digest_size = len(create_avb_hashtree_hasher(hash_algorithm, b'')
                      .digest())
    digest_padding = round_to_pow2(digest_size) - digest_size

    # If |partition_size| is given (e.g. not 0), calculate the maximum image
    # size such that an image this size + the hashtree + metadata (footer +
    # vbmeta struct) fits in |partition_size|. We use very conservative figures
    # for metadata.
    if partition_size > 0:
      max_tree_size = 0
      max_fec_size = 0
      if not no_hashtree:
        (_, max_tree_size) = calc_hash_level_offsets(
            partition_size, block_size, digest_size + digest_padding)
        if generate_fec:
          max_fec_size = calc_fec_data_size(partition_size, fec_num_roots)
      max_metadata_size = (max_fec_size + max_tree_size +
                           self.MAX_VBMETA_SIZE +
                           self.MAX_FOOTER_SIZE)
      max_image_size = partition_size - max_metadata_size
    else:
      max_image_size = 0

    # If we're asked to only calculate the maximum image size, we're done.
    if calc_max_image_size:
      print('{}'.format(max_image_size))
      return

    image = ImageHandler(image_filename)

    if partition_size > 0:
      if partition_size % image.block_size != 0:
        raise AvbError('Partition size of {} is not a multiple of the image '
                       'block size {}.'.format(partition_size,
                                               image.block_size))
    elif image.image_size % image.block_size != 0:
      raise AvbError('File size of {} is not a multiple of the image '
                     'block size {}.'.format(image.image_size,
                                             image.block_size))

    # If there's already a footer, truncate the image to its original
    # size. This way 'avbtool add_hashtree_footer' is idempotent
    # (modulo salts).
    if image.image_size >= AvbFooter.SIZE:
      image.seek(image.image_size - AvbFooter.SIZE)
      try:
        footer = AvbFooter(image.read(AvbFooter.SIZE))
        # Existing footer found. Just truncate.
        original_image_size = footer.original_image_size
        image.truncate(footer.original_image_size)
      except (LookupError, struct.error):
        original_image_size = image.image_size
    else:
      # Image size is too small to possibly contain a footer.
      original_image_size = image.image_size

    # If anything goes wrong from here-on, restore the image back to
    # its original size.
    try:
      # Ensure image is multiple of block_size.
      rounded_image_size = round_to_multiple(image.image_size, block_size)
      if rounded_image_size > image.image_size:
        # If we need to round up the image size, it means the length of the
        # data to append is not a multiple of block size.
        # Setting multiple_block_size to false, so append_raw() will not
        # require it.
        image.append_raw(b'\0' * (rounded_image_size - image.image_size),
                         multiple_block_size=False)

      # If image size exceeds the maximum image size, fail.
      if partition_size > 0:
        if image.image_size > max_image_size:
          raise AvbError('Image size of {} exceeds maximum image '
                         'size of {} in order to fit in a partition '
                         'size of {}.'.format(image.image_size, max_image_size,
                                              partition_size))

      if salt:
        salt = binascii.unhexlify(salt)
      elif salt is None and not use_persistent_root_digest:
        # If salt is not explicitly specified, choose a hash that's the same
        # size as the hash size. Don't populate a random salt if this
        # descriptor is being created to use a persistent digest on device.
        hash_size = digest_size
        with open('/dev/urandom', 'rb') as f:
          salt = f.read(hash_size)
      else:
        salt = b''

      # Hashes are stored upside down so we need to calculate hash
      # offsets in advance.
      (hash_level_offsets, tree_size) = calc_hash_level_offsets(
          image.image_size, block_size, digest_size + digest_padding)

      # If the image isn't sparse, its size might not be a multiple of
      # the block size. This will screw up padding later so just grow it.
      if image.image_size % image.block_size != 0:
        assert not image.is_sparse
        padding_needed = image.block_size - (image.image_size%image.block_size)
        image.truncate(image.image_size + padding_needed)

      # Generate the tree and add padding as needed.
      tree_offset = image.image_size
      root_digest, hash_tree = generate_hash_tree(image, image.image_size,
                                                  block_size,
                                                  hash_algorithm, salt,
                                                  digest_padding,
                                                  hash_level_offsets,
                                                  tree_size)

      # Generate HashtreeDescriptor with details about the tree we
      # just generated.
      if no_hashtree:
        tree_size = 0
        hash_tree = b''
      ht_desc = AvbHashtreeDescriptor()
      ht_desc.dm_verity_version = 1
      ht_desc.image_size = image.image_size
      ht_desc.tree_offset = tree_offset
      ht_desc.tree_size = tree_size
      ht_desc.data_block_size = block_size
      ht_desc.hash_block_size = block_size
      ht_desc.hash_algorithm = hash_algorithm
      ht_desc.partition_name = partition_name
      ht_desc.salt = salt
      if do_not_use_ab:
        ht_desc.flags |= AvbHashtreeDescriptor.FLAGS_DO_NOT_USE_AB
      if not use_persistent_root_digest:
        ht_desc.root_digest = root_digest
      if check_at_most_once:
        ht_desc.flags |= AvbHashtreeDescriptor.FLAGS_CHECK_AT_MOST_ONCE

      # Write the hash tree
      padding_needed = (round_to_multiple(len(hash_tree), image.block_size) -
                        len(hash_tree))
      hash_tree_with_padding = hash_tree + b'\0' * padding_needed
      if len(hash_tree_with_padding) > 0:
        image.append_raw(hash_tree_with_padding)
      len_hashtree_and_fec = len(hash_tree_with_padding)

      # Generate FEC codes, if requested.
      if generate_fec:
        if no_hashtree:
          fec_data = b''
        else:
          fec_data = generate_fec_data(image_filename, fec_num_roots)
        padding_needed = (round_to_multiple(len(fec_data), image.block_size) -
                          len(fec_data))
        fec_data_with_padding = fec_data + b'\0' * padding_needed
        fec_offset = image.image_size
        image.append_raw(fec_data_with_padding)
        len_hashtree_and_fec += len(fec_data_with_padding)
        # Update the hashtree descriptor.
        ht_desc.fec_num_roots = fec_num_roots
        ht_desc.fec_offset = fec_offset
        ht_desc.fec_size = len(fec_data)

      ht_desc_to_setup = None
      if setup_as_rootfs_from_kernel:
        ht_desc_to_setup = ht_desc

      # Generate the VBMeta footer and add padding as needed.
      vbmeta_offset = tree_offset + len_hashtree_and_fec
      vbmeta_blob = self._generate_vbmeta_blob(
          algorithm_name, key_path, public_key_metadata_path, [ht_desc],
          chain_partitions, rollback_index, flags, rollback_index_location,
          props, props_from_file,
          kernel_cmdlines, setup_rootfs_from_kernel, ht_desc_to_setup,
          include_descriptors_from_image, signing_helper,
          signing_helper_with_files, release_string,
          append_to_release_string, required_libavb_version_minor)
      padding_needed = (round_to_multiple(len(vbmeta_blob), image.block_size) -
                        len(vbmeta_blob))
      vbmeta_blob_with_padding = vbmeta_blob + b'\0' * padding_needed

      # Write vbmeta blob, if requested.
      if output_vbmeta_image:
        output_vbmeta_image.write(vbmeta_blob)

      # Append vbmeta blob and footer, unless requested not to.
      if not do_not_append_vbmeta_image:
        image.append_raw(vbmeta_blob_with_padding)

        # Now insert a DONT_CARE chunk with enough bytes such that the
        # final Footer block is at the end of partition_size..
        if partition_size > 0:
          image.append_dont_care(partition_size - image.image_size -
                                 1 * image.block_size)

        # Generate the Footer that tells where the VBMeta footer
        # is. Also put enough padding in the front of the footer since
        # we'll write out an entire block.
        footer = AvbFooter()
        footer.original_image_size = original_image_size
        footer.vbmeta_offset = vbmeta_offset
        footer.vbmeta_size = len(vbmeta_blob)
        footer_blob = footer.encode()
        footer_blob_with_padding = (
            b'\0' * (image.block_size - AvbFooter.SIZE) + footer_blob)
        image.append_raw(footer_blob_with_padding)

    except Exception as e:
      # Truncate back to original size, then re-raise.
      image.truncate(original_image_size)
      raise AvbError('Adding hashtree_footer failed: {}.'.format(e)) from e

  def make_atx_certificate(self, output, authority_key_path, subject_key_path,
                           subject_key_version, subject,
                           is_intermediate_authority, usage, signing_helper,
                           signing_helper_with_files):
    """Implements the 'make_atx_certificate' command.

    Android Things certificates are required for Android Things public key
    metadata. They chain the vbmeta signing key for a particular product back to
    a fused, permanent root key. These certificates are fixed-length and fixed-
    format with the explicit goal of not parsing ASN.1 in bootloader code.

    Arguments:
      output: Certificate will be written to this file on success.
      authority_key_path: A PEM file path with the authority private key.
                          If None, then a certificate will be created without a
                          signature. The signature can be created out-of-band
                          and appended.
      subject_key_path: Path to a PEM or DER subject public key.
      subject_key_version: A 64-bit version value. If this is None, the number
                           of seconds since the epoch is used.
      subject: A subject identifier. For Product Signing Key certificates this
               should be the same Product ID found in the permanent attributes.
      is_intermediate_authority: True if the certificate is for an intermediate
                                 authority.
      usage: If not empty, overrides the cert usage with a hash of this value.
      signing_helper: Program which signs a hash and returns the signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.

    Raises:
      AvbError: If there an error during signing.
    """
    signed_data = bytearray()
    signed_data.extend(struct.pack('<I', 1))  # Format Version
    signed_data.extend(RSAPublicKey(subject_key_path).encode())
    hasher = hashlib.sha256()
    hasher.update(subject)
    signed_data.extend(hasher.digest())
    if not usage:
      usage = 'com.google.android.things.vboot'
      if is_intermediate_authority:
        usage += '.ca'
    hasher = hashlib.sha256()
    hasher.update(usage.encode('ascii'))
    signed_data.extend(hasher.digest())
    if subject_key_version is None:
      subject_key_version = int(time.time())
    signed_data.extend(struct.pack('<Q', subject_key_version))
    signature = b''
    if authority_key_path:
      rsa_key = RSAPublicKey(authority_key_path)
      algorithm_name = 'SHA512_RSA4096'
      signature = rsa_key.sign(algorithm_name, signed_data, signing_helper,
                               signing_helper_with_files)
    output.write(signed_data)
    output.write(signature)

  def make_atx_permanent_attributes(self, output, root_authority_key_path,
                                    product_id):
    """Implements the 'make_atx_permanent_attributes' command.

    Android Things permanent attributes are designed to be permanent for a
    particular product and a hash of these attributes should be fused into
    hardware to enforce this.

    Arguments:
      output: Attributes will be written to this file on success.
      root_authority_key_path: Path to a PEM or DER public key for
        the root authority.
      product_id: A 16-byte Product ID.

    Raises:
      AvbError: If an argument is incorrect.
    """
    EXPECTED_PRODUCT_ID_SIZE = 16  # pylint: disable=invalid-name
    if len(product_id) != EXPECTED_PRODUCT_ID_SIZE:
      raise AvbError('Invalid Product ID length.')
    output.write(struct.pack('<I', 1))  # Format Version
    output.write(RSAPublicKey(root_authority_key_path).encode())
    output.write(product_id)

  def make_atx_metadata(self, output, intermediate_key_certificate,
                        product_key_certificate):
    """Implements the 'make_atx_metadata' command.

    Android Things metadata are included in vbmeta images to facilitate
    verification. The output of this command can be used as the
    public_key_metadata argument to other commands.

    Arguments:
      output: Metadata will be written to this file on success.
      intermediate_key_certificate: A certificate file as output by
                                    make_atx_certificate with
                                    is_intermediate_authority set to true.
      product_key_certificate: A certificate file as output by
                               make_atx_certificate with
                               is_intermediate_authority set to false.

    Raises:
      AvbError: If an argument is incorrect.
    """
    EXPECTED_CERTIFICATE_SIZE = 1620  # pylint: disable=invalid-name
    if len(intermediate_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid intermediate key certificate length.')
    if len(product_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid product key certificate length.')
    output.write(struct.pack('<I', 1))  # Format Version
    output.write(intermediate_key_certificate)
    output.write(product_key_certificate)

  def make_atx_unlock_credential(self, output, intermediate_key_certificate,
                                 unlock_key_certificate, challenge_path,
                                 unlock_key_path, signing_helper,
                                 signing_helper_with_files):
    """Implements the 'make_atx_unlock_credential' command.

    Android Things unlock credentials can be used to authorize the unlock of AVB
    on a device. These credentials are presented to an Android Things bootloader
    via the fastboot interface in response to a 16-byte challenge. This method
    creates all fields of the credential except the challenge signature field
    (which is the last field) and can optionally create the challenge signature
    field as well if a challenge and the unlock_key_path is provided.

    Arguments:
      output: The credential will be written to this file on success.
      intermediate_key_certificate: A certificate file as output by
                                    make_atx_certificate with
                                    is_intermediate_authority set to true.
      unlock_key_certificate: A certificate file as output by
                              make_atx_certificate with
                              is_intermediate_authority set to false and the
                              usage set to
                              'com.google.android.things.vboot.unlock'.
      challenge_path: [optional] A path to the challenge to sign.
      unlock_key_path: [optional] A PEM file path with the unlock private key.
      signing_helper: Program which signs a hash and returns the signature.
      signing_helper_with_files: Same as signing_helper but uses files instead.

    Raises:
      AvbError: If an argument is incorrect or an error occurs during signing.
    """
    EXPECTED_CERTIFICATE_SIZE = 1620  # pylint: disable=invalid-name
    EXPECTED_CHALLENGE_SIZE = 16  # pylint: disable=invalid-name
    if len(intermediate_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid intermediate key certificate length.')
    if len(unlock_key_certificate) != EXPECTED_CERTIFICATE_SIZE:
      raise AvbError('Invalid product key certificate length.')
    challenge = b''
    if challenge_path:
      with open(challenge_path, 'rb') as f:
        challenge = f.read()
      if len(challenge) != EXPECTED_CHALLENGE_SIZE:
        raise AvbError('Invalid unlock challenge length.')
    output.write(struct.pack('<I', 1))  # Format Version
    output.write(intermediate_key_certificate)
    output.write(unlock_key_certificate)
    if challenge_path and unlock_key_path:
      rsa_key = RSAPublicKey(unlock_key_path)
      algorithm_name = 'SHA512_RSA4096'
      signature = rsa_key.sign(algorithm_name, challenge, signing_helper,
                               signing_helper_with_files)
      output.write(signature)


def calc_hash_level_offsets(image_size, block_size, digest_size):
  """Calculate the offsets of all the hash-levels in a Merkle-tree.

  Arguments:
    image_size: The size of the image to calculate a Merkle-tree for.
    block_size: The block size, e.g. 4096.
    digest_size: The size of each hash, e.g. 32 for SHA-256.

  Returns:
    A tuple where the first argument is an array of offsets and the
    second is size of the tree, in bytes.
  """
  level_offsets = []
  level_sizes = []
  tree_size = 0

  num_levels = 0
  size = image_size
  while size > block_size:
    num_blocks = (size + block_size - 1) // block_size
    level_size = round_to_multiple(num_blocks * digest_size, block_size)

    level_sizes.append(level_size)
    tree_size += level_size
    num_levels += 1

    size = level_size

  for n in range(0, num_levels):
    offset = 0
    for m in range(n + 1, num_levels):
      offset += level_sizes[m]
    level_offsets.append(offset)

  return level_offsets, tree_size


# See system/extras/libfec/include/fec/io.h for these definitions.
FEC_FOOTER_FORMAT = '<LLLLLQ32s'
FEC_MAGIC = 0xfecfecfe


def calc_fec_data_size(image_size, num_roots):
  """Calculates how much space FEC data will take.

  Arguments:
    image_size: The size of the image.
    num_roots: Number of roots.

  Returns:
    The number of bytes needed for FEC for an image of the given size
    and with the requested number of FEC roots.

  Raises:
    ValueError: If output from the 'fec' tool is invalid.
  """
  p = subprocess.Popen(
      ['fec', '--print-fec-size', str(image_size), '--roots', str(num_roots)],
      stdout=subprocess.PIPE,
      stderr=subprocess.PIPE)
  (pout, perr) = p.communicate()
  retcode = p.wait()
  if retcode != 0:
    raise ValueError('Error invoking fec: {}'.format(perr))
  return int(pout)


def generate_fec_data(image_filename, num_roots):
  """Generate FEC codes for an image.

  Arguments:
    image_filename: The filename of the image.
    num_roots: Number of roots.

  Returns:
    The FEC data blob as bytes.

  Raises:
    ValueError: If calling the 'fec' tool failed or the output is invalid.
  """
  with tempfile.NamedTemporaryFile() as fec_tmpfile:
    try:
      subprocess.check_call(
          ['fec', '--encode', '--roots', str(num_roots), image_filename,
           fec_tmpfile.name],
          stderr=open(os.devnull, 'wb'))
    except subprocess.CalledProcessError as e:
      raise ValueError('Execution of \'fec\' tool failed: {}.'
                       .format(e)) from e
    fec_data = fec_tmpfile.read()

  footer_size = struct.calcsize(FEC_FOOTER_FORMAT)
  footer_data = fec_data[-footer_size:]
  (magic, _, _, num_roots, fec_size, _, _) = struct.unpack(FEC_FOOTER_FORMAT,
                                                           footer_data)
  if magic != FEC_MAGIC:
    raise ValueError('Unexpected magic in FEC footer')
  return fec_data[0:fec_size]


def generate_hash_tree(image, image_size, block_size, hash_alg_name, salt,
                       digest_padding, hash_level_offsets, tree_size):
  """Generates a Merkle-tree for a file.

  Arguments:
    image: The image, as a file.
    image_size: The size of the image.
    block_size: The block size, e.g. 4096.
    hash_alg_name: The hash algorithm, e.g. 'sha256' or 'sha1'.
    salt: The salt to use.
    digest_padding: The padding for each digest.
    hash_level_offsets: The offsets from calc_hash_level_offsets().
    tree_size: The size of the tree, in number of bytes.

  Returns:
    A tuple where the first element is the top-level hash as bytes and the
    second element is the hash-tree as bytes.
  """
  hash_ret = bytearray(tree_size)
  hash_src_offset = 0
  hash_src_size = image_size
  level_num = 0

  # If there is only one block, returns the top-level hash directly.
  if hash_src_size == block_size:
    hasher = create_avb_hashtree_hasher(hash_alg_name, salt)
    image.seek(0)
    hasher.update(image.read(block_size))
    return hasher.digest(), bytes(hash_ret)

  while hash_src_size > block_size:
    level_output_list = []
    remaining = hash_src_size
    while remaining > 0:
      hasher = create_avb_hashtree_hasher(hash_alg_name, salt)
      # Only read from the file for the first level - for subsequent
      # levels, access the array we're building.
      if level_num == 0:
        image.seek(hash_src_offset + hash_src_size - remaining)
        data = image.read(min(remaining, block_size))
      else:
        offset = hash_level_offsets[level_num - 1] + hash_src_size - remaining
        data = hash_ret[offset:offset + block_size]
      hasher.update(data)

      remaining -= len(data)
      if len(data) < block_size:
        hasher.update(b'\0' * (block_size - len(data)))
      level_output_list.append(hasher.digest())
      if digest_padding > 0:
        level_output_list.append(b'\0' * digest_padding)

    level_output = b''.join(level_output_list)

    padding_needed = (round_to_multiple(
        len(level_output), block_size) - len(level_output))
    level_output += b'\0' * padding_needed

    # Copy level-output into resulting tree.
    offset = hash_level_offsets[level_num]
    hash_ret[offset:offset + len(level_output)] = level_output

    # Continue on to the next level.
    hash_src_size = len(level_output)
    level_num += 1

  hasher = create_avb_hashtree_hasher(hash_alg_name, salt)
  hasher.update(level_output)
  return hasher.digest(), bytes(hash_ret)


class AvbTool(object):
  """Object for avbtool command-line tool."""

  def __init__(self):
    """Initializer method."""
    self.avb = Avb()

  def _add_common_args(self, sub_parser):
    """Adds arguments used by several sub-commands.

    Arguments:
      sub_parser: The parser to add arguments to.
    """
    sub_parser.add_argument('--algorithm',
                            help='Algorithm to use (default: NONE)',
                            metavar='ALGORITHM',
                            default='NONE')
    sub_parser.add_argument('--key',
                            help='Path to RSA private key file',
                            metavar='KEY',
                            required=False)
    sub_parser.add_argument('--signing_helper',
                            help='Path to helper used for signing',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--signing_helper_with_files',
                            help='Path to helper used for signing using files',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--public_key_metadata',
                            help='Path to public key metadata file',
                            metavar='KEY_METADATA',
                            required=False)
    sub_parser.add_argument('--rollback_index',
                            help='Rollback Index',
                            type=parse_number,
                            default=0)
    sub_parser.add_argument('--rollback_index_location',
                            help='Location of main vbmeta Rollback Index',
                            type=parse_number,
                            default=0)
    # This is used internally for unit tests. Do not include in --help output.
    sub_parser.add_argument('--internal_release_string',
                            help=argparse.SUPPRESS)
    sub_parser.add_argument('--append_to_release_string',
                            help='Text to append to release string',
                            metavar='STR')
    sub_parser.add_argument('--prop',
                            help='Add property',
                            metavar='KEY:VALUE',
                            action='append')
    sub_parser.add_argument('--prop_from_file',
                            help='Add property from file',
                            metavar='KEY:PATH',
                            action='append')
    sub_parser.add_argument('--kernel_cmdline',
                            help='Add kernel cmdline',
                            metavar='CMDLINE',
                            action='append')
    # TODO(zeuthen): the --setup_rootfs_from_kernel option used to be called
    # --generate_dm_verity_cmdline_from_hashtree. Remove support for the latter
    # at some future point.
    sub_parser.add_argument('--setup_rootfs_from_kernel',
                            '--generate_dm_verity_cmdline_from_hashtree',
                            metavar='IMAGE',
                            help='Adds kernel cmdline to set up IMAGE',
                            type=argparse.FileType('rb'))
    sub_parser.add_argument('--include_descriptors_from_image',
                            help='Include descriptors from image',
                            metavar='IMAGE',
                            action='append',
                            type=argparse.FileType('rb'))
    sub_parser.add_argument('--print_required_libavb_version',
                            help=('Don\'t store the footer - '
                                  'instead calculate the required libavb '
                                  'version for the given options.'),
                            action='store_true')
    # These are only allowed from top-level vbmeta and boot-in-lieu-of-vbmeta.
    sub_parser.add_argument('--chain_partition',
                            help='Allow signed integrity-data for partition',
                            metavar='PART_NAME:ROLLBACK_SLOT:KEY_PATH',
                            action='append')
    sub_parser.add_argument('--flags',
                            help='VBMeta flags',
                            type=parse_number,
                            default=0)
    sub_parser.add_argument('--set_hashtree_disabled_flag',
                            help='Set the HASHTREE_DISABLED flag',
                            action='store_true')

  def _add_common_footer_args(self, sub_parser):
    """Adds arguments used by add_*_footer sub-commands.

    Arguments:
      sub_parser: The parser to add arguments to.
    """
    sub_parser.add_argument('--use_persistent_digest',
                            help='Use a persistent digest on device instead of '
                                 'storing the digest in the descriptor. This '
                                 'cannot be used with A/B so must be combined '
                                 'with --do_not_use_ab when an A/B suffix is '
                                 'expected at runtime.',
                            action='store_true')
    sub_parser.add_argument('--do_not_use_ab',
                            help='The partition does not use A/B even when an '
                                 'A/B suffix is present. This must not be used '
                                 'for vbmeta or chained partitions.',
                            action='store_true')

  def _fixup_common_args(self, args):
    """Common fixups needed by subcommands.

    Arguments:
      args: Arguments to modify.

    Returns:
      The modified arguments.
    """
    if args.set_hashtree_disabled_flag:
      args.flags |= AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED
    return args

  def run(self, argv):
    """Command-line processor.

    Arguments:
      argv: Pass sys.argv from main.
    """
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(title='subcommands')

    sub_parser = subparsers.add_parser(
        'generate_test_image',
        help=('Generates a test image with a known pattern for testing: '
              '0x00 0x01 0x02 ... 0xff 0x00 0x01 ...'))
    sub_parser.add_argument('--image_size',
                            help='Size of image to generate.',
                            type=parse_number,
                            required=True)
    sub_parser.add_argument('--start_byte',
                            help='Integer for the start byte of the pattern.',
                            type=parse_number,
                            default=0)
    sub_parser.add_argument('--output',
                            help='Output file name.',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.generate_test_image)

    sub_parser = subparsers.add_parser('version',
                                       help='Prints version of avbtool.')
    sub_parser.set_defaults(func=self.version)

    sub_parser = subparsers.add_parser('extract_public_key',
                                       help='Extract public key.')
    sub_parser.add_argument('--key',
                            help='Path to RSA private key file',
                            required=True)
    sub_parser.add_argument('--output',
                            help='Output file name',
                            type=argparse.FileType('wb'),
                            required=True)
    sub_parser.set_defaults(func=self.extract_public_key)

    sub_parser = subparsers.add_parser('make_vbmeta_image',
                                       help='Makes a vbmeta image.')
    sub_parser.add_argument('--output',
                            help='Output file name',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--padding_size',
                            metavar='NUMBER',
                            help='If non-zero, pads output with NUL bytes so '
                                 'its size is a multiple of NUMBER '
                                 '(default: 0)',
                            type=parse_number,
                            default=0)
    self._add_common_args(sub_parser)
    sub_parser.set_defaults(func=self.make_vbmeta_image)

    sub_parser = subparsers.add_parser('add_hash_footer',
                                       help='Add hashes and footer to image.')
    sub_parser.add_argument('--image',
                            help='Image to add hashes to',
                            type=argparse.FileType('rb+'))
    sub_parser.add_argument('--partition_size',
                            help='Partition size',
                            type=parse_number)
    sub_parser.add_argument('--dynamic_partition_size',
                            help='Calculate partition size based on image size',
                            action='store_true')
    sub_parser.add_argument('--partition_name',
                            help='Partition name',
                            default=None)
    sub_parser.add_argument('--hash_algorithm',
                            help='Hash algorithm to use (default: sha256)',
                            default='sha256')
    sub_parser.add_argument('--salt',
                            help='Salt in hex (default: /dev/urandom)')
    sub_parser.add_argument('--calc_max_image_size',
                            help=('Don\'t store the footer - '
                                  'instead calculate the maximum image size '
                                  'leaving enough room for metadata with '
                                  'the given partition size.'),
                            action='store_true')
    sub_parser.add_argument('--output_vbmeta_image',
                            help='Also write vbmeta struct to file',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--do_not_append_vbmeta_image',
                            help=('Do not append vbmeta struct or footer '
                                  'to the image'),
                            action='store_true')
    self._add_common_args(sub_parser)
    self._add_common_footer_args(sub_parser)
    sub_parser.set_defaults(func=self.add_hash_footer)

    sub_parser = subparsers.add_parser('append_vbmeta_image',
                                       help='Append vbmeta image to image.')
    sub_parser.add_argument('--image',
                            help='Image to append vbmeta blob to',
                            type=argparse.FileType('rb+'))
    sub_parser.add_argument('--partition_size',
                            help='Partition size',
                            type=parse_number,
                            required=True)
    sub_parser.add_argument('--vbmeta_image',
                            help='Image with vbmeta blob to append',
                            type=argparse.FileType('rb'))
    sub_parser.set_defaults(func=self.append_vbmeta_image)

    sub_parser = subparsers.add_parser(
        'add_hashtree_footer',
        help='Add hashtree and footer to image.')
    sub_parser.add_argument('--image',
                            help='Image to add hashtree to',
                            type=argparse.FileType('rb+'))
    sub_parser.add_argument('--partition_size',
                            help='Partition size',
                            default=0,
                            type=parse_number)
    sub_parser.add_argument('--partition_name',
                            help='Partition name',
                            default='')
    sub_parser.add_argument('--hash_algorithm',
                            help='Hash algorithm to use (default: sha1)',
                            default='sha1')
    sub_parser.add_argument('--salt',
                            help='Salt in hex (default: /dev/urandom)')
    sub_parser.add_argument('--block_size',
                            help='Block size (default: 4096)',
                            type=parse_number,
                            default=4096)
    # TODO(zeuthen): The --generate_fec option was removed when we
    # moved to generating FEC by default. To avoid breaking existing
    # users needing to transition we simply just print a warning below
    # in add_hashtree_footer(). Remove this option and the warning at
    # some point in the future.
    sub_parser.add_argument('--generate_fec',
                            help=argparse.SUPPRESS,
                            action='store_true')
    sub_parser.add_argument(
        '--do_not_generate_fec',
        help='Do not generate forward-error-correction codes',
        action='store_true')
    sub_parser.add_argument('--fec_num_roots',
                            help='Number of roots for FEC (default: 2)',
                            type=parse_number,
                            default=2)
    sub_parser.add_argument('--calc_max_image_size',
                            help=('Don\'t store the hashtree or footer - '
                                  'instead calculate the maximum image size '
                                  'leaving enough room for hashtree '
                                  'and metadata with the given partition '
                                  'size.'),
                            action='store_true')
    sub_parser.add_argument('--output_vbmeta_image',
                            help='Also write vbmeta struct to file',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--do_not_append_vbmeta_image',
                            help=('Do not append vbmeta struct or footer '
                                  'to the image'),
                            action='store_true')
    # This is different from --setup_rootfs_from_kernel insofar that
    # it doesn't take an IMAGE, the generated cmdline will be for the
    # hashtree we're adding.
    sub_parser.add_argument('--setup_as_rootfs_from_kernel',
                            action='store_true',
                            help='Adds kernel cmdline for setting up rootfs')
    sub_parser.add_argument('--no_hashtree',
                            action='store_true',
                            help='Do not append hashtree')
    sub_parser.add_argument('--check_at_most_once',
                            action='store_true',
                            help='Set to verify data block only once')
    self._add_common_args(sub_parser)
    self._add_common_footer_args(sub_parser)
    sub_parser.set_defaults(func=self.add_hashtree_footer)

    sub_parser = subparsers.add_parser('erase_footer',
                                       help='Erase footer from an image.')
    sub_parser.add_argument('--image',
                            help='Image with a footer',
                            type=argparse.FileType('rb+'),
                            required=True)
    sub_parser.add_argument('--keep_hashtree',
                            help='Keep the hashtree and FEC in the image',
                            action='store_true')
    sub_parser.set_defaults(func=self.erase_footer)

    sub_parser = subparsers.add_parser('zero_hashtree',
                                       help='Zero out hashtree and FEC data.')
    sub_parser.add_argument('--image',
                            help='Image with a footer',
                            type=argparse.FileType('rb+'),
                            required=True)
    sub_parser.set_defaults(func=self.zero_hashtree)

    sub_parser = subparsers.add_parser(
        'extract_vbmeta_image',
        help='Extracts vbmeta from an image with a footer.')
    sub_parser.add_argument('--image',
                            help='Image with footer',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--output',
                            help='Output file name',
                            type=argparse.FileType('wb'))
    sub_parser.add_argument('--padding_size',
                            metavar='NUMBER',
                            help='If non-zero, pads output with NUL bytes so '
                                 'its size is a multiple of NUMBER '
                                 '(default: 0)',
                            type=parse_number,
                            default=0)
    sub_parser.set_defaults(func=self.extract_vbmeta_image)

    sub_parser = subparsers.add_parser('resize_image',
                                       help='Resize image with a footer.')
    sub_parser.add_argument('--image',
                            help='Image with a footer',
                            type=argparse.FileType('rb+'),
                            required=True)
    sub_parser.add_argument('--partition_size',
                            help='New partition size',
                            type=parse_number)
    sub_parser.set_defaults(func=self.resize_image)

    sub_parser = subparsers.add_parser(
        'info_image',
        help='Show information about vbmeta or footer.')
    sub_parser.add_argument('--image',
                            help='Image to show information about',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--output',
                            help='Write info to file',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.add_argument('--atx',
                            help=('Show information about Android Things '
                                  'eXtension (ATX).'),
                            action='store_true')
    sub_parser.set_defaults(func=self.info_image)

    sub_parser = subparsers.add_parser(
        'verify_image',
        help='Verify an image.')
    sub_parser.add_argument('--image',
                            help='Image to verify',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--key',
                            help='Check embedded public key matches KEY',
                            metavar='KEY',
                            required=False)
    sub_parser.add_argument('--expected_chain_partition',
                            help='Expected chain partition',
                            metavar='PART_NAME:ROLLBACK_SLOT:KEY_PATH',
                            action='append')
    sub_parser.add_argument(
        '--follow_chain_partitions',
        help=('Follows chain partitions even when not '
              'specified with the --expected_chain_partition option'),
        action='store_true')
    sub_parser.add_argument(
        '--accept_zeroed_hashtree',
        help=('Accept images where the hashtree or FEC data is zeroed out'),
        action='store_true')
    sub_parser.set_defaults(func=self.verify_image)

    sub_parser = subparsers.add_parser(
        'print_partition_digests',
        help='Prints partition digests.')
    sub_parser.add_argument('--image',
                            help='Image to print partition digests from',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--output',
                            help='Write info to file',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.add_argument('--json',
                            help=('Print output as JSON'),
                            action='store_true')
    sub_parser.set_defaults(func=self.print_partition_digests)

    sub_parser = subparsers.add_parser(
        'calculate_vbmeta_digest',
        help='Calculate vbmeta digest.')
    sub_parser.add_argument('--image',
                            help='Image to calculate digest for',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--hash_algorithm',
                            help='Hash algorithm to use (default: sha256)',
                            default='sha256')
    sub_parser.add_argument('--output',
                            help='Write hex digest to file (default: stdout)',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.calculate_vbmeta_digest)

    sub_parser = subparsers.add_parser(
        'calculate_kernel_cmdline',
        help='Calculate kernel cmdline.')
    sub_parser.add_argument('--image',
                            help='Image to calculate kernel cmdline for',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--hashtree_disabled',
                            help='Return the cmdline for hashtree disabled',
                            action='store_true')
    sub_parser.add_argument('--output',
                            help='Write cmdline to file (default: stdout)',
                            type=argparse.FileType('wt'),
                            default=sys.stdout)
    sub_parser.set_defaults(func=self.calculate_kernel_cmdline)

    sub_parser = subparsers.add_parser('set_ab_metadata',
                                       help='Set A/B metadata.')
    sub_parser.add_argument('--misc_image',
                            help=('The misc image to modify. If the image does '
                                  'not exist, it will be created.'),
                            type=argparse.FileType('r+b'),
                            required=True)
    sub_parser.add_argument('--slot_data',
                            help=('Slot data of the form "priority", '
                                  '"tries_remaining", "sucessful_boot" for '
                                  'slot A followed by the same for slot B, '
                                  'separated by colons. The default value '
                                  'is 15:7:0:14:7:0.'),
                            default='15:7:0:14:7:0')
    sub_parser.set_defaults(func=self.set_ab_metadata)

    sub_parser = subparsers.add_parser(
        'make_atx_certificate',
        help='Create an Android Things eXtension (ATX) certificate.')
    sub_parser.add_argument('--output',
                            help='Write certificate to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--subject',
                            help=('Path to subject file'),
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--subject_key',
                            help=('Path to subject RSA public key file'),
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--subject_key_version',
                            help=('Version of the subject key'),
                            type=parse_number,
                            required=False)
    sub_parser.add_argument('--subject_is_intermediate_authority',
                            help=('Generate an intermediate authority '
                                  'certificate'),
                            action='store_true')
    sub_parser.add_argument('--usage',
                            help=('Override usage with a hash of the provided '
                                  'string'),
                            required=False)
    sub_parser.add_argument('--authority_key',
                            help='Path to authority RSA private key file',
                            required=False)
    sub_parser.add_argument('--signing_helper',
                            help='Path to helper used for signing',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--signing_helper_with_files',
                            help='Path to helper used for signing using files',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.set_defaults(func=self.make_atx_certificate)

    sub_parser = subparsers.add_parser(
        'make_atx_permanent_attributes',
        help='Create Android Things eXtension (ATX) permanent attributes.')
    sub_parser.add_argument('--output',
                            help='Write attributes to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--root_authority_key',
                            help='Path to authority RSA public key file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--product_id',
                            help=('Path to Product ID file'),
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.set_defaults(func=self.make_atx_permanent_attributes)

    sub_parser = subparsers.add_parser(
        'make_atx_metadata',
        help='Create Android Things eXtension (ATX) metadata.')
    sub_parser.add_argument('--output',
                            help='Write metadata to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--intermediate_key_certificate',
                            help='Path to intermediate key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--product_key_certificate',
                            help='Path to product key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.set_defaults(func=self.make_atx_metadata)

    sub_parser = subparsers.add_parser(
        'make_atx_unlock_credential',
        help='Create an Android Things eXtension (ATX) unlock credential.')
    sub_parser.add_argument('--output',
                            help='Write credential to file',
                            type=argparse.FileType('wb'),
                            default=sys.stdout)
    sub_parser.add_argument('--intermediate_key_certificate',
                            help='Path to intermediate key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--unlock_key_certificate',
                            help='Path to unlock key certificate file',
                            type=argparse.FileType('rb'),
                            required=True)
    sub_parser.add_argument('--challenge',
                            help='Path to the challenge to sign (optional). If '
                                 'this is not provided the challenge signature '
                                 'field is omitted and can be concatenated '
                                 'later.',
                            required=False)
    sub_parser.add_argument('--unlock_key',
                            help='Path to unlock key (optional). Must be '
                                 'provided if using --challenge.',
                            required=False)
    sub_parser.add_argument('--signing_helper',
                            help='Path to helper used for signing',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.add_argument('--signing_helper_with_files',
                            help='Path to helper used for signing using files',
                            metavar='APP',
                            default=None,
                            required=False)
    sub_parser.set_defaults(func=self.make_atx_unlock_credential)

    args = parser.parse_args(argv[1:])
    try:
      args.func(args)
    except AttributeError:
      # This error gets raised when the command line tool is called without any
      # arguments. It mimics the original Python 2 behavior.
      parser.print_usage()
      print('avbtool: error: too few arguments')
      sys.exit(2)
    except AvbError as e:
      sys.stderr.write('{}: {}\n'.format(argv[0], str(e)))
      sys.exit(1)

  def version(self, _):
    """Implements the 'version' sub-command."""
    print(get_release_string())

  def generate_test_image(self, args):
    """Implements the 'generate_test_image' sub-command."""
    self.avb.generate_test_image(args.output, args.image_size, args.start_byte)

  def extract_public_key(self, args):
    """Implements the 'extract_public_key' sub-command."""
    self.avb.extract_public_key(args.key, args.output)

  def make_vbmeta_image(self, args):
    """Implements the 'make_vbmeta_image' sub-command."""
    args = self._fixup_common_args(args)
    self.avb.make_vbmeta_image(args.output, args.chain_partition,
                               args.algorithm, args.key,
                               args.public_key_metadata, args.rollback_index,
                               args.flags, args.rollback_index_location,
                               args.prop, args.prop_from_file,
                               args.kernel_cmdline,
                               args.setup_rootfs_from_kernel,
                               args.include_descriptors_from_image,
                               args.signing_helper,
                               args.signing_helper_with_files,
                               args.internal_release_string,
                               args.append_to_release_string,
                               args.print_required_libavb_version,
                               args.padding_size)

  def append_vbmeta_image(self, args):
    """Implements the 'append_vbmeta_image' sub-command."""
    self.avb.append_vbmeta_image(args.image.name, args.vbmeta_image.name,
                                 args.partition_size)

  def add_hash_footer(self, args):
    """Implements the 'add_hash_footer' sub-command."""
    args = self._fixup_common_args(args)
    self.avb.add_hash_footer(args.image.name if args.image else None,
                             args.partition_size, args.dynamic_partition_size,
                             args.partition_name, args.hash_algorithm,
                             args.salt, args.chain_partition, args.algorithm,
                             args.key,
                             args.public_key_metadata, args.rollback_index,
                             args.flags, args.rollback_index_location,
                             args.prop, args.prop_from_file,
                             args.kernel_cmdline,
                             args.setup_rootfs_from_kernel,
                             args.include_descriptors_from_image,
                             args.calc_max_image_size,
                             args.signing_helper,
                             args.signing_helper_with_files,
                             args.internal_release_string,
                             args.append_to_release_string,
                             args.output_vbmeta_image,
                             args.do_not_append_vbmeta_image,
                             args.print_required_libavb_version,
                             args.use_persistent_digest,
                             args.do_not_use_ab)

  def add_hashtree_footer(self, args):
    """Implements the 'add_hashtree_footer' sub-command."""
    args = self._fixup_common_args(args)
    # TODO(zeuthen): Remove when removing support for the
    # '--generate_fec' option above.
    if args.generate_fec:
      sys.stderr.write('The --generate_fec option is deprecated since FEC '
                       'is now generated by default. Use the option '
                       '--do_not_generate_fec to not generate FEC.\n')
    self.avb.add_hashtree_footer(
        args.image.name if args.image else None,
        args.partition_size,
        args.partition_name,
        not args.do_not_generate_fec, args.fec_num_roots,
        args.hash_algorithm, args.block_size,
        args.salt, args.chain_partition, args.algorithm,
        args.key, args.public_key_metadata,
        args.rollback_index, args.flags,
        args.rollback_index_location, args.prop,
        args.prop_from_file,
        args.kernel_cmdline,
        args.setup_rootfs_from_kernel,
        args.setup_as_rootfs_from_kernel,
        args.include_descriptors_from_image,
        args.calc_max_image_size,
        args.signing_helper,
        args.signing_helper_with_files,
        args.internal_release_string,
        args.append_to_release_string,
        args.output_vbmeta_image,
        args.do_not_append_vbmeta_image,
        args.print_required_libavb_version,
        args.use_persistent_digest,
        args.do_not_use_ab,
        args.no_hashtree,
        args.check_at_most_once)

  def erase_footer(self, args):
    """Implements the 'erase_footer' sub-command."""
    self.avb.erase_footer(args.image.name, args.keep_hashtree)

  def zero_hashtree(self, args):
    """Implements the 'zero_hashtree' sub-command."""
    self.avb.zero_hashtree(args.image.name)

  def extract_vbmeta_image(self, args):
    """Implements the 'extract_vbmeta_image' sub-command."""
    self.avb.extract_vbmeta_image(args.output, args.image.name,
                                  args.padding_size)

  def resize_image(self, args):
    """Implements the 'resize_image' sub-command."""
    self.avb.resize_image(args.image.name, args.partition_size)

  def set_ab_metadata(self, args):
    """Implements the 'set_ab_metadata' sub-command."""
    self.avb.set_ab_metadata(args.misc_image, args.slot_data)

  def info_image(self, args):
    """Implements the 'info_image' sub-command."""
    self.avb.info_image(args.image.name, args.output, args.atx)

  def verify_image(self, args):
    """Implements the 'verify_image' sub-command."""
    self.avb.verify_image(args.image.name, args.key,
                          args.expected_chain_partition,
                          args.follow_chain_partitions,
                          args.accept_zeroed_hashtree)

  def print_partition_digests(self, args):
    """Implements the 'print_partition_digests' sub-command."""
    self.avb.print_partition_digests(args.image.name, args.output, args.json)

  def calculate_vbmeta_digest(self, args):
    """Implements the 'calculate_vbmeta_digest' sub-command."""
    self.avb.calculate_vbmeta_digest(args.image.name, args.hash_algorithm,
                                     args.output)

  def calculate_kernel_cmdline(self, args):
    """Implements the 'calculate_kernel_cmdline' sub-command."""
    self.avb.calculate_kernel_cmdline(args.image.name, args.hashtree_disabled,
                                      args.output)

  def make_atx_certificate(self, args):
    """Implements the 'make_atx_certificate' sub-command."""
    self.avb.make_atx_certificate(args.output, args.authority_key,
                                  args.subject_key.name,
                                  args.subject_key_version,
                                  args.subject.read(),
                                  args.subject_is_intermediate_authority,
                                  args.usage,
                                  args.signing_helper,
                                  args.signing_helper_with_files)

  def make_atx_permanent_attributes(self, args):
    """Implements the 'make_atx_permanent_attributes' sub-command."""
    self.avb.make_atx_permanent_attributes(args.output,
                                           args.root_authority_key.name,
                                           args.product_id.read())

  def make_atx_metadata(self, args):
    """Implements the 'make_atx_metadata' sub-command."""
    self.avb.make_atx_metadata(args.output,
                               args.intermediate_key_certificate.read(),
                               args.product_key_certificate.read())

  def make_atx_unlock_credential(self, args):
    """Implements the 'make_atx_unlock_credential' sub-command."""
    self.avb.make_atx_unlock_credential(
        args.output,
        args.intermediate_key_certificate.read(),
        args.unlock_key_certificate.read(),
        args.challenge,
        args.unlock_key,
        args.signing_helper,
        args.signing_helper_with_files)


if __name__ == '__main__':
  if AVB_INVOCATION_LOGFILE:
    with open(AVB_INVOCATION_LOGFILE, 'a') as log:
      log.write(' '.join(sys.argv))
      log.write('\n')

  tool = AvbTool()
  tool.run(sys.argv)

```

`aosp/avb/data/testkey_atx_pik.pem`:

```pem
-----BEGIN PRIVATE KEY-----
MIIJQwIBADANBgkqhkiG9w0BAQEFAASCCS0wggkpAgEAAoICAQDoTSKaxoiUJhZ9
Wb4fT59s9ZZsyIjewnmAhS/+gPTeOY7L+cpo+iDSeTAOOAw++ZcQZiGeQLwLO6DK
Aq2ujqi8ycwMx49aZsMcAKwyIMl2SoMZOgducS27z+Mzv4+FBoLV52eYVr+Idiat
b2ogciK8TEviBF7URyQa6wsdGrY4HwG7kEBL1NiZngkl24U+HNHlzn9L3/C6pg39
g5KIQyNNjIFzTqGnr1Q0lCNLCR/UP8NtQ0koUL26MeDJk8qANTkI3ihpw27CFmWy
8R9VK7EDkAgs/C7dqBlcVJvVptu9Gih7Yltfsqeq23W87J/JvxE+NSU/iipITHZe
1IdC2dhntAysKa5r+kikyO6uh9fN7siBzNBlTBRHtEaaNcOxaGMHf87J/SktamMT
pvy+NIVe7bdjtDyyd4FVo5dS65QTBt//E5FKUrxShCP7ww2L65xbldXdBjE4JSyQ
gpVrvDMne5+Ro0If1GYnfjgwsIWq/AAm7pZ8bzZOw0HtgjJbCI4HmkJG32wXAIzA
L00S6nICiq4Q3oWnf1mNIDTM6hrcCJxAqS3t1JSqpM5EkTOFg0SZ3y83vcogxr2a
NqP/LI+02FQRirgBwRWdngUbc7mbXG5jhuYirnl52ofzhzwWrGe/iKGzhzZWnjNx
logXB9N2n7E14D0LzmLmE8sALnBr+wIDAQABAoICAHHI3otbdajDYz6xB4xErv1q
6eyM6WXbcjI+irypo8d5//TvfHKhGhSeIajFUVJDZPg2Xn8qjDEgWui4GSSoYgRe
/+C+mvwX27fKqI3BO40CgGaJ4vv42gLlmA9P5FevUcS+nSKkUxrfbKCFM0GDRnpf
EMg7hcuKsSeyO3ZdECY7IdkilivOrO3J2AdAGGrNKQ7cb8PVhA+YqL+lg8/UuuUQ
TpQRTuNY4PEEIqltZbbMKMhLLfleWyBpsAZsqsLTzwUF9Fuhy42r9NKKguNwDDuH
gEmwmLAf15Q/KTmkint85ZlSGxmr466v4mLQsI/cU/DZjU4rOfzB3zUh+sMG+5UZ
OB1aCHdMIxTMBfSUqehPNP7Fe59+OmwYezhMkfy7jJat81OobUvyqLwR/Nx5qNvs
Ry5JOJaLPIouee9Dc3Wp1uEetgAfXj+0CmWyQCzdz5NkwX0nIssXr+9eUmlwgBO+
FdY72z8Nf84h74aZqcN4ysqU14YeIjv95U5TFQJ7Dj72DDir33t61etCIDceUpxG
y0gnGmnh7xZvVmP8rfnuXhbo4hNwxsXfReKQnP51V4yHIp2AtCReGwexRjGB6iky
K3v2XHKJnRIUFd5y7vhEfo/jj/e1GU9P6FFznJLhET5RS07JDhWhZRyvwcoa+muv
lxcFjysQb7z7dFGJSELBAoIBAQD7/Onpp9M5DniJnS8vVcFSpndpqd1M1f6ZBPQy
Owh9LOVSdJoBsaMuXStilKGxA2BqS4Ty3fww6urIjqYYL0R4q9+dSYAWBX/cGx+/
yypaPAMA/Vjv/0dPM9pY/lwyeIYUXYjU3sNewK3fgfvxc6piAAVwNfHCegbdHhNR
gCmeeszhmSnbdFZXM9EyzTXpDVb3IWE9mhQ9oYNDxQgQplMcrb30z3AEAV9ZjwGU
+/elaBvvebPrl6un9drAO2qVXMinjCXJTiWaJdlNZkTeYCeGqXHt4xeZJUGeWdVa
aI3s1MPPxxzXi4FlwND8sinnRdPh4w0ZjA9RlkumwCJMBgFhAoIBAQDr//ri23dX
6qX7dmZvdrF9E5ksPZxPZBmBZ0ymSCgxWwHd6DC74EMv406BuccloBxIRW9YAe0/
ZMNFvHYz/LPYa8eRFTcG34SSkMjWCPo0ywQFjAe0zpCJMpeqJ3BccZ51l5HjU4IH
8BMW83LOE3f47D0W6Sy98T2eTvJPnJ/lqck6rDvWY/G8b5rwchrScIo6+gV5fPbm
QX1fgyUrOrp5dfgDuAGfuEi/5ZoZKUNAX9KNREBV5XGqR+GPe3dxFwB50zA0aEQM
NUUbb85vSD/JoABTgyw33B+ZXnVbQ3cH9/s/TfOtg+DcJCNv4FOY/CVF+jEAQI1a
eiXrjYCjT/7bAoIBAQD69hoogOJWstjNhWRW6jtNi0jmTSx/t6iG0W47EJwVvr7t
bf9rrHTuWhA5b/nRB6HgezH/h6IBPhVyhM9aysiQvexJA8izJer/VWw7YaXelGIR
fEA1VbK5aNUPSNSd13cBlV4PU4SUO6VvMk+vWxjX3VmNNcx/eXSYh7mJs/C/S2H9
VMNhMu5CjvLMe6AzaPuxyObFqUx7TP4kYnjzzBJ+P3Mt++J9urgxw8E5lfBAJf2c
dUMBYd6tuqeQSByQgQW+CFAhutisOwG+mhoAtxbmgJ9c4ozAE2DUync4QWUH96bE
qnNJIEFRC8WXxgEBuoOZNr33MYyYHu1dN4Fw4ZJBAoIBAHX9r3PIgiyEdqP4mFJW
J3r/V2+VBhdzVoUqHlpsbRvwAkjuE597Clxg6xlUxsp6+Gjxvi9kFzfAqxislvR6
/XfQuyBAWRiom+GjXaYVKvNGJSaY0imFtSHDF6zMtxKhA7aLJzdewv4w+3pYESgS
98KOaiSQQ/xbJpGFqwQ+rHronmElR21y3qN1sSNSCTL5bUL7Sc1puw934rTkHqs0
W5Lqdit1zeoK+uRmaNr3lFYVEnHqk7feVSvrcEyKUDdMZsKB4fHxx0PLRlfnWHCu
0KV/x2n5hRwQhAPsBASzAEoNo6IM2S4BZ2To9Ia0w1cTiZco9WLI42M++sKAJraA
Ak0CggEBALwQ3FKc/dc9j3lSx43RH29rOZDXACJdA7vwWRucmdXoTlKxtNEB+Q6A
ycWsHsrgrfa1IqsXJu+uezDB3TlCq+YjElxUnZJopPJQJISRtaJYcMQ3GpU+eS+L
6IhGPhOuzQ7HxgKyxFVrNi7SVpODKS305rZUI1BoY5zFuZtRjx6uDV4R4jIVZczV
y9mXACViqGQBxRCIYV2W5iCPIzG02mzK62QilS+dqCGhKY4oTxfNzOy5huvtGXhK
Y5bwRFG1RPZj8TAyp0WVUIXgyOyt6AgqUZpQW6LWgWxcJecCpPM2ch4adNyusNgi
WM8yjCL8U3+kfP4L6uIgmAuVcmbrX68=
-----END PRIVATE KEY-----

```

`aosp/avb/data/testkey_atx_prk.pem`:

```pem
-----BEGIN PRIVATE KEY-----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-----END PRIVATE KEY-----

```

`aosp/avb/data/testkey_atx_psk.pem`:

```pem
-----BEGIN PRIVATE KEY-----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-----END PRIVATE KEY-----

```

`aosp/avb/data/testkey_rsa2048.pem`:

```pem
-----BEGIN RSA PRIVATE KEY-----
MIIEowIBAAKCAQEAxlVR3TIkouAOvH79vaJTgFhpfvVKQIeVkFRZPVXK/zY0Gvrh
4JAqGjJoW/PfrQv5sdD36qtHH3a+G5hLZ6Ni+t/mtfjucxZfuLGC3kmJ1T3XqEKZ
gXXI2IR7vVSoImREvDQGEDyJwtHzLANlkbGg0cghVhWZSCAndO8BenalC2v94/rt
DfkPekH6dgU3Sf40T0sBSeSY94mOzTaqOR2pfV1rWlLRdWmo33zeHBv52Rlbt0dM
uXAureXWiHztkm5GCBC1dgM+CaxNtizNEgC91KcD0xuRCCM2WxH+r1lpszyIJDct
YbrFmVEYl/kjQpafhy7Nsk1fqSTyRdriZSYmTQIDAQABAoIBAQC+kJgaCuX8wYAn
SXWQ0fmdZlXnMNRpcF0a0pD0SAzGb1RdYBXMaXiqtyhiwc53PPxsCDdNecjayIMd
jJVXPTwLhTruOgMS/bp3gcgWwV34UHV4LJXGOGAE+jbS0hbDBMiudOYmj6RmVshp
z9G1zZCSQNMXHaWsEYkX59XpzzoB384nRul2QgEtwzUNR9XlpzgtJBLk3SACkvsN
mQ/DW8IWHXLg8vLn1LzVJ2e3B16H4MoE2TCHxqfMgr03IDRRJogkenQuQsFhevYT
o/mJyHSWavVgzMHG9I5m+eepF4Wyhj1Y4WyKAuMI+9dHAX/h7Lt8XFCQCh5DbkVG
zGr34sWBAoGBAOs7n7YZqNaaguovfIdRRsxxZr1yJAyDsr6w3yGImDZYju4c4WY9
5esO2kP3FA4p0c7FhQF5oOb1rBuHEPp36cpL4aGeK87caqTfq63WZAujoTZpr9Lp
BRbkL7w/xG7jpQ/clpA8sHzHGQs/nelxoOtC7E118FiRgvD/jdhlMyL9AoGBANfX
vyoN1pplfT2xR8QOjSZ+Q35S/+SAtMuBnHx3l0qH2bbBjcvM1MNDWjnRDyaYhiRu
i+KA7tqfib09+XpB3g5D6Ov7ls/Ldx0S/VcmVWtia2HK8y8iLGtokoBZKQ5AaFX2
iQU8+tC4h69GnJYQKqNwgCUzh8+gHX5Y46oDiTmRAoGAYpOx8lX+czB8/Da6MNrW
mIZNT8atZLEsDs2ANEVRxDSIcTCZJId7+m1W+nRoaycLTWNowZ1+2ErLvR10+AGY
b7Ys79Wg9idYaY9yGn9lnZsMzAiuLeyIvXcSqgjvAKlVWrhOQFOughvNWvFl85Yy
oWSCMlPiTLtt7CCsCKsgKuECgYBgdIp6GZsIfkgclKe0hqgvRoeU4TR3gcjJlM9A
lBTo+pKhaBectplx9RxR8AnsPobbqwcaHnIfAuKDzjk5mEvKZjClnFXF4HAHbyAF
nRzZEy9XkWFhc80T5rRpZO7C7qdxmu2aiKixM3V3L3/0U58qULEDbubHMw9bEhAT
PudI8QKBgHEEiMm/hr9T41hbQi/LYanWnlFw1ue+osKuF8bXQuxnnHNuFT/c+9/A
vWhgqG6bOEHu+p/IPrYm4tBMYlwsyh4nXCyGgDJLbLIfzKwKAWCtH9LwnyDVhOow
GH9shdR+sW3Ew97xef02KAH4VlNANEmBV4sQNqWWvsYrcFm2rOdL
-----END RSA PRIVATE KEY-----

```

`aosp/avb/data/testkey_rsa4096.pem`:

```pem
-----BEGIN RSA PRIVATE KEY-----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-----END RSA PRIVATE KEY-----

```

`aosp/avb/data/testkey_rsa4096_pub.pem`:

```pem
-----BEGIN PUBLIC KEY-----
MIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA2ASv49OEbH4NiT3CjNMS
VeliyfEPXswWcqtEfCxlSpS1FisAuwbvEwdTTPlkuSh6G4SYiNhnpCP5p0vcSg/3
OhiuVKgV/rCtrDXaO60nvK/o0y83NNZRK2xaJ9eWBq9ruIDK+jC0sYWzTaqqwxY0
Grjnx/r5CXerl5PrRK7PILzwgBHbIwxHcblt1ntgR4cWVpO3wiqasEwBDDDYk4fw
7W6LvjBb9qav3YB8RV6PkZNeRP64ggfuecq/MXNiWOPNxLzCER2hSr/+J32h9jWj
XsrcVy8+8Mldhmr4r2an7c247aFfupuFGtUJrpROO8/LXMl5gPfMpkqoatjTMRH5
9gJjKhot0RpmGxZBvb33TcBK5SdJX39Y4yct5clmDlI4Fjj7FutTP+b96aJeJVnY
eUX/A0wmogBajsJRoRX5e/RcgZsYRzXYLQXprQ81dBWjjovMJ9p8XeT6BNMFC7o6
sklFL0fHDUE/l4BNP8G1u3BfpzevSCISRS71D4eS4oQB+RIPFBUkzomZ7rnEF3Bw
Feq+xmwfYrP0LRaH+1YeRauuMuReke1TZl697a3mEjkNg8noa2wtpe7EWmaujJfX
DWxJx/XEkjGLCe4z2qk3tkkY+A5gRcgzke8gVxC+eC2DJtbKYfkv4L8FMFJaEhwA
p13MfC7FlYujO/BDLl7dANsCAwEAAQ==
-----END PUBLIC KEY-----

```

`aosp/avb/data/testkey_rsa8192.pem`:

```pem
-----BEGIN RSA PRIVATE KEY-----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==
-----END RSA PRIVATE KEY-----

```

`aosp/boot_signer/build.gradle.kts`:

```kts
import org.gradle.jvm.tasks.Jar

plugins {
    java
}

repositories {
    mavenCentral()
}

dependencies {
    implementation("org.bouncycastle:bcprov-jdk15on:1.70")
    implementation("org.bouncycastle:bcpkix-jdk15on:1.70")
}

val fatJar = task("fatJar", type = Jar::class) {
    manifest {
        attributes["Implementation-Title"] = "AOSP boot signer"
        attributes["Main-Class"] = "com.android.verity.BootSignature"
    }
    from(configurations.runtimeClasspath.get().map({ if (it.isDirectory) it else zipTree(it) }))
    excludes.addAll(mutableSetOf("META-INF/*.RSA", "META-INF/*.SF", "META-INF/*.DSA"))
    duplicatesStrategy = DuplicatesStrategy.EXCLUDE
    with(tasks.jar.get() as CopySpec)
}

tasks {
    "build" {
        dependsOn(fatJar)
    }
}

```

`aosp/boot_signer/src/main/java/BootSignature.java`:

```java
/*
 * Copyright (C) 2014 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.android.verity;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.security.PrivateKey;
import java.security.PublicKey;
import java.security.Security;
import java.security.cert.X509Certificate;
import java.security.cert.Certificate;
import java.security.cert.CertificateFactory;
import java.security.cert.CertificateEncodingException;
import java.util.Arrays;
import org.bouncycastle.asn1.ASN1Encodable;
import org.bouncycastle.asn1.ASN1EncodableVector;
import org.bouncycastle.asn1.ASN1Integer;
import org.bouncycastle.asn1.ASN1Object;
import org.bouncycastle.asn1.ASN1ObjectIdentifier;
import org.bouncycastle.asn1.ASN1OctetString;
import org.bouncycastle.asn1.ASN1Primitive;
import org.bouncycastle.asn1.ASN1Sequence;
import org.bouncycastle.asn1.ASN1InputStream;
import org.bouncycastle.asn1.DEROctetString;
import org.bouncycastle.asn1.DERPrintableString;
import org.bouncycastle.asn1.DERSequence;
import org.bouncycastle.asn1.util.ASN1Dump;
import org.bouncycastle.asn1.x509.AlgorithmIdentifier;
import org.bouncycastle.jce.provider.BouncyCastleProvider;

/**
 *    AndroidVerifiedBootSignature DEFINITIONS ::=
 *    BEGIN
 *        formatVersion ::= INTEGER
 *        certificate ::= Certificate
 *        algorithmIdentifier ::= SEQUENCE {
 *            algorithm OBJECT IDENTIFIER,
 *            parameters ANY DEFINED BY algorithm OPTIONAL
 *        }
 *        authenticatedAttributes ::= SEQUENCE {
 *            target CHARACTER STRING,
 *            length INTEGER
 *        }
 *        signature ::= OCTET STRING
 *     END
 */

public class BootSignature extends ASN1Object
{
    private ASN1Integer             formatVersion;
    private ASN1Encodable           certificate;
    private AlgorithmIdentifier     algorithmIdentifier;
    private DERPrintableString      target;
    private ASN1Integer             length;
    private DEROctetString          signature;
    private PublicKey               publicKey;

    private static final int FORMAT_VERSION = 1;
    /**
     * Offset of recovery DTBO length in a boot image header of version greater than
     * or equal to 1.
     */
    private static final int BOOT_IMAGE_HEADER_V1_RECOVERY_DTBO_SIZE_OFFSET = 1632;
    /**
     * Offset of DTB length in a boot image header of version greater than
     * or equal to 2.
     */
    private static final int BOOT_IMAGE_HEADER_V2_DTB_SIZE_OFFSET = 1648;


    /**
     * Initializes the object for signing an image file
     * @param target Target name, included in the signed data
     * @param length Length of the image, included in the signed data
     */
    public BootSignature(String target, int length) {
        this.formatVersion = new ASN1Integer(FORMAT_VERSION);
        this.target = new DERPrintableString(target);
        this.length = new ASN1Integer(length);
    }

    /**
     * Initializes the object for verifying a signed image file
     * @param signature Signature footer
     */
    public BootSignature(byte[] signature)
            throws Exception {
        ASN1InputStream stream = new ASN1InputStream(signature);
        ASN1Sequence sequence = (ASN1Sequence) stream.readObject();

        formatVersion = (ASN1Integer) sequence.getObjectAt(0);
        if (formatVersion.getValue().intValue() != FORMAT_VERSION) {
            throw new IllegalArgumentException("Unsupported format version");
        }

        certificate = sequence.getObjectAt(1);
        byte[] encoded = ((ASN1Object) certificate).getEncoded();
        ByteArrayInputStream bis = new ByteArrayInputStream(encoded);

        CertificateFactory cf = CertificateFactory.getInstance("X.509");
        X509Certificate c = (X509Certificate) cf.generateCertificate(bis);
        publicKey = c.getPublicKey();

        ASN1Sequence algId = (ASN1Sequence) sequence.getObjectAt(2);
        algorithmIdentifier = new AlgorithmIdentifier(
            (ASN1ObjectIdentifier) algId.getObjectAt(0));

        ASN1Sequence attrs = (ASN1Sequence) sequence.getObjectAt(3);
        target = (DERPrintableString) attrs.getObjectAt(0);
        length = (ASN1Integer) attrs.getObjectAt(1);

        this.signature = (DEROctetString) sequence.getObjectAt(4);
    }

    public ASN1Object getAuthenticatedAttributes() {
        ASN1EncodableVector attrs = new ASN1EncodableVector();
        attrs.add(target);
        attrs.add(length);
        return new DERSequence(attrs);
    }

    public byte[] getEncodedAuthenticatedAttributes() throws IOException {
        return getAuthenticatedAttributes().getEncoded();
    }

    public AlgorithmIdentifier getAlgorithmIdentifier() {
        return algorithmIdentifier;
    }

    public PublicKey getPublicKey() {
        return publicKey;
    }

    public byte[] getSignature() {
        return signature.getOctets();
    }

    public void setSignature(byte[] sig, AlgorithmIdentifier algId) {
        algorithmIdentifier = algId;
        signature = new DEROctetString(sig);
    }

    public void setCertificate(X509Certificate cert)
            throws Exception, IOException, CertificateEncodingException {
        ASN1InputStream s = new ASN1InputStream(cert.getEncoded());
        certificate = s.readObject();
        publicKey = cert.getPublicKey();
    }

    public byte[] generateSignableImage(byte[] image) throws IOException {
        byte[] attrs = getEncodedAuthenticatedAttributes();
        byte[] signable = Arrays.copyOf(image, image.length + attrs.length);
        for (int i=0; i < attrs.length; i++) {
            signable[i+image.length] = attrs[i];
        }
        return signable;
    }

    public byte[] sign(byte[] image, PrivateKey key) throws Exception {
        byte[] signable = generateSignableImage(image);
        return Utils.sign(key, signable);
    }

    public boolean verify(byte[] image) throws Exception {
        if (length.getValue().intValue() != image.length) {
            throw new IllegalArgumentException("Invalid image length");
        }

        byte[] signable = generateSignableImage(image);
        return Utils.verify(publicKey, signable, signature.getOctets(),
                    algorithmIdentifier);
    }

    public ASN1Primitive toASN1Primitive() {
        ASN1EncodableVector v = new ASN1EncodableVector();
        v.add(formatVersion);
        v.add(certificate);
        v.add(algorithmIdentifier);
        v.add(getAuthenticatedAttributes());
        v.add(signature);
        return new DERSequence(v);
    }

    public static int getSignableImageSize(byte[] data) throws Exception {
        if (!Arrays.equals(Arrays.copyOfRange(data, 0, 8),
                "ANDROID!".getBytes("US-ASCII"))) {
            throw new IllegalArgumentException("Invalid image header: missing magic");
        }

        ByteBuffer image = ByteBuffer.wrap(data);
        image.order(ByteOrder.LITTLE_ENDIAN);

        image.getLong(); // magic
        int kernelSize = image.getInt();
        image.getInt(); // kernel_addr
        int ramdskSize = image.getInt();
        image.getInt(); // ramdisk_addr
        int secondSize = image.getInt();
        image.getLong(); // second_addr + tags_addr
        int pageSize = image.getInt();

        int length = pageSize // include the page aligned image header
                + ((kernelSize + pageSize - 1) / pageSize) * pageSize
                + ((ramdskSize + pageSize - 1) / pageSize) * pageSize
                + ((secondSize + pageSize - 1) / pageSize) * pageSize;

        int headerVersion = image.getInt(); // boot image header version
        if (headerVersion > 0) {
            image.position(BOOT_IMAGE_HEADER_V1_RECOVERY_DTBO_SIZE_OFFSET);
            int recoveryDtboLength = image.getInt();
            length += ((recoveryDtboLength + pageSize - 1) / pageSize) * pageSize;

            image.getLong(); // recovery_dtbo address
            int headerSize = image.getInt();
            if (headerVersion == 2) {
                image.position(BOOT_IMAGE_HEADER_V2_DTB_SIZE_OFFSET);
                int dtbLength = image.getInt();
                length += ((dtbLength + pageSize - 1) / pageSize) * pageSize;
                image.getLong(); // dtb address
            }
            if (image.position() != headerSize) {
                throw new IllegalArgumentException(
                        "Invalid image header: invalid header length");
            }
        }

        length = ((length + pageSize - 1) / pageSize) * pageSize;

        if (length <= 0) {
            throw new IllegalArgumentException("Invalid image header: invalid length");
        }

        return length;
    }

    public static void doSignature( String target,
                                    String imagePath,
                                    String keyPath,
                                    String certPath,
                                    String outPath) throws Exception {

        byte[] image = Utils.read(imagePath);
        int signableSize = getSignableImageSize(image);

        if (signableSize < image.length) {
            System.err.println("NOTE: truncating file " + imagePath +
                    " from " + image.length + " to " + signableSize + " bytes");
            image = Arrays.copyOf(image, signableSize);
        } else if (signableSize > image.length) {
            throw new IllegalArgumentException("Invalid image: too short, expected " +
                    signableSize + " bytes");
        }

        BootSignature bootsig = new BootSignature(target, image.length);

        X509Certificate cert = Utils.loadPEMCertificate(certPath);
        bootsig.setCertificate(cert);

        PrivateKey key = Utils.loadDERPrivateKeyFromFile(keyPath);
        bootsig.setSignature(bootsig.sign(image, key),
            Utils.getSignatureAlgorithmIdentifier(key));

        byte[] encoded_bootsig = bootsig.getEncoded();
        byte[] image_with_metadata = Arrays.copyOf(image, image.length + encoded_bootsig.length);

        System.arraycopy(encoded_bootsig, 0, image_with_metadata,
                image.length, encoded_bootsig.length);

        Utils.write(image_with_metadata, outPath);
    }

    public static void verifySignature(String imagePath, String certPath) throws Exception {
        byte[] image = Utils.read(imagePath);
        int signableSize = getSignableImageSize(image);

        if (signableSize >= image.length) {
            throw new IllegalArgumentException("Invalid image: not signed");
        }

        byte[] signature = Arrays.copyOfRange(image, signableSize, image.length);
        BootSignature bootsig = new BootSignature(signature);

        if (!certPath.isEmpty()) {
            System.err.println("NOTE: verifying using public key from " + certPath);
            bootsig.setCertificate(Utils.loadPEMCertificate(certPath));
        }

        try {
            if (bootsig.verify(Arrays.copyOf(image, signableSize))) {
                System.err.println("Signature is VALID");
                System.exit(0);
            } else {
                System.err.println("Signature is INVALID");
            }
        } catch (Exception e) {
            e.printStackTrace(System.err);
        }
        System.exit(1);
    }

    /* Example usage for signing a boot image using dev keys:
        java -cp \
            ../../../out/host/common/obj/JAVA_LIBRARIES/BootSignature_intermediates/ \
                classes/com.android.verity.BootSignature \
            /boot \
            ../../../out/target/product/$PRODUCT/boot.img \
            ../../../build/target/product/security/verity.pk8 \
            ../../../build/target/product/security/verity.x509.pem \
            /tmp/boot.img.signed
    */
    public static void main(String[] args) throws Exception {
        Security.addProvider(new BouncyCastleProvider());

        if ("-verify".equals(args[0])) {
            String certPath = "";

            if (args.length >= 4 && "-certificate".equals(args[2])) {
                /* args[3] is the path to a public key certificate */
                certPath = args[3];
            }

            /* args[1] is the path to a signed boot image */
            verifySignature(args[1], certPath);
        } else {
            /* args[0] is the target name, typically /boot
               args[1] is the path to a boot image to sign
               args[2] is the path to a private key
               args[3] is the path to the matching public key certificate
               args[4] is the path where to output the signed boot image
            */
            doSignature(args[0], args[1], args[2], args[3], args[4]);
        }
    }
}

```

`aosp/boot_signer/src/main/java/Utils.java`:

```java
/*
 * Copyright (C) 2014 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.android.verity;

import java.lang.reflect.Constructor;
import java.io.File;
import java.io.ByteArrayInputStream;
import java.io.Console;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.InputStreamReader;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.security.Key;
import java.security.PrivateKey;
import java.security.PublicKey;
import java.security.KeyFactory;
import java.security.Provider;
import java.security.Security;
import java.security.Signature;
import java.security.cert.Certificate;
import java.security.cert.CertificateFactory;
import java.security.cert.X509Certificate;
import java.security.spec.ECPublicKeySpec;
import java.security.spec.ECPrivateKeySpec;
import java.security.spec.X509EncodedKeySpec;
import java.security.spec.PKCS8EncodedKeySpec;
import java.security.spec.InvalidKeySpecException;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;

import javax.crypto.Cipher;
import javax.crypto.EncryptedPrivateKeyInfo;
import javax.crypto.SecretKeyFactory;
import javax.crypto.spec.PBEKeySpec;

import org.bouncycastle.asn1.ASN1InputStream;
import org.bouncycastle.asn1.ASN1ObjectIdentifier;
import org.bouncycastle.asn1.pkcs.PrivateKeyInfo;
import org.bouncycastle.asn1.pkcs.PKCSObjectIdentifiers;
import org.bouncycastle.asn1.x509.AlgorithmIdentifier;
import org.bouncycastle.asn1.x9.X9ObjectIdentifiers;
import org.bouncycastle.util.encoders.Base64;

public class Utils {

    private static final Map<String, String> ID_TO_ALG;
    private static final Map<String, String> ALG_TO_ID;

    static {
        ID_TO_ALG = new HashMap<String, String>();
        ALG_TO_ID = new HashMap<String, String>();

        ID_TO_ALG.put(X9ObjectIdentifiers.ecdsa_with_SHA256.getId(), "SHA256withECDSA");
        ID_TO_ALG.put(X9ObjectIdentifiers.ecdsa_with_SHA384.getId(), "SHA384withECDSA");
        ID_TO_ALG.put(X9ObjectIdentifiers.ecdsa_with_SHA512.getId(), "SHA512withECDSA");
        ID_TO_ALG.put(PKCSObjectIdentifiers.sha1WithRSAEncryption.getId(), "SHA1withRSA");
        ID_TO_ALG.put(PKCSObjectIdentifiers.sha256WithRSAEncryption.getId(), "SHA256withRSA");
        ID_TO_ALG.put(PKCSObjectIdentifiers.sha512WithRSAEncryption.getId(), "SHA512withRSA");

        ALG_TO_ID.put("SHA256withECDSA", X9ObjectIdentifiers.ecdsa_with_SHA256.getId());
        ALG_TO_ID.put("SHA384withECDSA", X9ObjectIdentifiers.ecdsa_with_SHA384.getId());
        ALG_TO_ID.put("SHA512withECDSA", X9ObjectIdentifiers.ecdsa_with_SHA512.getId());
        ALG_TO_ID.put("SHA1withRSA", PKCSObjectIdentifiers.sha1WithRSAEncryption.getId());
        ALG_TO_ID.put("SHA256withRSA", PKCSObjectIdentifiers.sha256WithRSAEncryption.getId());
        ALG_TO_ID.put("SHA512withRSA", PKCSObjectIdentifiers.sha512WithRSAEncryption.getId());
    }

    private static void loadProviderIfNecessary(String providerClassName) {
        if (providerClassName == null) {
            return;
        }

        final Class<?> klass;
        try {
            final ClassLoader sysLoader = ClassLoader.getSystemClassLoader();
            if (sysLoader != null) {
                klass = sysLoader.loadClass(providerClassName);
            } else {
                klass = Class.forName(providerClassName);
            }
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
            System.exit(1);
            return;
        }

        Constructor<?> constructor = null;
        for (Constructor<?> c : klass.getConstructors()) {
            if (c.getParameterTypes().length == 0) {
                constructor = c;
                break;
            }
        }
        if (constructor == null) {
            System.err.println("No zero-arg constructor found for " + providerClassName);
            System.exit(1);
            return;
        }

        final Object o;
        try {
            o = constructor.newInstance();
        } catch (Exception e) {
            e.printStackTrace();
            System.exit(1);
            return;
        }
        if (!(o instanceof Provider)) {
            System.err.println("Not a Provider class: " + providerClassName);
            System.exit(1);
        }

        Security.insertProviderAt((Provider) o, 1);
    }

    static byte[] pemToDer(String pem) throws Exception {
        pem = pem.replaceAll("^-.*", "");
        String base64_der = pem.replaceAll("-.*$", "");
        return Base64.decode(base64_der);
    }

    private static PKCS8EncodedKeySpec decryptPrivateKey(byte[] encryptedPrivateKey)
        throws GeneralSecurityException {
        EncryptedPrivateKeyInfo epkInfo;
        try {
            epkInfo = new EncryptedPrivateKeyInfo(encryptedPrivateKey);
        } catch (IOException ex) {
            // Probably not an encrypted key.
            return null;
        }

        char[] password = System.console().readPassword("Password for the private key file: ");

        SecretKeyFactory skFactory = SecretKeyFactory.getInstance(epkInfo.getAlgName());
        Key key = skFactory.generateSecret(new PBEKeySpec(password));
        Arrays.fill(password, '\0');

        Cipher cipher = Cipher.getInstance(epkInfo.getAlgName());
        cipher.init(Cipher.DECRYPT_MODE, key, epkInfo.getAlgParameters());

        try {
            return epkInfo.getKeySpec(cipher);
        } catch (InvalidKeySpecException ex) {
            System.err.println("Password may be bad.");
            throw ex;
        }
    }

    static PrivateKey loadDERPrivateKey(byte[] der) throws Exception {
        PKCS8EncodedKeySpec spec = decryptPrivateKey(der);

        if (spec == null) {
            spec = new PKCS8EncodedKeySpec(der);
        }

        ASN1InputStream bIn = new ASN1InputStream(new ByteArrayInputStream(spec.getEncoded()));
        PrivateKeyInfo pki = PrivateKeyInfo.getInstance(bIn.readObject());
        String algOid = pki.getPrivateKeyAlgorithm().getAlgorithm().getId();

        return KeyFactory.getInstance(algOid).generatePrivate(spec);
    }

    static PrivateKey loadPEMPrivateKey(byte[] pem) throws Exception {
        byte[] der = pemToDer(new String(pem));
        return loadDERPrivateKey(der);
    }

    static PrivateKey loadPEMPrivateKeyFromFile(String keyFname) throws Exception {
        return loadPEMPrivateKey(read(keyFname));
    }

    static PrivateKey loadDERPrivateKeyFromFile(String keyFname) throws Exception {
        return loadDERPrivateKey(read(keyFname));
    }

    static PublicKey loadDERPublicKey(byte[] der) throws Exception {
        X509EncodedKeySpec publicKeySpec = new X509EncodedKeySpec(der);
        KeyFactory factory = KeyFactory.getInstance("RSA");
        return factory.generatePublic(publicKeySpec);
    }

    static PublicKey loadPEMPublicKey(byte[] pem) throws Exception {
        byte[] der = pemToDer(new String(pem));
        X509EncodedKeySpec publicKeySpec = new X509EncodedKeySpec(der);
        KeyFactory factory = KeyFactory.getInstance("RSA");
        return factory.generatePublic(publicKeySpec);
    }

    static PublicKey loadPEMPublicKeyFromFile(String keyFname) throws Exception {
        return loadPEMPublicKey(read(keyFname));
    }

    static PublicKey loadDERPublicKeyFromFile(String keyFname) throws Exception {
        return loadDERPublicKey(read(keyFname));
    }

    static X509Certificate loadPEMCertificate(String fname) throws Exception {
        try (FileInputStream fis = new FileInputStream(fname)) {
            CertificateFactory cf = CertificateFactory.getInstance("X.509");
            return (X509Certificate) cf.generateCertificate(fis);
        }
    }

    private static String getSignatureAlgorithm(Key key) throws Exception {
        if ("EC".equals(key.getAlgorithm())) {
            int curveSize;
            KeyFactory factory = KeyFactory.getInstance("EC");

            if (key instanceof PublicKey) {
                ECPublicKeySpec spec = factory.getKeySpec(key, ECPublicKeySpec.class);
                curveSize = spec.getParams().getCurve().getField().getFieldSize();
            } else if (key instanceof PrivateKey) {
                ECPrivateKeySpec spec = factory.getKeySpec(key, ECPrivateKeySpec.class);
                curveSize = spec.getParams().getCurve().getField().getFieldSize();
            } else {
                throw new InvalidKeySpecException();
            }

            if (curveSize <= 256) {
                return "SHA256withECDSA";
            } else if (curveSize <= 384) {
                return "SHA384withECDSA";
            } else {
                return "SHA512withECDSA";
            }
        } else if ("RSA".equals(key.getAlgorithm())) {
            return "SHA256withRSA";
        } else {
            throw new IllegalArgumentException("Unsupported key type " + key.getAlgorithm());
        }
    }

    static AlgorithmIdentifier getSignatureAlgorithmIdentifier(Key key) throws Exception {
        String id = ALG_TO_ID.get(getSignatureAlgorithm(key));

        if (id == null) {
            throw new IllegalArgumentException("Unsupported key type " + key.getAlgorithm());
        }

        return new AlgorithmIdentifier(new ASN1ObjectIdentifier(id));
    }

    static boolean verify(PublicKey key, byte[] input, byte[] signature,
            AlgorithmIdentifier algId) throws Exception {
        String algName = ID_TO_ALG.get(algId.getAlgorithm().getId());

        if (algName == null) {
            throw new IllegalArgumentException("Unsupported algorithm " + algId.getAlgorithm());
        }

        Signature verifier = Signature.getInstance(algName);
        verifier.initVerify(key);
        verifier.update(input);

        return verifier.verify(signature);
    }

    static byte[] sign(PrivateKey privateKey, byte[] input) throws Exception {
        Signature signer = Signature.getInstance(getSignatureAlgorithm(privateKey));
        signer.initSign(privateKey);
        signer.update(input);
        return signer.sign();
    }

    static byte[] read(String fname) throws Exception {
        long offset = 0;
        File f = new File(fname);
        long length = f.length();
        byte[] image = new byte[(int)length];
        FileInputStream fis = new FileInputStream(f);
        while (offset < length) {
            offset += fis.read(image, (int)offset, (int)(length - offset));
        }
        fis.close();
        return image;
    }

    static void write(byte[] data, String fname) throws Exception{
        FileOutputStream out = new FileOutputStream(fname);
        out.write(data);
        out.close();
    }
}

```

`aosp/boot_signer/src/main/java/VeritySigner.java`:

```java
/*
 * Copyright (C) 2013 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.android.verity;

import java.security.PublicKey;
import java.security.PrivateKey;
import java.security.Security;
import java.security.cert.X509Certificate;
import org.bouncycastle.jce.provider.BouncyCastleProvider;

public class VeritySigner {

    private static void usage() {
        System.err.println("usage: VeritySigner <contentfile> <key.pk8> " +
                "<sigfile> | <contentfile> <certificate.x509.pem> <sigfile> " +
                "-verify");
        System.exit(1);
    }

    public static void main(String[] args) throws Exception {
        if (args.length < 3) {
            usage();
            return;
        }

        Security.addProvider(new BouncyCastleProvider());

        byte[] content = Utils.read(args[0]);

        if (args.length > 3 && "-verify".equals(args[3])) {
            X509Certificate cert = Utils.loadPEMCertificate(args[1]);
            PublicKey publicKey = cert.getPublicKey();

            byte[] signature = Utils.read(args[2]);

            try {
                if (Utils.verify(publicKey, content, signature,
                            Utils.getSignatureAlgorithmIdentifier(publicKey))) {
                    System.err.println("Signature is VALID");
                    System.exit(0);
                } else {
                    System.err.println("Signature is INVALID");
                }
            } catch (Exception e) {
                e.printStackTrace(System.err);
            }

            System.exit(1);
        } else {
            PrivateKey privateKey = Utils.loadDERPrivateKey(Utils.read(args[1]));
            byte[] signature = Utils.sign(privateKey, content);
            Utils.write(signature, args[2]);
        }
    }
}

```

`aosp/dispol/Makefile`:

```
.PHONY: all checkpolicy libsepol prepare
nothing:
	@echo "Nothing to do"

checkpolicy: export CFLAGS := -g -Wall -Werror -Wshadow -pipe -fno-strict-aliasing -I$(CURDIR)/libsepol-3.2/include
checkpolicy: export LIBSEPOLA := $(CURDIR)/libsepol-3.2/src/libsepol.a
checkpolicy: export LDLIBS_LIBSEPOLA := -l:libsepol.a -L$(CURDIR)/libsepol-3.2/src
checkpolicy: libsepol
	make -C checkpolicy-3.2 -j
	cp checkpolicy-3.2/test/dispol .

libsepol:
	make -C libsepol-3.2 -j

prepare:
	rm -fr libsepol-3.2 checkpolicy-3.2
	wget https://github.com/SELinuxProject/selinux/releases/download/3.2/libsepol-3.2.tar.gz
	wget https://github.com/SELinuxProject/selinux/releases/download/3.2/checkpolicy-3.2.tar.gz
	tar xaf checkpolicy-3.2.tar.gz
	tar xaf libsepol-3.2.tar.gz

all: checkpolicy libsepol prepare
# vim:ft=make
#

```

`aosp/dispol/README.md`:

```md
# dispol
decompile binary selinux policy file
Android sepolicy file is `/sys/fs/selinux/policy`
```
make all
./dispol <policy_file>
```

```

`aosp/dracut/README.md`:

```md
https://github.com/dracutdevs/dracut/tree/master/skipcpio

```

`aosp/dracut/skipcpio.c`:

```c
/* dracut-install.c  -- install files and executables

   Copyright (C) 2012 Harald Hoyer
   Copyright (C) 2012 Red Hat, Inc.  All rights reserved.

   This program is free software: you can redistribute it and/or modify
   under the terms of the GNU Lesser General Public License as published by
   the Free Software Foundation; either version 2.1 of the License, or
   (at your option) any later version.

   This program is distributed in the hope that it will be useful, but
   WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
   Lesser General Public License for more details.

   You should have received a copy of the GNU Lesser General Public License
   along with this program; If not, see <http://www.gnu.org/licenses/>.
*/

#define PROGRAM_VERSION_STRING "1"

#ifndef _GNU_SOURCE
#define _GNU_SOURCE
#endif

#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>

#define CPIO_END "TRAILER!!!"
#define CPIO_ENDLEN (sizeof(CPIO_END)-1)

static char buf[CPIO_ENDLEN * 2 + 1];

int main(int argc, char **argv)
{
        FILE *f;
        size_t s;

        if (argc != 2) {
                fprintf(stderr, "Usage: %s <file>\n", argv[0]);
                exit(1);
        }

        f = fopen(argv[1], "r");

        if (f == NULL) {
                fprintf(stderr, "Cannot open file '%s'\n", argv[1]);
                exit(1);
        }

        s = fread(buf, 6, 1, f);
        if (s <= 0) {
                fprintf(stderr, "Read error from file '%s'\n", argv[1]);
                fclose(f);
                exit(1);
        }
        fseek(f, 0, SEEK_SET);

        /* check, if this is a cpio archive */
        if (buf[0] == '0' && buf[1] == '7' && buf[2] == '0' && buf[3] == '7' && buf[4] == '0' && buf[5] == '1') {
                long pos = 0;

                /* Search for CPIO_END */
                do {
                        char *h;
                        fseek(f, pos, SEEK_SET);
                        buf[sizeof(buf) - 1] = 0;
                        s = fread(buf, CPIO_ENDLEN, 2, f);
                        if (s <= 0)
                                break;

                        h = strstr(buf, CPIO_END);
                        if (h) {
                                pos = (h - buf) + pos + CPIO_ENDLEN;
                                fseek(f, pos, SEEK_SET);
                                break;
                        }
                        pos += CPIO_ENDLEN;
                } while (!feof(f));

                if (feof(f)) {
                        /* CPIO_END not found, just cat the whole file */
                        fseek(f, 0, SEEK_SET);
                } else {
                        /* skip zeros */
                        while (!feof(f)) {
                                size_t i;

                                buf[sizeof(buf) - 1] = 0;
                                s = fread(buf, 1, sizeof(buf) - 1, f);
                                if (s <= 0)
                                        break;

                                for (i = 0; (i < s) && (buf[i] == 0); i++) ;

                                if (buf[i] != 0) {
                                        pos += i;
                                        fseek(f, pos, SEEK_SET);
                                        break;
                                }

                                pos += s;
                        }
                }
        }
        /* cat out the rest */
        while (!feof(f)) {
                s = fread(buf, 1, sizeof(buf), f);
                if (s <= 0)
                        break;

                s = fwrite(buf, 1, s, stdout);
                if (s <= 0)
                        break;
        }
        fclose(f);

        return EXIT_SUCCESS;
}

```

`aosp/libavb1.1/build.gradle`:

```gradle
apply plugin: "c"
apply plugin: "cpp"

model {
    buildTypes {
        release
    }

    components {
        avb(NativeLibrarySpec) {
            binaries.all {
                cCompiler.define "_FILE_OFFSET_BITS", "64" 
                cCompiler.define "_POSIX_C_SOURCE", "199309L" 
                cCompiler.define "AVB_ENABLE_DEBUG"
                cCompiler.define "AVB_COMPILATION"
                cCompiler.args << "-Wall" << "-g"
            }
        }
    }
}

```

`aosp/libavb1.1/src/avb/c/avb_chain_partition_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_chain_partition_descriptor.h"
#include "avb_util.h"

bool avb_chain_partition_descriptor_validate_and_byteswap(
    const AvbChainPartitionDescriptor* src, AvbChainPartitionDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbChainPartitionDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_CHAIN_PARTITION) {
    avb_error("Invalid tag for chain partition descriptor.\n");
    return false;
  }

  dest->rollback_index_location = avb_be32toh(dest->rollback_index_location);
  dest->partition_name_len = avb_be32toh(dest->partition_name_len);
  dest->public_key_len = avb_be32toh(dest->public_key_len);

  if (dest->rollback_index_location < 1) {
    avb_error("Invalid rollback index location value.\n");
    return false;
  }

  /* Check that partition_name and public_key are fully contained. */
  expected_size = sizeof(AvbChainPartitionDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->partition_name_len) ||
      !avb_safe_add_to(&expected_size, dest->public_key_len)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }
  return true;
}

```

`aosp/libavb1.1/src/avb/c/avb_cmdline.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_cmdline.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_version.h"

#define NUM_GUIDS 3

/* Substitutes all variables (e.g. $(ANDROID_SYSTEM_PARTUUID)) with
 * values. Returns NULL on OOM, otherwise the cmdline with values
 * replaced.
 */
char* avb_sub_cmdline(AvbOps* ops,
                      const char* cmdline,
                      const char* ab_suffix,
                      bool using_boot_for_vbmeta,
                      const AvbCmdlineSubstList* additional_substitutions) {
  const char* part_name_str[NUM_GUIDS] = {"system", "boot", "vbmeta"};
  const char* replace_str[NUM_GUIDS] = {"$(ANDROID_SYSTEM_PARTUUID)",
                                        "$(ANDROID_BOOT_PARTUUID)",
                                        "$(ANDROID_VBMETA_PARTUUID)"};
  char* ret = NULL;
  AvbIOResult io_ret;
  size_t n;

  /* Special-case for when the top-level vbmeta struct is in the boot
   * partition.
   */
  if (using_boot_for_vbmeta) {
    part_name_str[2] = "boot";
  }

  /* Replace unique partition GUIDs */
  for (n = 0; n < NUM_GUIDS; n++) {
    char part_name[AVB_PART_NAME_MAX_SIZE];
    char guid_buf[37];

    /* Don't attempt to query the partition guid unless its search string is
     * present in the command line. Note: the original cmdline is used here,
     * not the replaced one. See b/116010959.
     */
    if (avb_strstr(cmdline, replace_str[n]) == NULL) {
      continue;
    }

    if (!avb_str_concat(part_name,
                        sizeof part_name,
                        part_name_str[n],
                        avb_strlen(part_name_str[n]),
                        ab_suffix,
                        avb_strlen(ab_suffix))) {
      avb_error("Partition name and suffix does not fit.\n");
      goto fail;
    }

    io_ret = ops->get_unique_guid_for_partition(
        ops, part_name, guid_buf, sizeof guid_buf);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      goto fail;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_error("Error getting unique GUID for partition.\n");
      goto fail;
    }

    if (ret == NULL) {
      ret = avb_replace(cmdline, replace_str[n], guid_buf);
    } else {
      char* new_ret = avb_replace(ret, replace_str[n], guid_buf);
      avb_free(ret);
      ret = new_ret;
    }
    if (ret == NULL) {
      goto fail;
    }
  }

  /* It's possible there is no _PARTUUID for replacement above.
   * Duplicate cmdline to ret for additional substitutions below.
   */
  if (ret == NULL) {
    ret = avb_strdup(cmdline);
    if (ret == NULL) {
      goto fail;
    }
  }

  /* Replace any additional substitutions. */
  if (additional_substitutions != NULL) {
    for (n = 0; n < additional_substitutions->size; ++n) {
      char* new_ret = avb_replace(ret,
                                  additional_substitutions->tokens[n],
                                  additional_substitutions->values[n]);
      avb_free(ret);
      ret = new_ret;
      if (ret == NULL) {
        goto fail;
      }
    }
  }

  return ret;

fail:
  if (ret != NULL) {
    avb_free(ret);
  }
  return NULL;
}

static int cmdline_append_option(AvbSlotVerifyData* slot_data,
                                 const char* key,
                                 const char* value) {
  size_t offset, key_len, value_len;
  char* new_cmdline;

  key_len = avb_strlen(key);
  value_len = avb_strlen(value);

  offset = 0;
  if (slot_data->cmdline != NULL) {
    offset = avb_strlen(slot_data->cmdline);
    if (offset > 0) {
      offset += 1;
    }
  }

  new_cmdline = avb_calloc(offset + key_len + value_len + 2);
  if (new_cmdline == NULL) {
    return 0;
  }
  if (offset > 0) {
    avb_memcpy(new_cmdline, slot_data->cmdline, offset - 1);
    new_cmdline[offset - 1] = ' ';
  }
  avb_memcpy(new_cmdline + offset, key, key_len);
  new_cmdline[offset + key_len] = '=';
  avb_memcpy(new_cmdline + offset + key_len + 1, value, value_len);
  if (slot_data->cmdline != NULL) {
    avb_free(slot_data->cmdline);
  }
  slot_data->cmdline = new_cmdline;

  return 1;
}

#define AVB_MAX_DIGITS_UINT64 32

/* Writes |value| to |digits| in base 10 followed by a NUL byte.
 * Returns number of characters written excluding the NUL byte.
 */
static size_t uint64_to_base10(uint64_t value,
                               char digits[AVB_MAX_DIGITS_UINT64]) {
  char rev_digits[AVB_MAX_DIGITS_UINT64];
  size_t n, num_digits;

  for (num_digits = 0; num_digits < AVB_MAX_DIGITS_UINT64 - 1;) {
    rev_digits[num_digits++] = avb_div_by_10(&value) + '0';
    if (value == 0) {
      break;
    }
  }

  for (n = 0; n < num_digits; n++) {
    digits[n] = rev_digits[num_digits - 1 - n];
  }
  digits[n] = '\0';
  return n;
}

static int cmdline_append_version(AvbSlotVerifyData* slot_data,
                                  const char* key,
                                  uint64_t major_version,
                                  uint64_t minor_version) {
  char major_digits[AVB_MAX_DIGITS_UINT64];
  char minor_digits[AVB_MAX_DIGITS_UINT64];
  char combined[AVB_MAX_DIGITS_UINT64 * 2 + 1];
  size_t num_major_digits, num_minor_digits;

  num_major_digits = uint64_to_base10(major_version, major_digits);
  num_minor_digits = uint64_to_base10(minor_version, minor_digits);
  avb_memcpy(combined, major_digits, num_major_digits);
  combined[num_major_digits] = '.';
  avb_memcpy(combined + num_major_digits + 1, minor_digits, num_minor_digits);
  combined[num_major_digits + 1 + num_minor_digits] = '\0';

  return cmdline_append_option(slot_data, key, combined);
}

static int cmdline_append_uint64_base10(AvbSlotVerifyData* slot_data,
                                        const char* key,
                                        uint64_t value) {
  char digits[AVB_MAX_DIGITS_UINT64];
  uint64_to_base10(value, digits);
  return cmdline_append_option(slot_data, key, digits);
}

static int cmdline_append_hex(AvbSlotVerifyData* slot_data,
                              const char* key,
                              const uint8_t* data,
                              size_t data_len) {
  int ret;
  char* hex_data = avb_bin2hex(data, data_len);
  if (hex_data == NULL) {
    return 0;
  }
  ret = cmdline_append_option(slot_data, key, hex_data);
  avb_free(hex_data);
  return ret;
}

AvbSlotVerifyResult avb_append_options(
    AvbOps* ops,
    AvbSlotVerifyFlags flags,
    AvbSlotVerifyData* slot_data,
    AvbVBMetaImageHeader* toplevel_vbmeta,
    AvbAlgorithmType algorithm_type,
    AvbHashtreeErrorMode hashtree_error_mode,
    AvbHashtreeErrorMode resolved_hashtree_error_mode) {
  AvbSlotVerifyResult ret;
  const char* verity_mode;
  bool is_device_unlocked;
  AvbIOResult io_ret;

  /* Add androidboot.vbmeta.device option... except if not using a vbmeta
   * partition since it doesn't make sense in that case.
   */
  if (!(flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION)) {
    if (!cmdline_append_option(slot_data,
                               "androidboot.vbmeta.device",
                               "PARTUUID=$(ANDROID_VBMETA_PARTUUID)")) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
  }

  /* Add androidboot.vbmeta.avb_version option. */
  if (!cmdline_append_version(slot_data,
                              "androidboot.vbmeta.avb_version",
                              AVB_VERSION_MAJOR,
                              AVB_VERSION_MINOR)) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }

  /* Set androidboot.avb.device_state to "locked" or "unlocked". */
  io_ret = ops->read_is_device_unlocked(ops, &is_device_unlocked);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error getting device state.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    goto out;
  }
  if (!cmdline_append_option(slot_data,
                             "androidboot.vbmeta.device_state",
                             is_device_unlocked ? "unlocked" : "locked")) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }

  /* Set androidboot.vbmeta.{hash_alg, size, digest} - use same hash
   * function as is used to sign vbmeta.
   */
  switch (algorithm_type) {
    /* Explicit fallthrough. */
    case AVB_ALGORITHM_TYPE_NONE:
    case AVB_ALGORITHM_TYPE_SHA256_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA256_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA256_RSA8192: {
      size_t n, total_size = 0;
      uint8_t vbmeta_digest[AVB_SHA256_DIGEST_SIZE];
      avb_slot_verify_data_calculate_vbmeta_digest(
          slot_data, AVB_DIGEST_TYPE_SHA256, vbmeta_digest);
      for (n = 0; n < slot_data->num_vbmeta_images; n++) {
        total_size += slot_data->vbmeta_images[n].vbmeta_size;
      }
      if (!cmdline_append_option(
              slot_data, "androidboot.vbmeta.hash_alg", "sha256") ||
          !cmdline_append_uint64_base10(
              slot_data, "androidboot.vbmeta.size", total_size) ||
          !cmdline_append_hex(slot_data,
                              "androidboot.vbmeta.digest",
                              vbmeta_digest,
                              AVB_SHA256_DIGEST_SIZE)) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto out;
      }
    } break;
    /* Explicit fallthrough. */
    case AVB_ALGORITHM_TYPE_SHA512_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA512_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA512_RSA8192: {
      size_t n, total_size = 0;
      uint8_t vbmeta_digest[AVB_SHA512_DIGEST_SIZE];
      avb_slot_verify_data_calculate_vbmeta_digest(
          slot_data, AVB_DIGEST_TYPE_SHA512, vbmeta_digest);
      for (n = 0; n < slot_data->num_vbmeta_images; n++) {
        total_size += slot_data->vbmeta_images[n].vbmeta_size;
      }
      if (!cmdline_append_option(
              slot_data, "androidboot.vbmeta.hash_alg", "sha512") ||
          !cmdline_append_uint64_base10(
              slot_data, "androidboot.vbmeta.size", total_size) ||
          !cmdline_append_hex(slot_data,
                              "androidboot.vbmeta.digest",
                              vbmeta_digest,
                              AVB_SHA512_DIGEST_SIZE)) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto out;
      }
    } break;
    case _AVB_ALGORITHM_NUM_TYPES:
      avb_assert_not_reached();
      break;
  }

  /* Set androidboot.veritymode and androidboot.vbmeta.invalidate_on_error */
  if (toplevel_vbmeta->flags & AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED) {
    verity_mode = "disabled";
  } else {
    const char* dm_verity_mode;
    char* new_ret;

    switch (resolved_hashtree_error_mode) {
      case AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE:
        if (!cmdline_append_option(
                slot_data, "androidboot.vbmeta.invalidate_on_error", "yes")) {
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
          goto out;
        }
        verity_mode = "enforcing";
        dm_verity_mode = "restart_on_corruption";
        break;
      case AVB_HASHTREE_ERROR_MODE_RESTART:
        verity_mode = "enforcing";
        dm_verity_mode = "restart_on_corruption";
        break;
      case AVB_HASHTREE_ERROR_MODE_EIO:
        verity_mode = "eio";
        /* For now there's no option to specify the EIO mode. So
         * just use 'ignore_zero_blocks' since that's already set
         * and dm-verity-target.c supports specifying this multiple
         * times.
         */
        dm_verity_mode = "ignore_zero_blocks";
        break;
      case AVB_HASHTREE_ERROR_MODE_LOGGING:
        verity_mode = "logging";
        dm_verity_mode = "ignore_corruption";
        break;
      case AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO:
        // Should never get here because MANAGED_RESTART_AND_EIO is
        // remapped by avb_manage_hashtree_error_mode().
        avb_assert_not_reached();
        break;
    }
    new_ret = avb_replace(
        slot_data->cmdline, "$(ANDROID_VERITY_MODE)", dm_verity_mode);
    avb_free(slot_data->cmdline);
    slot_data->cmdline = new_ret;
    if (slot_data->cmdline == NULL) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
  }
  if (!cmdline_append_option(
          slot_data, "androidboot.veritymode", verity_mode)) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }
  if (hashtree_error_mode == AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO) {
    if (!cmdline_append_option(
            slot_data, "androidboot.veritymode.managed", "yes")) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
  }

  ret = AVB_SLOT_VERIFY_RESULT_OK;

out:

  return ret;
}

AvbCmdlineSubstList* avb_new_cmdline_subst_list() {
  return (AvbCmdlineSubstList*)avb_calloc(sizeof(AvbCmdlineSubstList));
}

void avb_free_cmdline_subst_list(AvbCmdlineSubstList* cmdline_subst) {
  size_t i;
  for (i = 0; i < cmdline_subst->size; ++i) {
    avb_free(cmdline_subst->tokens[i]);
    avb_free(cmdline_subst->values[i]);
  }
  cmdline_subst->size = 0;
  avb_free(cmdline_subst);
}

AvbSlotVerifyResult avb_add_root_digest_substitution(
    const char* part_name,
    const uint8_t* digest,
    size_t digest_size,
    AvbCmdlineSubstList* out_cmdline_subst) {
  const char* kDigestSubPrefix = "$(AVB_";
  const char* kDigestSubSuffix = "_ROOT_DIGEST)";
  size_t part_name_len = avb_strlen(part_name);
  size_t list_index = out_cmdline_subst->size;

  avb_assert(part_name_len < AVB_PART_NAME_MAX_SIZE);
  avb_assert(digest_size <= AVB_SHA512_DIGEST_SIZE);
  if (part_name_len >= AVB_PART_NAME_MAX_SIZE ||
      digest_size > AVB_SHA512_DIGEST_SIZE) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }

  if (out_cmdline_subst->size >= AVB_MAX_NUM_CMDLINE_SUBST) {
    /* The list is full. Currently dynamic growth of this list is not supported.
     */
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }

  /* Construct the token to replace in the command line based on the partition
   * name. For partition 'foo', this will be '$(AVB_FOO_ROOT_DIGEST)'.
   */
  out_cmdline_subst->tokens[list_index] =
      avb_strdupv(kDigestSubPrefix, part_name, kDigestSubSuffix, NULL);
  if (out_cmdline_subst->tokens[list_index] == NULL) {
    goto fail;
  }
  avb_uppercase(out_cmdline_subst->tokens[list_index]);

  /* The digest value is hex encoded when inserted in the command line. */
  out_cmdline_subst->values[list_index] = avb_bin2hex(digest, digest_size);
  if (out_cmdline_subst->values[list_index] == NULL) {
    goto fail;
  }

  out_cmdline_subst->size++;
  return AVB_SLOT_VERIFY_RESULT_OK;

fail:
  if (out_cmdline_subst->tokens[list_index]) {
    avb_free(out_cmdline_subst->tokens[list_index]);
  }
  if (out_cmdline_subst->values[list_index]) {
    avb_free(out_cmdline_subst->values[list_index]);
  }
  return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
}

```

`aosp/libavb1.1/src/avb/c/avb_crc32.c`:

```c
/*-
 *  COPYRIGHT (C) 1986 Gary S. Brown.  You may use this program, or
 *  code or tables extracted from it, as desired without restriction.
 */

/*
 *  First, the polynomial itself and its table of feedback terms.  The
 *  polynomial is
 *  X^32+X^26+X^23+X^22+X^16+X^12+X^11+X^10+X^8+X^7+X^5+X^4+X^2+X^1+X^0
 *
 *  Note that we take it "backwards" and put the highest-order term in
 *  the lowest-order bit.  The X^32 term is "implied"; the LSB is the
 *  X^31 term, etc.  The X^0 term (usually shown as "+1") results in
 *  the MSB being 1
 *
 *  Note that the usual hardware shift register implementation, which
 *  is what we're using (we're merely optimizing it by doing eight-bit
 *  chunks at a time) shifts bits into the lowest-order term.  In our
 *  implementation, that means shifting towards the right.  Why do we
 *  do it this way?  Because the calculated CRC must be transmitted in
 *  order from highest-order term to lowest-order term.  UARTs transmit
 *  characters in order from LSB to MSB.  By storing the CRC this way
 *  we hand it to the UART in the order low-byte to high-byte; the UART
 *  sends each low-bit to hight-bit; and the result is transmission bit
 *  by bit from highest- to lowest-order term without requiring any bit
 *  shuffling on our part.  Reception works similarly
 *
 *  The feedback terms table consists of 256, 32-bit entries.  Notes
 *
 *      The table can be generated at runtime if desired; code to do so
 *      is shown later.  It might not be obvious, but the feedback
 *      terms simply represent the results of eight shift/xor opera
 *      tions for all combinations of data and CRC register values
 *
 *      The values must be right-shifted by eight bits by the "updcrc
 *      logic; the shift must be unsigned (bring in zeroes).  On some
 *      hardware you could probably optimize the shift in assembler by
 *      using byte-swap instructions
 *      polynomial $edb88320
 *
 *
 * CRC32 code derived from work by Gary S. Brown.
 */

#include "avb_sysdeps.h"
#include "avb_util.h"

/* Code taken from FreeBSD 8 */

static uint32_t iavb_crc32_tab[] = {
    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f,
    0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988,
    0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91, 0x1db71064, 0x6ab020f2,
    0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,
    0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,
    0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172,
    0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b, 0x35b5a8fa, 0x42b2986c,
    0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,
    0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423,
    0xcfba9599, 0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,
    0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190, 0x01db7106,
    0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,
    0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d,
    0x91646c97, 0xe6635c01, 0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e,
    0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,
    0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,
    0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7,
    0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0,
    0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa,
    0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,
    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81,
    0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a,
    0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683, 0xe3630b12, 0x94643b84,
    0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,
    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,
    0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc,
    0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5, 0xd6d6a3e8, 0xa1d1937e,
    0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,
    0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55,
    0x316e8eef, 0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,
    0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe, 0xb2bd0b28,
    0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,
    0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f,
    0x72076785, 0x05005713, 0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38,
    0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,
    0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,
    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69,
    0x616bffd3, 0x166ccf45, 0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2,
    0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc,
    0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,
    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693,
    0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94,
    0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d};

/*
 * A function that calculates the CRC-32 based on the table above is
 * given below for documentation purposes. An equivalent implementation
 * of this function that's actually used in the kernel can be found
 * in sys/libkern.h, where it can be inlined.
 */

static uint32_t iavb_crc32(uint32_t crc_in, const uint8_t* buf, int size) {
  const uint8_t* p = buf;
  uint32_t crc;

  crc = crc_in ^ ~0U;
  while (size--)
    crc = iavb_crc32_tab[(crc ^ *p++) & 0xFF] ^ (crc >> 8);
  return crc ^ ~0U;
}

uint32_t avb_crc32(const uint8_t* buf, size_t size) {
  return iavb_crc32(0, buf, size);
}

```

`aosp/libavb1.1/src/avb/c/avb_crypto.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_crypto.h"
#include "avb_rsa.h"
#include "avb_sha.h"
#include "avb_util.h"

/* NOTE: The PKC1-v1.5 padding is a blob of binary DER of ASN.1 and is
 * obtained from section 5.2.2 of RFC 4880.
 */

static const uint8_t
    padding_RSA2048_SHA256[AVB_RSA2048_NUM_BYTES - AVB_SHA256_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0x00, 0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65,
        0x03, 0x04, 0x02, 0x01, 0x05, 0x00, 0x04, 0x20};

static const uint8_t
    padding_RSA4096_SHA256[AVB_RSA4096_NUM_BYTES - AVB_SHA256_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60,
        0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05, 0x00, 0x04, 0x20};

static const uint8_t
    padding_RSA8192_SHA256[AVB_RSA8192_NUM_BYTES - AVB_SHA256_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0x00, 0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65,
        0x03, 0x04, 0x02, 0x01, 0x05, 0x00, 0x04, 0x20};

static const uint8_t
    padding_RSA2048_SHA512[AVB_RSA2048_NUM_BYTES - AVB_SHA512_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60,
        0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05, 0x00, 0x04, 0x40};

static const uint8_t
    padding_RSA4096_SHA512[AVB_RSA4096_NUM_BYTES - AVB_SHA512_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x51, 0x30,
        0x0d, 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03,
        0x05, 0x00, 0x04, 0x40};

static const uint8_t
    padding_RSA8192_SHA512[AVB_RSA8192_NUM_BYTES - AVB_SHA512_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60,
        0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05, 0x00, 0x04, 0x40};

static AvbAlgorithmData algorithm_data[_AVB_ALGORITHM_NUM_TYPES] = {
    /* AVB_ALGORITHM_TYPE_NONE */
    {.padding = NULL, .padding_len = 0, .hash_len = 0},
    /* AVB_ALGORITHM_TYPE_SHA256_RSA2048 */
    {.padding = padding_RSA2048_SHA256,
     .padding_len = sizeof(padding_RSA2048_SHA256),
     .hash_len = AVB_SHA256_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA256_RSA4096 */
    {.padding = padding_RSA4096_SHA256,
     .padding_len = sizeof(padding_RSA4096_SHA256),
     .hash_len = AVB_SHA256_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA256_RSA8192 */
    {.padding = padding_RSA8192_SHA256,
     .padding_len = sizeof(padding_RSA8192_SHA256),
     .hash_len = AVB_SHA256_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA512_RSA2048 */
    {.padding = padding_RSA2048_SHA512,
     .padding_len = sizeof(padding_RSA2048_SHA512),
     .hash_len = AVB_SHA512_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA512_RSA4096 */
    {.padding = padding_RSA4096_SHA512,
     .padding_len = sizeof(padding_RSA4096_SHA512),
     .hash_len = AVB_SHA512_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA512_RSA8192 */
    {.padding = padding_RSA8192_SHA512,
     .padding_len = sizeof(padding_RSA8192_SHA512),
     .hash_len = AVB_SHA512_DIGEST_SIZE},
};

const AvbAlgorithmData* avb_get_algorithm_data(AvbAlgorithmType algorithm) {
  if ((size_t)algorithm < _AVB_ALGORITHM_NUM_TYPES) {
    return &algorithm_data[algorithm];
  }
  return NULL;
}

bool avb_rsa_public_key_header_validate_and_byteswap(
    const AvbRSAPublicKeyHeader* src, AvbRSAPublicKeyHeader* dest) {
  avb_memcpy(dest, src, sizeof(AvbRSAPublicKeyHeader));

  dest->key_num_bits = avb_be32toh(dest->key_num_bits);
  dest->n0inv = avb_be32toh(dest->n0inv);

  return true;
}

```

`aosp/libavb1.1/src/avb/c/avb_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_descriptor.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"

bool avb_descriptor_validate_and_byteswap(const AvbDescriptor* src,
                                          AvbDescriptor* dest) {
  dest->tag = avb_be64toh(src->tag);
  dest->num_bytes_following = avb_be64toh(src->num_bytes_following);

  if ((dest->num_bytes_following & 0x07) != 0) {
    avb_error("Descriptor size is not divisible by 8.\n");
    return false;
  }
  return true;
}

bool avb_descriptor_foreach(const uint8_t* image_data,
                            size_t image_size,
                            AvbDescriptorForeachFunc foreach_func,
                            void* user_data) {
  const AvbVBMetaImageHeader* header = NULL;
  bool ret = false;
  const uint8_t* image_end;
  const uint8_t* desc_start;
  const uint8_t* desc_end;
  const uint8_t* p;

  if (image_data == NULL) {
    avb_error("image_data is NULL\n.");
    goto out;
  }

  if (foreach_func == NULL) {
    avb_error("foreach_func is NULL\n.");
    goto out;
  }

  if (image_size < sizeof(AvbVBMetaImageHeader)) {
    avb_error("Length is smaller than header.\n");
    goto out;
  }

  /* Ensure magic is correct. */
  if (avb_memcmp(image_data, AVB_MAGIC, AVB_MAGIC_LEN) != 0) {
    avb_error("Magic is incorrect.\n");
    goto out;
  }

  /* Careful, not byteswapped - also ensure it's aligned properly. */
  avb_assert_aligned(image_data);
  header = (const AvbVBMetaImageHeader*)image_data;
  image_end = image_data + image_size;

  desc_start = image_data + sizeof(AvbVBMetaImageHeader) +
               avb_be64toh(header->authentication_data_block_size) +
               avb_be64toh(header->descriptors_offset);

  desc_end = desc_start + avb_be64toh(header->descriptors_size);

  if (desc_start < image_data || desc_start > image_end ||
      desc_end < image_data || desc_end > image_end || desc_end < desc_start) {
    avb_error("Descriptors not inside passed-in data.\n");
    goto out;
  }

  for (p = desc_start; p < desc_end;) {
    const AvbDescriptor* dh = (const AvbDescriptor*)p;
    avb_assert_aligned(dh);
    uint64_t nb_following = avb_be64toh(dh->num_bytes_following);
    uint64_t nb_total = 0;
    if (!avb_safe_add(&nb_total, sizeof(AvbDescriptor), nb_following)) {
      avb_error("Invalid descriptor length.\n");
      goto out;
    }

    if ((nb_total & 7) != 0) {
      avb_error("Invalid descriptor length.\n");
      goto out;
    }

    if (nb_total + p < desc_start || nb_total + p > desc_end) {
      avb_error("Invalid data in descriptors array.\n");
      goto out;
    }

    if (foreach_func(dh, user_data) == 0) {
      goto out;
    }

    if (!avb_safe_add_to((uint64_t*)(&p), nb_total)) {
      avb_error("Invalid descriptor length.\n");
      goto out;
    }
  }

  ret = true;

out:
  return ret;
}

static bool count_descriptors(const AvbDescriptor* descriptor,
                              void* user_data) {
  size_t* num_descriptors = user_data;
  *num_descriptors += 1;
  return true;
}

typedef struct {
  size_t descriptor_number;
  const AvbDescriptor** descriptors;
} SetDescriptorData;

static bool set_descriptors(const AvbDescriptor* descriptor, void* user_data) {
  SetDescriptorData* data = user_data;
  data->descriptors[data->descriptor_number++] = descriptor;
  return true;
}

const AvbDescriptor** avb_descriptor_get_all(const uint8_t* image_data,
                                             size_t image_size,
                                             size_t* out_num_descriptors) {
  size_t num_descriptors = 0;
  SetDescriptorData data;

  avb_descriptor_foreach(
      image_data, image_size, count_descriptors, &num_descriptors);

  data.descriptor_number = 0;
  data.descriptors =
      avb_calloc(sizeof(const AvbDescriptor*) * (num_descriptors + 1));
  if (data.descriptors == NULL) {
    return NULL;
  }
  avb_descriptor_foreach(image_data, image_size, set_descriptors, &data);
  avb_assert(data.descriptor_number == num_descriptors);

  if (out_num_descriptors != NULL) {
    *out_num_descriptors = num_descriptors;
  }

  return data.descriptors;
}

```

`aosp/libavb1.1/src/avb/c/avb_footer.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_footer.h"
#include "avb_util.h"

bool avb_footer_validate_and_byteswap(const AvbFooter* src, AvbFooter* dest) {
  avb_memcpy(dest, src, sizeof(AvbFooter));

  dest->version_major = avb_be32toh(dest->version_major);
  dest->version_minor = avb_be32toh(dest->version_minor);

  dest->original_image_size = avb_be64toh(dest->original_image_size);
  dest->vbmeta_offset = avb_be64toh(dest->vbmeta_offset);
  dest->vbmeta_size = avb_be64toh(dest->vbmeta_size);

  /* Check that magic is correct. */
  if (avb_safe_memcmp(dest->magic, AVB_FOOTER_MAGIC, AVB_FOOTER_MAGIC_LEN) !=
      0) {
    avb_error("Footer magic is incorrect.\n");
    return false;
  }

  /* Ensure we don't attempt to access any fields if the footer major
   * version is not supported.
   */
  if (dest->version_major > AVB_FOOTER_VERSION_MAJOR) {
    avb_error("No support for footer version.\n");
    return false;
  }

  return true;
}

```

`aosp/libavb1.1/src/avb/c/avb_hash_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_hash_descriptor.h"
#include "avb_util.h"

bool avb_hash_descriptor_validate_and_byteswap(const AvbHashDescriptor* src,
                                               AvbHashDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbHashDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_HASH) {
    avb_error("Invalid tag for hash descriptor.\n");
    return false;
  }

  dest->image_size = avb_be64toh(dest->image_size);
  dest->partition_name_len = avb_be32toh(dest->partition_name_len);
  dest->salt_len = avb_be32toh(dest->salt_len);
  dest->digest_len = avb_be32toh(dest->digest_len);
  dest->flags = avb_be32toh(dest->flags);

  /* Check that partition_name, salt, and digest are fully contained. */
  expected_size = sizeof(AvbHashDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->partition_name_len) ||
      !avb_safe_add_to(&expected_size, dest->salt_len) ||
      !avb_safe_add_to(&expected_size, dest->digest_len)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }
  return true;
}

```

`aosp/libavb1.1/src/avb/c/avb_hashtree_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_hashtree_descriptor.h"
#include "avb_util.h"

bool avb_hashtree_descriptor_validate_and_byteswap(
    const AvbHashtreeDescriptor* src, AvbHashtreeDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbHashtreeDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_HASHTREE) {
    avb_error("Invalid tag for hashtree descriptor.\n");
    return false;
  }

  dest->dm_verity_version = avb_be32toh(dest->dm_verity_version);
  dest->image_size = avb_be64toh(dest->image_size);
  dest->tree_offset = avb_be64toh(dest->tree_offset);
  dest->tree_size = avb_be64toh(dest->tree_size);
  dest->data_block_size = avb_be32toh(dest->data_block_size);
  dest->hash_block_size = avb_be32toh(dest->hash_block_size);
  dest->fec_num_roots = avb_be32toh(dest->fec_num_roots);
  dest->fec_offset = avb_be64toh(dest->fec_offset);
  dest->fec_size = avb_be64toh(dest->fec_size);
  dest->partition_name_len = avb_be32toh(dest->partition_name_len);
  dest->salt_len = avb_be32toh(dest->salt_len);
  dest->root_digest_len = avb_be32toh(dest->root_digest_len);
  dest->flags = avb_be32toh(dest->flags);

  /* Check that partition_name, salt, and root_digest are fully contained. */
  expected_size = sizeof(AvbHashtreeDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->partition_name_len) ||
      !avb_safe_add_to(&expected_size, dest->salt_len) ||
      !avb_safe_add_to(&expected_size, dest->root_digest_len)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }
  return true;
}

```

`aosp/libavb1.1/src/avb/c/avb_kernel_cmdline_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_kernel_cmdline_descriptor.h"
#include "avb_util.h"

bool avb_kernel_cmdline_descriptor_validate_and_byteswap(
    const AvbKernelCmdlineDescriptor* src, AvbKernelCmdlineDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbKernelCmdlineDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE) {
    avb_error("Invalid tag for kernel cmdline descriptor.\n");
    return false;
  }

  dest->flags = avb_be32toh(dest->flags);
  dest->kernel_cmdline_length = avb_be32toh(dest->kernel_cmdline_length);

  /* Check that kernel_cmdline is fully contained. */
  expected_size = sizeof(AvbKernelCmdlineDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->kernel_cmdline_length)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }

  return true;
}

```

`aosp/libavb1.1/src/avb/c/avb_property_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_property_descriptor.h"
#include "avb_util.h"

bool avb_property_descriptor_validate_and_byteswap(
    const AvbPropertyDescriptor* src, AvbPropertyDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbPropertyDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_PROPERTY) {
    avb_error("Invalid tag for property descriptor.\n");
    return false;
  }

  dest->key_num_bytes = avb_be64toh(dest->key_num_bytes);
  dest->value_num_bytes = avb_be64toh(dest->value_num_bytes);

  /* Check that key and value are fully contained. */
  expected_size = sizeof(AvbPropertyDescriptor) - sizeof(AvbDescriptor) + 2;
  if (!avb_safe_add_to(&expected_size, dest->key_num_bytes) ||
      !avb_safe_add_to(&expected_size, dest->value_num_bytes)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }

  return true;
}

typedef struct {
  const char* key;
  size_t key_size;
  const char* ret_value;
  size_t ret_value_size;
} PropertyIteratorData;

static bool property_lookup_desc_foreach(const AvbDescriptor* header,
                                         void* user_data) {
  PropertyIteratorData* data = (PropertyIteratorData*)user_data;
  AvbPropertyDescriptor prop_desc;
  const uint8_t* p;
  bool ret = true;

  if (header->tag != AVB_DESCRIPTOR_TAG_PROPERTY) {
    goto out;
  }

  if (!avb_property_descriptor_validate_and_byteswap(
          (const AvbPropertyDescriptor*)header, &prop_desc)) {
    goto out;
  }

  p = (const uint8_t*)header;
  if (p[sizeof(AvbPropertyDescriptor) + prop_desc.key_num_bytes] != 0) {
    avb_error("No terminating NUL byte in key.\n");
    goto out;
  }

  if (data->key_size == prop_desc.key_num_bytes) {
    if (avb_memcmp(p + sizeof(AvbPropertyDescriptor),
                   data->key,
                   data->key_size) == 0) {
      data->ret_value = (const char*)(p + sizeof(AvbPropertyDescriptor) +
                                      prop_desc.key_num_bytes + 1);
      data->ret_value_size = prop_desc.value_num_bytes;
      /* Stop iterating. */
      ret = false;
      goto out;
    }
  }

out:
  return ret;
}

const char* avb_property_lookup(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                size_t* out_value_size) {
  PropertyIteratorData data;

  if (key_size == 0) {
    key_size = avb_strlen(key);
  }

  data.key = key;
  data.key_size = key_size;

  if (avb_descriptor_foreach(
          image_data, image_size, property_lookup_desc_foreach, &data) == 0) {
    if (out_value_size != NULL) {
      *out_value_size = data.ret_value_size;
    }
    return data.ret_value;
  }

  if (out_value_size != NULL) {
    *out_value_size = 0;
  }
  return NULL;
}

bool avb_property_lookup_uint64(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                uint64_t* out_value) {
  const char* value;
  bool ret = false;
  uint64_t parsed_val;
  int base;
  int n;

  value = avb_property_lookup(image_data, image_size, key, key_size, NULL);
  if (value == NULL) {
    goto out;
  }

  base = 10;
  if (avb_memcmp(value, "0x", 2) == 0) {
    base = 16;
    value += 2;
  }

  parsed_val = 0;
  for (n = 0; value[n] != '\0'; n++) {
    int c = value[n];
    int digit;

    parsed_val *= base;

    if (c >= '0' && c <= '9') {
      digit = c - '0';
    } else if (base == 16 && c >= 'a' && c <= 'f') {
      digit = c - 'a' + 10;
    } else if (base == 16 && c >= 'A' && c <= 'F') {
      digit = c - 'A' + 10;
    } else {
      avb_error("Invalid digit.\n");
      goto out;
    }

    parsed_val += digit;
  }

  ret = true;
  if (out_value != NULL) {
    *out_value = parsed_val;
  }

out:
  return ret;
}

```

`aosp/libavb1.1/src/avb/c/avb_rsa.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

/* Copyright (c) 2011 The Chromium OS Authors. All rights reserved.
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

/* Implementation of RSA signature verification which uses a pre-processed
 * key for computation. The code extends libmincrypt RSA verification code to
 * support multiple RSA key lengths and hash digest algorithms.
 */

#include "avb_rsa.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"

typedef struct IAvbKey {
  unsigned int len; /* Length of n[] in number of uint32_t */
  uint32_t n0inv;   /* -1 / n[0] mod 2^32 */
  uint32_t* n;      /* modulus as array (host-byte order) */
  uint32_t* rr;     /* R^2 as array (host-byte order) */
} IAvbKey;

static IAvbKey* iavb_parse_key_data(const uint8_t* data, size_t length) {
  AvbRSAPublicKeyHeader h;
  IAvbKey* key = NULL;
  size_t expected_length;
  unsigned int i;
  const uint8_t* n;
  const uint8_t* rr;

  if (!avb_rsa_public_key_header_validate_and_byteswap(
          (const AvbRSAPublicKeyHeader*)data, &h)) {
    avb_error("Invalid key.\n");
    goto fail;
  }

  if (!(h.key_num_bits == 2048 || h.key_num_bits == 4096 ||
        h.key_num_bits == 8192)) {
    avb_error("Unexpected key length.\n");
    goto fail;
  }

  expected_length = sizeof(AvbRSAPublicKeyHeader) + 2 * h.key_num_bits / 8;
  if (length != expected_length) {
    avb_error("Key does not match expected length.\n");
    goto fail;
  }

  n = data + sizeof(AvbRSAPublicKeyHeader);
  rr = data + sizeof(AvbRSAPublicKeyHeader) + h.key_num_bits / 8;

  /* Store n and rr following the key header so we only have to do one
   * allocation.
   */
  key = (IAvbKey*)(avb_malloc(sizeof(IAvbKey) + 2 * h.key_num_bits / 8));
  if (key == NULL) {
    goto fail;
  }

  key->len = h.key_num_bits / 32;
  key->n0inv = h.n0inv;
  key->n = (uint32_t*)(key + 1); /* Skip ahead sizeof(IAvbKey) bytes. */
  key->rr = key->n + key->len;

  /* Crypto-code below (modpowF4() and friends) expects the key in
   * little-endian format (rather than the format we're storing the
   * key in), so convert it.
   */
  for (i = 0; i < key->len; i++) {
    key->n[i] = avb_be32toh(((uint32_t*)n)[key->len - i - 1]);
    key->rr[i] = avb_be32toh(((uint32_t*)rr)[key->len - i - 1]);
  }
  return key;

fail:
  if (key != NULL) {
    avb_free(key);
  }
  return NULL;
}

static void iavb_free_parsed_key(IAvbKey* key) {
  avb_free(key);
}

/* a[] -= mod */
static void subM(const IAvbKey* key, uint32_t* a) {
  int64_t A = 0;
  uint32_t i;
  for (i = 0; i < key->len; ++i) {
    A += (uint64_t)a[i] - key->n[i];
    a[i] = (uint32_t)A;
    A >>= 32;
  }
}

/* return a[] >= mod */
static int geM(const IAvbKey* key, uint32_t* a) {
  uint32_t i;
  for (i = key->len; i;) {
    --i;
    if (a[i] < key->n[i]) {
      return 0;
    }
    if (a[i] > key->n[i]) {
      return 1;
    }
  }
  return 1; /* equal */
}

/* montgomery c[] += a * b[] / R % mod */
static void montMulAdd(const IAvbKey* key,
                       uint32_t* c,
                       const uint32_t a,
                       const uint32_t* b) {
  uint64_t A = (uint64_t)a * b[0] + c[0];
  uint32_t d0 = (uint32_t)A * key->n0inv;
  uint64_t B = (uint64_t)d0 * key->n[0] + (uint32_t)A;
  uint32_t i;

  for (i = 1; i < key->len; ++i) {
    A = (A >> 32) + (uint64_t)a * b[i] + c[i];
    B = (B >> 32) + (uint64_t)d0 * key->n[i] + (uint32_t)A;
    c[i - 1] = (uint32_t)B;
  }

  A = (A >> 32) + (B >> 32);

  c[i - 1] = (uint32_t)A;

  if (A >> 32) {
    subM(key, c);
  }
}

/* montgomery c[] = a[] * b[] / R % mod */
static void montMul(const IAvbKey* key, uint32_t* c, uint32_t* a, uint32_t* b) {
  uint32_t i;
  for (i = 0; i < key->len; ++i) {
    c[i] = 0;
  }
  for (i = 0; i < key->len; ++i) {
    montMulAdd(key, c, a[i], b);
  }
}

/* In-place public exponentiation. (65537}
 * Input and output big-endian byte array in inout.
 */
static void modpowF4(const IAvbKey* key, uint8_t* inout) {
  uint32_t* a = (uint32_t*)avb_malloc(key->len * sizeof(uint32_t));
  uint32_t* aR = (uint32_t*)avb_malloc(key->len * sizeof(uint32_t));
  uint32_t* aaR = (uint32_t*)avb_malloc(key->len * sizeof(uint32_t));
  if (a == NULL || aR == NULL || aaR == NULL) {
    goto out;
  }

  uint32_t* aaa = aaR; /* Re-use location. */
  int i;

  /* Convert from big endian byte array to little endian word array. */
  for (i = 0; i < (int)key->len; ++i) {
    uint32_t tmp = (inout[((key->len - 1 - i) * 4) + 0] << 24) |
                   (inout[((key->len - 1 - i) * 4) + 1] << 16) |
                   (inout[((key->len - 1 - i) * 4) + 2] << 8) |
                   (inout[((key->len - 1 - i) * 4) + 3] << 0);
    a[i] = tmp;
  }

  montMul(key, aR, a, key->rr); /* aR = a * RR / R mod M   */
  for (i = 0; i < 16; i += 2) {
    montMul(key, aaR, aR, aR);  /* aaR = aR * aR / R mod M */
    montMul(key, aR, aaR, aaR); /* aR = aaR * aaR / R mod M */
  }
  montMul(key, aaa, aR, a); /* aaa = aR * a / R mod M */

  /* Make sure aaa < mod; aaa is at most 1x mod too large. */
  if (geM(key, aaa)) {
    subM(key, aaa);
  }

  /* Convert to bigendian byte array */
  for (i = (int)key->len - 1; i >= 0; --i) {
    uint32_t tmp = aaa[i];
    *inout++ = (uint8_t)(tmp >> 24);
    *inout++ = (uint8_t)(tmp >> 16);
    *inout++ = (uint8_t)(tmp >> 8);
    *inout++ = (uint8_t)(tmp >> 0);
  }

out:
  if (a != NULL) {
    avb_free(a);
  }
  if (aR != NULL) {
    avb_free(aR);
  }
  if (aaR != NULL) {
    avb_free(aaR);
  }
}

/* Verify a RSA PKCS1.5 signature against an expected hash.
 * Returns false on failure, true on success.
 */
bool avb_rsa_verify(const uint8_t* key,
                    size_t key_num_bytes,
                    const uint8_t* sig,
                    size_t sig_num_bytes,
                    const uint8_t* hash,
                    size_t hash_num_bytes,
                    const uint8_t* padding,
                    size_t padding_num_bytes) {
  uint8_t* buf = NULL;
  IAvbKey* parsed_key = NULL;
  bool success = false;

  if (key == NULL || sig == NULL || hash == NULL || padding == NULL) {
    avb_error("Invalid input.\n");
    goto out;
  }

  parsed_key = iavb_parse_key_data(key, key_num_bytes);
  if (parsed_key == NULL) {
    avb_error("Error parsing key.\n");
    goto out;
  }

  if (sig_num_bytes != (parsed_key->len * sizeof(uint32_t))) {
    avb_error("Signature length does not match key length.\n");
    goto out;
  }

  if (padding_num_bytes != sig_num_bytes - hash_num_bytes) {
    avb_error("Padding length does not match hash and signature lengths.\n");
    goto out;
  }

  buf = (uint8_t*)avb_malloc(sig_num_bytes);
  if (buf == NULL) {
    avb_error("Error allocating memory.\n");
    goto out;
  }
  avb_memcpy(buf, sig, sig_num_bytes);

  modpowF4(parsed_key, buf);

  /* Check padding bytes.
   *
   * Even though there are probably no timing issues here, we use
   * avb_safe_memcmp() just to be on the safe side.
   */
  if (avb_safe_memcmp(buf, padding, padding_num_bytes)) {
    avb_error("Padding check failed.\n");
    goto out;
  }

  /* Check hash. */
  if (avb_safe_memcmp(buf + padding_num_bytes, hash, hash_num_bytes)) {
    avb_error("Hash check failed.\n");
    goto out;
  }

  success = true;

out:
  if (parsed_key != NULL) {
    iavb_free_parsed_key(parsed_key);
  }
  if (buf != NULL) {
    avb_free(buf);
  }
  return success;
}

```

`aosp/libavb1.1/src/avb/c/avb_sha256.c`:

```c
/* SHA-256 and SHA-512 implementation based on code by Oliver Gay
 * <olivier.gay@a3.epfl.ch> under a BSD-style license. See below.
 */

/*
 * FIPS 180-2 SHA-224/256/384/512 implementation
 * Last update: 02/02/2007
 * Issue date:  04/30/2005
 *
 * Copyright (C) 2005, 2007 Olivier Gay <olivier.gay@a3.epfl.ch>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the project nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

#include "avb_sha.h"

#define SHFR(x, n) (x >> n)
#define ROTR(x, n) ((x >> n) | (x << ((sizeof(x) << 3) - n)))
#define ROTL(x, n) ((x << n) | (x >> ((sizeof(x) << 3) - n)))
#define CH(x, y, z) ((x & y) ^ (~x & z))
#define MAJ(x, y, z) ((x & y) ^ (x & z) ^ (y & z))

#define SHA256_F1(x) (ROTR(x, 2) ^ ROTR(x, 13) ^ ROTR(x, 22))
#define SHA256_F2(x) (ROTR(x, 6) ^ ROTR(x, 11) ^ ROTR(x, 25))
#define SHA256_F3(x) (ROTR(x, 7) ^ ROTR(x, 18) ^ SHFR(x, 3))
#define SHA256_F4(x) (ROTR(x, 17) ^ ROTR(x, 19) ^ SHFR(x, 10))

#define UNPACK32(x, str)                 \
  {                                      \
    *((str) + 3) = (uint8_t)((x));       \
    *((str) + 2) = (uint8_t)((x) >> 8);  \
    *((str) + 1) = (uint8_t)((x) >> 16); \
    *((str) + 0) = (uint8_t)((x) >> 24); \
  }

#define UNPACK64(x, str)                         \
  {                                              \
    *((str) + 7) = (uint8_t)x;                   \
    *((str) + 6) = (uint8_t)((uint64_t)x >> 8);  \
    *((str) + 5) = (uint8_t)((uint64_t)x >> 16); \
    *((str) + 4) = (uint8_t)((uint64_t)x >> 24); \
    *((str) + 3) = (uint8_t)((uint64_t)x >> 32); \
    *((str) + 2) = (uint8_t)((uint64_t)x >> 40); \
    *((str) + 1) = (uint8_t)((uint64_t)x >> 48); \
    *((str) + 0) = (uint8_t)((uint64_t)x >> 56); \
  }

#define PACK32(str, x)                                                    \
  {                                                                       \
    *(x) = ((uint32_t) * ((str) + 3)) | ((uint32_t) * ((str) + 2) << 8) | \
           ((uint32_t) * ((str) + 1) << 16) |                             \
           ((uint32_t) * ((str) + 0) << 24);                              \
  }

/* Macros used for loops unrolling */

#define SHA256_SCR(i) \
  { w[i] = SHA256_F4(w[i - 2]) + w[i - 7] + SHA256_F3(w[i - 15]) + w[i - 16]; }

#define SHA256_EXP(a, b, c, d, e, f, g, h, j)                               \
  {                                                                         \
    t1 = wv[h] + SHA256_F2(wv[e]) + CH(wv[e], wv[f], wv[g]) + sha256_k[j] + \
         w[j];                                                              \
    t2 = SHA256_F1(wv[a]) + MAJ(wv[a], wv[b], wv[c]);                       \
    wv[d] += t1;                                                            \
    wv[h] = t1 + t2;                                                        \
  }

static const uint32_t sha256_h0[8] = {0x6a09e667,
                                      0xbb67ae85,
                                      0x3c6ef372,
                                      0xa54ff53a,
                                      0x510e527f,
                                      0x9b05688c,
                                      0x1f83d9ab,
                                      0x5be0cd19};

static const uint32_t sha256_k[64] = {
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1,
    0x923f82a4, 0xab1c5ed5, 0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174, 0xe49b69c1, 0xefbe4786,
    0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147,
    0x06ca6351, 0x14292967, 0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85, 0xa2bfe8a1, 0xa81a664b,
    0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a,
    0x5b9cca4f, 0x682e6ff3, 0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2};

/* SHA-256 implementation */
void avb_sha256_init(AvbSHA256Ctx* ctx) {
#ifndef UNROLL_LOOPS
  int i;
  for (i = 0; i < 8; i++) {
    ctx->h[i] = sha256_h0[i];
  }
#else
  ctx->h[0] = sha256_h0[0];
  ctx->h[1] = sha256_h0[1];
  ctx->h[2] = sha256_h0[2];
  ctx->h[3] = sha256_h0[3];
  ctx->h[4] = sha256_h0[4];
  ctx->h[5] = sha256_h0[5];
  ctx->h[6] = sha256_h0[6];
  ctx->h[7] = sha256_h0[7];
#endif /* !UNROLL_LOOPS */

  ctx->len = 0;
  ctx->tot_len = 0;
}

static void SHA256_transform(AvbSHA256Ctx* ctx,
                             const uint8_t* message,
                             size_t block_nb) {
  uint32_t w[64];
  uint32_t wv[8];
  uint32_t t1, t2;
  const unsigned char* sub_block;
  size_t i;

#ifndef UNROLL_LOOPS
  size_t j;
#endif

  for (i = 0; i < block_nb; i++) {
    sub_block = message + (i << 6);

#ifndef UNROLL_LOOPS
    for (j = 0; j < 16; j++) {
      PACK32(&sub_block[j << 2], &w[j]);
    }

    for (j = 16; j < 64; j++) {
      SHA256_SCR(j);
    }

    for (j = 0; j < 8; j++) {
      wv[j] = ctx->h[j];
    }

    for (j = 0; j < 64; j++) {
      t1 = wv[7] + SHA256_F2(wv[4]) + CH(wv[4], wv[5], wv[6]) + sha256_k[j] +
           w[j];
      t2 = SHA256_F1(wv[0]) + MAJ(wv[0], wv[1], wv[2]);
      wv[7] = wv[6];
      wv[6] = wv[5];
      wv[5] = wv[4];
      wv[4] = wv[3] + t1;
      wv[3] = wv[2];
      wv[2] = wv[1];
      wv[1] = wv[0];
      wv[0] = t1 + t2;
    }

    for (j = 0; j < 8; j++) {
      ctx->h[j] += wv[j];
    }
#else
    PACK32(&sub_block[0], &w[0]);
    PACK32(&sub_block[4], &w[1]);
    PACK32(&sub_block[8], &w[2]);
    PACK32(&sub_block[12], &w[3]);
    PACK32(&sub_block[16], &w[4]);
    PACK32(&sub_block[20], &w[5]);
    PACK32(&sub_block[24], &w[6]);
    PACK32(&sub_block[28], &w[7]);
    PACK32(&sub_block[32], &w[8]);
    PACK32(&sub_block[36], &w[9]);
    PACK32(&sub_block[40], &w[10]);
    PACK32(&sub_block[44], &w[11]);
    PACK32(&sub_block[48], &w[12]);
    PACK32(&sub_block[52], &w[13]);
    PACK32(&sub_block[56], &w[14]);
    PACK32(&sub_block[60], &w[15]);

    SHA256_SCR(16);
    SHA256_SCR(17);
    SHA256_SCR(18);
    SHA256_SCR(19);
    SHA256_SCR(20);
    SHA256_SCR(21);
    SHA256_SCR(22);
    SHA256_SCR(23);
    SHA256_SCR(24);
    SHA256_SCR(25);
    SHA256_SCR(26);
    SHA256_SCR(27);
    SHA256_SCR(28);
    SHA256_SCR(29);
    SHA256_SCR(30);
    SHA256_SCR(31);
    SHA256_SCR(32);
    SHA256_SCR(33);
    SHA256_SCR(34);
    SHA256_SCR(35);
    SHA256_SCR(36);
    SHA256_SCR(37);
    SHA256_SCR(38);
    SHA256_SCR(39);
    SHA256_SCR(40);
    SHA256_SCR(41);
    SHA256_SCR(42);
    SHA256_SCR(43);
    SHA256_SCR(44);
    SHA256_SCR(45);
    SHA256_SCR(46);
    SHA256_SCR(47);
    SHA256_SCR(48);
    SHA256_SCR(49);
    SHA256_SCR(50);
    SHA256_SCR(51);
    SHA256_SCR(52);
    SHA256_SCR(53);
    SHA256_SCR(54);
    SHA256_SCR(55);
    SHA256_SCR(56);
    SHA256_SCR(57);
    SHA256_SCR(58);
    SHA256_SCR(59);
    SHA256_SCR(60);
    SHA256_SCR(61);
    SHA256_SCR(62);
    SHA256_SCR(63);

    wv[0] = ctx->h[0];
    wv[1] = ctx->h[1];
    wv[2] = ctx->h[2];
    wv[3] = ctx->h[3];
    wv[4] = ctx->h[4];
    wv[5] = ctx->h[5];
    wv[6] = ctx->h[6];
    wv[7] = ctx->h[7];

    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 0);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 1);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 2);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 3);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 4);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 5);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 6);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 7);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 8);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 9);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 10);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 11);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 12);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 13);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 14);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 15);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 16);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 17);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 18);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 19);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 20);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 21);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 22);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 23);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 24);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 25);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 26);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 27);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 28);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 29);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 30);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 31);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 32);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 33);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 34);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 35);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 36);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 37);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 38);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 39);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 40);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 41);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 42);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 43);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 44);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 45);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 46);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 47);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 48);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 49);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 50);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 51);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 52);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 53);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 54);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 55);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 56);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 57);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 58);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 59);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 60);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 61);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 62);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 63);

    ctx->h[0] += wv[0];
    ctx->h[1] += wv[1];
    ctx->h[2] += wv[2];
    ctx->h[3] += wv[3];
    ctx->h[4] += wv[4];
    ctx->h[5] += wv[5];
    ctx->h[6] += wv[6];
    ctx->h[7] += wv[7];
#endif /* !UNROLL_LOOPS */
  }
}

void avb_sha256_update(AvbSHA256Ctx* ctx, const uint8_t* data, size_t len) {
  size_t block_nb;
  size_t new_len, rem_len, tmp_len;
  const uint8_t* shifted_data;

  tmp_len = AVB_SHA256_BLOCK_SIZE - ctx->len;
  rem_len = len < tmp_len ? len : tmp_len;

  avb_memcpy(&ctx->block[ctx->len], data, rem_len);

  if (ctx->len + len < AVB_SHA256_BLOCK_SIZE) {
    ctx->len += len;
    return;
  }

  new_len = len - rem_len;
  block_nb = new_len / AVB_SHA256_BLOCK_SIZE;

  shifted_data = data + rem_len;

  SHA256_transform(ctx, ctx->block, 1);
  SHA256_transform(ctx, shifted_data, block_nb);

  rem_len = new_len % AVB_SHA256_BLOCK_SIZE;

  avb_memcpy(ctx->block, &shifted_data[block_nb << 6], rem_len);

  ctx->len = rem_len;
  ctx->tot_len += (block_nb + 1) << 6;
}

uint8_t* avb_sha256_final(AvbSHA256Ctx* ctx) {
  size_t block_nb;
  size_t pm_len;
  uint64_t len_b;
#ifndef UNROLL_LOOPS
  size_t i;
#endif

  block_nb =
      (1 + ((AVB_SHA256_BLOCK_SIZE - 9) < (ctx->len % AVB_SHA256_BLOCK_SIZE)));

  len_b = (ctx->tot_len + ctx->len) << 3;
  pm_len = block_nb << 6;

  avb_memset(ctx->block + ctx->len, 0, pm_len - ctx->len);
  ctx->block[ctx->len] = 0x80;
  UNPACK64(len_b, ctx->block + pm_len - 8);

  SHA256_transform(ctx, ctx->block, block_nb);

#ifndef UNROLL_LOOPS
  for (i = 0; i < 8; i++) {
    UNPACK32(ctx->h[i], &ctx->buf[i << 2]);
  }
#else
  UNPACK32(ctx->h[0], &ctx->buf[0]);
  UNPACK32(ctx->h[1], &ctx->buf[4]);
  UNPACK32(ctx->h[2], &ctx->buf[8]);
  UNPACK32(ctx->h[3], &ctx->buf[12]);
  UNPACK32(ctx->h[4], &ctx->buf[16]);
  UNPACK32(ctx->h[5], &ctx->buf[20]);
  UNPACK32(ctx->h[6], &ctx->buf[24]);
  UNPACK32(ctx->h[7], &ctx->buf[28]);
#endif /* !UNROLL_LOOPS */

  return ctx->buf;
}

```

`aosp/libavb1.1/src/avb/c/avb_sha512.c`:

```c
/* SHA-256 and SHA-512 implementation based on code by Oliver Gay
 * <olivier.gay@a3.epfl.ch> under a BSD-style license. See below.
 */

/*
 * FIPS 180-2 SHA-224/256/384/512 implementation
 * Last update: 02/02/2007
 * Issue date:  04/30/2005
 *
 * Copyright (C) 2005, 2007 Olivier Gay <olivier.gay@a3.epfl.ch>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the project nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

#include "avb_sha.h"

#define SHFR(x, n) (x >> n)
#define ROTR(x, n) ((x >> n) | (x << ((sizeof(x) << 3) - n)))
#define ROTL(x, n) ((x << n) | (x >> ((sizeof(x) << 3) - n)))
#define CH(x, y, z) ((x & y) ^ (~x & z))
#define MAJ(x, y, z) ((x & y) ^ (x & z) ^ (y & z))

#define SHA512_F1(x) (ROTR(x, 28) ^ ROTR(x, 34) ^ ROTR(x, 39))
#define SHA512_F2(x) (ROTR(x, 14) ^ ROTR(x, 18) ^ ROTR(x, 41))
#define SHA512_F3(x) (ROTR(x, 1) ^ ROTR(x, 8) ^ SHFR(x, 7))
#define SHA512_F4(x) (ROTR(x, 19) ^ ROTR(x, 61) ^ SHFR(x, 6))

#define UNPACK32(x, str)                 \
  {                                      \
    *((str) + 3) = (uint8_t)((x));       \
    *((str) + 2) = (uint8_t)((x) >> 8);  \
    *((str) + 1) = (uint8_t)((x) >> 16); \
    *((str) + 0) = (uint8_t)((x) >> 24); \
  }

#define UNPACK64(x, str)                         \
  {                                              \
    *((str) + 7) = (uint8_t)x;                   \
    *((str) + 6) = (uint8_t)((uint64_t)x >> 8);  \
    *((str) + 5) = (uint8_t)((uint64_t)x >> 16); \
    *((str) + 4) = (uint8_t)((uint64_t)x >> 24); \
    *((str) + 3) = (uint8_t)((uint64_t)x >> 32); \
    *((str) + 2) = (uint8_t)((uint64_t)x >> 40); \
    *((str) + 1) = (uint8_t)((uint64_t)x >> 48); \
    *((str) + 0) = (uint8_t)((uint64_t)x >> 56); \
  }

#define PACK64(str, x)                                                        \
  {                                                                           \
    *(x) =                                                                    \
        ((uint64_t) * ((str) + 7)) | ((uint64_t) * ((str) + 6) << 8) |        \
        ((uint64_t) * ((str) + 5) << 16) | ((uint64_t) * ((str) + 4) << 24) | \
        ((uint64_t) * ((str) + 3) << 32) | ((uint64_t) * ((str) + 2) << 40) | \
        ((uint64_t) * ((str) + 1) << 48) | ((uint64_t) * ((str) + 0) << 56);  \
  }

/* Macros used for loops unrolling */

#define SHA512_SCR(i) \
  { w[i] = SHA512_F4(w[i - 2]) + w[i - 7] + SHA512_F3(w[i - 15]) + w[i - 16]; }

#define SHA512_EXP(a, b, c, d, e, f, g, h, j)                               \
  {                                                                         \
    t1 = wv[h] + SHA512_F2(wv[e]) + CH(wv[e], wv[f], wv[g]) + sha512_k[j] + \
         w[j];                                                              \
    t2 = SHA512_F1(wv[a]) + MAJ(wv[a], wv[b], wv[c]);                       \
    wv[d] += t1;                                                            \
    wv[h] = t1 + t2;                                                        \
  }

static const uint64_t sha512_h0[8] = {0x6a09e667f3bcc908ULL,
                                      0xbb67ae8584caa73bULL,
                                      0x3c6ef372fe94f82bULL,
                                      0xa54ff53a5f1d36f1ULL,
                                      0x510e527fade682d1ULL,
                                      0x9b05688c2b3e6c1fULL,
                                      0x1f83d9abfb41bd6bULL,
                                      0x5be0cd19137e2179ULL};

static const uint64_t sha512_k[80] = {
    0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL, 0xb5c0fbcfec4d3b2fULL,
    0xe9b5dba58189dbbcULL, 0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,
    0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL, 0xd807aa98a3030242ULL,
    0x12835b0145706fbeULL, 0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,
    0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL, 0x9bdc06a725c71235ULL,
    0xc19bf174cf692694ULL, 0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,
    0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL, 0x2de92c6f592b0275ULL,
    0x4a7484aa6ea6e483ULL, 0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,
    0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL, 0xb00327c898fb213fULL,
    0xbf597fc7beef0ee4ULL, 0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,
    0x06ca6351e003826fULL, 0x142929670a0e6e70ULL, 0x27b70a8546d22ffcULL,
    0x2e1b21385c26c926ULL, 0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,
    0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL, 0x81c2c92e47edaee6ULL,
    0x92722c851482353bULL, 0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,
    0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL, 0xd192e819d6ef5218ULL,
    0xd69906245565a910ULL, 0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,
    0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL, 0x2748774cdf8eeb99ULL,
    0x34b0bcb5e19b48a8ULL, 0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,
    0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL, 0x748f82ee5defb2fcULL,
    0x78a5636f43172f60ULL, 0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,
    0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL, 0xbef9a3f7b2c67915ULL,
    0xc67178f2e372532bULL, 0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,
    0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL, 0x06f067aa72176fbaULL,
    0x0a637dc5a2c898a6ULL, 0x113f9804bef90daeULL, 0x1b710b35131c471bULL,
    0x28db77f523047d84ULL, 0x32caab7b40c72493ULL, 0x3c9ebe0a15c9bebcULL,
    0x431d67c49c100d4cULL, 0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,
    0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL};

/* SHA-512 implementation */

void avb_sha512_init(AvbSHA512Ctx* ctx) {
#ifdef UNROLL_LOOPS_SHA512
  ctx->h[0] = sha512_h0[0];
  ctx->h[1] = sha512_h0[1];
  ctx->h[2] = sha512_h0[2];
  ctx->h[3] = sha512_h0[3];
  ctx->h[4] = sha512_h0[4];
  ctx->h[5] = sha512_h0[5];
  ctx->h[6] = sha512_h0[6];
  ctx->h[7] = sha512_h0[7];
#else
  int i;

  for (i = 0; i < 8; i++)
    ctx->h[i] = sha512_h0[i];
#endif /* UNROLL_LOOPS_SHA512 */

  ctx->len = 0;
  ctx->tot_len = 0;
}

static void SHA512_transform(AvbSHA512Ctx* ctx,
                             const uint8_t* message,
                             size_t block_nb) {
  uint64_t w[80];
  uint64_t wv[8];
  uint64_t t1, t2;
  const uint8_t* sub_block;
  size_t i, j;

  for (i = 0; i < block_nb; i++) {
    sub_block = message + (i << 7);

#ifdef UNROLL_LOOPS_SHA512
    PACK64(&sub_block[0], &w[0]);
    PACK64(&sub_block[8], &w[1]);
    PACK64(&sub_block[16], &w[2]);
    PACK64(&sub_block[24], &w[3]);
    PACK64(&sub_block[32], &w[4]);
    PACK64(&sub_block[40], &w[5]);
    PACK64(&sub_block[48], &w[6]);
    PACK64(&sub_block[56], &w[7]);
    PACK64(&sub_block[64], &w[8]);
    PACK64(&sub_block[72], &w[9]);
    PACK64(&sub_block[80], &w[10]);
    PACK64(&sub_block[88], &w[11]);
    PACK64(&sub_block[96], &w[12]);
    PACK64(&sub_block[104], &w[13]);
    PACK64(&sub_block[112], &w[14]);
    PACK64(&sub_block[120], &w[15]);

    SHA512_SCR(16);
    SHA512_SCR(17);
    SHA512_SCR(18);
    SHA512_SCR(19);
    SHA512_SCR(20);
    SHA512_SCR(21);
    SHA512_SCR(22);
    SHA512_SCR(23);
    SHA512_SCR(24);
    SHA512_SCR(25);
    SHA512_SCR(26);
    SHA512_SCR(27);
    SHA512_SCR(28);
    SHA512_SCR(29);
    SHA512_SCR(30);
    SHA512_SCR(31);
    SHA512_SCR(32);
    SHA512_SCR(33);
    SHA512_SCR(34);
    SHA512_SCR(35);
    SHA512_SCR(36);
    SHA512_SCR(37);
    SHA512_SCR(38);
    SHA512_SCR(39);
    SHA512_SCR(40);
    SHA512_SCR(41);
    SHA512_SCR(42);
    SHA512_SCR(43);
    SHA512_SCR(44);
    SHA512_SCR(45);
    SHA512_SCR(46);
    SHA512_SCR(47);
    SHA512_SCR(48);
    SHA512_SCR(49);
    SHA512_SCR(50);
    SHA512_SCR(51);
    SHA512_SCR(52);
    SHA512_SCR(53);
    SHA512_SCR(54);
    SHA512_SCR(55);
    SHA512_SCR(56);
    SHA512_SCR(57);
    SHA512_SCR(58);
    SHA512_SCR(59);
    SHA512_SCR(60);
    SHA512_SCR(61);
    SHA512_SCR(62);
    SHA512_SCR(63);
    SHA512_SCR(64);
    SHA512_SCR(65);
    SHA512_SCR(66);
    SHA512_SCR(67);
    SHA512_SCR(68);
    SHA512_SCR(69);
    SHA512_SCR(70);
    SHA512_SCR(71);
    SHA512_SCR(72);
    SHA512_SCR(73);
    SHA512_SCR(74);
    SHA512_SCR(75);
    SHA512_SCR(76);
    SHA512_SCR(77);
    SHA512_SCR(78);
    SHA512_SCR(79);

    wv[0] = ctx->h[0];
    wv[1] = ctx->h[1];
    wv[2] = ctx->h[2];
    wv[3] = ctx->h[3];
    wv[4] = ctx->h[4];
    wv[5] = ctx->h[5];
    wv[6] = ctx->h[6];
    wv[7] = ctx->h[7];

    j = 0;

    do {
      SHA512_EXP(0, 1, 2, 3, 4, 5, 6, 7, j);
      j++;
      SHA512_EXP(7, 0, 1, 2, 3, 4, 5, 6, j);
      j++;
      SHA512_EXP(6, 7, 0, 1, 2, 3, 4, 5, j);
      j++;
      SHA512_EXP(5, 6, 7, 0, 1, 2, 3, 4, j);
      j++;
      SHA512_EXP(4, 5, 6, 7, 0, 1, 2, 3, j);
      j++;
      SHA512_EXP(3, 4, 5, 6, 7, 0, 1, 2, j);
      j++;
      SHA512_EXP(2, 3, 4, 5, 6, 7, 0, 1, j);
      j++;
      SHA512_EXP(1, 2, 3, 4, 5, 6, 7, 0, j);
      j++;
    } while (j < 80);

    ctx->h[0] += wv[0];
    ctx->h[1] += wv[1];
    ctx->h[2] += wv[2];
    ctx->h[3] += wv[3];
    ctx->h[4] += wv[4];
    ctx->h[5] += wv[5];
    ctx->h[6] += wv[6];
    ctx->h[7] += wv[7];
#else
    for (j = 0; j < 16; j++) {
      PACK64(&sub_block[j << 3], &w[j]);
    }

    for (j = 16; j < 80; j++) {
      SHA512_SCR(j);
    }

    for (j = 0; j < 8; j++) {
      wv[j] = ctx->h[j];
    }

    for (j = 0; j < 80; j++) {
      t1 = wv[7] + SHA512_F2(wv[4]) + CH(wv[4], wv[5], wv[6]) + sha512_k[j] +
           w[j];
      t2 = SHA512_F1(wv[0]) + MAJ(wv[0], wv[1], wv[2]);
      wv[7] = wv[6];
      wv[6] = wv[5];
      wv[5] = wv[4];
      wv[4] = wv[3] + t1;
      wv[3] = wv[2];
      wv[2] = wv[1];
      wv[1] = wv[0];
      wv[0] = t1 + t2;
    }

    for (j = 0; j < 8; j++)
      ctx->h[j] += wv[j];
#endif /* UNROLL_LOOPS_SHA512 */
  }
}

void avb_sha512_update(AvbSHA512Ctx* ctx, const uint8_t* data, size_t len) {
  size_t block_nb;
  size_t new_len, rem_len, tmp_len;
  const uint8_t* shifted_data;

  tmp_len = AVB_SHA512_BLOCK_SIZE - ctx->len;
  rem_len = len < tmp_len ? len : tmp_len;

  avb_memcpy(&ctx->block[ctx->len], data, rem_len);

  if (ctx->len + len < AVB_SHA512_BLOCK_SIZE) {
    ctx->len += len;
    return;
  }

  new_len = len - rem_len;
  block_nb = new_len / AVB_SHA512_BLOCK_SIZE;

  shifted_data = data + rem_len;

  SHA512_transform(ctx, ctx->block, 1);
  SHA512_transform(ctx, shifted_data, block_nb);

  rem_len = new_len % AVB_SHA512_BLOCK_SIZE;

  avb_memcpy(ctx->block, &shifted_data[block_nb << 7], rem_len);

  ctx->len = rem_len;
  ctx->tot_len += (block_nb + 1) << 7;
}

uint8_t* avb_sha512_final(AvbSHA512Ctx* ctx) {
  size_t block_nb;
  size_t pm_len;
  uint64_t len_b;

#ifndef UNROLL_LOOPS_SHA512
  size_t i;
#endif

  block_nb =
      1 + ((AVB_SHA512_BLOCK_SIZE - 17) < (ctx->len % AVB_SHA512_BLOCK_SIZE));

  len_b = (ctx->tot_len + ctx->len) << 3;
  pm_len = block_nb << 7;

  avb_memset(ctx->block + ctx->len, 0, pm_len - ctx->len);
  ctx->block[ctx->len] = 0x80;
  UNPACK64(len_b, ctx->block + pm_len - 8);

  SHA512_transform(ctx, ctx->block, block_nb);

#ifdef UNROLL_LOOPS_SHA512
  UNPACK64(ctx->h[0], &ctx->buf[0]);
  UNPACK64(ctx->h[1], &ctx->buf[8]);
  UNPACK64(ctx->h[2], &ctx->buf[16]);
  UNPACK64(ctx->h[3], &ctx->buf[24]);
  UNPACK64(ctx->h[4], &ctx->buf[32]);
  UNPACK64(ctx->h[5], &ctx->buf[40]);
  UNPACK64(ctx->h[6], &ctx->buf[48]);
  UNPACK64(ctx->h[7], &ctx->buf[56]);
#else
  for (i = 0; i < 8; i++)
    UNPACK64(ctx->h[i], &ctx->buf[i << 3]);
#endif /* UNROLL_LOOPS_SHA512 */

  return ctx->buf;
}

```

`aosp/libavb1.1/src/avb/c/avb_slot_verify.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_slot_verify.h"
#include "avb_chain_partition_descriptor.h"
#include "avb_cmdline.h"
#include "avb_footer.h"
#include "avb_hash_descriptor.h"
#include "avb_hashtree_descriptor.h"
#include "avb_kernel_cmdline_descriptor.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"
#include "avb_version.h"

/* Maximum number of partitions that can be loaded with avb_slot_verify(). */
#define MAX_NUMBER_OF_LOADED_PARTITIONS 32

/* Maximum number of vbmeta images that can be loaded with avb_slot_verify(). */
#define MAX_NUMBER_OF_VBMETA_IMAGES 32

/* Maximum size of a vbmeta image - 64 KiB. */
#define VBMETA_MAX_SIZE (64 * 1024)

static AvbSlotVerifyResult initialize_persistent_digest(
    AvbOps* ops,
    const char* part_name,
    const char* persistent_value_name,
    size_t digest_size,
    const uint8_t* initial_digest,
    uint8_t* out_digest);

/* Helper function to see if we should continue with verification in
 * allow_verification_error=true mode if something goes wrong. See the
 * comments for the avb_slot_verify() function for more information.
 */
static inline bool result_should_continue(AvbSlotVerifyResult result) {
  switch (result) {
    case AVB_SLOT_VERIFY_RESULT_ERROR_OOM:
    case AVB_SLOT_VERIFY_RESULT_ERROR_IO:
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA:
    case AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION:
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT:
      return false;

    case AVB_SLOT_VERIFY_RESULT_OK:
    case AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION:
    case AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX:
    case AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED:
      return true;
  }

  return false;
}

static AvbSlotVerifyResult load_full_partition(AvbOps* ops,
                                               const char* part_name,
                                               uint64_t image_size,
                                               uint8_t** out_image_buf,
                                               bool* out_image_preloaded) {
  size_t part_num_read;
  AvbIOResult io_ret;

  /* Make sure that we do not overwrite existing data. */
  avb_assert(*out_image_buf == NULL);
  avb_assert(!*out_image_preloaded);

  /* We are going to implicitly cast image_size from uint64_t to size_t in the
   * following code, so we need to make sure that the cast is safe. */
  if (image_size != (size_t)(image_size)) {
    avb_errorv(part_name, ": Partition size too large to load.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }

  /* Try use a preloaded one. */
  if (ops->get_preloaded_partition != NULL) {
    io_ret = ops->get_preloaded_partition(
        ops, part_name, image_size, out_image_buf, &part_num_read);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error loading data from partition.\n", NULL);
      return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    }

    if (*out_image_buf != NULL) {
      if (part_num_read != image_size) {
        avb_errorv(part_name, ": Read incorrect number of bytes.\n", NULL);
        return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      }
      *out_image_preloaded = true;
    }
  }

  /* Allocate and copy the partition. */
  if (!*out_image_preloaded) {
    *out_image_buf = avb_malloc(image_size);
    if (*out_image_buf == NULL) {
      return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    }

    io_ret = ops->read_from_partition(ops,
                                      part_name,
                                      0 /* offset */,
                                      image_size,
                                      *out_image_buf,
                                      &part_num_read);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error loading data from partition.\n", NULL);
      return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    }
    if (part_num_read != image_size) {
      avb_errorv(part_name, ": Read incorrect number of bytes.\n", NULL);
      return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    }
  }

  return AVB_SLOT_VERIFY_RESULT_OK;
}

/* Reads a persistent digest stored as a named persistent value corresponding to
 * the given |part_name|. The value is returned in |out_digest| which must point
 * to |expected_digest_size| bytes. If there is no digest stored for |part_name|
 * it can be initialized by providing a non-NULL |initial_digest| of length
 * |expected_digest_size|. This automatic initialization will only occur if the
 * device is currently locked. The |initial_digest| may be NULL.
 *
 * Returns AVB_SLOT_VERIFY_RESULT_OK on success, otherwise returns an
 * AVB_SLOT_VERIFY_RESULT_ERROR_* error code.
 *
 * If the value does not exist, is not supported, or is not populated, and
 * |initial_digest| is NULL, returns
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA. If |expected_digest_size| does
 * not match the stored digest size, also returns
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA.
 */
static AvbSlotVerifyResult read_persistent_digest(AvbOps* ops,
                                                  const char* part_name,
                                                  size_t expected_digest_size,
                                                  const uint8_t* initial_digest,
                                                  uint8_t* out_digest) {
  char* persistent_value_name = NULL;
  AvbIOResult io_ret = AVB_IO_RESULT_OK;
  size_t stored_digest_size = 0;

  if (ops->read_persistent_value == NULL) {
    avb_errorv(part_name, ": Persistent values are not implemented.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }
  persistent_value_name =
      avb_strdupv(AVB_NPV_PERSISTENT_DIGEST_PREFIX, part_name, NULL);
  if (persistent_value_name == NULL) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  }

  io_ret = ops->read_persistent_value(ops,
                                      persistent_value_name,
                                      expected_digest_size,
                                      out_digest,
                                      &stored_digest_size);

  // If no such named persistent value exists and an initial digest value was
  // given, initialize the named persistent value with the given digest. If
  // initialized successfully, this will recurse into this function but with a
  // NULL initial_digest.
  if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_VALUE && initial_digest) {
    AvbSlotVerifyResult ret =
        initialize_persistent_digest(ops,
                                     part_name,
                                     persistent_value_name,
                                     expected_digest_size,
                                     initial_digest,
                                     out_digest);
    avb_free(persistent_value_name);
    return ret;
  }
  avb_free(persistent_value_name);

  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  } else if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_VALUE) {
    // Treat a missing persistent value as a verification error, which is
    // ignoreable, rather than a metadata error which is not.
    avb_errorv(part_name, ": Persistent digest does not exist.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
  } else if (io_ret == AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE ||
             io_ret == AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE) {
    avb_errorv(
        part_name, ": Persistent digest is not of expected size.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_errorv(part_name, ": Error reading persistent digest.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
  } else if (expected_digest_size != stored_digest_size) {
    avb_errorv(
        part_name, ": Persistent digest is not of expected size.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }
  return AVB_SLOT_VERIFY_RESULT_OK;
}

static AvbSlotVerifyResult initialize_persistent_digest(
    AvbOps* ops,
    const char* part_name,
    const char* persistent_value_name,
    size_t digest_size,
    const uint8_t* initial_digest,
    uint8_t* out_digest) {
  AvbSlotVerifyResult ret;
  AvbIOResult io_ret = AVB_IO_RESULT_OK;
  bool is_device_unlocked = true;

  io_ret = ops->read_is_device_unlocked(ops, &is_device_unlocked);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error getting device lock state.\n");
    return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
  }

  if (is_device_unlocked) {
    avb_debugv(part_name,
               ": Digest does not exist, device unlocked so not initializing "
               "digest.\n",
               NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
  }

  // Device locked; initialize digest with given initial value.
  avb_debugv(part_name,
             ": Digest does not exist, initializing persistent digest.\n",
             NULL);
  io_ret = ops->write_persistent_value(
      ops, persistent_value_name, digest_size, initial_digest);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_errorv(part_name, ": Error initializing persistent digest.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
  }

  // To ensure that the digest value was written successfully - and avoid a
  // scenario where the digest is simply 'initialized' on every verify - recurse
  // into read_persistent_digest to read back the written value. The NULL
  // initial_digest ensures that this will not recurse again.
  ret = read_persistent_digest(ops, part_name, digest_size, NULL, out_digest);
  if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
    avb_errorv(part_name,
               ": Reading back initialized persistent digest failed!\n",
               NULL);
  }
  return ret;
}

static AvbSlotVerifyResult load_and_verify_hash_partition(
    AvbOps* ops,
    const char* const* requested_partitions,
    const char* ab_suffix,
    bool allow_verification_error,
    const AvbDescriptor* descriptor,
    AvbSlotVerifyData* slot_data) {
  AvbHashDescriptor hash_desc;
  const uint8_t* desc_partition_name = NULL;
  const uint8_t* desc_salt;
  const uint8_t* desc_digest;
  char part_name[AVB_PART_NAME_MAX_SIZE];
  AvbSlotVerifyResult ret;
  AvbIOResult io_ret;
  uint8_t* image_buf = NULL;
  bool image_preloaded = false;
  uint8_t* digest;
  size_t digest_len;
  const char* found;
  uint64_t image_size;
  size_t expected_digest_len = 0;
  uint8_t expected_digest_buf[AVB_SHA512_DIGEST_SIZE];
  const uint8_t* expected_digest = NULL;

  if (!avb_hash_descriptor_validate_and_byteswap(
          (const AvbHashDescriptor*)descriptor, &hash_desc)) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  desc_partition_name =
      ((const uint8_t*)descriptor) + sizeof(AvbHashDescriptor);
  desc_salt = desc_partition_name + hash_desc.partition_name_len;
  desc_digest = desc_salt + hash_desc.salt_len;

  if (!avb_validate_utf8(desc_partition_name, hash_desc.partition_name_len)) {
    avb_error("Partition name is not valid UTF-8.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  /* Don't bother loading or validating unless the partition was
   * requested in the first place.
   */
  found = avb_strv_find_str(requested_partitions,
                            (const char*)desc_partition_name,
                            hash_desc.partition_name_len);
  if (found == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_OK;
    goto out;
  }

  if ((hash_desc.flags & AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB) != 0) {
    /* No ab_suffix, just copy the partition name as is. */
    if (hash_desc.partition_name_len >= AVB_PART_NAME_MAX_SIZE) {
      avb_error("Partition name does not fit.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }
    avb_memcpy(part_name, desc_partition_name, hash_desc.partition_name_len);
    part_name[hash_desc.partition_name_len] = '\0';
  } else if (hash_desc.digest_len == 0 && avb_strlen(ab_suffix) != 0) {
    /* No ab_suffix allowed for partitions without a digest in the descriptor
     * because these partitions hold data unique to this device and are not
     * updated using an A/B scheme.
     */
    avb_error("Cannot use A/B with a persistent digest.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  } else {
    /* Add ab_suffix to the partition name. */
    if (!avb_str_concat(part_name,
                        sizeof part_name,
                        (const char*)desc_partition_name,
                        hash_desc.partition_name_len,
                        ab_suffix,
                        avb_strlen(ab_suffix))) {
      avb_error("Partition name and suffix does not fit.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }
  }

  /* If we're allowing verification errors then hash_desc.image_size
   * may no longer match what's in the partition... so in this case
   * just load the entire partition.
   *
   * For example, this can happen if a developer does 'fastboot flash
   * boot /path/to/new/and/bigger/boot.img'. We want this to work
   * since it's such a common workflow.
   */
  image_size = hash_desc.image_size;
  if (allow_verification_error) {
    io_ret = ops->get_size_of_partition(ops, part_name, &image_size);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error determining partition size.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
    avb_debugv(part_name, ": Loading entire partition.\n", NULL);
  }

  ret = load_full_partition(
      ops, part_name, image_size, &image_buf, &image_preloaded);
  if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
    goto out;
  }
  // Although only one of the type might be used, we have to defined the
  // structure here so that they would live outside the 'if/else' scope to be
  // used later.
  AvbSHA256Ctx sha256_ctx;
  AvbSHA512Ctx sha512_ctx;
  size_t image_size_to_hash = hash_desc.image_size;
  // If we allow verification error and the whole partition is smaller than
  // image size in hash descriptor, we just hash the whole partition.
  if (image_size_to_hash > image_size) {
    image_size_to_hash = image_size;
  }
  if (avb_strcmp((const char*)hash_desc.hash_algorithm, "sha256") == 0) {
    avb_sha256_init(&sha256_ctx);
    avb_sha256_update(&sha256_ctx, desc_salt, hash_desc.salt_len);
    avb_sha256_update(&sha256_ctx, image_buf, image_size_to_hash);
    digest = avb_sha256_final(&sha256_ctx);
    digest_len = AVB_SHA256_DIGEST_SIZE;
  } else if (avb_strcmp((const char*)hash_desc.hash_algorithm, "sha512") == 0) {
    avb_sha512_init(&sha512_ctx);
    avb_sha512_update(&sha512_ctx, desc_salt, hash_desc.salt_len);
    avb_sha512_update(&sha512_ctx, image_buf, image_size_to_hash);
    digest = avb_sha512_final(&sha512_ctx);
    digest_len = AVB_SHA512_DIGEST_SIZE;
  } else {
    avb_errorv(part_name, ": Unsupported hash algorithm.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  if (hash_desc.digest_len == 0) {
    /* Expect a match to a persistent digest. */
    avb_debugv(part_name, ": No digest, using persistent digest.\n", NULL);
    expected_digest_len = digest_len;
    expected_digest = expected_digest_buf;
    avb_assert(expected_digest_len <= sizeof(expected_digest_buf));
    /* Pass |digest| as the |initial_digest| so devices not yet initialized get
     * initialized to the current partition digest.
     */
    ret = read_persistent_digest(
        ops, part_name, digest_len, digest, expected_digest_buf);
    if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
      goto out;
    }
  } else {
    /* Expect a match to the digest in the descriptor. */
    expected_digest_len = hash_desc.digest_len;
    expected_digest = desc_digest;
  }

  if (digest_len != expected_digest_len) {
    avb_errorv(
        part_name, ": Digest in descriptor not of expected size.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  if (avb_safe_memcmp(digest, expected_digest, digest_len) != 0) {
    avb_errorv(part_name,
               ": Hash of data does not match digest in descriptor.\n",
               NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
    goto out;
  }

  ret = AVB_SLOT_VERIFY_RESULT_OK;

out:

  /* If it worked and something was loaded, copy to slot_data. */
  if ((ret == AVB_SLOT_VERIFY_RESULT_OK || result_should_continue(ret)) &&
      image_buf != NULL) {
    AvbPartitionData* loaded_partition;
    if (slot_data->num_loaded_partitions == MAX_NUMBER_OF_LOADED_PARTITIONS) {
      avb_errorv(part_name, ": Too many loaded partitions.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto fail;
    }
    loaded_partition =
        &slot_data->loaded_partitions[slot_data->num_loaded_partitions++];
    loaded_partition->partition_name = avb_strdup(found);
    loaded_partition->data_size = image_size;
    loaded_partition->data = image_buf;
    loaded_partition->preloaded = image_preloaded;
    image_buf = NULL;
  }

fail:
  if (image_buf != NULL && !image_preloaded) {
    avb_free(image_buf);
  }
  return ret;
}

static AvbSlotVerifyResult load_requested_partitions(
    AvbOps* ops,
    const char* const* requested_partitions,
    const char* ab_suffix,
    AvbSlotVerifyData* slot_data) {
  AvbSlotVerifyResult ret;
  uint8_t* image_buf = NULL;
  bool image_preloaded = false;
  size_t n;

  for (n = 0; requested_partitions[n] != NULL; n++) {
    char part_name[AVB_PART_NAME_MAX_SIZE];
    AvbIOResult io_ret;
    uint64_t image_size;
    AvbPartitionData* loaded_partition;

    if (!avb_str_concat(part_name,
                        sizeof part_name,
                        requested_partitions[n],
                        avb_strlen(requested_partitions[n]),
                        ab_suffix,
                        avb_strlen(ab_suffix))) {
      avb_error("Partition name and suffix does not fit.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }

    io_ret = ops->get_size_of_partition(ops, part_name, &image_size);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error determining partition size.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
    avb_debugv(part_name, ": Loading entire partition.\n", NULL);

    ret = load_full_partition(
        ops, part_name, image_size, &image_buf, &image_preloaded);
    if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
      goto out;
    }

    /* Move to slot_data. */
    if (slot_data->num_loaded_partitions == MAX_NUMBER_OF_LOADED_PARTITIONS) {
      avb_errorv(part_name, ": Too many loaded partitions.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
    loaded_partition =
        &slot_data->loaded_partitions[slot_data->num_loaded_partitions++];
    loaded_partition->partition_name = avb_strdup(requested_partitions[n]);
    if (loaded_partition->partition_name == NULL) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
    loaded_partition->data_size = image_size;
    loaded_partition->data = image_buf; /* Transferring the owner. */
    loaded_partition->preloaded = image_preloaded;
    image_buf = NULL;
    image_preloaded = false;
  }

  ret = AVB_SLOT_VERIFY_RESULT_OK;

out:
  /* Free the current buffer if any. */
  if (image_buf != NULL && !image_preloaded) {
    avb_free(image_buf);
  }
  /* Buffers that are already saved in slot_data will be handled by the caller
   * even on failure. */
  return ret;
}

static AvbSlotVerifyResult load_and_verify_vbmeta(
    AvbOps* ops,
    const char* const* requested_partitions,
    const char* ab_suffix,
    AvbSlotVerifyFlags flags,
    bool allow_verification_error,
    AvbVBMetaImageFlags toplevel_vbmeta_flags,
    int rollback_index_location,
    const char* partition_name,
    size_t partition_name_len,
    const uint8_t* expected_public_key,
    size_t expected_public_key_length,
    AvbSlotVerifyData* slot_data,
    AvbAlgorithmType* out_algorithm_type,
    AvbCmdlineSubstList* out_additional_cmdline_subst) {
  char full_partition_name[AVB_PART_NAME_MAX_SIZE];
  AvbSlotVerifyResult ret;
  AvbIOResult io_ret;
  uint64_t vbmeta_offset;
  size_t vbmeta_size;
  uint8_t* vbmeta_buf = NULL;
  size_t vbmeta_num_read;
  AvbVBMetaVerifyResult vbmeta_ret;
  const uint8_t* pk_data;
  size_t pk_len;
  AvbVBMetaImageHeader vbmeta_header;
  uint64_t stored_rollback_index;
  const AvbDescriptor** descriptors = NULL;
  size_t num_descriptors;
  size_t n;
  bool is_main_vbmeta;
  bool look_for_vbmeta_footer;
  AvbVBMetaData* vbmeta_image_data = NULL;

  ret = AVB_SLOT_VERIFY_RESULT_OK;

  avb_assert(slot_data != NULL);

  /* Since we allow top-level vbmeta in 'boot', use
   * rollback_index_location to determine whether we're the main
   * vbmeta struct.
   */
  is_main_vbmeta = false;
  if (rollback_index_location == 0) {
    if ((flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) == 0) {
      is_main_vbmeta = true;
    }
  }

  /* Don't use footers for vbmeta partitions ('vbmeta' or
   * 'vbmeta_<partition_name>').
   */
  look_for_vbmeta_footer = true;
  if (avb_strncmp(partition_name, "vbmeta", avb_strlen("vbmeta")) == 0) {
    look_for_vbmeta_footer = false;
  }

  if (!avb_validate_utf8((const uint8_t*)partition_name, partition_name_len)) {
    avb_error("Partition name is not valid UTF-8.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  /* Construct full partition name e.g. system_a. */
  if (!avb_str_concat(full_partition_name,
                      sizeof full_partition_name,
                      partition_name,
                      partition_name_len,
                      ab_suffix,
                      avb_strlen(ab_suffix))) {
    avb_error("Partition name and suffix does not fit.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  /* If we're loading from the main vbmeta partition, the vbmeta struct is in
   * the beginning. Otherwise we may have to locate it via a footer... if no
   * footer is found, we look in the beginning to support e.g. vbmeta_<org>
   * partitions holding data for e.g. super partitions (b/80195851 for
   * rationale).
   */
  vbmeta_offset = 0;
  vbmeta_size = VBMETA_MAX_SIZE;
  if (look_for_vbmeta_footer) {
    uint8_t footer_buf[AVB_FOOTER_SIZE];
    size_t footer_num_read;
    AvbFooter footer;

    io_ret = ops->read_from_partition(ops,
                                      full_partition_name,
                                      -AVB_FOOTER_SIZE,
                                      AVB_FOOTER_SIZE,
                                      footer_buf,
                                      &footer_num_read);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(full_partition_name, ": Error loading footer.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
    avb_assert(footer_num_read == AVB_FOOTER_SIZE);

    if (!avb_footer_validate_and_byteswap((const AvbFooter*)footer_buf,
                                          &footer)) {
      avb_debugv(full_partition_name, ": No footer detected.\n", NULL);
    } else {
      /* Basic footer sanity check since the data is untrusted. */
      if (footer.vbmeta_size > VBMETA_MAX_SIZE) {
        avb_errorv(
            full_partition_name, ": Invalid vbmeta size in footer.\n", NULL);
      } else {
        vbmeta_offset = footer.vbmeta_offset;
        vbmeta_size = footer.vbmeta_size;
      }
    }
  }

  vbmeta_buf = avb_malloc(vbmeta_size);
  if (vbmeta_buf == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }

  if (vbmeta_offset != 0) {
    avb_debugv("Loading vbmeta struct in footer from partition '",
               full_partition_name,
               "'.\n",
               NULL);
  } else {
    avb_debugv("Loading vbmeta struct from partition '",
               full_partition_name,
               "'.\n",
               NULL);
  }

  io_ret = ops->read_from_partition(ops,
                                    full_partition_name,
                                    vbmeta_offset,
                                    vbmeta_size,
                                    vbmeta_buf,
                                    &vbmeta_num_read);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    /* If we're looking for 'vbmeta' but there is no such partition,
     * go try to get it from the boot partition instead.
     */
    if (is_main_vbmeta && io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION &&
        !look_for_vbmeta_footer) {
      avb_debugv(full_partition_name,
                 ": No such partition. Trying 'boot' instead.\n",
                 NULL);
      ret = load_and_verify_vbmeta(ops,
                                   requested_partitions,
                                   ab_suffix,
                                   flags,
                                   allow_verification_error,
                                   0 /* toplevel_vbmeta_flags */,
                                   0 /* rollback_index_location */,
                                   "boot",
                                   avb_strlen("boot"),
                                   NULL /* expected_public_key */,
                                   0 /* expected_public_key_length */,
                                   slot_data,
                                   out_algorithm_type,
                                   out_additional_cmdline_subst);
      goto out;
    } else {
      avb_errorv(full_partition_name, ": Error loading vbmeta data.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
  }
  avb_assert(vbmeta_num_read <= vbmeta_size);

  /* Check if the image is properly signed and get the public key used
   * to sign the image.
   */
  vbmeta_ret =
      avb_vbmeta_image_verify(vbmeta_buf, vbmeta_num_read, &pk_data, &pk_len);
  switch (vbmeta_ret) {
    case AVB_VBMETA_VERIFY_RESULT_OK:
      avb_assert(pk_data != NULL && pk_len > 0);
      break;

    case AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED:
    case AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH:
    case AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH:
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
      avb_errorv(full_partition_name,
                 ": Error verifying vbmeta image: ",
                 avb_vbmeta_verify_result_to_string(vbmeta_ret),
                 "\n",
                 NULL);
      if (!allow_verification_error) {
        goto out;
      }
      break;

    case AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER:
      /* No way to continue this case. */
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      avb_errorv(full_partition_name,
                 ": Error verifying vbmeta image: invalid vbmeta header\n",
                 NULL);
      goto out;

    case AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION:
      /* No way to continue this case. */
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION;
      avb_errorv(full_partition_name,
                 ": Error verifying vbmeta image: unsupported AVB version\n",
                 NULL);
      goto out;
  }

  /* Byteswap the header. */
  avb_vbmeta_image_header_to_host_byte_order((AvbVBMetaImageHeader*)vbmeta_buf,
                                             &vbmeta_header);

  /* If we're the toplevel, assign flags so they'll be passed down. */
  if (is_main_vbmeta) {
    toplevel_vbmeta_flags = (AvbVBMetaImageFlags)vbmeta_header.flags;
  } else {
    if (vbmeta_header.flags != 0) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      avb_errorv(full_partition_name,
                 ": chained vbmeta image has non-zero flags\n",
                 NULL);
      goto out;
    }
  }

  uint32_t rollback_index_location_to_use = rollback_index_location;

  /* Check if key used to make signature matches what is expected. */
  if (pk_data != NULL) {
    if (expected_public_key != NULL) {
      avb_assert(!is_main_vbmeta);
      if (expected_public_key_length != pk_len ||
          avb_safe_memcmp(expected_public_key, pk_data, pk_len) != 0) {
        avb_errorv(full_partition_name,
                   ": Public key used to sign data does not match key in chain "
                   "partition descriptor.\n",
                   NULL);
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED;
        if (!allow_verification_error) {
          goto out;
        }
      }
    } else {
      bool key_is_trusted = false;
      const uint8_t* pk_metadata = NULL;
      size_t pk_metadata_len = 0;

      if (vbmeta_header.public_key_metadata_size > 0) {
        pk_metadata = vbmeta_buf + sizeof(AvbVBMetaImageHeader) +
                      vbmeta_header.authentication_data_block_size +
                      vbmeta_header.public_key_metadata_offset;
        pk_metadata_len = vbmeta_header.public_key_metadata_size;
      }

      // If we're not using a vbmeta partition, need to use another AvbOps...
      if (flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) {
        io_ret = ops->validate_public_key_for_partition(
            ops,
            full_partition_name,
            pk_data,
            pk_len,
            pk_metadata,
            pk_metadata_len,
            &key_is_trusted,
            &rollback_index_location_to_use);
      } else {
        avb_assert(is_main_vbmeta);
        io_ret = ops->validate_vbmeta_public_key(ops,
                                                 pk_data,
                                                 pk_len,
                                                 pk_metadata,
                                                 pk_metadata_len,
                                                 &key_is_trusted);
      }

      if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto out;
      } else if (io_ret != AVB_IO_RESULT_OK) {
        avb_errorv(full_partition_name,
                   ": Error while checking public key used to sign data.\n",
                   NULL);
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
        goto out;
      }
      if (!key_is_trusted) {
        avb_errorv(full_partition_name,
                   ": Public key used to sign data rejected.\n",
                   NULL);
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED;
        if (!allow_verification_error) {
          goto out;
        }
      }
    }
  }

  /* Check rollback index. */
  io_ret = ops->read_rollback_index(
      ops, rollback_index_location_to_use, &stored_rollback_index);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_errorv(full_partition_name,
               ": Error getting rollback index for location.\n",
               NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    goto out;
  }
  if (vbmeta_header.rollback_index < stored_rollback_index) {
    avb_errorv(
        full_partition_name,
        ": Image rollback index is less than the stored rollback index.\n",
        NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX;
    if (!allow_verification_error) {
      goto out;
    }
  }

  /* Copy vbmeta to vbmeta_images before recursing. */
  if (is_main_vbmeta) {
    avb_assert(slot_data->num_vbmeta_images == 0);
  } else {
    if (!(flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION)) {
      avb_assert(slot_data->num_vbmeta_images > 0);
    }
  }
  if (slot_data->num_vbmeta_images == MAX_NUMBER_OF_VBMETA_IMAGES) {
    avb_errorv(full_partition_name, ": Too many vbmeta images.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }
  vbmeta_image_data = &slot_data->vbmeta_images[slot_data->num_vbmeta_images++];
  vbmeta_image_data->partition_name = avb_strdup(partition_name);
  vbmeta_image_data->vbmeta_data = vbmeta_buf;
  /* Note that |vbmeta_buf| is actually |vbmeta_num_read| bytes long
   * and this includes data past the end of the image. Pass the
   * actual size of the vbmeta image. Also, no need to use
   * avb_safe_add() since the header has already been verified.
   */
  vbmeta_image_data->vbmeta_size =
      sizeof(AvbVBMetaImageHeader) +
      vbmeta_header.authentication_data_block_size +
      vbmeta_header.auxiliary_data_block_size;
  vbmeta_image_data->verify_result = vbmeta_ret;

  /* If verification has been disabled by setting a bit in the image,
   * we're done... except that we need to load the entirety of the
   * requested partitions.
   */
  if (vbmeta_header.flags & AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED) {
    AvbSlotVerifyResult sub_ret;
    avb_debugv(
        full_partition_name, ": VERIFICATION_DISABLED bit is set.\n", NULL);
    /* If load_requested_partitions() fail it is always a fatal
     * failure (e.g. ERROR_INVALID_ARGUMENT, ERROR_OOM, etc.) rather
     * than recoverable (e.g. one where result_should_continue()
     * returns true) and we want to convey that error.
     */
    sub_ret = load_requested_partitions(
        ops, requested_partitions, ab_suffix, slot_data);
    if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
      ret = sub_ret;
    }
    goto out;
  }

  /* Now go through all descriptors and take the appropriate action:
   *
   * - hash descriptor: Load data from partition, calculate hash, and
   *   checks that it matches what's in the hash descriptor.
   *
   * - hashtree descriptor: Do nothing since verification happens
   *   on-the-fly from within the OS. (Unless the descriptor uses a
   *   persistent digest, in which case we need to find it).
   *
   * - chained partition descriptor: Load the footer, load the vbmeta
   *   image, verify vbmeta image (includes rollback checks, hash
   *   checks, bail on chained partitions).
   */
  descriptors =
      avb_descriptor_get_all(vbmeta_buf, vbmeta_num_read, &num_descriptors);
  for (n = 0; n < num_descriptors; n++) {
    AvbDescriptor desc;

    if (!avb_descriptor_validate_and_byteswap(descriptors[n], &desc)) {
      avb_errorv(full_partition_name, ": Descriptor is invalid.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }

    switch (desc.tag) {
      case AVB_DESCRIPTOR_TAG_HASH: {
        AvbSlotVerifyResult sub_ret;
        sub_ret = load_and_verify_hash_partition(ops,
                                                 requested_partitions,
                                                 ab_suffix,
                                                 allow_verification_error,
                                                 descriptors[n],
                                                 slot_data);
        if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
          ret = sub_ret;
          if (!allow_verification_error || !result_should_continue(ret)) {
            goto out;
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_CHAIN_PARTITION: {
        AvbSlotVerifyResult sub_ret;
        AvbChainPartitionDescriptor chain_desc;
        const uint8_t* chain_partition_name;
        const uint8_t* chain_public_key;

        /* Only allow CHAIN_PARTITION descriptors in the main vbmeta image. */
        if (!is_main_vbmeta) {
          avb_errorv(full_partition_name,
                     ": Encountered chain descriptor not in main image.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        if (!avb_chain_partition_descriptor_validate_and_byteswap(
                (AvbChainPartitionDescriptor*)descriptors[n], &chain_desc)) {
          avb_errorv(full_partition_name,
                     ": Chain partition descriptor is invalid.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        if (chain_desc.rollback_index_location == 0) {
          avb_errorv(full_partition_name,
                     ": Chain partition has invalid "
                     "rollback_index_location field.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        chain_partition_name = ((const uint8_t*)descriptors[n]) +
                               sizeof(AvbChainPartitionDescriptor);
        chain_public_key = chain_partition_name + chain_desc.partition_name_len;

        sub_ret =
            load_and_verify_vbmeta(ops,
                                   requested_partitions,
                                   ab_suffix,
                                   flags,
                                   allow_verification_error,
                                   toplevel_vbmeta_flags,
                                   chain_desc.rollback_index_location,
                                   (const char*)chain_partition_name,
                                   chain_desc.partition_name_len,
                                   chain_public_key,
                                   chain_desc.public_key_len,
                                   slot_data,
                                   NULL, /* out_algorithm_type */
                                   NULL /* out_additional_cmdline_subst */);
        if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
          ret = sub_ret;
          if (!result_should_continue(ret)) {
            goto out;
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE: {
        const uint8_t* kernel_cmdline;
        AvbKernelCmdlineDescriptor kernel_cmdline_desc;
        bool apply_cmdline;

        if (!avb_kernel_cmdline_descriptor_validate_and_byteswap(
                (AvbKernelCmdlineDescriptor*)descriptors[n],
                &kernel_cmdline_desc)) {
          avb_errorv(full_partition_name,
                     ": Kernel cmdline descriptor is invalid.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        kernel_cmdline = ((const uint8_t*)descriptors[n]) +
                         sizeof(AvbKernelCmdlineDescriptor);

        if (!avb_validate_utf8(kernel_cmdline,
                               kernel_cmdline_desc.kernel_cmdline_length)) {
          avb_errorv(full_partition_name,
                     ": Kernel cmdline is not valid UTF-8.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        /* Compare the flags for top-level VBMeta struct with flags in
         * the command-line descriptor so command-line snippets only
         * intended for a certain mode (dm-verity enabled/disabled)
         * are skipped if applicable.
         */
        apply_cmdline = true;
        if (toplevel_vbmeta_flags & AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED) {
          if (kernel_cmdline_desc.flags &
              AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED) {
            apply_cmdline = false;
          }
        } else {
          if (kernel_cmdline_desc.flags &
              AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED) {
            apply_cmdline = false;
          }
        }

        if (apply_cmdline) {
          if (slot_data->cmdline == NULL) {
            slot_data->cmdline =
                avb_calloc(kernel_cmdline_desc.kernel_cmdline_length + 1);
            if (slot_data->cmdline == NULL) {
              ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
              goto out;
            }
            avb_memcpy(slot_data->cmdline,
                       kernel_cmdline,
                       kernel_cmdline_desc.kernel_cmdline_length);
          } else {
            /* new cmdline is: <existing_cmdline> + ' ' + <newcmdline> + '\0' */
            size_t orig_size = avb_strlen(slot_data->cmdline);
            size_t new_size =
                orig_size + 1 + kernel_cmdline_desc.kernel_cmdline_length + 1;
            char* new_cmdline = avb_calloc(new_size);
            if (new_cmdline == NULL) {
              ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
              goto out;
            }
            avb_memcpy(new_cmdline, slot_data->cmdline, orig_size);
            new_cmdline[orig_size] = ' ';
            avb_memcpy(new_cmdline + orig_size + 1,
                       kernel_cmdline,
                       kernel_cmdline_desc.kernel_cmdline_length);
            avb_free(slot_data->cmdline);
            slot_data->cmdline = new_cmdline;
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_HASHTREE: {
        AvbHashtreeDescriptor hashtree_desc;

        if (!avb_hashtree_descriptor_validate_and_byteswap(
                (AvbHashtreeDescriptor*)descriptors[n], &hashtree_desc)) {
          avb_errorv(
              full_partition_name, ": Hashtree descriptor is invalid.\n", NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        /* We only need to continue when there is no digest in the descriptor.
         * This is because the only processing here is to find the digest and
         * make it available on the kernel command line.
         */
        if (hashtree_desc.root_digest_len == 0) {
          char part_name[AVB_PART_NAME_MAX_SIZE];
          size_t digest_len = 0;
          uint8_t digest_buf[AVB_SHA512_DIGEST_SIZE];
          const uint8_t* desc_partition_name =
              ((const uint8_t*)descriptors[n]) + sizeof(AvbHashtreeDescriptor);

          if (!avb_validate_utf8(desc_partition_name,
                                 hashtree_desc.partition_name_len)) {
            avb_error("Partition name is not valid UTF-8.\n");
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }

          /* No ab_suffix for partitions without a digest in the descriptor
           * because these partitions hold data unique to this device and are
           * not updated using an A/B scheme.
           */
          if ((hashtree_desc.flags &
               AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB) == 0 &&
              avb_strlen(ab_suffix) != 0) {
            avb_error("Cannot use A/B with a persistent root digest.\n");
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }
          if (hashtree_desc.partition_name_len >= AVB_PART_NAME_MAX_SIZE) {
            avb_error("Partition name does not fit.\n");
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }
          avb_memcpy(
              part_name, desc_partition_name, hashtree_desc.partition_name_len);
          part_name[hashtree_desc.partition_name_len] = '\0';

          /* Determine the expected digest size from the hash algorithm. */
          if (avb_strcmp((const char*)hashtree_desc.hash_algorithm, "sha1") ==
              0) {
            digest_len = AVB_SHA1_DIGEST_SIZE;
          } else if (avb_strcmp((const char*)hashtree_desc.hash_algorithm,
                                "sha256") == 0) {
            digest_len = AVB_SHA256_DIGEST_SIZE;
          } else if (avb_strcmp((const char*)hashtree_desc.hash_algorithm,
                                "sha512") == 0) {
            digest_len = AVB_SHA512_DIGEST_SIZE;
          } else {
            avb_errorv(part_name, ": Unsupported hash algorithm.\n", NULL);
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }

          ret = read_persistent_digest(ops,
                                       part_name,
                                       digest_len,
                                       NULL /* initial_digest */,
                                       digest_buf);
          if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
            goto out;
          }

          if (out_additional_cmdline_subst) {
            ret =
                avb_add_root_digest_substitution(part_name,
                                                 digest_buf,
                                                 digest_len,
                                                 out_additional_cmdline_subst);
            if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
              goto out;
            }
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_PROPERTY:
        /* Do nothing. */
        break;
    }
  }

  if (rollback_index_location < 0 ||
      rollback_index_location >= AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS) {
    avb_errorv(
        full_partition_name, ": Invalid rollback_index_location.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  slot_data->rollback_indexes[rollback_index_location] =
      vbmeta_header.rollback_index;

  if (out_algorithm_type != NULL) {
    *out_algorithm_type = (AvbAlgorithmType)vbmeta_header.algorithm_type;
  }

out:
  /* If |vbmeta_image_data| isn't NULL it means that it adopted
   * |vbmeta_buf| so in that case don't free it here.
   */
  if (vbmeta_image_data == NULL) {
    if (vbmeta_buf != NULL) {
      avb_free(vbmeta_buf);
    }
  }
  if (descriptors != NULL) {
    avb_free(descriptors);
  }
  return ret;
}

static AvbIOResult avb_manage_hashtree_error_mode(
    AvbOps* ops,
    AvbSlotVerifyFlags flags,
    AvbSlotVerifyData* data,
    AvbHashtreeErrorMode* out_hashtree_error_mode) {
  AvbHashtreeErrorMode ret = AVB_HASHTREE_ERROR_MODE_RESTART;
  AvbIOResult io_ret = AVB_IO_RESULT_OK;
  uint8_t vbmeta_digest_sha256[AVB_SHA256_DIGEST_SIZE];
  uint8_t stored_vbmeta_digest_sha256[AVB_SHA256_DIGEST_SIZE];
  size_t num_bytes_read;

  avb_assert(out_hashtree_error_mode != NULL);
  avb_assert(ops->read_persistent_value != NULL);
  avb_assert(ops->write_persistent_value != NULL);

  // If we're rebooting because of dm-verity corruption, make a note of
  // the vbmeta hash so we can stay in 'eio' mode until things change.
  if (flags & AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION) {
    avb_debug(
        "Rebooting because of dm-verity corruption - "
        "recording OS instance and using 'eio' mode.\n");
    avb_slot_verify_data_calculate_vbmeta_digest(
        data, AVB_DIGEST_TYPE_SHA256, vbmeta_digest_sha256);
    io_ret = ops->write_persistent_value(ops,
                                         AVB_NPV_MANAGED_VERITY_MODE,
                                         AVB_SHA256_DIGEST_SIZE,
                                         vbmeta_digest_sha256);
    if (io_ret != AVB_IO_RESULT_OK) {
      avb_error("Error writing to " AVB_NPV_MANAGED_VERITY_MODE ".\n");
      goto out;
    }
    ret = AVB_HASHTREE_ERROR_MODE_EIO;
    io_ret = AVB_IO_RESULT_OK;
    goto out;
  }

  // See if we're in 'eio' mode.
  io_ret = ops->read_persistent_value(ops,
                                      AVB_NPV_MANAGED_VERITY_MODE,
                                      AVB_SHA256_DIGEST_SIZE,
                                      stored_vbmeta_digest_sha256,
                                      &num_bytes_read);
  if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_VALUE ||
      (io_ret == AVB_IO_RESULT_OK && num_bytes_read == 0)) {
    // This is the usual case ('eio' mode not set).
    avb_debug("No dm-verity corruption - using in 'restart' mode.\n");
    ret = AVB_HASHTREE_ERROR_MODE_RESTART;
    io_ret = AVB_IO_RESULT_OK;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error reading from " AVB_NPV_MANAGED_VERITY_MODE ".\n");
    goto out;
  }
  if (num_bytes_read != AVB_SHA256_DIGEST_SIZE) {
    avb_error(
        "Unexpected number of bytes read from " AVB_NPV_MANAGED_VERITY_MODE
        ".\n");
    io_ret = AVB_IO_RESULT_ERROR_IO;
    goto out;
  }

  // OK, so we're currently in 'eio' mode and the vbmeta digest of the OS
  // that caused this is in |stored_vbmeta_digest_sha256| ... now see if
  // the OS we're dealing with now is the same.
  avb_slot_verify_data_calculate_vbmeta_digest(
      data, AVB_DIGEST_TYPE_SHA256, vbmeta_digest_sha256);
  if (avb_memcmp(vbmeta_digest_sha256,
                 stored_vbmeta_digest_sha256,
                 AVB_SHA256_DIGEST_SIZE) == 0) {
    // It's the same so we're still in 'eio' mode.
    avb_debug("Same OS instance detected - staying in 'eio' mode.\n");
    ret = AVB_HASHTREE_ERROR_MODE_EIO;
    io_ret = AVB_IO_RESULT_OK;
  } else {
    // It did change!
    avb_debug(
        "New OS instance detected - changing from 'eio' to 'restart' mode.\n");
    io_ret =
        ops->write_persistent_value(ops,
                                    AVB_NPV_MANAGED_VERITY_MODE,
                                    0,  // This clears the persistent property.
                                    vbmeta_digest_sha256);
    if (io_ret != AVB_IO_RESULT_OK) {
      avb_error("Error clearing " AVB_NPV_MANAGED_VERITY_MODE ".\n");
      goto out;
    }
    ret = AVB_HASHTREE_ERROR_MODE_RESTART;
    io_ret = AVB_IO_RESULT_OK;
  }

out:
  *out_hashtree_error_mode = ret;
  return io_ret;
}

static bool has_system_partition(AvbOps* ops, const char* ab_suffix) {
  char part_name[AVB_PART_NAME_MAX_SIZE];
  char* system_part_name = "system";
  char guid_buf[37];
  AvbIOResult io_ret;

  if (!avb_str_concat(part_name,
                      sizeof part_name,
                      system_part_name,
                      avb_strlen(system_part_name),
                      ab_suffix,
                      avb_strlen(ab_suffix))) {
    avb_error("System partition name and suffix does not fit.\n");
    return false;
  }

  io_ret = ops->get_unique_guid_for_partition(
      ops, part_name, guid_buf, sizeof guid_buf);
  if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION) {
    avb_debug("No system partition.\n");
    return false;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error getting unique GUID for system partition.\n");
    return false;
  }

  return true;
}

AvbSlotVerifyResult avb_slot_verify(AvbOps* ops,
                                    const char* const* requested_partitions,
                                    const char* ab_suffix,
                                    AvbSlotVerifyFlags flags,
                                    AvbHashtreeErrorMode hashtree_error_mode,
                                    AvbSlotVerifyData** out_data) {
  AvbSlotVerifyResult ret;
  AvbSlotVerifyData* slot_data = NULL;
  AvbAlgorithmType algorithm_type = AVB_ALGORITHM_TYPE_NONE;
  bool using_boot_for_vbmeta = false;
  AvbVBMetaImageHeader toplevel_vbmeta;
  bool allow_verification_error =
      (flags & AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR);
  AvbCmdlineSubstList* additional_cmdline_subst = NULL;

  /* Fail early if we're missing the AvbOps needed for slot verification. */
  avb_assert(ops->read_is_device_unlocked != NULL);
  avb_assert(ops->read_from_partition != NULL);
  avb_assert(ops->get_size_of_partition != NULL);
  avb_assert(ops->read_rollback_index != NULL);
  avb_assert(ops->get_unique_guid_for_partition != NULL);

  if (out_data != NULL) {
    *out_data = NULL;
  }

  /* Allowing dm-verity errors defeats the purpose of verified boot so
   * only allow this if set up to allow verification errors
   * (e.g. typically only UNLOCKED mode).
   */
  if (hashtree_error_mode == AVB_HASHTREE_ERROR_MODE_LOGGING &&
      !allow_verification_error) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
    goto fail;
  }

  /* Make sure passed-in AvbOps support persistent values if
   * asking for libavb to manage verity state.
   */
  if (hashtree_error_mode == AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO) {
    if (ops->read_persistent_value == NULL ||
        ops->write_persistent_value == NULL) {
      avb_error(
          "Persistent values required for "
          "AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO "
          "but are not implemented in given AvbOps.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
      goto fail;
    }
  }

  /* Make sure passed-in AvbOps support verifying public keys and getting
   * rollback index location if not using a vbmeta partition.
   */
  if (flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) {
    if (ops->validate_public_key_for_partition == NULL) {
      avb_error(
          "AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION was passed but the "
          "validate_public_key_for_partition() operation isn't implemented.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
      goto fail;
    }
  } else {
    avb_assert(ops->validate_vbmeta_public_key != NULL);
  }

  slot_data = avb_calloc(sizeof(AvbSlotVerifyData));
  if (slot_data == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }
  slot_data->vbmeta_images =
      avb_calloc(sizeof(AvbVBMetaData) * MAX_NUMBER_OF_VBMETA_IMAGES);
  if (slot_data->vbmeta_images == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }
  slot_data->loaded_partitions =
      avb_calloc(sizeof(AvbPartitionData) * MAX_NUMBER_OF_LOADED_PARTITIONS);
  if (slot_data->loaded_partitions == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }

  additional_cmdline_subst = avb_new_cmdline_subst_list();
  if (additional_cmdline_subst == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }

  if (flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) {
    if (requested_partitions == NULL || requested_partitions[0] == NULL) {
      avb_fatal(
          "Requested partitions cannot be empty when using "
          "AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
      goto fail;
    }

    /* No vbmeta partition, go through each of the requested partitions... */
    for (size_t n = 0; requested_partitions[n] != NULL; n++) {
      ret = load_and_verify_vbmeta(ops,
                                   requested_partitions,
                                   ab_suffix,
                                   flags,
                                   allow_verification_error,
                                   0 /* toplevel_vbmeta_flags */,
                                   0 /* rollback_index_location */,
                                   requested_partitions[n],
                                   avb_strlen(requested_partitions[n]),
                                   NULL /* expected_public_key */,
                                   0 /* expected_public_key_length */,
                                   slot_data,
                                   &algorithm_type,
                                   additional_cmdline_subst);
      if (!allow_verification_error && ret != AVB_SLOT_VERIFY_RESULT_OK) {
        goto fail;
      }
    }

  } else {
    /* Usual path, load "vbmeta"... */
    ret = load_and_verify_vbmeta(ops,
                                 requested_partitions,
                                 ab_suffix,
                                 flags,
                                 allow_verification_error,
                                 0 /* toplevel_vbmeta_flags */,
                                 0 /* rollback_index_location */,
                                 "vbmeta",
                                 avb_strlen("vbmeta"),
                                 NULL /* expected_public_key */,
                                 0 /* expected_public_key_length */,
                                 slot_data,
                                 &algorithm_type,
                                 additional_cmdline_subst);
    if (!allow_verification_error && ret != AVB_SLOT_VERIFY_RESULT_OK) {
      goto fail;
    }
  }

  if (!result_should_continue(ret)) {
    goto fail;
  }

  /* If things check out, mangle the kernel command-line as needed. */
  if (!(flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION)) {
    if (avb_strcmp(slot_data->vbmeta_images[0].partition_name, "vbmeta") != 0) {
      avb_assert(
          avb_strcmp(slot_data->vbmeta_images[0].partition_name, "boot") == 0);
      using_boot_for_vbmeta = true;
    }
  }

  /* Byteswap top-level vbmeta header since we'll need it below. */
  avb_vbmeta_image_header_to_host_byte_order(
      (const AvbVBMetaImageHeader*)slot_data->vbmeta_images[0].vbmeta_data,
      &toplevel_vbmeta);

  /* Fill in |ab_suffix| field. */
  slot_data->ab_suffix = avb_strdup(ab_suffix);
  if (slot_data->ab_suffix == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }

  /* If verification is disabled, we are done ... we specifically
   * don't want to add any androidboot.* options since verification
   * is disabled.
   */
  if (toplevel_vbmeta.flags & AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED) {
    /* Since verification is disabled we didn't process any
     * descriptors and thus there's no cmdline... so set root= such
     * that the system partition is mounted.
     */
    avb_assert(slot_data->cmdline == NULL);
    // Devices with dynamic partitions won't have system partition.
    // Instead, it has a large super partition to accommodate *.img files.
    // See b/119551429 for details.
    if (has_system_partition(ops, ab_suffix)) {
      slot_data->cmdline =
          avb_strdup("root=PARTUUID=$(ANDROID_SYSTEM_PARTUUID)");
    } else {
      // The |cmdline| field should be a NUL-terminated string.
      slot_data->cmdline = avb_strdup("");
    }
    if (slot_data->cmdline == NULL) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto fail;
    }
  } else {
    /* If requested, manage dm-verity mode... */
    AvbHashtreeErrorMode resolved_hashtree_error_mode = hashtree_error_mode;
    if (hashtree_error_mode ==
        AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO) {
      AvbIOResult io_ret;
      io_ret = avb_manage_hashtree_error_mode(
          ops, flags, slot_data, &resolved_hashtree_error_mode);
      if (io_ret != AVB_IO_RESULT_OK) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
        if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        }
        goto fail;
      }
    }
    slot_data->resolved_hashtree_error_mode = resolved_hashtree_error_mode;

    /* Add options... */
    AvbSlotVerifyResult sub_ret;
    sub_ret = avb_append_options(ops,
                                 flags,
                                 slot_data,
                                 &toplevel_vbmeta,
                                 algorithm_type,
                                 hashtree_error_mode,
                                 resolved_hashtree_error_mode);
    if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
      ret = sub_ret;
      goto fail;
    }
  }

  /* Substitute $(ANDROID_SYSTEM_PARTUUID) and friends. */
  if (slot_data->cmdline != NULL && avb_strlen(slot_data->cmdline) != 0) {
    char* new_cmdline;
    new_cmdline = avb_sub_cmdline(ops,
                                  slot_data->cmdline,
                                  ab_suffix,
                                  using_boot_for_vbmeta,
                                  additional_cmdline_subst);
    if (new_cmdline != slot_data->cmdline) {
      if (new_cmdline == NULL) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto fail;
      }
      avb_free(slot_data->cmdline);
      slot_data->cmdline = new_cmdline;
    }
  }

  if (out_data != NULL) {
    *out_data = slot_data;
  } else {
    avb_slot_verify_data_free(slot_data);
  }

  avb_free_cmdline_subst_list(additional_cmdline_subst);
  additional_cmdline_subst = NULL;

  if (!allow_verification_error) {
    avb_assert(ret == AVB_SLOT_VERIFY_RESULT_OK);
  }

  return ret;

fail:
  if (slot_data != NULL) {
    avb_slot_verify_data_free(slot_data);
  }
  if (additional_cmdline_subst != NULL) {
    avb_free_cmdline_subst_list(additional_cmdline_subst);
  }
  return ret;
}

void avb_slot_verify_data_free(AvbSlotVerifyData* data) {
  if (data->ab_suffix != NULL) {
    avb_free(data->ab_suffix);
  }
  if (data->cmdline != NULL) {
    avb_free(data->cmdline);
  }
  if (data->vbmeta_images != NULL) {
    size_t n;
    for (n = 0; n < data->num_vbmeta_images; n++) {
      AvbVBMetaData* vbmeta_image = &data->vbmeta_images[n];
      if (vbmeta_image->partition_name != NULL) {
        avb_free(vbmeta_image->partition_name);
      }
      if (vbmeta_image->vbmeta_data != NULL) {
        avb_free(vbmeta_image->vbmeta_data);
      }
    }
    avb_free(data->vbmeta_images);
  }
  if (data->loaded_partitions != NULL) {
    size_t n;
    for (n = 0; n < data->num_loaded_partitions; n++) {
      AvbPartitionData* loaded_partition = &data->loaded_partitions[n];
      if (loaded_partition->partition_name != NULL) {
        avb_free(loaded_partition->partition_name);
      }
      if (loaded_partition->data != NULL && !loaded_partition->preloaded) {
        avb_free(loaded_partition->data);
      }
    }
    avb_free(data->loaded_partitions);
  }
  avb_free(data);
}

const char* avb_slot_verify_result_to_string(AvbSlotVerifyResult result) {
  const char* ret = NULL;

  switch (result) {
    case AVB_SLOT_VERIFY_RESULT_OK:
      ret = "OK";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_OOM:
      ret = "ERROR_OOM";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_IO:
      ret = "ERROR_IO";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION:
      ret = "ERROR_VERIFICATION";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX:
      ret = "ERROR_ROLLBACK_INDEX";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED:
      ret = "ERROR_PUBLIC_KEY_REJECTED";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA:
      ret = "ERROR_INVALID_METADATA";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION:
      ret = "ERROR_UNSUPPORTED_VERSION";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT:
      ret = "ERROR_INVALID_ARGUMENT";
      break;
      /* Do not add a 'default:' case here because of -Wswitch. */
  }

  if (ret == NULL) {
    avb_error("Unknown AvbSlotVerifyResult value.\n");
    ret = "(unknown)";
  }

  return ret;
}

void avb_slot_verify_data_calculate_vbmeta_digest(AvbSlotVerifyData* data,
                                                  AvbDigestType digest_type,
                                                  uint8_t* out_digest) {
  bool ret = false;
  size_t n;

  switch (digest_type) {
    case AVB_DIGEST_TYPE_SHA256: {
      AvbSHA256Ctx ctx;
      avb_sha256_init(&ctx);
      for (n = 0; n < data->num_vbmeta_images; n++) {
        avb_sha256_update(&ctx,
                          data->vbmeta_images[n].vbmeta_data,
                          data->vbmeta_images[n].vbmeta_size);
      }
      avb_memcpy(out_digest, avb_sha256_final(&ctx), AVB_SHA256_DIGEST_SIZE);
      ret = true;
    } break;

    case AVB_DIGEST_TYPE_SHA512: {
      AvbSHA512Ctx ctx;
      avb_sha512_init(&ctx);
      for (n = 0; n < data->num_vbmeta_images; n++) {
        avb_sha512_update(&ctx,
                          data->vbmeta_images[n].vbmeta_data,
                          data->vbmeta_images[n].vbmeta_size);
      }
      avb_memcpy(out_digest, avb_sha512_final(&ctx), AVB_SHA512_DIGEST_SIZE);
      ret = true;
    } break;

      /* Do not add a 'default:' case here because of -Wswitch. */
  }

  if (!ret) {
    avb_fatal("Unknown digest type");
  }
}

```

`aosp/libavb1.1/src/avb/c/avb_sysdeps_posix.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if defined(__APPLE__) && defined(__MACH__)
#include <machine/endian.h>
#else
#include <endian.h>
#endif
#include <stdarg.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "avb_sysdeps.h"

int avb_memcmp(const void* src1, const void* src2, size_t n) {
  return memcmp(src1, src2, n);
}

void* avb_memcpy(void* dest, const void* src, size_t n) {
  return memcpy(dest, src, n);
}

void* avb_memset(void* dest, const int c, size_t n) {
  return memset(dest, c, n);
}

int avb_strcmp(const char* s1, const char* s2) {
  return strcmp(s1, s2);
}

int avb_strncmp(const char* s1, const char* s2, size_t n) {
  return strncmp(s1, s2, n);
}

size_t avb_strlen(const char* str) {
  return strlen(str);
}

void avb_abort(void) {
  abort();
}

void avb_print(const char* message) {
  fprintf(stderr, "%s", message);
}

void avb_printv(const char* message, ...) {
  va_list ap;
  const char* m;

  va_start(ap, message);
  for (m = message; m != NULL; m = va_arg(ap, const char*)) {
    fprintf(stderr, "%s", m);
  }
  va_end(ap);
}

void* avb_malloc_(size_t size) {
  return malloc(size);
}

void avb_free(void* ptr) {
  free(ptr);
}

uint32_t avb_div_by_10(uint64_t* dividend) {
  uint32_t rem = (uint32_t)(*dividend % 10);
  *dividend /= 10;
  return rem;
}

```

`aosp/libavb1.1/src/avb/c/avb_util.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_util.h"

#include <stdarg.h>

uint32_t avb_be32toh(uint32_t in) {
  uint8_t* d = (uint8_t*)&in;
  uint32_t ret;
  ret = ((uint32_t)d[0]) << 24;
  ret |= ((uint32_t)d[1]) << 16;
  ret |= ((uint32_t)d[2]) << 8;
  ret |= ((uint32_t)d[3]);
  return ret;
}

uint64_t avb_be64toh(uint64_t in) {
  uint8_t* d = (uint8_t*)&in;
  uint64_t ret;
  ret = ((uint64_t)d[0]) << 56;
  ret |= ((uint64_t)d[1]) << 48;
  ret |= ((uint64_t)d[2]) << 40;
  ret |= ((uint64_t)d[3]) << 32;
  ret |= ((uint64_t)d[4]) << 24;
  ret |= ((uint64_t)d[5]) << 16;
  ret |= ((uint64_t)d[6]) << 8;
  ret |= ((uint64_t)d[7]);
  return ret;
}

/* Converts a 32-bit unsigned integer from host to big-endian byte order. */
uint32_t avb_htobe32(uint32_t in) {
  union {
    uint32_t word;
    uint8_t bytes[4];
  } ret;
  ret.bytes[0] = (in >> 24) & 0xff;
  ret.bytes[1] = (in >> 16) & 0xff;
  ret.bytes[2] = (in >> 8) & 0xff;
  ret.bytes[3] = in & 0xff;
  return ret.word;
}

/* Converts a 64-bit unsigned integer from host to big-endian byte order. */
uint64_t avb_htobe64(uint64_t in) {
  union {
    uint64_t word;
    uint8_t bytes[8];
  } ret;
  ret.bytes[0] = (in >> 56) & 0xff;
  ret.bytes[1] = (in >> 48) & 0xff;
  ret.bytes[2] = (in >> 40) & 0xff;
  ret.bytes[3] = (in >> 32) & 0xff;
  ret.bytes[4] = (in >> 24) & 0xff;
  ret.bytes[5] = (in >> 16) & 0xff;
  ret.bytes[6] = (in >> 8) & 0xff;
  ret.bytes[7] = in & 0xff;
  return ret.word;
}

int avb_safe_memcmp(const void* s1, const void* s2, size_t n) {
  const unsigned char* us1 = s1;
  const unsigned char* us2 = s2;
  int result = 0;

  if (0 == n) {
    return 0;
  }

  /*
   * Code snippet without data-dependent branch due to Nate Lawson
   * (nate@root.org) of Root Labs.
   */
  while (n--) {
    result |= *us1++ ^ *us2++;
  }

  return result != 0;
}

bool avb_safe_add_to(uint64_t* value, uint64_t value_to_add) {
  uint64_t original_value;

  avb_assert(value != NULL);

  original_value = *value;

  *value += value_to_add;
  if (*value < original_value) {
    avb_error("Overflow when adding values.\n");
    return false;
  }

  return true;
}

bool avb_safe_add(uint64_t* out_result, uint64_t a, uint64_t b) {
  uint64_t dummy;
  if (out_result == NULL) {
    out_result = &dummy;
  }
  *out_result = a;
  return avb_safe_add_to(out_result, b);
}

bool avb_validate_utf8(const uint8_t* data, size_t num_bytes) {
  size_t n;
  unsigned int num_cc;

  for (n = 0, num_cc = 0; n < num_bytes; n++) {
    uint8_t c = data[n];

    if (num_cc > 0) {
      if ((c & (0x80 | 0x40)) == 0x80) {
        /* 10xx xxxx */
      } else {
        goto fail;
      }
      num_cc--;
    } else {
      if (c < 0x80) {
        num_cc = 0;
      } else if ((c & (0x80 | 0x40 | 0x20)) == (0x80 | 0x40)) {
        /* 110x xxxx */
        num_cc = 1;
      } else if ((c & (0x80 | 0x40 | 0x20 | 0x10)) == (0x80 | 0x40 | 0x20)) {
        /* 1110 xxxx */
        num_cc = 2;
      } else if ((c & (0x80 | 0x40 | 0x20 | 0x10 | 0x08)) ==
                 (0x80 | 0x40 | 0x20 | 0x10)) {
        /* 1111 0xxx */
        num_cc = 3;
      } else {
        goto fail;
      }
    }
  }

  if (num_cc != 0) {
    goto fail;
  }

  return true;

fail:
  return false;
}

bool avb_str_concat(char* buf,
                    size_t buf_size,
                    const char* str1,
                    size_t str1_len,
                    const char* str2,
                    size_t str2_len) {
  uint64_t combined_len;

  if (!avb_safe_add(&combined_len, str1_len, str2_len)) {
    avb_error("Overflow when adding string sizes.\n");
    return false;
  }

  if (combined_len > buf_size - 1) {
    avb_error("Insufficient buffer space.\n");
    return false;
  }

  avb_memcpy(buf, str1, str1_len);
  avb_memcpy(buf + str1_len, str2, str2_len);
  buf[combined_len] = '\0';

  return true;
}

void* avb_malloc(size_t size) {
  void* ret = avb_malloc_(size);
  if (ret == NULL) {
    avb_error("Failed to allocate memory.\n");
    return NULL;
  }
  return ret;
}

void* avb_calloc(size_t size) {
  void* ret = avb_malloc(size);
  if (ret == NULL) {
    return NULL;
  }

  avb_memset(ret, '\0', size);
  return ret;
}

char* avb_strdup(const char* str) {
  size_t len = avb_strlen(str);
  char* ret = avb_malloc(len + 1);
  if (ret == NULL) {
    return NULL;
  }

  avb_memcpy(ret, str, len);
  ret[len] = '\0';

  return ret;
}

const char* avb_strstr(const char* haystack, const char* needle) {
  size_t n, m;

  /* Look through |haystack| and check if the first character of
   * |needle| matches. If so, check the rest of |needle|.
   */
  for (n = 0; haystack[n] != '\0'; n++) {
    if (haystack[n] != needle[0]) {
      continue;
    }

    for (m = 1;; m++) {
      if (needle[m] == '\0') {
        return haystack + n;
      }

      if (haystack[n + m] != needle[m]) {
        break;
      }
    }
  }

  return NULL;
}

const char* avb_strv_find_str(const char* const* strings,
                              const char* str,
                              size_t str_size) {
  size_t n;
  for (n = 0; strings[n] != NULL; n++) {
    if (avb_strlen(strings[n]) == str_size &&
        avb_memcmp(strings[n], str, str_size) == 0) {
      return strings[n];
    }
  }
  return NULL;
}

char* avb_replace(const char* str, const char* search, const char* replace) {
  char* ret = NULL;
  size_t ret_len = 0;
  size_t search_len, replace_len;
  const char* str_after_last_replace;

  search_len = avb_strlen(search);
  replace_len = avb_strlen(replace);

  str_after_last_replace = str;
  while (*str != '\0') {
    const char* s;
    size_t num_before;
    size_t num_new;

    s = avb_strstr(str, search);
    if (s == NULL) {
      break;
    }

    num_before = s - str;

    if (ret == NULL) {
      num_new = num_before + replace_len + 1;
      ret = avb_malloc(num_new);
      if (ret == NULL) {
        goto out;
      }
      avb_memcpy(ret, str, num_before);
      avb_memcpy(ret + num_before, replace, replace_len);
      ret[num_new - 1] = '\0';
      ret_len = num_new - 1;
    } else {
      char* new_str;
      num_new = ret_len + num_before + replace_len + 1;
      new_str = avb_malloc(num_new);
      if (new_str == NULL) {
        goto out;
      }
      avb_memcpy(new_str, ret, ret_len);
      avb_memcpy(new_str + ret_len, str, num_before);
      avb_memcpy(new_str + ret_len + num_before, replace, replace_len);
      new_str[num_new - 1] = '\0';
      avb_free(ret);
      ret = new_str;
      ret_len = num_new - 1;
    }

    str = s + search_len;
    str_after_last_replace = str;
  }

  if (ret == NULL) {
    ret = avb_strdup(str_after_last_replace);
    if (ret == NULL) {
      goto out;
    }
  } else {
    size_t num_remaining = avb_strlen(str_after_last_replace);
    size_t num_new = ret_len + num_remaining + 1;
    char* new_str = avb_malloc(num_new);
    if (new_str == NULL) {
      goto out;
    }
    avb_memcpy(new_str, ret, ret_len);
    avb_memcpy(new_str + ret_len, str_after_last_replace, num_remaining);
    new_str[num_new - 1] = '\0';
    avb_free(ret);
    ret = new_str;
    ret_len = num_new - 1;
  }

out:
  return ret;
}

/* We only support a limited amount of strings in avb_strdupv(). */
#define AVB_STRDUPV_MAX_NUM_STRINGS 32

char* avb_strdupv(const char* str, ...) {
  va_list ap;
  const char* strings[AVB_STRDUPV_MAX_NUM_STRINGS];
  size_t lengths[AVB_STRDUPV_MAX_NUM_STRINGS];
  size_t num_strings, n;
  uint64_t total_length;
  char *ret = NULL, *dest;

  num_strings = 0;
  total_length = 0;
  va_start(ap, str);
  do {
    size_t str_len = avb_strlen(str);
    strings[num_strings] = str;
    lengths[num_strings] = str_len;
    if (!avb_safe_add_to(&total_length, str_len)) {
      avb_fatal("Overflow while determining total length.\n");
      break;
    }
    num_strings++;
    if (num_strings == AVB_STRDUPV_MAX_NUM_STRINGS) {
      avb_fatal("Too many strings passed.\n");
      break;
    }
    str = va_arg(ap, const char*);
  } while (str != NULL);
  va_end(ap);

  ret = avb_malloc(total_length + 1);
  if (ret == NULL) {
    goto out;
  }

  dest = ret;
  for (n = 0; n < num_strings; n++) {
    avb_memcpy(dest, strings[n], lengths[n]);
    dest += lengths[n];
  }
  *dest = '\0';
  avb_assert(dest == ret + total_length);

out:
  return ret;
}

const char* avb_basename(const char* str) {
  int64_t n;
  size_t len;

  len = avb_strlen(str);
  if (len >= 2) {
    for (n = len - 2; n >= 0; n--) {
      if (str[n] == '/') {
        return str + n + 1;
      }
    }
  }
  return str;
}

void avb_uppercase(char* str) {
  size_t i;
  for (i = 0; str[i] != '\0'; ++i) {
    if (str[i] <= 0x7A && str[i] >= 0x61) {
      str[i] -= 0x20;
    }
  }
}

char* avb_bin2hex(const uint8_t* data, size_t data_len) {
  const char hex_digits[17] = "0123456789abcdef";
  char* hex_data;
  size_t n;

  hex_data = avb_malloc(data_len * 2 + 1);
  if (hex_data == NULL) {
    return NULL;
  }

  for (n = 0; n < data_len; n++) {
    hex_data[n * 2] = hex_digits[data[n] >> 4];
    hex_data[n * 2 + 1] = hex_digits[data[n] & 0x0f];
  }
  hex_data[n * 2] = '\0';
  return hex_data;
}

```

`aosp/libavb1.1/src/avb/c/avb_vbmeta_image.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_vbmeta_image.h"
#include "avb_crypto.h"
#include "avb_rsa.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_version.h"

AvbVBMetaVerifyResult avb_vbmeta_image_verify(
    const uint8_t* data,
    size_t length,
    const uint8_t** out_public_key_data,
    size_t* out_public_key_length) {
  AvbVBMetaVerifyResult ret;
  AvbVBMetaImageHeader h;
  uint8_t* computed_hash;
  const AvbAlgorithmData* algorithm;
  AvbSHA256Ctx sha256_ctx;
  AvbSHA512Ctx sha512_ctx;
  const uint8_t* header_block;
  const uint8_t* authentication_block;
  const uint8_t* auxiliary_block;
  int verification_result;

  ret = AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER;

  if (out_public_key_data != NULL) {
    *out_public_key_data = NULL;
  }
  if (out_public_key_length != NULL) {
    *out_public_key_length = 0;
  }

  /* Before we byteswap or compare Magic, ensure length is long enough. */
  if (length < sizeof(AvbVBMetaImageHeader)) {
    avb_error("Length is smaller than header.\n");
    goto out;
  }

  /* Ensure magic is correct. */
  if (avb_safe_memcmp(data, AVB_MAGIC, AVB_MAGIC_LEN) != 0) {
    avb_error("Magic is incorrect.\n");
    goto out;
  }

  avb_vbmeta_image_header_to_host_byte_order((const AvbVBMetaImageHeader*)data,
                                             &h);

  /* Ensure we don't attempt to access any fields if we do not meet
   * the specified minimum version of libavb.
   */
  if ((h.required_libavb_version_major != AVB_VERSION_MAJOR) ||
      (h.required_libavb_version_minor > AVB_VERSION_MINOR)) {
    avb_error("Mismatch between image version and libavb version.\n");
    ret = AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION;
    goto out;
  }

  /* Ensure |release_string| ends with a NUL byte. */
  if (h.release_string[AVB_RELEASE_STRING_SIZE - 1] != '\0') {
    avb_error("Release string does not end with a NUL byte.\n");
    goto out;
  }

  /* Ensure inner block sizes are multiple of 64. */
  if ((h.authentication_data_block_size & 0x3f) != 0 ||
      (h.auxiliary_data_block_size & 0x3f) != 0) {
    avb_error("Block size is not a multiple of 64.\n");
    goto out;
  }

  /* Ensure block sizes all add up to at most |length|. */
  uint64_t block_total = sizeof(AvbVBMetaImageHeader);
  if (!avb_safe_add_to(&block_total, h.authentication_data_block_size) ||
      !avb_safe_add_to(&block_total, h.auxiliary_data_block_size)) {
    avb_error("Overflow while computing size of boot image.\n");
    goto out;
  }
  if (block_total > length) {
    avb_error("Block sizes add up to more than given length.\n");
    goto out;
  }

  uintptr_t data_ptr = (uintptr_t)data;
  /* Ensure passed in memory doesn't wrap. */
  if (!avb_safe_add(NULL, (uint64_t)data_ptr, length)) {
    avb_error("Boot image location and length mismatch.\n");
    goto out;
  }

  /* Ensure hash and signature are entirely in the Authentication data block. */
  uint64_t hash_end;
  if (!avb_safe_add(&hash_end, h.hash_offset, h.hash_size) ||
      hash_end > h.authentication_data_block_size) {
    avb_error("Hash is not entirely in its block.\n");
    goto out;
  }
  uint64_t signature_end;
  if (!avb_safe_add(&signature_end, h.signature_offset, h.signature_size) ||
      signature_end > h.authentication_data_block_size) {
    avb_error("Signature is not entirely in its block.\n");
    goto out;
  }

  /* Ensure public key is entirely in the Auxiliary data block. */
  uint64_t pubkey_end;
  if (!avb_safe_add(&pubkey_end, h.public_key_offset, h.public_key_size) ||
      pubkey_end > h.auxiliary_data_block_size) {
    avb_error("Public key is not entirely in its block.\n");
    goto out;
  }

  /* Ensure public key metadata (if set) is entirely in the Auxiliary
   * data block. */
  if (h.public_key_metadata_size > 0) {
    uint64_t pubkey_md_end;
    if (!avb_safe_add(&pubkey_md_end,
                      h.public_key_metadata_offset,
                      h.public_key_metadata_size) ||
        pubkey_md_end > h.auxiliary_data_block_size) {
      avb_error("Public key metadata is not entirely in its block.\n");
      goto out;
    }
  }

  /* Bail early if there's no hash or signature. */
  if (h.algorithm_type == AVB_ALGORITHM_TYPE_NONE) {
    ret = AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED;
    goto out;
  }

  /* Ensure algorithm field is supported. */
  algorithm = avb_get_algorithm_data(h.algorithm_type);
  if (!algorithm) {
    avb_error("Invalid or unknown algorithm.\n");
    goto out;
  }

  /* Bail if the embedded hash size doesn't match the chosen algorithm. */
  if (h.hash_size != algorithm->hash_len) {
    avb_error("Embedded hash has wrong size.\n");
    goto out;
  }

  /* No overflow checks needed from here-on after since all block
   * sizes and offsets have been verified above.
   */

  header_block = data;
  authentication_block = header_block + sizeof(AvbVBMetaImageHeader);
  auxiliary_block = authentication_block + h.authentication_data_block_size;

  switch (h.algorithm_type) {
    /* Explicit fall-through: */
    case AVB_ALGORITHM_TYPE_SHA256_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA256_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA256_RSA8192:
      avb_sha256_init(&sha256_ctx);
      avb_sha256_update(
          &sha256_ctx, header_block, sizeof(AvbVBMetaImageHeader));
      avb_sha256_update(
          &sha256_ctx, auxiliary_block, h.auxiliary_data_block_size);
      computed_hash = avb_sha256_final(&sha256_ctx);
      break;
    /* Explicit fall-through: */
    case AVB_ALGORITHM_TYPE_SHA512_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA512_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA512_RSA8192:
      avb_sha512_init(&sha512_ctx);
      avb_sha512_update(
          &sha512_ctx, header_block, sizeof(AvbVBMetaImageHeader));
      avb_sha512_update(
          &sha512_ctx, auxiliary_block, h.auxiliary_data_block_size);
      computed_hash = avb_sha512_final(&sha512_ctx);
      break;
    default:
      avb_error("Unknown algorithm.\n");
      goto out;
  }

  if (avb_safe_memcmp(authentication_block + h.hash_offset,
                      computed_hash,
                      h.hash_size) != 0) {
    avb_error("Hash does not match!\n");
    ret = AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH;
    goto out;
  }

  verification_result =
      avb_rsa_verify(auxiliary_block + h.public_key_offset,
                     h.public_key_size,
                     authentication_block + h.signature_offset,
                     h.signature_size,
                     authentication_block + h.hash_offset,
                     h.hash_size,
                     algorithm->padding,
                     algorithm->padding_len);

  if (verification_result == 0) {
    ret = AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH;
    goto out;
  }

  if (h.public_key_size > 0) {
    if (out_public_key_data != NULL) {
      *out_public_key_data = auxiliary_block + h.public_key_offset;
    }
    if (out_public_key_length != NULL) {
      *out_public_key_length = h.public_key_size;
    }
  }

  ret = AVB_VBMETA_VERIFY_RESULT_OK;

out:
  return ret;
}

void avb_vbmeta_image_header_to_host_byte_order(const AvbVBMetaImageHeader* src,
                                                AvbVBMetaImageHeader* dest) {
  avb_memcpy(dest, src, sizeof(AvbVBMetaImageHeader));

  dest->required_libavb_version_major =
      avb_be32toh(dest->required_libavb_version_major);
  dest->required_libavb_version_minor =
      avb_be32toh(dest->required_libavb_version_minor);

  dest->authentication_data_block_size =
      avb_be64toh(dest->authentication_data_block_size);
  dest->auxiliary_data_block_size =
      avb_be64toh(dest->auxiliary_data_block_size);

  dest->algorithm_type = avb_be32toh(dest->algorithm_type);

  dest->hash_offset = avb_be64toh(dest->hash_offset);
  dest->hash_size = avb_be64toh(dest->hash_size);

  dest->signature_offset = avb_be64toh(dest->signature_offset);
  dest->signature_size = avb_be64toh(dest->signature_size);

  dest->public_key_offset = avb_be64toh(dest->public_key_offset);
  dest->public_key_size = avb_be64toh(dest->public_key_size);

  dest->public_key_metadata_offset =
      avb_be64toh(dest->public_key_metadata_offset);
  dest->public_key_metadata_size = avb_be64toh(dest->public_key_metadata_size);

  dest->descriptors_offset = avb_be64toh(dest->descriptors_offset);
  dest->descriptors_size = avb_be64toh(dest->descriptors_size);

  dest->rollback_index = avb_be64toh(dest->rollback_index);
  dest->flags = avb_be32toh(dest->flags);
}

const char* avb_vbmeta_verify_result_to_string(AvbVBMetaVerifyResult result) {
  const char* ret = NULL;

  switch (result) {
    case AVB_VBMETA_VERIFY_RESULT_OK:
      ret = "OK";
      break;
    case AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED:
      ret = "OK_NOT_SIGNED";
      break;
    case AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER:
      ret = "INVALID_VBMETA_HEADER";
      break;
    case AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION:
      ret = "UNSUPPORTED_VERSION";
      break;
    case AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH:
      ret = "HASH_MISMATCH";
      break;
    case AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH:
      ret = "SIGNATURE_MISMATCH";
      break;
      /* Do not add a 'default:' case here because of -Wswitch. */
  }

  if (ret == NULL) {
    avb_error("Unknown AvbVBMetaVerifyResult value.\n");
    ret = "(unknown)";
  }

  return ret;
}

```

`aosp/libavb1.1/src/avb/c/avb_version.c`:

```c
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_version.h"

#define AVB_QUOTE(str) #str
#define AVB_EXPAND_AND_QUOTE(str) AVB_QUOTE(str)

/* Keep in sync with get_release_string() in avbtool. */
const char* avb_version_string(void) {
  return AVB_EXPAND_AND_QUOTE(AVB_VERSION_MAJOR) "." AVB_EXPAND_AND_QUOTE(
      AVB_VERSION_MINOR) "." AVB_EXPAND_AND_QUOTE(AVB_VERSION_SUB);
}

```

`aosp/libavb1.1/src/avb/headers/avb_chain_partition_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_CHAIN_PARTITION_DESCRIPTOR_H_
#define AVB_CHAIN_PARTITION_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* A descriptor containing a pointer to signed integrity data stored
 * on another partition. The descriptor contains the partition name in
 * question (without the A/B suffix), the public key used to sign the
 * integrity data, and rollback index location to use for rollback
 * protection.
 *
 * Following this struct are |partition_name_len| bytes of the
 * partition name (UTF-8 encoded) and |public_key_len| bytes of the
 * public key.
 *
 * The |reserved| field is for future expansion and must be set to NUL
 * bytes.
 */
typedef struct AvbChainPartitionDescriptor {
  AvbDescriptor parent_descriptor;
  uint32_t rollback_index_location;
  uint32_t partition_name_len;
  uint32_t public_key_len;
  uint8_t reserved[64];
} AVB_ATTR_PACKED AvbChainPartitionDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_chain_partition_descriptor_validate_and_byteswap(
    const AvbChainPartitionDescriptor* src,
    AvbChainPartitionDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_CHAIN_PARTITION_DESCRIPTOR_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_cmdline.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_sha.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_CMDLINE_H_
#define AVB_CMDLINE_H_

#include "avb_ops.h"
#include "avb_slot_verify.h"

/* Maximum allow length (in bytes) of a partition name, including
 * ab_suffix.
 */
#define AVB_PART_NAME_MAX_SIZE 32

#define AVB_MAX_NUM_CMDLINE_SUBST 10

/* Holds information about command-line substitutions. */
typedef struct AvbCmdlineSubstList {
  size_t size;
  char* tokens[AVB_MAX_NUM_CMDLINE_SUBST];
  char* values[AVB_MAX_NUM_CMDLINE_SUBST];
} AvbCmdlineSubstList;

/* Substitutes all variables (e.g. $(ANDROID_SYSTEM_PARTUUID)) with
 * values. Returns NULL on OOM, otherwise the cmdline with values
 * replaced.
 */
char* avb_sub_cmdline(AvbOps* ops,
                      const char* cmdline,
                      const char* ab_suffix,
                      bool using_boot_for_vbmeta,
                      const AvbCmdlineSubstList* additional_substitutions);

AvbSlotVerifyResult avb_append_options(
    AvbOps* ops,
    AvbSlotVerifyFlags flags,
    AvbSlotVerifyData* slot_data,
    AvbVBMetaImageHeader* toplevel_vbmeta,
    AvbAlgorithmType algorithm_type,
    AvbHashtreeErrorMode hashtree_error_mode,
    AvbHashtreeErrorMode resolved_hashtree_error_mode);

/* Allocates and initializes a new command line substitution list. Free with
 * |avb_free_cmdline_subst_list|.
 */
AvbCmdlineSubstList* avb_new_cmdline_subst_list(void);

/* Use this instead of |avb_free| to deallocate a AvbCmdlineSubstList. */
void avb_free_cmdline_subst_list(AvbCmdlineSubstList* cmdline_subst);

/* Adds a hashtree root digest to be substituted in $(AVB_*_ROOT_DIGEST)
 * variables. The partition name differentiates the variable. For example, if
 * |part_name| is "foo" then $(AVB_FOO_ROOT_DIGEST) will be substituted with the
 * hex encoding of the digest. The substitution will be added to
 * |out_cmdline_subst|. Returns AVB_SLOT_VERIFY_RESULT_OK on success.
 */
AvbSlotVerifyResult avb_add_root_digest_substitution(
    const char* part_name,
    const uint8_t* digest,
    size_t digest_size,
    AvbCmdlineSubstList* out_cmdline_subst);

#endif

```

`aosp/libavb1.1/src/avb/headers/avb_crypto.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_CRYPTO_H_
#define AVB_CRYPTO_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Size of a RSA-2048 signature. */
#define AVB_RSA2048_NUM_BYTES 256

/* Size of a RSA-4096 signature. */
#define AVB_RSA4096_NUM_BYTES 512

/* Size of a RSA-8192 signature. */
#define AVB_RSA8192_NUM_BYTES 1024

/* Size in bytes of a SHA-1 digest. */
#define AVB_SHA1_DIGEST_SIZE 20

/* Size in bytes of a SHA-256 digest. */
#define AVB_SHA256_DIGEST_SIZE 32

/* Size in bytes of a SHA-512 digest. */
#define AVB_SHA512_DIGEST_SIZE 64

/* Possible digest types supported by libavb routines. */
typedef enum {
  AVB_DIGEST_TYPE_SHA256,
  AVB_DIGEST_TYPE_SHA512,
} AvbDigestType;

/* Algorithms that can be used in the vbmeta image for
 * verification. An algorithm consists of a hash type and a signature
 * type.
 *
 * The data used to calculate the hash is the three blocks mentioned
 * in the documentation for |AvbVBMetaImageHeader| except for the data
 * in the "Authentication data" block.
 *
 * For signatures with RSA keys, PKCS v1.5 padding is used. The public
 * key data is stored in the auxiliary data block, see
 * |AvbRSAPublicKeyHeader| for the serialization format.
 *
 * Each algorithm type is described below:
 *
 * AVB_ALGORITHM_TYPE_NONE: There is no hash, no signature of the
 * data, and no public key. The data cannot be verified. The fields
 * |hash_size|, |signature_size|, and |public_key_size| must be zero.
 *
 * AVB_ALGORITHM_TYPE_SHA256_RSA2048: The hash function used is
 * SHA-256, resulting in 32 bytes of hash digest data. This hash is
 * signed with a 2048-bit RSA key. The field |hash_size| must be 32,
 * |signature_size| must be 256, and the public key data must have
 * |key_num_bits| set to 2048.
 *
 * AVB_ALGORITHM_TYPE_SHA256_RSA4096: Like above, but only with
 * a 4096-bit RSA key and |signature_size| set to 512.
 *
 * AVB_ALGORITHM_TYPE_SHA256_RSA8192: Like above, but only with
 * a 8192-bit RSA key and |signature_size| set to 1024.
 *
 * AVB_ALGORITHM_TYPE_SHA512_RSA2048: The hash function used is
 * SHA-512, resulting in 64 bytes of hash digest data. This hash is
 * signed with a 2048-bit RSA key. The field |hash_size| must be 64,
 * |signature_size| must be 256, and the public key data must have
 * |key_num_bits| set to 2048.
 *
 * AVB_ALGORITHM_TYPE_SHA512_RSA4096: Like above, but only with
 * a 4096-bit RSA key and |signature_size| set to 512.
 *
 * AVB_ALGORITHM_TYPE_SHA512_RSA8192: Like above, but only with
 * a 8192-bit RSA key and |signature_size| set to 1024.
 */
typedef enum {
  AVB_ALGORITHM_TYPE_NONE,
  AVB_ALGORITHM_TYPE_SHA256_RSA2048,
  AVB_ALGORITHM_TYPE_SHA256_RSA4096,
  AVB_ALGORITHM_TYPE_SHA256_RSA8192,
  AVB_ALGORITHM_TYPE_SHA512_RSA2048,
  AVB_ALGORITHM_TYPE_SHA512_RSA4096,
  AVB_ALGORITHM_TYPE_SHA512_RSA8192,
  _AVB_ALGORITHM_NUM_TYPES
} AvbAlgorithmType;

/* Holds algorithm-specific data. The |padding| is needed by avb_rsa_verify. */
typedef struct {
  const uint8_t* padding;
  size_t padding_len;
  size_t hash_len;
} AvbAlgorithmData;

/* Provides algorithm-specific data for a given |algorithm|. Returns NULL if
 * |algorithm| is invalid.
 */
const AvbAlgorithmData* avb_get_algorithm_data(AvbAlgorithmType algorithm)
    AVB_ATTR_WARN_UNUSED_RESULT;

/* The header for a serialized RSA public key.
 *
 * The size of the key is given by |key_num_bits|, for example 2048
 * for a RSA-2048 key. By definition, a RSA public key is the pair (n,
 * e) where |n| is the modulus (which can be represented in
 * |key_num_bits| bits) and |e| is the public exponent. The exponent
 * is not stored since it's assumed to always be 65537.
 *
 * To optimize verification, the key block includes two precomputed
 * values, |n0inv| (fits in 32 bits) and |rr| and can always be
 * represented in |key_num_bits|.

 * The value |n0inv| is the value -1/n[0] (mod 2^32). The value |rr|
 * is (2^key_num_bits)^2 (mod n).
 *
 * Following this header is |key_num_bits| bits of |n|, then
 * |key_num_bits| bits of |rr|. Both values are stored with most
 * significant bit first. Each serialized number takes up
 * |key_num_bits|/8 bytes.
 *
 * All fields in this struct are stored in network byte order when
 * serialized.  To generate a copy with fields swapped to native byte
 * order, use the function avb_rsa_public_key_header_validate_and_byteswap().
 *
 * The avb_rsa_verify() function expects a key in this serialized
 * format.
 *
 * The 'avbtool extract_public_key' command can be used to generate a
 * serialized RSA public key.
 */
typedef struct AvbRSAPublicKeyHeader {
  uint32_t key_num_bits;
  uint32_t n0inv;
} AVB_ATTR_PACKED AvbRSAPublicKeyHeader;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 */
bool avb_rsa_public_key_header_validate_and_byteswap(
    const AvbRSAPublicKeyHeader* src,
    AvbRSAPublicKeyHeader* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_CRYPTO_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_DESCRIPTOR_H_
#define AVB_DESCRIPTOR_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Well-known descriptor tags.
 *
 * AVB_DESCRIPTOR_TAG_PROPERTY: see |AvbPropertyDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_HASHTREE: see |AvbHashtreeDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_HASH: see |AvbHashDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE: see |AvbKernelCmdlineDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_CHAIN_PARTITION: see |AvbChainPartitionDescriptor| struct.
 */
typedef enum {
  AVB_DESCRIPTOR_TAG_PROPERTY,
  AVB_DESCRIPTOR_TAG_HASHTREE,
  AVB_DESCRIPTOR_TAG_HASH,
  AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE,
  AVB_DESCRIPTOR_TAG_CHAIN_PARTITION,
} AvbDescriptorTag;

/* The header for a serialized descriptor.
 *
 * A descriptor always have two fields, a |tag| (denoting its type,
 * see the |AvbDescriptorTag| enumeration) and the size of the bytes
 * following, |num_bytes_following|.
 *
 * For padding, |num_bytes_following| is always a multiple of 8.
 */
typedef struct AvbDescriptor {
  uint64_t tag;
  uint64_t num_bytes_following;
} AVB_ATTR_PACKED AvbDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_descriptor_validate_and_byteswap(
    const AvbDescriptor* src, AvbDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

/* Signature for callback function used in avb_descriptor_foreach().
 * The passed in descriptor is given by |descriptor| and the
 * |user_data| passed to avb_descriptor_foreach() function is in
 * |user_data|. Return true to continue iterating, false to stop
 * iterating.
 *
 * Note that |descriptor| points into the image passed to
 * avb_descriptor_foreach() - all fields need to be byteswapped!
 */
typedef bool AvbDescriptorForeachFunc(const AvbDescriptor* descriptor,
                                      void* user_data);

/* Convenience function to iterate over all descriptors in an vbmeta
 * image.
 *
 * The function given by |foreach_func| will be called for each
 * descriptor. The given function should return true to continue
 * iterating, false to stop.
 *
 * The |user_data| parameter will be passed to |foreach_func|.
 *
 * Returns false if the iteration was short-circuited, that is if
 * an invocation of |foreach_func| returned false.
 *
 * Before using this function, you MUST verify |image_data| with
 * avb_vbmeta_image_verify() and reject it unless it's signed by a known
 * good public key. Additionally, |image_data| must be word-aligned.
 */
bool avb_descriptor_foreach(const uint8_t* image_data,
                            size_t image_size,
                            AvbDescriptorForeachFunc foreach_func,
                            void* user_data);

/* Gets all descriptors in a vbmeta image.
 *
 * The return value is a NULL-pointer terminated array of
 * AvbDescriptor pointers. Free with avb_free() when you are done with
 * it. If |out_num_descriptors| is non-NULL, the number of descriptors
 * will be returned there.
 *
 * Note that each AvbDescriptor pointer in the array points into
 * |image_data| - all fields need to be byteswapped!
 *
 * Before using this function, you MUST verify |image_data| with
 * avb_vbmeta_image_verify() and reject it unless it's signed by a known
 * good public key. Additionally, |image_data| must be word-aligned.
 */
const AvbDescriptor** avb_descriptor_get_all(const uint8_t* image_data,
                                             size_t image_size,
                                             size_t* out_num_descriptors)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_DESCRIPTOR_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_footer.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_FOOTER_H_
#define AVB_FOOTER_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Magic for the footer. */
#define AVB_FOOTER_MAGIC "AVBf"
#define AVB_FOOTER_MAGIC_LEN 4

/* Size of the footer. */
#define AVB_FOOTER_SIZE 64

/* The current footer version used - keep in sync with avbtool. */
#define AVB_FOOTER_VERSION_MAJOR 1
#define AVB_FOOTER_VERSION_MINOR 0

/* The struct used as a footer used on partitions, used to find the
 * AvbVBMetaImageHeader struct. This struct is always stored at the
 * end of a partition.
 */
typedef struct AvbFooter {
  /*   0: Four bytes equal to "AVBf" (AVB_FOOTER_MAGIC). */
  uint8_t magic[AVB_FOOTER_MAGIC_LEN];
  /*   4: The major version of the footer struct. */
  uint32_t version_major;
  /*   8: The minor version of the footer struct. */
  uint32_t version_minor;

  /*  12: The original size of the image on the partition. */
  uint64_t original_image_size;

  /*  20: The offset of the |AvbVBMetaImageHeader| struct. */
  uint64_t vbmeta_offset;

  /*  28: The size of the vbmeta block (header + auth + aux blocks). */
  uint64_t vbmeta_size;

  /*  36: Padding to ensure struct is size AVB_FOOTER_SIZE bytes. This
   * must be set to zeroes.
   */
  uint8_t reserved[28];
} AVB_ATTR_PACKED AvbFooter;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 */
bool avb_footer_validate_and_byteswap(const AvbFooter* src, AvbFooter* dest)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_FOOTER_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_hash_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_HASH_DESCRIPTOR_H_
#define AVB_HASH_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Flags for hash descriptors.
 *
 * AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB: Do not apply the default A/B
 *   partition logic to this partition. This is intentionally a negative boolean
 *   because A/B should be both the default and most used in practice.
 */
typedef enum {
  AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB = (1 << 0),
} AvbHashDescriptorFlags;

/* A descriptor containing information about hash for an image.
 *
 * This descriptor is typically used for boot partitions to verify the
 * entire kernel+initramfs image before executing it.
 *
 * Following this struct are |partition_name_len| bytes of the
 * partition name (UTF-8 encoded), |salt_len| bytes of salt, and then
 * |digest_len| bytes of the digest.
 *
 * The |reserved| field is for future expansion and must be set to NUL
 * bytes.
 *
 * Changes in v1.1:
 *   - flags field is added which supports AVB_HASH_DESCRIPTOR_FLAGS_USE_AB
 *   - digest_len may be zero, which indicates the use of a persistent digest
 */
typedef struct AvbHashDescriptor {
  AvbDescriptor parent_descriptor;
  uint64_t image_size;
  uint8_t hash_algorithm[32];
  uint32_t partition_name_len;
  uint32_t salt_len;
  uint32_t digest_len;
  uint32_t flags;
  uint8_t reserved[60];
} AVB_ATTR_PACKED AvbHashDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_hash_descriptor_validate_and_byteswap(const AvbHashDescriptor* src,
                                               AvbHashDescriptor* dest)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_HASH_DESCRIPTOR_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_hashtree_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_HASHTREE_DESCRIPTOR_H_
#define AVB_HASHTREE_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Flags for hashtree descriptors.
 *
 * AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB: Do not apply the default A/B
 *   partition logic to this partition. This is intentionally a negative boolean
 *   because A/B should be both the default and most used in practice.
 */
typedef enum {
  AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB = (1 << 0),
} AvbHashtreeDescriptorFlags;

/* A descriptor containing information about a dm-verity hashtree.
 *
 * Hash-trees are used to verify large partitions typically containing
 * file systems. See
 * https://gitlab.com/cryptsetup/cryptsetup/wikis/DMVerity for more
 * information about dm-verity.
 *
 * Following this struct are |partition_name_len| bytes of the
 * partition name (UTF-8 encoded), |salt_len| bytes of salt, and then
 * |root_digest_len| bytes of the root digest.
 *
 * The |reserved| field is for future expansion and must be set to NUL
 * bytes.
 *
 * Changes in v1.1:
 *   - flags field is added which supports AVB_HASHTREE_DESCRIPTOR_FLAGS_USE_AB
 *   - digest_len may be zero, which indicates the use of a persistent digest
 */
typedef struct AvbHashtreeDescriptor {
  AvbDescriptor parent_descriptor;
  uint32_t dm_verity_version;
  uint64_t image_size;
  uint64_t tree_offset;
  uint64_t tree_size;
  uint32_t data_block_size;
  uint32_t hash_block_size;
  uint32_t fec_num_roots;
  uint64_t fec_offset;
  uint64_t fec_size;
  uint8_t hash_algorithm[32];
  uint32_t partition_name_len;
  uint32_t salt_len;
  uint32_t root_digest_len;
  uint32_t flags;
  uint8_t reserved[60];
} AVB_ATTR_PACKED AvbHashtreeDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_hashtree_descriptor_validate_and_byteswap(
    const AvbHashtreeDescriptor* src,
    AvbHashtreeDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_HASHTREE_DESCRIPTOR_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_kernel_cmdline_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_KERNEL_CMDLINE_DESCRIPTOR_H_
#define AVB_KERNEL_CMDLINE_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Flags for kernel command-line descriptors.
 *
 * AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED: The
 * cmdline will only be applied if hashtree verification is not
 * disabled (cf. AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED).
 *
 * AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED: The cmdline
 * will only be applied if hashtree verification is disabled
 * (cf. AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED).
 */
typedef enum {
  AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED = (1 << 0),
  AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED = (1 << 1)
} AvbKernelCmdlineFlags;

/* A descriptor containing information to be appended to the kernel
 * command-line.
 *
 * The |flags| field contains flags from the AvbKernelCmdlineFlags
 * enumeration.
 *
 * Following this struct are |kernel_cmdline_len| bytes with the
 * kernel command-line (UTF-8 encoded).
 */
typedef struct AvbKernelCmdlineDescriptor {
  AvbDescriptor parent_descriptor;
  uint32_t flags;
  uint32_t kernel_cmdline_length;
} AVB_ATTR_PACKED AvbKernelCmdlineDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_kernel_cmdline_descriptor_validate_and_byteswap(
    const AvbKernelCmdlineDescriptor* src,
    AvbKernelCmdlineDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_KERNEL_CMDLINE_DESCRIPTOR_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_ops.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_OPS_H_
#define AVB_OPS_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Well-known names of named persistent values. */
#define AVB_NPV_PERSISTENT_DIGEST_PREFIX "avb.persistent_digest."
#define AVB_NPV_MANAGED_VERITY_MODE "avb.managed_verity_mode"

/* Return codes used for I/O operations.
 *
 * AVB_IO_RESULT_OK is returned if the requested operation was
 * successful.
 *
 * AVB_IO_RESULT_ERROR_IO is returned if the underlying hardware (disk
 * or other subsystem) encountered an I/O error.
 *
 * AVB_IO_RESULT_ERROR_OOM is returned if unable to allocate memory.
 *
 * AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION is returned if the requested
 * partition does not exist.
 *
 * AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION is returned if the
 * range of bytes requested to be read or written is outside the range
 * of the partition.
 *
 * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE is returned if a named persistent value
 * does not exist.
 *
 * AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE is returned if a named persistent
 * value size is not supported or does not match the expected size.
 *
 * AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE is returned if a buffer is too small
 * for the requested operation.
 */
typedef enum {
  AVB_IO_RESULT_OK,
  AVB_IO_RESULT_ERROR_OOM,
  AVB_IO_RESULT_ERROR_IO,
  AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION,
  AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION,
  AVB_IO_RESULT_ERROR_NO_SUCH_VALUE,
  AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE,
  AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE,
} AvbIOResult;

struct AvbOps;
typedef struct AvbOps AvbOps;

/* Forward-declaration of operations in libavb_ab. */
struct AvbABOps;

/* Forward-declaration of operations in libavb_atx. */
struct AvbAtxOps;

/* High-level operations/functions/methods that are platform
 * dependent.
 *
 * Operations may be added in the future so when implementing it
 * always make sure to zero out sizeof(AvbOps) bytes of the struct to
 * ensure that unimplemented operations are set to NULL.
 */
struct AvbOps {
  /* This pointer can be used by the application/bootloader using
   * libavb and is typically used in each operation to get a pointer
   * to platform-specific resources. It cannot be used by libraries.
   */
  void* user_data;

  /* If libavb_ab is used, this should point to the
   * AvbABOps. Otherwise it must be set to NULL.
   */
  struct AvbABOps* ab_ops;

  /* If libavb_atx is used, this should point to the
   * AvbAtxOps. Otherwise it must be set to NULL.
   */
  struct AvbAtxOps* atx_ops;

  /* Reads |num_bytes| from offset |offset| from partition with name
   * |partition| (NUL-terminated UTF-8 string). If |offset| is
   * negative, its absolute value should be interpreted as the number
   * of bytes from the end of the partition.
   *
   * This function returns AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION if
   * there is no partition with the given name,
   * AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION if the requested
   * |offset| is outside the partition, and AVB_IO_RESULT_ERROR_IO if
   * there was an I/O error from the underlying I/O subsystem.  If the
   * operation succeeds as requested AVB_IO_RESULT_OK is returned and
   * the data is available in |buffer|.
   *
   * The only time partial I/O may occur is if reading beyond the end
   * of the partition. In this case the value returned in
   * |out_num_read| may be smaller than |num_bytes|.
   */
  AvbIOResult (*read_from_partition)(AvbOps* ops,
                                     const char* partition,
                                     int64_t offset,
                                     size_t num_bytes,
                                     void* buffer,
                                     size_t* out_num_read);

  /* Gets the starting pointer of a partition that is pre-loaded in memory, and
   * save it to |out_pointer|. The preloaded partition is expected to be
   * |num_bytes|, where the actual preloaded byte count is returned in
   * |out_num_bytes_preloaded|. |out_num_bytes_preloaded| must be no larger than
   * |num_bytes|.
   *
   * This provides an alternative way to access a partition that is preloaded
   * into memory without a full memory copy. When this function pointer is not
   * set (has value NULL), or when the |out_pointer| is set to NULL as a result,
   * |read_from_partition| will be used as the fallback. This function is mainly
   * used for accessing the entire partition content to calculate its hash.
   *
   * Preloaded partition data must outlive the lifespan of the
   * |AvbSlotVerifyData| structure that |avb_slot_verify| outputs.
   */
  AvbIOResult (*get_preloaded_partition)(AvbOps* ops,
                                         const char* partition,
                                         size_t num_bytes,
                                         uint8_t** out_pointer,
                                         size_t* out_num_bytes_preloaded);

  /* Writes |num_bytes| from |bffer| at offset |offset| to partition
   * with name |partition| (NUL-terminated UTF-8 string). If |offset|
   * is negative, its absolute value should be interpreted as the
   * number of bytes from the end of the partition.
   *
   * This function returns AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION if
   * there is no partition with the given name,
   * AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION if the requested
   * byterange goes outside the partition, and AVB_IO_RESULT_ERROR_IO
   * if there was an I/O error from the underlying I/O subsystem.  If
   * the operation succeeds as requested AVB_IO_RESULT_OK is
   * returned.
   *
   * This function never does any partial I/O, it either transfers all
   * of the requested bytes or returns an error.
   */
  AvbIOResult (*write_to_partition)(AvbOps* ops,
                                    const char* partition,
                                    int64_t offset,
                                    size_t num_bytes,
                                    const void* buffer);

  /* Checks if the given public key used to sign the 'vbmeta'
   * partition is trusted. Boot loaders typically compare this with
   * embedded key material generated with 'avbtool
   * extract_public_key'.
   *
   * The public key is in the array pointed to by |public_key_data|
   * and is of |public_key_length| bytes.
   *
   * If there is no public key metadata (set with the avbtool option
   * --public_key_metadata) then |public_key_metadata| will be set to
   * NULL. Otherwise this field points to the data which is
   * |public_key_metadata_length| bytes long.
   *
   * If AVB_IO_RESULT_OK is returned then |out_is_trusted| is set -
   * true if trusted or false if untrusted.
   *
   * NOTE: If AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION is passed to
   * avb_slot_verify() then this operation is never used. Instead, the
   * validate_public_key_for_partition() operation is used
   */
  AvbIOResult (*validate_vbmeta_public_key)(AvbOps* ops,
                                            const uint8_t* public_key_data,
                                            size_t public_key_length,
                                            const uint8_t* public_key_metadata,
                                            size_t public_key_metadata_length,
                                            bool* out_is_trusted);

  /* Gets the rollback index corresponding to the location given by
   * |rollback_index_location|. The value is returned in
   * |out_rollback_index|. Returns AVB_IO_RESULT_OK if the rollback
   * index was retrieved, otherwise an error code.
   *
   * A device may have a limited amount of rollback index locations (say,
   * one or four) so may error out if |rollback_index_location| exceeds
   * this number.
   */
  AvbIOResult (*read_rollback_index)(AvbOps* ops,
                                     size_t rollback_index_location,
                                     uint64_t* out_rollback_index);

  /* Sets the rollback index corresponding to the location given by
   * |rollback_index_location| to |rollback_index|. Returns
   * AVB_IO_RESULT_OK if the rollback index was set, otherwise an
   * error code.
   *
   * A device may have a limited amount of rollback index locations (say,
   * one or four) so may error out if |rollback_index_location| exceeds
   * this number.
   */
  AvbIOResult (*write_rollback_index)(AvbOps* ops,
                                      size_t rollback_index_location,
                                      uint64_t rollback_index);

  /* Gets whether the device is unlocked. The value is returned in
   * |out_is_unlocked| (true if unlocked, false otherwise). Returns
   * AVB_IO_RESULT_OK if the state was retrieved, otherwise an error
   * code.
   */
  AvbIOResult (*read_is_device_unlocked)(AvbOps* ops, bool* out_is_unlocked);

  /* Gets the unique partition GUID for a partition with name in
   * |partition| (NUL-terminated UTF-8 string). The GUID is copied as
   * a string into |guid_buf| of size |guid_buf_size| and will be NUL
   * terminated. The string must be lower-case and properly
   * hyphenated. For example:
   *
   *  527c1c6d-6361-4593-8842-3c78fcd39219
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   */
  AvbIOResult (*get_unique_guid_for_partition)(AvbOps* ops,
                                               const char* partition,
                                               char* guid_buf,
                                               size_t guid_buf_size);

  /* Gets the size of a partition with the name in |partition|
   * (NUL-terminated UTF-8 string). Returns the value in
   * |out_size_num_bytes|.
   *
   * If the partition doesn't exist the AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION
   * error code should be returned.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   */
  AvbIOResult (*get_size_of_partition)(AvbOps* ops,
                                       const char* partition,
                                       uint64_t* out_size_num_bytes);

  /* Reads a persistent value corresponding to the given |name|. The value is
   * returned in |out_buffer| which must point to |buffer_size| bytes. On
   * success |out_num_bytes_read| contains the number of bytes read into
   * |out_buffer|. If AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE is returned,
   * |out_num_bytes_read| contains the number of bytes that would have been read
   * which can be used to allocate a buffer.
   *
   * The |buffer_size| may be zero and the |out_buffer| may be NULL, but if
   * |out_buffer| is NULL then |buffer_size| *must* be zero.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   *
   * If the value does not exist, is not supported, or is not populated, returns
   * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE. If |buffer_size| is smaller than the
   * size of the stored value, returns AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE.
   *
   * This operation is currently only used to support persistent digests or the
   * AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO hashtree error mode. If a
   * device does not use one of these features this function pointer can be set
   * to NULL.
   */
  AvbIOResult (*read_persistent_value)(AvbOps* ops,
                                       const char* name,
                                       size_t buffer_size,
                                       uint8_t* out_buffer,
                                       size_t* out_num_bytes_read);

  /* Writes a persistent value corresponding to the given |name|. The value is
   * supplied in |value| which must point to |value_size| bytes. Any existing
   * value with the same name is overwritten. If |value_size| is zero, future
   * calls to |read_persistent_value| will return
   * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   *
   * If the value |name| is not supported, returns
   * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE. If the |value_size| is not supported,
   * returns AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE.
   *
   * This operation is currently only used to support persistent digests or the
   * AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO hashtree error mode. If a
   * device does not use one of these features this function pointer can be set
   * to NULL.
   */
  AvbIOResult (*write_persistent_value)(AvbOps* ops,
                                        const char* name,
                                        size_t value_size,
                                        const uint8_t* value);

  /* Like validate_vbmeta_public_key() but for when the flag
   * AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION is being used. The name of the
   * partition to get the public key for is passed in |partition_name|.
   *
   * Also returns the rollback index location to use for the partition, in
   * |out_rollback_index_location|.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   */
  AvbIOResult (*validate_public_key_for_partition)(
      AvbOps* ops,
      const char* partition,
      const uint8_t* public_key_data,
      size_t public_key_length,
      const uint8_t* public_key_metadata,
      size_t public_key_metadata_length,
      bool* out_is_trusted,
      uint32_t* out_rollback_index_location);
};

#ifdef __cplusplus
}
#endif

#endif /* AVB_OPS_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_property_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_PROPERTY_DESCRIPTOR_H_
#define AVB_PROPERTY_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* A descriptor for properties (free-form key/value pairs).
 *
 * Following this struct are |key_num_bytes| bytes of key data,
 * followed by a NUL byte, then |value_num_bytes| bytes of value data,
 * followed by a NUL byte and then enough padding to make the combined
 * size a multiple of 8.
 */
typedef struct AvbPropertyDescriptor {
  AvbDescriptor parent_descriptor;
  uint64_t key_num_bytes;
  uint64_t value_num_bytes;
} AVB_ATTR_PACKED AvbPropertyDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_property_descriptor_validate_and_byteswap(
    const AvbPropertyDescriptor* src,
    AvbPropertyDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

/* Convenience function for looking up the value for a property with
 * name |key| in a vbmeta image. If |key_size| is 0, |key| must be
 * NUL-terminated.
 *
 * The |image_data| parameter must be a pointer to a vbmeta image of
 * size |image_size|.
 *
 * This function returns a pointer to the value inside the passed-in
 * image or NULL if not found. Note that the value is always
 * guaranteed to be followed by a NUL byte.
 *
 * If the value was found and |out_value_size| is not NULL, the size
 * of the value is returned there.
 *
 * This function is O(n) in number of descriptors so if you need to
 * look up a lot of values, you may want to build a more efficient
 * lookup-table by manually walking all descriptors using
 * avb_descriptor_foreach().
 *
 * Before using this function, you MUST verify |image_data| with
 * avb_vbmeta_image_verify() and reject it unless it's signed by a
 * known good public key.
 */
const char* avb_property_lookup(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                size_t* out_value_size)
    AVB_ATTR_WARN_UNUSED_RESULT;

/* Like avb_property_lookup() but parses the intial portions of the
 * value as an unsigned 64-bit integer. Both decimal and hexadecimal
 * representations (e.g. "0x2a") are supported. Returns false on
 * failure and true on success. On success, the parsed value is
 * returned in |out_value|.
 */
bool avb_property_lookup_uint64(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                uint64_t* out_value)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_PROPERTY_DESCRIPTOR_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_rsa.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

/* Copyright (c) 2011 The Chromium OS Authors. All rights reserved.
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_rsa.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_RSA_H_
#define AVB_RSA_H_

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_crypto.h"
#include "avb_sysdeps.h"

/* Using the key given by |key|, verify a RSA signature |sig| of
 * length |sig_num_bytes| against an expected |hash| of length
 * |hash_num_bytes|. The padding to expect must be passed in using
 * |padding| of length |padding_num_bytes|.
 *
 * The data in |key| must match the format defined in
 * |AvbRSAPublicKeyHeader|, including the two large numbers
 * following. The |key_num_bytes| must be the size of the entire
 * serialized key.
 *
 * Returns false if verification fails, true otherwise.
 */
bool avb_rsa_verify(const uint8_t* key,
                    size_t key_num_bytes,
                    const uint8_t* sig,
                    size_t sig_num_bytes,
                    const uint8_t* hash,
                    size_t hash_num_bytes,
                    const uint8_t* padding,
                    size_t padding_num_bytes) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_RSA_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_sha.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_sha.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_SHA_H_
#define AVB_SHA_H_

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_crypto.h"
#include "avb_sysdeps.h"

/* Block size in bytes of a SHA-256 digest. */
#define AVB_SHA256_BLOCK_SIZE 64


/* Block size in bytes of a SHA-512 digest. */
#define AVB_SHA512_BLOCK_SIZE 128

/* Data structure used for SHA-256. */
typedef struct {
  uint32_t h[8];
  uint64_t tot_len;
  size_t len;
  uint8_t block[2 * AVB_SHA256_BLOCK_SIZE];
  uint8_t buf[AVB_SHA256_DIGEST_SIZE]; /* Used for storing the final digest. */
} AvbSHA256Ctx;

/* Data structure used for SHA-512. */
typedef struct {
  uint64_t h[8];
  uint64_t tot_len;
  size_t len;
  uint8_t block[2 * AVB_SHA512_BLOCK_SIZE];
  uint8_t buf[AVB_SHA512_DIGEST_SIZE]; /* Used for storing the final digest. */
} AvbSHA512Ctx;

/* Initializes the SHA-256 context. */
void avb_sha256_init(AvbSHA256Ctx* ctx);

/* Updates the SHA-256 context with |len| bytes from |data|. */
void avb_sha256_update(AvbSHA256Ctx* ctx, const uint8_t* data, size_t len);

/* Returns the SHA-256 digest. */
uint8_t* avb_sha256_final(AvbSHA256Ctx* ctx) AVB_ATTR_WARN_UNUSED_RESULT;

/* Initializes the SHA-512 context. */
void avb_sha512_init(AvbSHA512Ctx* ctx);

/* Updates the SHA-512 context with |len| bytes from |data|. */
void avb_sha512_update(AvbSHA512Ctx* ctx, const uint8_t* data, size_t len);

/* Returns the SHA-512 digest. */
uint8_t* avb_sha512_final(AvbSHA512Ctx* ctx) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_SHA_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_slot_verify.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_SLOT_VERIFY_H_
#define AVB_SLOT_VERIFY_H_

#include "avb_ops.h"
#include "avb_vbmeta_image.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Return codes used in avb_slot_verify(), see that function for
 * documentation for each field.
 *
 * Use avb_slot_verify_result_to_string() to get a textual
 * representation usable for error/debug output.
 */
typedef enum {
  AVB_SLOT_VERIFY_RESULT_OK,
  AVB_SLOT_VERIFY_RESULT_ERROR_OOM,
  AVB_SLOT_VERIFY_RESULT_ERROR_IO,
  AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION,
  AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX,
  AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED,
  AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA,
  AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION,
  AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT
} AvbSlotVerifyResult;

/* Various error handling modes for when verification fails using a
 * hashtree at runtime inside the HLOS.
 *
 * AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE means that the OS
 * will invalidate the current slot and restart.
 *
 * AVB_HASHTREE_ERROR_MODE_RESTART means that the OS will restart.
 *
 * AVB_HASHTREE_ERROR_MODE_EIO means that an EIO error will be
 * returned to applications.
 *
 * AVB_HASHTREE_ERROR_MODE_LOGGING means that errors will be logged
 * and corrupt data may be returned to applications. This mode should
 * be used ONLY for diagnostics and debugging. It cannot be used
 * unless AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is also
 * used.
 *
 * AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO means that either
 * AVB_HASHTREE_ERROR_MODE_RESTART or AVB_HASHTREE_ERROR_MODE_EIO is used
 * depending on state. This mode implements a state machine whereby
 * AVB_HASHTREE_ERROR_MODE_RESTART is used by default and when
 * AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION is passed the
 * mode transitions to AVB_HASHTREE_ERROR_MODE_EIO. When a new OS has been
 * detected the device transitions back to the AVB_HASHTREE_ERROR_MODE_RESTART
 * mode. To do this persistent storage is needed - specifically this means that
 * the passed in AvbOps will need to have the read_persistent_value() and
 * write_persistent_value() operations implemented. The name of the persistent
 * value used is "avb.managed_verity_mode" and 32 bytes of storage is needed.
 */
typedef enum {
  AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE,
  AVB_HASHTREE_ERROR_MODE_RESTART,
  AVB_HASHTREE_ERROR_MODE_EIO,
  AVB_HASHTREE_ERROR_MODE_LOGGING,
  AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO
} AvbHashtreeErrorMode;

/* Flags that influence how avb_slot_verify() works.
 *
 * If AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is NOT set then
 * avb_slot_verify() will bail out as soon as an error is encountered
 * and |out_data| is set only if AVB_SLOT_VERIFY_RESULT_OK is
 * returned.
 *
 * Otherwise if AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is set
 * avb_slot_verify() will continue verification efforts and |out_data|
 * is also set if AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED,
 * AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION, or
 * AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX is returned. It is
 * undefined which error is returned if more than one distinct error
 * is encountered. It is guaranteed that AVB_SLOT_VERIFY_RESULT_OK is
 * returned if, and only if, there are no errors. This mode is needed
 * to boot valid but unverified slots when the device is unlocked.
 *
 * Also, if AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is set the
 * contents loaded from |requested_partition| will be the contents of
 * the entire partition instead of just the size specified in the hash
 * descriptor.
 *
 * The AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION flag
 * should be set if using AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO
 * and the reason the boot loader is running is because the device
 * was restarted by the dm-verity driver.
 *
 * If the AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION flag is set then
 * data won't be loaded from the "vbmeta" partition and the
 * |validate_vbmeta_public_key| operation is never called. Instead, the
 * vbmeta structs in |requested_partitions| are loaded and processed and the
 * |validate_public_key_for_partition| operation is called for each of these
 * vbmeta structs. This flag is useful when booting into recovery on a device
 * not using A/B - see section "Booting into recovery" in README.md for
 * more information.
 */
typedef enum {
  AVB_SLOT_VERIFY_FLAGS_NONE = 0,
  AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR = (1 << 0),
  AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION = (1 << 1),
  AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION = (1 << 2),
} AvbSlotVerifyFlags;

/* Get a textual representation of |result|. */
const char* avb_slot_verify_result_to_string(AvbSlotVerifyResult result);

/* Maximum number of rollback index locations supported. */
#define AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS 32

/* AvbPartitionData contains data loaded from partitions when using
 * avb_slot_verify(). The |partition_name| field contains the name of
 * the partition (without A/B suffix), |data| points to the loaded
 * data which is |data_size| bytes long. If |preloaded| is set to true,
 * this structure dose not own |data|. The caller of |avb_slot_verify|
 * needs to make sure that the preloaded data outlives this
 * |AvbPartitionData| structure.
 *
 * Note that this is strictly less than the partition size - it's only
 * the image stored there, not the entire partition nor any of the
 * metadata.
 */
typedef struct {
  char* partition_name;
  uint8_t* data;
  size_t data_size;
  bool preloaded;
} AvbPartitionData;

/* AvbVBMetaData contains a vbmeta struct loaded from a partition when
 * using avb_slot_verify(). The |partition_name| field contains the
 * name of the partition (without A/B suffix), |vbmeta_data| points to
 * the loaded data which is |vbmeta_size| bytes long.
 *
 * The |verify_result| field contains the result of
 * avb_vbmeta_image_verify() on the data. This is guaranteed to be
 * AVB_VBMETA_VERIFY_RESULT_OK for all vbmeta images if
 * avb_slot_verify() returns AVB_SLOT_VERIFY_RESULT_OK.
 *
 * You can use avb_descriptor_get_all(), avb_descriptor_foreach(), and
 * avb_vbmeta_image_header_to_host_byte_order() with this data.
 */
typedef struct {
  char* partition_name;
  uint8_t* vbmeta_data;
  size_t vbmeta_size;
  AvbVBMetaVerifyResult verify_result;
} AvbVBMetaData;

/* AvbSlotVerifyData contains data needed to boot a particular slot
 * and is returned by avb_slot_verify() if partitions in a slot are
 * successfully verified.
 *
 * All data pointed to by this struct - including data in each item in
 * the |partitions| array - will be freed when the
 * avb_slot_verify_data_free() function is called.
 *
 * The |ab_suffix| field is the copy of the of |ab_suffix| field
 * passed to avb_slot_verify(). It is the A/B suffix of the slot. This
 * value includes the leading underscore - typical values are "" (if
 * no slots are in use), "_a" (for the first slot), and "_b" (for the
 * second slot).
 *
 * The VBMeta images that were checked are available in the
 * |vbmeta_images| field. The field |num_vbmeta_images| contains the
 * number of elements in this array. The first element -
 * vbmeta_images[0] - is guaranteed to be from the partition with the
 * top-level vbmeta struct. This is usually the "vbmeta" partition in
 * the requested slot but if there is no "vbmeta" partition it can
 * also be the "boot" partition.
 *
 * The partitions loaded and verified from from the slot are
 * accessible in the |loaded_partitions| array. The field
 * |num_loaded_partitions| contains the number of elements in this
 * array. The order of partitions in this array may not necessarily be
 * the same order as in the passed-in |requested_partitions| array.
 *
 * Rollback indexes for the verified slot are stored in the
 * |rollback_indexes| field. Note that avb_slot_verify() will NEVER
 * modify stored_rollback_index[n] locations e.g. it will never use
 * the write_rollback_index() AvbOps operation. Instead it is the job
 * of the caller of avb_slot_verify() to do this based on e.g. A/B
 * policy and other factors. See libavb_ab/avb_ab_flow.c for an
 * example of how to do this.
 *
 * The |cmdline| field is a NUL-terminated string in UTF-8 resulting
 * from concatenating all |AvbKernelCmdlineDescriptor| and then
 * performing proper substitution of the variables
 * $(ANDROID_SYSTEM_PARTUUID), $(ANDROID_BOOT_PARTUUID), and
 * $(ANDROID_VBMETA_PARTUUID) using the
 * get_unique_guid_for_partition() operation in |AvbOps|. Additionally
 * $(ANDROID_VERITY_MODE) will be replaced with the proper dm-verity
 * option depending on the value of |hashtree_error_mode|.
 *
 * Additionally, the |cmdline| field will have the following kernel
 * command-line options set (unless verification is disabled, see
 * below):
 *
 *   androidboot.veritymode: This is set to 'disabled' if the
 *   AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED flag is set in top-level
 *   vbmeta struct. Otherwise it is set to 'enforcing' if the
 *   passed-in hashtree error mode is AVB_HASHTREE_ERROR_MODE_RESTART
 *   or AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE, 'eio' if it's
 *   set to AVB_HASHTREE_ERROR_MODE_EIO, and 'logging' if it's set to
 *   AVB_HASHTREE_ERROR_MODE_LOGGING.
 *
 *   androidboot.veritymode.managed: This is set to 'yes' only
 *   if hashtree validation isn't disabled and the passed-in hashtree
 *   error mode is AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO.
 *
 *   androidboot.vbmeta.invalidate_on_error: This is set to 'yes' only
 *   if hashtree validation isn't disabled and the passed-in hashtree
 *   error mode is AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE.
 *
 *   androidboot.vbmeta.device_state: set to "locked" or "unlocked"
 *   depending on the result of the result of AvbOps's
 *   read_is_unlocked() function.
 *
 *   androidboot.vbmeta.{hash_alg, size, digest}: Will be set to
 *   the digest of all images in |vbmeta_images|.
 *
 *   androidboot.vbmeta.device: This is set to the value
 *   PARTUUID=$(ANDROID_VBMETA_PARTUUID) before substitution so it
 *   will end up pointing to the vbmeta partition for the verified
 *   slot. If there is no vbmeta partition it will point to the boot
 *   partition of the verified slot. If the flag
 *   AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION is used, this is not
 *   set.
 *
 *   androidboot.vbmeta.avb_version: This is set to the decimal value
 *   of AVB_VERSION_MAJOR followed by a dot followed by the decimal
 *   value of AVB_VERSION_MINOR, for example "1.0" or "1.4". This
 *   version number represents the vbmeta file format version
 *   supported by libavb copy used in the boot loader. This is not
 *   necessarily the same version number of the on-disk metadata for
 *   the slot that was verified.
 *
 * Note that androidboot.slot_suffix is not set in the |cmdline| field
 * in |AvbSlotVerifyData| - you will have to set this yourself.
 *
 * If the |AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED| flag is set
 * in the top-level vbmeta struct then only the top-level vbmeta
 * struct is verified and descriptors will not processed. The return
 * value will be set accordingly (if this flag is set via 'avbctl
 * disable-verification' then the return value will be
 * |AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION|) and
 * |AvbSlotVerifyData| is returned. Additionally all partitions in the
 * |requested_partitions| are loaded and the |cmdline| field is set to
 * "root=PARTUUID=$(ANDROID_SYSTEM_PARTUUID)" and the GUID for the
 * appropriate system partition is substituted in. Note that none of
 * the androidboot.* options mentioned above will be set.
 *
 * The |resolved_hashtree_error_mode| is the the value of the passed
 * avb_slot_verify()'s |hashtree_error_mode| parameter except that it never has
 * the value AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO. If this value was
 * passed in, then the restart/eio state machine is used resulting in
 * |resolved_hashtree_error_mode| being set to either
 * AVB_HASHTREE_ERROR_MODE_RESTART or AVB_HASHTREE_ERROR_MODE_EIO.  If set to
 * AVB_HASHTREE_ERROR_MODE_EIO the boot loader should present a RED warning
 * screen for the user to click through before continuing to boot.
 *
 * This struct may grow in the future without it being considered an
 * ABI break.
 */
typedef struct {
  char* ab_suffix;
  AvbVBMetaData* vbmeta_images;
  size_t num_vbmeta_images;
  AvbPartitionData* loaded_partitions;
  size_t num_loaded_partitions;
  char* cmdline;
  uint64_t rollback_indexes[AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS];
  AvbHashtreeErrorMode resolved_hashtree_error_mode;
} AvbSlotVerifyData;

/* Calculates a digest of all vbmeta images in |data| using
 * the digest indicated by |digest_type|. Stores the result
 * in |out_digest| which must be large enough to hold a digest
 * of the requested type.
 */
void avb_slot_verify_data_calculate_vbmeta_digest(AvbSlotVerifyData* data,
                                                  AvbDigestType digest_type,
                                                  uint8_t* out_digest);

/* Frees a |AvbSlotVerifyData| including all data it points to. */
void avb_slot_verify_data_free(AvbSlotVerifyData* data);

/* Performs a full verification of the slot identified by |ab_suffix|
 * and load and verify the contents of the partitions whose name is in
 * the NULL-terminated string array |requested_partitions| (each
 * partition must use hash verification). If not using A/B, pass an
 * empty string (e.g. "", not NULL) for |ab_suffix|. This parameter
 * must include the leading underscore, for example "_a" should be
 * used to refer to the first slot.
 *
 * Typically the |requested_partitions| array only contains a single
 * item for the boot partition, 'boot'.
 *
 * Verification includes loading and verifying data from the 'vbmeta',
 * the requested hash partitions, and possibly other partitions (with
 * |ab_suffix| appended), inspecting rollback indexes, and checking if
 * the public key used to sign the data is acceptable. The functions
 * in |ops| will be used to do this.
 *
 * If |out_data| is not NULL, it will be set to a newly allocated
 * |AvbSlotVerifyData| struct containing all the data needed to
 * actually boot the slot. This data structure should be freed with
 * avb_slot_verify_data_free() when you are done with it. See below
 * for when this is returned.
 *
 * The |flags| parameter is used to influence the semantics of
 * avb_slot_verify() - for example the
 * AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR flag can be used to
 * ignore verification errors which is something needed in the
 * UNLOCKED state. See the AvbSlotVerifyFlags enumeration for details.
 *
 * The |hashtree_error_mode| parameter should be set to the desired error
 * handling mode. See the AvbHashtreeErrorMode enumeration for details.
 *
 * Also note that |out_data| is never set if
 * AVB_SLOT_VERIFY_RESULT_ERROR_OOM, AVB_SLOT_VERIFY_RESULT_ERROR_IO,
 * or AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA is returned.
 *
 * AVB_SLOT_VERIFY_RESULT_OK is returned if everything is verified
 * correctly and all public keys are accepted.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED is returned if
 * everything is verified correctly out but one or more public keys
 * are not accepted. This includes the case where integrity data is
 * not signed.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_OOM is returned if unable to
 * allocate memory.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_IO is returned if an I/O error
 * occurred while trying to load data or get a rollback index.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION is returned if the data
 * did not verify, e.g. the digest didn't match or signature checks
 * failed.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX is returned if a
 * rollback index was less than its stored value.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA is returned if some
 * of the metadata is invalid or inconsistent.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION is returned if
 * some of the metadata requires a newer version of libavb than what
 * is in use.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT is returned if the
 * caller passed invalid parameters, for example trying to use
 * AVB_HASHTREE_ERROR_MODE_LOGGING without
 * AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR.
 */
AvbSlotVerifyResult avb_slot_verify(AvbOps* ops,
                                    const char* const* requested_partitions,
                                    const char* ab_suffix,
                                    AvbSlotVerifyFlags flags,
                                    AvbHashtreeErrorMode hashtree_error_mode,
                                    AvbSlotVerifyData** out_data);

#ifdef __cplusplus
}
#endif

#endif /* AVB_SLOT_VERIFY_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_sysdeps.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_SYSDEPS_H_
#define AVB_SYSDEPS_H_

#ifdef __cplusplus
extern "C" {
#endif

/* Change these includes to match your platform to bring in the
 * equivalent types available in a normal C runtime. At least things
 * like uint8_t, uint64_t, and bool (with |false|, |true| keywords)
 * must be present.
 */
#include <inttypes.h>
#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>

/* If you don't have gcc or clang, these attribute macros may need to
 * be adjusted.
 */
#define AVB_ATTR_WARN_UNUSED_RESULT __attribute__((warn_unused_result))
#define AVB_ATTR_PACKED __attribute__((packed))
#define AVB_ATTR_NO_RETURN __attribute__((noreturn))
#define AVB_ATTR_SENTINEL __attribute__((__sentinel__))

/* Size in bytes used for alignment. */
#ifdef __LP64__
#define AVB_ALIGNMENT_SIZE 8
#else
#define AVB_ALIGNMENT_SIZE 4
#endif

/* Compare |n| bytes in |src1| and |src2|.
 *
 * Returns an integer less than, equal to, or greater than zero if the
 * first |n| bytes of |src1| is found, respectively, to be less than,
 * to match, or be greater than the first |n| bytes of |src2|. */
int avb_memcmp(const void* src1,
               const void* src2,
               size_t n) AVB_ATTR_WARN_UNUSED_RESULT;

/* Compare two strings.
 *
 * Return an integer less than, equal to, or greater than zero if |s1|
 * is found, respectively, to be less than, to match, or be greater
 * than |s2|.
 */
int avb_strcmp(const char* s1, const char* s2);

/* Compare |n| bytes in two strings.
 *
 * Return an integer less than, equal to, or greater than zero if the
 * first |n| bytes of |s1| is found, respectively, to be less than,
 * to match, or be greater than the first |n| bytes of |s2|.
 */
int avb_strncmp(const char* s1, const char* s2, size_t n);

/* Copy |n| bytes from |src| to |dest|. */
void* avb_memcpy(void* dest, const void* src, size_t n);

/* Set |n| bytes starting at |s| to |c|.  Returns |dest|. */
void* avb_memset(void* dest, const int c, size_t n);

/* Prints out a message. The string passed must be a NUL-terminated
 * UTF-8 string.
 */
void avb_print(const char* message);

/* Prints out a vector of strings. Each argument must point to a
 * NUL-terminated UTF-8 string and NULL should be the last argument.
 */
void avb_printv(const char* message, ...) AVB_ATTR_SENTINEL;

/* Aborts the program or reboots the device. */
void avb_abort(void) AVB_ATTR_NO_RETURN;

/* Allocates |size| bytes. Returns NULL if no memory is available,
 * otherwise a pointer to the allocated memory.
 *
 * The memory is not initialized.
 *
 * The pointer returned is guaranteed to be word-aligned.
 *
 * The memory should be freed with avb_free() when you are done with it.
 */
void* avb_malloc_(size_t size) AVB_ATTR_WARN_UNUSED_RESULT;

/* Frees memory previously allocated with avb_malloc(). */
void avb_free(void* ptr);

/* Returns the lenght of |str|, excluding the terminating NUL-byte. */
size_t avb_strlen(const char* str) AVB_ATTR_WARN_UNUSED_RESULT;

/* Divide the |dividend| by 10 and saves back to the pointer. Return the
 * remainder. */
uint32_t avb_div_by_10(uint64_t* dividend);

#ifdef __cplusplus
}
#endif

#endif /* AVB_SYSDEPS_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_util.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_UTIL_H_
#define AVB_UTIL_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

#define AVB_STRINGIFY(x) #x
#define AVB_TO_STRING(x) AVB_STRINGIFY(x)

#ifdef AVB_ENABLE_DEBUG
/* Aborts the program if |expr| is false.
 *
 * This has no effect unless AVB_ENABLE_DEBUG is defined.
 */
#define avb_assert(expr)                     \
  do {                                       \
    if (!(expr)) {                           \
      avb_fatal("assert fail: " #expr "\n"); \
    }                                        \
  } while (0)
#else
#define avb_assert(expr)
#endif

/* Aborts the program if reached.
 *
 * This has no effect unless AVB_ENABLE_DEBUG is defined.
 */
#ifdef AVB_ENABLE_DEBUG
#define avb_assert_not_reached()         \
  do {                                   \
    avb_fatal("assert_not_reached()\n"); \
  } while (0)
#else
#define avb_assert_not_reached()
#endif

/* Aborts the program if |addr| is not word-aligned.
 *
 * This has no effect unless AVB_ENABLE_DEBUG is defined.
 */
#define avb_assert_aligned(addr) \
  avb_assert((((uintptr_t)addr) & (AVB_ALIGNMENT_SIZE - 1)) == 0)

#ifdef AVB_ENABLE_DEBUG
/* Print functions, used for diagnostics.
 *
 * These have no effect unless AVB_ENABLE_DEBUG is defined.
 */
#define avb_debug(message)              \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": DEBUG: ",             \
               message,                 \
               NULL);                   \
  } while (0)
#define avb_debugv(message, ...)        \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": DEBUG: ",             \
               message,                 \
               ##__VA_ARGS__);          \
  } while (0)
#else
#define avb_debug(message)
#define avb_debugv(message, ...)
#endif

/* Prints out a message. This is typically used if a runtime-error
 * occurs.
 */
#define avb_error(message)              \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": ERROR: ",             \
               message,                 \
               NULL);                   \
  } while (0)
#define avb_errorv(message, ...)        \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": ERROR: ",             \
               message,                 \
               ##__VA_ARGS__);          \
  } while (0)

/* Prints out a message and calls avb_abort().
 */
#define avb_fatal(message)              \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": FATAL: ",             \
               message,                 \
               NULL);                   \
    avb_abort();                        \
  } while (0)
#define avb_fatalv(message, ...)        \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": FATAL: ",             \
               message,                 \
               ##__VA_ARGS__);          \
    avb_abort();                        \
  } while (0)

/* Converts a 32-bit unsigned integer from big-endian to host byte order. */
uint32_t avb_be32toh(uint32_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 64-bit unsigned integer from big-endian to host byte order. */
uint64_t avb_be64toh(uint64_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 32-bit unsigned integer from host to big-endian byte order. */
uint32_t avb_htobe32(uint32_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 64-bit unsigned integer from host to big-endian byte order. */
uint64_t avb_htobe64(uint64_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Compare |n| bytes starting at |s1| with |s2| and return 0 if they
 * match, 1 if they don't.  Returns 0 if |n|==0, since no bytes
 * mismatched.
 *
 * Time taken to perform the comparison is only dependent on |n| and
 * not on the relationship of the match between |s1| and |s2|.
 *
 * Note that unlike avb_memcmp(), this only indicates inequality, not
 * whether |s1| is less than or greater than |s2|.
 */
int avb_safe_memcmp(const void* s1,
                    const void* s2,
                    size_t n) AVB_ATTR_WARN_UNUSED_RESULT;

/* Adds |value_to_add| to |value| with overflow protection.
 *
 * Returns false if the addition overflows, true otherwise. In either
 * case, |value| is always modified.
 */
bool avb_safe_add_to(uint64_t* value,
                     uint64_t value_to_add) AVB_ATTR_WARN_UNUSED_RESULT;

/* Adds |a| and |b| with overflow protection, returning the value in
 * |out_result|.
 *
 * It's permissible to pass NULL for |out_result| if you just want to
 * check that the addition would not overflow.
 *
 * Returns false if the addition overflows, true otherwise.
 */
bool avb_safe_add(uint64_t* out_result,
                  uint64_t a,
                  uint64_t b) AVB_ATTR_WARN_UNUSED_RESULT;

/* Checks if |num_bytes| data at |data| is a valid UTF-8
 * string. Returns true if valid UTF-8, false otherwise.
 */
bool avb_validate_utf8(const uint8_t* data,
                       size_t num_bytes) AVB_ATTR_WARN_UNUSED_RESULT;

/* Concatenates |str1| (of |str1_len| bytes) and |str2| (of |str2_len|
 * bytes) and puts the result in |buf| which holds |buf_size|
 * bytes. The result is also guaranteed to be NUL terminated. Fail if
 * there is not enough room in |buf| for the resulting string plus
 * terminating NUL byte.
 *
 * Returns true if the operation succeeds, false otherwise.
 */
bool avb_str_concat(char* buf,
                    size_t buf_size,
                    const char* str1,
                    size_t str1_len,
                    const char* str2,
                    size_t str2_len);

/* Like avb_malloc_() but prints a error using avb_error() if memory
 * allocation fails.
 */
void* avb_malloc(size_t size) AVB_ATTR_WARN_UNUSED_RESULT;

/* Like avb_malloc() but sets the memory with zeroes. */
void* avb_calloc(size_t size) AVB_ATTR_WARN_UNUSED_RESULT;

/* Duplicates a NUL-terminated string. Returns NULL on OOM. */
char* avb_strdup(const char* str) AVB_ATTR_WARN_UNUSED_RESULT;

/* Duplicates a NULL-terminated array of NUL-terminated strings by
 * concatenating them. The returned string will be
 * NUL-terminated. Returns NULL on OOM.
 */
char* avb_strdupv(const char* str,
                  ...) AVB_ATTR_WARN_UNUSED_RESULT AVB_ATTR_SENTINEL;

/* Finds the first occurrence of |needle| in the string |haystack|
 * where both strings are NUL-terminated strings. The terminating NUL
 * bytes are not compared.
 *
 * Returns NULL if not found, otherwise points into |haystack| for the
 * first occurrence of |needle|.
 */
const char* avb_strstr(const char* haystack,
                       const char* needle) AVB_ATTR_WARN_UNUSED_RESULT;

/* Finds the first occurrence of |str| in the NULL-terminated string
 * array |strings|. Each element in |strings| must be
 * NUL-terminated. The string given by |str| need not be
 * NUL-terminated but its size must be given in |str_size|.
 *
 * Returns NULL if not found, otherwise points into |strings| for the
 * first occurrence of |str|.
 */
const char* avb_strv_find_str(const char* const* strings,
                              const char* str,
                              size_t str_size);

/* Replaces all occurrences of |search| with |replace| in |str|.
 *
 * Returns a newly allocated string or NULL if out of memory.
 */
char* avb_replace(const char* str,
                  const char* search,
                  const char* replace) AVB_ATTR_WARN_UNUSED_RESULT;

/* Calculates the CRC-32 for data in |buf| of size |buf_size|. */
uint32_t avb_crc32(const uint8_t* buf, size_t buf_size);

/* Returns the basename of |str|. This is defined as the last path
 * component, assuming the normal POSIX separator '/'. If there are no
 * separators, returns |str|.
 */
const char* avb_basename(const char* str);

/* Converts any ascii lowercase characters in |str| to uppercase in-place.
 * |str| must be NUL-terminated and valid UTF-8.
 */
void avb_uppercase(char* str);

/* Converts |data_len| bytes of |data| to hex and returns the result. Returns
 * NULL on OOM. Caller must free the returned string with avb_free.
 */
char* avb_bin2hex(const uint8_t* data, size_t data_len);

#ifdef __cplusplus
}
#endif

#endif /* AVB_UTIL_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_vbmeta_image.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_VBMETA_IMAGE_H_
#define AVB_VBMETA_IMAGE_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_crypto.h"
#include "avb_descriptor.h"

/* Size of the vbmeta image header. */
#define AVB_VBMETA_IMAGE_HEADER_SIZE 256

/* Magic for the vbmeta image header. */
#define AVB_MAGIC "AVB0"
#define AVB_MAGIC_LEN 4

/* Maximum size of the release string including the terminating NUL byte. */
#define AVB_RELEASE_STRING_SIZE 48

/* Flags for the vbmeta image.
 *
 * AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED: If this flag is set,
 * hashtree image verification will be disabled.
 *
 * AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED: If this flag is set,
 * verification will be disabled and descriptors will not be parsed.
 */
typedef enum {
  AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED = (1 << 0),
  AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED = (1 << 1)
} AvbVBMetaImageFlags;

/* Binary format for header of the vbmeta image.
 *
 * The vbmeta image consists of three blocks:
 *
 *  +-----------------------------------------+
 *  | Header data - fixed size                |
 *  +-----------------------------------------+
 *  | Authentication data - variable size     |
 *  +-----------------------------------------+
 *  | Auxiliary data - variable size          |
 *  +-----------------------------------------+
 *
 * The "Header data" block is described by this struct and is always
 * |AVB_VBMETA_IMAGE_HEADER_SIZE| bytes long.
 *
 * The "Authentication data" block is |authentication_data_block_size|
 * bytes long and contains the hash and signature used to authenticate
 * the vbmeta image. The type of the hash and signature is defined by
 * the |algorithm_type| field.
 *
 * The "Auxiliary data" is |auxiliary_data_block_size| bytes long and
 * contains the auxiliary data including the public key used to make
 * the signature and descriptors.
 *
 * The public key is at offset |public_key_offset| with size
 * |public_key_size| in this block. The size of the public key data is
 * defined by the |algorithm_type| field. The format of the public key
 * data is described in the |AvbRSAPublicKeyHeader| struct.
 *
 * The descriptors starts at |descriptors_offset| from the beginning
 * of the "Auxiliary Data" block and take up |descriptors_size|
 * bytes. Each descriptor is stored as a |AvbDescriptor| with tag and
 * number of bytes following. The number of descriptors can be
 * determined by walking this data until |descriptors_size| is
 * exhausted.
 *
 * The size of each of the "Authentication data" and "Auxiliary data"
 * blocks must be divisible by 64. This is to ensure proper alignment.
 *
 * Descriptors are free-form blocks stored in a part of the vbmeta
 * image subject to the same integrity checks as the rest of the
 * image. See the documentation for |AvbDescriptor| for well-known
 * descriptors. See avb_descriptor_foreach() for a convenience
 * function to iterate over descriptors.
 *
 * This struct is versioned, see the |required_libavb_version_major|
 * and |required_libavb_version_minor| fields. This represents the
 * minimum version of libavb required to verify the header and depends
 * on the features (e.g. algorithms, descriptors) used. Note that this
 * may be 1.0 even if generated by an avbtool from 1.4 but where no
 * features introduced after 1.0 has been used. See the "Versioning
 * and compatibility" section in the README.md file for more details.
 *
 * All fields are stored in network byte order when serialized. To
 * generate a copy with fields swapped to native byte order, use the
 * function avb_vbmeta_image_header_to_host_byte_order().
 *
 * Before reading and/or using any of this data, you MUST verify it
 * using avb_vbmeta_image_verify() and reject it unless it's signed by
 * a known good public key.
 */
typedef struct AvbVBMetaImageHeader {
  /*   0: Four bytes equal to "AVB0" (AVB_MAGIC). */
  uint8_t magic[AVB_MAGIC_LEN];

  /*   4: The major version of libavb required for this header. */
  uint32_t required_libavb_version_major;
  /*   8: The minor version of libavb required for this header. */
  uint32_t required_libavb_version_minor;

  /*  12: The size of the signature block. */
  uint64_t authentication_data_block_size;
  /*  20: The size of the auxiliary data block. */
  uint64_t auxiliary_data_block_size;

  /*  28: The verification algorithm used, see |AvbAlgorithmType| enum. */
  uint32_t algorithm_type;

  /*  32: Offset into the "Authentication data" block of hash data. */
  uint64_t hash_offset;
  /*  40: Length of the hash data. */
  uint64_t hash_size;

  /*  48: Offset into the "Authentication data" block of signature data. */
  uint64_t signature_offset;
  /*  56: Length of the signature data. */
  uint64_t signature_size;

  /*  64: Offset into the "Auxiliary data" block of public key data. */
  uint64_t public_key_offset;
  /*  72: Length of the public key data. */
  uint64_t public_key_size;

  /*  80: Offset into the "Auxiliary data" block of public key metadata. */
  uint64_t public_key_metadata_offset;
  /*  88: Length of the public key metadata. Must be set to zero if there
   *  is no public key metadata.
   */
  uint64_t public_key_metadata_size;

  /*  96: Offset into the "Auxiliary data" block of descriptor data. */
  uint64_t descriptors_offset;
  /* 104: Length of descriptor data. */
  uint64_t descriptors_size;

  /* 112: The rollback index which can be used to prevent rollback to
   *  older versions.
   */
  uint64_t rollback_index;

  /* 120: Flags from the AvbVBMetaImageFlags enumeration. This must be
   * set to zero if the vbmeta image is not a top-level image.
   */
  uint32_t flags;

  /* 124: Reserved to ensure |release_string| start on a 16-byte
   * boundary. Must be set to zeroes.
   */
  uint8_t reserved0[4];

  /* 128: The release string from avbtool, e.g. "avbtool 1.0.0" or
   * "avbtool 1.0.0 xyz_board Git-234abde89". Is guaranteed to be NUL
   * terminated. Applications must not make assumptions about how this
   * string is formatted.
   */
  uint8_t release_string[AVB_RELEASE_STRING_SIZE];

  /* 176: Padding to ensure struct is size AVB_VBMETA_IMAGE_HEADER_SIZE
   * bytes. This must be set to zeroes.
   */
  uint8_t reserved[80];
} AVB_ATTR_PACKED AvbVBMetaImageHeader;

/* Copies |src| to |dest|, byte-swapping fields in the process.
 *
 * Make sure you've verified |src| using avb_vbmeta_image_verify()
 * before accessing the data and/or using this function.
 */
void avb_vbmeta_image_header_to_host_byte_order(const AvbVBMetaImageHeader* src,
                                                AvbVBMetaImageHeader* dest);

/* Return codes used in avb_vbmeta_image_verify().
 *
 * AVB_VBMETA_VERIFY_RESULT_OK is returned if the vbmeta image header
 * is valid, the hash is correct and the signature is correct. Keep in
 * mind that you still need to check that you know the public key used
 * to sign the image, see avb_vbmeta_image_verify() for details.
 *
 * AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED is returned if the vbmeta
 * image header is valid but there is no signature or hash.
 *
 * AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER is returned if the
 * header of the vbmeta image is invalid, for example, invalid magic
 * or inconsistent data.
 *
 * AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION is returned if a) the
 * vbmeta image requires a minimum version of libavb which exceeds the
 * version of libavb used; or b) the vbmeta image major version
 * differs from the major version of libavb in use.
 *
 * AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH is returned if the hash
 * stored in the "Authentication data" block does not match the
 * calculated hash.
 *
 * AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH is returned if the
 * signature stored in the "Authentication data" block is invalid or
 * doesn't match the public key stored in the vbmeta image.
 */
typedef enum {
  AVB_VBMETA_VERIFY_RESULT_OK,
  AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED,
  AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER,
  AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION,
  AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH,
  AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH,
} AvbVBMetaVerifyResult;

/* Get a textual representation of |result|. */
const char* avb_vbmeta_verify_result_to_string(AvbVBMetaVerifyResult result);

/* Checks that vbmeta image at |data| of size |length| is a valid
 * vbmeta image. The complete contents of the vbmeta image must be
 * passed in. It's fine if |length| is bigger than the actual image,
 * typically callers of this function will load the entire contents of
 * the 'vbmeta_a' or 'vbmeta_b' partition and pass in its length (for
 * example, 1 MiB).
 *
 * See the |AvbVBMetaImageHeader| struct for information about the
 * three blocks (header, authentication, auxiliary) that make up a
 * vbmeta image.
 *
 * If the function returns |AVB_VBMETA_VERIFY_RESULT_OK| and
 * |out_public_key_data| is non-NULL, it will be set to point inside
 * |data| for where the serialized public key data is stored and
 * |out_public_key_length|, if non-NULL, will be set to the length of
 * the public key data. If there is no public key in the metadata then
 * |out_public_key_data| is set to NULL.
 *
 * See the |AvbVBMetaVerifyResult| enum for possible return values.
 *
 * VERY IMPORTANT:
 *
 *   1. Even if |AVB_VBMETA_VERIFY_RESULT_OK| is returned, you still
 *      need to check that the public key embedded in the image
 *      matches a known key! You can use 'avbtool extract_public_key'
 *      to extract the key (at build time, then store it along your
 *      code) and compare it to what is returned in
 *      |out_public_key_data|.
 *
 *   2. You need to check the |rollback_index| field against a stored
 *      value in NVRAM and reject the vbmeta image if the value in
 *      NVRAM is bigger than |rollback_index|. You must also update
 *      the value stored in NVRAM to the smallest value of
 *      |rollback_index| field from boot images in all bootable and
 *      authentic slots marked as GOOD.
 *
 * This is a low-level function to only verify the vbmeta data - you
 * are likely looking for avb_slot_verify() instead for verifying
 * integrity data for a whole set of partitions.
 */
AvbVBMetaVerifyResult avb_vbmeta_image_verify(
    const uint8_t* data,
    size_t length,
    const uint8_t** out_public_key_data,
    size_t* out_public_key_length) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_VBMETA_IMAGE_H_ */

```

`aosp/libavb1.1/src/avb/headers/avb_version.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_VERSION_H_
#define AVB_VERSION_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* The version number of AVB - keep in sync with avbtool. */
#define AVB_VERSION_MAJOR 1
#define AVB_VERSION_MINOR 1
#define AVB_VERSION_SUB 0

/* Returns a NUL-terminated string for the libavb version in use.  The
 * returned string usually looks like "%d.%d.%d". Applications must
 * not make assumptions about the content of this string.
 *
 * Boot loaders should display this string in debug/diagnostics output
 * to aid with debugging.
 *
 * This is similar to the string put in the |release_string| string
 * field in the VBMeta struct by avbtool.
 */
const char* avb_version_string(void);

#ifdef __cplusplus
}
#endif

#endif /* AVB_VERSION_H_ */

```

`aosp/libavb1.1/src/avb/headers/libavb.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef LIBAVB_H_
#define LIBAVB_H_

/* The AVB_INSIDE_LIBAVB_H preprocessor symbol is used to enforce
 * library users to include only this file. All public interfaces, and
 * only public interfaces, must be included here.
 */

#define AVB_INSIDE_LIBAVB_H
#include "avb_chain_partition_descriptor.h"
#include "avb_crypto.h"
#include "avb_descriptor.h"
#include "avb_footer.h"
#include "avb_hash_descriptor.h"
#include "avb_hashtree_descriptor.h"
#include "avb_kernel_cmdline_descriptor.h"
#include "avb_ops.h"
#include "avb_property_descriptor.h"
#include "avb_slot_verify.h"
#include "avb_sysdeps.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"
#include "avb_version.h"
#undef AVB_INSIDE_LIBAVB_H

#endif /* LIBAVB_H_ */

```

`aosp/libavb1.2/build.gradle`:

```gradle
apply plugin: "c"

model {
    buildTypes {
        release
    }

    components {
        avb(NativeLibrarySpec) {
            binaries.all {
                cCompiler.define "_FILE_OFFSET_BITS", "64" 
                cCompiler.define "_POSIX_C_SOURCE", "199309L" 
                cCompiler.define "AVB_ENABLE_DEBUG"
                cCompiler.define "AVB_COMPILATION"
                cCompiler.args << "-Wall" << "-g"
            }
        }
    }
}

```

`aosp/libavb1.2/src/avb/c/avb_chain_partition_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_chain_partition_descriptor.h"
#include "avb_util.h"

bool avb_chain_partition_descriptor_validate_and_byteswap(
    const AvbChainPartitionDescriptor* src, AvbChainPartitionDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbChainPartitionDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_CHAIN_PARTITION) {
    avb_error("Invalid tag for chain partition descriptor.\n");
    return false;
  }

  dest->rollback_index_location = avb_be32toh(dest->rollback_index_location);
  dest->partition_name_len = avb_be32toh(dest->partition_name_len);
  dest->public_key_len = avb_be32toh(dest->public_key_len);

  if (dest->rollback_index_location < 1) {
    avb_error("Invalid rollback index location value.\n");
    return false;
  }

  /* Check that partition_name and public_key are fully contained. */
  expected_size = sizeof(AvbChainPartitionDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->partition_name_len) ||
      !avb_safe_add_to(&expected_size, dest->public_key_len)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }
  return true;
}

```

`aosp/libavb1.2/src/avb/c/avb_cmdline.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_cmdline.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_version.h"

#define NUM_GUIDS 3

/* Substitutes all variables (e.g. $(ANDROID_SYSTEM_PARTUUID)) with
 * values. Returns NULL on OOM, otherwise the cmdline with values
 * replaced.
 */
char* avb_sub_cmdline(AvbOps* ops,
                      const char* cmdline,
                      const char* ab_suffix,
                      bool using_boot_for_vbmeta,
                      const AvbCmdlineSubstList* additional_substitutions) {
  const char* part_name_str[NUM_GUIDS] = {"system", "boot", "vbmeta"};
  const char* replace_str[NUM_GUIDS] = {"$(ANDROID_SYSTEM_PARTUUID)",
                                        "$(ANDROID_BOOT_PARTUUID)",
                                        "$(ANDROID_VBMETA_PARTUUID)"};
  char* ret = NULL;
  AvbIOResult io_ret;
  size_t n;

  /* Special-case for when the top-level vbmeta struct is in the boot
   * partition.
   */
  if (using_boot_for_vbmeta) {
    part_name_str[2] = "boot";
  }

  /* Replace unique partition GUIDs */
  for (n = 0; n < NUM_GUIDS; n++) {
    char part_name[AVB_PART_NAME_MAX_SIZE];
    char guid_buf[37];

    /* Don't attempt to query the partition guid unless its search string is
     * present in the command line. Note: the original cmdline is used here,
     * not the replaced one. See b/116010959.
     */
    if (avb_strstr(cmdline, replace_str[n]) == NULL) {
      continue;
    }

    if (!avb_str_concat(part_name,
                        sizeof part_name,
                        part_name_str[n],
                        avb_strlen(part_name_str[n]),
                        ab_suffix,
                        avb_strlen(ab_suffix))) {
      avb_error("Partition name and suffix does not fit.\n");
      goto fail;
    }

    io_ret = ops->get_unique_guid_for_partition(
        ops, part_name, guid_buf, sizeof guid_buf);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      goto fail;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_error("Error getting unique GUID for partition.\n");
      goto fail;
    }

    if (ret == NULL) {
      ret = avb_replace(cmdline, replace_str[n], guid_buf);
    } else {
      char* new_ret = avb_replace(ret, replace_str[n], guid_buf);
      avb_free(ret);
      ret = new_ret;
    }
    if (ret == NULL) {
      goto fail;
    }
  }

  /* It's possible there is no _PARTUUID for replacement above.
   * Duplicate cmdline to ret for additional substitutions below.
   */
  if (ret == NULL) {
    ret = avb_strdup(cmdline);
    if (ret == NULL) {
      goto fail;
    }
  }

  /* Replace any additional substitutions. */
  if (additional_substitutions != NULL) {
    for (n = 0; n < additional_substitutions->size; ++n) {
      char* new_ret = avb_replace(ret,
                                  additional_substitutions->tokens[n],
                                  additional_substitutions->values[n]);
      avb_free(ret);
      ret = new_ret;
      if (ret == NULL) {
        goto fail;
      }
    }
  }

  return ret;

fail:
  if (ret != NULL) {
    avb_free(ret);
  }
  return NULL;
}

static int cmdline_append_option(AvbSlotVerifyData* slot_data,
                                 const char* key,
                                 const char* value) {
  size_t offset, key_len, value_len;
  char* new_cmdline;

  key_len = avb_strlen(key);
  value_len = avb_strlen(value);

  offset = 0;
  if (slot_data->cmdline != NULL) {
    offset = avb_strlen(slot_data->cmdline);
    if (offset > 0) {
      offset += 1;
    }
  }

  new_cmdline = avb_calloc(offset + key_len + value_len + 2);
  if (new_cmdline == NULL) {
    return 0;
  }
  if (offset > 0) {
    avb_memcpy(new_cmdline, slot_data->cmdline, offset - 1);
    new_cmdline[offset - 1] = ' ';
  }
  avb_memcpy(new_cmdline + offset, key, key_len);
  new_cmdline[offset + key_len] = '=';
  avb_memcpy(new_cmdline + offset + key_len + 1, value, value_len);
  if (slot_data->cmdline != NULL) {
    avb_free(slot_data->cmdline);
  }
  slot_data->cmdline = new_cmdline;

  return 1;
}

static int cmdline_append_version(AvbSlotVerifyData* slot_data,
                                  const char* key,
                                  uint64_t major_version,
                                  uint64_t minor_version) {
  char major_digits[AVB_MAX_DIGITS_UINT64];
  char minor_digits[AVB_MAX_DIGITS_UINT64];
  char combined[AVB_MAX_DIGITS_UINT64 * 2 + 1];
  size_t num_major_digits, num_minor_digits;

  num_major_digits = avb_uint64_to_base10(major_version, major_digits);
  num_minor_digits = avb_uint64_to_base10(minor_version, minor_digits);
  avb_memcpy(combined, major_digits, num_major_digits);
  combined[num_major_digits] = '.';
  avb_memcpy(combined + num_major_digits + 1, minor_digits, num_minor_digits);
  combined[num_major_digits + 1 + num_minor_digits] = '\0';

  return cmdline_append_option(slot_data, key, combined);
}

static int cmdline_append_uint64_base10(AvbSlotVerifyData* slot_data,
                                        const char* key,
                                        uint64_t value) {
  char digits[AVB_MAX_DIGITS_UINT64];
  avb_uint64_to_base10(value, digits);
  return cmdline_append_option(slot_data, key, digits);
}

static int cmdline_append_hex(AvbSlotVerifyData* slot_data,
                              const char* key,
                              const uint8_t* data,
                              size_t data_len) {
  int ret;
  char* hex_data = avb_bin2hex(data, data_len);
  if (hex_data == NULL) {
    return 0;
  }
  ret = cmdline_append_option(slot_data, key, hex_data);
  avb_free(hex_data);
  return ret;
}

AvbSlotVerifyResult avb_append_options(
    AvbOps* ops,
    AvbSlotVerifyFlags flags,
    AvbSlotVerifyData* slot_data,
    AvbVBMetaImageHeader* toplevel_vbmeta,
    AvbAlgorithmType algorithm_type,
    AvbHashtreeErrorMode hashtree_error_mode,
    AvbHashtreeErrorMode resolved_hashtree_error_mode) {
  AvbSlotVerifyResult ret;
  const char* verity_mode;
  bool is_device_unlocked;
  AvbIOResult io_ret;

  /* Add androidboot.vbmeta.device option... except if not using a vbmeta
   * partition since it doesn't make sense in that case.
   */
  if (!(flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION)) {
    if (!cmdline_append_option(slot_data,
                               "androidboot.vbmeta.device",
                               "PARTUUID=$(ANDROID_VBMETA_PARTUUID)")) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
  }

  /* Add androidboot.vbmeta.avb_version option. */
  if (!cmdline_append_version(slot_data,
                              "androidboot.vbmeta.avb_version",
                              AVB_VERSION_MAJOR,
                              AVB_VERSION_MINOR)) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }

  /* Set androidboot.avb.device_state to "locked" or "unlocked". */
  io_ret = ops->read_is_device_unlocked(ops, &is_device_unlocked);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error getting device state.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    goto out;
  }
  if (!cmdline_append_option(slot_data,
                             "androidboot.vbmeta.device_state",
                             is_device_unlocked ? "unlocked" : "locked")) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }

  /* Set androidboot.vbmeta.{hash_alg, size, digest} - use same hash
   * function as is used to sign vbmeta.
   */
  switch (algorithm_type) {
    /* Explicit fallthrough. */
    case AVB_ALGORITHM_TYPE_NONE:
    case AVB_ALGORITHM_TYPE_SHA256_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA256_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA256_RSA8192: {
      size_t n, total_size = 0;
      uint8_t vbmeta_digest[AVB_SHA256_DIGEST_SIZE];
      avb_slot_verify_data_calculate_vbmeta_digest(
          slot_data, AVB_DIGEST_TYPE_SHA256, vbmeta_digest);
      for (n = 0; n < slot_data->num_vbmeta_images; n++) {
        total_size += slot_data->vbmeta_images[n].vbmeta_size;
      }
      if (!cmdline_append_option(
              slot_data, "androidboot.vbmeta.hash_alg", "sha256") ||
          !cmdline_append_uint64_base10(
              slot_data, "androidboot.vbmeta.size", total_size) ||
          !cmdline_append_hex(slot_data,
                              "androidboot.vbmeta.digest",
                              vbmeta_digest,
                              AVB_SHA256_DIGEST_SIZE)) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto out;
      }
    } break;
    /* Explicit fallthrough. */
    case AVB_ALGORITHM_TYPE_SHA512_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA512_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA512_RSA8192: {
      size_t n, total_size = 0;
      uint8_t vbmeta_digest[AVB_SHA512_DIGEST_SIZE];
      avb_slot_verify_data_calculate_vbmeta_digest(
          slot_data, AVB_DIGEST_TYPE_SHA512, vbmeta_digest);
      for (n = 0; n < slot_data->num_vbmeta_images; n++) {
        total_size += slot_data->vbmeta_images[n].vbmeta_size;
      }
      if (!cmdline_append_option(
              slot_data, "androidboot.vbmeta.hash_alg", "sha512") ||
          !cmdline_append_uint64_base10(
              slot_data, "androidboot.vbmeta.size", total_size) ||
          !cmdline_append_hex(slot_data,
                              "androidboot.vbmeta.digest",
                              vbmeta_digest,
                              AVB_SHA512_DIGEST_SIZE)) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto out;
      }
    } break;
    case _AVB_ALGORITHM_NUM_TYPES:
      avb_assert_not_reached();
      break;
  }

  /* Set androidboot.veritymode and androidboot.vbmeta.invalidate_on_error */
  if (toplevel_vbmeta->flags & AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED) {
    verity_mode = "disabled";
  } else {
    const char* dm_verity_mode;
    char* new_ret;

    switch (resolved_hashtree_error_mode) {
      case AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE:
        if (!cmdline_append_option(
                slot_data, "androidboot.vbmeta.invalidate_on_error", "yes")) {
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
          goto out;
        }
        verity_mode = "enforcing";
        dm_verity_mode = "restart_on_corruption";
        break;
      case AVB_HASHTREE_ERROR_MODE_RESTART:
        verity_mode = "enforcing";
        dm_verity_mode = "restart_on_corruption";
        break;
      case AVB_HASHTREE_ERROR_MODE_EIO:
        verity_mode = "eio";
        /* For now there's no option to specify the EIO mode. So
         * just use 'ignore_zero_blocks' since that's already set
         * and dm-verity-target.c supports specifying this multiple
         * times.
         */
        dm_verity_mode = "ignore_zero_blocks";
        break;
      case AVB_HASHTREE_ERROR_MODE_LOGGING:
        verity_mode = "logging";
        dm_verity_mode = "ignore_corruption";
        break;
      case AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO:
        // Should never get here because MANAGED_RESTART_AND_EIO is
        // remapped by avb_manage_hashtree_error_mode().
        avb_assert_not_reached();
        break;
      case AVB_HASHTREE_ERROR_MODE_PANIC:
        verity_mode = "panicking";
        dm_verity_mode = "panic_on_corruption";
        break;
    }
    new_ret = avb_replace(
        slot_data->cmdline, "$(ANDROID_VERITY_MODE)", dm_verity_mode);
    avb_free(slot_data->cmdline);
    slot_data->cmdline = new_ret;
    if (slot_data->cmdline == NULL) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
  }
  if (!cmdline_append_option(
          slot_data, "androidboot.veritymode", verity_mode)) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }
  if (hashtree_error_mode == AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO) {
    if (!cmdline_append_option(
            slot_data, "androidboot.veritymode.managed", "yes")) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
  }

  ret = AVB_SLOT_VERIFY_RESULT_OK;

out:

  return ret;
}

AvbCmdlineSubstList* avb_new_cmdline_subst_list() {
  return (AvbCmdlineSubstList*)avb_calloc(sizeof(AvbCmdlineSubstList));
}

void avb_free_cmdline_subst_list(AvbCmdlineSubstList* cmdline_subst) {
  size_t i;
  for (i = 0; i < cmdline_subst->size; ++i) {
    avb_free(cmdline_subst->tokens[i]);
    avb_free(cmdline_subst->values[i]);
  }
  cmdline_subst->size = 0;
  avb_free(cmdline_subst);
}

AvbSlotVerifyResult avb_add_root_digest_substitution(
    const char* part_name,
    const uint8_t* digest,
    size_t digest_size,
    AvbCmdlineSubstList* out_cmdline_subst) {
  const char* kDigestSubPrefix = "$(AVB_";
  const char* kDigestSubSuffix = "_ROOT_DIGEST)";
  size_t part_name_len = avb_strlen(part_name);
  size_t list_index = out_cmdline_subst->size;

  avb_assert(part_name_len < AVB_PART_NAME_MAX_SIZE);
  avb_assert(digest_size <= AVB_SHA512_DIGEST_SIZE);
  if (part_name_len >= AVB_PART_NAME_MAX_SIZE ||
      digest_size > AVB_SHA512_DIGEST_SIZE) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }

  if (out_cmdline_subst->size >= AVB_MAX_NUM_CMDLINE_SUBST) {
    /* The list is full. Currently dynamic growth of this list is not supported.
     */
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }

  /* Construct the token to replace in the command line based on the partition
   * name. For partition 'foo', this will be '$(AVB_FOO_ROOT_DIGEST)'.
   */
  out_cmdline_subst->tokens[list_index] =
      avb_strdupv(kDigestSubPrefix, part_name, kDigestSubSuffix, NULL);
  if (out_cmdline_subst->tokens[list_index] == NULL) {
    goto fail;
  }
  avb_uppercase(out_cmdline_subst->tokens[list_index]);

  /* The digest value is hex encoded when inserted in the command line. */
  out_cmdline_subst->values[list_index] = avb_bin2hex(digest, digest_size);
  if (out_cmdline_subst->values[list_index] == NULL) {
    goto fail;
  }

  out_cmdline_subst->size++;
  return AVB_SLOT_VERIFY_RESULT_OK;

fail:
  if (out_cmdline_subst->tokens[list_index]) {
    avb_free(out_cmdline_subst->tokens[list_index]);
  }
  if (out_cmdline_subst->values[list_index]) {
    avb_free(out_cmdline_subst->values[list_index]);
  }
  return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
}

```

`aosp/libavb1.2/src/avb/c/avb_crc32.c`:

```c
/*
 * Copyright 2020 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/* See https://en.wikipedia.org/wiki/Computation_of_cyclic_redundancy_checks
 * for info on the general algorithm. We use the following configuration:
 *   32-bit CRC
 *   Polynomial = 0x04C11DB7
 *   MSB-first
 *   Input and output complement
 *   Input and output bit reversal
 *
 * This implementation optimizes for size and readability. We only need this for
 * 28 bytes of A/B booting metadata, so efficiency is largely irrelevant whereas
 * a 1KiB lookup table can be a significant cost for bootloaders.
 */

#include "avb_util.h"

/* Lookup table for reversing 4 bits. */
/* clang-format off */
static uint8_t reverse_4bit_table[] = {
  0x0, 0x8, 0x4, 0xC,
  0x2, 0xA, 0x6, 0xE,
  0x1, 0x9, 0x5, 0xD,
  0x3, 0xB, 0x7, 0xF
};
/* clang-format on */

static uint8_t reverse_byte(uint8_t val) {
  return (reverse_4bit_table[val & 0xF] << 4) | reverse_4bit_table[val >> 4];
}

static uint32_t reverse_uint32(uint32_t val) {
  return (reverse_byte(val) << 24) | (reverse_byte(val >> 8) << 16) |
         (reverse_byte(val >> 16) << 8) | reverse_byte(val >> 24);
}

uint32_t avb_crc32(const uint8_t* buf, size_t size) {
  uint32_t crc = 0xFFFFFFFF;

  for (size_t i = 0; i < size; ++i) {
    crc = crc ^ ((uint32_t)reverse_byte(buf[i]) << 24);
    for (int j = 0; j < 8; ++j) {
      if (crc & 0x80000000) {
        crc = (crc << 1) ^ 0x04C11DB7;
      } else {
        crc <<= 1;
      }
    }
  }

  return reverse_uint32(~crc);
}

```

`aosp/libavb1.2/src/avb/c/avb_crypto.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_crypto.h"
#include "avb_rsa.h"
#include "avb_sha.h"
#include "avb_util.h"

/* NOTE: The PKC1-v1.5 padding is a blob of binary DER of ASN.1 and is
 * obtained from section 5.2.2 of RFC 4880.
 */

static const uint8_t
    padding_RSA2048_SHA256[AVB_RSA2048_NUM_BYTES - AVB_SHA256_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0x00, 0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65,
        0x03, 0x04, 0x02, 0x01, 0x05, 0x00, 0x04, 0x20};

static const uint8_t
    padding_RSA4096_SHA256[AVB_RSA4096_NUM_BYTES - AVB_SHA256_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60,
        0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05, 0x00, 0x04, 0x20};

static const uint8_t
    padding_RSA8192_SHA256[AVB_RSA8192_NUM_BYTES - AVB_SHA256_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0x00, 0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65,
        0x03, 0x04, 0x02, 0x01, 0x05, 0x00, 0x04, 0x20};

static const uint8_t
    padding_RSA2048_SHA512[AVB_RSA2048_NUM_BYTES - AVB_SHA512_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60,
        0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05, 0x00, 0x04, 0x40};

static const uint8_t
    padding_RSA4096_SHA512[AVB_RSA4096_NUM_BYTES - AVB_SHA512_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x51, 0x30,
        0x0d, 0x06, 0x09, 0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03,
        0x05, 0x00, 0x04, 0x40};

static const uint8_t
    padding_RSA8192_SHA512[AVB_RSA8192_NUM_BYTES - AVB_SHA512_DIGEST_SIZE] = {
        0x00, 0x01, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
        0xff, 0xff, 0xff, 0xff, 0x00, 0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60,
        0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05, 0x00, 0x04, 0x40};

static AvbAlgorithmData algorithm_data[_AVB_ALGORITHM_NUM_TYPES] = {
    /* AVB_ALGORITHM_TYPE_NONE */
    {.padding = NULL, .padding_len = 0, .hash_len = 0},
    /* AVB_ALGORITHM_TYPE_SHA256_RSA2048 */
    {.padding = padding_RSA2048_SHA256,
     .padding_len = sizeof(padding_RSA2048_SHA256),
     .hash_len = AVB_SHA256_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA256_RSA4096 */
    {.padding = padding_RSA4096_SHA256,
     .padding_len = sizeof(padding_RSA4096_SHA256),
     .hash_len = AVB_SHA256_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA256_RSA8192 */
    {.padding = padding_RSA8192_SHA256,
     .padding_len = sizeof(padding_RSA8192_SHA256),
     .hash_len = AVB_SHA256_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA512_RSA2048 */
    {.padding = padding_RSA2048_SHA512,
     .padding_len = sizeof(padding_RSA2048_SHA512),
     .hash_len = AVB_SHA512_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA512_RSA4096 */
    {.padding = padding_RSA4096_SHA512,
     .padding_len = sizeof(padding_RSA4096_SHA512),
     .hash_len = AVB_SHA512_DIGEST_SIZE},
    /* AVB_ALGORITHM_TYPE_SHA512_RSA8192 */
    {.padding = padding_RSA8192_SHA512,
     .padding_len = sizeof(padding_RSA8192_SHA512),
     .hash_len = AVB_SHA512_DIGEST_SIZE},
};

const AvbAlgorithmData* avb_get_algorithm_data(AvbAlgorithmType algorithm) {
  if ((size_t)algorithm < _AVB_ALGORITHM_NUM_TYPES) {
    return &algorithm_data[algorithm];
  }
  return NULL;
}

bool avb_rsa_public_key_header_validate_and_byteswap(
    const AvbRSAPublicKeyHeader* src, AvbRSAPublicKeyHeader* dest) {
  avb_memcpy(dest, src, sizeof(AvbRSAPublicKeyHeader));

  dest->key_num_bits = avb_be32toh(dest->key_num_bits);
  dest->n0inv = avb_be32toh(dest->n0inv);

  return true;
}

```

`aosp/libavb1.2/src/avb/c/avb_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_descriptor.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"

bool avb_descriptor_validate_and_byteswap(const AvbDescriptor* src,
                                          AvbDescriptor* dest) {
  dest->tag = avb_be64toh(src->tag);
  dest->num_bytes_following = avb_be64toh(src->num_bytes_following);

  if ((dest->num_bytes_following & 0x07) != 0) {
    avb_error("Descriptor size is not divisible by 8.\n");
    return false;
  }
  return true;
}

bool avb_descriptor_foreach(const uint8_t* image_data,
                            size_t image_size,
                            AvbDescriptorForeachFunc foreach_func,
                            void* user_data) {
  const AvbVBMetaImageHeader* header = NULL;
  bool ret = false;
  const uint8_t* image_end;
  const uint8_t* desc_start;
  const uint8_t* desc_end;
  const uint8_t* p;
  uint64_t desc_offset = 0;
  uint64_t desc_size = 0;

  if (image_data == NULL) {
    avb_error("image_data is NULL\n.");
    goto out;
  }

  if (foreach_func == NULL) {
    avb_error("foreach_func is NULL\n.");
    goto out;
  }

  /* The data is supposed to have been cryptographically verified at this point,
   * This check is just adding defense in depth.
   */
  if (image_size < sizeof(AvbVBMetaImageHeader)) {
    avb_error("Length is smaller than header.\n");
    goto out;
  }

  /* Ensure magic is correct. */
  if (avb_memcmp(image_data, AVB_MAGIC, AVB_MAGIC_LEN) != 0) {
    avb_error("Magic is incorrect.\n");
    goto out;
  }

  /* Careful, not byteswapped - also ensure it's aligned properly. */
  avb_assert_aligned(image_data);
  header = (const AvbVBMetaImageHeader*)image_data;
  image_end = image_data + image_size;

  /* Since the data is supposed to have been cryptographically verified at this
   * point, being overflow-safe is just for defense.
   * The following lines are overflow-safe version of:
   * desc_offset = sizeof(AvbVBMetaImageHeader) +
   *               avb_be64toh(header->authentication_data_block_size)) +
   *               avb_be64toh(header->descriptors_offset)
   */
  if (!avb_safe_add(&desc_offset,
                    sizeof(AvbVBMetaImageHeader),
                    avb_be64toh(header->authentication_data_block_size))) {
    avb_error("Invalid authentication data block size.\n");
    goto out;
  }
  if (!avb_safe_add_to(&desc_offset, avb_be64toh(header->descriptors_offset))) {
    avb_error("Invalid descriptors offset.\n");
    goto out;
  }

  if (desc_offset > (uint64_t)(image_end - image_data)) {
    avb_error("Descriptors not inside passed-in data.\n");
    goto out;
  }

  desc_start = image_data + desc_offset;

  desc_size = avb_be64toh(header->descriptors_size);
  if (desc_size > (uint64_t)(image_end - desc_start)) {
    avb_error("Descriptors not inside passed-in data.\n");
    goto out;
  }

  desc_end = desc_start + desc_size;

  for (p = desc_start; p < desc_end;) {
    uint64_t nb_following;
    uint64_t nb_total = 0;
    const AvbDescriptor* dh;

    if (sizeof(AvbDescriptor) > (size_t)(desc_end - p)) {
      avb_error("Invalid descriptor length.\n");
      goto out;
    }

    dh = (const AvbDescriptor*)p;
    avb_assert_aligned(dh);
    nb_following = avb_be64toh(dh->num_bytes_following);

    if (!avb_safe_add(&nb_total, sizeof(AvbDescriptor), nb_following)) {
      avb_error("Invalid descriptor length.\n");
      goto out;
    }

    if ((nb_total & 7) != 0) {
      avb_error("Invalid descriptor length.\n");
      goto out;
    }

    if (nb_total > (uint64_t)(desc_end - p)) {
      avb_error("Invalid data in descriptors array.\n");
      goto out;
    }

    if (foreach_func(dh, user_data) == 0) {
      goto out;
    }

    p += nb_total;
  }

  ret = true;

out:
  return ret;
}

static bool count_descriptors(const AvbDescriptor* descriptor,
                              void* user_data) {
  size_t* num_descriptors = user_data;
  *num_descriptors += 1;
  return true;
}

typedef struct {
  size_t descriptor_number;
  const AvbDescriptor** descriptors;
} SetDescriptorData;

static bool set_descriptors(const AvbDescriptor* descriptor, void* user_data) {
  SetDescriptorData* data = user_data;
  data->descriptors[data->descriptor_number++] = descriptor;
  return true;
}

const AvbDescriptor** avb_descriptor_get_all(const uint8_t* image_data,
                                             size_t image_size,
                                             size_t* out_num_descriptors) {
  size_t num_descriptors = 0;
  SetDescriptorData data;

  avb_descriptor_foreach(
      image_data, image_size, count_descriptors, &num_descriptors);

  data.descriptor_number = 0;
  data.descriptors =
      avb_calloc(sizeof(const AvbDescriptor*) * (num_descriptors + 1));
  if (data.descriptors == NULL) {
    return NULL;
  }
  avb_descriptor_foreach(image_data, image_size, set_descriptors, &data);
  avb_assert(data.descriptor_number == num_descriptors);

  if (out_num_descriptors != NULL) {
    *out_num_descriptors = num_descriptors;
  }

  return data.descriptors;
}

```

`aosp/libavb1.2/src/avb/c/avb_footer.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_footer.h"
#include "avb_util.h"

bool avb_footer_validate_and_byteswap(const AvbFooter* src, AvbFooter* dest) {
  avb_memcpy(dest, src, sizeof(AvbFooter));

  dest->version_major = avb_be32toh(dest->version_major);
  dest->version_minor = avb_be32toh(dest->version_minor);

  dest->original_image_size = avb_be64toh(dest->original_image_size);
  dest->vbmeta_offset = avb_be64toh(dest->vbmeta_offset);
  dest->vbmeta_size = avb_be64toh(dest->vbmeta_size);

  /* Check that magic is correct. */
  if (avb_safe_memcmp(dest->magic, AVB_FOOTER_MAGIC, AVB_FOOTER_MAGIC_LEN) !=
      0) {
    avb_error("Footer magic is incorrect.\n");
    return false;
  }

  /* Ensure we don't attempt to access any fields if the footer major
   * version is not supported.
   */
  if (dest->version_major > AVB_FOOTER_VERSION_MAJOR) {
    avb_error("No support for footer version.\n");
    return false;
  }

  return true;
}

```

`aosp/libavb1.2/src/avb/c/avb_hash_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_hash_descriptor.h"
#include "avb_util.h"

bool avb_hash_descriptor_validate_and_byteswap(const AvbHashDescriptor* src,
                                               AvbHashDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbHashDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_HASH) {
    avb_error("Invalid tag for hash descriptor.\n");
    return false;
  }

  dest->image_size = avb_be64toh(dest->image_size);
  dest->partition_name_len = avb_be32toh(dest->partition_name_len);
  dest->salt_len = avb_be32toh(dest->salt_len);
  dest->digest_len = avb_be32toh(dest->digest_len);
  dest->flags = avb_be32toh(dest->flags);

  /* Check that partition_name, salt, and digest are fully contained. */
  expected_size = sizeof(AvbHashDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->partition_name_len) ||
      !avb_safe_add_to(&expected_size, dest->salt_len) ||
      !avb_safe_add_to(&expected_size, dest->digest_len)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }
  return true;
}

```

`aosp/libavb1.2/src/avb/c/avb_hashtree_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_hashtree_descriptor.h"
#include "avb_util.h"

bool avb_hashtree_descriptor_validate_and_byteswap(
    const AvbHashtreeDescriptor* src, AvbHashtreeDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbHashtreeDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_HASHTREE) {
    avb_error("Invalid tag for hashtree descriptor.\n");
    return false;
  }

  dest->dm_verity_version = avb_be32toh(dest->dm_verity_version);
  dest->image_size = avb_be64toh(dest->image_size);
  dest->tree_offset = avb_be64toh(dest->tree_offset);
  dest->tree_size = avb_be64toh(dest->tree_size);
  dest->data_block_size = avb_be32toh(dest->data_block_size);
  dest->hash_block_size = avb_be32toh(dest->hash_block_size);
  dest->fec_num_roots = avb_be32toh(dest->fec_num_roots);
  dest->fec_offset = avb_be64toh(dest->fec_offset);
  dest->fec_size = avb_be64toh(dest->fec_size);
  dest->partition_name_len = avb_be32toh(dest->partition_name_len);
  dest->salt_len = avb_be32toh(dest->salt_len);
  dest->root_digest_len = avb_be32toh(dest->root_digest_len);
  dest->flags = avb_be32toh(dest->flags);

  /* Check that partition_name, salt, and root_digest are fully contained. */
  expected_size = sizeof(AvbHashtreeDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->partition_name_len) ||
      !avb_safe_add_to(&expected_size, dest->salt_len) ||
      !avb_safe_add_to(&expected_size, dest->root_digest_len)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }
  return true;
}

```

`aosp/libavb1.2/src/avb/c/avb_kernel_cmdline_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_kernel_cmdline_descriptor.h"
#include "avb_util.h"

bool avb_kernel_cmdline_descriptor_validate_and_byteswap(
    const AvbKernelCmdlineDescriptor* src, AvbKernelCmdlineDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbKernelCmdlineDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE) {
    avb_error("Invalid tag for kernel cmdline descriptor.\n");
    return false;
  }

  dest->flags = avb_be32toh(dest->flags);
  dest->kernel_cmdline_length = avb_be32toh(dest->kernel_cmdline_length);

  /* Check that kernel_cmdline is fully contained. */
  expected_size = sizeof(AvbKernelCmdlineDescriptor) - sizeof(AvbDescriptor);
  if (!avb_safe_add_to(&expected_size, dest->kernel_cmdline_length)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }

  return true;
}

```

`aosp/libavb1.2/src/avb/c/avb_property_descriptor.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_property_descriptor.h"
#include "avb_util.h"

bool avb_property_descriptor_validate_and_byteswap(
    const AvbPropertyDescriptor* src, AvbPropertyDescriptor* dest) {
  uint64_t expected_size;

  avb_memcpy(dest, src, sizeof(AvbPropertyDescriptor));

  if (!avb_descriptor_validate_and_byteswap((const AvbDescriptor*)src,
                                            (AvbDescriptor*)dest))
    return false;

  if (dest->parent_descriptor.tag != AVB_DESCRIPTOR_TAG_PROPERTY) {
    avb_error("Invalid tag for property descriptor.\n");
    return false;
  }

  dest->key_num_bytes = avb_be64toh(dest->key_num_bytes);
  dest->value_num_bytes = avb_be64toh(dest->value_num_bytes);

  /* Check that key and value are fully contained. */
  expected_size = sizeof(AvbPropertyDescriptor) - sizeof(AvbDescriptor) + 2;
  if (!avb_safe_add_to(&expected_size, dest->key_num_bytes) ||
      !avb_safe_add_to(&expected_size, dest->value_num_bytes)) {
    avb_error("Overflow while adding up sizes.\n");
    return false;
  }
  if (expected_size > dest->parent_descriptor.num_bytes_following) {
    avb_error("Descriptor payload size overflow.\n");
    return false;
  }

  return true;
}

typedef struct {
  const char* key;
  size_t key_size;
  const char* ret_value;
  size_t ret_value_size;
} PropertyIteratorData;

static bool property_lookup_desc_foreach(const AvbDescriptor* header,
                                         void* user_data) {
  PropertyIteratorData* data = (PropertyIteratorData*)user_data;
  AvbPropertyDescriptor prop_desc;
  const uint8_t* p;
  bool ret = true;

  if (header->tag != AVB_DESCRIPTOR_TAG_PROPERTY) {
    goto out;
  }

  if (!avb_property_descriptor_validate_and_byteswap(
          (const AvbPropertyDescriptor*)header, &prop_desc)) {
    goto out;
  }

  p = (const uint8_t*)header;
  if (p[sizeof(AvbPropertyDescriptor) + prop_desc.key_num_bytes] != 0) {
    avb_error("No terminating NUL byte in key.\n");
    goto out;
  }

  if (data->key_size == prop_desc.key_num_bytes) {
    if (avb_memcmp(p + sizeof(AvbPropertyDescriptor),
                   data->key,
                   data->key_size) == 0) {
      data->ret_value = (const char*)(p + sizeof(AvbPropertyDescriptor) +
                                      prop_desc.key_num_bytes + 1);
      data->ret_value_size = prop_desc.value_num_bytes;
      /* Stop iterating. */
      ret = false;
      goto out;
    }
  }

out:
  return ret;
}

const char* avb_property_lookup(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                size_t* out_value_size) {
  PropertyIteratorData data;

  if (key_size == 0) {
    key_size = avb_strlen(key);
  }

  data.key = key;
  data.key_size = key_size;

  if (avb_descriptor_foreach(
          image_data, image_size, property_lookup_desc_foreach, &data) == 0) {
    if (out_value_size != NULL) {
      *out_value_size = data.ret_value_size;
    }
    return data.ret_value;
  }

  if (out_value_size != NULL) {
    *out_value_size = 0;
  }
  return NULL;
}

bool avb_property_lookup_uint64(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                uint64_t* out_value) {
  const char* value;
  bool ret = false;
  uint64_t parsed_val;
  int base;
  int n;

  value = avb_property_lookup(image_data, image_size, key, key_size, NULL);
  if (value == NULL) {
    goto out;
  }

  base = 10;
  if (avb_memcmp(value, "0x", 2) == 0) {
    base = 16;
    value += 2;
  }

  parsed_val = 0;
  for (n = 0; value[n] != '\0'; n++) {
    int c = value[n];
    int digit;

    parsed_val *= base;

    if (c >= '0' && c <= '9') {
      digit = c - '0';
    } else if (base == 16 && c >= 'a' && c <= 'f') {
      digit = c - 'a' + 10;
    } else if (base == 16 && c >= 'A' && c <= 'F') {
      digit = c - 'A' + 10;
    } else {
      avb_error("Invalid digit.\n");
      goto out;
    }

    parsed_val += digit;
  }

  ret = true;
  if (out_value != NULL) {
    *out_value = parsed_val;
  }

out:
  return ret;
}

```

`aosp/libavb1.2/src/avb/c/avb_rsa.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

/* Copyright (c) 2011 The Chromium OS Authors. All rights reserved.
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

/* Implementation of RSA signature verification which uses a pre-processed
 * key for computation. The code extends libmincrypt RSA verification code to
 * support multiple RSA key lengths and hash digest algorithms.
 */

#include "avb_rsa.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"

typedef struct IAvbKey {
  unsigned int len; /* Length of n[] in number of uint32_t */
  uint32_t n0inv;   /* -1 / n[0] mod 2^32 */
  uint32_t* n;      /* modulus as array (host-byte order) */
  uint32_t* rr;     /* R^2 as array (host-byte order) */
} IAvbKey;

static IAvbKey* iavb_parse_key_data(const uint8_t* data, size_t length) {
  AvbRSAPublicKeyHeader h;
  IAvbKey* key = NULL;
  size_t expected_length;
  unsigned int i;
  const uint8_t* n;
  const uint8_t* rr;

  if (!avb_rsa_public_key_header_validate_and_byteswap(
          (const AvbRSAPublicKeyHeader*)data, &h)) {
    avb_error("Invalid key.\n");
    goto fail;
  }

  if (!(h.key_num_bits == 2048 || h.key_num_bits == 4096 ||
        h.key_num_bits == 8192)) {
    avb_error("Unexpected key length.\n");
    goto fail;
  }

  expected_length = sizeof(AvbRSAPublicKeyHeader) + 2 * h.key_num_bits / 8;
  if (length != expected_length) {
    avb_error("Key does not match expected length.\n");
    goto fail;
  }

  n = data + sizeof(AvbRSAPublicKeyHeader);
  rr = data + sizeof(AvbRSAPublicKeyHeader) + h.key_num_bits / 8;

  /* Store n and rr following the key header so we only have to do one
   * allocation.
   */
  key = (IAvbKey*)(avb_malloc(sizeof(IAvbKey) + 2 * h.key_num_bits / 8));
  if (key == NULL) {
    goto fail;
  }

  key->len = h.key_num_bits / 32;
  key->n0inv = h.n0inv;
  key->n = (uint32_t*)(key + 1); /* Skip ahead sizeof(IAvbKey) bytes. */
  key->rr = key->n + key->len;

  /* Crypto-code below (modpowF4() and friends) expects the key in
   * little-endian format (rather than the format we're storing the
   * key in), so convert it.
   */
  for (i = 0; i < key->len; i++) {
    key->n[i] = avb_be32toh(((uint32_t*)n)[key->len - i - 1]);
    key->rr[i] = avb_be32toh(((uint32_t*)rr)[key->len - i - 1]);
  }
  return key;

fail:
  if (key != NULL) {
    avb_free(key);
  }
  return NULL;
}

static void iavb_free_parsed_key(IAvbKey* key) {
  avb_free(key);
}

/* a[] -= mod */
static void subM(const IAvbKey* key, uint32_t* a) {
  int64_t A = 0;
  uint32_t i;
  for (i = 0; i < key->len; ++i) {
    A += (uint64_t)a[i] - key->n[i];
    a[i] = (uint32_t)A;
    A >>= 32;
  }
}

/* return a[] >= mod */
static int geM(const IAvbKey* key, uint32_t* a) {
  uint32_t i;
  for (i = key->len; i;) {
    --i;
    if (a[i] < key->n[i]) {
      return 0;
    }
    if (a[i] > key->n[i]) {
      return 1;
    }
  }
  return 1; /* equal */
}

/* montgomery c[] += a * b[] / R % mod */
static void montMulAdd(const IAvbKey* key,
                       uint32_t* c,
                       const uint32_t a,
                       const uint32_t* b) {
  uint64_t A = (uint64_t)a * b[0] + c[0];
  uint32_t d0 = (uint32_t)A * key->n0inv;
  uint64_t B = (uint64_t)d0 * key->n[0] + (uint32_t)A;
  uint32_t i;

  for (i = 1; i < key->len; ++i) {
    A = (A >> 32) + (uint64_t)a * b[i] + c[i];
    B = (B >> 32) + (uint64_t)d0 * key->n[i] + (uint32_t)A;
    c[i - 1] = (uint32_t)B;
  }

  A = (A >> 32) + (B >> 32);

  c[i - 1] = (uint32_t)A;

  if (A >> 32) {
    subM(key, c);
  }
}

/* montgomery c[] = a[] * b[] / R % mod */
static void montMul(const IAvbKey* key, uint32_t* c, uint32_t* a, uint32_t* b) {
  uint32_t i;
  for (i = 0; i < key->len; ++i) {
    c[i] = 0;
  }
  for (i = 0; i < key->len; ++i) {
    montMulAdd(key, c, a[i], b);
  }
}

/* In-place public exponentiation. (65537}
 * Input and output big-endian byte array in inout.
 */
static void modpowF4(const IAvbKey* key, uint8_t* inout) {
  uint32_t* a = (uint32_t*)avb_malloc(key->len * sizeof(uint32_t));
  uint32_t* aR = (uint32_t*)avb_malloc(key->len * sizeof(uint32_t));
  uint32_t* aaR = (uint32_t*)avb_malloc(key->len * sizeof(uint32_t));
  if (a == NULL || aR == NULL || aaR == NULL) {
    goto out;
  }

  uint32_t* aaa = aaR; /* Re-use location. */
  int i;

  /* Convert from big endian byte array to little endian word array. */
  for (i = 0; i < (int)key->len; ++i) {
    uint32_t tmp = (inout[((key->len - 1 - i) * 4) + 0] << 24) |
                   (inout[((key->len - 1 - i) * 4) + 1] << 16) |
                   (inout[((key->len - 1 - i) * 4) + 2] << 8) |
                   (inout[((key->len - 1 - i) * 4) + 3] << 0);
    a[i] = tmp;
  }

  montMul(key, aR, a, key->rr); /* aR = a * RR / R mod M   */
  for (i = 0; i < 16; i += 2) {
    montMul(key, aaR, aR, aR);  /* aaR = aR * aR / R mod M */
    montMul(key, aR, aaR, aaR); /* aR = aaR * aaR / R mod M */
  }
  montMul(key, aaa, aR, a); /* aaa = aR * a / R mod M */

  /* Make sure aaa < mod; aaa is at most 1x mod too large. */
  if (geM(key, aaa)) {
    subM(key, aaa);
  }

  /* Convert to bigendian byte array */
  for (i = (int)key->len - 1; i >= 0; --i) {
    uint32_t tmp = aaa[i];
    *inout++ = (uint8_t)(tmp >> 24);
    *inout++ = (uint8_t)(tmp >> 16);
    *inout++ = (uint8_t)(tmp >> 8);
    *inout++ = (uint8_t)(tmp >> 0);
  }

out:
  if (a != NULL) {
    avb_free(a);
  }
  if (aR != NULL) {
    avb_free(aR);
  }
  if (aaR != NULL) {
    avb_free(aaR);
  }
}

/* Verify a RSA PKCS1.5 signature against an expected hash.
 * Returns false on failure, true on success.
 */
bool avb_rsa_verify(const uint8_t* key,
                    size_t key_num_bytes,
                    const uint8_t* sig,
                    size_t sig_num_bytes,
                    const uint8_t* hash,
                    size_t hash_num_bytes,
                    const uint8_t* padding,
                    size_t padding_num_bytes) {
  uint8_t* buf = NULL;
  IAvbKey* parsed_key = NULL;
  bool success = false;

  if (key == NULL || sig == NULL || hash == NULL || padding == NULL) {
    avb_error("Invalid input.\n");
    goto out;
  }

  parsed_key = iavb_parse_key_data(key, key_num_bytes);
  if (parsed_key == NULL) {
    avb_error("Error parsing key.\n");
    goto out;
  }

  if (sig_num_bytes != (parsed_key->len * sizeof(uint32_t))) {
    avb_error("Signature length does not match key length.\n");
    goto out;
  }

  if (padding_num_bytes != sig_num_bytes - hash_num_bytes) {
    avb_error("Padding length does not match hash and signature lengths.\n");
    goto out;
  }

  buf = (uint8_t*)avb_malloc(sig_num_bytes);
  if (buf == NULL) {
    avb_error("Error allocating memory.\n");
    goto out;
  }
  avb_memcpy(buf, sig, sig_num_bytes);

  modpowF4(parsed_key, buf);

  /* Check padding bytes.
   *
   * Even though there are probably no timing issues here, we use
   * avb_safe_memcmp() just to be on the safe side.
   */
  if (avb_safe_memcmp(buf, padding, padding_num_bytes)) {
    avb_error("Padding check failed.\n");
    goto out;
  }

  /* Check hash. */
  if (avb_safe_memcmp(buf + padding_num_bytes, hash, hash_num_bytes)) {
    avb_error("Hash check failed.\n");
    goto out;
  }

  success = true;

out:
  if (parsed_key != NULL) {
    iavb_free_parsed_key(parsed_key);
  }
  if (buf != NULL) {
    avb_free(buf);
  }
  return success;
}

```

`aosp/libavb1.2/src/avb/c/avb_slot_verify.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_slot_verify.h"
#include "avb_chain_partition_descriptor.h"
#include "avb_cmdline.h"
#include "avb_footer.h"
#include "avb_hash_descriptor.h"
#include "avb_hashtree_descriptor.h"
#include "avb_kernel_cmdline_descriptor.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"
#include "avb_version.h"

/* Maximum number of partitions that can be loaded with avb_slot_verify(). */
#define MAX_NUMBER_OF_LOADED_PARTITIONS 32

/* Maximum number of vbmeta images that can be loaded with avb_slot_verify(). */
#define MAX_NUMBER_OF_VBMETA_IMAGES 32

/* Maximum size of a vbmeta image - 64 KiB. */
#define VBMETA_MAX_SIZE (64 * 1024)

static AvbSlotVerifyResult initialize_persistent_digest(
    AvbOps* ops,
    const char* part_name,
    const char* persistent_value_name,
    size_t digest_size,
    const uint8_t* initial_digest,
    uint8_t* out_digest);

/* Helper function to see if we should continue with verification in
 * allow_verification_error=true mode if something goes wrong. See the
 * comments for the avb_slot_verify() function for more information.
 */
static inline bool result_should_continue(AvbSlotVerifyResult result) {
  switch (result) {
    case AVB_SLOT_VERIFY_RESULT_ERROR_OOM:
    case AVB_SLOT_VERIFY_RESULT_ERROR_IO:
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA:
    case AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION:
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT:
      return false;

    case AVB_SLOT_VERIFY_RESULT_OK:
    case AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION:
    case AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX:
    case AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED:
      return true;
  }

  return false;
}

static AvbSlotVerifyResult load_full_partition(AvbOps* ops,
                                               const char* part_name,
                                               uint64_t image_size,
                                               uint8_t** out_image_buf,
                                               bool* out_image_preloaded) {
  size_t part_num_read;
  AvbIOResult io_ret;

  /* Make sure that we do not overwrite existing data. */
  avb_assert(*out_image_buf == NULL);
  avb_assert(!*out_image_preloaded);

  /* We are going to implicitly cast image_size from uint64_t to size_t in the
   * following code, so we need to make sure that the cast is safe. */
  if (image_size != (size_t)(image_size)) {
    avb_errorv(part_name, ": Partition size too large to load.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }

  /* Try use a preloaded one. */
  if (ops->get_preloaded_partition != NULL) {
    io_ret = ops->get_preloaded_partition(
        ops, part_name, image_size, out_image_buf, &part_num_read);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error loading data from partition.\n", NULL);
      return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    }

    if (*out_image_buf != NULL) {
      *out_image_preloaded = true;
      if (part_num_read != image_size) {
        avb_errorv(part_name, ": Read incorrect number of bytes.\n", NULL);
        return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      }
    }
  }

  /* Allocate and copy the partition. */
  if (!*out_image_preloaded) {
    *out_image_buf = avb_malloc(image_size);
    if (*out_image_buf == NULL) {
      return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    }

    io_ret = ops->read_from_partition(ops,
                                      part_name,
                                      0 /* offset */,
                                      image_size,
                                      *out_image_buf,
                                      &part_num_read);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error loading data from partition.\n", NULL);
      return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    }
    if (part_num_read != image_size) {
      avb_errorv(part_name, ": Read incorrect number of bytes.\n", NULL);
      return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    }
  }

  return AVB_SLOT_VERIFY_RESULT_OK;
}

/* Reads a persistent digest stored as a named persistent value corresponding to
 * the given |part_name|. The value is returned in |out_digest| which must point
 * to |expected_digest_size| bytes. If there is no digest stored for |part_name|
 * it can be initialized by providing a non-NULL |initial_digest| of length
 * |expected_digest_size|. This automatic initialization will only occur if the
 * device is currently locked. The |initial_digest| may be NULL.
 *
 * Returns AVB_SLOT_VERIFY_RESULT_OK on success, otherwise returns an
 * AVB_SLOT_VERIFY_RESULT_ERROR_* error code.
 *
 * If the value does not exist, is not supported, or is not populated, and
 * |initial_digest| is NULL, returns
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA. If |expected_digest_size| does
 * not match the stored digest size, also returns
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA.
 */
static AvbSlotVerifyResult read_persistent_digest(AvbOps* ops,
                                                  const char* part_name,
                                                  size_t expected_digest_size,
                                                  const uint8_t* initial_digest,
                                                  uint8_t* out_digest) {
  char* persistent_value_name = NULL;
  AvbIOResult io_ret = AVB_IO_RESULT_OK;
  size_t stored_digest_size = 0;

  if (ops->read_persistent_value == NULL) {
    avb_errorv(part_name, ": Persistent values are not implemented.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }
  persistent_value_name =
      avb_strdupv(AVB_NPV_PERSISTENT_DIGEST_PREFIX, part_name, NULL);
  if (persistent_value_name == NULL) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  }

  io_ret = ops->read_persistent_value(ops,
                                      persistent_value_name,
                                      expected_digest_size,
                                      out_digest,
                                      &stored_digest_size);

  // If no such named persistent value exists and an initial digest value was
  // given, initialize the named persistent value with the given digest. If
  // initialized successfully, this will recurse into this function but with a
  // NULL initial_digest.
  if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_VALUE && initial_digest) {
    AvbSlotVerifyResult ret =
        initialize_persistent_digest(ops,
                                     part_name,
                                     persistent_value_name,
                                     expected_digest_size,
                                     initial_digest,
                                     out_digest);
    avb_free(persistent_value_name);
    return ret;
  }
  avb_free(persistent_value_name);

  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  } else if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_VALUE) {
    // Treat a missing persistent value as a verification error, which is
    // ignoreable, rather than a metadata error which is not.
    avb_errorv(part_name, ": Persistent digest does not exist.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
  } else if (io_ret == AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE ||
             io_ret == AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE) {
    avb_errorv(
        part_name, ": Persistent digest is not of expected size.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_errorv(part_name, ": Error reading persistent digest.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
  } else if (expected_digest_size != stored_digest_size) {
    avb_errorv(
        part_name, ": Persistent digest is not of expected size.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
  }
  return AVB_SLOT_VERIFY_RESULT_OK;
}

static AvbSlotVerifyResult initialize_persistent_digest(
    AvbOps* ops,
    const char* part_name,
    const char* persistent_value_name,
    size_t digest_size,
    const uint8_t* initial_digest,
    uint8_t* out_digest) {
  AvbSlotVerifyResult ret;
  AvbIOResult io_ret = AVB_IO_RESULT_OK;
  bool is_device_unlocked = true;

  io_ret = ops->read_is_device_unlocked(ops, &is_device_unlocked);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error getting device lock state.\n");
    return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
  }

  if (is_device_unlocked) {
    avb_debugv(part_name,
               ": Digest does not exist, device unlocked so not initializing "
               "digest.\n",
               NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
  }

  // Device locked; initialize digest with given initial value.
  avb_debugv(part_name,
             ": Digest does not exist, initializing persistent digest.\n",
             NULL);
  io_ret = ops->write_persistent_value(
      ops, persistent_value_name, digest_size, initial_digest);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    return AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_errorv(part_name, ": Error initializing persistent digest.\n", NULL);
    return AVB_SLOT_VERIFY_RESULT_ERROR_IO;
  }

  // To ensure that the digest value was written successfully - and avoid a
  // scenario where the digest is simply 'initialized' on every verify - recurse
  // into read_persistent_digest to read back the written value. The NULL
  // initial_digest ensures that this will not recurse again.
  ret = read_persistent_digest(ops, part_name, digest_size, NULL, out_digest);
  if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
    avb_errorv(part_name,
               ": Reading back initialized persistent digest failed!\n",
               NULL);
  }
  return ret;
}

static AvbSlotVerifyResult load_and_verify_hash_partition(
    AvbOps* ops,
    const char* const* requested_partitions,
    const char* ab_suffix,
    bool allow_verification_error,
    const AvbDescriptor* descriptor,
    AvbSlotVerifyData* slot_data) {
  AvbHashDescriptor hash_desc;
  const uint8_t* desc_partition_name = NULL;
  const uint8_t* desc_salt;
  const uint8_t* desc_digest;
  char part_name[AVB_PART_NAME_MAX_SIZE];
  AvbSlotVerifyResult ret;
  AvbIOResult io_ret;
  uint8_t* image_buf = NULL;
  bool image_preloaded = false;
  uint8_t* digest;
  size_t digest_len;
  const char* found;
  uint64_t image_size;
  size_t expected_digest_len = 0;
  uint8_t expected_digest_buf[AVB_SHA512_DIGEST_SIZE];
  const uint8_t* expected_digest = NULL;

  if (!avb_hash_descriptor_validate_and_byteswap(
          (const AvbHashDescriptor*)descriptor, &hash_desc)) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  desc_partition_name =
      ((const uint8_t*)descriptor) + sizeof(AvbHashDescriptor);
  desc_salt = desc_partition_name + hash_desc.partition_name_len;
  desc_digest = desc_salt + hash_desc.salt_len;

  if (!avb_validate_utf8(desc_partition_name, hash_desc.partition_name_len)) {
    avb_error("Partition name is not valid UTF-8.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  /* Don't bother loading or validating unless the partition was
   * requested in the first place.
   */
  found = avb_strv_find_str(requested_partitions,
                            (const char*)desc_partition_name,
                            hash_desc.partition_name_len);
  if (found == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_OK;
    goto out;
  }

  if ((hash_desc.flags & AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB) != 0) {
    /* No ab_suffix, just copy the partition name as is. */
    if (hash_desc.partition_name_len >= AVB_PART_NAME_MAX_SIZE) {
      avb_error("Partition name does not fit.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }
    avb_memcpy(part_name, desc_partition_name, hash_desc.partition_name_len);
    part_name[hash_desc.partition_name_len] = '\0';
  } else if (hash_desc.digest_len == 0 && avb_strlen(ab_suffix) != 0) {
    /* No ab_suffix allowed for partitions without a digest in the descriptor
     * because these partitions hold data unique to this device and are not
     * updated using an A/B scheme.
     */
    avb_error("Cannot use A/B with a persistent digest.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  } else {
    /* Add ab_suffix to the partition name. */
    if (!avb_str_concat(part_name,
                        sizeof part_name,
                        (const char*)desc_partition_name,
                        hash_desc.partition_name_len,
                        ab_suffix,
                        avb_strlen(ab_suffix))) {
      avb_error("Partition name and suffix does not fit.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }
  }

  /* If we're allowing verification errors then hash_desc.image_size
   * may no longer match what's in the partition... so in this case
   * just load the entire partition.
   *
   * For example, this can happen if a developer does 'fastboot flash
   * boot /path/to/new/and/bigger/boot.img'. We want this to work
   * since it's such a common workflow.
   */
  image_size = hash_desc.image_size;
  if (allow_verification_error) {
    io_ret = ops->get_size_of_partition(ops, part_name, &image_size);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error determining partition size.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
    avb_debugv(part_name, ": Loading entire partition.\n", NULL);
  }

  ret = load_full_partition(
      ops, part_name, image_size, &image_buf, &image_preloaded);
  if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
    goto out;
  }
  // Although only one of the type might be used, we have to defined the
  // structure here so that they would live outside the 'if/else' scope to be
  // used later.
  AvbSHA256Ctx sha256_ctx;
  AvbSHA512Ctx sha512_ctx;
  size_t image_size_to_hash = hash_desc.image_size;
  // If we allow verification error and the whole partition is smaller than
  // image size in hash descriptor, we just hash the whole partition.
  if (image_size_to_hash > image_size) {
    image_size_to_hash = image_size;
  }
  if (avb_strcmp((const char*)hash_desc.hash_algorithm, "sha256") == 0) {
    avb_sha256_init(&sha256_ctx);
    avb_sha256_update(&sha256_ctx, desc_salt, hash_desc.salt_len);
    avb_sha256_update(&sha256_ctx, image_buf, image_size_to_hash);
    digest = avb_sha256_final(&sha256_ctx);
    digest_len = AVB_SHA256_DIGEST_SIZE;
  } else if (avb_strcmp((const char*)hash_desc.hash_algorithm, "sha512") == 0) {
    avb_sha512_init(&sha512_ctx);
    avb_sha512_update(&sha512_ctx, desc_salt, hash_desc.salt_len);
    avb_sha512_update(&sha512_ctx, image_buf, image_size_to_hash);
    digest = avb_sha512_final(&sha512_ctx);
    digest_len = AVB_SHA512_DIGEST_SIZE;
  } else {
    avb_errorv(part_name, ": Unsupported hash algorithm.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  if (hash_desc.digest_len == 0) {
    /* Expect a match to a persistent digest. */
    avb_debugv(part_name, ": No digest, using persistent digest.\n", NULL);
    expected_digest_len = digest_len;
    expected_digest = expected_digest_buf;
    avb_assert(expected_digest_len <= sizeof(expected_digest_buf));
    /* Pass |digest| as the |initial_digest| so devices not yet initialized get
     * initialized to the current partition digest.
     */
    ret = read_persistent_digest(
        ops, part_name, digest_len, digest, expected_digest_buf);
    if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
      goto out;
    }
  } else {
    /* Expect a match to the digest in the descriptor. */
    expected_digest_len = hash_desc.digest_len;
    expected_digest = desc_digest;
  }

  if (digest_len != expected_digest_len) {
    avb_errorv(
        part_name, ": Digest in descriptor not of expected size.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  if (avb_safe_memcmp(digest, expected_digest, digest_len) != 0) {
    avb_errorv(part_name,
               ": Hash of data does not match digest in descriptor.\n",
               NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
    goto out;
  }

  ret = AVB_SLOT_VERIFY_RESULT_OK;

out:

  /* If it worked and something was loaded, copy to slot_data. */
  if ((ret == AVB_SLOT_VERIFY_RESULT_OK || result_should_continue(ret)) &&
      image_buf != NULL) {
    AvbPartitionData* loaded_partition;
    if (slot_data->num_loaded_partitions == MAX_NUMBER_OF_LOADED_PARTITIONS) {
      avb_errorv(part_name, ": Too many loaded partitions.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto fail;
    }
    loaded_partition =
        &slot_data->loaded_partitions[slot_data->num_loaded_partitions++];
    loaded_partition->partition_name = avb_strdup(found);
    loaded_partition->data_size = image_size;
    loaded_partition->data = image_buf;
    loaded_partition->preloaded = image_preloaded;
    loaded_partition->verify_result = ret;
    image_buf = NULL;
  }

fail:
  if (image_buf != NULL && !image_preloaded) {
    avb_free(image_buf);
  }
  return ret;
}

static AvbSlotVerifyResult load_requested_partitions(
    AvbOps* ops,
    const char* const* requested_partitions,
    const char* ab_suffix,
    AvbSlotVerifyData* slot_data) {
  AvbSlotVerifyResult ret;
  uint8_t* image_buf = NULL;
  bool image_preloaded = false;
  size_t n;

  for (n = 0; requested_partitions[n] != NULL; n++) {
    char part_name[AVB_PART_NAME_MAX_SIZE];
    AvbIOResult io_ret;
    uint64_t image_size;
    AvbPartitionData* loaded_partition;

    if (!avb_str_concat(part_name,
                        sizeof part_name,
                        requested_partitions[n],
                        avb_strlen(requested_partitions[n]),
                        ab_suffix,
                        avb_strlen(ab_suffix))) {
      avb_error("Partition name and suffix does not fit.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }

    io_ret = ops->get_size_of_partition(ops, part_name, &image_size);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(part_name, ": Error determining partition size.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
    avb_debugv(part_name, ": Loading entire partition.\n", NULL);

    ret = load_full_partition(
        ops, part_name, image_size, &image_buf, &image_preloaded);
    if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
      goto out;
    }

    /* Move to slot_data. */
    if (slot_data->num_loaded_partitions == MAX_NUMBER_OF_LOADED_PARTITIONS) {
      avb_errorv(part_name, ": Too many loaded partitions.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
    loaded_partition =
        &slot_data->loaded_partitions[slot_data->num_loaded_partitions++];
    loaded_partition->partition_name = avb_strdup(requested_partitions[n]);
    if (loaded_partition->partition_name == NULL) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    }
    loaded_partition->data_size = image_size;
    loaded_partition->data = image_buf; /* Transferring the owner. */
    loaded_partition->preloaded = image_preloaded;
    image_buf = NULL;
    image_preloaded = false;
  }

  ret = AVB_SLOT_VERIFY_RESULT_OK;

out:
  /* Free the current buffer if any. */
  if (image_buf != NULL && !image_preloaded) {
    avb_free(image_buf);
  }
  /* Buffers that are already saved in slot_data will be handled by the caller
   * even on failure. */
  return ret;
}

static AvbSlotVerifyResult load_and_verify_vbmeta(
    AvbOps* ops,
    const char* const* requested_partitions,
    const char* ab_suffix,
    AvbSlotVerifyFlags flags,
    bool allow_verification_error,
    AvbVBMetaImageFlags toplevel_vbmeta_flags,
    uint32_t rollback_index_location,
    const char* partition_name,
    size_t partition_name_len,
    const uint8_t* expected_public_key,
    size_t expected_public_key_length,
    AvbSlotVerifyData* slot_data,
    AvbAlgorithmType* out_algorithm_type,
    AvbCmdlineSubstList* out_additional_cmdline_subst) {
  char full_partition_name[AVB_PART_NAME_MAX_SIZE];
  AvbSlotVerifyResult ret;
  AvbIOResult io_ret;
  uint64_t vbmeta_offset;
  size_t vbmeta_size;
  uint8_t* vbmeta_buf = NULL;
  size_t vbmeta_num_read;
  AvbVBMetaVerifyResult vbmeta_ret;
  const uint8_t* pk_data;
  size_t pk_len;
  AvbVBMetaImageHeader vbmeta_header;
  uint64_t stored_rollback_index;
  const AvbDescriptor** descriptors = NULL;
  size_t num_descriptors;
  size_t n;
  bool is_main_vbmeta;
  bool look_for_vbmeta_footer;
  AvbVBMetaData* vbmeta_image_data = NULL;

  ret = AVB_SLOT_VERIFY_RESULT_OK;

  avb_assert(slot_data != NULL);

  /* Since we allow top-level vbmeta in 'boot', use
   * rollback_index_location to determine whether we're the main
   * vbmeta struct.
   */
  is_main_vbmeta = false;
  if (rollback_index_location == 0) {
    if ((flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) == 0) {
      is_main_vbmeta = true;
    }
  }

  /* Don't use footers for vbmeta partitions ('vbmeta' or
   * 'vbmeta_<partition_name>').
   */
  look_for_vbmeta_footer = true;
  if (avb_strncmp(partition_name, "vbmeta", avb_strlen("vbmeta")) == 0) {
    look_for_vbmeta_footer = false;
  }

  if (!avb_validate_utf8((const uint8_t*)partition_name, partition_name_len)) {
    avb_error("Partition name is not valid UTF-8.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  /* Construct full partition name e.g. system_a. */
  if (!avb_str_concat(full_partition_name,
                      sizeof full_partition_name,
                      partition_name,
                      partition_name_len,
                      ab_suffix,
                      avb_strlen(ab_suffix))) {
    avb_error("Partition name and suffix does not fit.\n");
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  /* If we're loading from the main vbmeta partition, the vbmeta struct is in
   * the beginning. Otherwise we may have to locate it via a footer... if no
   * footer is found, we look in the beginning to support e.g. vbmeta_<org>
   * partitions holding data for e.g. super partitions (b/80195851 for
   * rationale).
   */
  vbmeta_offset = 0;
  vbmeta_size = VBMETA_MAX_SIZE;
  if (look_for_vbmeta_footer) {
    uint8_t footer_buf[AVB_FOOTER_SIZE];
    size_t footer_num_read;
    AvbFooter footer;

    io_ret = ops->read_from_partition(ops,
                                      full_partition_name,
                                      -AVB_FOOTER_SIZE,
                                      AVB_FOOTER_SIZE,
                                      footer_buf,
                                      &footer_num_read);
    if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto out;
    } else if (io_ret != AVB_IO_RESULT_OK) {
      avb_errorv(full_partition_name, ": Error loading footer.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
    avb_assert(footer_num_read == AVB_FOOTER_SIZE);

    if (!avb_footer_validate_and_byteswap((const AvbFooter*)footer_buf,
                                          &footer)) {
      avb_debugv(full_partition_name, ": No footer detected.\n", NULL);
    } else {
      /* Basic footer sanity check since the data is untrusted. */
      if (footer.vbmeta_size > VBMETA_MAX_SIZE) {
        avb_errorv(
            full_partition_name, ": Invalid vbmeta size in footer.\n", NULL);
      } else {
        vbmeta_offset = footer.vbmeta_offset;
        vbmeta_size = footer.vbmeta_size;
      }
    }
  }

  vbmeta_buf = avb_malloc(vbmeta_size);
  if (vbmeta_buf == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }

  if (vbmeta_offset != 0) {
    avb_debugv("Loading vbmeta struct in footer from partition '",
               full_partition_name,
               "'.\n",
               NULL);
  } else {
    avb_debugv("Loading vbmeta struct from partition '",
               full_partition_name,
               "'.\n",
               NULL);
  }

  io_ret = ops->read_from_partition(ops,
                                    full_partition_name,
                                    vbmeta_offset,
                                    vbmeta_size,
                                    vbmeta_buf,
                                    &vbmeta_num_read);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    /* If we're looking for 'vbmeta' but there is no such partition,
     * go try to get it from the boot partition instead.
     */
    if (is_main_vbmeta && io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION &&
        !look_for_vbmeta_footer) {
      avb_debugv(full_partition_name,
                 ": No such partition. Trying 'boot' instead.\n",
                 NULL);
      ret = load_and_verify_vbmeta(ops,
                                   requested_partitions,
                                   ab_suffix,
                                   flags,
                                   allow_verification_error,
                                   0 /* toplevel_vbmeta_flags */,
                                   0 /* rollback_index_location */,
                                   "boot",
                                   avb_strlen("boot"),
                                   NULL /* expected_public_key */,
                                   0 /* expected_public_key_length */,
                                   slot_data,
                                   out_algorithm_type,
                                   out_additional_cmdline_subst);
      goto out;
    } else {
      avb_errorv(full_partition_name, ": Error loading vbmeta data.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
      goto out;
    }
  }
  avb_assert(vbmeta_num_read <= vbmeta_size);

  /* Check if the image is properly signed and get the public key used
   * to sign the image.
   */
  vbmeta_ret =
      avb_vbmeta_image_verify(vbmeta_buf, vbmeta_num_read, &pk_data, &pk_len);
  switch (vbmeta_ret) {
    case AVB_VBMETA_VERIFY_RESULT_OK:
      avb_assert(pk_data != NULL && pk_len > 0);
      break;

    case AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED:
    case AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH:
    case AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH:
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION;
      avb_errorv(full_partition_name,
                 ": Error verifying vbmeta image: ",
                 avb_vbmeta_verify_result_to_string(vbmeta_ret),
                 "\n",
                 NULL);
      if (!allow_verification_error) {
        goto out;
      }
      break;

    case AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER:
      /* No way to continue this case. */
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      avb_errorv(full_partition_name,
                 ": Error verifying vbmeta image: invalid vbmeta header\n",
                 NULL);
      goto out;

    case AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION:
      /* No way to continue this case. */
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION;
      avb_errorv(full_partition_name,
                 ": Error verifying vbmeta image: unsupported AVB version\n",
                 NULL);
      goto out;
  }

  /* Byteswap the header. */
  avb_vbmeta_image_header_to_host_byte_order((AvbVBMetaImageHeader*)vbmeta_buf,
                                             &vbmeta_header);

  /* If we're the toplevel, assign flags so they'll be passed down. */
  if (is_main_vbmeta) {
    toplevel_vbmeta_flags = (AvbVBMetaImageFlags)vbmeta_header.flags;
  } else {
    if (vbmeta_header.flags != 0) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      avb_errorv(full_partition_name,
                 ": chained vbmeta image has non-zero flags\n",
                 NULL);
      goto out;
    }
  }

  uint32_t rollback_index_location_to_use = rollback_index_location;
  if (is_main_vbmeta) {
    rollback_index_location_to_use = vbmeta_header.rollback_index_location;
  }

  /* Check if key used to make signature matches what is expected. */
  if (pk_data != NULL) {
    if (expected_public_key != NULL) {
      avb_assert(!is_main_vbmeta);
      if (expected_public_key_length != pk_len ||
          avb_safe_memcmp(expected_public_key, pk_data, pk_len) != 0) {
        avb_errorv(full_partition_name,
                   ": Public key used to sign data does not match key in chain "
                   "partition descriptor.\n",
                   NULL);
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED;
        if (!allow_verification_error) {
          goto out;
        }
      }
    } else {
      bool key_is_trusted = false;
      const uint8_t* pk_metadata = NULL;
      size_t pk_metadata_len = 0;

      if (vbmeta_header.public_key_metadata_size > 0) {
        pk_metadata = vbmeta_buf + sizeof(AvbVBMetaImageHeader) +
                      vbmeta_header.authentication_data_block_size +
                      vbmeta_header.public_key_metadata_offset;
        pk_metadata_len = vbmeta_header.public_key_metadata_size;
      }

      // If we're not using a vbmeta partition, need to use another AvbOps...
      if (flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) {
        io_ret = ops->validate_public_key_for_partition(
            ops,
            full_partition_name,
            pk_data,
            pk_len,
            pk_metadata,
            pk_metadata_len,
            &key_is_trusted,
            &rollback_index_location_to_use);
      } else {
        avb_assert(is_main_vbmeta);
        io_ret = ops->validate_vbmeta_public_key(ops,
                                                 pk_data,
                                                 pk_len,
                                                 pk_metadata,
                                                 pk_metadata_len,
                                                 &key_is_trusted);
      }

      if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto out;
      } else if (io_ret != AVB_IO_RESULT_OK) {
        avb_errorv(full_partition_name,
                   ": Error while checking public key used to sign data.\n",
                   NULL);
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
        goto out;
      }
      if (!key_is_trusted) {
        avb_errorv(full_partition_name,
                   ": Public key used to sign data rejected.\n",
                   NULL);
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED;
        if (!allow_verification_error) {
          goto out;
        }
      }
    }
  }

  /* Check rollback index. */
  io_ret = ops->read_rollback_index(
      ops, rollback_index_location_to_use, &stored_rollback_index);
  if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_errorv(full_partition_name,
               ": Error getting rollback index for location.\n",
               NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
    goto out;
  }
  if (vbmeta_header.rollback_index < stored_rollback_index) {
    avb_errorv(
        full_partition_name,
        ": Image rollback index is less than the stored rollback index.\n",
        NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX;
    if (!allow_verification_error) {
      goto out;
    }
  }

  /* Copy vbmeta to vbmeta_images before recursing. */
  if (is_main_vbmeta) {
    avb_assert(slot_data->num_vbmeta_images == 0);
  } else {
    if (!(flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION)) {
      avb_assert(slot_data->num_vbmeta_images > 0);
    }
  }
  if (slot_data->num_vbmeta_images == MAX_NUMBER_OF_VBMETA_IMAGES) {
    avb_errorv(full_partition_name, ": Too many vbmeta images.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto out;
  }
  vbmeta_image_data = &slot_data->vbmeta_images[slot_data->num_vbmeta_images++];
  vbmeta_image_data->partition_name = avb_strdup(partition_name);
  vbmeta_image_data->vbmeta_data = vbmeta_buf;
  /* Note that |vbmeta_buf| is actually |vbmeta_num_read| bytes long
   * and this includes data past the end of the image. Pass the
   * actual size of the vbmeta image. Also, no need to use
   * avb_safe_add() since the header has already been verified.
   */
  vbmeta_image_data->vbmeta_size =
      sizeof(AvbVBMetaImageHeader) +
      vbmeta_header.authentication_data_block_size +
      vbmeta_header.auxiliary_data_block_size;
  vbmeta_image_data->verify_result = vbmeta_ret;

  /* If verification has been disabled by setting a bit in the image,
   * we're done... except that we need to load the entirety of the
   * requested partitions.
   */
  if (vbmeta_header.flags & AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED) {
    AvbSlotVerifyResult sub_ret;
    avb_debugv(
        full_partition_name, ": VERIFICATION_DISABLED bit is set.\n", NULL);
    /* If load_requested_partitions() fail it is always a fatal
     * failure (e.g. ERROR_INVALID_ARGUMENT, ERROR_OOM, etc.) rather
     * than recoverable (e.g. one where result_should_continue()
     * returns true) and we want to convey that error.
     */
    sub_ret = load_requested_partitions(
        ops, requested_partitions, ab_suffix, slot_data);
    if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
      ret = sub_ret;
    }
    goto out;
  }

  /* Now go through all descriptors and take the appropriate action:
   *
   * - hash descriptor: Load data from partition, calculate hash, and
   *   checks that it matches what's in the hash descriptor.
   *
   * - hashtree descriptor: Do nothing since verification happens
   *   on-the-fly from within the OS. (Unless the descriptor uses a
   *   persistent digest, in which case we need to find it).
   *
   * - chained partition descriptor: Load the footer, load the vbmeta
   *   image, verify vbmeta image (includes rollback checks, hash
   *   checks, bail on chained partitions).
   */
  descriptors =
      avb_descriptor_get_all(vbmeta_buf, vbmeta_num_read, &num_descriptors);
  for (n = 0; n < num_descriptors; n++) {
    AvbDescriptor desc;

    if (!avb_descriptor_validate_and_byteswap(descriptors[n], &desc)) {
      avb_errorv(full_partition_name, ": Descriptor is invalid.\n", NULL);
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
      goto out;
    }

    switch (desc.tag) {
      case AVB_DESCRIPTOR_TAG_HASH: {
        AvbSlotVerifyResult sub_ret;
        sub_ret = load_and_verify_hash_partition(ops,
                                                 requested_partitions,
                                                 ab_suffix,
                                                 allow_verification_error,
                                                 descriptors[n],
                                                 slot_data);
        if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
          ret = sub_ret;
          if (!allow_verification_error || !result_should_continue(ret)) {
            goto out;
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_CHAIN_PARTITION: {
        AvbSlotVerifyResult sub_ret;
        AvbChainPartitionDescriptor chain_desc;
        const uint8_t* chain_partition_name;
        const uint8_t* chain_public_key;

        /* Only allow CHAIN_PARTITION descriptors in the main vbmeta image. */
        if (!is_main_vbmeta) {
          avb_errorv(full_partition_name,
                     ": Encountered chain descriptor not in main image.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        if (!avb_chain_partition_descriptor_validate_and_byteswap(
                (AvbChainPartitionDescriptor*)descriptors[n], &chain_desc)) {
          avb_errorv(full_partition_name,
                     ": Chain partition descriptor is invalid.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        if (chain_desc.rollback_index_location == 0) {
          avb_errorv(full_partition_name,
                     ": Chain partition has invalid "
                     "rollback_index_location field.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        chain_partition_name = ((const uint8_t*)descriptors[n]) +
                               sizeof(AvbChainPartitionDescriptor);
        chain_public_key = chain_partition_name + chain_desc.partition_name_len;

        sub_ret =
            load_and_verify_vbmeta(ops,
                                   requested_partitions,
                                   ab_suffix,
                                   flags,
                                   allow_verification_error,
                                   toplevel_vbmeta_flags,
                                   chain_desc.rollback_index_location,
                                   (const char*)chain_partition_name,
                                   chain_desc.partition_name_len,
                                   chain_public_key,
                                   chain_desc.public_key_len,
                                   slot_data,
                                   NULL, /* out_algorithm_type */
                                   NULL /* out_additional_cmdline_subst */);
        if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
          ret = sub_ret;
          if (!result_should_continue(ret)) {
            goto out;
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE: {
        const uint8_t* kernel_cmdline;
        AvbKernelCmdlineDescriptor kernel_cmdline_desc;
        bool apply_cmdline;

        if (!avb_kernel_cmdline_descriptor_validate_and_byteswap(
                (AvbKernelCmdlineDescriptor*)descriptors[n],
                &kernel_cmdline_desc)) {
          avb_errorv(full_partition_name,
                     ": Kernel cmdline descriptor is invalid.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        kernel_cmdline = ((const uint8_t*)descriptors[n]) +
                         sizeof(AvbKernelCmdlineDescriptor);

        if (!avb_validate_utf8(kernel_cmdline,
                               kernel_cmdline_desc.kernel_cmdline_length)) {
          avb_errorv(full_partition_name,
                     ": Kernel cmdline is not valid UTF-8.\n",
                     NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        /* Compare the flags for top-level VBMeta struct with flags in
         * the command-line descriptor so command-line snippets only
         * intended for a certain mode (dm-verity enabled/disabled)
         * are skipped if applicable.
         */
        apply_cmdline = true;
        if (toplevel_vbmeta_flags & AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED) {
          if (kernel_cmdline_desc.flags &
              AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED) {
            apply_cmdline = false;
          }
        } else {
          if (kernel_cmdline_desc.flags &
              AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED) {
            apply_cmdline = false;
          }
        }

        if (apply_cmdline) {
          if (slot_data->cmdline == NULL) {
            slot_data->cmdline =
                avb_calloc(kernel_cmdline_desc.kernel_cmdline_length + 1);
            if (slot_data->cmdline == NULL) {
              ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
              goto out;
            }
            avb_memcpy(slot_data->cmdline,
                       kernel_cmdline,
                       kernel_cmdline_desc.kernel_cmdline_length);
          } else {
            /* new cmdline is: <existing_cmdline> + ' ' + <newcmdline> + '\0' */
            size_t orig_size = avb_strlen(slot_data->cmdline);
            size_t new_size =
                orig_size + 1 + kernel_cmdline_desc.kernel_cmdline_length + 1;
            char* new_cmdline = avb_calloc(new_size);
            if (new_cmdline == NULL) {
              ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
              goto out;
            }
            avb_memcpy(new_cmdline, slot_data->cmdline, orig_size);
            new_cmdline[orig_size] = ' ';
            avb_memcpy(new_cmdline + orig_size + 1,
                       kernel_cmdline,
                       kernel_cmdline_desc.kernel_cmdline_length);
            avb_free(slot_data->cmdline);
            slot_data->cmdline = new_cmdline;
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_HASHTREE: {
        AvbHashtreeDescriptor hashtree_desc;

        if (!avb_hashtree_descriptor_validate_and_byteswap(
                (AvbHashtreeDescriptor*)descriptors[n], &hashtree_desc)) {
          avb_errorv(
              full_partition_name, ": Hashtree descriptor is invalid.\n", NULL);
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
          goto out;
        }

        /* We only need to continue when there is no digest in the descriptor.
         * This is because the only processing here is to find the digest and
         * make it available on the kernel command line.
         */
        if (hashtree_desc.root_digest_len == 0) {
          char part_name[AVB_PART_NAME_MAX_SIZE];
          size_t digest_len = 0;
          uint8_t digest_buf[AVB_SHA512_DIGEST_SIZE];
          const uint8_t* desc_partition_name =
              ((const uint8_t*)descriptors[n]) + sizeof(AvbHashtreeDescriptor);

          if (!avb_validate_utf8(desc_partition_name,
                                 hashtree_desc.partition_name_len)) {
            avb_error("Partition name is not valid UTF-8.\n");
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }

          /* No ab_suffix for partitions without a digest in the descriptor
           * because these partitions hold data unique to this device and are
           * not updated using an A/B scheme.
           */
          if ((hashtree_desc.flags &
               AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB) == 0 &&
              avb_strlen(ab_suffix) != 0) {
            avb_error("Cannot use A/B with a persistent root digest.\n");
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }
          if (hashtree_desc.partition_name_len >= AVB_PART_NAME_MAX_SIZE) {
            avb_error("Partition name does not fit.\n");
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }
          avb_memcpy(
              part_name, desc_partition_name, hashtree_desc.partition_name_len);
          part_name[hashtree_desc.partition_name_len] = '\0';

          /* Determine the expected digest size from the hash algorithm. */
          if (avb_strcmp((const char*)hashtree_desc.hash_algorithm, "sha1") ==
              0) {
            digest_len = AVB_SHA1_DIGEST_SIZE;
          } else if (avb_strcmp((const char*)hashtree_desc.hash_algorithm,
                                "sha256") == 0) {
            digest_len = AVB_SHA256_DIGEST_SIZE;
          } else if (avb_strcmp((const char*)hashtree_desc.hash_algorithm,
                                "sha512") == 0) {
            digest_len = AVB_SHA512_DIGEST_SIZE;
          } else {
            avb_errorv(part_name, ": Unsupported hash algorithm.\n", NULL);
            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
            goto out;
          }

          ret = read_persistent_digest(ops,
                                       part_name,
                                       digest_len,
                                       NULL /* initial_digest */,
                                       digest_buf);
          if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
            goto out;
          }

          if (out_additional_cmdline_subst) {
            ret =
                avb_add_root_digest_substitution(part_name,
                                                 digest_buf,
                                                 digest_len,
                                                 out_additional_cmdline_subst);
            if (ret != AVB_SLOT_VERIFY_RESULT_OK) {
              goto out;
            }
          }
        }
      } break;

      case AVB_DESCRIPTOR_TAG_PROPERTY:
        /* Do nothing. */
        break;
    }
  }

  if (rollback_index_location_to_use >=
      AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS) {
    avb_errorv(
        full_partition_name, ": Invalid rollback_index_location.\n", NULL);
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
    goto out;
  }

  slot_data->rollback_indexes[rollback_index_location_to_use] =
      vbmeta_header.rollback_index;

  if (out_algorithm_type != NULL) {
    *out_algorithm_type = (AvbAlgorithmType)vbmeta_header.algorithm_type;
  }

out:
  /* If |vbmeta_image_data| isn't NULL it means that it adopted
   * |vbmeta_buf| so in that case don't free it here.
   */
  if (vbmeta_image_data == NULL) {
    if (vbmeta_buf != NULL) {
      avb_free(vbmeta_buf);
    }
  }
  if (descriptors != NULL) {
    avb_free(descriptors);
  }
  return ret;
}

static AvbIOResult avb_manage_hashtree_error_mode(
    AvbOps* ops,
    AvbSlotVerifyFlags flags,
    AvbSlotVerifyData* data,
    AvbHashtreeErrorMode* out_hashtree_error_mode) {
  AvbHashtreeErrorMode ret = AVB_HASHTREE_ERROR_MODE_RESTART;
  AvbIOResult io_ret = AVB_IO_RESULT_OK;
  uint8_t vbmeta_digest_sha256[AVB_SHA256_DIGEST_SIZE];
  uint8_t stored_vbmeta_digest_sha256[AVB_SHA256_DIGEST_SIZE];
  size_t num_bytes_read;

  avb_assert(out_hashtree_error_mode != NULL);
  avb_assert(ops->read_persistent_value != NULL);
  avb_assert(ops->write_persistent_value != NULL);

  // If we're rebooting because of dm-verity corruption, make a note of
  // the vbmeta hash so we can stay in 'eio' mode until things change.
  if (flags & AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION) {
    avb_debug(
        "Rebooting because of dm-verity corruption - "
        "recording OS instance and using 'eio' mode.\n");
    avb_slot_verify_data_calculate_vbmeta_digest(
        data, AVB_DIGEST_TYPE_SHA256, vbmeta_digest_sha256);
    io_ret = ops->write_persistent_value(ops,
                                         AVB_NPV_MANAGED_VERITY_MODE,
                                         AVB_SHA256_DIGEST_SIZE,
                                         vbmeta_digest_sha256);
    if (io_ret != AVB_IO_RESULT_OK) {
      avb_error("Error writing to " AVB_NPV_MANAGED_VERITY_MODE ".\n");
      goto out;
    }
    ret = AVB_HASHTREE_ERROR_MODE_EIO;
    io_ret = AVB_IO_RESULT_OK;
    goto out;
  }

  // See if we're in 'eio' mode.
  io_ret = ops->read_persistent_value(ops,
                                      AVB_NPV_MANAGED_VERITY_MODE,
                                      AVB_SHA256_DIGEST_SIZE,
                                      stored_vbmeta_digest_sha256,
                                      &num_bytes_read);
  if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_VALUE ||
      (io_ret == AVB_IO_RESULT_OK && num_bytes_read == 0)) {
    // This is the usual case ('eio' mode not set).
    avb_debug("No dm-verity corruption - using in 'restart' mode.\n");
    ret = AVB_HASHTREE_ERROR_MODE_RESTART;
    io_ret = AVB_IO_RESULT_OK;
    goto out;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error reading from " AVB_NPV_MANAGED_VERITY_MODE ".\n");
    goto out;
  }
  if (num_bytes_read != AVB_SHA256_DIGEST_SIZE) {
    avb_error(
        "Unexpected number of bytes read from " AVB_NPV_MANAGED_VERITY_MODE
        ".\n");
    io_ret = AVB_IO_RESULT_ERROR_IO;
    goto out;
  }

  // OK, so we're currently in 'eio' mode and the vbmeta digest of the OS
  // that caused this is in |stored_vbmeta_digest_sha256| ... now see if
  // the OS we're dealing with now is the same.
  avb_slot_verify_data_calculate_vbmeta_digest(
      data, AVB_DIGEST_TYPE_SHA256, vbmeta_digest_sha256);
  if (avb_memcmp(vbmeta_digest_sha256,
                 stored_vbmeta_digest_sha256,
                 AVB_SHA256_DIGEST_SIZE) == 0) {
    // It's the same so we're still in 'eio' mode.
    avb_debug("Same OS instance detected - staying in 'eio' mode.\n");
    ret = AVB_HASHTREE_ERROR_MODE_EIO;
    io_ret = AVB_IO_RESULT_OK;
  } else {
    // It did change!
    avb_debug(
        "New OS instance detected - changing from 'eio' to 'restart' mode.\n");
    io_ret =
        ops->write_persistent_value(ops,
                                    AVB_NPV_MANAGED_VERITY_MODE,
                                    0,  // This clears the persistent property.
                                    vbmeta_digest_sha256);
    if (io_ret != AVB_IO_RESULT_OK) {
      avb_error("Error clearing " AVB_NPV_MANAGED_VERITY_MODE ".\n");
      goto out;
    }
    ret = AVB_HASHTREE_ERROR_MODE_RESTART;
    io_ret = AVB_IO_RESULT_OK;
  }

out:
  *out_hashtree_error_mode = ret;
  return io_ret;
}

static bool has_system_partition(AvbOps* ops, const char* ab_suffix) {
  char part_name[AVB_PART_NAME_MAX_SIZE];
  const char* system_part_name = "system";
  char guid_buf[37];
  AvbIOResult io_ret;

  if (!avb_str_concat(part_name,
                      sizeof part_name,
                      system_part_name,
                      avb_strlen(system_part_name),
                      ab_suffix,
                      avb_strlen(ab_suffix))) {
    avb_error("System partition name and suffix does not fit.\n");
    return false;
  }

  io_ret = ops->get_unique_guid_for_partition(
      ops, part_name, guid_buf, sizeof guid_buf);
  if (io_ret == AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION) {
    avb_debug("No system partition.\n");
    return false;
  } else if (io_ret != AVB_IO_RESULT_OK) {
    avb_error("Error getting unique GUID for system partition.\n");
    return false;
  }

  return true;
}

AvbSlotVerifyResult avb_slot_verify(AvbOps* ops,
                                    const char* const* requested_partitions,
                                    const char* ab_suffix,
                                    AvbSlotVerifyFlags flags,
                                    AvbHashtreeErrorMode hashtree_error_mode,
                                    AvbSlotVerifyData** out_data) {
  AvbSlotVerifyResult ret;
  AvbSlotVerifyData* slot_data = NULL;
  AvbAlgorithmType algorithm_type = AVB_ALGORITHM_TYPE_NONE;
  bool using_boot_for_vbmeta = false;
  AvbVBMetaImageHeader toplevel_vbmeta;
  bool allow_verification_error =
      (flags & AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR);
  AvbCmdlineSubstList* additional_cmdline_subst = NULL;

  /* Fail early if we're missing the AvbOps needed for slot verification. */
  avb_assert(ops->read_is_device_unlocked != NULL);
  avb_assert(ops->read_from_partition != NULL);
  avb_assert(ops->get_size_of_partition != NULL);
  avb_assert(ops->read_rollback_index != NULL);
  avb_assert(ops->get_unique_guid_for_partition != NULL);

  if (out_data != NULL) {
    *out_data = NULL;
  }

  /* Allowing dm-verity errors defeats the purpose of verified boot so
   * only allow this if set up to allow verification errors
   * (e.g. typically only UNLOCKED mode).
   */
  if (hashtree_error_mode == AVB_HASHTREE_ERROR_MODE_LOGGING &&
      !allow_verification_error) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
    goto fail;
  }

  /* Make sure passed-in AvbOps support persistent values if
   * asking for libavb to manage verity state.
   */
  if (hashtree_error_mode == AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO) {
    if (ops->read_persistent_value == NULL ||
        ops->write_persistent_value == NULL) {
      avb_error(
          "Persistent values required for "
          "AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO "
          "but are not implemented in given AvbOps.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
      goto fail;
    }
  }

  /* Make sure passed-in AvbOps support verifying public keys and getting
   * rollback index location if not using a vbmeta partition.
   */
  if (flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) {
    if (ops->validate_public_key_for_partition == NULL) {
      avb_error(
          "AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION was passed but the "
          "validate_public_key_for_partition() operation isn't implemented.\n");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
      goto fail;
    }
  } else {
    avb_assert(ops->validate_vbmeta_public_key != NULL);
  }

  slot_data = avb_calloc(sizeof(AvbSlotVerifyData));
  if (slot_data == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }
  slot_data->vbmeta_images =
      avb_calloc(sizeof(AvbVBMetaData) * MAX_NUMBER_OF_VBMETA_IMAGES);
  if (slot_data->vbmeta_images == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }
  slot_data->loaded_partitions =
      avb_calloc(sizeof(AvbPartitionData) * MAX_NUMBER_OF_LOADED_PARTITIONS);
  if (slot_data->loaded_partitions == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }

  additional_cmdline_subst = avb_new_cmdline_subst_list();
  if (additional_cmdline_subst == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }

  if (flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION) {
    if (requested_partitions == NULL || requested_partitions[0] == NULL) {
      avb_fatal(
          "Requested partitions cannot be empty when using "
          "AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION");
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT;
      goto fail;
    }

    /* No vbmeta partition, go through each of the requested partitions... */
    for (size_t n = 0; requested_partitions[n] != NULL; n++) {
      ret = load_and_verify_vbmeta(ops,
                                   requested_partitions,
                                   ab_suffix,
                                   flags,
                                   allow_verification_error,
                                   0 /* toplevel_vbmeta_flags */,
                                   0 /* rollback_index_location */,
                                   requested_partitions[n],
                                   avb_strlen(requested_partitions[n]),
                                   NULL /* expected_public_key */,
                                   0 /* expected_public_key_length */,
                                   slot_data,
                                   &algorithm_type,
                                   additional_cmdline_subst);
      if (!allow_verification_error && ret != AVB_SLOT_VERIFY_RESULT_OK) {
        goto fail;
      }
    }

  } else {
    /* Usual path, load "vbmeta"... */
    ret = load_and_verify_vbmeta(ops,
                                 requested_partitions,
                                 ab_suffix,
                                 flags,
                                 allow_verification_error,
                                 0 /* toplevel_vbmeta_flags */,
                                 0 /* rollback_index_location */,
                                 "vbmeta",
                                 avb_strlen("vbmeta"),
                                 NULL /* expected_public_key */,
                                 0 /* expected_public_key_length */,
                                 slot_data,
                                 &algorithm_type,
                                 additional_cmdline_subst);
    if (!allow_verification_error && ret != AVB_SLOT_VERIFY_RESULT_OK) {
      goto fail;
    }
  }

  if (!result_should_continue(ret)) {
    goto fail;
  }

  /* If things check out, mangle the kernel command-line as needed. */
  if (!(flags & AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION)) {
    if (avb_strcmp(slot_data->vbmeta_images[0].partition_name, "vbmeta") != 0) {
      avb_assert(
          avb_strcmp(slot_data->vbmeta_images[0].partition_name, "boot") == 0);
      using_boot_for_vbmeta = true;
    }
  }

  /* Byteswap top-level vbmeta header since we'll need it below. */
  avb_vbmeta_image_header_to_host_byte_order(
      (const AvbVBMetaImageHeader*)slot_data->vbmeta_images[0].vbmeta_data,
      &toplevel_vbmeta);

  /* Fill in |ab_suffix| field. */
  slot_data->ab_suffix = avb_strdup(ab_suffix);
  if (slot_data->ab_suffix == NULL) {
    ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
    goto fail;
  }

  /* If verification is disabled, we are done ... we specifically
   * don't want to add any androidboot.* options since verification
   * is disabled.
   */
  if (toplevel_vbmeta.flags & AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED) {
    /* Since verification is disabled we didn't process any
     * descriptors and thus there's no cmdline... so set root= such
     * that the system partition is mounted.
     */
    avb_assert(slot_data->cmdline == NULL);
    // Devices with dynamic partitions won't have system partition.
    // Instead, it has a large super partition to accommodate *.img files.
    // See b/119551429 for details.
    if (has_system_partition(ops, ab_suffix)) {
      slot_data->cmdline =
          avb_strdup("root=PARTUUID=$(ANDROID_SYSTEM_PARTUUID)");
    } else {
      // The |cmdline| field should be a NUL-terminated string.
      slot_data->cmdline = avb_strdup("");
    }
    if (slot_data->cmdline == NULL) {
      ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
      goto fail;
    }
  } else {
    /* If requested, manage dm-verity mode... */
    AvbHashtreeErrorMode resolved_hashtree_error_mode = hashtree_error_mode;
    if (hashtree_error_mode ==
        AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO) {
      AvbIOResult io_ret;
      io_ret = avb_manage_hashtree_error_mode(
          ops, flags, slot_data, &resolved_hashtree_error_mode);
      if (io_ret != AVB_IO_RESULT_OK) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_IO;
        if (io_ret == AVB_IO_RESULT_ERROR_OOM) {
          ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        }
        goto fail;
      }
    }
    slot_data->resolved_hashtree_error_mode = resolved_hashtree_error_mode;

    /* Add options... */
    AvbSlotVerifyResult sub_ret;
    sub_ret = avb_append_options(ops,
                                 flags,
                                 slot_data,
                                 &toplevel_vbmeta,
                                 algorithm_type,
                                 hashtree_error_mode,
                                 resolved_hashtree_error_mode);
    if (sub_ret != AVB_SLOT_VERIFY_RESULT_OK) {
      ret = sub_ret;
      goto fail;
    }
  }

  /* Substitute $(ANDROID_SYSTEM_PARTUUID) and friends. */
  if (slot_data->cmdline != NULL && avb_strlen(slot_data->cmdline) != 0) {
    char* new_cmdline;
    new_cmdline = avb_sub_cmdline(ops,
                                  slot_data->cmdline,
                                  ab_suffix,
                                  using_boot_for_vbmeta,
                                  additional_cmdline_subst);
    if (new_cmdline != slot_data->cmdline) {
      if (new_cmdline == NULL) {
        ret = AVB_SLOT_VERIFY_RESULT_ERROR_OOM;
        goto fail;
      }
      avb_free(slot_data->cmdline);
      slot_data->cmdline = new_cmdline;
    }
  }

  if (out_data != NULL) {
    *out_data = slot_data;
  } else {
    avb_slot_verify_data_free(slot_data);
  }

  avb_free_cmdline_subst_list(additional_cmdline_subst);
  additional_cmdline_subst = NULL;

  if (!allow_verification_error) {
    avb_assert(ret == AVB_SLOT_VERIFY_RESULT_OK);
  }

  return ret;

fail:
  if (slot_data != NULL) {
    avb_slot_verify_data_free(slot_data);
  }
  if (additional_cmdline_subst != NULL) {
    avb_free_cmdline_subst_list(additional_cmdline_subst);
  }
  return ret;
}

void avb_slot_verify_data_free(AvbSlotVerifyData* data) {
  if (data->ab_suffix != NULL) {
    avb_free(data->ab_suffix);
  }
  if (data->cmdline != NULL) {
    avb_free(data->cmdline);
  }
  if (data->vbmeta_images != NULL) {
    size_t n;
    for (n = 0; n < data->num_vbmeta_images; n++) {
      AvbVBMetaData* vbmeta_image = &data->vbmeta_images[n];
      if (vbmeta_image->partition_name != NULL) {
        avb_free(vbmeta_image->partition_name);
      }
      if (vbmeta_image->vbmeta_data != NULL) {
        avb_free(vbmeta_image->vbmeta_data);
      }
    }
    avb_free(data->vbmeta_images);
  }
  if (data->loaded_partitions != NULL) {
    size_t n;
    for (n = 0; n < data->num_loaded_partitions; n++) {
      AvbPartitionData* loaded_partition = &data->loaded_partitions[n];
      if (loaded_partition->partition_name != NULL) {
        avb_free(loaded_partition->partition_name);
      }
      if (loaded_partition->data != NULL && !loaded_partition->preloaded) {
        avb_free(loaded_partition->data);
      }
    }
    avb_free(data->loaded_partitions);
  }
  avb_free(data);
}

const char* avb_slot_verify_result_to_string(AvbSlotVerifyResult result) {
  const char* ret = NULL;

  switch (result) {
    case AVB_SLOT_VERIFY_RESULT_OK:
      ret = "OK";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_OOM:
      ret = "ERROR_OOM";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_IO:
      ret = "ERROR_IO";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION:
      ret = "ERROR_VERIFICATION";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX:
      ret = "ERROR_ROLLBACK_INDEX";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED:
      ret = "ERROR_PUBLIC_KEY_REJECTED";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA:
      ret = "ERROR_INVALID_METADATA";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION:
      ret = "ERROR_UNSUPPORTED_VERSION";
      break;
    case AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT:
      ret = "ERROR_INVALID_ARGUMENT";
      break;
      /* Do not add a 'default:' case here because of -Wswitch. */
  }

  if (ret == NULL) {
    avb_error("Unknown AvbSlotVerifyResult value.\n");
    ret = "(unknown)";
  }

  return ret;
}

void avb_slot_verify_data_calculate_vbmeta_digest(const AvbSlotVerifyData* data,
                                                  AvbDigestType digest_type,
                                                  uint8_t* out_digest) {
  bool ret = false;
  size_t n;

  switch (digest_type) {
    case AVB_DIGEST_TYPE_SHA256: {
      AvbSHA256Ctx ctx;
      avb_sha256_init(&ctx);
      for (n = 0; n < data->num_vbmeta_images; n++) {
        avb_sha256_update(&ctx,
                          data->vbmeta_images[n].vbmeta_data,
                          data->vbmeta_images[n].vbmeta_size);
      }
      avb_memcpy(out_digest, avb_sha256_final(&ctx), AVB_SHA256_DIGEST_SIZE);
      ret = true;
    } break;

    case AVB_DIGEST_TYPE_SHA512: {
      AvbSHA512Ctx ctx;
      avb_sha512_init(&ctx);
      for (n = 0; n < data->num_vbmeta_images; n++) {
        avb_sha512_update(&ctx,
                          data->vbmeta_images[n].vbmeta_data,
                          data->vbmeta_images[n].vbmeta_size);
      }
      avb_memcpy(out_digest, avb_sha512_final(&ctx), AVB_SHA512_DIGEST_SIZE);
      ret = true;
    } break;

      /* Do not add a 'default:' case here because of -Wswitch. */
  }

  if (!ret) {
    avb_fatal("Unknown digest type");
  }
}

```

`aosp/libavb1.2/src/avb/c/avb_sysdeps_posix.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include <endian.h>
#include <stdarg.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "avb_sysdeps.h"

int avb_memcmp(const void* src1, const void* src2, size_t n) {
  return memcmp(src1, src2, n);
}

void* avb_memcpy(void* dest, const void* src, size_t n) {
  return memcpy(dest, src, n);
}

void* avb_memset(void* dest, const int c, size_t n) {
  return memset(dest, c, n);
}

int avb_strcmp(const char* s1, const char* s2) {
  return strcmp(s1, s2);
}

int avb_strncmp(const char* s1, const char* s2, size_t n) {
  return strncmp(s1, s2, n);
}

size_t avb_strlen(const char* str) {
  return strlen(str);
}

void avb_abort(void) {
  abort();
}

void avb_print(const char* message) {
  fprintf(stderr, "%s", message);
}

void avb_printv(const char* message, ...) {
  va_list ap;
  const char* m;

  va_start(ap, message);
  for (m = message; m != NULL; m = va_arg(ap, const char*)) {
    fprintf(stderr, "%s", m);
  }
  va_end(ap);
}

void* avb_malloc_(size_t size) {
  return malloc(size);
}

void avb_free(void* ptr) {
  free(ptr);
}

uint32_t avb_div_by_10(uint64_t* dividend) {
  uint32_t rem = (uint32_t)(*dividend % 10);
  *dividend /= 10;
  return rem;
}

```

`aosp/libavb1.2/src/avb/c/avb_util.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_util.h"

#include <stdarg.h>

uint16_t avb_be16toh(uint16_t in) {
  uint8_t* d = (uint8_t*)&in;
  uint16_t ret;
  ret = ((uint16_t)d[0]) << 8;
  ret |= ((uint16_t)d[1]);
  return ret;
}

uint32_t avb_be32toh(uint32_t in) {
  uint8_t* d = (uint8_t*)&in;
  uint32_t ret;
  ret = ((uint32_t)d[0]) << 24;
  ret |= ((uint32_t)d[1]) << 16;
  ret |= ((uint32_t)d[2]) << 8;
  ret |= ((uint32_t)d[3]);
  return ret;
}

uint64_t avb_be64toh(uint64_t in) {
  uint8_t* d = (uint8_t*)&in;
  uint64_t ret;
  ret = ((uint64_t)d[0]) << 56;
  ret |= ((uint64_t)d[1]) << 48;
  ret |= ((uint64_t)d[2]) << 40;
  ret |= ((uint64_t)d[3]) << 32;
  ret |= ((uint64_t)d[4]) << 24;
  ret |= ((uint64_t)d[5]) << 16;
  ret |= ((uint64_t)d[6]) << 8;
  ret |= ((uint64_t)d[7]);
  return ret;
}

/* Converts a 16-bit unsigned integer from host to big-endian byte order. */
uint16_t avb_htobe16(uint16_t in) {
  union {
    uint16_t word;
    uint8_t bytes[2];
  } ret;
  ret.bytes[0] = (in >> 8) & 0xff;
  ret.bytes[1] = in & 0xff;
  return ret.word;
}

/* Converts a 32-bit unsigned integer from host to big-endian byte order. */
uint32_t avb_htobe32(uint32_t in) {
  union {
    uint32_t word;
    uint8_t bytes[4];
  } ret;
  ret.bytes[0] = (in >> 24) & 0xff;
  ret.bytes[1] = (in >> 16) & 0xff;
  ret.bytes[2] = (in >> 8) & 0xff;
  ret.bytes[3] = in & 0xff;
  return ret.word;
}

/* Converts a 64-bit unsigned integer from host to big-endian byte order. */
uint64_t avb_htobe64(uint64_t in) {
  union {
    uint64_t word;
    uint8_t bytes[8];
  } ret;
  ret.bytes[0] = (in >> 56) & 0xff;
  ret.bytes[1] = (in >> 48) & 0xff;
  ret.bytes[2] = (in >> 40) & 0xff;
  ret.bytes[3] = (in >> 32) & 0xff;
  ret.bytes[4] = (in >> 24) & 0xff;
  ret.bytes[5] = (in >> 16) & 0xff;
  ret.bytes[6] = (in >> 8) & 0xff;
  ret.bytes[7] = in & 0xff;
  return ret.word;
}

int avb_safe_memcmp(const void* s1, const void* s2, size_t n) {
  const unsigned char* us1 = s1;
  const unsigned char* us2 = s2;
  int result = 0;

  if (0 == n) {
    return 0;
  }

  /*
   * Code snippet without data-dependent branch due to Nate Lawson
   * (nate@root.org) of Root Labs.
   */
  while (n--) {
    result |= *us1++ ^ *us2++;
  }

  return result != 0;
}

bool avb_safe_add_to(uint64_t* value, uint64_t value_to_add) {
  uint64_t original_value;

  avb_assert(value != NULL);

  original_value = *value;

  *value += value_to_add;
  if (*value < original_value) {
    avb_error("Overflow when adding values.\n");
    return false;
  }

  return true;
}

bool avb_safe_add(uint64_t* out_result, uint64_t a, uint64_t b) {
  uint64_t dummy;
  if (out_result == NULL) {
    out_result = &dummy;
  }
  *out_result = a;
  return avb_safe_add_to(out_result, b);
}

bool avb_validate_utf8(const uint8_t* data, size_t num_bytes) {
  size_t n;
  unsigned int num_cc;

  for (n = 0, num_cc = 0; n < num_bytes; n++) {
    uint8_t c = data[n];

    if (num_cc > 0) {
      if ((c & (0x80 | 0x40)) == 0x80) {
        /* 10xx xxxx */
      } else {
        goto fail;
      }
      num_cc--;
    } else {
      if (c < 0x80) {
        num_cc = 0;
      } else if ((c & (0x80 | 0x40 | 0x20)) == (0x80 | 0x40)) {
        /* 110x xxxx */
        num_cc = 1;
      } else if ((c & (0x80 | 0x40 | 0x20 | 0x10)) == (0x80 | 0x40 | 0x20)) {
        /* 1110 xxxx */
        num_cc = 2;
      } else if ((c & (0x80 | 0x40 | 0x20 | 0x10 | 0x08)) ==
                 (0x80 | 0x40 | 0x20 | 0x10)) {
        /* 1111 0xxx */
        num_cc = 3;
      } else {
        goto fail;
      }
    }
  }

  if (num_cc != 0) {
    goto fail;
  }

  return true;

fail:
  return false;
}

bool avb_str_concat(char* buf,
                    size_t buf_size,
                    const char* str1,
                    size_t str1_len,
                    const char* str2,
                    size_t str2_len) {
  uint64_t combined_len;

  // Doesn't make sense to pass 0 for buf_size since there's
  // no room for the terminating NUL byte.
  if (buf_size == 0) {
    return false;
  }

  if (!avb_safe_add(&combined_len, str1_len, str2_len)) {
    avb_error("Overflow when adding string sizes.\n");
    return false;
  }

  if (combined_len > buf_size - 1) {
    avb_error("Insufficient buffer space.\n");
    return false;
  }

  avb_memcpy(buf, str1, str1_len);
  avb_memcpy(buf + str1_len, str2, str2_len);
  buf[combined_len] = '\0';

  return true;
}

void* avb_malloc(size_t size) {
  void* ret = avb_malloc_(size);
  if (ret == NULL) {
    avb_error("Failed to allocate memory.\n");
    return NULL;
  }
  return ret;
}

void* avb_calloc(size_t size) {
  void* ret = avb_malloc(size);
  if (ret == NULL) {
    return NULL;
  }

  avb_memset(ret, '\0', size);
  return ret;
}

char* avb_strdup(const char* str) {
  size_t len = avb_strlen(str);
  char* ret = avb_malloc(len + 1);
  if (ret == NULL) {
    return NULL;
  }

  avb_memcpy(ret, str, len);
  ret[len] = '\0';

  return ret;
}

const char* avb_strstr(const char* haystack, const char* needle) {
  size_t n, m;

  /* Look through |haystack| and check if the first character of
   * |needle| matches. If so, check the rest of |needle|.
   */
  for (n = 0; haystack[n] != '\0'; n++) {
    if (haystack[n] != needle[0]) {
      continue;
    }

    for (m = 1;; m++) {
      if (needle[m] == '\0') {
        return haystack + n;
      }

      if (haystack[n + m] != needle[m]) {
        break;
      }
    }
  }

  return NULL;
}

const char* avb_strv_find_str(const char* const* strings,
                              const char* str,
                              size_t str_size) {
  size_t n;
  for (n = 0; strings[n] != NULL; n++) {
    if (avb_strlen(strings[n]) == str_size &&
        avb_memcmp(strings[n], str, str_size) == 0) {
      return strings[n];
    }
  }
  return NULL;
}

char* avb_replace(const char* str, const char* search, const char* replace) {
  char* ret = NULL;
  size_t ret_len = 0;
  size_t search_len, replace_len;
  const char* str_after_last_replace;

  search_len = avb_strlen(search);
  replace_len = avb_strlen(replace);

  str_after_last_replace = str;
  while (*str != '\0') {
    const char* s;
    size_t num_before;
    size_t num_new;

    s = avb_strstr(str, search);
    if (s == NULL) {
      break;
    }

    num_before = s - str;

    if (ret == NULL) {
      num_new = num_before + replace_len + 1;
      ret = avb_malloc(num_new);
      if (ret == NULL) {
        goto out;
      }
      avb_memcpy(ret, str, num_before);
      avb_memcpy(ret + num_before, replace, replace_len);
      ret[num_new - 1] = '\0';
      ret_len = num_new - 1;
    } else {
      char* new_str;
      num_new = ret_len + num_before + replace_len + 1;
      new_str = avb_malloc(num_new);
      if (new_str == NULL) {
        goto out;
      }
      avb_memcpy(new_str, ret, ret_len);
      avb_memcpy(new_str + ret_len, str, num_before);
      avb_memcpy(new_str + ret_len + num_before, replace, replace_len);
      new_str[num_new - 1] = '\0';
      avb_free(ret);
      ret = new_str;
      ret_len = num_new - 1;
    }

    str = s + search_len;
    str_after_last_replace = str;
  }

  if (ret == NULL) {
    ret = avb_strdup(str_after_last_replace);
    if (ret == NULL) {
      goto out;
    }
  } else {
    size_t num_remaining = avb_strlen(str_after_last_replace);
    size_t num_new = ret_len + num_remaining + 1;
    char* new_str = avb_malloc(num_new);
    if (new_str == NULL) {
      goto out;
    }
    avb_memcpy(new_str, ret, ret_len);
    avb_memcpy(new_str + ret_len, str_after_last_replace, num_remaining);
    new_str[num_new - 1] = '\0';
    avb_free(ret);
    ret = new_str;
    ret_len = num_new - 1;
  }

out:
  return ret;
}

/* We only support a limited amount of strings in avb_strdupv(). */
#define AVB_STRDUPV_MAX_NUM_STRINGS 32

char* avb_strdupv(const char* str, ...) {
  va_list ap;
  const char* strings[AVB_STRDUPV_MAX_NUM_STRINGS];
  size_t lengths[AVB_STRDUPV_MAX_NUM_STRINGS];
  size_t num_strings, n;
  uint64_t total_length;
  char *ret = NULL, *dest;

  num_strings = 0;
  total_length = 0;
  va_start(ap, str);
  do {
    size_t str_len = avb_strlen(str);
    strings[num_strings] = str;
    lengths[num_strings] = str_len;
    if (!avb_safe_add_to(&total_length, str_len)) {
      avb_fatal("Overflow while determining total length.\n");
      break;
    }
    num_strings++;
    if (num_strings == AVB_STRDUPV_MAX_NUM_STRINGS) {
      avb_fatal("Too many strings passed.\n");
      break;
    }
    str = va_arg(ap, const char*);
  } while (str != NULL);
  va_end(ap);

  ret = avb_malloc(total_length + 1);
  if (ret == NULL) {
    goto out;
  }

  dest = ret;
  for (n = 0; n < num_strings; n++) {
    avb_memcpy(dest, strings[n], lengths[n]);
    dest += lengths[n];
  }
  *dest = '\0';
  avb_assert(dest == ret + total_length);

out:
  return ret;
}

const char* avb_basename(const char* str) {
  int64_t n;
  size_t len;

  len = avb_strlen(str);
  if (len >= 2) {
    for (n = len - 2; n >= 0; n--) {
      if (str[n] == '/') {
        return str + n + 1;
      }
    }
  }
  return str;
}

void avb_uppercase(char* str) {
  size_t i;
  for (i = 0; str[i] != '\0'; ++i) {
    if (str[i] <= 0x7A && str[i] >= 0x61) {
      str[i] -= 0x20;
    }
  }
}

char* avb_bin2hex(const uint8_t* data, size_t data_len) {
  const char hex_digits[17] = "0123456789abcdef";
  char* hex_data;
  size_t n;

  hex_data = avb_malloc(data_len * 2 + 1);
  if (hex_data == NULL) {
    return NULL;
  }

  for (n = 0; n < data_len; n++) {
    hex_data[n * 2] = hex_digits[data[n] >> 4];
    hex_data[n * 2 + 1] = hex_digits[data[n] & 0x0f];
  }
  hex_data[n * 2] = '\0';
  return hex_data;
}

size_t avb_uint64_to_base10(uint64_t value,
                            char digits[AVB_MAX_DIGITS_UINT64]) {
  char rev_digits[AVB_MAX_DIGITS_UINT64];
  size_t n, num_digits;

  for (num_digits = 0; num_digits < AVB_MAX_DIGITS_UINT64 - 1;) {
    rev_digits[num_digits++] = avb_div_by_10(&value) + '0';
    if (value == 0) {
      break;
    }
  }

  for (n = 0; n < num_digits; n++) {
    digits[n] = rev_digits[num_digits - 1 - n];
  }
  digits[n] = '\0';
  return n;
}

```

`aosp/libavb1.2/src/avb/c/avb_vbmeta_image.c`:

```c
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_vbmeta_image.h"
#include "avb_crypto.h"
#include "avb_rsa.h"
#include "avb_sha.h"
#include "avb_util.h"
#include "avb_version.h"

AvbVBMetaVerifyResult avb_vbmeta_image_verify(
    const uint8_t* data,
    size_t length,
    const uint8_t** out_public_key_data,
    size_t* out_public_key_length) {
  AvbVBMetaVerifyResult ret;
  AvbVBMetaImageHeader h;
  uint8_t* computed_hash;
  const AvbAlgorithmData* algorithm;
  AvbSHA256Ctx sha256_ctx;
  AvbSHA512Ctx sha512_ctx;
  const uint8_t* header_block;
  const uint8_t* authentication_block;
  const uint8_t* auxiliary_block;
  int verification_result;

  ret = AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER;

  if (out_public_key_data != NULL) {
    *out_public_key_data = NULL;
  }
  if (out_public_key_length != NULL) {
    *out_public_key_length = 0;
  }

  /* Before we byteswap or compare Magic, ensure length is long enough. */
  if (length < sizeof(AvbVBMetaImageHeader)) {
    avb_error("Length is smaller than header.\n");
    goto out;
  }

  /* Ensure magic is correct. */
  if (avb_safe_memcmp(data, AVB_MAGIC, AVB_MAGIC_LEN) != 0) {
    avb_error("Magic is incorrect.\n");
    goto out;
  }

  avb_vbmeta_image_header_to_host_byte_order((const AvbVBMetaImageHeader*)data,
                                             &h);

  /* Ensure we don't attempt to access any fields if we do not meet
   * the specified minimum version of libavb.
   */
  if ((h.required_libavb_version_major != AVB_VERSION_MAJOR) ||
      (h.required_libavb_version_minor > AVB_VERSION_MINOR)) {
    avb_error("Mismatch between image version and libavb version.\n");
    ret = AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION;
    goto out;
  }

  /* Ensure |release_string| ends with a NUL byte. */
  if (h.release_string[AVB_RELEASE_STRING_SIZE - 1] != '\0') {
    avb_error("Release string does not end with a NUL byte.\n");
    goto out;
  }

  /* Ensure inner block sizes are multiple of 64. */
  if ((h.authentication_data_block_size & 0x3f) != 0 ||
      (h.auxiliary_data_block_size & 0x3f) != 0) {
    avb_error("Block size is not a multiple of 64.\n");
    goto out;
  }

  /* Ensure block sizes all add up to at most |length|. */
  uint64_t block_total = sizeof(AvbVBMetaImageHeader);
  if (!avb_safe_add_to(&block_total, h.authentication_data_block_size) ||
      !avb_safe_add_to(&block_total, h.auxiliary_data_block_size)) {
    avb_error("Overflow while computing size of boot image.\n");
    goto out;
  }
  if (block_total > length) {
    avb_error("Block sizes add up to more than given length.\n");
    goto out;
  }

  uintptr_t data_ptr = (uintptr_t)data;
  /* Ensure passed in memory doesn't wrap. */
  if (!avb_safe_add(NULL, (uint64_t)data_ptr, length)) {
    avb_error("Boot image location and length mismatch.\n");
    goto out;
  }

  /* Ensure hash and signature are entirely in the Authentication data block. */
  uint64_t hash_end;
  if (!avb_safe_add(&hash_end, h.hash_offset, h.hash_size) ||
      hash_end > h.authentication_data_block_size) {
    avb_error("Hash is not entirely in its block.\n");
    goto out;
  }
  uint64_t signature_end;
  if (!avb_safe_add(&signature_end, h.signature_offset, h.signature_size) ||
      signature_end > h.authentication_data_block_size) {
    avb_error("Signature is not entirely in its block.\n");
    goto out;
  }

  /* Ensure public key is entirely in the Auxiliary data block. */
  uint64_t pubkey_end;
  if (!avb_safe_add(&pubkey_end, h.public_key_offset, h.public_key_size) ||
      pubkey_end > h.auxiliary_data_block_size) {
    avb_error("Public key is not entirely in its block.\n");
    goto out;
  }

  /* Ensure public key metadata (if set) is entirely in the Auxiliary
   * data block. */
  if (h.public_key_metadata_size > 0) {
    uint64_t pubkey_md_end;
    if (!avb_safe_add(&pubkey_md_end,
                      h.public_key_metadata_offset,
                      h.public_key_metadata_size) ||
        pubkey_md_end > h.auxiliary_data_block_size) {
      avb_error("Public key metadata is not entirely in its block.\n");
      goto out;
    }
  }

  /* Bail early if there's no hash or signature. */
  if (h.algorithm_type == AVB_ALGORITHM_TYPE_NONE) {
    ret = AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED;
    goto out;
  }

  /* Ensure algorithm field is supported. */
  algorithm = avb_get_algorithm_data(h.algorithm_type);
  if (!algorithm) {
    avb_error("Invalid or unknown algorithm.\n");
    goto out;
  }

  /* Bail if the embedded hash size doesn't match the chosen algorithm. */
  if (h.hash_size != algorithm->hash_len) {
    avb_error("Embedded hash has wrong size.\n");
    goto out;
  }

  /* No overflow checks needed from here-on after since all block
   * sizes and offsets have been verified above.
   */

  header_block = data;
  authentication_block = header_block + sizeof(AvbVBMetaImageHeader);
  auxiliary_block = authentication_block + h.authentication_data_block_size;

  switch (h.algorithm_type) {
    /* Explicit fall-through: */
    case AVB_ALGORITHM_TYPE_SHA256_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA256_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA256_RSA8192:
      avb_sha256_init(&sha256_ctx);
      avb_sha256_update(
          &sha256_ctx, header_block, sizeof(AvbVBMetaImageHeader));
      avb_sha256_update(
          &sha256_ctx, auxiliary_block, h.auxiliary_data_block_size);
      computed_hash = avb_sha256_final(&sha256_ctx);
      break;
    /* Explicit fall-through: */
    case AVB_ALGORITHM_TYPE_SHA512_RSA2048:
    case AVB_ALGORITHM_TYPE_SHA512_RSA4096:
    case AVB_ALGORITHM_TYPE_SHA512_RSA8192:
      avb_sha512_init(&sha512_ctx);
      avb_sha512_update(
          &sha512_ctx, header_block, sizeof(AvbVBMetaImageHeader));
      avb_sha512_update(
          &sha512_ctx, auxiliary_block, h.auxiliary_data_block_size);
      computed_hash = avb_sha512_final(&sha512_ctx);
      break;
    default:
      avb_error("Unknown algorithm.\n");
      goto out;
  }

  if (avb_safe_memcmp(authentication_block + h.hash_offset,
                      computed_hash,
                      h.hash_size) != 0) {
    avb_error("Hash does not match!\n");
    ret = AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH;
    goto out;
  }

  verification_result =
      avb_rsa_verify(auxiliary_block + h.public_key_offset,
                     h.public_key_size,
                     authentication_block + h.signature_offset,
                     h.signature_size,
                     authentication_block + h.hash_offset,
                     h.hash_size,
                     algorithm->padding,
                     algorithm->padding_len);

  if (verification_result == 0) {
    ret = AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH;
    goto out;
  }

  if (h.public_key_size > 0) {
    if (out_public_key_data != NULL) {
      *out_public_key_data = auxiliary_block + h.public_key_offset;
    }
    if (out_public_key_length != NULL) {
      *out_public_key_length = h.public_key_size;
    }
  }

  ret = AVB_VBMETA_VERIFY_RESULT_OK;

out:
  return ret;
}

void avb_vbmeta_image_header_to_host_byte_order(const AvbVBMetaImageHeader* src,
                                                AvbVBMetaImageHeader* dest) {
  avb_memcpy(dest, src, sizeof(AvbVBMetaImageHeader));

  dest->required_libavb_version_major =
      avb_be32toh(dest->required_libavb_version_major);
  dest->required_libavb_version_minor =
      avb_be32toh(dest->required_libavb_version_minor);

  dest->authentication_data_block_size =
      avb_be64toh(dest->authentication_data_block_size);
  dest->auxiliary_data_block_size =
      avb_be64toh(dest->auxiliary_data_block_size);

  dest->algorithm_type = avb_be32toh(dest->algorithm_type);

  dest->hash_offset = avb_be64toh(dest->hash_offset);
  dest->hash_size = avb_be64toh(dest->hash_size);

  dest->signature_offset = avb_be64toh(dest->signature_offset);
  dest->signature_size = avb_be64toh(dest->signature_size);

  dest->public_key_offset = avb_be64toh(dest->public_key_offset);
  dest->public_key_size = avb_be64toh(dest->public_key_size);

  dest->public_key_metadata_offset =
      avb_be64toh(dest->public_key_metadata_offset);
  dest->public_key_metadata_size = avb_be64toh(dest->public_key_metadata_size);

  dest->descriptors_offset = avb_be64toh(dest->descriptors_offset);
  dest->descriptors_size = avb_be64toh(dest->descriptors_size);

  dest->rollback_index = avb_be64toh(dest->rollback_index);
  dest->flags = avb_be32toh(dest->flags);
  dest->rollback_index_location = avb_be32toh(dest->rollback_index_location);
}

const char* avb_vbmeta_verify_result_to_string(AvbVBMetaVerifyResult result) {
  const char* ret = NULL;

  switch (result) {
    case AVB_VBMETA_VERIFY_RESULT_OK:
      ret = "OK";
      break;
    case AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED:
      ret = "OK_NOT_SIGNED";
      break;
    case AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER:
      ret = "INVALID_VBMETA_HEADER";
      break;
    case AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION:
      ret = "UNSUPPORTED_VERSION";
      break;
    case AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH:
      ret = "HASH_MISMATCH";
      break;
    case AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH:
      ret = "SIGNATURE_MISMATCH";
      break;
      /* Do not add a 'default:' case here because of -Wswitch. */
  }

  if (ret == NULL) {
    avb_error("Unknown AvbVBMetaVerifyResult value.\n");
    ret = "(unknown)";
  }

  return ret;
}

```

`aosp/libavb1.2/src/avb/c/avb_version.c`:

```c
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#include "avb_version.h"

#define AVB_QUOTE(str) #str
#define AVB_EXPAND_AND_QUOTE(str) AVB_QUOTE(str)

/* Keep in sync with get_release_string() in avbtool. */
const char* avb_version_string(void) {
  return AVB_EXPAND_AND_QUOTE(AVB_VERSION_MAJOR) "." AVB_EXPAND_AND_QUOTE(
      AVB_VERSION_MINOR) "." AVB_EXPAND_AND_QUOTE(AVB_VERSION_SUB);
}

```

`aosp/libavb1.2/src/avb/c/sha256_impl.c`:

```c
/* SHA-256 and SHA-512 implementation based on code by Oliver Gay
 * <olivier.gay@a3.epfl.ch> under a BSD-style license. See below.
 */

/*
 * FIPS 180-2 SHA-224/256/384/512 implementation
 * Last update: 02/02/2007
 * Issue date:  04/30/2005
 *
 * Copyright (C) 2005, 2007 Olivier Gay <olivier.gay@a3.epfl.ch>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the project nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

#include "avb_sha.h"
#include "avb_crypto_ops_impl.h"

#define SHFR(x, n) (x >> n)
#define ROTR(x, n) ((x >> n) | (x << ((sizeof(x) << 3) - n)))
#define ROTL(x, n) ((x << n) | (x >> ((sizeof(x) << 3) - n)))
#define CH(x, y, z) ((x & y) ^ (~x & z))
#define MAJ(x, y, z) ((x & y) ^ (x & z) ^ (y & z))

#define SHA256_F1(x) (ROTR(x, 2) ^ ROTR(x, 13) ^ ROTR(x, 22))
#define SHA256_F2(x) (ROTR(x, 6) ^ ROTR(x, 11) ^ ROTR(x, 25))
#define SHA256_F3(x) (ROTR(x, 7) ^ ROTR(x, 18) ^ SHFR(x, 3))
#define SHA256_F4(x) (ROTR(x, 17) ^ ROTR(x, 19) ^ SHFR(x, 10))

#define UNPACK32(x, str)                 \
  {                                      \
    *((str) + 3) = (uint8_t)((x));       \
    *((str) + 2) = (uint8_t)((x) >> 8);  \
    *((str) + 1) = (uint8_t)((x) >> 16); \
    *((str) + 0) = (uint8_t)((x) >> 24); \
  }

#define UNPACK64(x, str)                         \
  {                                              \
    *((str) + 7) = (uint8_t)x;                   \
    *((str) + 6) = (uint8_t)((uint64_t)x >> 8);  \
    *((str) + 5) = (uint8_t)((uint64_t)x >> 16); \
    *((str) + 4) = (uint8_t)((uint64_t)x >> 24); \
    *((str) + 3) = (uint8_t)((uint64_t)x >> 32); \
    *((str) + 2) = (uint8_t)((uint64_t)x >> 40); \
    *((str) + 1) = (uint8_t)((uint64_t)x >> 48); \
    *((str) + 0) = (uint8_t)((uint64_t)x >> 56); \
  }

#define PACK32(str, x)                                                    \
  {                                                                       \
    *(x) = ((uint32_t) * ((str) + 3)) | ((uint32_t) * ((str) + 2) << 8) | \
           ((uint32_t) * ((str) + 1) << 16) |                             \
           ((uint32_t) * ((str) + 0) << 24);                              \
  }

/* Macros used for loops unrolling */

#define SHA256_SCR(i) \
  { w[i] = SHA256_F4(w[i - 2]) + w[i - 7] + SHA256_F3(w[i - 15]) + w[i - 16]; }

#define SHA256_EXP(a, b, c, d, e, f, g, h, j)                               \
  {                                                                         \
    t1 = wv[h] + SHA256_F2(wv[e]) + CH(wv[e], wv[f], wv[g]) + sha256_k[j] + \
         w[j];                                                              \
    t2 = SHA256_F1(wv[a]) + MAJ(wv[a], wv[b], wv[c]);                       \
    wv[d] += t1;                                                            \
    wv[h] = t1 + t2;                                                        \
  }

static const uint32_t sha256_h0[8] = {0x6a09e667,
                                      0xbb67ae85,
                                      0x3c6ef372,
                                      0xa54ff53a,
                                      0x510e527f,
                                      0x9b05688c,
                                      0x1f83d9ab,
                                      0x5be0cd19};

static const uint32_t sha256_k[64] = {
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1,
    0x923f82a4, 0xab1c5ed5, 0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174, 0xe49b69c1, 0xefbe4786,
    0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147,
    0x06ca6351, 0x14292967, 0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85, 0xa2bfe8a1, 0xa81a664b,
    0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a,
    0x5b9cca4f, 0x682e6ff3, 0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2};

/* SHA-256 implementation */
void avb_sha256_init(AvbSHA256Ctx* avb_ctx) {
  AvbSHA256ImplCtx* ctx = (AvbSHA256ImplCtx*)avb_ctx->reserved;
#ifndef UNROLL_LOOPS
  int i;
  for (i = 0; i < 8; i++) {
    ctx->h[i] = sha256_h0[i];
  }
#else
  ctx->h[0] = sha256_h0[0];
  ctx->h[1] = sha256_h0[1];
  ctx->h[2] = sha256_h0[2];
  ctx->h[3] = sha256_h0[3];
  ctx->h[4] = sha256_h0[4];
  ctx->h[5] = sha256_h0[5];
  ctx->h[6] = sha256_h0[6];
  ctx->h[7] = sha256_h0[7];
#endif /* !UNROLL_LOOPS */

  ctx->len = 0;
  ctx->tot_len = 0;
}

static void SHA256_transform(AvbSHA256ImplCtx* ctx,
                             const uint8_t* message,
                             size_t block_nb) {
  uint32_t w[64];
  uint32_t wv[8];
  uint32_t t1, t2;
  const unsigned char* sub_block;
  size_t i;

#ifndef UNROLL_LOOPS
  size_t j;
#endif

  for (i = 0; i < block_nb; i++) {
    sub_block = message + (i << 6);

#ifndef UNROLL_LOOPS
    for (j = 0; j < 16; j++) {
      PACK32(&sub_block[j << 2], &w[j]);
    }

    for (j = 16; j < 64; j++) {
      SHA256_SCR(j);
    }

    for (j = 0; j < 8; j++) {
      wv[j] = ctx->h[j];
    }

    for (j = 0; j < 64; j++) {
      t1 = wv[7] + SHA256_F2(wv[4]) + CH(wv[4], wv[5], wv[6]) + sha256_k[j] +
           w[j];
      t2 = SHA256_F1(wv[0]) + MAJ(wv[0], wv[1], wv[2]);
      wv[7] = wv[6];
      wv[6] = wv[5];
      wv[5] = wv[4];
      wv[4] = wv[3] + t1;
      wv[3] = wv[2];
      wv[2] = wv[1];
      wv[1] = wv[0];
      wv[0] = t1 + t2;
    }

    for (j = 0; j < 8; j++) {
      ctx->h[j] += wv[j];
    }
#else
    PACK32(&sub_block[0], &w[0]);
    PACK32(&sub_block[4], &w[1]);
    PACK32(&sub_block[8], &w[2]);
    PACK32(&sub_block[12], &w[3]);
    PACK32(&sub_block[16], &w[4]);
    PACK32(&sub_block[20], &w[5]);
    PACK32(&sub_block[24], &w[6]);
    PACK32(&sub_block[28], &w[7]);
    PACK32(&sub_block[32], &w[8]);
    PACK32(&sub_block[36], &w[9]);
    PACK32(&sub_block[40], &w[10]);
    PACK32(&sub_block[44], &w[11]);
    PACK32(&sub_block[48], &w[12]);
    PACK32(&sub_block[52], &w[13]);
    PACK32(&sub_block[56], &w[14]);
    PACK32(&sub_block[60], &w[15]);

    SHA256_SCR(16);
    SHA256_SCR(17);
    SHA256_SCR(18);
    SHA256_SCR(19);
    SHA256_SCR(20);
    SHA256_SCR(21);
    SHA256_SCR(22);
    SHA256_SCR(23);
    SHA256_SCR(24);
    SHA256_SCR(25);
    SHA256_SCR(26);
    SHA256_SCR(27);
    SHA256_SCR(28);
    SHA256_SCR(29);
    SHA256_SCR(30);
    SHA256_SCR(31);
    SHA256_SCR(32);
    SHA256_SCR(33);
    SHA256_SCR(34);
    SHA256_SCR(35);
    SHA256_SCR(36);
    SHA256_SCR(37);
    SHA256_SCR(38);
    SHA256_SCR(39);
    SHA256_SCR(40);
    SHA256_SCR(41);
    SHA256_SCR(42);
    SHA256_SCR(43);
    SHA256_SCR(44);
    SHA256_SCR(45);
    SHA256_SCR(46);
    SHA256_SCR(47);
    SHA256_SCR(48);
    SHA256_SCR(49);
    SHA256_SCR(50);
    SHA256_SCR(51);
    SHA256_SCR(52);
    SHA256_SCR(53);
    SHA256_SCR(54);
    SHA256_SCR(55);
    SHA256_SCR(56);
    SHA256_SCR(57);
    SHA256_SCR(58);
    SHA256_SCR(59);
    SHA256_SCR(60);
    SHA256_SCR(61);
    SHA256_SCR(62);
    SHA256_SCR(63);

    wv[0] = ctx->h[0];
    wv[1] = ctx->h[1];
    wv[2] = ctx->h[2];
    wv[3] = ctx->h[3];
    wv[4] = ctx->h[4];
    wv[5] = ctx->h[5];
    wv[6] = ctx->h[6];
    wv[7] = ctx->h[7];

    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 0);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 1);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 2);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 3);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 4);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 5);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 6);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 7);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 8);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 9);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 10);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 11);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 12);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 13);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 14);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 15);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 16);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 17);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 18);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 19);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 20);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 21);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 22);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 23);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 24);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 25);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 26);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 27);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 28);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 29);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 30);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 31);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 32);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 33);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 34);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 35);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 36);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 37);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 38);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 39);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 40);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 41);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 42);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 43);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 44);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 45);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 46);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 47);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 48);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 49);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 50);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 51);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 52);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 53);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 54);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 55);
    SHA256_EXP(0, 1, 2, 3, 4, 5, 6, 7, 56);
    SHA256_EXP(7, 0, 1, 2, 3, 4, 5, 6, 57);
    SHA256_EXP(6, 7, 0, 1, 2, 3, 4, 5, 58);
    SHA256_EXP(5, 6, 7, 0, 1, 2, 3, 4, 59);
    SHA256_EXP(4, 5, 6, 7, 0, 1, 2, 3, 60);
    SHA256_EXP(3, 4, 5, 6, 7, 0, 1, 2, 61);
    SHA256_EXP(2, 3, 4, 5, 6, 7, 0, 1, 62);
    SHA256_EXP(1, 2, 3, 4, 5, 6, 7, 0, 63);

    ctx->h[0] += wv[0];
    ctx->h[1] += wv[1];
    ctx->h[2] += wv[2];
    ctx->h[3] += wv[3];
    ctx->h[4] += wv[4];
    ctx->h[5] += wv[5];
    ctx->h[6] += wv[6];
    ctx->h[7] += wv[7];
#endif /* !UNROLL_LOOPS */
  }
}

void avb_sha256_update(AvbSHA256Ctx* avb_ctx, const uint8_t* data, size_t len) {
  AvbSHA256ImplCtx* ctx = (AvbSHA256ImplCtx*)avb_ctx->reserved;
  size_t block_nb;
  size_t new_len, rem_len, tmp_len;
  const uint8_t* shifted_data;

  tmp_len = AVB_SHA256_BLOCK_SIZE - ctx->len;
  rem_len = len < tmp_len ? len : tmp_len;

  avb_memcpy(&ctx->block[ctx->len], data, rem_len);

  if (ctx->len + len < AVB_SHA256_BLOCK_SIZE) {
    ctx->len += len;
    return;
  }

  new_len = len - rem_len;
  block_nb = new_len / AVB_SHA256_BLOCK_SIZE;

  shifted_data = data + rem_len;

  SHA256_transform(ctx, ctx->block, 1);
  SHA256_transform(ctx, shifted_data, block_nb);

  rem_len = new_len % AVB_SHA256_BLOCK_SIZE;

  avb_memcpy(ctx->block, &shifted_data[block_nb << 6], rem_len);

  ctx->len = rem_len;
  ctx->tot_len += (block_nb + 1) << 6;
}

uint8_t* avb_sha256_final(AvbSHA256Ctx* avb_ctx) {
  AvbSHA256ImplCtx* ctx = (AvbSHA256ImplCtx*)avb_ctx->reserved;
  size_t block_nb;
  size_t pm_len;
  uint64_t len_b;
#ifndef UNROLL_LOOPS
  size_t i;
#endif

  block_nb =
      (1 + ((AVB_SHA256_BLOCK_SIZE - 9) < (ctx->len % AVB_SHA256_BLOCK_SIZE)));

  len_b = (ctx->tot_len + ctx->len) << 3;
  pm_len = block_nb << 6;

  avb_memset(ctx->block + ctx->len, 0, pm_len - ctx->len);
  ctx->block[ctx->len] = 0x80;
  UNPACK64(len_b, ctx->block + pm_len - 8);

  SHA256_transform(ctx, ctx->block, block_nb);

#ifndef UNROLL_LOOPS
  for (i = 0; i < 8; i++) {
    UNPACK32(ctx->h[i], &avb_ctx->buf[i << 2]);
  }
#else
  UNPACK32(ctx->h[0], &avb_ctx->buf[0]);
  UNPACK32(ctx->h[1], &avb_ctx->buf[4]);
  UNPACK32(ctx->h[2], &avb_ctx->buf[8]);
  UNPACK32(ctx->h[3], &avb_ctx->buf[12]);
  UNPACK32(ctx->h[4], &avb_ctx->buf[16]);
  UNPACK32(ctx->h[5], &avb_ctx->buf[20]);
  UNPACK32(ctx->h[6], &avb_ctx->buf[24]);
  UNPACK32(ctx->h[7], &avb_ctx->buf[28]);
#endif /* !UNROLL_LOOPS */

  return avb_ctx->buf;
}

```

`aosp/libavb1.2/src/avb/c/sha512_impl.c`:

```c
/* SHA-256 and SHA-512 implementation based on code by Oliver Gay
 * <olivier.gay@a3.epfl.ch> under a BSD-style license. See below.
 */

/*
 * FIPS 180-2 SHA-224/256/384/512 implementation
 * Last update: 02/02/2007
 * Issue date:  04/30/2005
 *
 * Copyright (C) 2005, 2007 Olivier Gay <olivier.gay@a3.epfl.ch>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the project nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

#include "avb_sha.h"
#include "avb_crypto_ops_impl.h"

#define SHFR(x, n) (x >> n)
#define ROTR(x, n) ((x >> n) | (x << ((sizeof(x) << 3) - n)))
#define ROTL(x, n) ((x << n) | (x >> ((sizeof(x) << 3) - n)))
#define CH(x, y, z) ((x & y) ^ (~x & z))
#define MAJ(x, y, z) ((x & y) ^ (x & z) ^ (y & z))

#define SHA512_F1(x) (ROTR(x, 28) ^ ROTR(x, 34) ^ ROTR(x, 39))
#define SHA512_F2(x) (ROTR(x, 14) ^ ROTR(x, 18) ^ ROTR(x, 41))
#define SHA512_F3(x) (ROTR(x, 1) ^ ROTR(x, 8) ^ SHFR(x, 7))
#define SHA512_F4(x) (ROTR(x, 19) ^ ROTR(x, 61) ^ SHFR(x, 6))

#define UNPACK32(x, str)                 \
  {                                      \
    *((str) + 3) = (uint8_t)((x));       \
    *((str) + 2) = (uint8_t)((x) >> 8);  \
    *((str) + 1) = (uint8_t)((x) >> 16); \
    *((str) + 0) = (uint8_t)((x) >> 24); \
  }

#define UNPACK64(x, str)                         \
  {                                              \
    *((str) + 7) = (uint8_t)x;                   \
    *((str) + 6) = (uint8_t)((uint64_t)x >> 8);  \
    *((str) + 5) = (uint8_t)((uint64_t)x >> 16); \
    *((str) + 4) = (uint8_t)((uint64_t)x >> 24); \
    *((str) + 3) = (uint8_t)((uint64_t)x >> 32); \
    *((str) + 2) = (uint8_t)((uint64_t)x >> 40); \
    *((str) + 1) = (uint8_t)((uint64_t)x >> 48); \
    *((str) + 0) = (uint8_t)((uint64_t)x >> 56); \
  }

#define PACK64(str, x)                                                        \
  {                                                                           \
    *(x) =                                                                    \
        ((uint64_t) * ((str) + 7)) | ((uint64_t) * ((str) + 6) << 8) |        \
        ((uint64_t) * ((str) + 5) << 16) | ((uint64_t) * ((str) + 4) << 24) | \
        ((uint64_t) * ((str) + 3) << 32) | ((uint64_t) * ((str) + 2) << 40) | \
        ((uint64_t) * ((str) + 1) << 48) | ((uint64_t) * ((str) + 0) << 56);  \
  }

/* Macros used for loops unrolling */

#define SHA512_SCR(i) \
  { w[i] = SHA512_F4(w[i - 2]) + w[i - 7] + SHA512_F3(w[i - 15]) + w[i - 16]; }

#define SHA512_EXP(a, b, c, d, e, f, g, h, j)                               \
  {                                                                         \
    t1 = wv[h] + SHA512_F2(wv[e]) + CH(wv[e], wv[f], wv[g]) + sha512_k[j] + \
         w[j];                                                              \
    t2 = SHA512_F1(wv[a]) + MAJ(wv[a], wv[b], wv[c]);                       \
    wv[d] += t1;                                                            \
    wv[h] = t1 + t2;                                                        \
  }

static const uint64_t sha512_h0[8] = {0x6a09e667f3bcc908ULL,
                                      0xbb67ae8584caa73bULL,
                                      0x3c6ef372fe94f82bULL,
                                      0xa54ff53a5f1d36f1ULL,
                                      0x510e527fade682d1ULL,
                                      0x9b05688c2b3e6c1fULL,
                                      0x1f83d9abfb41bd6bULL,
                                      0x5be0cd19137e2179ULL};

static const uint64_t sha512_k[80] = {
    0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL, 0xb5c0fbcfec4d3b2fULL,
    0xe9b5dba58189dbbcULL, 0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL,
    0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL, 0xd807aa98a3030242ULL,
    0x12835b0145706fbeULL, 0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,
    0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL, 0x9bdc06a725c71235ULL,
    0xc19bf174cf692694ULL, 0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL,
    0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL, 0x2de92c6f592b0275ULL,
    0x4a7484aa6ea6e483ULL, 0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,
    0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL, 0xb00327c898fb213fULL,
    0xbf597fc7beef0ee4ULL, 0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL,
    0x06ca6351e003826fULL, 0x142929670a0e6e70ULL, 0x27b70a8546d22ffcULL,
    0x2e1b21385c26c926ULL, 0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,
    0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL, 0x81c2c92e47edaee6ULL,
    0x92722c851482353bULL, 0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL,
    0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL, 0xd192e819d6ef5218ULL,
    0xd69906245565a910ULL, 0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,
    0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL, 0x2748774cdf8eeb99ULL,
    0x34b0bcb5e19b48a8ULL, 0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL,
    0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL, 0x748f82ee5defb2fcULL,
    0x78a5636f43172f60ULL, 0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,
    0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL, 0xbef9a3f7b2c67915ULL,
    0xc67178f2e372532bULL, 0xca273eceea26619cULL, 0xd186b8c721c0c207ULL,
    0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL, 0x06f067aa72176fbaULL,
    0x0a637dc5a2c898a6ULL, 0x113f9804bef90daeULL, 0x1b710b35131c471bULL,
    0x28db77f523047d84ULL, 0x32caab7b40c72493ULL, 0x3c9ebe0a15c9bebcULL,
    0x431d67c49c100d4cULL, 0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL,
    0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL};

/* SHA-512 implementation */

void avb_sha512_init(AvbSHA512Ctx* avb_ctx) {
  AvbSHA512ImplCtx* ctx = (AvbSHA512ImplCtx*)avb_ctx->reserved;
#ifdef UNROLL_LOOPS_SHA512
  ctx->h[0] = sha512_h0[0];
  ctx->h[1] = sha512_h0[1];
  ctx->h[2] = sha512_h0[2];
  ctx->h[3] = sha512_h0[3];
  ctx->h[4] = sha512_h0[4];
  ctx->h[5] = sha512_h0[5];
  ctx->h[6] = sha512_h0[6];
  ctx->h[7] = sha512_h0[7];
#else
  int i;

  for (i = 0; i < 8; i++)
    ctx->h[i] = sha512_h0[i];
#endif /* UNROLL_LOOPS_SHA512 */

  ctx->len = 0;
  ctx->tot_len = 0;
}

static void SHA512_transform(AvbSHA512ImplCtx* ctx,
                             const uint8_t* message,
                             size_t block_nb) {
  uint64_t w[80];
  uint64_t wv[8];
  uint64_t t1, t2;
  const uint8_t* sub_block;
  size_t i, j;

  for (i = 0; i < block_nb; i++) {
    sub_block = message + (i << 7);

#ifdef UNROLL_LOOPS_SHA512
    PACK64(&sub_block[0], &w[0]);
    PACK64(&sub_block[8], &w[1]);
    PACK64(&sub_block[16], &w[2]);
    PACK64(&sub_block[24], &w[3]);
    PACK64(&sub_block[32], &w[4]);
    PACK64(&sub_block[40], &w[5]);
    PACK64(&sub_block[48], &w[6]);
    PACK64(&sub_block[56], &w[7]);
    PACK64(&sub_block[64], &w[8]);
    PACK64(&sub_block[72], &w[9]);
    PACK64(&sub_block[80], &w[10]);
    PACK64(&sub_block[88], &w[11]);
    PACK64(&sub_block[96], &w[12]);
    PACK64(&sub_block[104], &w[13]);
    PACK64(&sub_block[112], &w[14]);
    PACK64(&sub_block[120], &w[15]);

    SHA512_SCR(16);
    SHA512_SCR(17);
    SHA512_SCR(18);
    SHA512_SCR(19);
    SHA512_SCR(20);
    SHA512_SCR(21);
    SHA512_SCR(22);
    SHA512_SCR(23);
    SHA512_SCR(24);
    SHA512_SCR(25);
    SHA512_SCR(26);
    SHA512_SCR(27);
    SHA512_SCR(28);
    SHA512_SCR(29);
    SHA512_SCR(30);
    SHA512_SCR(31);
    SHA512_SCR(32);
    SHA512_SCR(33);
    SHA512_SCR(34);
    SHA512_SCR(35);
    SHA512_SCR(36);
    SHA512_SCR(37);
    SHA512_SCR(38);
    SHA512_SCR(39);
    SHA512_SCR(40);
    SHA512_SCR(41);
    SHA512_SCR(42);
    SHA512_SCR(43);
    SHA512_SCR(44);
    SHA512_SCR(45);
    SHA512_SCR(46);
    SHA512_SCR(47);
    SHA512_SCR(48);
    SHA512_SCR(49);
    SHA512_SCR(50);
    SHA512_SCR(51);
    SHA512_SCR(52);
    SHA512_SCR(53);
    SHA512_SCR(54);
    SHA512_SCR(55);
    SHA512_SCR(56);
    SHA512_SCR(57);
    SHA512_SCR(58);
    SHA512_SCR(59);
    SHA512_SCR(60);
    SHA512_SCR(61);
    SHA512_SCR(62);
    SHA512_SCR(63);
    SHA512_SCR(64);
    SHA512_SCR(65);
    SHA512_SCR(66);
    SHA512_SCR(67);
    SHA512_SCR(68);
    SHA512_SCR(69);
    SHA512_SCR(70);
    SHA512_SCR(71);
    SHA512_SCR(72);
    SHA512_SCR(73);
    SHA512_SCR(74);
    SHA512_SCR(75);
    SHA512_SCR(76);
    SHA512_SCR(77);
    SHA512_SCR(78);
    SHA512_SCR(79);

    wv[0] = ctx->h[0];
    wv[1] = ctx->h[1];
    wv[2] = ctx->h[2];
    wv[3] = ctx->h[3];
    wv[4] = ctx->h[4];
    wv[5] = ctx->h[5];
    wv[6] = ctx->h[6];
    wv[7] = ctx->h[7];

    j = 0;

    do {
      SHA512_EXP(0, 1, 2, 3, 4, 5, 6, 7, j);
      j++;
      SHA512_EXP(7, 0, 1, 2, 3, 4, 5, 6, j);
      j++;
      SHA512_EXP(6, 7, 0, 1, 2, 3, 4, 5, j);
      j++;
      SHA512_EXP(5, 6, 7, 0, 1, 2, 3, 4, j);
      j++;
      SHA512_EXP(4, 5, 6, 7, 0, 1, 2, 3, j);
      j++;
      SHA512_EXP(3, 4, 5, 6, 7, 0, 1, 2, j);
      j++;
      SHA512_EXP(2, 3, 4, 5, 6, 7, 0, 1, j);
      j++;
      SHA512_EXP(1, 2, 3, 4, 5, 6, 7, 0, j);
      j++;
    } while (j < 80);

    ctx->h[0] += wv[0];
    ctx->h[1] += wv[1];
    ctx->h[2] += wv[2];
    ctx->h[3] += wv[3];
    ctx->h[4] += wv[4];
    ctx->h[5] += wv[5];
    ctx->h[6] += wv[6];
    ctx->h[7] += wv[7];
#else
    for (j = 0; j < 16; j++) {
      PACK64(&sub_block[j << 3], &w[j]);
    }

    for (j = 16; j < 80; j++) {
      SHA512_SCR(j);
    }

    for (j = 0; j < 8; j++) {
      wv[j] = ctx->h[j];
    }

    for (j = 0; j < 80; j++) {
      t1 = wv[7] + SHA512_F2(wv[4]) + CH(wv[4], wv[5], wv[6]) + sha512_k[j] +
           w[j];
      t2 = SHA512_F1(wv[0]) + MAJ(wv[0], wv[1], wv[2]);
      wv[7] = wv[6];
      wv[6] = wv[5];
      wv[5] = wv[4];
      wv[4] = wv[3] + t1;
      wv[3] = wv[2];
      wv[2] = wv[1];
      wv[1] = wv[0];
      wv[0] = t1 + t2;
    }

    for (j = 0; j < 8; j++)
      ctx->h[j] += wv[j];
#endif /* UNROLL_LOOPS_SHA512 */
  }
}

void avb_sha512_update(AvbSHA512Ctx* avb_ctx, const uint8_t* data, size_t len) {
  AvbSHA512ImplCtx* ctx = (AvbSHA512ImplCtx*)avb_ctx->reserved;
  size_t block_nb;
  size_t new_len, rem_len, tmp_len;
  const uint8_t* shifted_data;

  tmp_len = AVB_SHA512_BLOCK_SIZE - ctx->len;
  rem_len = len < tmp_len ? len : tmp_len;

  avb_memcpy(&ctx->block[ctx->len], data, rem_len);

  if (ctx->len + len < AVB_SHA512_BLOCK_SIZE) {
    ctx->len += len;
    return;
  }

  new_len = len - rem_len;
  block_nb = new_len / AVB_SHA512_BLOCK_SIZE;

  shifted_data = data + rem_len;

  SHA512_transform(ctx, ctx->block, 1);
  SHA512_transform(ctx, shifted_data, block_nb);

  rem_len = new_len % AVB_SHA512_BLOCK_SIZE;

  avb_memcpy(ctx->block, &shifted_data[block_nb << 7], rem_len);

  ctx->len = rem_len;
  ctx->tot_len += (block_nb + 1) << 7;
}

uint8_t* avb_sha512_final(AvbSHA512Ctx* avb_ctx) {
  AvbSHA512ImplCtx* ctx = (AvbSHA512ImplCtx*)avb_ctx->reserved;
  size_t block_nb;
  size_t pm_len;
  uint64_t len_b;

#ifndef UNROLL_LOOPS_SHA512
  size_t i;
#endif

  block_nb =
      1 + ((AVB_SHA512_BLOCK_SIZE - 17) < (ctx->len % AVB_SHA512_BLOCK_SIZE));

  len_b = (ctx->tot_len + ctx->len) << 3;
  pm_len = block_nb << 7;

  avb_memset(ctx->block + ctx->len, 0, pm_len - ctx->len);
  ctx->block[ctx->len] = 0x80;
  UNPACK64(len_b, ctx->block + pm_len - 8);

  SHA512_transform(ctx, ctx->block, block_nb);

#ifdef UNROLL_LOOPS_SHA512
  UNPACK64(ctx->h[0], &avb_ctx->buf[0]);
  UNPACK64(ctx->h[1], &avb_ctx->buf[8]);
  UNPACK64(ctx->h[2], &avb_ctx->buf[16]);
  UNPACK64(ctx->h[3], &avb_ctx->buf[24]);
  UNPACK64(ctx->h[4], &avb_ctx->buf[32]);
  UNPACK64(ctx->h[5], &avb_ctx->buf[40]);
  UNPACK64(ctx->h[6], &avb_ctx->buf[48]);
  UNPACK64(ctx->h[7], &avb_ctx->buf[56]);
#else
  for (i = 0; i < 8; i++)
    UNPACK64(ctx->h[i], &avb_ctx->buf[i << 3]);
#endif /* UNROLL_LOOPS_SHA512 */

  return avb_ctx->buf;
}

```

`aosp/libavb1.2/src/avb/headers/avb_chain_partition_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_CHAIN_PARTITION_DESCRIPTOR_H_
#define AVB_CHAIN_PARTITION_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* A descriptor containing a pointer to signed integrity data stored
 * on another partition. The descriptor contains the partition name in
 * question (without the A/B suffix), the public key used to sign the
 * integrity data, and rollback index location to use for rollback
 * protection.
 *
 * Following this struct are |partition_name_len| bytes of the
 * partition name (UTF-8 encoded) and |public_key_len| bytes of the
 * public key.
 *
 * The |reserved| field is for future expansion and must be set to NUL
 * bytes.
 */
typedef struct AvbChainPartitionDescriptor {
  AvbDescriptor parent_descriptor;
  uint32_t rollback_index_location;
  uint32_t partition_name_len;
  uint32_t public_key_len;
  uint8_t reserved[64];
} AVB_ATTR_PACKED AvbChainPartitionDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_chain_partition_descriptor_validate_and_byteswap(
    const AvbChainPartitionDescriptor* src,
    AvbChainPartitionDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_CHAIN_PARTITION_DESCRIPTOR_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_cmdline.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_sha.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_CMDLINE_H_
#define AVB_CMDLINE_H_

#include "avb_ops.h"
#include "avb_slot_verify.h"

/* Maximum allow length (in bytes) of a partition name, including
 * ab_suffix.
 */
#define AVB_PART_NAME_MAX_SIZE 32

#define AVB_MAX_NUM_CMDLINE_SUBST 10

/* Holds information about command-line substitutions. */
typedef struct AvbCmdlineSubstList {
  size_t size;
  char* tokens[AVB_MAX_NUM_CMDLINE_SUBST];
  char* values[AVB_MAX_NUM_CMDLINE_SUBST];
} AvbCmdlineSubstList;

/* Substitutes all variables (e.g. $(ANDROID_SYSTEM_PARTUUID)) with
 * values. Returns NULL on OOM, otherwise the cmdline with values
 * replaced.
 */
char* avb_sub_cmdline(AvbOps* ops,
                      const char* cmdline,
                      const char* ab_suffix,
                      bool using_boot_for_vbmeta,
                      const AvbCmdlineSubstList* additional_substitutions);

AvbSlotVerifyResult avb_append_options(
    AvbOps* ops,
    AvbSlotVerifyFlags flags,
    AvbSlotVerifyData* slot_data,
    AvbVBMetaImageHeader* toplevel_vbmeta,
    AvbAlgorithmType algorithm_type,
    AvbHashtreeErrorMode hashtree_error_mode,
    AvbHashtreeErrorMode resolved_hashtree_error_mode);

/* Allocates and initializes a new command line substitution list. Free with
 * |avb_free_cmdline_subst_list|.
 */
AvbCmdlineSubstList* avb_new_cmdline_subst_list(void);

/* Use this instead of |avb_free| to deallocate a AvbCmdlineSubstList. */
void avb_free_cmdline_subst_list(AvbCmdlineSubstList* cmdline_subst);

/* Adds a hashtree root digest to be substituted in $(AVB_*_ROOT_DIGEST)
 * variables. The partition name differentiates the variable. For example, if
 * |part_name| is "foo" then $(AVB_FOO_ROOT_DIGEST) will be substituted with the
 * hex encoding of the digest. The substitution will be added to
 * |out_cmdline_subst|. Returns AVB_SLOT_VERIFY_RESULT_OK on success.
 */
AvbSlotVerifyResult avb_add_root_digest_substitution(
    const char* part_name,
    const uint8_t* digest,
    size_t digest_size,
    AvbCmdlineSubstList* out_cmdline_subst);

#endif

```

`aosp/libavb1.2/src/avb/headers/avb_crypto.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_CRYPTO_H_
#define AVB_CRYPTO_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Size of a RSA-2048 signature. */
#define AVB_RSA2048_NUM_BYTES 256

/* Size of a RSA-4096 signature. */
#define AVB_RSA4096_NUM_BYTES 512

/* Size of a RSA-8192 signature. */
#define AVB_RSA8192_NUM_BYTES 1024

/* Size in bytes of a SHA-1 digest. */
#define AVB_SHA1_DIGEST_SIZE 20

/* Size in bytes of a SHA-256 digest. */
#define AVB_SHA256_DIGEST_SIZE 32

/* Size in bytes of a SHA-512 digest. */
#define AVB_SHA512_DIGEST_SIZE 64

/* Possible digest types supported by libavb routines. */
typedef enum {
  AVB_DIGEST_TYPE_SHA256,
  AVB_DIGEST_TYPE_SHA512,
} AvbDigestType;

/* Algorithms that can be used in the vbmeta image for
 * verification. An algorithm consists of a hash type and a signature
 * type.
 *
 * The data used to calculate the hash is the three blocks mentioned
 * in the documentation for |AvbVBMetaImageHeader| except for the data
 * in the "Authentication data" block.
 *
 * For signatures with RSA keys, PKCS v1.5 padding is used. The public
 * key data is stored in the auxiliary data block, see
 * |AvbRSAPublicKeyHeader| for the serialization format.
 *
 * Each algorithm type is described below:
 *
 * AVB_ALGORITHM_TYPE_NONE: There is no hash, no signature of the
 * data, and no public key. The data cannot be verified. The fields
 * |hash_size|, |signature_size|, and |public_key_size| must be zero.
 *
 * AVB_ALGORITHM_TYPE_SHA256_RSA2048: The hash function used is
 * SHA-256, resulting in 32 bytes of hash digest data. This hash is
 * signed with a 2048-bit RSA key. The field |hash_size| must be 32,
 * |signature_size| must be 256, and the public key data must have
 * |key_num_bits| set to 2048.
 *
 * AVB_ALGORITHM_TYPE_SHA256_RSA4096: Like above, but only with
 * a 4096-bit RSA key and |signature_size| set to 512.
 *
 * AVB_ALGORITHM_TYPE_SHA256_RSA8192: Like above, but only with
 * a 8192-bit RSA key and |signature_size| set to 1024.
 *
 * AVB_ALGORITHM_TYPE_SHA512_RSA2048: The hash function used is
 * SHA-512, resulting in 64 bytes of hash digest data. This hash is
 * signed with a 2048-bit RSA key. The field |hash_size| must be 64,
 * |signature_size| must be 256, and the public key data must have
 * |key_num_bits| set to 2048.
 *
 * AVB_ALGORITHM_TYPE_SHA512_RSA4096: Like above, but only with
 * a 4096-bit RSA key and |signature_size| set to 512.
 *
 * AVB_ALGORITHM_TYPE_SHA512_RSA8192: Like above, but only with
 * a 8192-bit RSA key and |signature_size| set to 1024.
 */
typedef enum {
  AVB_ALGORITHM_TYPE_NONE,
  AVB_ALGORITHM_TYPE_SHA256_RSA2048,
  AVB_ALGORITHM_TYPE_SHA256_RSA4096,
  AVB_ALGORITHM_TYPE_SHA256_RSA8192,
  AVB_ALGORITHM_TYPE_SHA512_RSA2048,
  AVB_ALGORITHM_TYPE_SHA512_RSA4096,
  AVB_ALGORITHM_TYPE_SHA512_RSA8192,
  _AVB_ALGORITHM_NUM_TYPES
} AvbAlgorithmType;

/* Holds algorithm-specific data. The |padding| is needed by avb_rsa_verify. */
typedef struct {
  const uint8_t* padding;
  size_t padding_len;
  size_t hash_len;
} AvbAlgorithmData;

/* Provides algorithm-specific data for a given |algorithm|. Returns NULL if
 * |algorithm| is invalid.
 */
const AvbAlgorithmData* avb_get_algorithm_data(AvbAlgorithmType algorithm)
    AVB_ATTR_WARN_UNUSED_RESULT;

/* The header for a serialized RSA public key.
 *
 * The size of the key is given by |key_num_bits|, for example 2048
 * for a RSA-2048 key. By definition, a RSA public key is the pair (n,
 * e) where |n| is the modulus (which can be represented in
 * |key_num_bits| bits) and |e| is the public exponent. The exponent
 * is not stored since it's assumed to always be 65537.
 *
 * To optimize verification, the key block includes two precomputed
 * values, |n0inv| (fits in 32 bits) and |rr| and can always be
 * represented in |key_num_bits|.

 * The value |n0inv| is the value -1/n[0] (mod 2^32). The value |rr|
 * is (2^key_num_bits)^2 (mod n).
 *
 * Following this header is |key_num_bits| bits of |n|, then
 * |key_num_bits| bits of |rr|. Both values are stored with most
 * significant bit first. Each serialized number takes up
 * |key_num_bits|/8 bytes.
 *
 * All fields in this struct are stored in network byte order when
 * serialized.  To generate a copy with fields swapped to native byte
 * order, use the function avb_rsa_public_key_header_validate_and_byteswap().
 *
 * The avb_rsa_verify() function expects a key in this serialized
 * format.
 *
 * The 'avbtool extract_public_key' command can be used to generate a
 * serialized RSA public key.
 */
typedef struct AvbRSAPublicKeyHeader {
  uint32_t key_num_bits;
  uint32_t n0inv;
} AVB_ATTR_PACKED AvbRSAPublicKeyHeader;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 */
bool avb_rsa_public_key_header_validate_and_byteswap(
    const AvbRSAPublicKeyHeader* src,
    AvbRSAPublicKeyHeader* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_CRYPTO_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_crypto_ops_impl.h`:

```h
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_crypto_ops_impl.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_CRYPTO_OPS_IMPL_H_
#define AVB_CRYPTO_OPS_IMPL_H_

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_sysdeps.h"

/* Block size in bytes of a SHA-256 digest. */
#define AVB_SHA256_BLOCK_SIZE 64

/* Block size in bytes of a SHA-512 digest. */
#define AVB_SHA512_BLOCK_SIZE 128

/* Data structure used for SHA-256. */
typedef struct {
  uint32_t h[8];
  uint64_t tot_len;
  size_t len;
  uint8_t block[2 * AVB_SHA256_BLOCK_SIZE];
} AvbSHA256ImplCtx;

/* Data structure used for SHA-512. */
typedef struct {
  uint64_t h[8];
  uint64_t tot_len;
  size_t len;
  uint8_t block[2 * AVB_SHA512_BLOCK_SIZE];
} AvbSHA512ImplCtx;

#define AVB_SHA256_CONTEXT_SIZE sizeof(AvbSHA256ImplCtx)
#define AVB_SHA512_CONTEXT_SIZE sizeof(AvbSHA512ImplCtx)

#ifdef __cplusplus
}
#endif

#endif /* AVB_CRYPTO_OPS_IMPL_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_DESCRIPTOR_H_
#define AVB_DESCRIPTOR_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Well-known descriptor tags.
 *
 * AVB_DESCRIPTOR_TAG_PROPERTY: see |AvbPropertyDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_HASHTREE: see |AvbHashtreeDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_HASH: see |AvbHashDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE: see |AvbKernelCmdlineDescriptor| struct.
 * AVB_DESCRIPTOR_TAG_CHAIN_PARTITION: see |AvbChainPartitionDescriptor| struct.
 */
typedef enum {
  AVB_DESCRIPTOR_TAG_PROPERTY,
  AVB_DESCRIPTOR_TAG_HASHTREE,
  AVB_DESCRIPTOR_TAG_HASH,
  AVB_DESCRIPTOR_TAG_KERNEL_CMDLINE,
  AVB_DESCRIPTOR_TAG_CHAIN_PARTITION,
} AvbDescriptorTag;

/* The header for a serialized descriptor.
 *
 * A descriptor always have two fields, a |tag| (denoting its type,
 * see the |AvbDescriptorTag| enumeration) and the size of the bytes
 * following, |num_bytes_following|.
 *
 * For padding, |num_bytes_following| is always a multiple of 8.
 */
typedef struct AvbDescriptor {
  uint64_t tag;
  uint64_t num_bytes_following;
} AVB_ATTR_PACKED AvbDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_descriptor_validate_and_byteswap(
    const AvbDescriptor* src, AvbDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

/* Signature for callback function used in avb_descriptor_foreach().
 * The passed in descriptor is given by |descriptor| and the
 * |user_data| passed to avb_descriptor_foreach() function is in
 * |user_data|. Return true to continue iterating, false to stop
 * iterating.
 *
 * Note that |descriptor| points into the image passed to
 * avb_descriptor_foreach() - all fields need to be byteswapped!
 */
typedef bool AvbDescriptorForeachFunc(const AvbDescriptor* descriptor,
                                      void* user_data);

/* Convenience function to iterate over all descriptors in an vbmeta
 * image.
 *
 * The function given by |foreach_func| will be called for each
 * descriptor. The given function should return true to continue
 * iterating, false to stop.
 *
 * The |user_data| parameter will be passed to |foreach_func|.
 *
 * Returns false if the iteration was short-circuited, that is if
 * an invocation of |foreach_func| returned false.
 *
 * Before using this function, you MUST verify |image_data| with
 * avb_vbmeta_image_verify() and reject it unless it's signed by a known
 * good public key. Additionally, |image_data| must be word-aligned.
 */
bool avb_descriptor_foreach(const uint8_t* image_data,
                            size_t image_size,
                            AvbDescriptorForeachFunc foreach_func,
                            void* user_data);

/* Gets all descriptors in a vbmeta image.
 *
 * The return value is a NULL-pointer terminated array of
 * AvbDescriptor pointers. Free with avb_free() when you are done with
 * it. If |out_num_descriptors| is non-NULL, the number of descriptors
 * will be returned there.
 *
 * Note that each AvbDescriptor pointer in the array points into
 * |image_data| - all fields need to be byteswapped!
 *
 * Before using this function, you MUST verify |image_data| with
 * avb_vbmeta_image_verify() and reject it unless it's signed by a known
 * good public key. Additionally, |image_data| must be word-aligned.
 */
const AvbDescriptor** avb_descriptor_get_all(const uint8_t* image_data,
                                             size_t image_size,
                                             size_t* out_num_descriptors)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_DESCRIPTOR_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_footer.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_FOOTER_H_
#define AVB_FOOTER_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Magic for the footer. */
#define AVB_FOOTER_MAGIC "AVBf"
#define AVB_FOOTER_MAGIC_LEN 4

/* Size of the footer. */
#define AVB_FOOTER_SIZE 64

/* The current footer version used - keep in sync with avbtool. */
#define AVB_FOOTER_VERSION_MAJOR 1
#define AVB_FOOTER_VERSION_MINOR 0

/* The struct used as a footer used on partitions, used to find the
 * AvbVBMetaImageHeader struct. This struct is always stored at the
 * end of a partition.
 */
typedef struct AvbFooter {
  /*   0: Four bytes equal to "AVBf" (AVB_FOOTER_MAGIC). */
  uint8_t magic[AVB_FOOTER_MAGIC_LEN];
  /*   4: The major version of the footer struct. */
  uint32_t version_major;
  /*   8: The minor version of the footer struct. */
  uint32_t version_minor;

  /*  12: The original size of the image on the partition. */
  uint64_t original_image_size;

  /*  20: The offset of the |AvbVBMetaImageHeader| struct. */
  uint64_t vbmeta_offset;

  /*  28: The size of the vbmeta block (header + auth + aux blocks). */
  uint64_t vbmeta_size;

  /*  36: Padding to ensure struct is size AVB_FOOTER_SIZE bytes. This
   * must be set to zeroes.
   */
  uint8_t reserved[28];
} AVB_ATTR_PACKED AvbFooter;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 */
bool avb_footer_validate_and_byteswap(const AvbFooter* src, AvbFooter* dest)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_FOOTER_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_hash_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_HASH_DESCRIPTOR_H_
#define AVB_HASH_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Flags for hash descriptors.
 *
 * AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB: Do not apply the default A/B
 *   partition logic to this partition. This is intentionally a negative boolean
 *   because A/B should be both the default and most used in practice.
 */
typedef enum {
  AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB = (1 << 0),
} AvbHashDescriptorFlags;

/* A descriptor containing information about hash for an image.
 *
 * This descriptor is typically used for boot partitions to verify the
 * entire kernel+initramfs image before executing it.
 *
 * Following this struct are |partition_name_len| bytes of the
 * partition name (UTF-8 encoded), |salt_len| bytes of salt, and then
 * |digest_len| bytes of the digest.
 *
 * The |reserved| field is for future expansion and must be set to NUL
 * bytes.
 *
 * Changes in v1.1:
 *   - flags field is added which supports AVB_HASH_DESCRIPTOR_FLAGS_USE_AB
 *   - digest_len may be zero, which indicates the use of a persistent digest
 */
typedef struct AvbHashDescriptor {
  AvbDescriptor parent_descriptor;
  uint64_t image_size;
  uint8_t hash_algorithm[32];
  uint32_t partition_name_len;
  uint32_t salt_len;
  uint32_t digest_len;
  uint32_t flags;
  uint8_t reserved[60];
} AVB_ATTR_PACKED AvbHashDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_hash_descriptor_validate_and_byteswap(const AvbHashDescriptor* src,
                                               AvbHashDescriptor* dest)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_HASH_DESCRIPTOR_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_hashtree_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_HASHTREE_DESCRIPTOR_H_
#define AVB_HASHTREE_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Flags for hashtree descriptors.
 *
 * AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB: Do not apply the default A/B
 *   partition logic to this partition. This is intentionally a negative boolean
 *   because A/B should be both the default and most used in practice.
 * AVB_HASHTREE_DESCRIPTOR_FLAGS_CHECK_AT_MOST_ONCE: supports to validate hashes
 *   at most once in DM-Verity.
 */
typedef enum {
  AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB = (1 << 0),
  AVB_HASHTREE_DESCRIPTOR_FLAGS_CHECK_AT_MOST_ONCE = (1 << 1),
} AvbHashtreeDescriptorFlags;

/* A descriptor containing information about a dm-verity hashtree.
 *
 * Hash-trees are used to verify large partitions typically containing
 * file systems. See
 * https://gitlab.com/cryptsetup/cryptsetup/wikis/DMVerity for more
 * information about dm-verity.
 *
 * Following this struct are |partition_name_len| bytes of the
 * partition name (UTF-8 encoded), |salt_len| bytes of salt, and then
 * |root_digest_len| bytes of the root digest.
 *
 * The |reserved| field is for future expansion and must be set to NUL
 * bytes.
 *
 * Changes in v1.1:
 *   - flags field is added which supports AVB_HASHTREE_DESCRIPTOR_FLAGS_USE_AB
 *   - digest_len may be zero, which indicates the use of a persistent digest
 */
typedef struct AvbHashtreeDescriptor {
  AvbDescriptor parent_descriptor;
  uint32_t dm_verity_version;
  uint64_t image_size;
  uint64_t tree_offset;
  uint64_t tree_size;
  uint32_t data_block_size;
  uint32_t hash_block_size;
  uint32_t fec_num_roots;
  uint64_t fec_offset;
  uint64_t fec_size;
  uint8_t hash_algorithm[32];
  uint32_t partition_name_len;
  uint32_t salt_len;
  uint32_t root_digest_len;
  uint32_t flags;
  uint8_t reserved[60];
} AVB_ATTR_PACKED AvbHashtreeDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_hashtree_descriptor_validate_and_byteswap(
    const AvbHashtreeDescriptor* src,
    AvbHashtreeDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_HASHTREE_DESCRIPTOR_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_kernel_cmdline_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_KERNEL_CMDLINE_DESCRIPTOR_H_
#define AVB_KERNEL_CMDLINE_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Flags for kernel command-line descriptors.
 *
 * AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED: The
 * cmdline will only be applied if hashtree verification is not
 * disabled (cf. AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED).
 *
 * AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED: The cmdline
 * will only be applied if hashtree verification is disabled
 * (cf. AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED).
 */
typedef enum {
  AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED = (1 << 0),
  AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED = (1 << 1)
} AvbKernelCmdlineFlags;

/* A descriptor containing information to be appended to the kernel
 * command-line.
 *
 * The |flags| field contains flags from the AvbKernelCmdlineFlags
 * enumeration.
 *
 * Following this struct are |kernel_cmdline_len| bytes with the
 * kernel command-line (UTF-8 encoded).
 */
typedef struct AvbKernelCmdlineDescriptor {
  AvbDescriptor parent_descriptor;
  uint32_t flags;
  uint32_t kernel_cmdline_length;
} AVB_ATTR_PACKED AvbKernelCmdlineDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_kernel_cmdline_descriptor_validate_and_byteswap(
    const AvbKernelCmdlineDescriptor* src,
    AvbKernelCmdlineDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_KERNEL_CMDLINE_DESCRIPTOR_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_ops.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_OPS_H_
#define AVB_OPS_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Well-known names of named persistent values. */
#define AVB_NPV_PERSISTENT_DIGEST_PREFIX "avb.persistent_digest."
#define AVB_NPV_MANAGED_VERITY_MODE "avb.managed_verity_mode"

/* Return codes used for I/O operations.
 *
 * AVB_IO_RESULT_OK is returned if the requested operation was
 * successful.
 *
 * AVB_IO_RESULT_ERROR_IO is returned if the underlying hardware (disk
 * or other subsystem) encountered an I/O error.
 *
 * AVB_IO_RESULT_ERROR_OOM is returned if unable to allocate memory.
 *
 * AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION is returned if the requested
 * partition does not exist.
 *
 * AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION is returned if the
 * range of bytes requested to be read or written is outside the range
 * of the partition.
 *
 * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE is returned if a named persistent value
 * does not exist.
 *
 * AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE is returned if a named persistent
 * value size is not supported or does not match the expected size.
 *
 * AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE is returned if a buffer is too small
 * for the requested operation.
 */
typedef enum {
  AVB_IO_RESULT_OK,
  AVB_IO_RESULT_ERROR_OOM,
  AVB_IO_RESULT_ERROR_IO,
  AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION,
  AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION,
  AVB_IO_RESULT_ERROR_NO_SUCH_VALUE,
  AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE,
  AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE,
} AvbIOResult;

struct AvbOps;
typedef struct AvbOps AvbOps;

/* Forward-declaration of operations in libavb_ab. */
struct AvbABOps;

/* Forward-declaration of operations in libavb_atx. */
struct AvbAtxOps;

/* High-level operations/functions/methods that are platform
 * dependent.
 *
 * Operations may be added in the future so when implementing it
 * always make sure to zero out sizeof(AvbOps) bytes of the struct to
 * ensure that unimplemented operations are set to NULL.
 */
struct AvbOps {
  /* This pointer can be used by the application/bootloader using
   * libavb and is typically used in each operation to get a pointer
   * to platform-specific resources. It cannot be used by libraries.
   */
  void* user_data;

  /* If libavb_ab is used, this should point to the
   * AvbABOps. Otherwise it must be set to NULL.
   */
  struct AvbABOps* ab_ops;

  /* If libavb_atx is used, this should point to the
   * AvbAtxOps. Otherwise it must be set to NULL.
   */
  struct AvbAtxOps* atx_ops;

  /* Reads |num_bytes| from offset |offset| from partition with name
   * |partition| (NUL-terminated UTF-8 string). If |offset| is
   * negative, its absolute value should be interpreted as the number
   * of bytes from the end of the partition.
   *
   * This function returns AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION if
   * there is no partition with the given name,
   * AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION if the requested
   * |offset| is outside the partition, and AVB_IO_RESULT_ERROR_IO if
   * there was an I/O error from the underlying I/O subsystem.  If the
   * operation succeeds as requested AVB_IO_RESULT_OK is returned and
   * the data is available in |buffer|.
   *
   * The only time partial I/O may occur is if reading beyond the end
   * of the partition. In this case the value returned in
   * |out_num_read| may be smaller than |num_bytes|.
   */
  AvbIOResult (*read_from_partition)(AvbOps* ops,
                                     const char* partition,
                                     int64_t offset,
                                     size_t num_bytes,
                                     void* buffer,
                                     size_t* out_num_read);

  /* Gets the starting pointer of a partition that is pre-loaded in memory, and
   * save it to |out_pointer|. The preloaded partition is expected to be
   * |num_bytes|, where the actual preloaded byte count is returned in
   * |out_num_bytes_preloaded|. |out_num_bytes_preloaded| must be no larger than
   * |num_bytes|.
   *
   * This provides an alternative way to access a partition that is preloaded
   * into memory without a full memory copy. When this function pointer is not
   * set (has value NULL), or when the |out_pointer| is set to NULL as a result,
   * |read_from_partition| will be used as the fallback. This function is mainly
   * used for accessing the entire partition content to calculate its hash.
   *
   * Preloaded partition data must outlive the lifespan of the
   * |AvbSlotVerifyData| structure that |avb_slot_verify| outputs.
   */
  AvbIOResult (*get_preloaded_partition)(AvbOps* ops,
                                         const char* partition,
                                         size_t num_bytes,
                                         uint8_t** out_pointer,
                                         size_t* out_num_bytes_preloaded);

  /* Writes |num_bytes| from |bffer| at offset |offset| to partition
   * with name |partition| (NUL-terminated UTF-8 string). If |offset|
   * is negative, its absolute value should be interpreted as the
   * number of bytes from the end of the partition.
   *
   * This function returns AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION if
   * there is no partition with the given name,
   * AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION if the requested
   * byterange goes outside the partition, and AVB_IO_RESULT_ERROR_IO
   * if there was an I/O error from the underlying I/O subsystem.  If
   * the operation succeeds as requested AVB_IO_RESULT_OK is
   * returned.
   *
   * This function never does any partial I/O, it either transfers all
   * of the requested bytes or returns an error.
   */
  AvbIOResult (*write_to_partition)(AvbOps* ops,
                                    const char* partition,
                                    int64_t offset,
                                    size_t num_bytes,
                                    const void* buffer);

  /* Checks if the given public key used to sign the 'vbmeta'
   * partition is trusted. Boot loaders typically compare this with
   * embedded key material generated with 'avbtool
   * extract_public_key'.
   *
   * The public key is in the array pointed to by |public_key_data|
   * and is of |public_key_length| bytes.
   *
   * If there is no public key metadata (set with the avbtool option
   * --public_key_metadata) then |public_key_metadata| will be set to
   * NULL. Otherwise this field points to the data which is
   * |public_key_metadata_length| bytes long.
   *
   * If AVB_IO_RESULT_OK is returned then |out_is_trusted| is set -
   * true if trusted or false if untrusted.
   *
   * NOTE: If AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION is passed to
   * avb_slot_verify() then this operation is never used. Instead, the
   * validate_public_key_for_partition() operation is used
   */
  AvbIOResult (*validate_vbmeta_public_key)(AvbOps* ops,
                                            const uint8_t* public_key_data,
                                            size_t public_key_length,
                                            const uint8_t* public_key_metadata,
                                            size_t public_key_metadata_length,
                                            bool* out_is_trusted);

  /* Gets the rollback index corresponding to the location given by
   * |rollback_index_location|. The value is returned in
   * |out_rollback_index|. Returns AVB_IO_RESULT_OK if the rollback
   * index was retrieved, otherwise an error code.
   *
   * A device may have a limited amount of rollback index locations (say,
   * one or four) so may error out if |rollback_index_location| exceeds
   * this number.
   */
  AvbIOResult (*read_rollback_index)(AvbOps* ops,
                                     size_t rollback_index_location,
                                     uint64_t* out_rollback_index);

  /* Sets the rollback index corresponding to the location given by
   * |rollback_index_location| to |rollback_index|. Returns
   * AVB_IO_RESULT_OK if the rollback index was set, otherwise an
   * error code.
   *
   * A device may have a limited amount of rollback index locations (say,
   * one or four) so may error out if |rollback_index_location| exceeds
   * this number.
   */
  AvbIOResult (*write_rollback_index)(AvbOps* ops,
                                      size_t rollback_index_location,
                                      uint64_t rollback_index);

  /* Gets whether the device is unlocked. The value is returned in
   * |out_is_unlocked| (true if unlocked, false otherwise). Returns
   * AVB_IO_RESULT_OK if the state was retrieved, otherwise an error
   * code.
   */
  AvbIOResult (*read_is_device_unlocked)(AvbOps* ops, bool* out_is_unlocked);

  /* Gets the unique partition GUID for a partition with name in
   * |partition| (NUL-terminated UTF-8 string). The GUID is copied as
   * a string into |guid_buf| of size |guid_buf_size| and will be NUL
   * terminated. The string must be lower-case and properly
   * hyphenated. For example:
   *
   *  527c1c6d-6361-4593-8842-3c78fcd39219
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   */
  AvbIOResult (*get_unique_guid_for_partition)(AvbOps* ops,
                                               const char* partition,
                                               char* guid_buf,
                                               size_t guid_buf_size);

  /* Gets the size of a partition with the name in |partition|
   * (NUL-terminated UTF-8 string). Returns the value in
   * |out_size_num_bytes|.
   *
   * If the partition doesn't exist the AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION
   * error code should be returned.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   */
  AvbIOResult (*get_size_of_partition)(AvbOps* ops,
                                       const char* partition,
                                       uint64_t* out_size_num_bytes);

  /* Reads a persistent value corresponding to the given |name|. The value is
   * returned in |out_buffer| which must point to |buffer_size| bytes. On
   * success |out_num_bytes_read| contains the number of bytes read into
   * |out_buffer|. If AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE is returned,
   * |out_num_bytes_read| contains the number of bytes that would have been read
   * which can be used to allocate a buffer.
   *
   * The |buffer_size| may be zero and the |out_buffer| may be NULL, but if
   * |out_buffer| is NULL then |buffer_size| *must* be zero.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   *
   * If the value does not exist, is not supported, or is not populated, returns
   * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE. If |buffer_size| is smaller than the
   * size of the stored value, returns AVB_IO_RESULT_ERROR_INSUFFICIENT_SPACE.
   *
   * This operation is currently only used to support persistent digests or the
   * AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO hashtree error mode. If a
   * device does not use one of these features this function pointer can be set
   * to NULL.
   */
  AvbIOResult (*read_persistent_value)(AvbOps* ops,
                                       const char* name,
                                       size_t buffer_size,
                                       uint8_t* out_buffer,
                                       size_t* out_num_bytes_read);

  /* Writes a persistent value corresponding to the given |name|. The value is
   * supplied in |value| which must point to |value_size| bytes. Any existing
   * value with the same name is overwritten. If |value_size| is zero, future
   * calls to |read_persistent_value| will return
   * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   *
   * If the value |name| is not supported, returns
   * AVB_IO_RESULT_ERROR_NO_SUCH_VALUE. If the |value_size| is not supported,
   * returns AVB_IO_RESULT_ERROR_INVALID_VALUE_SIZE.
   *
   * This operation is currently only used to support persistent digests or the
   * AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO hashtree error mode. If a
   * device does not use one of these features this function pointer can be set
   * to NULL.
   */
  AvbIOResult (*write_persistent_value)(AvbOps* ops,
                                        const char* name,
                                        size_t value_size,
                                        const uint8_t* value);

  /* Like validate_vbmeta_public_key() but for when the flag
   * AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION is being used. The name of the
   * partition to get the public key for is passed in |partition_name|.
   *
   * Also returns the rollback index location to use for the partition, in
   * |out_rollback_index_location|.
   *
   * Returns AVB_IO_RESULT_OK on success, otherwise an error code.
   */
  AvbIOResult (*validate_public_key_for_partition)(
      AvbOps* ops,
      const char* partition,
      const uint8_t* public_key_data,
      size_t public_key_length,
      const uint8_t* public_key_metadata,
      size_t public_key_metadata_length,
      bool* out_is_trusted,
      uint32_t* out_rollback_index_location);
};

#ifdef __cplusplus
}
#endif

#endif /* AVB_OPS_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_property_descriptor.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_PROPERTY_DESCRIPTOR_H_
#define AVB_PROPERTY_DESCRIPTOR_H_

#include "avb_descriptor.h"

#ifdef __cplusplus
extern "C" {
#endif

/* A descriptor for properties (free-form key/value pairs).
 *
 * Following this struct are |key_num_bytes| bytes of key data encoded
 * as UTF-8, followed by a NUL byte, then |value_num_bytes| bytes of
 * value data, followed by a NUL byte and then enough padding to make
 * the combined size a multiple of 8.
 */
typedef struct AvbPropertyDescriptor {
  AvbDescriptor parent_descriptor;
  uint64_t key_num_bytes;
  uint64_t value_num_bytes;
} AVB_ATTR_PACKED AvbPropertyDescriptor;

/* Copies |src| to |dest| and validates, byte-swapping fields in the
 * process if needed. Returns true if valid, false if invalid.
 *
 * Data following the struct is not validated nor copied.
 */
bool avb_property_descriptor_validate_and_byteswap(
    const AvbPropertyDescriptor* src,
    AvbPropertyDescriptor* dest) AVB_ATTR_WARN_UNUSED_RESULT;

/* Convenience function for looking up the value for a property with
 * name |key| in a vbmeta image. If |key_size| is 0, |key| must be
 * NUL-terminated.
 *
 * The |image_data| parameter must be a pointer to a vbmeta image of
 * size |image_size|.
 *
 * This function returns a pointer to the value inside the passed-in
 * image or NULL if not found. Note that the value is always
 * guaranteed to be followed by a NUL byte.
 *
 * If the value was found and |out_value_size| is not NULL, the size
 * of the value is returned there.
 *
 * This function is O(n) in number of descriptors so if you need to
 * look up a lot of values, you may want to build a more efficient
 * lookup-table by manually walking all descriptors using
 * avb_descriptor_foreach().
 *
 * Before using this function, you MUST verify |image_data| with
 * avb_vbmeta_image_verify() and reject it unless it's signed by a
 * known good public key.
 */
const char* avb_property_lookup(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                size_t* out_value_size)
    AVB_ATTR_WARN_UNUSED_RESULT;

/* Like avb_property_lookup() but parses the intial portions of the
 * value as an unsigned 64-bit integer. Both decimal and hexadecimal
 * representations (e.g. "0x2a") are supported. Returns false on
 * failure and true on success. On success, the parsed value is
 * returned in |out_value|.
 */
bool avb_property_lookup_uint64(const uint8_t* image_data,
                                size_t image_size,
                                const char* key,
                                size_t key_size,
                                uint64_t* out_value)
    AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_PROPERTY_DESCRIPTOR_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_rsa.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

/* Copyright (c) 2011 The Chromium OS Authors. All rights reserved.
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_rsa.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_RSA_H_
#define AVB_RSA_H_

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_crypto.h"
#include "avb_sysdeps.h"

/* Using the key given by |key|, verify a RSA signature |sig| of
 * length |sig_num_bytes| against an expected |hash| of length
 * |hash_num_bytes|. The padding to expect must be passed in using
 * |padding| of length |padding_num_bytes|.
 *
 * The data in |key| must match the format defined in
 * |AvbRSAPublicKeyHeader|, including the two large numbers
 * following. The |key_num_bytes| must be the size of the entire
 * serialized key.
 *
 * Returns false if verification fails, true otherwise.
 */
bool avb_rsa_verify(const uint8_t* key,
                    size_t key_num_bytes,
                    const uint8_t* sig,
                    size_t sig_num_bytes,
                    const uint8_t* hash,
                    size_t hash_num_bytes,
                    const uint8_t* padding,
                    size_t padding_num_bytes) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_RSA_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_sha.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifdef AVB_INSIDE_LIBAVB_H
#error "You can't include avb_sha.h in the public header libavb.h."
#endif

#ifndef AVB_COMPILATION
#error "Never include this file, it may only be used from internal avb code."
#endif

#ifndef AVB_SHA_H_
#define AVB_SHA_H_

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_crypto.h"
#include "avb_sysdeps.h"

/* The following defines must be set to something appropriate
 *
 *   AVB_SHA256_CONTEXT_SIZE - the size of AvbSHA256Ctx, excluding the buffer
 *   AVB_SHA512_CONTEXT_SIZE - the size of AvbSHA512Ctx, exclusing the buffer
 *
 * For example, if AvbSHA512Ctx is implemented using BoringSSL this would be
 * defined as sizeof(SHA256_CTX).
 *
 * We expect the implementation to provide a header file with the name
 * avb_crypto_ops_impl.h to do all this.
 */
#include "avb_crypto_ops_impl.h"

/* Data structure used for SHA-256. */
typedef struct {
  uint8_t reserved[AVB_SHA256_CONTEXT_SIZE];
  uint8_t buf[AVB_SHA256_DIGEST_SIZE]; /* Used for storing the final digest. */
} AvbSHA256Ctx;

/* Data structure used for SHA-512. */
typedef struct {
  uint8_t reserved[AVB_SHA512_CONTEXT_SIZE];
  uint8_t buf[AVB_SHA512_DIGEST_SIZE]; /* Used for storing the final digest. */
} AvbSHA512Ctx;

/* Initializes the SHA-256 context. */
void avb_sha256_init(AvbSHA256Ctx* ctx);

/* Updates the SHA-256 context with |len| bytes from |data|. */
void avb_sha256_update(AvbSHA256Ctx* ctx, const uint8_t* data, size_t len);

/* Returns the SHA-256 digest. */
uint8_t* avb_sha256_final(AvbSHA256Ctx* ctx) AVB_ATTR_WARN_UNUSED_RESULT;

/* Initializes the SHA-512 context. */
void avb_sha512_init(AvbSHA512Ctx* ctx);

/* Updates the SHA-512 context with |len| bytes from |data|. */
void avb_sha512_update(AvbSHA512Ctx* ctx, const uint8_t* data, size_t len);

/* Returns the SHA-512 digest. */
uint8_t* avb_sha512_final(AvbSHA512Ctx* ctx) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_SHA_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_slot_verify.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_SLOT_VERIFY_H_
#define AVB_SLOT_VERIFY_H_

#include "avb_ops.h"
#include "avb_vbmeta_image.h"

#ifdef __cplusplus
extern "C" {
#endif

/* Return codes used in avb_slot_verify(), see that function for
 * documentation for each field.
 *
 * Use avb_slot_verify_result_to_string() to get a textual
 * representation usable for error/debug output.
 */
typedef enum {
  AVB_SLOT_VERIFY_RESULT_OK,
  AVB_SLOT_VERIFY_RESULT_ERROR_OOM,
  AVB_SLOT_VERIFY_RESULT_ERROR_IO,
  AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION,
  AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX,
  AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED,
  AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA,
  AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION,
  AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT
} AvbSlotVerifyResult;

/* Various error handling modes for when verification fails using a
 * hashtree at runtime inside the HLOS.
 *
 * AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE means that the OS
 * will invalidate the current slot and restart.
 *
 * AVB_HASHTREE_ERROR_MODE_RESTART means that the OS will restart.
 *
 * AVB_HASHTREE_ERROR_MODE_EIO means that an EIO error will be
 * returned to applications.
 *
 * AVB_HASHTREE_ERROR_MODE_LOGGING means that errors will be logged
 * and corrupt data may be returned to applications. This mode should
 * be used ONLY for diagnostics and debugging. It cannot be used
 * unless AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is also
 * used.
 *
 * AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO means that either
 * AVB_HASHTREE_ERROR_MODE_RESTART or AVB_HASHTREE_ERROR_MODE_EIO is used
 * depending on state. This mode implements a state machine whereby
 * AVB_HASHTREE_ERROR_MODE_RESTART is used by default and when
 * AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION is passed the
 * mode transitions to AVB_HASHTREE_ERROR_MODE_EIO. When a new OS has been
 * detected the device transitions back to the AVB_HASHTREE_ERROR_MODE_RESTART
 * mode. To do this persistent storage is needed - specifically this means that
 * the passed in AvbOps will need to have the read_persistent_value() and
 * write_persistent_value() operations implemented. The name of the persistent
 * value used is "avb.managed_verity_mode" and 32 bytes of storage is needed.
 */
typedef enum {
  AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE,
  AVB_HASHTREE_ERROR_MODE_RESTART,
  AVB_HASHTREE_ERROR_MODE_EIO,
  AVB_HASHTREE_ERROR_MODE_LOGGING,
  AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO,
  AVB_HASHTREE_ERROR_MODE_PANIC
} AvbHashtreeErrorMode;

/* Flags that influence how avb_slot_verify() works.
 *
 * If AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is NOT set then
 * avb_slot_verify() will bail out as soon as an error is encountered
 * and |out_data| is set only if AVB_SLOT_VERIFY_RESULT_OK is
 * returned.
 *
 * Otherwise if AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is set
 * avb_slot_verify() will continue verification efforts and |out_data|
 * is also set if AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED,
 * AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION, or
 * AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX is returned. It is
 * undefined which error is returned if more than one distinct error
 * is encountered. It is guaranteed that AVB_SLOT_VERIFY_RESULT_OK is
 * returned if, and only if, there are no errors. This mode is needed
 * to boot valid but unverified slots when the device is unlocked.
 *
 * Also, if AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR is set the
 * contents loaded from |requested_partition| will be the contents of
 * the entire partition instead of just the size specified in the hash
 * descriptor.
 *
 * The AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION flag
 * should be set if using AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO
 * and the reason the boot loader is running is because the device
 * was restarted by the dm-verity driver.
 *
 * If the AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION flag is set then
 * data won't be loaded from the "vbmeta" partition and the
 * |validate_vbmeta_public_key| operation is never called. Instead, the
 * vbmeta structs in |requested_partitions| are loaded and processed and the
 * |validate_public_key_for_partition| operation is called for each of these
 * vbmeta structs. This flag is useful when booting into recovery on a device
 * not using A/B - see section "Booting into recovery" in README.md for
 * more information.
 */
typedef enum {
  AVB_SLOT_VERIFY_FLAGS_NONE = 0,
  AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR = (1 << 0),
  AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION = (1 << 1),
  AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION = (1 << 2),
} AvbSlotVerifyFlags;

/* Get a textual representation of |result|. */
const char* avb_slot_verify_result_to_string(AvbSlotVerifyResult result);

/* Maximum number of rollback index locations supported. */
#define AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS 32

/* AvbPartitionData contains data loaded from partitions when using
 * avb_slot_verify(). The |partition_name| field contains the name of
 * the partition (without A/B suffix), |data| points to the loaded
 * data which is |data_size| bytes long. If |preloaded| is set to true,
 * this structure dose not own |data|. The caller of |avb_slot_verify|
 * needs to make sure that the preloaded data outlives this
 * |AvbPartitionData| structure.
 *
 * Note that this is strictly less than the partition size - it's only
 * the image stored there, not the entire partition nor any of the
 * metadata.
 */
typedef struct {
  char* partition_name;
  uint8_t* data;
  size_t data_size;
  bool preloaded;
  AvbSlotVerifyResult verify_result;
} AvbPartitionData;

/* AvbVBMetaData contains a vbmeta struct loaded from a partition when
 * using avb_slot_verify(). The |partition_name| field contains the
 * name of the partition (without A/B suffix), |vbmeta_data| points to
 * the loaded data which is |vbmeta_size| bytes long.
 *
 * The |verify_result| field contains the result of
 * avb_vbmeta_image_verify() on the data. This is guaranteed to be
 * AVB_VBMETA_VERIFY_RESULT_OK for all vbmeta images if
 * avb_slot_verify() returns AVB_SLOT_VERIFY_RESULT_OK.
 *
 * You can use avb_descriptor_get_all(), avb_descriptor_foreach(), and
 * avb_vbmeta_image_header_to_host_byte_order() with this data.
 */
typedef struct {
  char* partition_name;
  uint8_t* vbmeta_data;
  size_t vbmeta_size;
  AvbVBMetaVerifyResult verify_result;
} AvbVBMetaData;

/* AvbSlotVerifyData contains data needed to boot a particular slot
 * and is returned by avb_slot_verify() if partitions in a slot are
 * successfully verified.
 *
 * All data pointed to by this struct - including data in each item in
 * the |partitions| array - will be freed when the
 * avb_slot_verify_data_free() function is called.
 *
 * The |ab_suffix| field is the copy of the of |ab_suffix| field
 * passed to avb_slot_verify(). It is the A/B suffix of the slot. This
 * value includes the leading underscore - typical values are "" (if
 * no slots are in use), "_a" (for the first slot), and "_b" (for the
 * second slot).
 *
 * The VBMeta images that were checked are available in the
 * |vbmeta_images| field. The field |num_vbmeta_images| contains the
 * number of elements in this array. The first element -
 * vbmeta_images[0] - is guaranteed to be from the partition with the
 * top-level vbmeta struct. This is usually the "vbmeta" partition in
 * the requested slot but if there is no "vbmeta" partition it can
 * also be the "boot" partition.
 *
 * The partitions loaded and verified from from the slot are
 * accessible in the |loaded_partitions| array. The field
 * |num_loaded_partitions| contains the number of elements in this
 * array. The order of partitions in this array may not necessarily be
 * the same order as in the passed-in |requested_partitions| array.
 *
 * Rollback indexes for the verified slot are stored in the
 * |rollback_indexes| field. Note that avb_slot_verify() will NEVER
 * modify stored_rollback_index[n] locations e.g. it will never use
 * the write_rollback_index() AvbOps operation. Instead it is the job
 * of the caller of avb_slot_verify() to do this based on e.g. A/B
 * policy and other factors. See libavb_ab/avb_ab_flow.c for an
 * example of how to do this.
 *
 * The |cmdline| field is a NUL-terminated string in UTF-8 resulting
 * from concatenating all |AvbKernelCmdlineDescriptor| and then
 * performing proper substitution of the variables
 * $(ANDROID_SYSTEM_PARTUUID), $(ANDROID_BOOT_PARTUUID), and
 * $(ANDROID_VBMETA_PARTUUID) using the
 * get_unique_guid_for_partition() operation in |AvbOps|. Additionally
 * $(ANDROID_VERITY_MODE) will be replaced with the proper dm-verity
 * option depending on the value of |hashtree_error_mode|.
 *
 * Additionally, the |cmdline| field will have the following kernel
 * command-line options set (unless verification is disabled, see
 * below):
 *
 *   androidboot.veritymode: This is set to 'disabled' if the
 *   AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED flag is set in top-level
 *   vbmeta struct. Otherwise it is set to 'enforcing' if the
 *   passed-in hashtree error mode is AVB_HASHTREE_ERROR_MODE_RESTART
 *   or AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE, 'eio' if it's
 *   set to AVB_HASHTREE_ERROR_MODE_EIO, and 'logging' if it's set to
 *   AVB_HASHTREE_ERROR_MODE_LOGGING.
 *
 *   androidboot.veritymode.managed: This is set to 'yes' only
 *   if hashtree validation isn't disabled and the passed-in hashtree
 *   error mode is AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO.
 *
 *   androidboot.vbmeta.invalidate_on_error: This is set to 'yes' only
 *   if hashtree validation isn't disabled and the passed-in hashtree
 *   error mode is AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE.
 *
 *   androidboot.vbmeta.device_state: set to "locked" or "unlocked"
 *   depending on the result of the result of AvbOps's
 *   read_is_unlocked() function.
 *
 *   androidboot.vbmeta.{hash_alg, size, digest}: Will be set to
 *   the digest of all images in |vbmeta_images|.
 *
 *   androidboot.vbmeta.device: This is set to the value
 *   PARTUUID=$(ANDROID_VBMETA_PARTUUID) before substitution so it
 *   will end up pointing to the vbmeta partition for the verified
 *   slot. If there is no vbmeta partition it will point to the boot
 *   partition of the verified slot. If the flag
 *   AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION is used, this is not
 *   set.
 *
 *   androidboot.vbmeta.avb_version: This is set to the decimal value
 *   of AVB_VERSION_MAJOR followed by a dot followed by the decimal
 *   value of AVB_VERSION_MINOR, for example "1.0" or "1.4". This
 *   version number represents the vbmeta file format version
 *   supported by libavb copy used in the boot loader. This is not
 *   necessarily the same version number of the on-disk metadata for
 *   the slot that was verified.
 *
 * Note that androidboot.slot_suffix is not set in the |cmdline| field
 * in |AvbSlotVerifyData| - you will have to set this yourself.
 *
 * If the |AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED| flag is set
 * in the top-level vbmeta struct then only the top-level vbmeta
 * struct is verified and descriptors will not processed. The return
 * value will be set accordingly (if this flag is set via 'avbctl
 * disable-verification' then the return value will be
 * |AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION|) and
 * |AvbSlotVerifyData| is returned. Additionally all partitions in the
 * |requested_partitions| are loaded and the |cmdline| field is set to
 * "root=PARTUUID=$(ANDROID_SYSTEM_PARTUUID)" and the GUID for the
 * appropriate system partition is substituted in. Note that none of
 * the androidboot.* options mentioned above will be set.
 *
 * The |resolved_hashtree_error_mode| is the the value of the passed
 * avb_slot_verify()'s |hashtree_error_mode| parameter except that it never has
 * the value AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO. If this value was
 * passed in, then the restart/eio state machine is used resulting in
 * |resolved_hashtree_error_mode| being set to either
 * AVB_HASHTREE_ERROR_MODE_RESTART or AVB_HASHTREE_ERROR_MODE_EIO.  If set to
 * AVB_HASHTREE_ERROR_MODE_EIO the boot loader should present a RED warning
 * screen for the user to click through before continuing to boot.
 *
 * This struct may grow in the future without it being considered an
 * ABI break.
 */
typedef struct {
  char* ab_suffix;
  AvbVBMetaData* vbmeta_images;
  size_t num_vbmeta_images;
  AvbPartitionData* loaded_partitions;
  size_t num_loaded_partitions;
  char* cmdline;
  uint64_t rollback_indexes[AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS];
  AvbHashtreeErrorMode resolved_hashtree_error_mode;
} AvbSlotVerifyData;

/* Calculates a digest of all vbmeta images in |data| using
 * the digest indicated by |digest_type|. Stores the result
 * in |out_digest| which must be large enough to hold a digest
 * of the requested type.
 */
void avb_slot_verify_data_calculate_vbmeta_digest(const AvbSlotVerifyData* data,
                                                  AvbDigestType digest_type,
                                                  uint8_t* out_digest);

/* Frees a |AvbSlotVerifyData| including all data it points to. */
void avb_slot_verify_data_free(AvbSlotVerifyData* data);

/* Performs a full verification of the slot identified by |ab_suffix|
 * and load and verify the contents of the partitions whose name is in
 * the NULL-terminated string array |requested_partitions| (each
 * partition must use hash verification). If not using A/B, pass an
 * empty string (e.g. "", not NULL) for |ab_suffix|. This parameter
 * must include the leading underscore, for example "_a" should be
 * used to refer to the first slot.
 *
 * Typically the |requested_partitions| array only contains a single
 * item for the boot partition, 'boot'.
 *
 * Verification includes loading and verifying data from the 'vbmeta',
 * the requested hash partitions, and possibly other partitions (with
 * |ab_suffix| appended), inspecting rollback indexes, and checking if
 * the public key used to sign the data is acceptable. The functions
 * in |ops| will be used to do this.
 *
 * If |out_data| is not NULL, it will be set to a newly allocated
 * |AvbSlotVerifyData| struct containing all the data needed to
 * actually boot the slot. This data structure should be freed with
 * avb_slot_verify_data_free() when you are done with it. See below
 * for when this is returned.
 *
 * The |flags| parameter is used to influence the semantics of
 * avb_slot_verify() - for example the
 * AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR flag can be used to
 * ignore verification errors which is something needed in the
 * UNLOCKED state. See the AvbSlotVerifyFlags enumeration for details.
 *
 * The |hashtree_error_mode| parameter should be set to the desired error
 * handling mode. See the AvbHashtreeErrorMode enumeration for details.
 *
 * Also note that |out_data| is never set if
 * AVB_SLOT_VERIFY_RESULT_ERROR_OOM, AVB_SLOT_VERIFY_RESULT_ERROR_IO,
 * or AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA is returned.
 *
 * AVB_SLOT_VERIFY_RESULT_OK is returned if everything is verified
 * correctly and all public keys are accepted.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED is returned if
 * everything is verified correctly out but one or more public keys
 * are not accepted. This includes the case where integrity data is
 * not signed.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_OOM is returned if unable to
 * allocate memory.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_IO is returned if an I/O error
 * occurred while trying to load data or get a rollback index.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION is returned if the data
 * did not verify, e.g. the digest didn't match or signature checks
 * failed.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX is returned if a
 * rollback index was less than its stored value.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA is returned if some
 * of the metadata is invalid or inconsistent.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION is returned if
 * some of the metadata requires a newer version of libavb than what
 * is in use.
 *
 * AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT is returned if the
 * caller passed invalid parameters, for example trying to use
 * AVB_HASHTREE_ERROR_MODE_LOGGING without
 * AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR.
 */
AvbSlotVerifyResult avb_slot_verify(AvbOps* ops,
                                    const char* const* requested_partitions,
                                    const char* ab_suffix,
                                    AvbSlotVerifyFlags flags,
                                    AvbHashtreeErrorMode hashtree_error_mode,
                                    AvbSlotVerifyData** out_data);

#ifdef __cplusplus
}
#endif

#endif /* AVB_SLOT_VERIFY_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_sysdeps.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_SYSDEPS_H_
#define AVB_SYSDEPS_H_

#ifdef __cplusplus
extern "C" {
#endif

/* Change these includes to match your platform to bring in the
 * equivalent types available in a normal C runtime. At least things
 * like uint8_t, uint64_t, and bool (with |false|, |true| keywords)
 * must be present.
 */
#include <inttypes.h>
#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>

/* If you don't have gcc or clang, these attribute macros may need to
 * be adjusted.
 */
#define AVB_ATTR_WARN_UNUSED_RESULT __attribute__((warn_unused_result))
#define AVB_ATTR_PACKED __attribute__((packed))
#define AVB_ATTR_NO_RETURN __attribute__((noreturn))
#define AVB_ATTR_SENTINEL __attribute__((__sentinel__))

/* Size in bytes used for alignment. */
#ifdef __LP64__
#define AVB_ALIGNMENT_SIZE 8
#else
#define AVB_ALIGNMENT_SIZE 4
#endif

/* Compare |n| bytes in |src1| and |src2|.
 *
 * Returns an integer less than, equal to, or greater than zero if the
 * first |n| bytes of |src1| is found, respectively, to be less than,
 * to match, or be greater than the first |n| bytes of |src2|. */
int avb_memcmp(const void* src1,
               const void* src2,
               size_t n) AVB_ATTR_WARN_UNUSED_RESULT;

/* Compare two strings.
 *
 * Return an integer less than, equal to, or greater than zero if |s1|
 * is found, respectively, to be less than, to match, or be greater
 * than |s2|.
 */
int avb_strcmp(const char* s1, const char* s2);

/* Compare |n| bytes in two strings.
 *
 * Return an integer less than, equal to, or greater than zero if the
 * first |n| bytes of |s1| is found, respectively, to be less than,
 * to match, or be greater than the first |n| bytes of |s2|.
 */
int avb_strncmp(const char* s1, const char* s2, size_t n);

/* Copy |n| bytes from |src| to |dest|. */
void* avb_memcpy(void* dest, const void* src, size_t n);

/* Set |n| bytes starting at |s| to |c|.  Returns |dest|. */
void* avb_memset(void* dest, const int c, size_t n);

/* Prints out a message. The string passed must be a NUL-terminated
 * UTF-8 string.
 */
void avb_print(const char* message);

/* Prints out a vector of strings. Each argument must point to a
 * NUL-terminated UTF-8 string and NULL should be the last argument.
 */
void avb_printv(const char* message, ...) AVB_ATTR_SENTINEL;

/* Aborts the program or reboots the device. */
void avb_abort(void) AVB_ATTR_NO_RETURN;

/* Allocates |size| bytes. Returns NULL if no memory is available,
 * otherwise a pointer to the allocated memory.
 *
 * The memory is not initialized.
 *
 * The pointer returned is guaranteed to be word-aligned.
 *
 * The memory should be freed with avb_free() when you are done with it.
 */
void* avb_malloc_(size_t size) AVB_ATTR_WARN_UNUSED_RESULT;

/* Frees memory previously allocated with avb_malloc(). */
void avb_free(void* ptr);

/* Returns the lenght of |str|, excluding the terminating NUL-byte. */
size_t avb_strlen(const char* str) AVB_ATTR_WARN_UNUSED_RESULT;

/* Divide the |dividend| by 10 and saves back to the pointer. Return the
 * remainder. */
uint32_t avb_div_by_10(uint64_t* dividend);

#ifdef __cplusplus
}
#endif

#endif /* AVB_SYSDEPS_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_util.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_UTIL_H_
#define AVB_UTIL_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

#define AVB_STRINGIFY(x) #x
#define AVB_TO_STRING(x) AVB_STRINGIFY(x)

#ifdef AVB_ENABLE_DEBUG
/* Aborts the program if |expr| is false.
 *
 * This has no effect unless AVB_ENABLE_DEBUG is defined.
 */
#define avb_assert(expr)                     \
  do {                                       \
    if (!(expr)) {                           \
      avb_fatal("assert fail: " #expr "\n"); \
    }                                        \
  } while (0)
#else
#define avb_assert(expr)
#endif

/* Aborts the program if reached.
 *
 * This has no effect unless AVB_ENABLE_DEBUG is defined.
 */
#ifdef AVB_ENABLE_DEBUG
#define avb_assert_not_reached()         \
  do {                                   \
    avb_fatal("assert_not_reached()\n"); \
  } while (0)
#else
#define avb_assert_not_reached()
#endif

/* Aborts the program if |addr| is not word-aligned.
 *
 * This has no effect unless AVB_ENABLE_DEBUG is defined.
 */
#define avb_assert_aligned(addr) \
  avb_assert((((uintptr_t)addr) & (AVB_ALIGNMENT_SIZE - 1)) == 0)

#ifdef AVB_ENABLE_DEBUG
/* Print functions, used for diagnostics.
 *
 * These have no effect unless AVB_ENABLE_DEBUG is defined.
 */
#define avb_debug(message)              \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": DEBUG: ",             \
               message,                 \
               NULL);                   \
  } while (0)
#define avb_debugv(message, ...)        \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": DEBUG: ",             \
               message,                 \
               ##__VA_ARGS__);          \
  } while (0)
#else
#define avb_debug(message)
#define avb_debugv(message, ...)
#endif

/* Prints out a message. This is typically used if a runtime-error
 * occurs.
 */
#define avb_error(message)              \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": ERROR: ",             \
               message,                 \
               NULL);                   \
  } while (0)
#define avb_errorv(message, ...)        \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": ERROR: ",             \
               message,                 \
               ##__VA_ARGS__);          \
  } while (0)

/* Prints out a message and calls avb_abort().
 */
#define avb_fatal(message)              \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": FATAL: ",             \
               message,                 \
               NULL);                   \
    avb_abort();                        \
  } while (0)
#define avb_fatalv(message, ...)        \
  do {                                  \
    avb_printv(avb_basename(__FILE__),  \
               ":",                     \
               AVB_TO_STRING(__LINE__), \
               ": FATAL: ",             \
               message,                 \
               ##__VA_ARGS__);          \
    avb_abort();                        \
  } while (0)

/* Converts a 16-bit unsigned integer from big-endian to host byte order. */
uint16_t avb_be16toh(uint16_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 32-bit unsigned integer from big-endian to host byte order. */
uint32_t avb_be32toh(uint32_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 64-bit unsigned integer from big-endian to host byte order. */
uint64_t avb_be64toh(uint64_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 16-bit unsigned integer from host to big-endian byte order. */
uint16_t avb_htobe16(uint16_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 32-bit unsigned integer from host to big-endian byte order. */
uint32_t avb_htobe32(uint32_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Converts a 64-bit unsigned integer from host to big-endian byte order. */
uint64_t avb_htobe64(uint64_t in) AVB_ATTR_WARN_UNUSED_RESULT;

/* Compare |n| bytes starting at |s1| with |s2| and return 0 if they
 * match, 1 if they don't.  Returns 0 if |n|==0, since no bytes
 * mismatched.
 *
 * Time taken to perform the comparison is only dependent on |n| and
 * not on the relationship of the match between |s1| and |s2|.
 *
 * Note that unlike avb_memcmp(), this only indicates inequality, not
 * whether |s1| is less than or greater than |s2|.
 */
int avb_safe_memcmp(const void* s1,
                    const void* s2,
                    size_t n) AVB_ATTR_WARN_UNUSED_RESULT;

/* Adds |value_to_add| to |value| with overflow protection.
 *
 * Returns false if the addition overflows, true otherwise. In either
 * case, |value| is always modified.
 */
bool avb_safe_add_to(uint64_t* value,
                     uint64_t value_to_add) AVB_ATTR_WARN_UNUSED_RESULT;

/* Adds |a| and |b| with overflow protection, returning the value in
 * |out_result|.
 *
 * It's permissible to pass NULL for |out_result| if you just want to
 * check that the addition would not overflow.
 *
 * Returns false if the addition overflows, true otherwise.
 */
bool avb_safe_add(uint64_t* out_result,
                  uint64_t a,
                  uint64_t b) AVB_ATTR_WARN_UNUSED_RESULT;

/* Checks if |num_bytes| data at |data| is a valid UTF-8
 * string. Returns true if valid UTF-8, false otherwise.
 */
bool avb_validate_utf8(const uint8_t* data,
                       size_t num_bytes) AVB_ATTR_WARN_UNUSED_RESULT;

/* Concatenates |str1| (of |str1_len| bytes) and |str2| (of |str2_len|
 * bytes) and puts the result in |buf| which holds |buf_size|
 * bytes. The result is also guaranteed to be NUL terminated. Fail if
 * there is not enough room in |buf| for the resulting string plus
 * terminating NUL byte.
 *
 * Returns true if the operation succeeds, false otherwise.
 */
bool avb_str_concat(char* buf,
                    size_t buf_size,
                    const char* str1,
                    size_t str1_len,
                    const char* str2,
                    size_t str2_len);

/* Like avb_malloc_() but prints a error using avb_error() if memory
 * allocation fails.
 */
void* avb_malloc(size_t size) AVB_ATTR_WARN_UNUSED_RESULT;

/* Like avb_malloc() but sets the memory with zeroes. */
void* avb_calloc(size_t size) AVB_ATTR_WARN_UNUSED_RESULT;

/* Duplicates a NUL-terminated string. Returns NULL on OOM. */
char* avb_strdup(const char* str) AVB_ATTR_WARN_UNUSED_RESULT;

/* Duplicates a NULL-terminated array of NUL-terminated strings by
 * concatenating them. The returned string will be
 * NUL-terminated. Returns NULL on OOM.
 */
char* avb_strdupv(const char* str,
                  ...) AVB_ATTR_WARN_UNUSED_RESULT AVB_ATTR_SENTINEL;

/* Finds the first occurrence of |needle| in the string |haystack|
 * where both strings are NUL-terminated strings. The terminating NUL
 * bytes are not compared.
 *
 * Returns NULL if not found, otherwise points into |haystack| for the
 * first occurrence of |needle|.
 */
const char* avb_strstr(const char* haystack,
                       const char* needle) AVB_ATTR_WARN_UNUSED_RESULT;

/* Finds the first occurrence of |str| in the NULL-terminated string
 * array |strings|. Each element in |strings| must be
 * NUL-terminated. The string given by |str| need not be
 * NUL-terminated but its size must be given in |str_size|.
 *
 * Returns NULL if not found, otherwise points into |strings| for the
 * first occurrence of |str|.
 */
const char* avb_strv_find_str(const char* const* strings,
                              const char* str,
                              size_t str_size);

/* Replaces all occurrences of |search| with |replace| in |str|.
 *
 * Returns a newly allocated string or NULL if out of memory.
 */
char* avb_replace(const char* str,
                  const char* search,
                  const char* replace) AVB_ATTR_WARN_UNUSED_RESULT;

/* Calculates the CRC-32 for data in |buf| of size |buf_size|. */
uint32_t avb_crc32(const uint8_t* buf, size_t buf_size);

/* Returns the basename of |str|. This is defined as the last path
 * component, assuming the normal POSIX separator '/'. If there are no
 * separators, returns |str|.
 */
const char* avb_basename(const char* str);

/* Converts any ascii lowercase characters in |str| to uppercase in-place.
 * |str| must be NUL-terminated and valid UTF-8.
 */
void avb_uppercase(char* str);

/* Converts |data_len| bytes of |data| to hex and returns the result. Returns
 * NULL on OOM. Caller must free the returned string with avb_free.
 */
char* avb_bin2hex(const uint8_t* data, size_t data_len);

/* Writes |value| to |digits| in base 10 followed by a NUL byte.
 * Returns number of characters written excluding the NUL byte.
 */
#define AVB_MAX_DIGITS_UINT64 32
size_t avb_uint64_to_base10(uint64_t value, char digits[AVB_MAX_DIGITS_UINT64]);
#ifdef __cplusplus
}
#endif

#endif /* AVB_UTIL_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_vbmeta_image.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_VBMETA_IMAGE_H_
#define AVB_VBMETA_IMAGE_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

#include "avb_crypto.h"
#include "avb_descriptor.h"

/* Size of the vbmeta image header. */
#define AVB_VBMETA_IMAGE_HEADER_SIZE 256

/* Magic for the vbmeta image header. */
#define AVB_MAGIC "AVB0"
#define AVB_MAGIC_LEN 4

/* Maximum size of the release string including the terminating NUL byte. */
#define AVB_RELEASE_STRING_SIZE 48

/* Flags for the vbmeta image.
 *
 * AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED: If this flag is set,
 * hashtree image verification will be disabled.
 *
 * AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED: If this flag is set,
 * verification will be disabled and descriptors will not be parsed.
 */
typedef enum {
  AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED = (1 << 0),
  AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED = (1 << 1)
} AvbVBMetaImageFlags;

/* Binary format for header of the vbmeta image.
 *
 * The vbmeta image consists of three blocks:
 *
 *  +-----------------------------------------+
 *  | Header data - fixed size                |
 *  +-----------------------------------------+
 *  | Authentication data - variable size     |
 *  +-----------------------------------------+
 *  | Auxiliary data - variable size          |
 *  +-----------------------------------------+
 *
 * The "Header data" block is described by this struct and is always
 * |AVB_VBMETA_IMAGE_HEADER_SIZE| bytes long.
 *
 * The "Authentication data" block is |authentication_data_block_size|
 * bytes long and contains the hash and signature used to authenticate
 * the vbmeta image. The type of the hash and signature is defined by
 * the |algorithm_type| field.
 *
 * The "Auxiliary data" is |auxiliary_data_block_size| bytes long and
 * contains the auxiliary data including the public key used to make
 * the signature and descriptors.
 *
 * The public key is at offset |public_key_offset| with size
 * |public_key_size| in this block. The size of the public key data is
 * defined by the |algorithm_type| field. The format of the public key
 * data is described in the |AvbRSAPublicKeyHeader| struct.
 *
 * The descriptors starts at |descriptors_offset| from the beginning
 * of the "Auxiliary Data" block and take up |descriptors_size|
 * bytes. Each descriptor is stored as a |AvbDescriptor| with tag and
 * number of bytes following. The number of descriptors can be
 * determined by walking this data until |descriptors_size| is
 * exhausted.
 *
 * The size of each of the "Authentication data" and "Auxiliary data"
 * blocks must be divisible by 64. This is to ensure proper alignment.
 *
 * Descriptors are free-form blocks stored in a part of the vbmeta
 * image subject to the same integrity checks as the rest of the
 * image. See the documentation for |AvbDescriptor| for well-known
 * descriptors. See avb_descriptor_foreach() for a convenience
 * function to iterate over descriptors.
 *
 * This struct is versioned, see the |required_libavb_version_major|
 * and |required_libavb_version_minor| fields. This represents the
 * minimum version of libavb required to verify the header and depends
 * on the features (e.g. algorithms, descriptors) used. Note that this
 * may be 1.0 even if generated by an avbtool from 1.4 but where no
 * features introduced after 1.0 has been used. See the "Versioning
 * and compatibility" section in the README.md file for more details.
 *
 * All fields are stored in network byte order when serialized. To
 * generate a copy with fields swapped to native byte order, use the
 * function avb_vbmeta_image_header_to_host_byte_order().
 *
 * Before reading and/or using any of this data, you MUST verify it
 * using avb_vbmeta_image_verify() and reject it unless it's signed by
 * a known good public key.
 */
typedef struct AvbVBMetaImageHeader {
  /*   0: Four bytes equal to "AVB0" (AVB_MAGIC). */
  uint8_t magic[AVB_MAGIC_LEN];

  /*   4: The major version of libavb required for this header. */
  uint32_t required_libavb_version_major;
  /*   8: The minor version of libavb required for this header. */
  uint32_t required_libavb_version_minor;

  /*  12: The size of the signature block. */
  uint64_t authentication_data_block_size;
  /*  20: The size of the auxiliary data block. */
  uint64_t auxiliary_data_block_size;

  /*  28: The verification algorithm used, see |AvbAlgorithmType| enum. */
  uint32_t algorithm_type;

  /*  32: Offset into the "Authentication data" block of hash data. */
  uint64_t hash_offset;
  /*  40: Length of the hash data. */
  uint64_t hash_size;

  /*  48: Offset into the "Authentication data" block of signature data. */
  uint64_t signature_offset;
  /*  56: Length of the signature data. */
  uint64_t signature_size;

  /*  64: Offset into the "Auxiliary data" block of public key data. */
  uint64_t public_key_offset;
  /*  72: Length of the public key data. */
  uint64_t public_key_size;

  /*  80: Offset into the "Auxiliary data" block of public key metadata. */
  uint64_t public_key_metadata_offset;
  /*  88: Length of the public key metadata. Must be set to zero if there
   *  is no public key metadata.
   */
  uint64_t public_key_metadata_size;

  /*  96: Offset into the "Auxiliary data" block of descriptor data. */
  uint64_t descriptors_offset;
  /* 104: Length of descriptor data. */
  uint64_t descriptors_size;

  /* 112: The rollback index which can be used to prevent rollback to
   *  older versions.
   */
  uint64_t rollback_index;

  /* 120: Flags from the AvbVBMetaImageFlags enumeration. This must be
   * set to zero if the vbmeta image is not a top-level image.
   */
  uint32_t flags;

  /* 124: The location of the rollback index defined in this header.
   * Only valid for the main vbmeta. For chained partitions, the rollback
   * index location must be specified in the AvbChainPartitionDescriptor
   * and this value must be set to 0.
   */
  uint32_t rollback_index_location;

  /* 128: The release string from avbtool, e.g. "avbtool 1.0.0" or
   * "avbtool 1.0.0 xyz_board Git-234abde89". Is guaranteed to be NUL
   * terminated. Applications must not make assumptions about how this
   * string is formatted.
   */
  uint8_t release_string[AVB_RELEASE_STRING_SIZE];

  /* 176: Padding to ensure struct is size AVB_VBMETA_IMAGE_HEADER_SIZE
   * bytes. This must be set to zeroes.
   */
  uint8_t reserved[80];
} AVB_ATTR_PACKED AvbVBMetaImageHeader;

/* Copies |src| to |dest|, byte-swapping fields in the process.
 *
 * Make sure you've verified |src| using avb_vbmeta_image_verify()
 * before accessing the data and/or using this function.
 */
void avb_vbmeta_image_header_to_host_byte_order(const AvbVBMetaImageHeader* src,
                                                AvbVBMetaImageHeader* dest);

/* Return codes used in avb_vbmeta_image_verify().
 *
 * AVB_VBMETA_VERIFY_RESULT_OK is returned if the vbmeta image header
 * is valid, the hash is correct and the signature is correct. Keep in
 * mind that you still need to check that you know the public key used
 * to sign the image, see avb_vbmeta_image_verify() for details.
 *
 * AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED is returned if the vbmeta
 * image header is valid but there is no signature or hash.
 *
 * AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER is returned if the
 * header of the vbmeta image is invalid, for example, invalid magic
 * or inconsistent data.
 *
 * AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION is returned if a) the
 * vbmeta image requires a minimum version of libavb which exceeds the
 * version of libavb used; or b) the vbmeta image major version
 * differs from the major version of libavb in use.
 *
 * AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH is returned if the hash
 * stored in the "Authentication data" block does not match the
 * calculated hash.
 *
 * AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH is returned if the
 * signature stored in the "Authentication data" block is invalid or
 * doesn't match the public key stored in the vbmeta image.
 */
typedef enum {
  AVB_VBMETA_VERIFY_RESULT_OK,
  AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED,
  AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER,
  AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION,
  AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH,
  AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH,
} AvbVBMetaVerifyResult;

/* Get a textual representation of |result|. */
const char* avb_vbmeta_verify_result_to_string(AvbVBMetaVerifyResult result);

/* Checks that vbmeta image at |data| of size |length| is a valid
 * vbmeta image. The complete contents of the vbmeta image must be
 * passed in. It's fine if |length| is bigger than the actual image,
 * typically callers of this function will load the entire contents of
 * the 'vbmeta_a' or 'vbmeta_b' partition and pass in its length (for
 * example, 1 MiB).
 *
 * See the |AvbVBMetaImageHeader| struct for information about the
 * three blocks (header, authentication, auxiliary) that make up a
 * vbmeta image.
 *
 * If the function returns |AVB_VBMETA_VERIFY_RESULT_OK| and
 * |out_public_key_data| is non-NULL, it will be set to point inside
 * |data| for where the serialized public key data is stored and
 * |out_public_key_length|, if non-NULL, will be set to the length of
 * the public key data. If there is no public key in the metadata then
 * |out_public_key_data| is set to NULL.
 *
 * See the |AvbVBMetaVerifyResult| enum for possible return values.
 *
 * VERY IMPORTANT:
 *
 *   1. Even if |AVB_VBMETA_VERIFY_RESULT_OK| is returned, you still
 *      need to check that the public key embedded in the image
 *      matches a known key! You can use 'avbtool extract_public_key'
 *      to extract the key (at build time, then store it along your
 *      code) and compare it to what is returned in
 *      |out_public_key_data|.
 *
 *   2. You need to check the |rollback_index| field against a stored
 *      value in NVRAM and reject the vbmeta image if the value in
 *      NVRAM is bigger than |rollback_index|. You must also update
 *      the value stored in NVRAM to the smallest value of
 *      |rollback_index| field from boot images in all bootable and
 *      authentic slots marked as GOOD.
 *
 * This is a low-level function to only verify the vbmeta data - you
 * are likely looking for avb_slot_verify() instead for verifying
 * integrity data for a whole set of partitions.
 */
AvbVBMetaVerifyResult avb_vbmeta_image_verify(
    const uint8_t* data,
    size_t length,
    const uint8_t** out_public_key_data,
    size_t* out_public_key_length) AVB_ATTR_WARN_UNUSED_RESULT;

#ifdef __cplusplus
}
#endif

#endif /* AVB_VBMETA_IMAGE_H_ */

```

`aosp/libavb1.2/src/avb/headers/avb_version.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#if !defined(AVB_INSIDE_LIBAVB_H) && !defined(AVB_COMPILATION)
#error "Never include this file directly, include libavb.h instead."
#endif

#ifndef AVB_VERSION_H_
#define AVB_VERSION_H_

#include "avb_sysdeps.h"

#ifdef __cplusplus
extern "C" {
#endif

/* The version number of AVB - keep in sync with avbtool. */
#define AVB_VERSION_MAJOR 1
#define AVB_VERSION_MINOR 2
#define AVB_VERSION_SUB 0

/* Returns a NUL-terminated string for the libavb version in use.  The
 * returned string usually looks like "%d.%d.%d". Applications must
 * not make assumptions about the content of this string.
 *
 * Boot loaders should display this string in debug/diagnostics output
 * to aid with debugging.
 *
 * This is similar to the string put in the |release_string| string
 * field in the VBMeta struct by avbtool.
 */
const char* avb_version_string(void);

#ifdef __cplusplus
}
#endif

#endif /* AVB_VERSION_H_ */

```

`aosp/libavb1.2/src/avb/headers/libavb.h`:

```h
/*
 * Copyright (C) 2016 The Android Open Source Project
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef LIBAVB_H_
#define LIBAVB_H_

/* The AVB_INSIDE_LIBAVB_H preprocessor symbol is used to enforce
 * library users to include only this file. All public interfaces, and
 * only public interfaces, must be included here.
 */

#define AVB_INSIDE_LIBAVB_H
#include "avb_chain_partition_descriptor.h"
#include "avb_crypto.h"
#include "avb_descriptor.h"
#include "avb_footer.h"
#include "avb_hash_descriptor.h"
#include "avb_hashtree_descriptor.h"
#include "avb_kernel_cmdline_descriptor.h"
#include "avb_ops.h"
#include "avb_property_descriptor.h"
#include "avb_slot_verify.h"
#include "avb_sysdeps.h"
#include "avb_util.h"
#include "avb_vbmeta_image.h"
#include "avb_version.h"
#undef AVB_INSIDE_LIBAVB_H

#endif /* LIBAVB_H_ */

```

`aosp/libsparse/append2simg/build.gradle.kts`:

```kts
plugins {
    `cpp-application`
}

application {
    targetMachines.set(listOf(machines.linux.x86_64, machines.macOS.x86_64))
    dependencies {
        implementation(project(":aosp:libsparse:sparse"))
    }
}

tasks.withType(LinkExecutable::class.java).configureEach {
    linkerArgs.add("-lz")
}

tasks.withType(CppCompile::class.java).configureEach {
    compilerArgs.add("-std=c++17")
}

```

`aosp/libsparse/append2simg/src/main/cpp/append2simg.cpp`:

```cpp
/*
 * Copyright (C) 2013 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#define _FILE_OFFSET_BITS 64
#define _LARGEFILE64_SOURCE 1

#include <errno.h>
#include <fcntl.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

#include <sparse/sparse.h>
#include "backed_block.h"
#include "sparse_file.h"

#ifndef O_BINARY
#define O_BINARY 0
#endif

#if defined(__APPLE__) && defined(__MACH__)
#define lseek64 lseek
#endif
#if defined(__APPLE__) && defined(__MACH__)
#define lseek64 lseek
#define off64_t off_t
#endif

void usage() {
  fprintf(stderr, "Usage: append2simg <output> <input>\n");
}

int main(int argc, char* argv[]) {
  int output;
  int output_block;
  char* output_path;
  struct sparse_file* sparse_output;

  int input;
  char* input_path;
  off64_t input_len;

  int tmp_fd;
  char* tmp_path;

  int ret;

  if (argc == 3) {
    output_path = argv[1];
    input_path = argv[2];
  } else {
    usage();
    exit(-1);
  }

  ret = asprintf(&tmp_path, "%s.append2simg", output_path);
  if (ret < 0) {
    fprintf(stderr, "Couldn't allocate filename\n");
    exit(-1);
  }

  output = open(output_path, O_RDWR | O_BINARY);
  if (output < 0) {
    fprintf(stderr, "Couldn't open output file (%s)\n", strerror(errno));
    exit(-1);
  }

  sparse_output = sparse_file_import_auto(output, false, true);
  if (!sparse_output) {
    fprintf(stderr, "Couldn't import output file\n");
    exit(-1);
  }

  input = open(input_path, O_RDONLY | O_BINARY);
  if (input < 0) {
    fprintf(stderr, "Couldn't open input file (%s)\n", strerror(errno));
    exit(-1);
  }

  input_len = lseek64(input, 0, SEEK_END);
  if (input_len < 0) {
    fprintf(stderr, "Couldn't get input file length (%s)\n", strerror(errno));
    exit(-1);
  } else if (input_len % sparse_output->block_size) {
    fprintf(stderr, "Input file is not a multiple of the output file's block size");
    exit(-1);
  }
  lseek64(input, 0, SEEK_SET);

  output_block = sparse_output->len / sparse_output->block_size;
  if (sparse_file_add_fd(sparse_output, input, 0, input_len, output_block) < 0) {
    fprintf(stderr, "Couldn't add input file\n");
    exit(-1);
  }
  sparse_output->len += input_len;

  tmp_fd = open(tmp_path, O_WRONLY | O_CREAT | O_BINARY, 0664);
  if (tmp_fd < 0) {
    fprintf(stderr, "Couldn't open temporary file (%s)\n", strerror(errno));
    exit(-1);
  }

  lseek64(output, 0, SEEK_SET);
  if (sparse_file_write(sparse_output, tmp_fd, false, true, false) < 0) {
    fprintf(stderr, "Failed to write sparse file\n");
    exit(-1);
  }

  sparse_file_destroy(sparse_output);
  close(tmp_fd);
  close(output);
  close(input);

  ret = rename(tmp_path, output_path);
  if (ret < 0) {
    fprintf(stderr, "Failed to rename temporary file (%s)\n", strerror(errno));
    exit(-1);
  }

  free(tmp_path);

  exit(0);
}

```

`aosp/libsparse/base/build.gradle.kts`:

```kts
plugins {
    `cpp-library`
}

library {
    targetMachines.set(listOf(machines.linux.x86_64, machines.macOS.x86_64))
    linkage.set(listOf(Linkage.STATIC))
}

extensions.configure<CppLibrary> {
    source.from(file("src/main/cpp"))
    privateHeaders.from(file("src/main/headers"))
    publicHeaders.from(file("src/main/public"))
}

tasks.withType(CppCompile::class.java).configureEach {
    compilerArgs.add("-std=c++17")
}

```

`aosp/libsparse/base/src/main/cpp/mapped_file.cpp`:

```cpp
/*
 * Copyright (C) 2018 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "android-base/mapped_file.h"

#include <utility>

#include <errno.h>

namespace android {
namespace base {

static constexpr char kEmptyBuffer[] = {'0'};

static off64_t InitPageSize() {
#if defined(_WIN32)
  SYSTEM_INFO si;
  GetSystemInfo(&si);
  return si.dwAllocationGranularity;
#else
  return sysconf(_SC_PAGE_SIZE);
#endif
}

std::unique_ptr<MappedFile> MappedFile::FromFd(borrowed_fd fd, off64_t offset, size_t length,
                                               int prot) {
#if defined(_WIN32)
  return FromOsHandle(reinterpret_cast<HANDLE>(_get_osfhandle(fd.get())), offset, length, prot);
#else
  return FromOsHandle(fd.get(), offset, length, prot);
#endif
}

std::unique_ptr<MappedFile> MappedFile::FromOsHandle(os_handle h, off64_t offset, size_t length,
                                                     int prot) {
  static const off64_t page_size = InitPageSize();
  size_t slop = offset % page_size;
  off64_t file_offset = offset - slop;
  off64_t file_length = length + slop;

#if defined(_WIN32)
  HANDLE handle = CreateFileMappingW(
      h, nullptr, (prot & PROT_WRITE) ? PAGE_READWRITE : PAGE_READONLY, 0, 0, nullptr);
  if (handle == nullptr) {
    // http://b/119818070 "app crashes when reading asset of zero length".
    // Return a MappedFile that's only valid for reading the size.
    if (length == 0 && ::GetLastError() == ERROR_FILE_INVALID) {
      return std::unique_ptr<MappedFile>(
          new MappedFile(const_cast<char*>(kEmptyBuffer), 0, 0, nullptr));
    }
    return nullptr;
  }
  void* base = MapViewOfFile(handle, (prot & PROT_WRITE) ? FILE_MAP_ALL_ACCESS : FILE_MAP_READ, 0,
                             file_offset, file_length);
  if (base == nullptr) {
    CloseHandle(handle);
    return nullptr;
  }
  return std::unique_ptr<MappedFile>(
      new MappedFile(static_cast<char*>(base), length, slop, handle));
#else
  void* base = mmap(nullptr, file_length, prot, MAP_SHARED, h, file_offset);
  if (base == MAP_FAILED) {
    // http://b/119818070 "app crashes when reading asset of zero length".
    // mmap fails with EINVAL for a zero length region.
    if (errno == EINVAL && length == 0) {
      return std::unique_ptr<MappedFile>(new MappedFile(const_cast<char*>(kEmptyBuffer), 0, 0));
    }
    return nullptr;
  }
  return std::unique_ptr<MappedFile>(new MappedFile(static_cast<char*>(base), length, slop));
#endif
}

MappedFile::MappedFile(MappedFile&& other)
    : base_(std::exchange(other.base_, nullptr)),
      size_(std::exchange(other.size_, 0)),
      offset_(std::exchange(other.offset_, 0))
#ifdef _WIN32
      ,
      handle_(std::exchange(other.handle_, nullptr))
#endif
{
}

MappedFile& MappedFile::operator=(MappedFile&& other) {
  Close();
  base_ = std::exchange(other.base_, nullptr);
  size_ = std::exchange(other.size_, 0);
  offset_ = std::exchange(other.offset_, 0);
#ifdef _WIN32
  handle_ = std::exchange(other.handle_, nullptr);
#endif
  return *this;
}

MappedFile::~MappedFile() {
  Close();
}

void MappedFile::Close() {
#if defined(_WIN32)
  if (base_ != nullptr && size_ != 0) UnmapViewOfFile(base_);
  if (handle_ != nullptr) CloseHandle(handle_);
  handle_ = nullptr;
#else
  if (base_ != nullptr && size_ != 0) munmap(base_, size_ + offset_);
#endif

  base_ = nullptr;
  offset_ = size_ = 0;
}

}  // namespace base
}  // namespace android

```

`aosp/libsparse/base/src/main/cpp/stringprintf.cpp`:

```cpp
/*
 * =====================================================================================
 *
 *       Filename:  stringprintf.cpp
 *
 *    Description:  
 *
 *        Version:  1.0
 *        Created:  08/14/2019 11:09:23 AM
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  YOUR NAME (), 
 *   Organization:  
 *
 * =====================================================================================
 */

#include <cstdarg>
#include <cstdio>
#include <string>

namespace android {
namespace base {

void StringAppendV(std::string* dst, const char* format, va_list ap) {
  // First try with a small fixed size buffer
  char space[1024];

  // It's possible for methods that use a va_list to invalidate
  // the data in it upon use.  The fix is to make a copy
  // of the structure before using it and use that copy instead.
  va_list backup_ap;
  va_copy(backup_ap, ap);
  int result = vsnprintf(space, sizeof(space), format, backup_ap);
  va_end(backup_ap);

  if (result < static_cast<int>(sizeof(space))) {
    if (result >= 0) {
      // Normal case -- everything fit.
      dst->append(space, result);
      return;
    }

    if (result < 0) {
      // Just an error.
      return;
    }
  }

  // Increase the buffer size to the size requested by vsnprintf,
  // plus one for the closing \0.
  int length = result + 1;
  char* buf = new char[length];

  // Restore the va_list before we use it again
  va_copy(backup_ap, ap);
  result = vsnprintf(buf, length, format, backup_ap);
  va_end(backup_ap);

  if (result >= 0 && result < length) {
    // It fit
    dst->append(buf, result);
  }
  delete[] buf;
}

std::string StringPrintf(const char* fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  std::string result;
  StringAppendV(&result, fmt, ap);
  va_end(ap);
  return result;
}

void StringAppendF(std::string* dst, const char* format, ...) {
  va_list ap;
  va_start(ap, format);
  StringAppendV(dst, format, ap);
  va_end(ap);
}

}  // namespace base
}  // namespace android

```

`aosp/libsparse/base/src/main/public/android-base/macros.h`:

```h
/*
 * Copyright (C) 2015 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <stddef.h>  // for size_t
#include <unistd.h>  // for TEMP_FAILURE_RETRY

#include <utility>

// bionic and glibc both have TEMP_FAILURE_RETRY, but eg Mac OS' libc doesn't.
#ifndef TEMP_FAILURE_RETRY
#define TEMP_FAILURE_RETRY(exp)            \
  ({                                       \
    decltype(exp) _rc;                     \
    do {                                   \
      _rc = (exp);                         \
    } while (_rc == -1 && errno == EINTR); \
    _rc;                                   \
  })
#endif

// A macro to disallow the copy constructor and operator= functions
// This must be placed in the private: declarations for a class.
//
// For disallowing only assign or copy, delete the relevant operator or
// constructor, for example:
// void operator=(const TypeName&) = delete;
// Note, that most uses of DISALLOW_ASSIGN and DISALLOW_COPY are broken
// semantically, one should either use disallow both or neither. Try to
// avoid these in new code.
#define DISALLOW_COPY_AND_ASSIGN(TypeName) \
  TypeName(const TypeName&) = delete;      \
  void operator=(const TypeName&) = delete

// A macro to disallow all the implicit constructors, namely the
// default constructor, copy constructor and operator= functions.
//
// This should be used in the private: declarations for a class
// that wants to prevent anyone from instantiating it. This is
// especially useful for classes containing only static methods.
#define DISALLOW_IMPLICIT_CONSTRUCTORS(TypeName) \
  TypeName() = delete;                           \
  DISALLOW_COPY_AND_ASSIGN(TypeName)

// The arraysize(arr) macro returns the # of elements in an array arr.
// The expression is a compile-time constant, and therefore can be
// used in defining new arrays, for example.  If you use arraysize on
// a pointer by mistake, you will get a compile-time error.
//
// One caveat is that arraysize() doesn't accept any array of an
// anonymous type or a type defined inside a function.  In these rare
// cases, you have to use the unsafe ARRAYSIZE_UNSAFE() macro below.  This is
// due to a limitation in C++'s template system.  The limitation might
// eventually be removed, but it hasn't happened yet.

// This template function declaration is used in defining arraysize.
// Note that the function doesn't need an implementation, as we only
// use its type.
template <typename T, size_t N>
char(&ArraySizeHelper(T(&array)[N]))[N];  // NOLINT(readability/casting)

#define arraysize(array) (sizeof(ArraySizeHelper(array)))

#define SIZEOF_MEMBER(t, f) sizeof(std::declval<t>().f)

// Changing this definition will cause you a lot of pain.  A majority of
// vendor code defines LIKELY and UNLIKELY this way, and includes
// this header through an indirect path.
#define LIKELY( exp )       (__builtin_expect( (exp) != 0, true  ))
#define UNLIKELY( exp )     (__builtin_expect( (exp) != 0, false ))

#define WARN_UNUSED __attribute__((warn_unused_result))

// A deprecated function to call to create a false use of the parameter, for
// example:
//   int foo(int x) { UNUSED(x); return 10; }
// to avoid compiler warnings. Going forward we prefer ATTRIBUTE_UNUSED.
template <typename... T>
void UNUSED(const T&...) {
}

// An attribute to place on a parameter to a function, for example:
//   int foo(int x ATTRIBUTE_UNUSED) { return 10; }
// to avoid compiler warnings.
#define ATTRIBUTE_UNUSED __attribute__((__unused__))

// The FALLTHROUGH_INTENDED macro can be used to annotate implicit fall-through
// between switch labels:
//  switch (x) {
//    case 40:
//    case 41:
//      if (truth_is_out_there) {
//        ++x;
//        FALLTHROUGH_INTENDED;  // Use instead of/along with annotations in
//                               // comments.
//      } else {
//        return x;
//      }
//    case 42:
//      ...
//
// As shown in the example above, the FALLTHROUGH_INTENDED macro should be
// followed by a semicolon. It is designed to mimic control-flow statements
// like 'break;', so it can be placed in most places where 'break;' can, but
// only if there are no statements on the execution path between it and the
// next switch label.
//
// When compiled with clang, the FALLTHROUGH_INTENDED macro is expanded to
// [[clang::fallthrough]] attribute, which is analysed when performing switch
// labels fall-through diagnostic ('-Wimplicit-fallthrough'). See clang
// documentation on language extensions for details:
// http://clang.llvm.org/docs/LanguageExtensions.html#clang__fallthrough
//
// When used with unsupported compilers, the FALLTHROUGH_INTENDED macro has no
// effect on diagnostics.
//
// In either case this macro has no effect on runtime behavior and performance
// of code.
#ifndef FALLTHROUGH_INTENDED
#define FALLTHROUGH_INTENDED [[clang::fallthrough]]  // NOLINT
#endif

// Current ABI string
#if defined(__arm__)
#define ABI_STRING "arm"
#elif defined(__aarch64__)
#define ABI_STRING "arm64"
#elif defined(__i386__)
#define ABI_STRING "x86"
#elif defined(__x86_64__)
#define ABI_STRING "x86_64"
#endif

```

`aosp/libsparse/base/src/main/public/android-base/mapped_file.h`:

```h
/*
 * Copyright (C) 2018 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <sys/types.h>

#include <memory>

#include "android-base/macros.h"
#include "android-base/off64_t.h"
#include "android-base/unique_fd.h"

#if defined(_WIN32)
#include <windows.h>
#define PROT_READ 1
#define PROT_WRITE 2
using os_handle = HANDLE;
#else
#include <sys/mman.h>
using os_handle = int;
#endif

namespace android {
namespace base {

/**
 * A region of a file mapped into memory (for grepping: also known as MmapFile or file mapping).
 */
class MappedFile {
 public:
  /**
   * Creates a new mapping of the file pointed to by `fd`. Unlike the underlying OS primitives,
   * `offset` does not need to be page-aligned. If `PROT_WRITE` is set in `prot`, the mapping
   * will be writable, otherwise it will be read-only. Mappings are always `MAP_SHARED`.
   */
  static std::unique_ptr<MappedFile> FromFd(borrowed_fd fd, off64_t offset, size_t length,
                                            int prot);

  /**
   * Same thing, but using the raw OS file handle instead of a CRT wrapper.
   */
  static std::unique_ptr<MappedFile> FromOsHandle(os_handle h, off64_t offset, size_t length,
                                                  int prot);

  /**
   * Removes the mapping.
   */
  ~MappedFile();

  /**
   * Not copyable but movable.
   */
  MappedFile(MappedFile&& other);
  MappedFile& operator=(MappedFile&& other);

  char* data() const { return base_ + offset_; }
  size_t size() const { return size_; }

 private:
  DISALLOW_IMPLICIT_CONSTRUCTORS(MappedFile);

  void Close();

  char* base_;
  size_t size_;

  size_t offset_;

#if defined(_WIN32)
  MappedFile(char* base, size_t size, size_t offset, HANDLE handle)
      : base_(base), size_(size), offset_(offset), handle_(handle) {}
  HANDLE handle_;
#else
  MappedFile(char* base, size_t size, size_t offset) : base_(base), size_(size), offset_(offset) {}
#endif
};

}  // namespace base
}  // namespace android

```

`aosp/libsparse/base/src/main/public/android-base/off64_t.h`:

```h
/*
 * Copyright (C) 2018 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#if defined(__APPLE__)
/** Mac OS has always had a 64-bit off_t, so it doesn't have off64_t. */
typedef off_t off64_t;
#endif

```

`aosp/libsparse/base/src/main/public/android-base/stringprintf.h`:

```h
/*
 * Copyright (C) 2011 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <stdarg.h>
#include <string>

namespace android {
namespace base {

// These printf-like functions are implemented in terms of vsnprintf, so they
// use the same attribute for compile-time format string checking.

// Returns a string corresponding to printf-like formatting of the arguments.
std::string StringPrintf(const char* fmt, ...) __attribute__((__format__(__printf__, 1, 2)));

// Appends a printf-like formatting of the arguments to 'dst'.
void StringAppendF(std::string* dst, const char* fmt, ...)
    __attribute__((__format__(__printf__, 2, 3)));

// Appends a printf-like formatting of the arguments to 'dst'.
void StringAppendV(std::string* dst, const char* format, va_list ap)
    __attribute__((__format__(__printf__, 2, 0)));

}  // namespace base
}  // namespace android

```

`aosp/libsparse/base/src/main/public/android-base/unique_fd.h`:

```h
/*
 * Copyright (C) 2015 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <dirent.h>
#include <errno.h>
#include <fcntl.h>

#if !defined(_WIN32)
#include <sys/socket.h>
#endif

#include <stdio.h>
#include <sys/types.h>
#include <unistd.h>

// DO NOT INCLUDE OTHER LIBBASE HEADERS!
// This file gets used in libbinder, and libbinder is used everywhere.
// Including other headers from libbase frequently results in inclusion of
// android-base/macros.h, which causes macro collisions.

// Container for a file descriptor that automatically closes the descriptor as
// it goes out of scope.
//
//      unique_fd ufd(open("/some/path", "r"));
//      if (ufd.get() == -1) return error;
//
//      // Do something useful, possibly including 'return'.
//
//      return 0; // Descriptor is closed for you.
//
// unique_fd is also known as ScopedFd/ScopedFD/scoped_fd; mentioned here to help
// you find this class if you're searching for one of those names.

#if defined(__BIONIC__)
#include <android/fdsan.h>
#endif

namespace android {
namespace base {

struct DefaultCloser {
#if defined(__BIONIC__)
  static void Tag(int fd, void* old_addr, void* new_addr) {
    if (android_fdsan_exchange_owner_tag) {
      uint64_t old_tag = android_fdsan_create_owner_tag(ANDROID_FDSAN_OWNER_TYPE_UNIQUE_FD,
                                                        reinterpret_cast<uint64_t>(old_addr));
      uint64_t new_tag = android_fdsan_create_owner_tag(ANDROID_FDSAN_OWNER_TYPE_UNIQUE_FD,
                                                        reinterpret_cast<uint64_t>(new_addr));
      android_fdsan_exchange_owner_tag(fd, old_tag, new_tag);
    }
  }
  static void Close(int fd, void* addr) {
    if (android_fdsan_close_with_tag) {
      uint64_t tag = android_fdsan_create_owner_tag(ANDROID_FDSAN_OWNER_TYPE_UNIQUE_FD,
                                                    reinterpret_cast<uint64_t>(addr));
      android_fdsan_close_with_tag(fd, tag);
    } else {
      close(fd);
    }
  }
#else
  static void Close(int fd) {
    // Even if close(2) fails with EINTR, the fd will have been closed.
    // Using TEMP_FAILURE_RETRY will either lead to EBADF or closing someone
    // else's fd.
    // http://lkml.indiana.edu/hypermail/linux/kernel/0509.1/0877.html
    ::close(fd);
  }
#endif
};

template <typename Closer>
class unique_fd_impl final {
 public:
  unique_fd_impl() {}

  explicit unique_fd_impl(int fd) { reset(fd); }
  ~unique_fd_impl() { reset(); }

  unique_fd_impl(const unique_fd_impl&) = delete;
  void operator=(const unique_fd_impl&) = delete;
  unique_fd_impl(unique_fd_impl&& other) noexcept { reset(other.release()); }
  unique_fd_impl& operator=(unique_fd_impl&& s) noexcept {
    int fd = s.fd_;
    s.fd_ = -1;
    reset(fd, &s);
    return *this;
  }

  [[clang::reinitializes]] void reset(int new_value = -1) { reset(new_value, nullptr); }

  int get() const { return fd_; }

#if !defined(ANDROID_BASE_UNIQUE_FD_DISABLE_IMPLICIT_CONVERSION)
  // unique_fd's operator int is dangerous, but we have way too much code that
  // depends on it, so make this opt-in at first.
  operator int() const { return get(); }  // NOLINT
#endif

  bool operator>=(int rhs) const { return get() >= rhs; }
  bool operator<(int rhs) const { return get() < rhs; }
  bool operator==(int rhs) const { return get() == rhs; }
  bool operator!=(int rhs) const { return get() != rhs; }
  bool operator==(const unique_fd_impl& rhs) const { return get() == rhs.get(); }
  bool operator!=(const unique_fd_impl& rhs) const { return get() != rhs.get(); }

  // Catch bogus error checks (i.e.: "!fd" instead of "fd != -1").
  bool operator!() const = delete;

  bool ok() const { return get() >= 0; }

  int release() __attribute__((warn_unused_result)) {
    tag(fd_, this, nullptr);
    int ret = fd_;
    fd_ = -1;
    return ret;
  }

 private:
  void reset(int new_value, void* previous_tag) {
    int previous_errno = errno;

    if (fd_ != -1) {
      close(fd_, this);
    }

    fd_ = new_value;
    if (new_value != -1) {
      tag(new_value, previous_tag, this);
    }

    errno = previous_errno;
  }

  int fd_ = -1;

  // Template magic to use Closer::Tag if available, and do nothing if not.
  // If Closer::Tag exists, this implementation is preferred, because int is a better match.
  // If not, this implementation is SFINAEd away, and the no-op below is the only one that exists.
  template <typename T = Closer>
  static auto tag(int fd, void* old_tag, void* new_tag)
      -> decltype(T::Tag(fd, old_tag, new_tag), void()) {
    T::Tag(fd, old_tag, new_tag);
  }

  template <typename T = Closer>
  static void tag(long, void*, void*) {
    // No-op.
  }

  // Same as above, to select between Closer::Close(int) and Closer::Close(int, void*).
  template <typename T = Closer>
  static auto close(int fd, void* tag_value) -> decltype(T::Close(fd, tag_value), void()) {
    T::Close(fd, tag_value);
  }

  template <typename T = Closer>
  static auto close(int fd, void*) -> decltype(T::Close(fd), void()) {
    T::Close(fd);
  }
};

using unique_fd = unique_fd_impl<DefaultCloser>;

#if !defined(_WIN32)

// Inline functions, so that they can be used header-only.
template <typename Closer>
inline bool Pipe(unique_fd_impl<Closer>* read, unique_fd_impl<Closer>* write,
                 int flags = O_CLOEXEC) {
  int pipefd[2];

#if defined(__linux__)
  if (pipe2(pipefd, flags) != 0) {
    return false;
  }
#else  // defined(__APPLE__)
  if (flags & ~(O_CLOEXEC | O_NONBLOCK)) {
    return false;
  }
  if (pipe(pipefd) != 0) {
    return false;
  }

  if (flags & O_CLOEXEC) {
    if (fcntl(pipefd[0], F_SETFD, FD_CLOEXEC) != 0 || fcntl(pipefd[1], F_SETFD, FD_CLOEXEC) != 0) {
      close(pipefd[0]);
      close(pipefd[1]);
      return false;
    }
  }
  if (flags & O_NONBLOCK) {
    if (fcntl(pipefd[0], F_SETFL, O_NONBLOCK) != 0 || fcntl(pipefd[1], F_SETFL, O_NONBLOCK) != 0) {
      close(pipefd[0]);
      close(pipefd[1]);
      return false;
    }
  }
#endif

  read->reset(pipefd[0]);
  write->reset(pipefd[1]);
  return true;
}

template <typename Closer>
inline bool Socketpair(int domain, int type, int protocol, unique_fd_impl<Closer>* left,
                       unique_fd_impl<Closer>* right) {
  int sockfd[2];
  if (socketpair(domain, type, protocol, sockfd) != 0) {
    return false;
  }
  left->reset(sockfd[0]);
  right->reset(sockfd[1]);
  return true;
}

template <typename Closer>
inline bool Socketpair(int type, unique_fd_impl<Closer>* left, unique_fd_impl<Closer>* right) {
  return Socketpair(AF_UNIX, type, 0, left, right);
}

// Using fdopen with unique_fd correctly is more annoying than it should be,
// because fdopen doesn't close the file descriptor received upon failure.
inline FILE* Fdopen(unique_fd&& ufd, const char* mode) {
  int fd = ufd.release();
  FILE* file = fdopen(fd, mode);
  if (!file) {
    close(fd);
  }
  return file;
}

// Using fdopendir with unique_fd correctly is more annoying than it should be,
// because fdopen doesn't close the file descriptor received upon failure.
inline DIR* Fdopendir(unique_fd&& ufd) {
  int fd = ufd.release();
  DIR* dir = fdopendir(fd);
  if (dir == nullptr) {
    close(fd);
  }
  return dir;
}

#endif  // !defined(_WIN32)

// A wrapper type that can be implicitly constructed from either int or unique_fd.
struct borrowed_fd {
  /* implicit */ borrowed_fd(int fd) : fd_(fd) {}  // NOLINT
  template <typename T>
  /* implicit */ borrowed_fd(const unique_fd_impl<T>& ufd) : fd_(ufd.get()) {}  // NOLINT

  int get() const { return fd_; }

  bool operator>=(int rhs) const { return get() >= rhs; }
  bool operator<(int rhs) const { return get() < rhs; }
  bool operator==(int rhs) const { return get() == rhs; }
  bool operator!=(int rhs) const { return get() != rhs; }

 private:
  int fd_ = -1;
};
}  // namespace base
}  // namespace android

template <typename T>
int close(const android::base::unique_fd_impl<T>&)
    __attribute__((__unavailable__("close called on unique_fd")));

template <typename T>
FILE* fdopen(const android::base::unique_fd_impl<T>&, const char* mode)
    __attribute__((__unavailable__("fdopen takes ownership of the fd passed in; either dup the "
                                   "unique_fd, or use android::base::Fdopen to pass ownership")));

template <typename T>
DIR* fdopendir(const android::base::unique_fd_impl<T>&) __attribute__((
    __unavailable__("fdopendir takes ownership of the fd passed in; either dup the "
                    "unique_fd, or use android::base::Fdopendir to pass ownership")));

```

`aosp/libsparse/base/src/test/cpp/hello_test.cpp`:

```cpp
/*
 * This C++ source file was generated by the Gradle 'init' task.
 */

#include <cassert>

int main() {
    return 0;
}

```

`aosp/libsparse/img2simg/build.gradle.kts`:

```kts
plugins {
    `cpp-application`
}

application {
    targetMachines.set(listOf(machines.linux.x86_64, machines.macOS.x86_64))
    dependencies {
        implementation(project(":aosp:libsparse:sparse"))
    }
}

tasks.withType(LinkExecutable::class.java).configureEach {
    linkerArgs.add("-lz")
}

tasks.withType(CppCompile::class.java).configureEach {
    compilerArgs.add("-std=c++17")
}

```

`aosp/libsparse/img2simg/src/main/cpp/img2simg.cpp`:

```cpp
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#define _FILE_OFFSET_BITS 64
#define _LARGEFILE64_SOURCE 1

#include <fcntl.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>

#include <sparse/sparse.h>

#ifndef O_BINARY
#define O_BINARY 0
#endif

#if defined(__APPLE__) && defined(__MACH__)
#define lseek64 lseek
#define off64_t off_t
#endif

void usage() {
  fprintf(stderr, "Usage: img2simg <raw_image_file> <sparse_image_file> [<block_size>]\n");
}

int main(int argc, char* argv[]) {
  int in;
  int out;
  int ret;
  struct sparse_file* s;
  unsigned int block_size = 4096;
  off64_t len;

  if (argc < 3 || argc > 4) {
    usage();
    exit(-1);
  }

  if (argc == 4) {
    block_size = atoi(argv[3]);
  }

  if (block_size < 1024 || block_size % 4 != 0) {
    usage();
    exit(-1);
  }

  if (strcmp(argv[1], "-") == 0) {
    in = STDIN_FILENO;
  } else {
    in = open(argv[1], O_RDONLY | O_BINARY);
    if (in < 0) {
      fprintf(stderr, "Cannot open input file %s\n", argv[1]);
      exit(-1);
    }
  }

  if (strcmp(argv[2], "-") == 0) {
    out = STDOUT_FILENO;
  } else {
    out = open(argv[2], O_WRONLY | O_CREAT | O_TRUNC | O_BINARY, 0664);
    if (out < 0) {
      fprintf(stderr, "Cannot open output file %s\n", argv[2]);
      exit(-1);
    }
  }

  len = lseek64(in, 0, SEEK_END);
  lseek64(in, 0, SEEK_SET);

  s = sparse_file_new(block_size, len);
  if (!s) {
    fprintf(stderr, "Failed to create sparse file\n");
    exit(-1);
  }

  sparse_file_verbose(s);
  ret = sparse_file_read(s, in, false, false);
  if (ret) {
    fprintf(stderr, "Failed to read file\n");
    exit(-1);
  }

  ret = sparse_file_write(s, out, false, true, false);
  if (ret) {
    fprintf(stderr, "Failed to write sparse file\n");
    exit(-1);
  }

  close(in);
  close(out);

  exit(0);
}

```

`aosp/libsparse/simg2img/build.gradle.kts`:

```kts
plugins {
    `cpp-application`
}

application {
    targetMachines.set(listOf(machines.linux.x86_64, machines.macOS.x86_64))
    dependencies {
        implementation(project(":aosp:libsparse:sparse"))
    }
}

tasks.withType(LinkExecutable::class.java).configureEach {
    linkerArgs.add("-lz")
}

tasks.register<CppCompile>("hello") {
}

tasks.withType(CppCompile::class.java).configureEach {
    compilerArgs.add("-std=c++17")
}

```

`aosp/libsparse/simg2img/src/main/cpp/simg2img.cpp`:

```cpp
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <sparse/sparse.h>

#include <fcntl.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>

#ifndef O_BINARY
#define O_BINARY 0
#endif

void usage() {
  fprintf(stderr, "Usage: simg2img <sparse_image_files> <raw_image_file>\n");
}

int main(int argc, char* argv[]) {
  int in;
  int out;
  int i;
  struct sparse_file* s;

  if (argc < 3) {
    usage();
    exit(-1);
  }

  out = open(argv[argc - 1], O_WRONLY | O_CREAT | O_TRUNC | O_BINARY, 0664);
  if (out < 0) {
    fprintf(stderr, "Cannot open output file %s\n", argv[argc - 1]);
    exit(-1);
  }

  for (i = 1; i < argc - 1; i++) {
    if (strcmp(argv[i], "-") == 0) {
      in = STDIN_FILENO;
    } else {
      in = open(argv[i], O_RDONLY | O_BINARY);
      if (in < 0) {
        fprintf(stderr, "Cannot open input file %s\n", argv[i]);
        exit(-1);
      }
    }

    s = sparse_file_import(in, true, false);
    if (!s) {
      fprintf(stderr, "Failed to read sparse file\n");
      exit(-1);
    }

    if (lseek(out, 0, SEEK_SET) == -1) {
      perror("lseek failed");
      exit(EXIT_FAILURE);
    }

    if (sparse_file_write(s, out, false, false, false) < 0) {
      fprintf(stderr, "Cannot write output file\n");
      exit(-1);
    }
    sparse_file_destroy(s);
    close(in);
  }

  close(out);

  exit(0);
}

```

`aosp/libsparse/simg2simg/build.gradle.kts`:

```kts
plugins {
    `cpp-application`
}

application {
    targetMachines.set(listOf(machines.linux.x86_64, machines.macOS.x86_64))
    dependencies {
        implementation(project(":aosp:libsparse:sparse"))
    }
}

tasks.withType(LinkExecutable::class.java).configureEach {
    linkerArgs.add("-lz")
}

tasks.withType(CppCompile::class.java).configureEach {
    compilerArgs.add("-std=c++17")
}

```

`aosp/libsparse/simg2simg/src/main/cpp/simg2simg.cpp`:

```cpp
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#define _FILE_OFFSET_BITS 64
#define _LARGEFILE64_SOURCE 1

#include <fcntl.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>

#include <sparse/sparse.h>

#ifndef O_BINARY
#define O_BINARY 0
#endif

void usage() {
  fprintf(stderr, "Usage: simg2simg <sparse image file> <sparse_image_file> <max_size>\n");
}

int main(int argc, char* argv[]) {
  int in;
  int out;
  int i;
  int ret;
  struct sparse_file* s;
  int64_t max_size;
  struct sparse_file** out_s;
  int files;
  char filename[4096];

  if (argc != 4) {
    usage();
    exit(-1);
  }

  max_size = atoll(argv[3]);

  in = open(argv[1], O_RDONLY | O_BINARY);
  if (in < 0) {
    fprintf(stderr, "Cannot open input file %s\n", argv[1]);
    exit(-1);
  }

  s = sparse_file_import(in, true, false);
  if (!s) {
    fprintf(stderr, "Failed to import sparse file\n");
    exit(-1);
  }

  files = sparse_file_resparse(s, max_size, nullptr, 0);
  if (files < 0) {
    fprintf(stderr, "Failed to resparse\n");
    exit(-1);
  }

  out_s = (sparse_file**) calloc(sizeof(struct sparse_file*), files);
  if (!out_s) {
    fprintf(stderr, "Failed to allocate sparse file array\n");
    exit(-1);
  }

  files = sparse_file_resparse(s, max_size, out_s, files);
  if (files < 0) {
    fprintf(stderr, "Failed to resparse\n");
    exit(-1);
  }

  for (i = 0; i < files; i++) {
    ret = snprintf(filename, sizeof(filename), "%s.%d", argv[2], i);
    if (ret >= (int)sizeof(filename)) {
      fprintf(stderr, "Filename too long\n");
      exit(-1);
    }

    out = open(filename, O_WRONLY | O_CREAT | O_TRUNC | O_BINARY, 0664);
    if (out < 0) {
      fprintf(stderr, "Cannot open output file %s\n", argv[2]);
      exit(-1);
    }

    ret = sparse_file_write(out_s[i], out, false, true, false);
    if (ret) {
      fprintf(stderr, "Failed to write sparse file\n");
      exit(-1);
    }
    close(out);
  }

  close(in);

  exit(0);
}

```

`aosp/libsparse/sparse/build.gradle.kts`:

```kts
plugins {
    `cpp-library`
}

library {
    targetMachines.set(listOf(machines.linux.x86_64, machines.macOS.x86_64))
    linkage.set(listOf(Linkage.STATIC))
    dependencies {
        implementation(project(":aosp:libsparse:base"))
    }
}

tasks.withType(CppCompile::class.java).configureEach {
    macros.put("NDEBUG", null)
    compilerArgs.add("-Wall")
    compilerArgs.add("-std=c++17")
}

tasks.withType(LinkSharedLibrary::class.java).configureEach {
    linkerArgs.add("-lz")
}

tasks.withType(CreateStaticLibrary::class.java).configureEach {
}

```

`aosp/libsparse/sparse/src/main/cpp/Android.bp`:

```bp
// Copyright 2010 The Android Open Source Project

cc_library {
    name: "libsparse",
    host_supported: true,
    recovery_available: true,
    unique_host_soname: true,
    srcs: [
        "backed_block.cpp",
        "output_file.cpp",
        "sparse.cpp",
        "sparse_crc32.cpp",
        "sparse_err.cpp",
        "sparse_read.cpp",
    ],
    cflags: ["-Werror"],
    local_include_dirs: ["include"],
    export_include_dirs: ["include"],
    shared_libs: [
        "libz",
        "libbase",
    ],
    target: {
        windows: {
            enabled: true,
        },
    },
}

cc_binary {
    name: "simg2img",
    host_supported: true,
    srcs: [
        "simg2img.cpp",
        "sparse_crc32.cpp",
    ],
    static_libs: [
        "libsparse",
        "libz",
        "libbase",
    ],

    cflags: ["-Werror"],
}

cc_binary {
    name: "img2simg",
    host_supported: true,
    srcs: ["img2simg.cpp"],
    static_libs: [
        "libsparse",
        "libz",
        "libbase",
    ],

    cflags: ["-Werror"],
}

cc_binary_host {
    name: "append2simg",
    srcs: ["append2simg.cpp"],
    static_libs: [
        "libsparse",
        "libz",
        "libbase",
    ],

    cflags: ["-Werror"],
}

python_binary_host {
    name: "simg_dump.py",
    main: "simg_dump.py",
    srcs: ["simg_dump.py"],
    version: {
        py2: {
            embedded_launcher: true,
            enabled: true,
        },
        py3: {
            enabled: false,
        },
    },
}

```

`aosp/libsparse/sparse/src/main/cpp/backed_block.cpp`:

```cpp
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <assert.h>
#include <errno.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#include "backed_block.h"
#include "sparse_defs.h"

struct backed_block {
  unsigned int block;
  unsigned int len;
  enum backed_block_type type;
  union {
    struct {
      void* data;
    } data;
    struct {
      char* filename;
      int64_t offset;
    } file;
    struct {
      int fd;
      int64_t offset;
    } fd;
    struct {
      uint32_t val;
    } fill;
  };
  struct backed_block* next;
};

struct backed_block_list {
  struct backed_block* data_blocks;
  struct backed_block* last_used;
  unsigned int block_size;
};

struct backed_block* backed_block_iter_new(struct backed_block_list* bbl) {
  return bbl->data_blocks;
}

struct backed_block* backed_block_iter_next(struct backed_block* bb) {
  return bb->next;
}

unsigned int backed_block_len(struct backed_block* bb) {
  return bb->len;
}

unsigned int backed_block_block(struct backed_block* bb) {
  return bb->block;
}

void* backed_block_data(struct backed_block* bb) {
  assert(bb->type == BACKED_BLOCK_DATA);
  return bb->data.data;
}

const char* backed_block_filename(struct backed_block* bb) {
  assert(bb->type == BACKED_BLOCK_FILE);
  return bb->file.filename;
}

int backed_block_fd(struct backed_block* bb) {
  assert(bb->type == BACKED_BLOCK_FD);
  return bb->fd.fd;
}

int64_t backed_block_file_offset(struct backed_block* bb) {
  assert(bb->type == BACKED_BLOCK_FILE || bb->type == BACKED_BLOCK_FD);
  if (bb->type == BACKED_BLOCK_FILE) {
    return bb->file.offset;
  } else { /* bb->type == BACKED_BLOCK_FD */
    return bb->fd.offset;
  }
}

uint32_t backed_block_fill_val(struct backed_block* bb) {
  assert(bb->type == BACKED_BLOCK_FILL);
  return bb->fill.val;
}

enum backed_block_type backed_block_type(struct backed_block* bb) {
  return bb->type;
}

void backed_block_destroy(struct backed_block* bb) {
  if (bb->type == BACKED_BLOCK_FILE) {
    free(bb->file.filename);
  }

  free(bb);
}

struct backed_block_list* backed_block_list_new(unsigned int block_size) {
  struct backed_block_list* b =
      reinterpret_cast<backed_block_list*>(calloc(sizeof(struct backed_block_list), 1));
  b->block_size = block_size;
  return b;
}

void backed_block_list_destroy(struct backed_block_list* bbl) {
  if (bbl->data_blocks) {
    struct backed_block* bb = bbl->data_blocks;
    while (bb) {
      struct backed_block* next = bb->next;
      backed_block_destroy(bb);
      bb = next;
    }
  }

  free(bbl);
}

void backed_block_list_move(struct backed_block_list* from, struct backed_block_list* to,
                            struct backed_block* start, struct backed_block* end) {
  struct backed_block* bb;

  if (start == nullptr) {
    start = from->data_blocks;
  }

  if (!end) {
    for (end = start; end && end->next; end = end->next)
      ;
  }

  if (start == nullptr || end == nullptr) {
    return;
  }

  from->last_used = nullptr;
  to->last_used = nullptr;
  if (from->data_blocks == start) {
    from->data_blocks = end->next;
  } else {
    for (bb = from->data_blocks; bb; bb = bb->next) {
      if (bb->next == start) {
        bb->next = end->next;
        break;
      }
    }
  }

  if (!to->data_blocks) {
    to->data_blocks = start;
    end->next = nullptr;
  } else {
    for (bb = to->data_blocks; bb; bb = bb->next) {
      if (!bb->next || bb->next->block > start->block) {
        end->next = bb->next;
        bb->next = start;
        break;
      }
    }
  }
}

/* may free b */
static int merge_bb(struct backed_block_list* bbl, struct backed_block* a, struct backed_block* b) {
  unsigned int block_len;

  /* Block doesn't exist (possible if one block is the last block) */
  if (!a || !b) {
    return -EINVAL;
  }

  assert(a->block < b->block);

  /* Blocks are of different types */
  if (a->type != b->type) {
    return -EINVAL;
  }

  /* Blocks are not adjacent */
  block_len = a->len / bbl->block_size; /* rounds down */
  if (a->block + block_len != b->block) {
    return -EINVAL;
  }

  switch (a->type) {
    case BACKED_BLOCK_DATA:
      /* Don't support merging data for now */
      return -EINVAL;
    case BACKED_BLOCK_FILL:
      if (a->fill.val != b->fill.val) {
        return -EINVAL;
      }
      break;
    case BACKED_BLOCK_FILE:
      /* Already make sure b->type is BACKED_BLOCK_FILE */
      if (strcmp(a->file.filename, b->file.filename) || a->file.offset + a->len != b->file.offset) {
        return -EINVAL;
      }
      break;
    case BACKED_BLOCK_FD:
      if (a->fd.fd != b->fd.fd || a->fd.offset + a->len != b->fd.offset) {
        return -EINVAL;
      }
      break;
  }

  /* Blocks are compatible and adjacent, with a before b.  Merge b into a,
   * and free b */
  a->len += b->len;
  a->next = b->next;

  backed_block_destroy(b);

  return 0;
}

static int queue_bb(struct backed_block_list* bbl, struct backed_block* new_bb) {
  struct backed_block* bb;

  if (bbl->data_blocks == nullptr) {
    bbl->data_blocks = new_bb;
    return 0;
  }

  if (bbl->data_blocks->block > new_bb->block) {
    new_bb->next = bbl->data_blocks;
    bbl->data_blocks = new_bb;
    return 0;
  }

  /* Optimization: blocks are mostly queued in sequence, so save the
     pointer to the last bb that was added, and start searching from
     there if the next block number is higher */
  if (bbl->last_used && new_bb->block > bbl->last_used->block)
    bb = bbl->last_used;
  else
    bb = bbl->data_blocks;
  bbl->last_used = new_bb;

  for (; bb->next && bb->next->block < new_bb->block; bb = bb->next)
    ;

  if (bb->next == nullptr) {
    bb->next = new_bb;
  } else {
    new_bb->next = bb->next;
    bb->next = new_bb;
  }

  merge_bb(bbl, new_bb, new_bb->next);
  if (!merge_bb(bbl, bb, new_bb)) {
    /* new_bb destroyed, point to retained as last_used */
    bbl->last_used = bb;
  }

  return 0;
}

/* Queues a fill block of memory to be written to the specified data blocks */
int backed_block_add_fill(struct backed_block_list* bbl, unsigned int fill_val, unsigned int len,
                          unsigned int block) {
  struct backed_block* bb = reinterpret_cast<backed_block*>(calloc(1, sizeof(struct backed_block)));
  if (bb == nullptr) {
    return -ENOMEM;
  }

  bb->block = block;
  bb->len = len;
  bb->type = BACKED_BLOCK_FILL;
  bb->fill.val = fill_val;
  bb->next = nullptr;

  return queue_bb(bbl, bb);
}

/* Queues a block of memory to be written to the specified data blocks */
int backed_block_add_data(struct backed_block_list* bbl, void* data, unsigned int len,
                          unsigned int block) {
  struct backed_block* bb = reinterpret_cast<backed_block*>(calloc(1, sizeof(struct backed_block)));
  if (bb == nullptr) {
    return -ENOMEM;
  }

  bb->block = block;
  bb->len = len;
  bb->type = BACKED_BLOCK_DATA;
  bb->data.data = data;
  bb->next = nullptr;

  return queue_bb(bbl, bb);
}

/* Queues a chunk of a file on disk to be written to the specified data blocks */
int backed_block_add_file(struct backed_block_list* bbl, const char* filename, int64_t offset,
                          unsigned int len, unsigned int block) {
  struct backed_block* bb = reinterpret_cast<backed_block*>(calloc(1, sizeof(struct backed_block)));
  if (bb == nullptr) {
    return -ENOMEM;
  }

  bb->block = block;
  bb->len = len;
  bb->type = BACKED_BLOCK_FILE;
  bb->file.filename = strdup(filename);
  bb->file.offset = offset;
  bb->next = nullptr;

  return queue_bb(bbl, bb);
}

/* Queues a chunk of a fd to be written to the specified data blocks */
int backed_block_add_fd(struct backed_block_list* bbl, int fd, int64_t offset, unsigned int len,
                        unsigned int block) {
  struct backed_block* bb = reinterpret_cast<backed_block*>(calloc(1, sizeof(struct backed_block)));
  if (bb == nullptr) {
    return -ENOMEM;
  }

  bb->block = block;
  bb->len = len;
  bb->type = BACKED_BLOCK_FD;
  bb->fd.fd = fd;
  bb->fd.offset = offset;
  bb->next = nullptr;

  return queue_bb(bbl, bb);
}

int backed_block_split(struct backed_block_list* bbl, struct backed_block* bb,
                       unsigned int max_len) {
  struct backed_block* new_bb;

  max_len = ALIGN_DOWN(max_len, bbl->block_size);

  if (bb->len <= max_len) {
    return 0;
  }

  new_bb = reinterpret_cast<backed_block*>(malloc(sizeof(struct backed_block)));
  if (new_bb == nullptr) {
    return -ENOMEM;
  }

  *new_bb = *bb;

  new_bb->len = bb->len - max_len;
  new_bb->block = bb->block + max_len / bbl->block_size;
  new_bb->next = bb->next;
  bb->next = new_bb;
  bb->len = max_len;

  switch (bb->type) {
    case BACKED_BLOCK_DATA:
      new_bb->data.data = (char*)bb->data.data + max_len;
      break;
    case BACKED_BLOCK_FILE:
      new_bb->file.offset += max_len;
      break;
    case BACKED_BLOCK_FD:
      new_bb->fd.offset += max_len;
      break;
    case BACKED_BLOCK_FILL:
      break;
  }

  return 0;
}

```

`aosp/libsparse/sparse/src/main/cpp/defs.h`:

```h
/*
 * Copyright (C) 2014 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _LIBSPARSE_DEFS_H_

#ifndef __unused
#define __unused __attribute__((__unused__))
#endif

#endif /* _LIBSPARSE_DEFS_H_ */

```

`aosp/libsparse/sparse/src/main/cpp/output_file.cpp`:

```cpp
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#define _FILE_OFFSET_BITS 64
#define _LARGEFILE64_SOURCE 1

#include <algorithm>
#include <fcntl.h>
#include <inttypes.h>
#include <limits.h>
#include <stdbool.h>
#include <stddef.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>
#include <zlib.h>

#include "defs.h"
#include "output_file.h"
#include "sparse_crc32.h"
#include "sparse_format.h"

#include <android-base/mapped_file.h>

#ifndef _WIN32
#define O_BINARY 0
#else
#define ftruncate64 ftruncate
#endif

#if defined(__APPLE__) && defined(__MACH__)
#define lseek64 lseek
#define ftruncate64 ftruncate
#define off64_t off_t
#endif

#define SPARSE_HEADER_MAJOR_VER 1
#define SPARSE_HEADER_MINOR_VER 0
#define SPARSE_HEADER_LEN (sizeof(sparse_header_t))
#define CHUNK_HEADER_LEN (sizeof(chunk_header_t))

#define container_of(inner, outer_t, elem) ((outer_t*)((char*)(inner)-offsetof(outer_t, elem)))

struct output_file_ops {
  int (*open)(struct output_file*, int fd);
  int (*skip)(struct output_file*, int64_t);
  int (*pad)(struct output_file*, int64_t);
  int (*write)(struct output_file*, void*, size_t);
  void (*close)(struct output_file*);
};

struct sparse_file_ops {
  int (*write_data_chunk)(struct output_file* out, unsigned int len, void* data);
  int (*write_fill_chunk)(struct output_file* out, unsigned int len, uint32_t fill_val);
  int (*write_skip_chunk)(struct output_file* out, int64_t len);
  int (*write_end_chunk)(struct output_file* out);
};

struct output_file {
  int64_t cur_out_ptr;
  unsigned int chunk_cnt;
  uint32_t crc32;
  struct output_file_ops* ops;
  struct sparse_file_ops* sparse_ops;
  int use_crc;
  unsigned int block_size;
  int64_t len;
  char* zero_buf;
  uint32_t* fill_buf;
  char* buf;
};

struct output_file_gz {
  struct output_file out;
  gzFile gz_fd;
};

#define to_output_file_gz(_o) container_of((_o), struct output_file_gz, out)

struct output_file_normal {
  struct output_file out;
  int fd;
};

#define to_output_file_normal(_o) container_of((_o), struct output_file_normal, out)

struct output_file_callback {
  struct output_file out;
  void* priv;
  int (*write)(void* priv, const void* buf, size_t len);
};

#define to_output_file_callback(_o) container_of((_o), struct output_file_callback, out)

static int file_open(struct output_file* out, int fd) {
  struct output_file_normal* outn = to_output_file_normal(out);

  outn->fd = fd;
  return 0;
}

static int file_skip(struct output_file* out, int64_t cnt) {
  off64_t ret;
  struct output_file_normal* outn = to_output_file_normal(out);

  ret = lseek64(outn->fd, cnt, SEEK_CUR);
  if (ret < 0) {
    error_errno("lseek64");
    return -1;
  }
  return 0;
}

static int file_pad(struct output_file* out, int64_t len) {
  int ret;
  struct output_file_normal* outn = to_output_file_normal(out);

  ret = ftruncate64(outn->fd, len);
  if (ret < 0) {
    return -errno;
  }

  return 0;
}

static int file_write(struct output_file* out, void* data, size_t len) {
  ssize_t ret;
  struct output_file_normal* outn = to_output_file_normal(out);

  while (len > 0) {
    ret = write(outn->fd, data, len);
    if (ret < 0) {
      if (errno == EINTR) {
        continue;
      }
      error_errno("write");
      return -1;
    }

    data = (char*)data + ret;
    len -= ret;
  }

  return 0;
}

static void file_close(struct output_file* out) {
  struct output_file_normal* outn = to_output_file_normal(out);

  free(outn);
}

static struct output_file_ops file_ops = {
    .open = file_open,
    .skip = file_skip,
    .pad = file_pad,
    .write = file_write,
    .close = file_close,
};

static int gz_file_open(struct output_file* out, int fd) {
  struct output_file_gz* outgz = to_output_file_gz(out);

  outgz->gz_fd = gzdopen(fd, "wb9");
  if (!outgz->gz_fd) {
    error_errno("gzopen");
    return -errno;
  }

  return 0;
}

static int gz_file_skip(struct output_file* out, int64_t cnt) {
  off64_t ret;
  struct output_file_gz* outgz = to_output_file_gz(out);

  ret = gzseek(outgz->gz_fd, cnt, SEEK_CUR);
  if (ret < 0) {
    error_errno("gzseek");
    return -1;
  }
  return 0;
}

static int gz_file_pad(struct output_file* out, int64_t len) {
  off64_t ret;
  struct output_file_gz* outgz = to_output_file_gz(out);

  ret = gztell(outgz->gz_fd);
  if (ret < 0) {
    return -1;
  }

  if (ret >= len) {
    return 0;
  }

  ret = gzseek(outgz->gz_fd, len - 1, SEEK_SET);
  if (ret < 0) {
    return -1;
  }

  gzwrite(outgz->gz_fd, "", 1);

  return 0;
}

static int gz_file_write(struct output_file* out, void* data, size_t len) {
  int ret;
  struct output_file_gz* outgz = to_output_file_gz(out);

  while (len > 0) {
    ret = gzwrite(outgz->gz_fd, data, std::min<unsigned int>(len, (unsigned int)INT_MAX));
    if (ret == 0) {
      error("gzwrite %s", gzerror(outgz->gz_fd, nullptr));
      return -1;
    }
    len -= ret;
    data = (char*)data + ret;
  }

  return 0;
}

static void gz_file_close(struct output_file* out) {
  struct output_file_gz* outgz = to_output_file_gz(out);

  gzclose(outgz->gz_fd);
  free(outgz);
}

static struct output_file_ops gz_file_ops = {
    .open = gz_file_open,
    .skip = gz_file_skip,
    .pad = gz_file_pad,
    .write = gz_file_write,
    .close = gz_file_close,
};

static int callback_file_open(struct output_file* out __unused, int fd __unused) {
  return 0;
}

static int callback_file_skip(struct output_file* out, int64_t off) {
  struct output_file_callback* outc = to_output_file_callback(out);
  int to_write;
  int ret;

  while (off > 0) {
    to_write = std::min(off, (int64_t)INT_MAX);
    ret = outc->write(outc->priv, nullptr, to_write);
    if (ret < 0) {
      return ret;
    }
    off -= to_write;
  }

  return 0;
}

static int callback_file_pad(struct output_file* out __unused, int64_t len __unused) {
  return -1;
}

static int callback_file_write(struct output_file* out, void* data, size_t len) {
  struct output_file_callback* outc = to_output_file_callback(out);

  return outc->write(outc->priv, data, len);
}

static void callback_file_close(struct output_file* out) {
  struct output_file_callback* outc = to_output_file_callback(out);

  free(outc);
}

static struct output_file_ops callback_file_ops = {
    .open = callback_file_open,
    .skip = callback_file_skip,
    .pad = callback_file_pad,
    .write = callback_file_write,
    .close = callback_file_close,
};

int read_all(int fd, void* buf, size_t len) {
  size_t total = 0;
  int ret;
  char* ptr = reinterpret_cast<char*>(buf);

  while (total < len) {
    ret = read(fd, ptr, len - total);

    if (ret < 0) return -errno;

    if (ret == 0) return -EINVAL;

    ptr += ret;
    total += ret;
  }

  return 0;
}

static int write_sparse_skip_chunk(struct output_file* out, int64_t skip_len) {
  chunk_header_t chunk_header;
  int ret;

  if (skip_len % out->block_size) {
    error("don't care size %" PRIi64 " is not a multiple of the block size %u", skip_len,
          out->block_size);
    return -1;
  }

  /* We are skipping data, so emit a don't care chunk. */
  chunk_header.chunk_type = CHUNK_TYPE_DONT_CARE;
  chunk_header.reserved1 = 0;
  chunk_header.chunk_sz = skip_len / out->block_size;
  chunk_header.total_sz = CHUNK_HEADER_LEN;
  ret = out->ops->write(out, &chunk_header, sizeof(chunk_header));
  if (ret < 0) return -1;

  out->cur_out_ptr += skip_len;
  out->chunk_cnt++;

  return 0;
}

static int write_sparse_fill_chunk(struct output_file* out, unsigned int len, uint32_t fill_val) {
  chunk_header_t chunk_header;
  int rnd_up_len, count;
  int ret;

  /* Round up the fill length to a multiple of the block size */
  rnd_up_len = ALIGN(len, out->block_size);

  /* Finally we can safely emit a chunk of data */
  chunk_header.chunk_type = CHUNK_TYPE_FILL;
  chunk_header.reserved1 = 0;
  chunk_header.chunk_sz = rnd_up_len / out->block_size;
  chunk_header.total_sz = CHUNK_HEADER_LEN + sizeof(fill_val);
  ret = out->ops->write(out, &chunk_header, sizeof(chunk_header));

  if (ret < 0) return -1;
  ret = out->ops->write(out, &fill_val, sizeof(fill_val));
  if (ret < 0) return -1;

  if (out->use_crc) {
    count = out->block_size / sizeof(uint32_t);
    while (count--) out->crc32 = sparse_crc32(out->crc32, &fill_val, sizeof(uint32_t));
  }

  out->cur_out_ptr += rnd_up_len;
  out->chunk_cnt++;

  return 0;
}

static int write_sparse_data_chunk(struct output_file* out, unsigned int len, void* data) {
  chunk_header_t chunk_header;
  int rnd_up_len, zero_len;
  int ret;

  /* Round up the data length to a multiple of the block size */
  rnd_up_len = ALIGN(len, out->block_size);
  zero_len = rnd_up_len - len;

  /* Finally we can safely emit a chunk of data */
  chunk_header.chunk_type = CHUNK_TYPE_RAW;
  chunk_header.reserved1 = 0;
  chunk_header.chunk_sz = rnd_up_len / out->block_size;
  chunk_header.total_sz = CHUNK_HEADER_LEN + rnd_up_len;
  ret = out->ops->write(out, &chunk_header, sizeof(chunk_header));

  if (ret < 0) return -1;
  ret = out->ops->write(out, data, len);
  if (ret < 0) return -1;
  if (zero_len) {
    ret = out->ops->write(out, out->zero_buf, zero_len);
    if (ret < 0) return -1;
  }

  if (out->use_crc) {
    out->crc32 = sparse_crc32(out->crc32, data, len);
    if (zero_len) out->crc32 = sparse_crc32(out->crc32, out->zero_buf, zero_len);
  }

  out->cur_out_ptr += rnd_up_len;
  out->chunk_cnt++;

  return 0;
}

int write_sparse_end_chunk(struct output_file* out) {
  chunk_header_t chunk_header;
  int ret;

  if (out->use_crc) {
    chunk_header.chunk_type = CHUNK_TYPE_CRC32;
    chunk_header.reserved1 = 0;
    chunk_header.chunk_sz = 0;
    chunk_header.total_sz = CHUNK_HEADER_LEN + 4;

    ret = out->ops->write(out, &chunk_header, sizeof(chunk_header));
    if (ret < 0) {
      return ret;
    }
    out->ops->write(out, &out->crc32, 4);
    if (ret < 0) {
      return ret;
    }

    out->chunk_cnt++;
  }

  return 0;
}

static struct sparse_file_ops sparse_file_ops = {
    .write_data_chunk = write_sparse_data_chunk,
    .write_fill_chunk = write_sparse_fill_chunk,
    .write_skip_chunk = write_sparse_skip_chunk,
    .write_end_chunk = write_sparse_end_chunk,
};

static int write_normal_data_chunk(struct output_file* out, unsigned int len, void* data) {
  int ret;
  unsigned int rnd_up_len = ALIGN(len, out->block_size);

  ret = out->ops->write(out, data, len);
  if (ret < 0) {
    return ret;
  }

  if (rnd_up_len > len) {
    ret = out->ops->skip(out, rnd_up_len - len);
  }

  return ret;
}

static int write_normal_fill_chunk(struct output_file* out, unsigned int len, uint32_t fill_val) {
  int ret;
  unsigned int i;
  unsigned int write_len;

  /* Initialize fill_buf with the fill_val */
  for (i = 0; i < out->block_size / sizeof(uint32_t); i++) {
    out->fill_buf[i] = fill_val;
  }

  while (len) {
    write_len = std::min(len, out->block_size);
    ret = out->ops->write(out, out->fill_buf, write_len);
    if (ret < 0) {
      return ret;
    }

    len -= write_len;
  }

  return 0;
}

static int write_normal_skip_chunk(struct output_file* out, int64_t len) {
  return out->ops->skip(out, len);
}

int write_normal_end_chunk(struct output_file* out) {
  return out->ops->pad(out, out->len);
}

static struct sparse_file_ops normal_file_ops = {
    .write_data_chunk = write_normal_data_chunk,
    .write_fill_chunk = write_normal_fill_chunk,
    .write_skip_chunk = write_normal_skip_chunk,
    .write_end_chunk = write_normal_end_chunk,
};

void output_file_close(struct output_file* out) {
  out->sparse_ops->write_end_chunk(out);
  free(out->zero_buf);
  free(out->fill_buf);
  out->zero_buf = nullptr;
  out->fill_buf = nullptr;
  out->ops->close(out);
}

static int output_file_init(struct output_file* out, int block_size, int64_t len, bool sparse,
                            int chunks, bool crc) {
  int ret;

  out->len = len;
  out->block_size = block_size;
  out->cur_out_ptr = 0LL;
  out->chunk_cnt = 0;
  out->crc32 = 0;
  out->use_crc = crc;

  out->zero_buf = reinterpret_cast<char*>(calloc(block_size, 1));
  if (!out->zero_buf) {
    error_errno("malloc zero_buf");
    return -ENOMEM;
  }

  out->fill_buf = reinterpret_cast<uint32_t*>(calloc(block_size, 1));
  if (!out->fill_buf) {
    error_errno("malloc fill_buf");
    ret = -ENOMEM;
    goto err_fill_buf;
  }

  if (sparse) {
    out->sparse_ops = &sparse_file_ops;
  } else {
    out->sparse_ops = &normal_file_ops;
  }

  if (sparse) {
    sparse_header_t sparse_header = {
        .magic = SPARSE_HEADER_MAGIC,
        .major_version = SPARSE_HEADER_MAJOR_VER,
        .minor_version = SPARSE_HEADER_MINOR_VER,
        .file_hdr_sz = SPARSE_HEADER_LEN,
        .chunk_hdr_sz = CHUNK_HEADER_LEN,
        .blk_sz = out->block_size,
        .total_blks = static_cast<unsigned>(DIV_ROUND_UP(out->len, out->block_size)),
        .total_chunks = static_cast<unsigned>(chunks),
        .image_checksum = 0};

    if (out->use_crc) {
      sparse_header.total_chunks++;
    }

    ret = out->ops->write(out, &sparse_header, sizeof(sparse_header));
    if (ret < 0) {
      goto err_write;
    }
  }

  return 0;

err_write:
  free(out->fill_buf);
err_fill_buf:
  free(out->zero_buf);
  return ret;
}

static struct output_file* output_file_new_gz(void) {
  struct output_file_gz* outgz =
      reinterpret_cast<struct output_file_gz*>(calloc(1, sizeof(struct output_file_gz)));
  if (!outgz) {
    error_errno("malloc struct outgz");
    return nullptr;
  }

  outgz->out.ops = &gz_file_ops;

  return &outgz->out;
}

static struct output_file* output_file_new_normal(void) {
  struct output_file_normal* outn =
      reinterpret_cast<struct output_file_normal*>(calloc(1, sizeof(struct output_file_normal)));
  if (!outn) {
    error_errno("malloc struct outn");
    return nullptr;
  }

  outn->out.ops = &file_ops;

  return &outn->out;
}

struct output_file* output_file_open_callback(int (*write)(void*, const void*, size_t), void* priv,
                                              unsigned int block_size, int64_t len, int gz __unused,
                                              int sparse, int chunks, int crc) {
  int ret;
  struct output_file_callback* outc;

  outc =
      reinterpret_cast<struct output_file_callback*>(calloc(1, sizeof(struct output_file_callback)));
  if (!outc) {
    error_errno("malloc struct outc");
    return nullptr;
  }

  outc->out.ops = &callback_file_ops;
  outc->priv = priv;
  outc->write = write;

  ret = output_file_init(&outc->out, block_size, len, sparse, chunks, crc);
  if (ret < 0) {
    free(outc);
    return nullptr;
  }

  return &outc->out;
}

struct output_file* output_file_open_fd(int fd, unsigned int block_size, int64_t len, int gz,
                                        int sparse, int chunks, int crc) {
  int ret;
  struct output_file* out;

  if (gz) {
    out = output_file_new_gz();
  } else {
    out = output_file_new_normal();
  }
  if (!out) {
    return nullptr;
  }

  out->ops->open(out, fd);

  ret = output_file_init(out, block_size, len, sparse, chunks, crc);
  if (ret < 0) {
    free(out);
    return nullptr;
  }

  return out;
}

/* Write a contiguous region of data blocks from a memory buffer */
int write_data_chunk(struct output_file* out, unsigned int len, void* data) {
  return out->sparse_ops->write_data_chunk(out, len, data);
}

/* Write a contiguous region of data blocks with a fill value */
int write_fill_chunk(struct output_file* out, unsigned int len, uint32_t fill_val) {
  return out->sparse_ops->write_fill_chunk(out, len, fill_val);
}

int write_fd_chunk(struct output_file* out, unsigned int len, int fd, int64_t offset) {
  auto m = android::base::MappedFile::FromFd(fd, offset, len, PROT_READ);
  if (!m) return -errno;

  return out->sparse_ops->write_data_chunk(out, m->size(), m->data());
}

/* Write a contiguous region of data blocks from a file */
int write_file_chunk(struct output_file* out, unsigned int len, const char* file, int64_t offset) {
  int ret;

  int file_fd = open(file, O_RDONLY | O_BINARY);
  if (file_fd < 0) {
    return -errno;
  }

  ret = write_fd_chunk(out, len, file_fd, offset);

  close(file_fd);

  return ret;
}

int write_skip_chunk(struct output_file* out, int64_t len) {
  return out->sparse_ops->write_skip_chunk(out, len);
}

```

`aosp/libsparse/sparse/src/main/cpp/output_file.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _OUTPUT_FILE_H_
#define _OUTPUT_FILE_H_

#ifdef __cplusplus
extern "C" {
#endif

#include <sparse/sparse.h>

struct output_file;

struct output_file* output_file_open_fd(int fd, unsigned int block_size, int64_t len, int gz,
                                        int sparse, int chunks, int crc);
struct output_file* output_file_open_callback(int (*write)(void*, const void*, size_t), void* priv,
                                              unsigned int block_size, int64_t len, int gz,
                                              int sparse, int chunks, int crc);
int write_data_chunk(struct output_file* out, unsigned int len, void* data);
int write_fill_chunk(struct output_file* out, unsigned int len, uint32_t fill_val);
int write_file_chunk(struct output_file* out, unsigned int len, const char* file, int64_t offset);
int write_fd_chunk(struct output_file* out, unsigned int len, int fd, int64_t offset);
int write_skip_chunk(struct output_file* out, int64_t len);
void output_file_close(struct output_file* out);

int read_all(int fd, void* buf, size_t len);

#ifdef __cplusplus
}
#endif

#endif

```

`aosp/libsparse/sparse/src/main/cpp/simg_dump.py`:

```py
#! /usr/bin/env python

# Copyright (C) 2012 The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function
import csv
import getopt
import hashlib
import posixpath
import signal
import struct
import sys


def usage(argv0):
  print("""
Usage: %s [-v] [-s] [-c <filename>] sparse_image_file ...
 -v             verbose output
 -s             show sha1sum of data blocks
 -c <filename>  save .csv file of blocks
""" % (argv0))
  sys.exit(2)


def main():
  signal.signal(signal.SIGPIPE, signal.SIG_DFL)

  me = posixpath.basename(sys.argv[0])

  # Parse the command line
  verbose = 0                   # -v
  showhash = 0                  # -s
  csvfilename = None            # -c
  try:
    opts, args = getopt.getopt(sys.argv[1:],
                               "vsc:",
                               ["verbose", "showhash", "csvfile"])
  except getopt.GetoptError, e:
    print(e)
    usage(me)
  for o, a in opts:
    if o in ("-v", "--verbose"):
      verbose += 1
    elif o in ("-s", "--showhash"):
      showhash = True
    elif o in ("-c", "--csvfile"):
      csvfilename = a
    else:
      print("Unrecognized option \"%s\"" % (o))
      usage(me)

  if not args:
    print("No sparse_image_file specified")
    usage(me)

  if csvfilename:
    csvfile = open(csvfilename, "wb")
    csvwriter = csv.writer(csvfile)

  output = verbose or csvfilename or showhash

  for path in args:
    FH = open(path, "rb")
    header_bin = FH.read(28)
    header = struct.unpack("<I4H4I", header_bin)

    magic = header[0]
    major_version = header[1]
    minor_version = header[2]
    file_hdr_sz = header[3]
    chunk_hdr_sz = header[4]
    blk_sz = header[5]
    total_blks = header[6]
    total_chunks = header[7]
    image_checksum = header[8]

    if magic != 0xED26FF3A:
      print("%s: %s: Magic should be 0xED26FF3A but is 0x%08X"
            % (me, path, magic))
      continue
    if major_version != 1 or minor_version != 0:
      print("%s: %s: I only know about version 1.0, but this is version %u.%u"
            % (me, path, major_version, minor_version))
      continue
    if file_hdr_sz != 28:
      print("%s: %s: The file header size was expected to be 28, but is %u."
            % (me, path, file_hdr_sz))
      continue
    if chunk_hdr_sz != 12:
      print("%s: %s: The chunk header size was expected to be 12, but is %u."
            % (me, path, chunk_hdr_sz))
      continue

    print("%s: Total of %u %u-byte output blocks in %u input chunks."
          % (path, total_blks, blk_sz, total_chunks))

    if image_checksum != 0:
      print("checksum=0x%08X" % (image_checksum))

    if not output:
      continue

    if verbose > 0:
      print("            input_bytes      output_blocks")
      print("chunk    offset     number  offset  number")

    if csvfilename:
      csvwriter.writerow(["chunk", "input offset", "input bytes",
                          "output offset", "output blocks", "type", "hash"])

    offset = 0
    for i in xrange(1, total_chunks + 1):
      header_bin = FH.read(12)
      header = struct.unpack("<2H2I", header_bin)
      chunk_type = header[0]
      chunk_sz = header[2]
      total_sz = header[3]
      data_sz = total_sz - 12
      curhash = ""
      curtype = ""
      curpos = FH.tell()

      if verbose > 0:
        print("%4u %10u %10u %7u %7u" % (i, curpos, data_sz, offset, chunk_sz),
              end=" ")

      if chunk_type == 0xCAC1:
        if data_sz != (chunk_sz * blk_sz):
          print("Raw chunk input size (%u) does not match output size (%u)"
                % (data_sz, chunk_sz * blk_sz))
          break
        else:
          curtype = "Raw data"
          data = FH.read(data_sz)
          if showhash:
            h = hashlib.sha1()
            h.update(data)
            curhash = h.hexdigest()
      elif chunk_type == 0xCAC2:
        if data_sz != 4:
          print("Fill chunk should have 4 bytes of fill, but this has %u"
                % (data_sz))
          break
        else:
          fill_bin = FH.read(4)
          fill = struct.unpack("<I", fill_bin)
          curtype = format("Fill with 0x%08X" % (fill))
          if showhash:
            h = hashlib.sha1()
            data = fill_bin * (blk_sz / 4);
            for block in xrange(chunk_sz):
              h.update(data)
            curhash = h.hexdigest()
      elif chunk_type == 0xCAC3:
        if data_sz != 0:
          print("Don't care chunk input size is non-zero (%u)" % (data_sz))
          break
        else:
          curtype = "Don't care"
      elif chunk_type == 0xCAC4:
        if data_sz != 4:
          print("CRC32 chunk should have 4 bytes of CRC, but this has %u"
                % (data_sz))
          break
        else:
          crc_bin = FH.read(4)
          crc = struct.unpack("<I", crc_bin)
          curtype = format("Unverified CRC32 0x%08X" % (crc))
      else:
        print("Unknown chunk type 0x%04X" % (chunk_type))
        break

      if verbose > 0:
        print("%-18s" % (curtype), end=" ")

        if verbose > 1:
          header = struct.unpack("<12B", header_bin)
          print(" (%02X%02X %02X%02X %02X%02X%02X%02X %02X%02X%02X%02X)"
                % (header[0], header[1], header[2], header[3],
                   header[4], header[5], header[6], header[7],
                   header[8], header[9], header[10], header[11]), end=" ")

        print(curhash)

      if csvfilename:
        csvwriter.writerow([i, curpos, data_sz, offset, chunk_sz, curtype,
                            curhash])

      offset += chunk_sz

    if verbose > 0:
      print("     %10u            %7u         End" % (FH.tell(), offset))

    if total_blks != offset:
      print("The header said we should have %u output blocks, but we saw %u"
            % (total_blks, offset))

    junk_len = len(FH.read())
    if junk_len:
      print("There were %u bytes of extra data at the end of the file."
            % (junk_len))

  if csvfilename:
    csvfile.close()

  sys.exit(0)

if __name__ == "__main__":
  main()

```

`aosp/libsparse/sparse/src/main/cpp/sparse.cpp`:

```cpp
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <assert.h>
#include <stdlib.h>

#include <sparse/sparse.h>

#include "defs.h"
#include "sparse_file.h"

#include "backed_block.h"
#include "output_file.h"
#include "sparse_defs.h"
#include "sparse_format.h"

struct sparse_file* sparse_file_new(unsigned int block_size, int64_t len) {
  struct sparse_file* s = reinterpret_cast<sparse_file*>(calloc(sizeof(struct sparse_file), 1));
  if (!s) {
    return nullptr;
  }

  s->backed_block_list = backed_block_list_new(block_size);
  if (!s->backed_block_list) {
    free(s);
    return nullptr;
  }

  s->block_size = block_size;
  s->len = len;

  return s;
}

void sparse_file_destroy(struct sparse_file* s) {
  backed_block_list_destroy(s->backed_block_list);
  free(s);
}

int sparse_file_add_data(struct sparse_file* s, void* data, unsigned int len, unsigned int block) {
  return backed_block_add_data(s->backed_block_list, data, len, block);
}

int sparse_file_add_fill(struct sparse_file* s, uint32_t fill_val, unsigned int len,
                         unsigned int block) {
  return backed_block_add_fill(s->backed_block_list, fill_val, len, block);
}

int sparse_file_add_file(struct sparse_file* s, const char* filename, int64_t file_offset,
                         unsigned int len, unsigned int block) {
  return backed_block_add_file(s->backed_block_list, filename, file_offset, len, block);
}

int sparse_file_add_fd(struct sparse_file* s, int fd, int64_t file_offset, unsigned int len,
                       unsigned int block) {
  return backed_block_add_fd(s->backed_block_list, fd, file_offset, len, block);
}
unsigned int sparse_count_chunks(struct sparse_file* s) {
  struct backed_block* bb;
  unsigned int last_block = 0;
  unsigned int chunks = 0;

  for (bb = backed_block_iter_new(s->backed_block_list); bb; bb = backed_block_iter_next(bb)) {
    if (backed_block_block(bb) > last_block) {
      /* If there is a gap between chunks, add a skip chunk */
      chunks++;
    }
    chunks++;
    last_block = backed_block_block(bb) + DIV_ROUND_UP(backed_block_len(bb), s->block_size);
  }
  if (last_block < DIV_ROUND_UP(s->len, s->block_size)) {
    chunks++;
  }

  return chunks;
}

static int sparse_file_write_block(struct output_file* out, struct backed_block* bb) {
  int ret = -EINVAL;

  switch (backed_block_type(bb)) {
    case BACKED_BLOCK_DATA:
      ret = write_data_chunk(out, backed_block_len(bb), backed_block_data(bb));
      break;
    case BACKED_BLOCK_FILE:
      ret = write_file_chunk(out, backed_block_len(bb), backed_block_filename(bb),
                             backed_block_file_offset(bb));
      break;
    case BACKED_BLOCK_FD:
      ret = write_fd_chunk(out, backed_block_len(bb), backed_block_fd(bb),
                           backed_block_file_offset(bb));
      break;
    case BACKED_BLOCK_FILL:
      ret = write_fill_chunk(out, backed_block_len(bb), backed_block_fill_val(bb));
      break;
  }

  return ret;
}

static int write_all_blocks(struct sparse_file* s, struct output_file* out) {
  struct backed_block* bb;
  unsigned int last_block = 0;
  int64_t pad;
  int ret = 0;

  for (bb = backed_block_iter_new(s->backed_block_list); bb; bb = backed_block_iter_next(bb)) {
    if (backed_block_block(bb) > last_block) {
      unsigned int blocks = backed_block_block(bb) - last_block;
      write_skip_chunk(out, (int64_t)blocks * s->block_size);
    }
    ret = sparse_file_write_block(out, bb);
    if (ret) return ret;
    last_block = backed_block_block(bb) + DIV_ROUND_UP(backed_block_len(bb), s->block_size);
  }

  pad = s->len - (int64_t)last_block * s->block_size;
  assert(pad >= 0);
  if (pad > 0) {
    write_skip_chunk(out, pad);
  }

  return 0;
}

/*
 * This is a workaround for 32-bit Windows: Limit the block size to 64 MB before
 * fastboot executable binary for windows 64-bit is released (b/156057250).
 */
#define MAX_BACKED_BLOCK_SIZE ((unsigned int) (64UL << 20))

int sparse_file_write(struct sparse_file* s, int fd, bool gz, bool sparse, bool crc) {
  struct backed_block* bb;
  int ret;
  int chunks;
  struct output_file* out;

  for (bb = backed_block_iter_new(s->backed_block_list); bb; bb = backed_block_iter_next(bb)) {
    ret = backed_block_split(s->backed_block_list, bb, MAX_BACKED_BLOCK_SIZE);
    if (ret) return ret;
  }

  chunks = sparse_count_chunks(s);
  out = output_file_open_fd(fd, s->block_size, s->len, gz, sparse, chunks, crc);

  if (!out) return -ENOMEM;

  ret = write_all_blocks(s, out);

  output_file_close(out);

  return ret;
}

int sparse_file_callback(struct sparse_file* s, bool sparse, bool crc,
                         int (*write)(void* priv, const void* data, size_t len), void* priv) {
  int ret;
  int chunks;
  struct output_file* out;

  chunks = sparse_count_chunks(s);
  out = output_file_open_callback(write, priv, s->block_size, s->len, false, sparse, chunks, crc);

  if (!out) return -ENOMEM;

  ret = write_all_blocks(s, out);

  output_file_close(out);

  return ret;
}

struct chunk_data {
  void* priv;
  unsigned int block;
  unsigned int nr_blocks;
  int (*write)(void* priv, const void* data, size_t len, unsigned int block, unsigned int nr_blocks);
};

static int foreach_chunk_write(void* priv, const void* data, size_t len) {
  struct chunk_data* chk = reinterpret_cast<chunk_data*>(priv);

  return chk->write(chk->priv, data, len, chk->block, chk->nr_blocks);
}

int sparse_file_foreach_chunk(struct sparse_file* s, bool sparse, bool crc,
                              int (*write)(void* priv, const void* data, size_t len,
                                           unsigned int block, unsigned int nr_blocks),
                              void* priv) {
  int ret = 0;
  int chunks;
  struct chunk_data chk;
  struct output_file* out;
  struct backed_block* bb;

  chk.priv = priv;
  chk.write = write;
  chk.block = chk.nr_blocks = 0;
  chunks = sparse_count_chunks(s);
  out = output_file_open_callback(foreach_chunk_write, &chk, s->block_size, s->len, false, sparse,
                                  chunks, crc);

  if (!out) return -ENOMEM;

  for (bb = backed_block_iter_new(s->backed_block_list); bb; bb = backed_block_iter_next(bb)) {
    chk.block = backed_block_block(bb);
    chk.nr_blocks = (backed_block_len(bb) - 1) / s->block_size + 1;
    ret = sparse_file_write_block(out, bb);
    if (ret) return ret;
  }

  output_file_close(out);

  return ret;
}

static int out_counter_write(void* priv, const void* data __unused, size_t len) {
  int64_t* count = reinterpret_cast<int64_t*>(priv);
  *count += len;
  return 0;
}

int64_t sparse_file_len(struct sparse_file* s, bool sparse, bool crc) {
  int ret;
  int chunks = sparse_count_chunks(s);
  int64_t count = 0;
  struct output_file* out;

  out = output_file_open_callback(out_counter_write, &count, s->block_size, s->len, false, sparse,
                                  chunks, crc);
  if (!out) {
    return -1;
  }

  ret = write_all_blocks(s, out);

  output_file_close(out);

  if (ret < 0) {
    return -1;
  }

  return count;
}

unsigned int sparse_file_block_size(struct sparse_file* s) {
  return s->block_size;
}

static struct backed_block* move_chunks_up_to_len(struct sparse_file* from, struct sparse_file* to,
                                                  unsigned int len) {
  int64_t count = 0;
  struct output_file* out_counter;
  struct backed_block* last_bb = nullptr;
  struct backed_block* bb;
  struct backed_block* start;
  unsigned int last_block = 0;
  int64_t file_len = 0;
  int ret;

  /*
   * overhead is sparse file header, the potential end skip
   * chunk and crc chunk.
   */
  int overhead = sizeof(sparse_header_t) + 2 * sizeof(chunk_header_t) + sizeof(uint32_t);
  len -= overhead;

  start = backed_block_iter_new(from->backed_block_list);
  out_counter = output_file_open_callback(out_counter_write, &count, to->block_size, to->len, false,
                                          true, 0, false);
  if (!out_counter) {
    return nullptr;
  }

  for (bb = start; bb; bb = backed_block_iter_next(bb)) {
    count = 0;
    if (backed_block_block(bb) > last_block) count += sizeof(chunk_header_t);
    last_block = backed_block_block(bb) + DIV_ROUND_UP(backed_block_len(bb), to->block_size);

    /* will call out_counter_write to update count */
    ret = sparse_file_write_block(out_counter, bb);
    if (ret) {
      bb = nullptr;
      goto out;
    }
    if (file_len + count > len) {
      /*
       * If the remaining available size is more than 1/8th of the
       * requested size, split the chunk.  Results in sparse files that
       * are at least 7/8ths of the requested size
       */
      file_len += sizeof(chunk_header_t);
      if (!last_bb || (len - file_len > (len / 8))) {
        backed_block_split(from->backed_block_list, bb, len - file_len);
        last_bb = bb;
      }
      goto move;
    }
    file_len += count;
    last_bb = bb;
  }

move:
  backed_block_list_move(from->backed_block_list, to->backed_block_list, start, last_bb);

out:
  output_file_close(out_counter);

  return bb;
}

int sparse_file_resparse(struct sparse_file* in_s, unsigned int max_len, struct sparse_file** out_s,
                         int out_s_count) {
  struct backed_block* bb;
  struct sparse_file* s;
  struct sparse_file* tmp;
  int c = 0;

  tmp = sparse_file_new(in_s->block_size, in_s->len);
  if (!tmp) {
    return -ENOMEM;
  }

  do {
    s = sparse_file_new(in_s->block_size, in_s->len);

    bb = move_chunks_up_to_len(in_s, s, max_len);

    if (c < out_s_count) {
      out_s[c] = s;
    } else {
      backed_block_list_move(s->backed_block_list, tmp->backed_block_list, nullptr, nullptr);
      sparse_file_destroy(s);
    }
    c++;
  } while (bb);

  backed_block_list_move(tmp->backed_block_list, in_s->backed_block_list, nullptr, nullptr);

  sparse_file_destroy(tmp);

  return c;
}

void sparse_file_verbose(struct sparse_file* s) {
  s->verbose = true;
}

```

`aosp/libsparse/sparse/src/main/cpp/sparse_crc32.cpp`:

```cpp
/*-
 *  COPYRIGHT (C) 1986 Gary S. Brown.  You may use this program, or
 *  code or tables extracted from it, as desired without restriction.
 */

/*
 *  First, the polynomial itself and its table of feedback terms.  The
 *  polynomial is
 *  X^32+X^26+X^23+X^22+X^16+X^12+X^11+X^10+X^8+X^7+X^5+X^4+X^2+X^1+X^0
 *
 *  Note that we take it "backwards" and put the highest-order term in
 *  the lowest-order bit.  The X^32 term is "implied"; the LSB is the
 *  X^31 term, etc.  The X^0 term (usually shown as "+1") results in
 *  the MSB being 1
 *
 *  Note that the usual hardware shift register implementation, which
 *  is what we're using (we're merely optimizing it by doing eight-bit
 *  chunks at a time) shifts bits into the lowest-order term.  In our
 *  implementation, that means shifting towards the right.  Why do we
 *  do it this way?  Because the calculated CRC must be transmitted in
 *  order from highest-order term to lowest-order term.  UARTs transmit
 *  characters in order from LSB to MSB.  By storing the CRC this way
 *  we hand it to the UART in the order low-byte to high-byte; the UART
 *  sends each low-bit to hight-bit; and the result is transmission bit
 *  by bit from highest- to lowest-order term without requiring any bit
 *  shuffling on our part.  Reception works similarly
 *
 *  The feedback terms table consists of 256, 32-bit entries.  Notes
 *
 *      The table can be generated at runtime if desired; code to do so
 *      is shown later.  It might not be obvious, but the feedback
 *      terms simply represent the results of eight shift/xor opera
 *      tions for all combinations of data and CRC register values
 *
 *      The values must be right-shifted by eight bits by the "updcrc
 *      logic; the shift must be unsigned (bring in zeroes).  On some
 *      hardware you could probably optimize the shift in assembler by
 *      using byte-swap instructions
 *      polynomial $edb88320
 *
 *
 * CRC32 code derived from work by Gary S. Brown.
 */

/* Code taken from FreeBSD 8 */
#include <stdint.h>
#include <stdio.h>

static uint32_t crc32_tab[] = {
    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f, 0xe963a535, 0x9e6495a3,
    0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91,
    0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,
    0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5,
    0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,
    0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,
    0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599, 0xb8bda50f,
    0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924, 0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d,
    0x76dc4190, 0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,
    0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,
    0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457,
    0x65b0d9c6, 0x12b7e950, 0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,
    0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb,
    0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9,
    0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,
    0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad,
    0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683,
    0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,
    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7,
    0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,
    0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,
    0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79,
    0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236, 0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f,
    0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,
    0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,
    0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21,
    0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,
    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45,
    0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db,
    0xaed16a4a, 0xd9d65adc, 0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,
    0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf,
    0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d};

/*
 * A function that calculates the CRC-32 based on the table above is
 * given below for documentation purposes. An equivalent implementation
 * of this function that's actually used in the kernel can be found
 * in sys/libkern.h, where it can be inlined.
 */

uint32_t sparse_crc32(uint32_t crc_in, const void* buf, size_t size) {
  const uint8_t* p = reinterpret_cast<const uint8_t*>(buf);
  uint32_t crc;

  crc = crc_in ^ ~0U;
  while (size--) crc = crc32_tab[(crc ^ *p++) & 0xFF] ^ (crc >> 8);
  return crc ^ ~0U;
}

```

`aosp/libsparse/sparse/src/main/cpp/sparse_crc32.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _LIBSPARSE_SPARSE_CRC32_H_
#define _LIBSPARSE_SPARSE_CRC32_H_

#include <stdint.h>

uint32_t sparse_crc32(uint32_t crc, const void* buf, size_t size);

#endif

```

`aosp/libsparse/sparse/src/main/cpp/sparse_defs.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _LIBSPARSE_SPARSE_DEFS_
#define _LIBSPARSE_SPARSE_DEFS_

#include <errno.h>
#include <stdio.h>

#define __le64 u64
#define __le32 u32
#define __le16 u16

#define __be64 u64
#define __be32 u32
#define __be16 u16

#define __u64 u64
#define __u32 u32
#define __u16 u16
#define __u8 u8

typedef unsigned long long u64;
typedef signed long long s64;
typedef unsigned int u32;
typedef unsigned short int u16;
typedef unsigned char u8;

#define DIV_ROUND_UP(x, y) (((x) + (y)-1) / (y))
#define ALIGN(x, y) ((y)*DIV_ROUND_UP((x), (y)))
#define ALIGN_DOWN(x, y) ((y) * ((x) / (y)))

#define error(fmt, args...)                                    \
  do {                                                         \
    fprintf(stderr, "error: %s: " fmt "\n", __func__, ##args); \
  } while (0)
#define error_errno(s, args...) error(s ": %s", ##args, strerror(errno))

#endif

```

`aosp/libsparse/sparse/src/main/cpp/sparse_err.cpp`:

```cpp
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <sparse/sparse.h>

#include <stdarg.h>
#include <stdio.h>
#include <unistd.h>

void sparse_default_print(const char* fmt, ...) {
  va_list argp;

  va_start(argp, fmt);
  vfprintf(stderr, fmt, argp);
  va_end(argp);
}

void (*sparse_print_error)(const char* fmt, ...) = sparse_default_print;
void (*sparse_print_verbose)(const char* fmt, ...) = sparse_default_print;

```

`aosp/libsparse/sparse/src/main/cpp/sparse_format.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _LIBSPARSE_SPARSE_FORMAT_H_
#define _LIBSPARSE_SPARSE_FORMAT_H_
#include "sparse_defs.h"

#ifdef __cplusplus
extern "C" {
#endif

typedef struct sparse_header {
  __le32 magic;          /* 0xed26ff3a */
  __le16 major_version;  /* (0x1) - reject images with higher major versions */
  __le16 minor_version;  /* (0x0) - allow images with higer minor versions */
  __le16 file_hdr_sz;    /* 28 bytes for first revision of the file format */
  __le16 chunk_hdr_sz;   /* 12 bytes for first revision of the file format */
  __le32 blk_sz;         /* block size in bytes, must be a multiple of 4 (4096) */
  __le32 total_blks;     /* total blocks in the non-sparse output image */
  __le32 total_chunks;   /* total chunks in the sparse input image */
  __le32 image_checksum; /* CRC32 checksum of the original data, counting "don't care" */
                         /* as 0. Standard 802.3 polynomial, use a Public Domain */
                         /* table implementation */
} sparse_header_t;

#define SPARSE_HEADER_MAGIC 0xed26ff3a

#define CHUNK_TYPE_RAW 0xCAC1
#define CHUNK_TYPE_FILL 0xCAC2
#define CHUNK_TYPE_DONT_CARE 0xCAC3
#define CHUNK_TYPE_CRC32 0xCAC4

typedef struct chunk_header {
  __le16 chunk_type; /* 0xCAC1 -> raw; 0xCAC2 -> fill; 0xCAC3 -> don't care */
  __le16 reserved1;
  __le32 chunk_sz; /* in blocks in output image */
  __le32 total_sz; /* in bytes of chunk input file including chunk header and data */
} chunk_header_t;

/* Following a Raw or Fill or CRC32 chunk is data.
 *  For a Raw chunk, it's the data in chunk_sz * blk_sz.
 *  For a Fill chunk, it's 4 bytes of the fill data.
 *  For a CRC32 chunk, it's 4 bytes of CRC32
 */

#ifdef __cplusplus
}
#endif

#endif

```

`aosp/libsparse/sparse/src/main/cpp/sparse_read.cpp`:

```cpp
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#define _FILE_OFFSET_BITS 64
#define _LARGEFILE64_SOURCE 1

#include <fcntl.h>
#include <inttypes.h>
#include <stdarg.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <algorithm>
#include <string>

#include <sparse/sparse.h>

#include "android-base/stringprintf.h"
#include "defs.h"
#include "output_file.h"
#include "sparse_crc32.h"
#include "sparse_file.h"
#include "sparse_format.h"

#if defined(__APPLE__) && defined(__MACH__)
#define lseek64 lseek
#define off64_t off_t
#endif

#define SPARSE_HEADER_MAJOR_VER 1
#define SPARSE_HEADER_LEN (sizeof(sparse_header_t))
#define CHUNK_HEADER_LEN (sizeof(chunk_header_t))

static constexpr int64_t COPY_BUF_SIZE = 1024 * 1024;
static char* copybuf;

static std::string ErrorString(int err) {
  if (err == -EOVERFLOW) return "EOF while reading file";
  if (err == -EINVAL) return "Invalid sparse file format";
  if (err == -ENOMEM) return "Failed allocation while reading file";
  return android::base::StringPrintf("Unknown error %d", err);
}

class SparseFileSource {
 public:
  /* Seeks the source ahead by the given offset. */
  virtual void Seek(int64_t offset) = 0;

  /* Return the current offset. */
  virtual int64_t GetOffset() = 0;

  /* Set the current offset. Return 0 if successful. */
  virtual int SetOffset(int64_t offset) = 0;

  /* Adds the given length from the current offset of the source to the file at the given block.
   * Return 0 if successful. */
  virtual int AddToSparseFile(struct sparse_file* s, int64_t len, unsigned int block) = 0;

  /* Get data of fixed size from the current offset and seek len bytes. Return 0 if successful. */
  virtual int ReadValue(void* ptr, int len) = 0;

  /* Find the crc32 of the next len bytes and seek ahead len bytes. Return 0 if successful. */
  virtual int GetCrc32(uint32_t* crc32, int64_t len) = 0;

  virtual ~SparseFileSource(){};
};

class SparseFileFdSource : public SparseFileSource {
 private:
  int fd;

 public:
  SparseFileFdSource(int fd) : fd(fd) {}
  ~SparseFileFdSource() override {}

  void Seek(int64_t off) override { lseek64(fd, off, SEEK_CUR); }

  int64_t GetOffset() override { return lseek64(fd, 0, SEEK_CUR); }

  int SetOffset(int64_t offset) override {
    return lseek64(fd, offset, SEEK_SET) == offset ? 0 : -errno;
  }

  int AddToSparseFile(struct sparse_file* s, int64_t len, unsigned int block) override {
    return sparse_file_add_fd(s, fd, GetOffset(), len, block);
  }

  int ReadValue(void* ptr, int len) override { return read_all(fd, ptr, len); }

  int GetCrc32(uint32_t* crc32, int64_t len) override {
    int chunk;
    int ret;
    while (len) {
      chunk = std::min(len, COPY_BUF_SIZE);
      ret = read_all(fd, copybuf, chunk);
      if (ret < 0) {
        return ret;
      }
      *crc32 = sparse_crc32(*crc32, copybuf, chunk);
      len -= chunk;
    }
    return 0;
  }
};

class SparseFileBufSource : public SparseFileSource {
 private:
  char* buf;
  int64_t offset;

 public:
  SparseFileBufSource(char* buf) : buf(buf), offset(0) {}
  ~SparseFileBufSource() override {}

  void Seek(int64_t off) override {
    buf += off;
    offset += off;
  }

  int64_t GetOffset() override { return offset; }

  int SetOffset(int64_t off) override {
    buf += off - offset;
    offset = off;
    return 0;
  }

  int AddToSparseFile(struct sparse_file* s, int64_t len, unsigned int block) override {
    return sparse_file_add_data(s, buf, len, block);
  }

  int ReadValue(void* ptr, int len) override {
    memcpy(ptr, buf, len);
    Seek(len);
    return 0;
  }

  int GetCrc32(uint32_t* crc32, int64_t len) override {
    *crc32 = sparse_crc32(*crc32, buf, len);
    Seek(len);
    return 0;
  }
};

static void verbose_error(bool verbose, int err, const char* fmt, ...) {
  if (!verbose) return;

  std::string msg = ErrorString(err);
  if (fmt) {
    msg += " at ";
    va_list argp;
    va_start(argp, fmt);
    android::base::StringAppendV(&msg, fmt, argp);
    va_end(argp);
  }
  sparse_print_verbose("%s\n", msg.c_str());
}

static int process_raw_chunk(struct sparse_file* s, unsigned int chunk_size,
                             SparseFileSource* source, unsigned int blocks, unsigned int block,
                             uint32_t* crc32) {
  int ret;
  int64_t len = blocks * s->block_size;

  if (chunk_size % s->block_size != 0) {
    return -EINVAL;
  }

  if (chunk_size / s->block_size != blocks) {
    return -EINVAL;
  }

  ret = source->AddToSparseFile(s, len, block);
  if (ret < 0) {
    return ret;
  }

  if (crc32) {
    ret = source->GetCrc32(crc32, len);
    if (ret < 0) {
      return ret;
    }
  } else {
    source->Seek(len);
  }

  return 0;
}

static int process_fill_chunk(struct sparse_file* s, unsigned int chunk_size,
                              SparseFileSource* source, unsigned int blocks, unsigned int block,
                              uint32_t* crc32) {
  int ret;
  int chunk;
  int64_t len = (int64_t)blocks * s->block_size;
  uint32_t fill_val;
  uint32_t* fillbuf;
  unsigned int i;

  if (chunk_size != sizeof(fill_val)) {
    return -EINVAL;
  }

  ret = source->ReadValue(&fill_val, sizeof(fill_val));
  if (ret < 0) {
    return ret;
  }

  ret = sparse_file_add_fill(s, fill_val, len, block);
  if (ret < 0) {
    return ret;
  }

  if (crc32) {
    /* Fill copy_buf with the fill value */
    fillbuf = (uint32_t*)copybuf;
    for (i = 0; i < (COPY_BUF_SIZE / sizeof(fill_val)); i++) {
      fillbuf[i] = fill_val;
    }

    while (len) {
      chunk = std::min(len, COPY_BUF_SIZE);
      *crc32 = sparse_crc32(*crc32, copybuf, chunk);
      len -= chunk;
    }
  }

  return 0;
}

static int process_skip_chunk(struct sparse_file* s, unsigned int chunk_size,
                              SparseFileSource* source __unused, unsigned int blocks,
                              unsigned int block __unused, uint32_t* crc32) {
  if (chunk_size != 0) {
    return -EINVAL;
  }

  if (crc32) {
    int64_t len = (int64_t)blocks * s->block_size;
    memset(copybuf, 0, COPY_BUF_SIZE);

    while (len) {
      int chunk = std::min(len, COPY_BUF_SIZE);
      *crc32 = sparse_crc32(*crc32, copybuf, chunk);
      len -= chunk;
    }
  }

  return 0;
}

static int process_crc32_chunk(SparseFileSource* source, unsigned int chunk_size, uint32_t* crc32) {
  uint32_t file_crc32;

  if (chunk_size != sizeof(file_crc32)) {
    return -EINVAL;
  }

  int ret = source->ReadValue(&file_crc32, sizeof(file_crc32));
  if (ret < 0) {
    return ret;
  }

  if (crc32 != nullptr && file_crc32 != *crc32) {
    return -EINVAL;
  }

  return 0;
}

static int process_chunk(struct sparse_file* s, SparseFileSource* source, unsigned int chunk_hdr_sz,
                         chunk_header_t* chunk_header, unsigned int cur_block, uint32_t* crc_ptr) {
  int ret;
  unsigned int chunk_data_size;
  int64_t offset = source->GetOffset();

  chunk_data_size = chunk_header->total_sz - chunk_hdr_sz;

  switch (chunk_header->chunk_type) {
    case CHUNK_TYPE_RAW:
      ret =
          process_raw_chunk(s, chunk_data_size, source, chunk_header->chunk_sz, cur_block, crc_ptr);
      if (ret < 0) {
        verbose_error(s->verbose, ret, "data block at %" PRId64, offset);
        return ret;
      }
      return chunk_header->chunk_sz;
    case CHUNK_TYPE_FILL:
      ret = process_fill_chunk(s, chunk_data_size, source, chunk_header->chunk_sz, cur_block,
                               crc_ptr);
      if (ret < 0) {
        verbose_error(s->verbose, ret, "fill block at %" PRId64, offset);
        return ret;
      }
      return chunk_header->chunk_sz;
    case CHUNK_TYPE_DONT_CARE:
      ret = process_skip_chunk(s, chunk_data_size, source, chunk_header->chunk_sz, cur_block,
                               crc_ptr);
      if (chunk_data_size != 0) {
        if (ret < 0) {
          verbose_error(s->verbose, ret, "skip block at %" PRId64, offset);
          return ret;
        }
      }
      return chunk_header->chunk_sz;
    case CHUNK_TYPE_CRC32:
      ret = process_crc32_chunk(source, chunk_data_size, crc_ptr);
      if (ret < 0) {
        verbose_error(s->verbose, -EINVAL, "crc block at %" PRId64, offset);
        return ret;
      }
      return 0;
    default:
      verbose_error(s->verbose, -EINVAL, "unknown block %04X at %" PRId64, chunk_header->chunk_type,
                    offset);
  }

  return 0;
}

static int sparse_file_read_sparse(struct sparse_file* s, SparseFileSource* source, bool crc) {
  int ret;
  unsigned int i;
  sparse_header_t sparse_header;
  chunk_header_t chunk_header;
  uint32_t crc32 = 0;
  uint32_t* crc_ptr = nullptr;
  unsigned int cur_block = 0;

  if (!copybuf) {
    copybuf = (char*)malloc(COPY_BUF_SIZE);
  }

  if (!copybuf) {
    return -ENOMEM;
  }

  if (crc) {
    crc_ptr = &crc32;
  }

  ret = source->ReadValue(&sparse_header, sizeof(sparse_header));
  if (ret < 0) {
    return ret;
  }

  if (sparse_header.magic != SPARSE_HEADER_MAGIC) {
    return -EINVAL;
  }

  if (sparse_header.major_version != SPARSE_HEADER_MAJOR_VER) {
    return -EINVAL;
  }

  if (sparse_header.file_hdr_sz < SPARSE_HEADER_LEN) {
    return -EINVAL;
  }

  if (sparse_header.chunk_hdr_sz < sizeof(chunk_header)) {
    return -EINVAL;
  }

  if (sparse_header.file_hdr_sz > SPARSE_HEADER_LEN) {
    /* Skip the remaining bytes in a header that is longer than
     * we expected.
     */
    source->Seek(sparse_header.file_hdr_sz - SPARSE_HEADER_LEN);
  }

  for (i = 0; i < sparse_header.total_chunks; i++) {
    ret = source->ReadValue(&chunk_header, sizeof(chunk_header));
    if (ret < 0) {
      return ret;
    }

    if (sparse_header.chunk_hdr_sz > CHUNK_HEADER_LEN) {
      /* Skip the remaining bytes in a header that is longer than
       * we expected.
       */
      source->Seek(sparse_header.chunk_hdr_sz - CHUNK_HEADER_LEN);
    }

    ret = process_chunk(s, source, sparse_header.chunk_hdr_sz, &chunk_header, cur_block, crc_ptr);
    if (ret < 0) {
      return ret;
    }

    cur_block += ret;
  }

  if (sparse_header.total_blks != cur_block) {
    return -EINVAL;
  }

  return 0;
}

static int sparse_file_read_normal(struct sparse_file* s, int fd) {
  int ret;
  uint32_t* buf = (uint32_t*)malloc(s->block_size);
  unsigned int block = 0;
  int64_t remain = s->len;
  int64_t offset = 0;
  unsigned int to_read;
  unsigned int i;
  bool sparse_block;

  if (!buf) {
    return -ENOMEM;
  }

  while (remain > 0) {
    to_read = std::min(remain, (int64_t)(s->block_size));
    ret = read_all(fd, buf, to_read);
    if (ret < 0) {
      error("failed to read sparse file");
      free(buf);
      return ret;
    }

    if (to_read == s->block_size) {
      sparse_block = true;
      for (i = 1; i < s->block_size / sizeof(uint32_t); i++) {
        if (buf[0] != buf[i]) {
          sparse_block = false;
          break;
        }
      }
    } else {
      sparse_block = false;
    }

    if (sparse_block) {
      /* TODO: add flag to use skip instead of fill for buf[0] == 0 */
      sparse_file_add_fill(s, buf[0], to_read, block);
    } else {
      sparse_file_add_fd(s, fd, offset, to_read, block);
    }

    remain -= to_read;
    offset += to_read;
    block++;
  }

  free(buf);
  return 0;
}

int sparse_file_read(struct sparse_file* s, int fd, bool sparse, bool crc) {
  if (crc && !sparse) {
    return -EINVAL;
  }

  if (sparse) {
    SparseFileFdSource source(fd);
    return sparse_file_read_sparse(s, &source, crc);
  } else {
    return sparse_file_read_normal(s, fd);
  }
}

int sparse_file_read_buf(struct sparse_file* s, char* buf, bool crc) {
  SparseFileBufSource source(buf);
  return sparse_file_read_sparse(s, &source, crc);
}

static struct sparse_file* sparse_file_import_source(SparseFileSource* source, bool verbose,
                                                     bool crc) {
  int ret;
  sparse_header_t sparse_header;
  int64_t len;
  struct sparse_file* s;

  ret = source->ReadValue(&sparse_header, sizeof(sparse_header));
  if (ret < 0) {
    verbose_error(verbose, ret, "header");
    return nullptr;
  }

  if (sparse_header.magic != SPARSE_HEADER_MAGIC) {
    verbose_error(verbose, -EINVAL, "header magic");
    return nullptr;
  }

  if (sparse_header.major_version != SPARSE_HEADER_MAJOR_VER) {
    verbose_error(verbose, -EINVAL, "header major version");
    return nullptr;
  }

  if (sparse_header.file_hdr_sz < SPARSE_HEADER_LEN) {
    return nullptr;
  }

  if (sparse_header.chunk_hdr_sz < sizeof(chunk_header_t)) {
    return nullptr;
  }

  len = (int64_t)sparse_header.total_blks * sparse_header.blk_sz;
  s = sparse_file_new(sparse_header.blk_sz, len);
  if (!s) {
    verbose_error(verbose, -EINVAL, nullptr);
    return nullptr;
  }

  ret = source->SetOffset(0);
  if (ret < 0) {
    verbose_error(verbose, ret, "seeking");
    sparse_file_destroy(s);
    return nullptr;
  }

  s->verbose = verbose;

  ret = sparse_file_read_sparse(s, source, crc);
  if (ret < 0) {
    sparse_file_destroy(s);
    return nullptr;
  }

  return s;
}

struct sparse_file* sparse_file_import(int fd, bool verbose, bool crc) {
  SparseFileFdSource source(fd);
  return sparse_file_import_source(&source, verbose, crc);
}

struct sparse_file* sparse_file_import_buf(char* buf, bool verbose, bool crc) {
  SparseFileBufSource source(buf);
  return sparse_file_import_source(&source, verbose, crc);
}

struct sparse_file* sparse_file_import_auto(int fd, bool crc, bool verbose) {
  struct sparse_file* s;
  int64_t len;
  int ret;

  s = sparse_file_import(fd, verbose, crc);
  if (s) {
    return s;
  }

  len = lseek64(fd, 0, SEEK_END);
  if (len < 0) {
    return nullptr;
  }

  lseek64(fd, 0, SEEK_SET);

  s = sparse_file_new(4096, len);
  if (!s) {
    return nullptr;
  }

  ret = sparse_file_read_normal(s, fd);
  if (ret < 0) {
    sparse_file_destroy(s);
    return nullptr;
  }

  return s;
}

```

`aosp/libsparse/sparse/src/main/public/backed_block.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _BACKED_BLOCK_H_
#define _BACKED_BLOCK_H_

#include <stdint.h>

struct backed_block_list;
struct backed_block;

enum backed_block_type {
  BACKED_BLOCK_DATA,
  BACKED_BLOCK_FILE,
  BACKED_BLOCK_FD,
  BACKED_BLOCK_FILL,
};

int backed_block_add_data(struct backed_block_list* bbl, void* data, unsigned int len,
                          unsigned int block);
int backed_block_add_fill(struct backed_block_list* bbl, unsigned int fill_val, unsigned int len,
                          unsigned int block);
int backed_block_add_file(struct backed_block_list* bbl, const char* filename, int64_t offset,
                          unsigned int len, unsigned int block);
int backed_block_add_fd(struct backed_block_list* bbl, int fd, int64_t offset, unsigned int len,
                        unsigned int block);

struct backed_block* backed_block_iter_new(struct backed_block_list* bbl);
struct backed_block* backed_block_iter_next(struct backed_block* bb);
unsigned int backed_block_len(struct backed_block* bb);
unsigned int backed_block_block(struct backed_block* bb);
void* backed_block_data(struct backed_block* bb);
const char* backed_block_filename(struct backed_block* bb);
int backed_block_fd(struct backed_block* bb);
int64_t backed_block_file_offset(struct backed_block* bb);
uint32_t backed_block_fill_val(struct backed_block* bb);
enum backed_block_type backed_block_type(struct backed_block* bb);
int backed_block_split(struct backed_block_list* bbl, struct backed_block* bb, unsigned int max_len);

struct backed_block* backed_block_iter_new(struct backed_block_list* bbl);
struct backed_block* backed_block_iter_next(struct backed_block* bb);

struct backed_block_list* backed_block_list_new(unsigned int block_size);
void backed_block_list_destroy(struct backed_block_list* bbl);

void backed_block_list_move(struct backed_block_list* from, struct backed_block_list* to,
                            struct backed_block* start, struct backed_block* end);

#endif

```

`aosp/libsparse/sparse/src/main/public/sparse/sparse.h`:

```h
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _LIBSPARSE_SPARSE_H_
#define _LIBSPARSE_SPARSE_H_

#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>

#ifdef	__cplusplus
extern "C" {
#endif

struct sparse_file;

// The callbacks in sparse_file_callback() and sparse_file_foreach_chunk() take
// size_t as the length type (was `int` in past). This allows clients to keep
// their codes compatibile with both versions as needed.
#define	SPARSE_CALLBACK_USES_SIZE_T

/**
 * sparse_file_new - create a new sparse file cookie
 *
 * @block_size - minimum size of a chunk
 * @len - size of the expanded sparse file.
 *
 * Creates a new sparse_file cookie that can be used to associate data
 * blocks.  Can later be written to a file with a variety of options.
 * block_size specifies the minimum size of a chunk in the file.  The maximum
 * size of the file is 2**32 * block_size (16TB for 4k block size).
 *
 * Returns the sparse file cookie, or NULL on error.
 */
struct sparse_file *sparse_file_new(unsigned int block_size, int64_t len);

/**
 * sparse_file_destroy - destroy a sparse file cookie
 *
 * @s - sparse file cookie
 *
 * Destroys a sparse file cookie.  After destroy, all memory passed in to
 * sparse_file_add_data can be freed by the caller
 */
void sparse_file_destroy(struct sparse_file *s);

/**
 * sparse_file_add_data - associate a data chunk with a sparse file
 *
 * @s - sparse file cookie
 * @data - pointer to data block
 * @len - length of the data block
 * @block - offset in blocks into the sparse file to place the data chunk
 *
 * Associates a data chunk with a sparse file cookie.  The region
 * [block * block_size : block * block_size + len) must not already be used in
 * the sparse file. If len is not a multiple of the block size the data
 * will be padded with zeros.
 *
 * The data pointer must remain valid until the sparse file is closed or the
 * data block is removed from the sparse file.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_add_data(struct sparse_file *s,
		void *data, unsigned int len, unsigned int block);

/**
 * sparse_file_add_fill - associate a fill chunk with a sparse file
 *
 * @s - sparse file cookie
 * @fill_val - 32 bit fill data
 * @len - length of the fill block
 * @block - offset in blocks into the sparse file to place the fill chunk
 *
 * Associates a chunk filled with fill_val with a sparse file cookie.
 * The region [block * block_size : block * block_size + len) must not already
 * be used in the sparse file. If len is not a multiple of the block size the
 * data will be padded with zeros.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_add_fill(struct sparse_file *s,
		uint32_t fill_val, unsigned int len, unsigned int block);

/**
 * sparse_file_add_file - associate a chunk of a file with a sparse file
 *
 * @s - sparse file cookie
 * @filename - filename of the file to be copied
 * @file_offset - offset into the copied file
 * @len - length of the copied block
 * @block - offset in blocks into the sparse file to place the file chunk
 *
 * Associates a chunk of an existing file with a sparse file cookie.
 * The region [block * block_size : block * block_size + len) must not already
 * be used in the sparse file. If len is not a multiple of the block size the
 * data will be padded with zeros.
 *
 * Allows adding large amounts of data to a sparse file without needing to keep
 * it all mapped.  File size is limited by available virtual address space,
 * exceptionally large files may need to be added in multiple chunks.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_add_file(struct sparse_file *s,
		const char *filename, int64_t file_offset, unsigned int len,
		unsigned int block);

/**
 * sparse_file_add_file - associate a chunk of a file with a sparse file
 *
 * @s - sparse file cookie
 * @filename - filename of the file to be copied
 * @file_offset - offset into the copied file
 * @len - length of the copied block
 * @block - offset in blocks into the sparse file to place the file chunk
 *
 * Associates a chunk of an existing fd with a sparse file cookie.
 * The region [block * block_size : block * block_size + len) must not already
 * be used in the sparse file. If len is not a multiple of the block size the
 * data will be padded with zeros.
 *
 * Allows adding large amounts of data to a sparse file without needing to keep
 * it all mapped.  File size is limited by available virtual address space,
 * exceptionally large files may need to be added in multiple chunks.
 *
 * The fd must remain open until the sparse file is closed or the fd block is
 * removed from the sparse file.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_add_fd(struct sparse_file *s,
		int fd, int64_t file_offset, unsigned int len, unsigned int block);

/**
 * sparse_file_write - write a sparse file to a file
 *
 * @s - sparse file cookie
 * @fd - file descriptor to write to
 * @gz - write a gzipped file
 * @sparse - write in the Android sparse file format
 * @crc - append a crc chunk
 *
 * Writes a sparse file to a file.  If gz is true, the data will be passed
 * through zlib.  If sparse is true, the file will be written in the Android
 * sparse file format.  If sparse is false, the file will be written by seeking
 * over unused chunks, producing a smaller file if the filesystem supports
 * sparse files.  If crc is true, the crc of the expanded data will be
 * calculated and appended in a crc chunk.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_write(struct sparse_file *s, int fd, bool gz, bool sparse,
		bool crc);

/**
 * sparse_file_len - return the length of a sparse file if written to disk
 *
 * @s - sparse file cookie
 * @sparse - write in the Android sparse file format
 * @crc - append a crc chunk
 *
 * Returns the size a sparse file would be on disk if it were written in the
 * specified format.  If sparse is true, this is the size of the data in the
 * sparse format.  If sparse is false, this is the size of the normal
 * non-sparse file.
 */
int64_t sparse_file_len(struct sparse_file *s, bool sparse, bool crc);

/**
 * sparse_file_block_size
 *
 * @s - sparse file cookie
 */
unsigned int sparse_file_block_size(struct sparse_file *s);

/**
 * sparse_file_callback - call a callback for blocks in sparse file
 *
 * @s - sparse file cookie
 * @sparse - write in the Android sparse file format
 * @crc - append a crc chunk
 * @write - function to call for each block
 * @priv - value that will be passed as the first argument to write
 *
 * Writes a sparse file by calling a callback function.  If sparse is true, the
 * file will be written in the Android sparse file format.  If crc is true, the
 * crc of the expanded data will be calculated and appended in a crc chunk.
 * The callback 'write' will be called with data and length for each data,
 * and with data==NULL to skip over a region (only used for non-sparse format).
 * The callback should return negative on error, 0 on success.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_callback(struct sparse_file *s, bool sparse, bool crc,
		int (*write)(void *priv, const void *data, size_t len), void *priv);

/**
 * sparse_file_foreach_chunk - call a callback for data blocks in sparse file
 *
 * @s - sparse file cookie
 * @sparse - write in the Android sparse file format
 * @crc - append a crc chunk
 * @write - function to call for each block
 * @priv - value that will be passed as the first argument to write
 *
 * The function has the same behavior as 'sparse_file_callback', except it only
 * iterates on blocks that contain data.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_foreach_chunk(struct sparse_file *s, bool sparse, bool crc,
	int (*write)(void *priv, const void *data, size_t len, unsigned int block,
		     unsigned int nr_blocks),
	void *priv);
/**
 * sparse_file_read - read a file into a sparse file cookie
 *
 * @s - sparse file cookie
 * @fd - file descriptor to read from
 * @sparse - read a file in the Android sparse file format
 * @crc - verify the crc of a file in the Android sparse file format
 *
 * Reads a file into a sparse file cookie.  If sparse is true, the file is
 * assumed to be in the Android sparse file format.  If sparse is false, the
 * file will be sparsed by looking for block aligned chunks of all zeros or
 * another 32 bit value.  If crc is true, the crc of the sparse file will be
 * verified.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_read(struct sparse_file *s, int fd, bool sparse, bool crc);

/**
 * sparse_file_read_buf - read a buffer into a sparse file cookie
 *
 * @s - sparse file cookie
 * @buf - buffer to read from
 * @crc - verify the crc of a file in the Android sparse file format
 *
 * Reads a buffer into a sparse file cookie. The buffer must remain
 * valid until the sparse file cookie is freed. If crc is true, the
 * crc of the sparse file will be verified.
 *
 * Returns 0 on success, negative errno on error.
 */
int sparse_file_read_buf(struct sparse_file *s, char *buf, bool crc);

/**
 * sparse_file_import - import an existing sparse file
 *
 * @fd - file descriptor to read from
 * @verbose - print verbose errors while reading the sparse file
 * @crc - verify the crc of a file in the Android sparse file format
 *
 * Reads an existing sparse file into a sparse file cookie, recreating the same
 * sparse cookie that was used to write it.  If verbose is true, prints verbose
 * errors when the sparse file is formatted incorrectly.
 *
 * Returns a new sparse file cookie on success, NULL on error.
 */
struct sparse_file *sparse_file_import(int fd, bool verbose, bool crc);

/**
 * sparse_file_import_buf - import an existing sparse file from a buffer
 *
 * @buf - buffer to read from
 * @verbose - print verbose errors while reading the sparse file
 * @crc - verify the crc of a file in the Android sparse file format
 *
 * Reads existing sparse file data into a sparse file cookie, recreating the same
 * sparse cookie that was used to write it.  If verbose is true, prints verbose
 * errors when the sparse file is formatted incorrectly.
 *
 * Returns a new sparse file cookie on success, NULL on error.
 */
struct sparse_file *sparse_file_import_buf(char* buf, bool verbose, bool crc);

/**
 * sparse_file_import_auto - import an existing sparse or normal file
 *
 * @fd - file descriptor to read from
 * @crc - verify the crc of a file in the Android sparse file format
 * @verbose - whether to use verbose logging
 *
 * Reads an existing sparse or normal file into a sparse file cookie.
 * Attempts to determine if the file is sparse or not by looking for the sparse
 * file magic number in the first 4 bytes.  If the file is not sparse, the file
 * will be sparsed by looking for block aligned chunks of all zeros or another
 * 32 bit value.  If crc is true, the crc of the sparse file will be verified.
 *
 * Returns a new sparse file cookie on success, NULL on error.
 */
struct sparse_file *sparse_file_import_auto(int fd, bool crc, bool verbose);

/** sparse_file_resparse - rechunk an existing sparse file into smaller files
 *
 * @in_s - sparse file cookie of the existing sparse file
 * @max_len - maximum file size
 * @out_s - array of sparse file cookies
 * @out_s_count - size of out_s array
 *
 * Splits chunks of an existing sparse file into smaller sparse files such that
 * each sparse file is less than max_len.  Returns the number of sparse_files
 * that would have been written to out_s if out_s were big enough.
 */
int sparse_file_resparse(struct sparse_file *in_s, unsigned int max_len,
		struct sparse_file **out_s, int out_s_count);

/**
 * sparse_file_verbose - set a sparse file cookie to print verbose errors
 *
 * @s - sparse file cookie
 *
 * Print verbose sparse file errors whenever using the sparse file cookie.
 */
void sparse_file_verbose(struct sparse_file *s);

/**
 * sparse_print_verbose - function called to print verbose errors
 *
 * By default, verbose errors will print to standard error.
 * sparse_print_verbose may be overridden to log verbose errors somewhere else.
 *
 */
extern void (*sparse_print_verbose)(const char *fmt, ...);

#ifdef	__cplusplus
}
#endif

#endif

```

`aosp/libsparse/sparse/src/main/public/sparse_file.h`:

```h
/*
 * Copyright (C) 2012 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef _LIBSPARSE_SPARSE_FILE_H_
#define _LIBSPARSE_SPARSE_FILE_H_

#ifdef __cplusplus
extern "C" {
#endif

#include <sparse/sparse.h>

struct sparse_file {
  unsigned int block_size;
  int64_t len;
  bool verbose;

  struct backed_block_list* backed_block_list;
  struct output_file* out;
};

#ifdef __cplusplus
}
#endif

#endif /* _LIBSPARSE_SPARSE_FILE_H_ */

```

`aosp/libxbc/COPYING`:

```

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

```

`aosp/libxbc/libxbc.c`:

```c
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "libxbc.h"

#define BOOTCONFIG_MAGIC "#BOOTCONFIG\n"
#define BOOTCONFIG_MAGIC_SIZE 12
#define BOOTCONFIG_SIZE_SIZE 4
#define BOOTCONFIG_CHECKSUM_SIZE 4
#define BOOTCONFIG_TRAILER_SIZE BOOTCONFIG_MAGIC_SIZE + \
                                BOOTCONFIG_SIZE_SIZE + \
                                BOOTCONFIG_CHECKSUM_SIZE
/*
 * Simple checksum for a buffer.
 *
 * @param addr pointer to the start of the buffer.
 * @param size size of the buffer in bytes.
 * @return check sum result.
 */
static uint32_t checksum(const unsigned char* const buffer, uint32_t size) {
    uint32_t sum = 0;
    for (uint32_t i = 0; i < size; i++) {
        sum += buffer[i];
    }
    return sum;
}

/*
 * Check if the bootconfig trailer is present within the bootconfig section.
 *
 * @param bootconfig_end_addr address of the end of the bootconfig section. If
 *        the trailer is present, it will be directly preceding this address.
 * @return true if the trailer is present, false if not.
 */
static bool isTrailerPresent(uint64_t bootconfig_end_addr) {
    return !strncmp((char*)(bootconfig_end_addr - BOOTCONFIG_MAGIC_SIZE),
                    BOOTCONFIG_MAGIC, BOOTCONFIG_MAGIC_SIZE);
}

/*
 * Add a string of boot config parameters to memory appended by the trailer.
 */
int32_t addBootConfigParameters(const char* params, uint32_t params_size,
    uint64_t bootconfig_start_addr, uint32_t bootconfig_size) {
    if (!params || !bootconfig_start_addr) {
        return -1;
    }
    if (params_size == 0) {
        return 0;
    }
    int32_t applied_bytes = 0;
    int32_t new_size = 0;
    uint64_t end = bootconfig_start_addr + bootconfig_size;

    if (isTrailerPresent(end)) {
      end -= BOOTCONFIG_TRAILER_SIZE;
      applied_bytes -= BOOTCONFIG_TRAILER_SIZE;
      memcpy(&new_size, (void *)end, BOOTCONFIG_SIZE_SIZE);
    } else {
      new_size = bootconfig_size;
    }

    // params
    memcpy((void*)end, params, params_size);

    applied_bytes += params_size;
    applied_bytes += addBootConfigTrailer(bootconfig_start_addr,
        bootconfig_size + applied_bytes);

    return applied_bytes;
}

/*
 * Add boot config trailer.
 */
int32_t addBootConfigTrailer(uint64_t bootconfig_start_addr,
                            uint32_t bootconfig_size) {
    if (!bootconfig_start_addr) {
        return -1;
    }
    if (bootconfig_size == 0) {
        return 0;
    }
    uint64_t end = bootconfig_start_addr + bootconfig_size;

    if (isTrailerPresent(end)) {
        // no need to overwrite the current trailers
        return 0;
    }

    // size
    memcpy((void *)(end), &bootconfig_size, BOOTCONFIG_SIZE_SIZE);

    // checksum
    uint32_t sum =
        checksum((unsigned char*)bootconfig_start_addr, bootconfig_size);
    memcpy((void *)(end + BOOTCONFIG_SIZE_SIZE), &sum,
        BOOTCONFIG_CHECKSUM_SIZE);

    // magic
    memcpy((void *)(end + BOOTCONFIG_SIZE_SIZE + BOOTCONFIG_CHECKSUM_SIZE),
           BOOTCONFIG_MAGIC, BOOTCONFIG_MAGIC_SIZE);

    return BOOTCONFIG_TRAILER_SIZE;
}

```

`aosp/libxbc/libxbc.h`:

```h
/*
 * Copyright (C) 2021 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef LIBXBC_H_
#define LIBXBC_H_

#include <stdint.h>
#include <string.h>
#include <stdbool.h>

#ifdef __cplusplus
extern "C" {
#endif

// memcpy and strncmp
//#include <common.h>

/*
 * Add a string of boot config parameters to memory appended by the trailer.
 * This memory needs to be immediately following the end of the ramdisks.
 * The new boot config trailer will be written to the end of the entire
 * parameter section(previous + new). The trailer contains a 4 byte size of the
 * parameters, followed by a 4 byte checksum of the parameters, followed by a 12
 * byte magic string.
 *
 * @param params pointer to string of boot config parameters
 * @param params_size size of params string in bytes
 * @param bootconfig_start_addr address that the boot config section is starting
 *        at in memory.
 * @param bootconfig_size size of the current bootconfig section in bytes.
 * @return number of bytes added to the boot config section. -1 for error.
 */
int addBootConfigParameters(const char *params, uint32_t params_size,
                            uint64_t bootconfig_start_addr,
                            uint32_t bootconfig_size);

/*
 * Add the boot config trailer to the end of the boot config parameter section.
 * This can be used after the vendor bootconfig section has been placed into
 * memory if there are no additional parameters that need to be added.
 * The new boot config trailer will be written to the end of the entire
 * parameter section at (bootconfig_start_addr + bootconfig_size).
 * The trailer contains a 4 byte size of the parameters, followed by a 4 byte
 * checksum of the parameters, followed by a 12 byte magic string.
 *
 * @param bootconfig_start_addr address that the boot config section is starting
 *        at in memory.
 * @param bootconfig_size size of the current bootconfig section in bytes.
 * @return number of bytes added to the boot config section. -1 for error.
 */
int addBootConfigTrailer(uint64_t bootconfig_start_addr,
                         uint32_t bootconfig_size);
#ifdef __cplusplus
}
#endif

#endif /* LIBXBC_H_ */

```

`aosp/libxbc/main.cpp`:

```cpp
#include <fcntl.h>
#include <libxbc.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <string>

static_assert(sizeof(uint64_t) == 8, "uint64_t 8 bytes");
static_assert(sizeof(void*) == 8, "void* 8 bytes");

void dumpBuf(void* buf, size_t bufSize, const char* outFile) {
    int flags = O_WRONLY | O_CREAT | O_TRUNC | O_CLOEXEC;
    printf("dumping buffer to %s...\n", outFile);
    auto fd = open(outFile, flags, 0644);
    if (fd == -1) {
        printf("fail to open file %s(%s)\n", outFile, strerror(errno));
        exit(1);
    }
    size_t bytesWrite = write(fd, (char*)buf, bufSize);
    if (bytesWrite != bufSize) {
        printf("write failed. exp=%zu, act=%ld\n", bufSize, bytesWrite);
        exit(2);
    }
    close(fd);
}

int main(int, char**) {
    size_t bufSize = 256;
    uint64_t buf = reinterpret_cast<uint64_t>(malloc(bufSize));
    uint32_t bootConfigSize = 0;
    if (!buf) {
        printf("malloc failed\n");
        exit(1);
    }

    {  // param1
        char* ANDROID_BOOT_PARAM = (char*)"androidboot.xx=yy\n";
        auto ret = addBootConfigParameters(ANDROID_BOOT_PARAM, strlen(ANDROID_BOOT_PARAM), buf,
                                           bootConfigSize);
        if (ret <= 0) {
            printf("fail to apply boot config params\n");
            exit(1);
        } else {
            printf("addBootConfigParameters() ret = %d\n", ret);
            bootConfigSize += ret;
        }
        dumpBuf((void*)buf, bufSize, "tmp.1");
    }

    {  // param2
        char* param2 = (char*)"k1=v1\nk2=v2\nk3=v3\n";
        auto ret = addBootConfigParameters(param2, strlen(param2), buf, bootConfigSize);
        if (ret <= 0) {
            printf("fail to apply boot config param2\n");
            exit(1);
        } else {
            printf("addBootConfigParameters() ret = %d\n", ret);
            bootConfigSize += ret;
        }
        dumpBuf((void*)buf, bufSize, "tmp.2");
    }

    {  // param3
        char* param3 =
                (char*)"vendorboot_k1=vendorboot_v1\nvendorboot_k2=vendorboot_v2\nvendorboot_k3="
                       "vendorboot_v3\n";
        auto ret = addBootConfigParameters(param3, strlen(param3), buf, bootConfigSize);
        if (ret <= 0) {
            printf("fail to apply boot config param3\n");
            exit(1);
        } else {
            printf("addBootConfigParameters() ret = %d\n", ret);
            bootConfigSize += ret;
        }
        dumpBuf((void*)buf, bufSize, "tmp.3");
        dumpBuf((void*)buf, bootConfigSize, "tmp.final");
    }

    free((void*)buf);
    return 0;
}

```

`aosp/libxbc/meson.build`:

```build
project('libxbc', 'c', 'cpp',
  version : '0.1',
  default_options : ['warning_level=3'])

executable('xbc',
           'libxbc.c',
           'main.cpp',
           install : true)

```

`aosp/make/target/product/gsi/testkey_rsa2048.pem`:

```pem
-----BEGIN RSA PRIVATE KEY-----
MIIEpAIBAAKCAQEA3fDgwU4JKVRHhAfofi/g8daTNplB2mTJCX9fIMy9FnZDXNij
1zijRQ8HKbt3bAGImQvb3GxSV4M5eIdiLDUF7RsUpE7K+s939i/AaTtcuyqimQbJ
QjP9emTsgngHzuKWMg1mwlRZYDfdv62zIQmZcbM9a0CZE36hAYvEBiDB8qT4ob++
godGAx3rpF2Wi7mhIYDINvkCw8/16Qi9CZgvOUrEolt3mz8Sps41z9j7YAsPbAa8
fg7dUu61s6NkZEykl4G67loOaf7h+SyP//LpFZ0gV+STZ+EMGofL0SXb8A+hdIYE
QxsnKUYo8e+GaQg92FLxVZqcfyG3AZuMB04R1QIDAQABAoIBAQDGj3/1UaSepjlJ
ZW3an2lH1Cpm2ZxyEGNQLPVluead1vaTdXq3zYM9AKHu8zp3lbOpAVQVk4/jnZJo
Q+9QD6waonTIP3oYBE+WIMirHSHsjctkzw52PV9VBkAWxd5ueIfZheXejGpdy/2H
RJcTQqxWbf7QGr4ZE9xmLq4UsW/zbXwy8qGEp9eMQIIaWBua43FkqmWYLSnVFVJI
Gl8mfVJctLNSZHhS3tKiV8up6NxZlDjO8o7kYVFCkv0xJ9yzQNBc3P2MEmvfZ06D
QnimHBqSxr0M9X6hqP43CnqtCbpsHS8A12Dm4l6fkXfkrAY0UNrEaCSDb8aN7TEc
7bc1MB4NAoGBAPK7xSuvQE9CH05Iy+G6mEQTtNmpfcQosqhi6dF60h4bqlkeGzUu
gF/PKHwwffHAxQSv4V831P3A/IoJFa9IFkg218mYPNfzpj4vJA4aNCDp+SYZAIYm
h6hMOmuByI97wds2yCBGt4mP0eow5B3A1b3UQeqW6LVSuobZ22QVlSk/AoGBAOoS
L82yda9hUa7vuXtqTraf9EGjSXhyjoPqWxa+a1ooI9l24f7mokS5Iof+a/SLfPUj
pwj8eOeOZksjAaWJIdrRb3TaYLaqhDkWQeV5N5XxYbn3+TvVJQyR+OSBfGoEpVP/
IS6fusvpT3eULJDax10By+gDcoLT5M1FNs4rBIvrAoGBAM8yJP5DHDwLjzl9vjsy
0iLaR3e8zBQTQV2nATvFAXKd3u0vW74rsX0XEdHgesFP8V0s3M4wlGj+wRL66j2y
5QJDfjMg9l7IJlHSX46CI5ks33X7xYy9evLYDs4R/Kct1q5OtsmGU8jisSadETus
jUb61kFvC7krovjVIgbuvWJ1AoGAVikzp4gVgeVU6AwePqu3JcpjYvX0SX4Br9VI
imq1oY49BAOa1PWYratoZp7kpjPiX2osRkaJStNEHExagtCjwaRuXpk0GIlT+p+S
yiGAsJUV4BrDh57B8IqbD6IKZgwnv2+ei0cIv562PdIxRXEDCd1rbZA3SqktA9KC
hgmXttkCgYBPU1lqRpwoHP9lpOBTDa6/Xi6WaDEWrG/tUF/wMlvrZ4hEVMDJRs1d
9JCXBxL/O4TMvpmyVKBZW15iZOcLM3EpiZ00UD+ChcAaFstup+oYKrs8gL9hgyTd
cvWMxGQm13KwSj2CLzEQpPAN5xG14njXaee5ksshxkzBz9z3MVWiiw==
-----END RSA PRIVATE KEY-----

```

`aosp/make/tools/extract_kernel.py`:

```py
#!/usr/bin/env python
#
# Copyright (C) 2018 The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
A tool to extract kernel information from a kernel image.
"""

import argparse
import subprocess
import sys
import re

CONFIG_PREFIX = b'IKCFG_ST'
GZIP_HEADER = b'\037\213\010'
COMPRESSION_ALGO = (
    (["gzip", "-d"], GZIP_HEADER),
    (["xz", "-d"], b'\3757zXZ\000'),
    (["bzip2", "-d"], b'BZh'),
    (["lz4", "-d", "-l"], b'\002\041\114\030'),

    # These are not supported in the build system yet.
    # (["unlzma"], b'\135\0\0\0'),
    # (["lzop", "-d"], b'\211\114\132'),
)

# "Linux version " UTS_RELEASE " (" LINUX_COMPILE_BY "@"
# LINUX_COMPILE_HOST ") (" LINUX_COMPILER ") " UTS_VERSION "\n";
LINUX_BANNER_PREFIX = b'Linux version '
LINUX_BANNER_REGEX = LINUX_BANNER_PREFIX.decode() + \
    r'(?P<release>(?P<version>[0-9]+[.][0-9]+[.][0-9]+).*) \(.*@.*\) \((?P<compiler>.*)\) .*\n'


def get_from_release(input_bytes, start_idx, key):
  null_idx = input_bytes.find(b'\x00', start_idx)
  if null_idx < 0:
    return None
  try:
    linux_banner = input_bytes[start_idx:null_idx].decode()
  except UnicodeDecodeError:
    return None
  mo = re.match(LINUX_BANNER_REGEX, linux_banner)
  if mo:
    return mo.group(key)
  return None


def dump_from_release(input_bytes, key):
  """
  Helper of dump_version and dump_release
  """
  idx = 0
  while True:
    idx = input_bytes.find(LINUX_BANNER_PREFIX, idx)
    if idx < 0:
      return None

    value = get_from_release(input_bytes, idx, key)
    if value:
      return value.encode()

    idx += len(LINUX_BANNER_PREFIX)


def dump_version(input_bytes):
  """
  Dump kernel version, w.x.y, from input_bytes. Search for the string
  "Linux version " and do pattern matching after it. See LINUX_BANNER_REGEX.
  """
  return dump_from_release(input_bytes, "version")


def dump_compiler(input_bytes):
  """
  Dump kernel version, w.x.y, from input_bytes. Search for the string
  "Linux version " and do pattern matching after it. See LINUX_BANNER_REGEX.
  """
  return dump_from_release(input_bytes, "compiler")


def dump_release(input_bytes):
  """
  Dump kernel release, w.x.y-..., from input_bytes. Search for the string
  "Linux version " and do pattern matching after it. See LINUX_BANNER_REGEX.
  """
  return dump_from_release(input_bytes, "release")


def dump_configs(input_bytes):
  """
  Dump kernel configuration from input_bytes. This can be done when
  CONFIG_IKCONFIG is enabled, which is a requirement on Treble devices.

  The kernel configuration is archived in GZip format right after the magic
  string 'IKCFG_ST' in the built kernel.
  """

  # Search for magic string + GZip header
  idx = input_bytes.find(CONFIG_PREFIX + GZIP_HEADER)
  if idx < 0:
    return None

  # Seek to the start of the archive
  idx += len(CONFIG_PREFIX)

  sp = subprocess.Popen(["gzip", "-d", "-c"], stdin=subprocess.PIPE,
                        stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  o, _ = sp.communicate(input=input_bytes[idx:])
  if sp.returncode == 1: # error
    return None

  # success or trailing garbage warning
  assert sp.returncode in (0, 2), sp.returncode

  return o


def try_decompress_bytes(cmd, input_bytes):
  sp = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE)
  o, _ = sp.communicate(input=input_bytes)
  # ignore errors
  return o


def try_decompress(cmd, search_bytes, input_bytes):
  idx = 0
  while True:
    idx = input_bytes.find(search_bytes, idx)
    if idx < 0:
      return

    yield try_decompress_bytes(cmd, input_bytes[idx:])
    idx += 1


def decompress_dump(func, input_bytes):
  """
  Run func(input_bytes) first; and if that fails (returns value evaluates to
  False), then try different decompression algorithm before running func.
  """
  o = func(input_bytes)
  if o:
    return o
  for cmd, search_bytes in COMPRESSION_ALGO:
    for decompressed in try_decompress(cmd, search_bytes, input_bytes):
      if decompressed:
        o = decompress_dump(func, decompressed)
        if o:
          return o
    # Force decompress the whole file even if header doesn't match
    decompressed = try_decompress_bytes(cmd, input_bytes)
    if decompressed:
      o = decompress_dump(func, decompressed)
      if o:
        return o


def dump_to_file(f, dump_fn, input_bytes, desc):
  """
  Call decompress_dump(dump_fn, input_bytes) and write to f. If it fails, return
  False; otherwise return True.
  """
  if f is not None:
    o = decompress_dump(dump_fn, input_bytes)
    if o:
      f.write(o)
    else:
      sys.stderr.write(
          "Cannot extract kernel {}".format(desc))
      return False
  return True

def to_bytes_io(b):
  """
  Make b, which is either sys.stdout or sys.stdin, receive bytes as arguments.
  """
  return b.buffer if sys.version_info.major == 3 else b

def main():
  parser = argparse.ArgumentParser(
      formatter_class=argparse.RawTextHelpFormatter,
      description=__doc__ +
      "\nThese algorithms are tried when decompressing the image:\n    " +
      " ".join(tup[0][0] for tup in COMPRESSION_ALGO))
  parser.add_argument('--input',
                      help='Input kernel image. If not specified, use stdin',
                      metavar='FILE',
                      type=argparse.FileType('rb'),
                      default=to_bytes_io(sys.stdin))
  parser.add_argument('--output-configs',
                      help='If specified, write configs. Use stdout if no file '
                           'is specified.',
                      metavar='FILE',
                      nargs='?',
                      type=argparse.FileType('wb'),
                      const=to_bytes_io(sys.stdout))
  parser.add_argument('--output-version',
                      help='If specified, write version. Use stdout if no file '
                           'is specified.',
                      metavar='FILE',
                      nargs='?',
                      type=argparse.FileType('wb'),
                      const=to_bytes_io(sys.stdout))
  parser.add_argument('--output-release',
                      help='If specified, write kernel release. Use stdout if '
                           'no file is specified.',
                      metavar='FILE',
                      nargs='?',
                      type=argparse.FileType('wb'),
                      const=to_bytes_io(sys.stdout))
  parser.add_argument('--output-compiler',
                      help='If specified, write the compiler information. Use stdout if no file '
                           'is specified.',
                      metavar='FILE',
                      nargs='?',
                      type=argparse.FileType('wb'),
                      const=to_bytes_io(sys.stdout))
  parser.add_argument('--tools',
                      help='Decompression tools to use. If not specified, PATH '
                           'is searched.',
                      metavar='ALGORITHM:EXECUTABLE',
                      nargs='*')
  args = parser.parse_args()

  tools = {pair[0]: pair[1]
           for pair in (token.split(':') for token in args.tools or [])}
  for cmd, _ in COMPRESSION_ALGO:
    if cmd[0] in tools:
      cmd[0] = tools[cmd[0]]

  input_bytes = args.input.read()

  ret = 0
  if not dump_to_file(args.output_configs, dump_configs, input_bytes,
                      "configs in {}".format(args.input.name)):
    ret = 1
  if not dump_to_file(args.output_version, dump_version, input_bytes,
                      "version in {}".format(args.input.name)):
    ret = 1
  if not dump_to_file(args.output_release, dump_release, input_bytes,
                      "kernel release in {}".format(args.input.name)):
    ret = 1

  if not dump_to_file(args.output_compiler, dump_compiler, input_bytes,
                      "kernel compiler in {}".format(args.input.name)):
    ret = 1

  return ret


if __name__ == '__main__':
  sys.exit(main())

```

`aosp/mkbootfs.10/build.gradle`:

```gradle
apply plugin: 'cpp'
apply plugin: 'c'

model {
    buildTypes {
        release
    }

    components {
        mkbootfs(NativeExecutableSpec) {
            binaries.all {
                cppCompiler.define "__ANDROID_VNDK__"
                //cppCompiler.define 'CFIG_NO_FIX_STAT'
                cppCompiler.args << "-Wno-write-strings"
            }
        }
    }
}

```

`aosp/mkbootfs.10/src/mkbootfs/cpp/fs_config.cpp`:

```cpp
/*
 * Copyright (C) 2007 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <private/fs_config.h>

// This file is used to define the properties of the filesystem
// images generated by build tools (mkbootfs and mkyaffs2image) and
// by the device side of adb.

#define LOG_TAG "fs_config"

#include <errno.h>
#include <fcntl.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>

#include <log/log.h>
#include <private/android_filesystem_config.h>
#include <utils/Compat.h>

#ifndef O_BINARY
#define O_BINARY 0
#endif

// My kingdom for <endian.h>
static inline uint16_t get2LE(const uint8_t* src) {
    return src[0] | (src[1] << 8);
}

static inline uint64_t get8LE(const uint8_t* src) {
    uint32_t low, high;

    low = src[0] | (src[1] << 8) | (src[2] << 16) | (src[3] << 24);
    high = src[4] | (src[5] << 8) | (src[6] << 16) | (src[7] << 24);
    return ((uint64_t)high << 32) | (uint64_t)low;
}

#define ALIGN(x, alignment) (((x) + ((alignment)-1)) & ~((alignment)-1))

// Rules for directories.
// These rules are applied based on "first match", so they
// should start with the most specific path and work their
// way up to the root.

static const struct fs_path_config android_dirs[] = {
    // clang-format off
    { 00770, AID_SYSTEM,       AID_CACHE,        0, "cache" },
    { 00500, AID_ROOT,         AID_ROOT,         0, "config" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/app" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/app-private" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/app-ephemeral" },
    { 00771, AID_ROOT,         AID_ROOT,         0, "data/dalvik-cache" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/data" },
    { 00771, AID_SHELL,        AID_SHELL,        0, "data/local/tmp" },
    { 00771, AID_SHELL,        AID_SHELL,        0, "data/local" },
    { 00770, AID_DHCP,         AID_DHCP,         0, "data/misc/dhcp" },
    { 00771, AID_SHARED_RELRO, AID_SHARED_RELRO, 0, "data/misc/shared_relro" },
    { 01771, AID_SYSTEM,       AID_MISC,         0, "data/misc" },
    { 00775, AID_MEDIA_RW,     AID_MEDIA_RW,     0, "data/media/Music" },
    { 00775, AID_MEDIA_RW,     AID_MEDIA_RW,     0, "data/media" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "data/nativetest" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "data/nativetest64" },
    { 00775, AID_ROOT,         AID_ROOT,         0, "data/preloads" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data" },
    { 00755, AID_ROOT,         AID_SYSTEM,       0, "mnt" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "sbin" },
    { 00777, AID_ROOT,         AID_ROOT,         0, "sdcard" },
    { 00751, AID_ROOT,         AID_SDCARD_R,     0, "storage" },
    { 00755, AID_ROOT,         AID_SHELL,        0, "system/bin" },
    { 00755, AID_ROOT,         AID_ROOT,         0, "system/etc/ppp" },
    { 00755, AID_ROOT,         AID_SHELL,        0, "system/vendor" },
    { 00755, AID_ROOT,         AID_SHELL,        0, "system/xbin" },
    { 00755, AID_ROOT,         AID_SHELL,        0, "vendor" },
    { 00755, AID_ROOT,         AID_ROOT,         0, 0 },
    // clang-format on
};
#ifndef __ANDROID_VNDK__
auto __for_testing_only__android_dirs = android_dirs;
#endif

// Rules for files.
// These rules are applied based on "first match", so they
// should start with the most specific path and work their
// way up to the root. Prefixes ending in * denotes wildcard
// and will allow partial matches.
static const char sys_conf_dir[] = "/system/etc/fs_config_dirs";
static const char sys_conf_file[] = "/system/etc/fs_config_files";
// No restrictions are placed on the vendor and oem file-system config files,
// although the developer is advised to restrict the scope to the /vendor or
// oem/ file-system since the intent is to provide support for customized
// portions of a separate vendor.img or oem.img.  Has to remain open so that
// customization can also land on /system/vendor, /system/oem or /system/odm.
// We expect build-time checking or filtering when constructing the associated
// fs_config_* files (see build/tools/fs_config/fs_config_generate.c)
static const char ven_conf_dir[] = "/vendor/etc/fs_config_dirs";
static const char ven_conf_file[] = "/vendor/etc/fs_config_files";
static const char oem_conf_dir[] = "/oem/etc/fs_config_dirs";
static const char oem_conf_file[] = "/oem/etc/fs_config_files";
static const char odm_conf_dir[] = "/odm/etc/fs_config_dirs";
static const char odm_conf_file[] = "/odm/etc/fs_config_files";
static const char* conf[][2] = {
    {sys_conf_file, sys_conf_dir},
    {ven_conf_file, ven_conf_dir},
    {oem_conf_file, oem_conf_dir},
    {odm_conf_file, odm_conf_dir},
};

// Do not use android_files to grant Linux capabilities.  Use ambient capabilities in their
// associated init.rc file instead.  See https://source.android.com/devices/tech/config/ambient.

// Do not place any new vendor/, data/vendor/, etc entries in android_files.
// Vendor entries should be done via a vendor or device specific config.fs.
// See https://source.android.com/devices/tech/config/filesystem#using-file-system-capabilities
static const struct fs_path_config android_files[] = {
    // clang-format off
    { 00644, AID_SYSTEM,    AID_SYSTEM,    0, "data/app/*" },
    { 00644, AID_SYSTEM,    AID_SYSTEM,    0, "data/app-ephemeral/*" },
    { 00644, AID_SYSTEM,    AID_SYSTEM,    0, "data/app-private/*" },
    { 00644, AID_APP,       AID_APP,       0, "data/data/*" },
    { 00644, AID_MEDIA_RW,  AID_MEDIA_RW,  0, "data/media/*" },
    { 00640, AID_ROOT,      AID_SHELL,     0, "data/nativetest/tests.txt" },
    { 00640, AID_ROOT,      AID_SHELL,     0, "data/nativetest64/tests.txt" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "data/nativetest/*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "data/nativetest64/*" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "default.prop" }, // legacy
    { 00600, AID_ROOT,      AID_ROOT,      0, "system/etc/prop.default" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "odm/build.prop" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "odm/default.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, odm_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, odm_conf_file + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, oem_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, oem_conf_file + 1 },
    { 00600, AID_ROOT,      AID_ROOT,      0, "product/build.prop" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "sbin/fs_mgr" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/crash_dump32" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/crash_dump64" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/debuggerd" },
    { 00750, AID_ROOT,      AID_ROOT,      0, "system/bin/install-recovery.sh" },
    { 00700, AID_ROOT,      AID_ROOT,      0, "system/bin/secilc" },
    { 00750, AID_ROOT,      AID_ROOT,      0, "system/bin/uncrypt" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "system/build.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, sys_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, sys_conf_file + 1 },
    { 00440, AID_ROOT,      AID_SHELL,     0, "system/etc/init.goldfish.rc" },
    { 00550, AID_ROOT,      AID_SHELL,     0, "system/etc/init.goldfish.sh" },
    { 00550, AID_ROOT,      AID_SHELL,     0, "system/etc/init.ril" },
    { 00555, AID_ROOT,      AID_ROOT,      0, "system/etc/ppp/*" },
    { 00555, AID_ROOT,      AID_ROOT,      0, "system/etc/rc.*" },
    { 00440, AID_ROOT,      AID_ROOT,      0, "system/etc/recovery.img" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "vendor/build.prop" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "vendor/default.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, ven_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, ven_conf_file + 1 },

    // the following two files are INTENTIONALLY set-uid, but they
    // are NOT included on user builds.
    { 06755, AID_ROOT,      AID_ROOT,      0, "system/xbin/procmem" },
    { 04750, AID_ROOT,      AID_SHELL,     0, "system/xbin/su" },

    // the following files have enhanced capabilities and ARE included
    // in user builds.
    { 00700, AID_SYSTEM,    AID_SHELL,     CAP_MASK_LONG(CAP_BLOCK_SUSPEND),
                                              "system/bin/inputflinger" },
    { 00550, AID_LOGD,      AID_LOGD,      CAP_MASK_LONG(CAP_SYSLOG) |
                                           CAP_MASK_LONG(CAP_AUDIT_CONTROL) |
                                           CAP_MASK_LONG(CAP_SETGID),
                                              "system/bin/logd" },
    { 00550, AID_SYSTEM,    AID_LOG,      CAP_MASK_LONG(CAP_SYSLOG),
                                              "system/bin/bootstat" },
    { 00750, AID_ROOT,      AID_SHELL,     CAP_MASK_LONG(CAP_SETUID) |
                                           CAP_MASK_LONG(CAP_SETGID),
                                              "system/bin/run-as" },

    // Support FIFO scheduling mode in SurfaceFlinger.
    { 00755, AID_SYSTEM,    AID_GRAPHICS,  CAP_MASK_LONG(CAP_SYS_NICE),
                                              "system/bin/surfaceflinger" },
    // generic defaults
    { 00755, AID_ROOT,      AID_ROOT,      0, "bin/*" },
    { 00640, AID_ROOT,      AID_SHELL,     0, "fstab.*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "init*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "sbin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/*" },
    { 00755, AID_ROOT,      AID_ROOT,      0, "system/lib/valgrind/*" },
    { 00755, AID_ROOT,      AID_ROOT,      0, "system/lib64/valgrind/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/xbin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "vendor/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "vendor/xbin/*" },
    { 00644, AID_ROOT,      AID_ROOT,      0, 0 },
    // clang-format on
};
#ifndef __ANDROID_VNDK__
auto __for_testing_only__android_files = android_files;
#endif

static size_t strip(const char* path, size_t len, const char suffix[]) {
    if (len < strlen(suffix)) return len;
    if (strncmp(path + len - strlen(suffix), suffix, strlen(suffix))) return len;
    return len - strlen(suffix);
}

static int fs_config_open(int dir, int which, const char* target_out_path) {
    int fd = -1;

    if (target_out_path && *target_out_path) {
        // target_out_path is the path to the directory holding content of
        // system partition but as we cannot guarantee it ends with '/system'
        // or with or without a trailing slash, need to strip them carefully.
        char* name = NULL;
        size_t len = strlen(target_out_path);
        len = strip(target_out_path, len, "/");
        len = strip(target_out_path, len, "/system");
        if (asprintf(&name, "%.*s%s", (int)len, target_out_path, conf[which][dir]) != -1) {
            fd = TEMP_FAILURE_RETRY(open(name, O_RDONLY | O_BINARY));
            free(name);
        }
    }
    if (fd < 0) {
        fd = TEMP_FAILURE_RETRY(open(conf[which][dir], O_RDONLY | O_BINARY));
    }
    return fd;
}

// if path is "vendor/<stuff>", "oem/<stuff>" or "odm/<stuff>"
static bool is_partition(const char* path, size_t len) {
    static const char* partitions[] = {"vendor/", "oem/", "odm/"};
    for (size_t i = 0; i < (sizeof(partitions) / sizeof(partitions[0])); ++i) {
        size_t plen = strlen(partitions[i]);
        if (len <= plen) continue;
        if (!strncmp(path, partitions[i], plen)) return true;
    }
    return false;
}

static inline bool prefix_cmp(bool partial, const char* prefix, size_t len, const char* path,
                              size_t plen) {
    return ((partial && plen >= len) || (plen == len)) && !strncmp(prefix, path, len);
}

// alias prefixes of "<partition>/<stuff>" to "system/<partition>/<stuff>" or
// "system/<partition>/<stuff>" to "<partition>/<stuff>"
static bool fs_config_cmp(bool partial, const char* prefix, size_t len, const char* path,
                          size_t plen) {
    // If name ends in * then allow partial matches.
    if (!partial && prefix[len - 1] == '*') {
        len--;
        partial = true;
    }

    if (prefix_cmp(partial, prefix, len, path, plen)) return true;

    static const char system[] = "system/";
    if (!strncmp(path, system, strlen(system))) {
        path += strlen(system);
        plen -= strlen(system);
    } else if (len <= strlen(system)) {
        return false;
    } else if (strncmp(prefix, system, strlen(system))) {
        return false;
    } else {
        prefix += strlen(system);
        len -= strlen(system);
    }
    return is_partition(prefix, len) && prefix_cmp(partial, prefix, len, path, plen);
}
#ifndef __ANDROID_VNDK__
auto __for_testing_only__fs_config_cmp = fs_config_cmp;
#endif

void fs_config(const char* path, int dir, const char* target_out_path, unsigned* uid, unsigned* gid,
               unsigned* mode, uint64_t* capabilities) {
    const struct fs_path_config* pc;
    size_t which, plen;

    if (path[0] == '/') {
        path++;
    }

    plen = strlen(path);

    for (which = 0; which < (sizeof(conf) / sizeof(conf[0])); ++which) {
        struct fs_path_config_from_file header;

        int fd = fs_config_open(dir, which, target_out_path);
        if (fd < 0) continue;

        while (TEMP_FAILURE_RETRY(read(fd, &header, sizeof(header))) == sizeof(header)) {
            char* prefix;
            uint16_t host_len = get2LE((const uint8_t*)&header.len);
            ssize_t len, remainder = host_len - sizeof(header);
            if (remainder <= 0) {
                ALOGE("%s len is corrupted", conf[which][dir]);
                break;
            }
            prefix = static_cast<char*>(calloc(1, remainder));
            if (!prefix) {
                ALOGE("%s out of memory", conf[which][dir]);
                break;
            }
            if (TEMP_FAILURE_RETRY(read(fd, prefix, remainder)) != remainder) {
                free(prefix);
                ALOGE("%s prefix is truncated", conf[which][dir]);
                break;
            }
            len = strnlen(prefix, remainder);
            if (len >= remainder) {  // missing a terminating null
                free(prefix);
                ALOGE("%s is corrupted", conf[which][dir]);
                break;
            }
            if (fs_config_cmp(dir, prefix, len, path, plen)) {
                free(prefix);
                close(fd);
                *uid = get2LE((const uint8_t*)&(header.uid));
                *gid = get2LE((const uint8_t*)&(header.gid));
                *mode = (*mode & (~07777)) | get2LE((const uint8_t*)&(header.mode));
                *capabilities = get8LE((const uint8_t*)&(header.capabilities));
                return;
            }
            free(prefix);
        }
        close(fd);
    }

    for (pc = dir ? android_dirs : android_files; pc->prefix; pc++) {
        if (fs_config_cmp(dir, pc->prefix, strlen(pc->prefix), path, plen)) {
            break;
        }
    }
    *uid = pc->uid;
    *gid = pc->gid;
    *mode = (*mode & (~07777)) | pc->mode;
    *capabilities = pc->capabilities;
}

ssize_t fs_config_generate(char* buffer, size_t length, const struct fs_path_config* pc) {
    struct fs_path_config_from_file* p = (struct fs_path_config_from_file*)buffer;
    size_t len = ALIGN(sizeof(*p) + strlen(pc->prefix) + 1, sizeof(uint64_t));

    if ((length < len) || (len > UINT16_MAX)) {
        return -ENOSPC;
    }
    memset(p, 0, len);
    uint16_t host_len = len;
    p->len = get2LE((const uint8_t*)&host_len);
    p->mode = get2LE((const uint8_t*)&(pc->mode));
    p->uid = get2LE((const uint8_t*)&(pc->uid));
    p->gid = get2LE((const uint8_t*)&(pc->gid));
    p->capabilities = get8LE((const uint8_t*)&(pc->capabilities));
    strcpy(p->prefix, pc->prefix);
    return len;
}

```

`aosp/mkbootfs.10/src/mkbootfs/cpp/mkbootfs.c`:

```c

#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <ctype.h>

#include <sys/types.h>
#include <sys/stat.h>
#include <dirent.h>

#include <stdarg.h>
#include <fcntl.h>

#include <private/android_filesystem_config.h>
//XXX
#include <cstdint>
#include <private/fs_config.h>
//XXX

/* NOTES
**
** - see buffer-format.txt from the linux kernel docs for
**   an explanation of this file format
** - dotfiles are ignored
** - directories named 'root' are ignored
** - device notes, pipes, etc are not supported (error)
*/

void die(const char *why, ...)
{
    va_list ap;

    va_start(ap, why);
    fprintf(stderr,"error: ");
    vfprintf(stderr, why, ap);
    fprintf(stderr,"\n");
    va_end(ap);
    exit(1);
}

struct fs_config_entry {
    char* name;
    int uid, gid, mode;
};

static struct fs_config_entry* canned_config = NULL;
static char *target_out_path = NULL;

/* Each line in the canned file should be a path plus three ints (uid,
 * gid, mode). */
#ifdef PATH_MAX
#define CANNED_LINE_LENGTH  (PATH_MAX+100)
#else
#define CANNED_LINE_LENGTH  (1024)
#endif

#define TRAILER "TRAILER!!!"

static int verbose = 0;
static int total_size = 0;

static void fix_stat(const char *path, struct stat *s)
{
    uint64_t capabilities;
    if (canned_config) {
        // Use the list of file uid/gid/modes loaded from the file
        // given with -f.

        struct fs_config_entry* empty_path_config = NULL;
        struct fs_config_entry* p;
        for (p = canned_config; p->name; ++p) {
            if (!p->name[0]) {
                empty_path_config = p;
            }
            if (strcmp(p->name, path) == 0) {
                s->st_uid = p->uid;
                s->st_gid = p->gid;
                s->st_mode = p->mode | (s->st_mode & ~07777);
                return;
            }
        }
        s->st_uid = empty_path_config->uid;
        s->st_gid = empty_path_config->gid;
        s->st_mode = empty_path_config->mode | (s->st_mode & ~07777);
    } else {
        // Use the compiled-in fs_config() function.
        unsigned st_mode = s->st_mode;
        int is_dir = S_ISDIR(s->st_mode) || strcmp(path, TRAILER) == 0;
        fs_config(path, is_dir, target_out_path, &s->st_uid, &s->st_gid, &st_mode, &capabilities);
        s->st_mode = (typeof(s->st_mode)) st_mode;
    }
}

static void _eject(struct stat *s, char *out, int olen, char *data, unsigned datasize)
{
    // Nothing is special about this value, just picked something in the
    // approximate range that was being used already, and avoiding small
    // values which may be special.
    static unsigned next_inode = 300000;

    while(total_size & 3) {
        total_size++;
        putchar(0);
    }

#ifdef CFIG_NO_FIX_STAT
#warning CFIG_NO_FIX_STAT defined, will not fix_stat() defined in Android
#else
    fix_stat(out, s);
#endif
//    fprintf(stderr, "_eject %s: mode=0%o\n", out, s->st_mode);

    printf("%06x%08x%08x%08x%08x%08x%08x"
           "%08x%08x%08x%08x%08x%08x%08x%s%c",
           0x070701,
           next_inode++,  //  s.st_ino,
           s->st_mode,
           0, // s.st_uid,
           0, // s.st_gid,
           1, // s.st_nlink,
           0, // s.st_mtime,
           datasize,
           0, // volmajor
           0, // volminor
           0, // devmajor
           0, // devminor,
           olen + 1,
           0,
           out,
           0
           );

    total_size += 6 + 8*13 + olen + 1;

    if(strlen(out) != (unsigned int)olen) die("ACK!");

    while(total_size & 3) {
        total_size++;
        putchar(0);
    }

    if(datasize) {
        fwrite(data, datasize, 1, stdout);
        total_size += datasize;
    }
}

static void _eject_trailer()
{
    struct stat s;
    memset(&s, 0, sizeof(s));
    _eject(&s, TRAILER, 10, 0, 0);

    while(total_size & 0xff) {
        total_size++;
        putchar(0);
    }
}

static void _archive(char *in, char *out, int ilen, int olen);

static int compare(const void* a, const void* b) {
  return strcmp(*(const char**)a, *(const char**)b);
}

static void _archive_dir(char *in, char *out, int ilen, int olen)
{
    int i, t;
    DIR *d;
    struct dirent *de;

    if(verbose) {
        fprintf(stderr,"_archive_dir('%s','%s',%d,%d)\n",
                in, out, ilen, olen);
    }

    d = opendir(in);
    if(d == 0) die("cannot open directory '%s'", in);

    int size = 32;
    int entries = 0;
    char** names = (char**) malloc(size * sizeof(char*));
    if (names == NULL) {
      fprintf(stderr, "failed to allocate dir names array (size %d)\n", size);
      exit(1);
    }

    while((de = readdir(d)) != 0){
            /* xxx: feature? maybe some dotfiles are okay */
        if(de->d_name[0] == '.') continue;

            /* xxx: hack. use a real exclude list */
        if(!strcmp(de->d_name, "root")) continue;

        if (entries >= size) {
          size *= 2;
          names = (char**) realloc(names, size * sizeof(char*));
          if (names == NULL) {
            fprintf(stderr, "failed to reallocate dir names array (size %d)\n",
                    size);
            exit(1);
          }
        }
        names[entries] = strdup(de->d_name);
        if (names[entries] == NULL) {
          fprintf(stderr, "failed to strdup name \"%s\"\n",
                  de->d_name);
          exit(1);
        }
        ++entries;
    }

    qsort(names, entries, sizeof(char*), compare);

    for (i = 0; i < entries; ++i) {
        t = strlen(names[i]);
        in[ilen] = '/';
        memcpy(in + ilen + 1, names[i], t + 1);

        if(olen > 0) {
            out[olen] = '/';
            memcpy(out + olen + 1, names[i], t + 1);
            _archive(in, out, ilen + t + 1, olen + t + 1);
        } else {
            memcpy(out, names[i], t + 1);
            _archive(in, out, ilen + t + 1, t);
        }

        in[ilen] = 0;
        out[olen] = 0;

        free(names[i]);
    }
    free(names);

    closedir(d);
}

static void _archive(char *in, char *out, int ilen, int olen)
{
    struct stat s;

    if(verbose) {
        fprintf(stderr,"_archive('%s','%s',%d,%d)\n",
                in, out, ilen, olen);
    }

    if(lstat(in, &s)) die("could not stat '%s'\n", in);

    if(S_ISREG(s.st_mode)){
        char *tmp;
        int fd;

        fd = open(in, O_RDONLY);
        if(fd < 0) die("cannot open '%s' for read", in);

        tmp = (char*) malloc(s.st_size);
        if(tmp == 0) die("cannot allocate %d bytes", s.st_size);

        if(read(fd, tmp, s.st_size) != s.st_size) {
            die("cannot read %d bytes", s.st_size);
        }

        _eject(&s, out, olen, tmp, s.st_size);

        free(tmp);
        close(fd);
    } else if(S_ISDIR(s.st_mode)) {
        _eject(&s, out, olen, 0, 0);
        _archive_dir(in, out, ilen, olen);
    } else if(S_ISLNK(s.st_mode)) {
        char buf[1024];
        int size;
        size = readlink(in, buf, 1024);
        if(size < 0) die("cannot read symlink '%s'", in);
        _eject(&s, out, olen, buf, size);
    } else {
        die("Unknown '%s' (mode %d)?\n", in, s.st_mode);
    }
}

void archive(const char *start, const char *prefix)
{
    char in[8192];
    char out[8192];

    strcpy(in, start);
    strcpy(out, prefix);

    _archive_dir(in, out, strlen(in), strlen(out));
}

static void read_canned_config(char* filename)
{
    int allocated = 8;
    int used = 0;

    canned_config =
        (struct fs_config_entry*)malloc(allocated * sizeof(struct fs_config_entry));

    char line[CANNED_LINE_LENGTH];
    FILE* f = fopen(filename, "r");
    if (f == NULL) die("failed to open canned file");

    while (fgets(line, CANNED_LINE_LENGTH, f) != NULL) {
        if (!line[0]) break;
        if (used >= allocated) {
            allocated *= 2;
            canned_config = (struct fs_config_entry*)realloc(
                canned_config, allocated * sizeof(struct fs_config_entry));
            if (canned_config == NULL) die("failed to reallocate memory");
        }

        struct fs_config_entry* cc = canned_config + used;

        if (isspace(line[0])) {
            cc->name = strdup("");
            cc->uid = atoi(strtok(line, " \n"));
        } else {
            cc->name = strdup(strtok(line, " \n"));
            cc->uid = atoi(strtok(NULL, " \n"));
        }
        cc->gid = atoi(strtok(NULL, " \n"));
        cc->mode = strtol(strtok(NULL, " \n"), NULL, 8);
        ++used;
    }
    if (used >= allocated) {
        ++allocated;
        canned_config = (struct fs_config_entry*)realloc(
            canned_config, allocated * sizeof(struct fs_config_entry));
        if (canned_config == NULL) die("failed to reallocate memory");
    }
    canned_config[used].name = NULL;

    fclose(f);
}


int main(int argc, char *argv[])
{
    argc--;
    argv++;

    if (argc > 1 && strcmp(argv[0], "-d") == 0) {
        target_out_path = argv[1];
        argc -= 2;
        argv += 2;
    }

    if (argc > 1 && strcmp(argv[0], "-f") == 0) {
        read_canned_config(argv[1]);
        argc -= 2;
        argv += 2;
    }

    if(argc == 0) die("no directories to process?!");

    while(argc-- > 0){
        char *x = strchr(*argv, '=');
        if(x != 0) {
            *x++ = 0;
        } else {
            x = "";
        }

        archive(*argv, x);

        argv++;
    }

    _eject_trailer();

    return 0;
}

```

`aosp/mkbootfs.10/src/mkbootfs/headers/log/log.h`:

```h
#ifndef _CFIG_LOG_H
#define _CFIG_LOG_H

#define ALOGE printf

#endif

```

`aosp/mkbootfs.10/src/mkbootfs/headers/private/android_filesystem_capability.h`:

```h
/*
 * Copyright (C) 2013 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * Taken from linux/capability.h, with minor modifications
 */

#ifndef _SYSTEM_CORE_INCLUDE_PRIVATE_ANDROID_FILESYSTEM_CAPABILITY_H
#define _SYSTEM_CORE_INCLUDE_PRIVATE_ANDROID_FILESYSTEM_CAPABILITY_H

#include <stdint.h>

#define __user
#define __u32 uint32_t
#define __le32 uint32_t

#define _LINUX_CAPABILITY_VERSION_1 0x19980330
#define _LINUX_CAPABILITY_U32S_1 1
#define _LINUX_CAPABILITY_VERSION_2 0x20071026
#define _LINUX_CAPABILITY_U32S_2 2
#define _LINUX_CAPABILITY_VERSION_3 0x20080522
#define _LINUX_CAPABILITY_U32S_3 2

typedef struct __user_cap_header_struct {
    __u32 version;
    int pid;
} __user* cap_user_header_t;

typedef struct __user_cap_data_struct {
    __u32 effective;
    __u32 permitted;
    __u32 inheritable;
} __user* cap_user_data_t;

#define VFS_CAP_REVISION_MASK 0xFF000000
#define VFS_CAP_REVISION_SHIFT 24
#define VFS_CAP_FLAGS_MASK ~VFS_CAP_REVISION_MASK
#define VFS_CAP_FLAGS_EFFECTIVE 0x000001
#define VFS_CAP_REVISION_1 0x01000000
#define VFS_CAP_U32_1 1
#define XATTR_CAPS_SZ_1 (sizeof(__le32) * (1 + 2 * VFS_CAP_U32_1))
#define VFS_CAP_REVISION_2 0x02000000
#define VFS_CAP_U32_2 2
#define XATTR_CAPS_SZ_2 (sizeof(__le32) * (1 + 2 * VFS_CAP_U32_2))
#define XATTR_CAPS_SZ XATTR_CAPS_SZ_2
#define VFS_CAP_U32 VFS_CAP_U32_2
#define VFS_CAP_REVISION VFS_CAP_REVISION_2

struct vfs_cap_data {
    __le32 magic_etc;
    struct {
        __le32 permitted;
        __le32 inheritable;
    } data[VFS_CAP_U32];
};

#define _LINUX_CAPABILITY_VERSION _LINUX_CAPABILITY_VERSION_1
#define _LINUX_CAPABILITY_U32S _LINUX_CAPABILITY_U32S_1
#define CAP_CHOWN 0
#define CAP_DAC_OVERRIDE 1
#define CAP_DAC_READ_SEARCH 2
#define CAP_FOWNER 3
#define CAP_FSETID 4
#define CAP_KILL 5
#define CAP_SETGID 6
#define CAP_SETUID 7
#define CAP_SETPCAP 8
#define CAP_LINUX_IMMUTABLE 9
#define CAP_NET_BIND_SERVICE 10
#define CAP_NET_BROADCAST 11
#define CAP_NET_ADMIN 12
#define CAP_NET_RAW 13
#define CAP_IPC_LOCK 14
#define CAP_IPC_OWNER 15
#define CAP_SYS_MODULE 16
#define CAP_SYS_RAWIO 17
#define CAP_SYS_CHROOT 18
#define CAP_SYS_PTRACE 19
#define CAP_SYS_PACCT 20
#define CAP_SYS_ADMIN 21
#define CAP_SYS_BOOT 22
#define CAP_SYS_NICE 23
#define CAP_SYS_RESOURCE 24
#define CAP_SYS_TIME 25
#define CAP_SYS_TTY_CONFIG 26
#define CAP_MKNOD 27
#define CAP_LEASE 28
#define CAP_AUDIT_WRITE 29
#define CAP_AUDIT_CONTROL 30
#define CAP_SETFCAP 31
#define CAP_MAC_OVERRIDE 32
#define CAP_MAC_ADMIN 33
#define CAP_SYSLOG 34
#define CAP_WAKE_ALARM 35
#define CAP_BLOCK_SUSPEND 36
#define CAP_AUDIT_READ 37
#define CAP_LAST_CAP CAP_AUDIT_READ
#define cap_valid(x) ((x) >= 0 && (x) <= CAP_LAST_CAP)
#define CAP_TO_INDEX(x) ((x) >> 5)
#define CAP_TO_MASK(x) (1 << ((x)&31))

#undef __user
#undef __u32
#undef __le32

#endif

```

`aosp/mkbootfs.10/src/mkbootfs/headers/private/android_filesystem_config.h`:

```h
/*
 * Copyright (C) 2007 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * This file is consumed by build/tools/fs_config and is used
 * for generating various files. Anything #define AID_<name>
 * becomes the mapping for getpwnam/getpwuid, etc. The <name>
 * field is lowercased.
 * For example:
 * #define AID_FOO_BAR 6666 becomes a friendly name of "foo_bar"
 *
 * The above holds true with the exception of:
 *   mediacodec
 *   mediaex
 *   mediadrm
 * Whose friendly names do not match the #define statements.
 *
 * Additionally, AID_OEM_RESERVED_START and AID_OEM_RESERVED_END
 * can be used to define reserved OEM ranges used for sanity checks
 * during the build process. The rules are, they must end with START/END
 * The proper convention is incrementing a number like so:
 * AID_OEM_RESERVED_START
 * AID_OEM_RESERVED_1_START
 * AID_OEM_RESERVED_2_START
 * ...
 * The same applies to the END.
 * They are not required to be in order, but must not overlap each other and
 * must define a START and END'ing range. START must be smaller than END.
 */

#ifndef _ANDROID_FILESYSTEM_CONFIG_H_
#define _ANDROID_FILESYSTEM_CONFIG_H_

#include <sys/types.h>

#if !defined(__ANDROID_VNDK__) && !defined(EXCLUDE_FS_CONFIG_STRUCTURES)
#include <private/fs_config.h>
#endif

/* This is the master Users and Groups config for the platform.
 * DO NOT EVER RENUMBER
 */

#define AID_ROOT 0 /* traditional unix root user */
/* The following are for LTP and should only be used for testing */
#define AID_DAEMON 1 /* traditional unix daemon owner */
#define AID_BIN 2    /* traditional unix binaries owner */

#define AID_SYSTEM 1000 /* system server */

#define AID_RADIO 1001           /* telephony subsystem, RIL */
#define AID_BLUETOOTH 1002       /* bluetooth subsystem */
#define AID_GRAPHICS 1003        /* graphics devices */
#define AID_INPUT 1004           /* input devices */
#define AID_AUDIO 1005           /* audio devices */
#define AID_CAMERA 1006          /* camera devices */
#define AID_LOG 1007             /* log devices */
#define AID_COMPASS 1008         /* compass device */
#define AID_MOUNT 1009           /* mountd socket */
#define AID_WIFI 1010            /* wifi subsystem */
#define AID_ADB 1011             /* android debug bridge (adbd) */
#define AID_INSTALL 1012         /* group for installing packages */
#define AID_MEDIA 1013           /* mediaserver process */
#define AID_DHCP 1014            /* dhcp client */
#define AID_SDCARD_RW 1015       /* external storage write access */
#define AID_VPN 1016             /* vpn system */
#define AID_KEYSTORE 1017        /* keystore subsystem */
#define AID_USB 1018             /* USB devices */
#define AID_DRM 1019             /* DRM server */
#define AID_MDNSR 1020           /* MulticastDNSResponder (service discovery) */
#define AID_GPS 1021             /* GPS daemon */
#define AID_UNUSED1 1022         /* deprecated, DO NOT USE */
#define AID_MEDIA_RW 1023        /* internal media storage write access */
#define AID_MTP 1024             /* MTP USB driver access */
#define AID_UNUSED2 1025         /* deprecated, DO NOT USE */
#define AID_DRMRPC 1026          /* group for drm rpc */
#define AID_NFC 1027             /* nfc subsystem */
#define AID_SDCARD_R 1028        /* external storage read access */
#define AID_CLAT 1029            /* clat part of nat464 */
#define AID_LOOP_RADIO 1030      /* loop radio devices */
#define AID_MEDIA_DRM 1031       /* MediaDrm plugins */
#define AID_PACKAGE_INFO 1032    /* access to installed package details */
#define AID_SDCARD_PICS 1033     /* external storage photos access */
#define AID_SDCARD_AV 1034       /* external storage audio/video access */
#define AID_SDCARD_ALL 1035      /* access all users external storage */
#define AID_LOGD 1036            /* log daemon */
#define AID_SHARED_RELRO 1037    /* creator of shared GNU RELRO files */
#define AID_DBUS 1038            /* dbus-daemon IPC broker process */
#define AID_TLSDATE 1039         /* tlsdate unprivileged user */
#define AID_MEDIA_EX 1040        /* mediaextractor process */
#define AID_AUDIOSERVER 1041     /* audioserver process */
#define AID_METRICS_COLL 1042    /* metrics_collector process */
#define AID_METRICSD 1043        /* metricsd process */
#define AID_WEBSERV 1044         /* webservd process */
#define AID_DEBUGGERD 1045       /* debuggerd unprivileged user */
#define AID_MEDIA_CODEC 1046     /* mediacodec process */
#define AID_CAMERASERVER 1047    /* cameraserver process */
#define AID_FIREWALL 1048        /* firewalld process */
#define AID_TRUNKS 1049          /* trunksd process (TPM daemon) */
#define AID_NVRAM 1050           /* Access-controlled NVRAM */
#define AID_DNS 1051             /* DNS resolution daemon (system: netd) */
#define AID_DNS_TETHER 1052      /* DNS resolution daemon (tether: dnsmasq) */
#define AID_WEBVIEW_ZYGOTE 1053  /* WebView zygote process */
#define AID_VEHICLE_NETWORK 1054 /* Vehicle network service */
#define AID_MEDIA_AUDIO 1055     /* GID for audio files on internal media storage */
#define AID_MEDIA_VIDEO 1056     /* GID for video files on internal media storage */
#define AID_MEDIA_IMAGE 1057     /* GID for image files on internal media storage */
#define AID_TOMBSTONED 1058      /* tombstoned user */
#define AID_MEDIA_OBB 1059       /* GID for OBB files on internal media storage */
#define AID_ESE 1060             /* embedded secure element (eSE) subsystem */
#define AID_OTA_UPDATE 1061      /* resource tracking UID for OTA updates */
#define AID_AUTOMOTIVE_EVS 1062  /* Automotive rear and surround view system */
#define AID_LOWPAN 1063          /* LoWPAN subsystem */
#define AID_HSM 1064             /* hardware security module subsystem */
#define AID_RESERVED_DISK 1065   /* GID that has access to reserved disk space */
#define AID_STATSD 1066          /* statsd daemon */
#define AID_INCIDENTD 1067       /* incidentd daemon */
#define AID_SECURE_ELEMENT 1068  /* secure element subsystem */
#define AID_LMKD 1069            /* low memory killer daemon */
#define AID_LLKD 1070            /* live lock daemon */
/* Changes to this file must be made in AOSP, *not* in internal branches. */

#define AID_SHELL 2000 /* adb and debug shell user */
#define AID_CACHE 2001 /* cache access */
#define AID_DIAG 2002  /* access to diagnostic resources */

/* The range 2900-2999 is reserved for OEM, and must never be
 * used here */
#define AID_OEM_RESERVED_START 2900
#define AID_OEM_RESERVED_END 2999

/* The 3000 series are intended for use as supplemental group id's only.
 * They indicate special Android capabilities that the kernel is aware of. */
#define AID_NET_BT_ADMIN 3001 /* bluetooth: create any socket */
#define AID_NET_BT 3002       /* bluetooth: create sco, rfcomm or l2cap sockets */
#define AID_INET 3003         /* can create AF_INET and AF_INET6 sockets */
#define AID_NET_RAW 3004      /* can create raw INET sockets */
#define AID_NET_ADMIN 3005    /* can configure interfaces and routing tables. */
#define AID_NET_BW_STATS 3006 /* read bandwidth statistics */
#define AID_NET_BW_ACCT 3007  /* change bandwidth statistics accounting */
#define AID_READPROC 3009     /* Allow /proc read access */
#define AID_WAKELOCK 3010     /* Allow system wakelock read/write access */
#define AID_UHID 3011         /* Allow read/write to /dev/uhid node */

/* The range 5000-5999 is also reserved for OEM, and must never be used here. */
#define AID_OEM_RESERVED_2_START 5000
#define AID_OEM_RESERVED_2_END 5999

#define AID_EVERYBODY 9997 /* shared between all apps in the same profile */
#define AID_MISC 9998      /* access to misc storage */
#define AID_NOBODY 9999

#define AID_APP 10000       /* TODO: switch users over to AID_APP_START */
#define AID_APP_START 10000 /* first app user */
#define AID_APP_END 19999   /* last app user */

#define AID_CACHE_GID_START 20000 /* start of gids for apps to mark cached data */
#define AID_CACHE_GID_END 29999   /* end of gids for apps to mark cached data */

#define AID_EXT_GID_START 30000 /* start of gids for apps to mark external data */
#define AID_EXT_GID_END 39999   /* end of gids for apps to mark external data */

#define AID_EXT_CACHE_GID_START 40000 /* start of gids for apps to mark external cached data */
#define AID_EXT_CACHE_GID_END 49999   /* end of gids for apps to mark external cached data */

#define AID_SHARED_GID_START 50000 /* start of gids for apps in each user to share */
#define AID_SHARED_GID_END 59999   /* end of gids for apps in each user to share */

/*
 * This is a magic number in the kernel and not something that was picked
 * arbitrarily. This value is returned whenever a uid that has no mapping in the
 * user namespace is returned to userspace:
 * https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/highuid.h?h=v4.4#n40
 */
#define AID_OVERFLOWUID 65534 /* unmapped user in the user namespace */

#define AID_ISOLATED_START 99000 /* start of uids for fully isolated sandboxed processes */
#define AID_ISOLATED_END 99999   /* end of uids for fully isolated sandboxed processes */

#define AID_USER 100000        /* TODO: switch users over to AID_USER_OFFSET */
#define AID_USER_OFFSET 100000 /* offset for uid ranges for each user */

/*
 * android_ids has moved to pwd/grp functionality.
 * If you need to add one, the structure is now
 * auto-generated based on the AID_ constraints
 * documented at the top of this header file.
 * Also see build/tools/fs_config for more details.
 */

#endif

```

`aosp/mkbootfs.10/src/mkbootfs/headers/private/fs_config.h`:

```h
/*
 * Copyright (C) 2007 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/* This file is used to define the properties of the filesystem
** images generated by build tools (mkbootfs and mkyaffs2image) and
** by the device side of adb.
*/

#ifndef _LIBS_CUTILS_PRIVATE_FS_CONFIG_H
#define _LIBS_CUTILS_PRIVATE_FS_CONFIG_H

#include <stdint.h>
#include <sys/cdefs.h>
#include <sys/types.h>

#if defined(__BIONIC__)
#include <linux/capability.h>
#else  // defined(__BIONIC__)
#include "android_filesystem_capability.h"
#endif  // defined(__BIONIC__)

#define CAP_MASK_LONG(cap_name) (1ULL << (cap_name))

/*
 * binary format for the runtime <partition>/etc/fs_config_(dirs|files)
 * filesystem override files.
 */

/* The following structure is stored little endian */
struct fs_path_config_from_file {
    uint16_t len;
    uint16_t mode;
    uint16_t uid;
    uint16_t gid;
    uint64_t capabilities;
    char prefix[];
} __attribute__((__aligned__(sizeof(uint64_t))));

struct fs_path_config {
    unsigned mode;
    unsigned uid;
    unsigned gid;
    uint64_t capabilities;
    const char* prefix;
};

/* Rules for directories and files has moved to system/code/libcutils/fs_config.c */

__BEGIN_DECLS

/*
 * Used in:
 *  build/tools/fs_config/fs_config.c
 *  build/tools/fs_get_stats/fs_get_stats.c
 *  system/extras/ext4_utils/make_ext4fs_main.c
 *  external/squashfs-tools/squashfs-tools/android.c
 *  system/core/cpio/mkbootfs.c
 *  system/core/adb/file_sync_service.cpp
 *  system/extras/ext4_utils/canned_fs_config.c
 */
void fs_config(const char* path, int dir, const char* target_out_path, unsigned* uid, unsigned* gid,
               unsigned* mode, uint64_t* capabilities);

ssize_t fs_config_generate(char* buffer, size_t length, const struct fs_path_config* pc);

__END_DECLS

#endif /* _LIBS_CUTILS_PRIVATE_FS_CONFIG_H */

```

`aosp/mkbootfs.10/src/mkbootfs/headers/utils/Compat.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef __LIB_UTILS_COMPAT_H
#define __LIB_UTILS_COMPAT_H

#include <unistd.h>

#if defined(__APPLE__)

/* Mac OS has always had a 64-bit off_t, so it doesn't have off64_t. */

typedef off_t off64_t;

static inline off64_t lseek64(int fd, off64_t offset, int whence) {
    return lseek(fd, offset, whence);
}

static inline ssize_t pread64(int fd, void* buf, size_t nbytes, off64_t offset) {
    return pread(fd, buf, nbytes, offset);
}

static inline ssize_t pwrite64(int fd, const void* buf, size_t nbytes, off64_t offset) {
    return pwrite(fd, buf, nbytes, offset);
}

static inline int ftruncate64(int fd, off64_t length) {
    return ftruncate(fd, length);
}

#endif /* __APPLE__ */

#if defined(_WIN32)
#define O_CLOEXEC O_NOINHERIT
#define O_NOFOLLOW 0
#define DEFFILEMODE 0666
#endif /* _WIN32 */

#define ZD "%zd"
#define ZD_TYPE ssize_t

/*
 * Needed for cases where something should be constexpr if possible, but not
 * being constexpr is fine if in pre-C++11 code (such as a const static float
 * member variable).
 */
#if __cplusplus >= 201103L
#define CONSTEXPR constexpr
#else
#define CONSTEXPR
#endif

/*
 * TEMP_FAILURE_RETRY is defined by some, but not all, versions of
 * <unistd.h>. (Alas, it is not as standard as we'd hoped!) So, if it's
 * not already defined, then define it here.
 */
#ifndef TEMP_FAILURE_RETRY
/* Used to retry syscalls that can return EINTR. */
#define TEMP_FAILURE_RETRY(exp) ({         \
    typeof (exp) _rc;                      \
    do {                                   \
        _rc = (exp);                       \
    } while (_rc == -1 && errno == EINTR); \
    _rc; })
#endif

#if defined(_WIN32)
#define OS_PATH_SEPARATOR '\\'
#else
#define OS_PATH_SEPARATOR '/'
#endif

#endif /* __LIB_UTILS_COMPAT_H */

```

`aosp/mkbootfs.11/build.gradle`:

```gradle
apply plugin: 'cpp'
apply plugin: 'c'

model {
    buildTypes {
        release
    }

    components {
        mkbootfs(NativeExecutableSpec) {
            binaries.all {
                //cppCompiler.define "ANDROID"
                //cppCompiler.define "ANDROID", "__ANDROID_VNDK__"
                //cppCompiler.define 'CFIG_NO_FIX_STAT'
                cppCompiler.args << "-std=c++17" << "-Wno-write-strings"
            }
        }
    }
}

```

`aosp/mkbootfs.11/src/mkbootfs/cpp/fs_config.cpp`:

```cpp
/*
 * Copyright (C) 2007 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <private/fs_config.h>

// This file is used to define the properties of the filesystem
// images generated by build tools (mkbootfs and mkyaffs2image) and
// by the device side of adb.

#define LOG_TAG "fs_config"

#include <errno.h>
#include <fcntl.h>
#include <fnmatch.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/stat.h>
#include <sys/types.h>

#include <string>

#include <android-base/strings.h>
#include <log/log.h>
#include <private/android_filesystem_config.h>
#include <utils/Compat.h>

#include "fs_config.h"

#ifndef O_BINARY
#define O_BINARY 0
#endif

using android::base::EndsWith;
using android::base::StartsWith;

#define ALIGN(x, alignment) (((x) + ((alignment)-1)) & ~((alignment)-1))
#define CAP_MASK_LONG(cap_name) (1ULL << (cap_name))

// Rules for directories.
// These rules are applied based on "first match", so they
// should start with the most specific path and work their
// way up to the root.

static const struct fs_path_config android_dirs[] = {
        // clang-format off
    { 00770, AID_SYSTEM,       AID_CACHE,        0, "cache" },
    { 00555, AID_ROOT,         AID_ROOT,         0, "config" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/app" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/app-private" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/app-ephemeral" },
    { 00771, AID_ROOT,         AID_ROOT,         0, "data/dalvik-cache" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data/data" },
    { 00771, AID_SHELL,        AID_SHELL,        0, "data/local/tmp" },
    { 00771, AID_SHELL,        AID_SHELL,        0, "data/local" },
    { 00770, AID_DHCP,         AID_DHCP,         0, "data/misc/dhcp" },
    { 00771, AID_SHARED_RELRO, AID_SHARED_RELRO, 0, "data/misc/shared_relro" },
    { 01771, AID_SYSTEM,       AID_MISC,         0, "data/misc" },
    { 00775, AID_MEDIA_RW,     AID_MEDIA_RW,     0, "data/media/Music" },
    { 00775, AID_MEDIA_RW,     AID_MEDIA_RW,     0, "data/media" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "data/nativetest" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "data/nativetest64" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "data/benchmarktest" },
    { 00750, AID_ROOT,         AID_SHELL,        0, "data/benchmarktest64" },
    { 00775, AID_ROOT,         AID_ROOT,         0, "data/preloads" },
    { 00771, AID_SYSTEM,       AID_SYSTEM,       0, "data" },
    { 00755, AID_ROOT,         AID_SYSTEM,       0, "mnt" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "product/bin" },
    { 00777, AID_ROOT,         AID_ROOT,         0, "sdcard" },
    { 00751, AID_ROOT,         AID_SDCARD_R,     0, "storage" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "system/bin" },
    { 00755, AID_ROOT,         AID_ROOT,         0, "system/etc/ppp" },
    { 00755, AID_ROOT,         AID_SHELL,        0, "system/vendor" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "system/xbin" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "system/apex/*/bin" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "system_ext/bin" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "system_ext/apex/*/bin" },
    { 00751, AID_ROOT,         AID_SHELL,        0, "vendor/bin" },
    { 00755, AID_ROOT,         AID_SHELL,        0, "vendor" },
    { 00755, AID_ROOT,         AID_ROOT,         0, 0 },
        // clang-format on
};
#ifndef __ANDROID_VNDK__
auto __for_testing_only__android_dirs = android_dirs;
#endif

// Rules for files.
// These rules are applied based on "first match", so they
// should start with the most specific path and work their
// way up to the root. Prefixes ending in * denotes wildcard
// and will allow partial matches.
static const char sys_conf_dir[] = "/system/etc/fs_config_dirs";
static const char sys_conf_file[] = "/system/etc/fs_config_files";
// No restrictions are placed on the vendor and oem file-system config files,
// although the developer is advised to restrict the scope to the /vendor or
// oem/ file-system since the intent is to provide support for customized
// portions of a separate vendor.img or oem.img.  Has to remain open so that
// customization can also land on /system/vendor, /system/oem, /system/odm,
// /system/product or /system/system_ext.
//
// We expect build-time checking or filtering when constructing the associated
// fs_config_* files (see build/tools/fs_config/fs_config_generate.c)
static const char ven_conf_dir[] = "/vendor/etc/fs_config_dirs";
static const char ven_conf_file[] = "/vendor/etc/fs_config_files";
static const char oem_conf_dir[] = "/oem/etc/fs_config_dirs";
static const char oem_conf_file[] = "/oem/etc/fs_config_files";
static const char odm_conf_dir[] = "/odm/etc/fs_config_dirs";
static const char odm_conf_file[] = "/odm/etc/fs_config_files";
static const char product_conf_dir[] = "/product/etc/fs_config_dirs";
static const char product_conf_file[] = "/product/etc/fs_config_files";
static const char system_ext_conf_dir[] = "/system_ext/etc/fs_config_dirs";
static const char system_ext_conf_file[] = "/system_ext/etc/fs_config_files";
static const char* conf[][2] = {
        {sys_conf_file, sys_conf_dir},         {ven_conf_file, ven_conf_dir},
        {oem_conf_file, oem_conf_dir},         {odm_conf_file, odm_conf_dir},
        {product_conf_file, product_conf_dir}, {system_ext_conf_file, system_ext_conf_dir},
};

// Do not use android_files to grant Linux capabilities.  Use ambient capabilities in their
// associated init.rc file instead.  See https://source.android.com/devices/tech/config/ambient.

// Do not place any new vendor/, data/vendor/, etc entries in android_files.
// Vendor entries should be done via a vendor or device specific config.fs.
// See https://source.android.com/devices/tech/config/filesystem#using-file-system-capabilities
static const struct fs_path_config android_files[] = {
        // clang-format off
    { 00644, AID_SYSTEM,    AID_SYSTEM,    0, "data/app/*" },
    { 00644, AID_SYSTEM,    AID_SYSTEM,    0, "data/app-ephemeral/*" },
    { 00644, AID_SYSTEM,    AID_SYSTEM,    0, "data/app-private/*" },
    { 00644, AID_APP,       AID_APP,       0, "data/data/*" },
    { 00644, AID_MEDIA_RW,  AID_MEDIA_RW,  0, "data/media/*" },
    { 00640, AID_ROOT,      AID_SHELL,     0, "data/nativetest/tests.txt" },
    { 00640, AID_ROOT,      AID_SHELL,     0, "data/nativetest64/tests.txt" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "data/nativetest/*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "data/nativetest64/*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "data/benchmarktest/*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "data/benchmarktest64/*" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "default.prop" }, // legacy
    { 00600, AID_ROOT,      AID_ROOT,      0, "system/etc/prop.default" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "odm/build.prop" }, // legacy; only for P release
    { 00600, AID_ROOT,      AID_ROOT,      0, "odm/default.prop" }, // legacy; only for P release
    { 00600, AID_ROOT,      AID_ROOT,      0, "odm/etc/build.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, odm_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, odm_conf_file + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, oem_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, oem_conf_file + 1 },
    { 00600, AID_ROOT,      AID_ROOT,      0, "product/build.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, product_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, product_conf_file + 1 },
    { 00600, AID_ROOT,      AID_ROOT,      0, "system_ext/build.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, system_ext_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, system_ext_conf_file + 1 },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/crash_dump32" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/crash_dump64" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/debuggerd" },
    { 00550, AID_LOGD,      AID_LOGD,      0, "system/bin/logd" },
    { 00700, AID_ROOT,      AID_ROOT,      0, "system/bin/secilc" },
    { 00750, AID_ROOT,      AID_ROOT,      0, "system/bin/uncrypt" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "system/build.prop" },
    { 00444, AID_ROOT,      AID_ROOT,      0, sys_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, sys_conf_file + 1 },
    { 00440, AID_ROOT,      AID_SHELL,     0, "system/etc/init.goldfish.rc" },
    { 00550, AID_ROOT,      AID_SHELL,     0, "system/etc/init.goldfish.sh" },
    { 00550, AID_ROOT,      AID_SHELL,     0, "system/etc/init.ril" },
    { 00555, AID_ROOT,      AID_ROOT,      0, "system/etc/ppp/*" },
    { 00555, AID_ROOT,      AID_ROOT,      0, "system/etc/rc.*" },
    { 00750, AID_ROOT,      AID_ROOT,      0, "vendor/bin/install-recovery.sh" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "vendor/build.prop" },
    { 00600, AID_ROOT,      AID_ROOT,      0, "vendor/default.prop" },
    { 00440, AID_ROOT,      AID_ROOT,      0, "vendor/etc/recovery.img" },
    { 00444, AID_ROOT,      AID_ROOT,      0, ven_conf_dir + 1 },
    { 00444, AID_ROOT,      AID_ROOT,      0, ven_conf_file + 1 },

    // the following two files are INTENTIONALLY set-uid, but they
    // are NOT included on user builds.
    { 06755, AID_ROOT,      AID_ROOT,      0, "system/xbin/procmem" },
    { 04750, AID_ROOT,      AID_SHELL,     0, "system/xbin/su" },

    // the following files have enhanced capabilities and ARE included
    // in user builds.
    { 00700, AID_SYSTEM,    AID_SHELL,     CAP_MASK_LONG(CAP_BLOCK_SUSPEND),
                                              "system/bin/inputflinger" },
    { 00750, AID_ROOT,      AID_SHELL,     CAP_MASK_LONG(CAP_SETUID) |
                                           CAP_MASK_LONG(CAP_SETGID),
                                              "system/bin/run-as" },
    { 00750, AID_ROOT,      AID_SHELL,     CAP_MASK_LONG(CAP_SETUID) |
                                           CAP_MASK_LONG(CAP_SETGID),
                                              "system/bin/simpleperf_app_runner" },
    { 00755, AID_ROOT,      AID_ROOT,      0, "first_stage_ramdisk/system/bin/e2fsck" },
    { 00755, AID_ROOT,      AID_ROOT,      0, "first_stage_ramdisk/system/bin/tune2fs" },
    { 00755, AID_ROOT,      AID_ROOT,      0, "first_stage_ramdisk/system/bin/resize2fs" },
    // generic defaults
    { 00755, AID_ROOT,      AID_ROOT,      0, "bin/*" },
    { 00640, AID_ROOT,      AID_SHELL,     0, "fstab.*" },
    { 00750, AID_ROOT,      AID_SHELL,     0, "init*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "odm/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "product/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/xbin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system/apex/*/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system_ext/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "system_ext/apex/*/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "vendor/bin/*" },
    { 00755, AID_ROOT,      AID_SHELL,     0, "vendor/xbin/*" },
    { 00644, AID_ROOT,      AID_ROOT,      0, 0 },
        // clang-format on
};
#ifndef __ANDROID_VNDK__
auto __for_testing_only__android_files = android_files;
#endif

static size_t strip(const char* path, size_t len, const char suffix[]) {
    if (len < strlen(suffix)) return len;
    if (strncmp(path + len - strlen(suffix), suffix, strlen(suffix))) return len;
    return len - strlen(suffix);
}

static int fs_config_open(int dir, int which, const char* target_out_path) {
    int fd = -1;

    if (target_out_path && *target_out_path) {
        // target_out_path is the path to the directory holding content of
        // system partition but as we cannot guarantee it ends with '/system'
        // or with or without a trailing slash, need to strip them carefully.
        char* name = NULL;
        size_t len = strlen(target_out_path);
        len = strip(target_out_path, len, "/");
        len = strip(target_out_path, len, "/system");
        if (asprintf(&name, "%.*s%s", (int)len, target_out_path, conf[which][dir]) != -1) {
            fd = TEMP_FAILURE_RETRY(open(name, O_RDONLY | O_BINARY));
            free(name);
        }
    }
    if (fd < 0) {
        fd = TEMP_FAILURE_RETRY(open(conf[which][dir], O_RDONLY | O_BINARY));
    }
    return fd;
}

// if path is "odm/<stuff>", "oem/<stuff>", "product/<stuff>",
// "system_ext/<stuff>" or "vendor/<stuff>"
static bool is_partition(const std::string& path) {
    static const char* partitions[] = {"odm/", "oem/", "product/", "system_ext/", "vendor/"};
    for (size_t i = 0; i < (sizeof(partitions) / sizeof(partitions[0])); ++i) {
        if (StartsWith(path, partitions[i])) return true;
    }
    return false;
}

// alias prefixes of "<partition>/<stuff>" to "system/<partition>/<stuff>" or
// "system/<partition>/<stuff>" to "<partition>/<stuff>"
static bool fs_config_cmp(bool dir, const char* prefix, size_t len, const char* path, size_t plen) {
    std::string pattern(prefix, len);
    std::string input(path, plen);

    // Massage pattern and input so that they can be used by fnmatch where
    // directories have to end with /.
    if (dir) {
        if (!EndsWith(input, "/")) {
            input.append("/");
        }

        if (!EndsWith(pattern, "/*")) {
            if (EndsWith(pattern, "/")) {
                pattern.append("*");
            } else {
                pattern.append("/*");
            }
        }
    }

    // no FNM_PATHNAME is set in order to match a/b/c/d with a/*
    // FNM_ESCAPE is set in order to prevent using \\? and \\* and maintenance issues.
    const int fnm_flags = FNM_NOESCAPE;
    if (fnmatch(pattern.c_str(), input.c_str(), fnm_flags) == 0) return true;

    // Check match between logical partition's files and patterns.
    static constexpr const char* kLogicalPartitions[] = {"system/product/", "system/system_ext/",
                                                         "system/vendor/", "vendor/odm/"};
    for (auto& logical_partition : kLogicalPartitions) {
        if (StartsWith(input, logical_partition)) {
            std::string input_in_partition = input.substr(input.find('/') + 1);
            if (!is_partition(input_in_partition)) continue;
            if (fnmatch(pattern.c_str(), input_in_partition.c_str(), fnm_flags) == 0) {
                return true;
            }
        }
    }
    return false;
}
#ifndef __ANDROID_VNDK__
auto __for_testing_only__fs_config_cmp = fs_config_cmp;
#endif

void fs_config(const char* path, int dir, const char* target_out_path, unsigned* uid, unsigned* gid,
               unsigned* mode, uint64_t* capabilities) {
    const struct fs_path_config* pc;
    size_t which, plen;

    if (path[0] == '/') {
        path++;
    }

    plen = strlen(path);

    for (which = 0; which < (sizeof(conf) / sizeof(conf[0])); ++which) {
        struct fs_path_config_from_file header;

        int fd = fs_config_open(dir, which, target_out_path);
        if (fd < 0) continue;

        while (TEMP_FAILURE_RETRY(read(fd, &header, sizeof(header))) == sizeof(header)) {
            char* prefix;
            uint16_t host_len = header.len;
            ssize_t len, remainder = host_len - sizeof(header);
            if (remainder <= 0) {
                ALOGE("%s len is corrupted", conf[which][dir]);
                break;
            }
            prefix = static_cast<char*>(calloc(1, remainder));
            if (!prefix) {
                ALOGE("%s out of memory", conf[which][dir]);
                break;
            }
            if (TEMP_FAILURE_RETRY(read(fd, prefix, remainder)) != remainder) {
                free(prefix);
                ALOGE("%s prefix is truncated", conf[which][dir]);
                break;
            }
            len = strnlen(prefix, remainder);
            if (len >= remainder) {  // missing a terminating null
                free(prefix);
                ALOGE("%s is corrupted", conf[which][dir]);
                break;
            }
            if (fs_config_cmp(dir, prefix, len, path, plen)) {
                free(prefix);
                close(fd);
                *uid = header.uid;
                *gid = header.gid;
                *mode = (*mode & (~07777)) | header.mode;
                *capabilities = header.capabilities;
                return;
            }
            free(prefix);
        }
        close(fd);
    }

    for (pc = dir ? android_dirs : android_files; pc->prefix; pc++) {
        if (fs_config_cmp(dir, pc->prefix, strlen(pc->prefix), path, plen)) {
            break;
        }
    }
    *uid = pc->uid;
    *gid = pc->gid;
    *mode = (*mode & (~07777)) | pc->mode;
    *capabilities = pc->capabilities;
}

```

`aosp/mkbootfs.11/src/mkbootfs/cpp/mkbootfs.c`:

```c

#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <ctype.h>

#include <sys/types.h>
#include <sys/stat.h>
#include <dirent.h>

#include <stdarg.h>
#include <fcntl.h>

#include <private/android_filesystem_config.h>
#include <private/fs_config.h>

/* NOTES
**
** - see buffer-format.txt from the linux kernel docs for
**   an explanation of this file format
** - dotfiles are ignored
** - directories named 'root' are ignored
** - device notes, pipes, etc are not supported (error)
*/

void die(const char *why, ...)
{
    va_list ap;

    va_start(ap, why);
    fprintf(stderr,"error: ");
    vfprintf(stderr, why, ap);
    fprintf(stderr,"\n");
    va_end(ap);
    exit(1);
}

struct fs_config_entry {
    char* name;
    int uid, gid, mode;
};

static struct fs_config_entry* canned_config = NULL;
static char *target_out_path = NULL;

/* Each line in the canned file should be a path plus three ints (uid,
 * gid, mode). */
#ifdef PATH_MAX
#define CANNED_LINE_LENGTH  (PATH_MAX+100)
#else
#define CANNED_LINE_LENGTH  (1024)
#endif

#define TRAILER "TRAILER!!!"

static int verbose = 0;
static int total_size = 0;

static void fix_stat(const char *path, struct stat *s)
{
    uint64_t capabilities;
    if (canned_config) {
        // Use the list of file uid/gid/modes loaded from the file
        // given with -f.

        struct fs_config_entry* empty_path_config = NULL;
        struct fs_config_entry* p;
        for (p = canned_config; p->name; ++p) {
            if (!p->name[0]) {
                empty_path_config = p;
            }
            if (strcmp(p->name, path) == 0) {
                s->st_uid = p->uid;
                s->st_gid = p->gid;
                s->st_mode = p->mode | (s->st_mode & ~07777);
                return;
            }
        }
        s->st_uid = empty_path_config->uid;
        s->st_gid = empty_path_config->gid;
        s->st_mode = empty_path_config->mode | (s->st_mode & ~07777);
    } else {
        // Use the compiled-in fs_config() function.
        unsigned st_mode = s->st_mode;
        int is_dir = S_ISDIR(s->st_mode) || strcmp(path, TRAILER) == 0;
        fs_config(path, is_dir, target_out_path, &s->st_uid, &s->st_gid, &st_mode, &capabilities);
        s->st_mode = (decltype(s->st_mode)) st_mode;
    }
}

static void _eject(struct stat *s, char *out, int olen, char *data, unsigned datasize)
{
    // Nothing is special about this value, just picked something in the
    // approximate range that was being used already, and avoiding small
    // values which may be special.
    static unsigned next_inode = 300000;

    while(total_size & 3) {
        total_size++;
        putchar(0);
    }

#ifdef CFIG_NO_FIX_STAT
#warning CFIG_NO_FIX_STAT defined, will not fix_stat() defined in Android
#else
    fix_stat(out, s);
#endif
//    fprintf(stderr, "_eject %s: mode=0%o\n", out, s->st_mode);

    printf("%06x%08x%08x%08x%08x%08x%08x"
           "%08x%08x%08x%08x%08x%08x%08x%s%c",
           0x070701,
           next_inode++,  //  s.st_ino,
           s->st_mode,
           0, // s.st_uid,
           0, // s.st_gid,
           1, // s.st_nlink,
           0, // s.st_mtime,
           datasize,
           0, // volmajor
           0, // volminor
           0, // devmajor
           0, // devminor,
           olen + 1,
           0,
           out,
           0
           );

    total_size += 6 + 8*13 + olen + 1;

    if(strlen(out) != (unsigned int)olen) die("ACK!");

    while(total_size & 3) {
        total_size++;
        putchar(0);
    }

    if(datasize) {
        fwrite(data, datasize, 1, stdout);
        total_size += datasize;
    }
}

static void _eject_trailer()
{
    struct stat s;
    memset(&s, 0, sizeof(s));
    _eject(&s, TRAILER, 10, 0, 0);

    while(total_size & 0xff) {
        total_size++;
        putchar(0);
    }
}

static void _archive(char *in, char *out, int ilen, int olen);

static int compare(const void* a, const void* b) {
  return strcmp(*(const char**)a, *(const char**)b);
}

static void _archive_dir(char *in, char *out, int ilen, int olen)
{
    int i, t;
    DIR *d;
    struct dirent *de;

    if(verbose) {
        fprintf(stderr,"_archive_dir('%s','%s',%d,%d)\n",
                in, out, ilen, olen);
    }

    d = opendir(in);
    if(d == 0) die("cannot open directory '%s'", in);

    int size = 32;
    int entries = 0;
    char** names = (char**) malloc(size * sizeof(char*));
    if (names == NULL) {
      fprintf(stderr, "failed to allocate dir names array (size %d)\n", size);
      exit(1);
    }

    while((de = readdir(d)) != 0){
            /* xxx: feature? maybe some dotfiles are okay */
        if(de->d_name[0] == '.') continue;

            /* xxx: hack. use a real exclude list */
        if(!strcmp(de->d_name, "root")) continue;

        if (entries >= size) {
          size *= 2;
          names = (char**) realloc(names, size * sizeof(char*));
          if (names == NULL) {
            fprintf(stderr, "failed to reallocate dir names array (size %d)\n",
                    size);
            exit(1);
          }
        }
        names[entries] = strdup(de->d_name);
        if (names[entries] == NULL) {
          fprintf(stderr, "failed to strdup name \"%s\"\n",
                  de->d_name);
          exit(1);
        }
        ++entries;
    }

    qsort(names, entries, sizeof(char*), compare);

    for (i = 0; i < entries; ++i) {
        t = strlen(names[i]);
        in[ilen] = '/';
        memcpy(in + ilen + 1, names[i], t + 1);

        if(olen > 0) {
            out[olen] = '/';
            memcpy(out + olen + 1, names[i], t + 1);
            _archive(in, out, ilen + t + 1, olen + t + 1);
        } else {
            memcpy(out, names[i], t + 1);
            _archive(in, out, ilen + t + 1, t);
        }

        in[ilen] = 0;
        out[olen] = 0;

        free(names[i]);
    }
    free(names);

    closedir(d);
}

static void _archive(char *in, char *out, int ilen, int olen)
{
    struct stat s;

    if(verbose) {
        fprintf(stderr,"_archive('%s','%s',%d,%d)\n",
                in, out, ilen, olen);
    }

    if(lstat(in, &s)) die("could not stat '%s'\n", in);

    if(S_ISREG(s.st_mode)){
        char *tmp;
        int fd;

        fd = open(in, O_RDONLY);
        if(fd < 0) die("cannot open '%s' for read", in);

        tmp = (char*) malloc(s.st_size);
        if(tmp == 0) die("cannot allocate %d bytes", s.st_size);

        if(read(fd, tmp, s.st_size) != s.st_size) {
            die("cannot read %d bytes", s.st_size);
        }

        _eject(&s, out, olen, tmp, s.st_size);

        free(tmp);
        close(fd);
    } else if(S_ISDIR(s.st_mode)) {
        _eject(&s, out, olen, 0, 0);
        _archive_dir(in, out, ilen, olen);
    } else if(S_ISLNK(s.st_mode)) {
        char buf[1024];
        int size;
        size = readlink(in, buf, 1024);
        if(size < 0) die("cannot read symlink '%s'", in);
        _eject(&s, out, olen, buf, size);
    } else {
        die("Unknown '%s' (mode %d)?\n", in, s.st_mode);
    }
}

void archive(const char *start, const char *prefix)
{
    char in[8192];
    char out[8192];

    strcpy(in, start);
    strcpy(out, prefix);

    _archive_dir(in, out, strlen(in), strlen(out));
}

static void read_canned_config(char* filename)
{
    int allocated = 8;
    int used = 0;

    canned_config =
        (struct fs_config_entry*)malloc(allocated * sizeof(struct fs_config_entry));

    char line[CANNED_LINE_LENGTH];
    FILE* f = fopen(filename, "r");
    if (f == NULL) die("failed to open canned file");

    while (fgets(line, CANNED_LINE_LENGTH, f) != NULL) {
        if (!line[0]) break;
        if (used >= allocated) {
            allocated *= 2;
            canned_config = (struct fs_config_entry*)realloc(
                canned_config, allocated * sizeof(struct fs_config_entry));
            if (canned_config == NULL) die("failed to reallocate memory");
        }

        struct fs_config_entry* cc = canned_config + used;

        if (isspace(line[0])) {
            cc->name = strdup("");
            cc->uid = atoi(strtok(line, " \n"));
        } else {
            cc->name = strdup(strtok(line, " \n"));
            cc->uid = atoi(strtok(NULL, " \n"));
        }
        cc->gid = atoi(strtok(NULL, " \n"));
        cc->mode = strtol(strtok(NULL, " \n"), NULL, 8);
        ++used;
    }
    if (used >= allocated) {
        ++allocated;
        canned_config = (struct fs_config_entry*)realloc(
            canned_config, allocated * sizeof(struct fs_config_entry));
        if (canned_config == NULL) die("failed to reallocate memory");
    }
    canned_config[used].name = NULL;

    fclose(f);
}


int main(int argc, char *argv[])
{
    argc--;
    argv++;

    if (argc > 1 && strcmp(argv[0], "-d") == 0) {
        target_out_path = argv[1];
        argc -= 2;
        argv += 2;
    }

    if (argc > 1 && strcmp(argv[0], "-f") == 0) {
        read_canned_config(argv[1]);
        argc -= 2;
        argv += 2;
    }

    if(argc == 0) die("no directories to process?!");

    while(argc-- > 0){
        char *x = strchr(*argv, '=');
        if(x != 0) {
            *x++ = 0;
        } else {
            x = "";
        }

        archive(*argv, x);

        argv++;
    }

    _eject_trailer();

    return 0;
}

```

`aosp/mkbootfs.11/src/mkbootfs/cpp/strings.cpp`:

```cpp
#include "android-base/strings.h"
#include <string>
#include <vector>

namespace android {
namespace base {

bool StartsWith(std::string_view s, std::string_view prefix) {
  return s.substr(0, prefix.size()) == prefix;
}

bool StartsWith(std::string_view s, char prefix) {
  return !s.empty() && s.front() == prefix;
}


bool EndsWith(std::string_view s, std::string_view suffix) {
  return s.size() >= suffix.size() && s.substr(s.size() - suffix.size(), suffix.size()) == suffix;
}

bool EndsWith(std::string_view s, char suffix) {
  return !s.empty() && s.back() == suffix;
}

}  // namespace base
}  // namespace android

```

`aosp/mkbootfs.11/src/mkbootfs/headers/android-base/strings.h`:

```h
#pragma once

#include <sstream>
#include <string>
#include <vector>

namespace android {
namespace base {

// Tests whether 's' starts with 'prefix'.
bool StartsWith(std::string_view s, std::string_view prefix);
bool StartsWith(std::string_view s, char prefix);

// Tests whether 's' ends with 'suffix'.
bool EndsWith(std::string_view s, std::string_view suffix);
bool EndsWith(std::string_view s, char suffix);

}  // namespace base
}  // namespace android

```

`aosp/mkbootfs.11/src/mkbootfs/headers/fs_config.h`:

```h
/*
 * Copyright (C) 2019 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <stdint.h>

// Binary format for the runtime <partition>/etc/fs_config_(dirs|files) filesystem override files.
struct fs_path_config_from_file {
    uint16_t len;
    uint16_t mode;
    uint16_t uid;
    uint16_t gid;
    uint64_t capabilities;
    char prefix[];
} __attribute__((__aligned__(sizeof(uint64_t))));

struct fs_path_config {
    unsigned mode;
    unsigned uid;
    unsigned gid;
    uint64_t capabilities;
    const char* prefix;
};

```

`aosp/mkbootfs.11/src/mkbootfs/headers/log/log.h`:

```h
#ifndef _CFIG_LOG_H
#define _CFIG_LOG_H

#define ALOGE printf

#endif

```

`aosp/mkbootfs.11/src/mkbootfs/headers/private/android_filesystem_capability.h`:

```h
/*
 * Copyright (C) 2013 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * Taken from linux/capability.h, with minor modifications
 */

#ifndef _SYSTEM_CORE_INCLUDE_PRIVATE_ANDROID_FILESYSTEM_CAPABILITY_H
#define _SYSTEM_CORE_INCLUDE_PRIVATE_ANDROID_FILESYSTEM_CAPABILITY_H

#include <stdint.h>

#define __user
#define __u32 uint32_t
#define __le32 uint32_t

#define _LINUX_CAPABILITY_VERSION_1 0x19980330
#define _LINUX_CAPABILITY_U32S_1 1
#define _LINUX_CAPABILITY_VERSION_2 0x20071026
#define _LINUX_CAPABILITY_U32S_2 2
#define _LINUX_CAPABILITY_VERSION_3 0x20080522
#define _LINUX_CAPABILITY_U32S_3 2

typedef struct __user_cap_header_struct {
    __u32 version;
    int pid;
} __user* cap_user_header_t;

typedef struct __user_cap_data_struct {
    __u32 effective;
    __u32 permitted;
    __u32 inheritable;
} __user* cap_user_data_t;

#define VFS_CAP_REVISION_MASK 0xFF000000
#define VFS_CAP_REVISION_SHIFT 24
#define VFS_CAP_FLAGS_MASK ~VFS_CAP_REVISION_MASK
#define VFS_CAP_FLAGS_EFFECTIVE 0x000001
#define VFS_CAP_REVISION_1 0x01000000
#define VFS_CAP_U32_1 1
#define XATTR_CAPS_SZ_1 (sizeof(__le32) * (1 + 2 * VFS_CAP_U32_1))
#define VFS_CAP_REVISION_2 0x02000000
#define VFS_CAP_U32_2 2
#define XATTR_CAPS_SZ_2 (sizeof(__le32) * (1 + 2 * VFS_CAP_U32_2))
#define XATTR_CAPS_SZ XATTR_CAPS_SZ_2
#define VFS_CAP_U32 VFS_CAP_U32_2
#define VFS_CAP_REVISION VFS_CAP_REVISION_2

struct vfs_cap_data {
    __le32 magic_etc;
    struct {
        __le32 permitted;
        __le32 inheritable;
    } data[VFS_CAP_U32];
};

#define _LINUX_CAPABILITY_VERSION _LINUX_CAPABILITY_VERSION_1
#define _LINUX_CAPABILITY_U32S _LINUX_CAPABILITY_U32S_1
#define CAP_CHOWN 0
#define CAP_DAC_OVERRIDE 1
#define CAP_DAC_READ_SEARCH 2
#define CAP_FOWNER 3
#define CAP_FSETID 4
#define CAP_KILL 5
#define CAP_SETGID 6
#define CAP_SETUID 7
#define CAP_SETPCAP 8
#define CAP_LINUX_IMMUTABLE 9
#define CAP_NET_BIND_SERVICE 10
#define CAP_NET_BROADCAST 11
#define CAP_NET_ADMIN 12
#define CAP_NET_RAW 13
#define CAP_IPC_LOCK 14
#define CAP_IPC_OWNER 15
#define CAP_SYS_MODULE 16
#define CAP_SYS_RAWIO 17
#define CAP_SYS_CHROOT 18
#define CAP_SYS_PTRACE 19
#define CAP_SYS_PACCT 20
#define CAP_SYS_ADMIN 21
#define CAP_SYS_BOOT 22
#define CAP_SYS_NICE 23
#define CAP_SYS_RESOURCE 24
#define CAP_SYS_TIME 25
#define CAP_SYS_TTY_CONFIG 26
#define CAP_MKNOD 27
#define CAP_LEASE 28
#define CAP_AUDIT_WRITE 29
#define CAP_AUDIT_CONTROL 30
#define CAP_SETFCAP 31
#define CAP_MAC_OVERRIDE 32
#define CAP_MAC_ADMIN 33
#define CAP_SYSLOG 34
#define CAP_WAKE_ALARM 35
#define CAP_BLOCK_SUSPEND 36
#define CAP_AUDIT_READ 37
#define CAP_LAST_CAP CAP_AUDIT_READ
#define cap_valid(x) ((x) >= 0 && (x) <= CAP_LAST_CAP)
#define CAP_TO_INDEX(x) ((x) >> 5)
#define CAP_TO_MASK(x) (1 << ((x)&31))

#undef __user
#undef __u32
#undef __le32

#endif

```

`aosp/mkbootfs.11/src/mkbootfs/headers/private/android_filesystem_config.h`:

```h
/*
 * Copyright (C) 2007 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * This file is consumed by build/tools/fs_config and is used
 * for generating various files. Anything #define AID_<name>
 * becomes the mapping for getpwnam/getpwuid, etc. The <name>
 * field is lowercased.
 * For example:
 * #define AID_FOO_BAR 6666 becomes a friendly name of "foo_bar"
 *
 * The above holds true with the exception of:
 *   mediacodec
 *   mediaex
 *   mediadrm
 * Whose friendly names do not match the #define statements.
 *
 * This file must only be used for platform (Google managed, and submitted through AOSP), AIDs.  3rd
 * party AIDs must be added via config.fs, which will place them in the corresponding partition's
 * passwd and group files.  There are ranges in this file reserved for AIDs for each 3rd party
 * partition, from which the system reads passwd and group files.
 */

#pragma once

/* This is the master Users and Groups config for the platform.
 * DO NOT EVER RENUMBER
 */

#define AID_ROOT 0 /* traditional unix root user */
/* The following are for LTP and should only be used for testing */
#define AID_DAEMON 1 /* traditional unix daemon owner */
#define AID_BIN 2    /* traditional unix binaries owner */

#define AID_SYSTEM 1000 /* system server */

#define AID_RADIO 1001           /* telephony subsystem, RIL */
#define AID_BLUETOOTH 1002       /* bluetooth subsystem */
#define AID_GRAPHICS 1003        /* graphics devices */
#define AID_INPUT 1004           /* input devices */
#define AID_AUDIO 1005           /* audio devices */
#define AID_CAMERA 1006          /* camera devices */
#define AID_LOG 1007             /* log devices */
#define AID_COMPASS 1008         /* compass device */
#define AID_MOUNT 1009           /* mountd socket */
#define AID_WIFI 1010            /* wifi subsystem */
#define AID_ADB 1011             /* android debug bridge (adbd) */
#define AID_INSTALL 1012         /* group for installing packages */
#define AID_MEDIA 1013           /* mediaserver process */
#define AID_DHCP 1014            /* dhcp client */
#define AID_SDCARD_RW 1015       /* external storage write access */
#define AID_VPN 1016             /* vpn system */
#define AID_KEYSTORE 1017        /* keystore subsystem */
#define AID_USB 1018             /* USB devices */
#define AID_DRM 1019             /* DRM server */
#define AID_MDNSR 1020           /* MulticastDNSResponder (service discovery) */
#define AID_GPS 1021             /* GPS daemon */
#define AID_UNUSED1 1022         /* deprecated, DO NOT USE */
#define AID_MEDIA_RW 1023        /* internal media storage write access */
#define AID_MTP 1024             /* MTP USB driver access */
#define AID_UNUSED2 1025         /* deprecated, DO NOT USE */
#define AID_DRMRPC 1026          /* group for drm rpc */
#define AID_NFC 1027             /* nfc subsystem */
#define AID_SDCARD_R 1028        /* external storage read access */
#define AID_CLAT 1029            /* clat part of nat464 */
#define AID_LOOP_RADIO 1030      /* loop radio devices */
#define AID_MEDIA_DRM 1031       /* MediaDrm plugins */
#define AID_PACKAGE_INFO 1032    /* access to installed package details */
#define AID_SDCARD_PICS 1033     /* external storage photos access */
#define AID_SDCARD_AV 1034       /* external storage audio/video access */
#define AID_SDCARD_ALL 1035      /* access all users external storage */
#define AID_LOGD 1036            /* log daemon */
#define AID_SHARED_RELRO 1037    /* creator of shared GNU RELRO files */
#define AID_DBUS 1038            /* dbus-daemon IPC broker process */
#define AID_TLSDATE 1039         /* tlsdate unprivileged user */
#define AID_MEDIA_EX 1040        /* mediaextractor process */
#define AID_AUDIOSERVER 1041     /* audioserver process */
#define AID_METRICS_COLL 1042    /* metrics_collector process */
#define AID_METRICSD 1043        /* metricsd process */
#define AID_WEBSERV 1044         /* webservd process */
#define AID_DEBUGGERD 1045       /* debuggerd unprivileged user */
#define AID_MEDIA_CODEC 1046     /* mediacodec process */
#define AID_CAMERASERVER 1047    /* cameraserver process */
#define AID_FIREWALL 1048        /* firewalld process */
#define AID_TRUNKS 1049          /* trunksd process (TPM daemon) */
#define AID_NVRAM 1050           /* Access-controlled NVRAM */
#define AID_DNS 1051             /* DNS resolution daemon (system: netd) */
#define AID_DNS_TETHER 1052      /* DNS resolution daemon (tether: dnsmasq) */
#define AID_WEBVIEW_ZYGOTE 1053  /* WebView zygote process */
#define AID_VEHICLE_NETWORK 1054 /* Vehicle network service */
#define AID_MEDIA_AUDIO 1055     /* GID for audio files on internal media storage */
#define AID_MEDIA_VIDEO 1056     /* GID for video files on internal media storage */
#define AID_MEDIA_IMAGE 1057     /* GID for image files on internal media storage */
#define AID_TOMBSTONED 1058      /* tombstoned user */
#define AID_MEDIA_OBB 1059       /* GID for OBB files on internal media storage */
#define AID_ESE 1060             /* embedded secure element (eSE) subsystem */
#define AID_OTA_UPDATE 1061      /* resource tracking UID for OTA updates */
#define AID_AUTOMOTIVE_EVS 1062  /* Automotive rear and surround view system */
#define AID_LOWPAN 1063          /* LoWPAN subsystem */
#define AID_HSM 1064             /* hardware security module subsystem */
#define AID_RESERVED_DISK 1065   /* GID that has access to reserved disk space */
#define AID_STATSD 1066          /* statsd daemon */
#define AID_INCIDENTD 1067       /* incidentd daemon */
#define AID_SECURE_ELEMENT 1068  /* secure element subsystem */
#define AID_LMKD 1069            /* low memory killer daemon */
#define AID_LLKD 1070            /* live lock daemon */
#define AID_IORAPD 1071          /* input/output readahead and pin daemon */
#define AID_GPU_SERVICE 1072     /* GPU service daemon */
#define AID_NETWORK_STACK 1073   /* network stack service */
#define AID_GSID 1074            /* GSI service daemon */
#define AID_FSVERITY_CERT 1075   /* fs-verity key ownership in keystore */
#define AID_CREDSTORE 1076       /* identity credential manager service */
#define AID_EXTERNAL_STORAGE 1077 /* Full external storage access including USB OTG volumes */
#define AID_EXT_DATA_RW 1078      /* GID for app-private data directories on external storage */
#define AID_EXT_OBB_RW 1079       /* GID for OBB directories on external storage */
#define AID_CONTEXT_HUB 1080      /* GID for access to the Context Hub */
/* Changes to this file must be made in AOSP, *not* in internal branches. */

#define AID_SHELL 2000 /* adb and debug shell user */
#define AID_CACHE 2001 /* cache access */
#define AID_DIAG 2002  /* access to diagnostic resources */

/* The range 2900-2999 is reserved for the vendor partition */
/* Note that the two 'OEM' ranges pre-dated the vendor partition, so they take the legacy 'OEM'
 * name. Additionally, they pre-dated passwd/group files, so there are users and groups named oem_#
 * created automatically for all values in these ranges.  If there is a user/group in a passwd/group
 * file corresponding to this range, both the oem_# and user/group names will resolve to the same
 * value. */
#define AID_OEM_RESERVED_START 2900
#define AID_OEM_RESERVED_END 2999

/* The 3000 series are intended for use as supplemental group id's only.
 * They indicate special Android capabilities that the kernel is aware of. */
#define AID_NET_BT_ADMIN 3001 /* bluetooth: create any socket */
#define AID_NET_BT 3002       /* bluetooth: create sco, rfcomm or l2cap sockets */
#define AID_INET 3003         /* can create AF_INET and AF_INET6 sockets */
#define AID_NET_RAW 3004      /* can create raw INET sockets */
#define AID_NET_ADMIN 3005    /* can configure interfaces and routing tables. */
#define AID_NET_BW_STATS 3006 /* read bandwidth statistics */
#define AID_NET_BW_ACCT 3007  /* change bandwidth statistics accounting */
#define AID_READPROC 3009     /* Allow /proc read access */
#define AID_WAKELOCK 3010     /* Allow system wakelock read/write access */
#define AID_UHID 3011         /* Allow read/write to /dev/uhid node */

/* The range 5000-5999 is also reserved for vendor partition. */
#define AID_OEM_RESERVED_2_START 5000
#define AID_OEM_RESERVED_2_END 5999

/* The range 6000-6499 is reserved for the system partition. */
#define AID_SYSTEM_RESERVED_START 6000
#define AID_SYSTEM_RESERVED_END 6499

/* The range 6500-6999 is reserved for the odm partition. */
#define AID_ODM_RESERVED_START 6500
#define AID_ODM_RESERVED_END 6999

/* The range 7000-7499 is reserved for the product partition. */
#define AID_PRODUCT_RESERVED_START 7000
#define AID_PRODUCT_RESERVED_END 7499

/* The range 7500-7999 is reserved for the system_ext partition. */
#define AID_SYSTEM_EXT_RESERVED_START 7500
#define AID_SYSTEM_EXT_RESERVED_END 7999

#define AID_EVERYBODY 9997 /* shared between all apps in the same profile */
#define AID_MISC 9998      /* access to misc storage */
#define AID_NOBODY 9999

#define AID_APP 10000       /* TODO: switch users over to AID_APP_START */
#define AID_APP_START 10000 /* first app user */
#define AID_APP_END 19999   /* last app user */

#define AID_CACHE_GID_START 20000 /* start of gids for apps to mark cached data */
#define AID_CACHE_GID_END 29999   /* end of gids for apps to mark cached data */

#define AID_EXT_GID_START 30000 /* start of gids for apps to mark external data */
#define AID_EXT_GID_END 39999   /* end of gids for apps to mark external data */

#define AID_EXT_CACHE_GID_START 40000 /* start of gids for apps to mark external cached data */
#define AID_EXT_CACHE_GID_END 49999   /* end of gids for apps to mark external cached data */

#define AID_SHARED_GID_START 50000 /* start of gids for apps in each user to share */
#define AID_SHARED_GID_END 59999   /* end of gids for apps in each user to share */

/*
 * This is a magic number in the kernel and not something that was picked
 * arbitrarily. This value is returned whenever a uid that has no mapping in the
 * user namespace is returned to userspace:
 * https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/highuid.h?h=v4.4#n40
 */
#define AID_OVERFLOWUID 65534 /* unmapped user in the user namespace */

/* use the ranges below to determine whether a process is isolated */
#define AID_ISOLATED_START 90000 /* start of uids for fully isolated sandboxed processes */
#define AID_ISOLATED_END 99999   /* end of uids for fully isolated sandboxed processes */

#define AID_USER 100000        /* TODO: switch users over to AID_USER_OFFSET */
#define AID_USER_OFFSET 100000 /* offset for uid ranges for each user */

/*
 * android_ids has moved to pwd/grp functionality.
 * If you need to add one, the structure is now
 * auto-generated based on the AID_ constraints
 * documented at the top of this header file.
 * Also see build/tools/fs_config for more details.
 */

```

`aosp/mkbootfs.11/src/mkbootfs/headers/private/fs_config.h`:

```h
/*
 * Copyright (C) 2007 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/* This file is used to define the properties of the filesystem
** images generated by build tools (mkbootfs and mkyaffs2image) and
** by the device side of adb.
*/

#pragma once

#include <stdint.h>
#include <sys/cdefs.h>

#if defined(__BIONIC__)
#include <linux/capability.h>
#else  // defined(__BIONIC__)
#include <private/android_filesystem_capability.h>
#endif  // defined(__BIONIC__)

/* Rules for directories and files has moved to system/code/libcutils/fs_config.c */

__BEGIN_DECLS

/*
 * Used in:
 *  build/tools/fs_config/fs_config.c
 *  build/tools/fs_get_stats/fs_get_stats.c
 *  system/extras/ext4_utils/make_ext4fs_main.c
 *  external/squashfs-tools/squashfs-tools/android.c
 *  system/core/cpio/mkbootfs.c
 *  system/core/adb/file_sync_service.cpp
 *  system/extras/ext4_utils/canned_fs_config.c
 */
void fs_config(const char* path, int dir, const char* target_out_path, unsigned* uid, unsigned* gid,
               unsigned* mode, uint64_t* capabilities);

__END_DECLS

```

`aosp/mkbootfs.11/src/mkbootfs/headers/utils/Compat.h`:

```h
/*
 * Copyright (C) 2010 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef __LIB_UTILS_COMPAT_H
#define __LIB_UTILS_COMPAT_H

#include <unistd.h>

#if !defined(__MINGW32__)
#include <sys/mman.h>
#endif

#if defined(__APPLE__)

/* Mac OS has always had a 64-bit off_t, so it doesn't have off64_t. */
static_assert(sizeof(off_t) >= 8, "This code requires that Mac OS have at least a 64-bit off_t.");
typedef off_t off64_t;

static inline void* mmap64(void* addr, size_t length, int prot, int flags, int fd, off64_t offset) {
    return mmap(addr, length, prot, flags, fd, offset);
}

static inline off64_t lseek64(int fd, off64_t offset, int whence) {
    return lseek(fd, offset, whence);
}

static inline ssize_t pread64(int fd, void* buf, size_t nbytes, off64_t offset) {
    return pread(fd, buf, nbytes, offset);
}

static inline ssize_t pwrite64(int fd, const void* buf, size_t nbytes, off64_t offset) {
    return pwrite(fd, buf, nbytes, offset);
}

static inline int ftruncate64(int fd, off64_t length) {
    return ftruncate(fd, length);
}

#endif /* __APPLE__ */

#if defined(_WIN32)
#define O_CLOEXEC O_NOINHERIT
#define O_NOFOLLOW 0
#define DEFFILEMODE 0666
#endif /* _WIN32 */

#define ZD "%zd"
#define ZD_TYPE ssize_t

/*
 * Needed for cases where something should be constexpr if possible, but not
 * being constexpr is fine if in pre-C++11 code (such as a const static float
 * member variable).
 */
#if __cplusplus >= 201103L
#define CONSTEXPR constexpr
#else
#define CONSTEXPR
#endif

/*
 * TEMP_FAILURE_RETRY is defined by some, but not all, versions of
 * <unistd.h>. (Alas, it is not as standard as we'd hoped!) So, if it's
 * not already defined, then define it here.
 */
#ifndef TEMP_FAILURE_RETRY
/* Used to retry syscalls that can return EINTR. */
#define TEMP_FAILURE_RETRY(exp) ({         \
    decltype (exp) _rc;                    \
    do {                                   \
        _rc = (exp);                       \
    } while (_rc == -1 && errno == EINTR); \
    _rc; })
#endif

#if defined(_WIN32)
#define OS_PATH_SEPARATOR '\\'
#else
#define OS_PATH_SEPARATOR '/'
#endif

#endif /* __LIB_UTILS_COMPAT_H */

```

`aosp/security/README`:

```
For detailed information on key types and image signing, please see:

https://source.android.com/devices/tech/ota/sign_builds.html

The test keys in this directory are used in development only and should
NEVER be used to sign packages in publicly released images (as that would
open a major security hole).

key generation
--------------

The following commands were used to generate the test key pairs:

  development/tools/make_key testkey  '/C=US/ST=California/L=Mountain View/O=Android/OU=Android/CN=Android/emailAddress=android@android.com'
  development/tools/make_key platform '/C=US/ST=California/L=Mountain View/O=Android/OU=Android/CN=Android/emailAddress=android@android.com'
  development/tools/make_key shared   '/C=US/ST=California/L=Mountain View/O=Android/OU=Android/CN=Android/emailAddress=android@android.com'
  development/tools/make_key media    '/C=US/ST=California/L=Mountain View/O=Android/OU=Android/CN=Android/emailAddress=android@android.com'

signing using the openssl commandline (for boot/system images)
--------------------------------------------------------------

1. convert pk8 format key to pem format
   % openssl pkcs8 -inform DER -nocrypt -in testkey.pk8 -out testkey.pem

2. create a signature using the pem format key
   % openssl dgst -binary -sha1 -sign testkey.pem FILE > FILE.sig

extracting public keys for embedding
------------------------------------

dumpkey.jar is a Java tool that takes an x.509 certificate in PEM format as
input and prints a C structure to standard output:

    $ java -jar out/host/linux-x86/framework/dumpkey.jar build/target/product/security/testkey.x509.pem
    {64,0xc926ad21,{1795090719,2141396315,950055447,2581568430,4268923165,1920809988,546586521,3498997798,1776797858,3740060814,1805317999,1429410244,129622599,1422441418,1783893377,1222374759,2563319927,323993566,28517732,609753416,1826472888,215237850,4261642700,4049082591,3228462402,774857746,154822455,2497198897,2758199418,3019015328,2794777644,87251430,2534927978,120774784,571297800,3695899472,2479925187,3811625450,3401832990,2394869647,3267246207,950095497,555058928,414729973,1136544882,3044590084,465547824,4058146728,2731796054,1689838846,3890756939,1048029507,895090649,247140249,178744550,3547885223,3165179243,109881576,3944604415,1044303212,3772373029,2985150306,3737520932,3599964420},{3437017481,3784475129,2800224972,3086222688,251333580,2131931323,512774938,325948880,2657486437,2102694287,3820568226,792812816,1026422502,2053275343,2800889200,3113586810,165549746,4273519969,4065247892,1902789247,772932719,3941848426,3652744109,216871947,3164400649,1942378755,3996765851,1055777370,964047799,629391717,2232744317,3910558992,191868569,2758883837,3682816752,2997714732,2702529250,3570700455,3776873832,3924067546,3555689545,2758825434,1323144535,61311905,1997411085,376844204,213777604,4077323584,9135381,1625809335,2804742137,2952293945,1117190829,4237312782,1825108855,3013147971,1111251351,2568837572,1684324211,2520978805,367251975,810756730,2353784344,1175080310}}

This is called by build/core/Makefile to incorporate the OTA signing keys
into the recovery image.

```

`aosp/security/media.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIIEqDCCA5CgAwIBAgIJAPK5jmEjVyxOMA0GCSqGSIb3DQEBBAUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g
VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE
AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0wODA0MTUyMzQwNTdaFw0zNTA5MDEyMzQwNTdaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G
A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI
hvcNAQEBBQADggENADCCAQgCggEBAK4lDFoW75f8KGmsZRsyF8w2ug6GlkFo1YoE
n0DOhYZxI6P/tPbZScM88to6BcI+rKpX2AOImxdZvPWefG8hiQriUIW37VaqYmwJ
ie+czTY2LKDo0blgP9TYModnkmzMCQxot3Wuf/MJNMw2nvKFWiZn3wxmf9DHz12O
umVYBnNzA7tiRybquu37cvB+16dqs8uaOBxLfc2AmxQNiR8AITvkAfWNagamHq3D
qcLxxlZyhbCa4JNCpm+kIer5Ot91c6AowzHXBgGrOvfMhAM+znx3KjpbhrDb6dd3
w6SKqYAe3O4ngVifRNnkETl5YAV2qZQQuoEJElna2YxsaP94S48CAQOjgfwwgfkw
HQYDVR0OBBYEFMopPKqLwO0+VC7vQgWiv/K1fk11MIHJBgNVHSMEgcEwgb6AFMop
PKqLwO0+VC7vQgWiv/K1fk11oYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH
QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG
CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJAPK5jmEjVyxOMAwGA1Ud
EwQFMAMBAf8wDQYJKoZIhvcNAQEEBQADggEBAITelRbV5KhyF6c9qEhwSPUzc6X3
M/OQ1hvfPMnlJRYlv8qnwxWcriddFyqa4eh21UWBJ6xUL2gpDdUQwAKdj1Hg7hVr
e3tazbOUJBuOx4t05cQsXK+uFWyvW9GZojonUk2gct6743hGSlM2MLDk0P+34I7L
cB+ttjecdEZ/bgDG7YiFlTgHkgOHVgB4csjjAHr0I6V6LKs6KChptkxLe9X8GH0K
fiQVll1ark4Hpt91G0p16Xk8kYphK4HNC2KK7gFo3ETkexDTWTJghJ1q321yfcJE
RMIh0/nsw2jK0HmZ8rgQW8HyDTjUEGbMFBHCV6lupDSfV0ZWVQfk6AIKGoE=
-----END CERTIFICATE-----

```

`aosp/security/platform.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIIEqDCCA5CgAwIBAgIJALOZgIbQVs/6MA0GCSqGSIb3DQEBBAUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g
VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE
AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0wODA0MTUyMjQwNTBaFw0zNTA5MDEyMjQwNTBaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G
A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI
hvcNAQEBBQADggENADCCAQgCggEBAJx4BZKsDV04HN6qZezIpgBuNkgMbXIHsSAR
vlCGOqvitV0Amt9xRtbyICKAx81Ne9smJDuKgGwms0sTdSOkkmgiSQTcAUk+fArP
GgXIdPabA3tgMJ2QdNJCgOFrrSqHNDYZUer3KkgtCbIEsYdeEqyYwap3PWgAuer9
5W1Yvtjo2hb5o2AJnDeoNKbf7be2tEoEngeiafzPLFSW8s821k35CjuNjzSjuqtM
9TNxqydxmzulh1StDFP8FOHbRdUeI0+76TybpO35zlQmE1DsU1YHv2mi/0qgfbX3
6iANCabBtJ4hQC+J7RGQiTqrWpGA8VLoL4WkV1PPX8GQccXuyCcCAQOjgfwwgfkw
HQYDVR0OBBYEFE/koLPdnLop9x1yh8Tnw48ghsKZMIHJBgNVHSMEgcEwgb6AFE/k
oLPdnLop9x1yh8Tnw48ghsKZoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH
QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG
CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJALOZgIbQVs/6MAwGA1Ud
EwQFMAMBAf8wDQYJKoZIhvcNAQEEBQADggEBAFclUbjZOh9z3g9tRp+G2tZwFAAp
PIigzXzXeLc9r8wZf6t25iEuVsHHYc/EL9cz3lLFCuCIFM78CjtaGkNGBU2Cnx2C
tCsgSL+ItdFJKe+F9g7dEtctVWV+IuPoXQTIMdYT0Zk4u4mCJH+jISVroS0dao+S
6h2xw3Mxe6DAN/DRr/ZFrvIkl5+6bnoUvAJccbmBOM7z3fwFlhfPJIRc97QNY4L3
J17XOElatuWTG5QhdlxJG3L7aOCA29tYwgKdNHyLMozkPvaosVUz7fvpib1qSN1L
IC7alMarjdW4OZID2q4u1EYjLk/pvZYTlMYwDlE448/Shebk5INTjLixs1c=
-----END CERTIFICATE-----

```

`aosp/security/shared.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIIEqDCCA5CgAwIBAgIJAPKnM5a9OHZ6MA0GCSqGSIb3DQEBBAUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g
VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE
AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0wODA3MjMyMTU3NTlaFw0zNTEyMDkyMTU3NTlaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G
A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI
hvcNAQEBBQADggENADCCAQgCggEBAMjC2/0JSi30XD/xoy7SGAXscvxY0BeXG9D2
tSwmLXCBnRkZZ+FY39Oix/Gz4OgM5UXXnShIIgIR64bw/YMS03tCDBE3UMyUYYro
cvSIZGO9xGJ8qgwEg8hkk+NRVXEXAzi/3MTNat3RwKLzX1zyTtPkBDo+WOKwXmZM
zeEry2dzX9bfEknDaeYlQrwKRynlORf1w4/6UtF7c8nHN5jdsY7UgVkIdVR+Zr/F
2spMJabrlg7ZaSNwnaMCumRstJazJehsXIsuejN3srvkx88zJUKRFj9okVKsCIVQ
yDxQj0v1rfCu1aLcoFg/mrCtF2UNt+6ksj/bRYhVR9D+q3IYOIkCAQOjgfwwgfkw
HQYDVR0OBBYEFMtMfizbs/CtqY2reZaNFy6dux7RMIHJBgNVHSMEgcEwgb6AFMtM
fizbs/CtqY2reZaNFy6dux7RoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH
QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG
CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJAPKnM5a9OHZ6MAwGA1Ud
EwQFMAMBAf8wDQYJKoZIhvcNAQEEBQADggEBAECo0JaZeVnpF6NsRCRra6wrrgVD
fs2JeUEY94NHIDUtHG+KObCGmUL02mWYH6opUdM5cRKewZIdeVZxxSfW4knyUoKf
r1tZExAxHi3gllANVorUEUplbcNKjG9hBFOvwep5ktukqns/hUOm41wHKN53/pfu
rIN3H9DskPjkRJQ07gtgRXg+cMei5GAkkmDgA892CNw1Kkye9wbe9LJgUOl4ri//
16MyN4cBSRXrPMh0/MeprpMId8XIx9HC4qjuhjyJGA0YVc7bpADnukPMyqckPTl+
fA6Ojk19T5K2u+rUnAzwGAae3coufi+0Zo2J2715UNDNJUGA+h6q/CpVb4Q=
-----END CERTIFICATE-----

```

`aosp/security/testkey.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIIEqDCCA5CgAwIBAgIJAJNurL4H8gHfMA0GCSqGSIb3DQEBBQUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g
VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE
AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0wODAyMjkwMTMzNDZaFw0zNTA3MTcwMTMzNDZaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G
A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI
hvcNAQEBBQADggENADCCAQgCggEBANaTGQTexgskse3HYuDZ2CU+Ps1s6x3i/waM
qOi8qM1r03hupwqnbOYOuw+ZNVn/2T53qUPn6D1LZLjk/qLT5lbx4meoG7+yMLV4
wgRDvkxyGLhG9SEVhvA4oU6Jwr44f46+z4/Kw9oe4zDJ6pPQp8PcSvNQIg1QCAcy
4ICXF+5qBTNZ5qaU7Cyz8oSgpGbIepTYOzEJOmc3Li9kEsBubULxWBjf/gOBzAzU
RNps3cO4JFgZSAGzJWQTT7/emMkod0jb9WdqVA2BVMi7yge54kdVMxHEa5r3b97s
zI5p58ii0I54JiCUP5lyfTwE/nKZHZnfm644oLIXf6MdW2r+6R8CAQOjgfwwgfkw
HQYDVR0OBBYEFEhZAFY9JyxGrhGGBaR0GawJyowRMIHJBgNVHSMEgcEwgb6AFEhZ
AFY9JyxGrhGGBaR0GawJyowRoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH
QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG
CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJAJNurL4H8gHfMAwGA1Ud
EwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEBAHqvlozrUMRBBVEY0NqrrwFbinZa
J6cVosK0TyIUFf/azgMJWr+kLfcHCHJsIGnlw27drgQAvilFLAhLwn62oX6snb4Y
LCBOsVMR9FXYJLZW2+TcIkCRLXWG/oiVHQGo/rWuWkJgU134NDEFJCJGjDbiLCpe
+ZTWHdcwauTJ9pUbo8EvHRkU3cYfGmLaLfgn9gP+pWA7LFQNvXwBnDa6sppCccEX
31I828XzgXpJ4O+mDL1/dBd+ek8ZPUP0IgdyZm5MTYPhvVqGCHzzTy3sIeJFymwr
sBbmg2OAUNLEMO6nwmocSdN2ClirfxqCzJOLSDE4QyS9BAH6EhY6UFcOaE0=
-----END CERTIFICATE-----

```

`aosp/security/verity.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIID/TCCAuWgAwIBAgIJAJcPmDkJqolJMA0GCSqGSIb3DQEBBQUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4g
VmlldzEQMA4GA1UECgwHQW5kcm9pZDEQMA4GA1UECwwHQW5kcm9pZDEQMA4GA1UE
AwwHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0xNDExMDYxOTA3NDBaFw00MjAzMjQxOTA3NDBaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91bnRhaW4gVmlldzEQMA4G
A1UECgwHQW5kcm9pZDEQMA4GA1UECwwHQW5kcm9pZDEQMA4GA1UEAwwHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAOjreE0vTVSRenuzO9vnaWfk0eQzYab0gqpi
6xAzi6dmD+ugoEKJmbPiuE5Dwf21isZ9uhUUu0dQM46dK4ocKxMRrcnmGxydFn6o
fs3ODJMXOkv2gKXL/FdbEPdDbxzdu8z3yk+W67udM/fW7WbaQ3DO0knu+izKak/3
T41c5uoXmQ81UNtAzRGzGchNVXMmWuTGOkg6U+0I2Td7K8yvUMWhAWPPpKLtVH9r
AL5TzjYNR92izdKcz3AjRsI3CTjtpiVABGeX0TcjRSuZB7K9EK56HV+OFNS6I1NP
jdD7FIShyGlqqZdUOkAUZYanbpgeT5N7QL6uuqcGpoTOkalu6kkCAwEAAaNQME4w
HQYDVR0OBBYEFH5DM/m7oArf4O3peeKO0ZIEkrQPMB8GA1UdIwQYMBaAFH5DM/m7
oArf4O3peeKO0ZIEkrQPMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEB
AHO3NSvDE5jFvMehGGtS8BnFYdFKRIglDMc4niWSzhzOVYRH4WajxdtBWc5fx0ix
NF/+hVKVhP6AIOQa+++sk+HIi7RvioPPbhjcsVlZe7cUEGrLSSveGouQyc+j0+m6
JF84kszIl5GGNMTnx0XRPO+g8t6h5LWfnVydgZfpGRRg+WHewk1U2HlvTjIceb0N
dcoJ8WKJAFWdcuE7VIm4w+vF/DYX/A2Oyzr2+QRhmYSv1cusgAeC1tvH4ap+J1Lg
UnOu5Kh/FqPLLSwNVQp4Bu7b9QFfqK8Moj84bj88NqRGZgDyqzuTrFxn6FW7dmyA
yttuAJAEAymk1mipd9+zp38=
-----END CERTIFICATE-----

```

`aosp/system/libufdt/utils/src/mkdtboimg.py`:

```py
#! /usr/bin/env python3
# Copyright 2017, The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function

"""Tool for packing multiple DTB/DTBO files into a single image"""

import argparse
import fnmatch
import os
import struct
import zlib
from array import array
from collections import namedtuple
from sys import stdout

class CompressionFormat(object):
    """Enum representing DT compression format for a DT entry.
    """
    NO_COMPRESSION = 0x00
    ZLIB_COMPRESSION = 0x01
    GZIP_COMPRESSION = 0x02

class DtEntry(object):
    """Provides individual DT image file arguments to be added to a DTBO.

    Attributes:
        REQUIRED_KEYS_V0: 'keys' needed to be present in the dictionary passed to instantiate
            an object of this class when a DTBO header of version 0 is used.
        REQUIRED_KEYS_V1: 'keys' needed to be present in the dictionary passed to instantiate
            an object of this class when a DTBO header of version 1 is used.
        COMPRESSION_FORMAT_MASK: Mask to retrieve compression info for DT entry from flags field
            when a DTBO header of version 1 is used.
    """
    COMPRESSION_FORMAT_MASK = 0x0f
    REQUIRED_KEYS_V0 = ('dt_file', 'dt_size', 'dt_offset', 'id', 'rev',
                     'custom0', 'custom1', 'custom2', 'custom3')
    REQUIRED_KEYS_V1 = ('dt_file', 'dt_size', 'dt_offset', 'id', 'rev',
                     'flags', 'custom0', 'custom1', 'custom2')

    @staticmethod
    def __get_number_or_prop(arg):
        """Converts string to integer or reads the property from DT image.

        Args:
            arg: String containing the argument provided on the command line.

        Returns:
            An integer property read from DT file or argument string
            converted to integer
        """

        if not arg or arg[0] == '+' or arg[0] == '-':
            raise ValueError('Invalid argument passed to DTImage')
        if arg[0] == '/':
            # TODO(b/XXX): Use pylibfdt to get property value from DT
            raise ValueError('Invalid argument passed to DTImage')
        else:
            base = 10
            if arg.startswith('0x') or arg.startswith('0X'):
                base = 16
            elif arg.startswith('0'):
                base = 8
            return int(arg, base)

    def __init__(self, **kwargs):
        """Constructor for DtEntry object.

        Initializes attributes from dictionary object that contains
        values keyed with names equivalent to the class's attributes.

        Args:
            kwargs: Dictionary object containing values to instantiate
                class members with. Expected keys in dictionary are from
                the tuple (_REQUIRED_KEYS)
        """

        self.__version = kwargs['version']
        required_keys = None
        if self.__version == 0:
            required_keys = self.REQUIRED_KEYS_V0
        elif self.__version == 1:
            required_keys = self.REQUIRED_KEYS_V1

        missing_keys = set(required_keys) - set(kwargs)
        if missing_keys:
            raise ValueError('Missing keys in DtEntry constructor: %r' %
                             sorted(missing_keys))

        self.__dt_file = kwargs['dt_file']
        self.__dt_offset = kwargs['dt_offset']
        self.__dt_size = kwargs['dt_size']
        self.__id = self.__get_number_or_prop(kwargs['id'])
        self.__rev = self.__get_number_or_prop(kwargs['rev'])
        if self.__version == 1:
            self.__flags = self.__get_number_or_prop(kwargs['flags'])
        self.__custom0 = self.__get_number_or_prop(kwargs['custom0'])
        self.__custom1 = self.__get_number_or_prop(kwargs['custom1'])
        self.__custom2 = self.__get_number_or_prop(kwargs['custom2'])
        if self.__version == 0:
            self.__custom3 = self.__get_number_or_prop(kwargs['custom3'])

    def __str__(self):
        sb = []
        sb.append('{key:>20} = {value:d}'.format(key='dt_size',
                                                 value=self.__dt_size))
        sb.append('{key:>20} = {value:d}'.format(key='dt_offset',
                                                 value=self.__dt_offset))
        sb.append('{key:>20} = {value:08x}'.format(key='id',
                                                   value=self.__id))
        sb.append('{key:>20} = {value:08x}'.format(key='rev',
                                                   value=self.__rev))
        if self.__version == 1:
            sb.append('{key:>20} = {value:08x}'.format(key='flags',
                                                       value=self.__flags))
        sb.append('{key:>20} = {value:08x}'.format(key='custom[0]',
                                                   value=self.__custom0))
        sb.append('{key:>20} = {value:08x}'.format(key='custom[1]',
                                                   value=self.__custom1))
        sb.append('{key:>20} = {value:08x}'.format(key='custom[2]',
                                                   value=self.__custom2))
        if self.__version == 0:
            sb.append('{key:>20} = {value:08x}'.format(key='custom[3]',
                                                       value=self.__custom3))
        return '\n'.join(sb)

    def compression_info(self):
        """CompressionFormat: compression format for DT image file.

           Args:
                version: Version of DTBO header, compression is only
                         supported from version 1.
        """
        if self.__version == 0:
            return CompressionFormat.NO_COMPRESSION
        return self.flags & self.COMPRESSION_FORMAT_MASK

    @property
    def dt_file(self):
        """file: File handle to the DT image file."""
        return self.__dt_file

    @property
    def size(self):
        """int: size in bytes of the DT image file."""
        return self.__dt_size

    @size.setter
    def size(self, value):
        self.__dt_size = value

    @property
    def dt_offset(self):
        """int: offset in DTBO file for this DT image."""
        return self.__dt_offset

    @dt_offset.setter
    def dt_offset(self, value):
        self.__dt_offset = value

    @property
    def image_id(self):
        """int: DT entry _id for this DT image."""
        return self.__id

    @property
    def rev(self):
        """int: DT entry _rev for this DT image."""
        return self.__rev

    @property
    def flags(self):
        """int: DT entry _flags for this DT image."""
        return self.__flags

    @property
    def custom0(self):
        """int: DT entry _custom0 for this DT image."""
        return self.__custom0

    @property
    def custom1(self):
        """int: DT entry _custom1 for this DT image."""
        return self.__custom1

    @property
    def custom2(self):
        """int: DT entry custom2 for this DT image."""
        return self.__custom2

    @property
    def custom3(self):
        """int: DT entry custom3 for this DT image."""
        return self.__custom3

class Dtbo(object):
    """
    Provides parser, reader, writer for dumping and creating Device Tree Blob
    Overlay (DTBO) images.

    Attributes:
        _DTBO_MAGIC: Device tree table header magic.
        _ACPIO_MAGIC: Advanced Configuration and Power Interface table header
                      magic.
        _DT_TABLE_HEADER_SIZE: Size of Device tree table header.
        _DT_TABLE_HEADER_INTS: Number of integers in DT table header.
        _DT_ENTRY_HEADER_SIZE: Size of Device tree entry header within a DTBO.
        _DT_ENTRY_HEADER_INTS: Number of integers in DT entry header.
        _GZIP_COMPRESSION_WBITS: Argument 'wbits' for gzip compression
        _ZLIB_DECOMPRESSION_WBITS: Argument 'wbits' for zlib/gzip compression
    """

    _DTBO_MAGIC = 0xd7b7ab1e
    _ACPIO_MAGIC = 0x41435049
    _DT_TABLE_HEADER_SIZE = struct.calcsize('>8I')
    _DT_TABLE_HEADER_INTS = 8
    _DT_ENTRY_HEADER_SIZE = struct.calcsize('>8I')
    _DT_ENTRY_HEADER_INTS = 8
    _GZIP_COMPRESSION_WBITS = 31
    _ZLIB_DECOMPRESSION_WBITS = 47

    def _update_dt_table_header(self):
        """Converts header entries into binary data for DTBO header.

        Packs the current Device tree table header attribute values in
        metadata buffer.
        """
        struct.pack_into('>8I', self.__metadata, 0, self.magic,
                         self.total_size, self.header_size,
                         self.dt_entry_size, self.dt_entry_count,
                         self.dt_entries_offset, self.page_size,
                         self.version)

    def _update_dt_entry_header(self, dt_entry, metadata_offset):
        """Converts each DT entry header entry into binary data for DTBO file.

        Packs the current device tree table entry attribute into
        metadata buffer as device tree entry header.

        Args:
            dt_entry: DtEntry object for the header to be packed.
            metadata_offset: Offset into metadata buffer to begin writing.
            dtbo_offset: Offset where the DT image file for this dt_entry can
                be found in the resulting DTBO image.
        """
        if self.version == 0:
            struct.pack_into('>8I', self.__metadata, metadata_offset, dt_entry.size,
                             dt_entry.dt_offset, dt_entry.image_id, dt_entry.rev,
                             dt_entry.custom0, dt_entry.custom1, dt_entry.custom2,
                             dt_entry.custom3)
        elif self.version == 1:
            struct.pack_into('>8I', self.__metadata, metadata_offset, dt_entry.size,
                             dt_entry.dt_offset, dt_entry.image_id, dt_entry.rev,
                             dt_entry.flags, dt_entry.custom0, dt_entry.custom1,
                             dt_entry.custom2)


    def _update_metadata(self):
        """Updates the DTBO metadata.

        Initialize the internal metadata buffer and fill it with all Device
        Tree table entries and update the DTBO header.
        """

        self.__metadata = array('b', b' ' * self.__metadata_size)
        metadata_offset = self.header_size
        for dt_entry in self.__dt_entries:
            self._update_dt_entry_header(dt_entry, metadata_offset)
            metadata_offset += self.dt_entry_size
        self._update_dt_table_header()

    def _read_dtbo_header(self, buf):
        """Reads DTBO file header into metadata buffer.

        Unpack and read the DTBO table header from given buffer. The
        buffer size must exactly be equal to _DT_TABLE_HEADER_SIZE.

        Args:
            buf: Bytebuffer read directly from the file of size
                _DT_TABLE_HEADER_SIZE.
        """
        (self.magic, self.total_size, self.header_size,
         self.dt_entry_size, self.dt_entry_count, self.dt_entries_offset,
         self.page_size, self.version) = struct.unpack_from('>8I', buf, 0)

        # verify the header
        if self.magic != self._DTBO_MAGIC and self.magic != self._ACPIO_MAGIC:
            raise ValueError('Invalid magic number 0x%x in DTBO/ACPIO file' %
                             (self.magic))

        if self.header_size != self._DT_TABLE_HEADER_SIZE:
            raise ValueError('Invalid header size (%d) in DTBO/ACPIO file' %
                             (self.header_size))

        if self.dt_entry_size != self._DT_ENTRY_HEADER_SIZE:
            raise ValueError('Invalid DT entry header size (%d) in DTBO/ACPIO file' %
                             (self.dt_entry_size))

    def _read_dt_entries_from_metadata(self):
        """Reads individual DT entry headers from metadata buffer.

        Unpack and read the DTBO DT entry headers from the internal buffer.
        The buffer size must exactly be equal to _DT_TABLE_HEADER_SIZE +
        (_DT_ENTRY_HEADER_SIZE * dt_entry_count). The method raises exception
        if DT entries have already been set for this object.
        """

        if self.__dt_entries:
            raise ValueError('DTBO DT entries can be added only once')

        offset = self.dt_entries_offset // 4
        params = {}
        params['version'] = self.version
        params['dt_file'] = None
        for i in range(0, self.dt_entry_count):
            dt_table_entry = self.__metadata[offset:offset + self._DT_ENTRY_HEADER_INTS]
            params['dt_size'] = dt_table_entry[0]
            params['dt_offset'] = dt_table_entry[1]
            for j in range(2, self._DT_ENTRY_HEADER_INTS):
                required_keys = None
                if self.version == 0:
                    required_keys = DtEntry.REQUIRED_KEYS_V0
                elif self.version == 1:
                    required_keys = DtEntry.REQUIRED_KEYS_V1
                params[required_keys[j + 1]] = str(dt_table_entry[j])
            dt_entry = DtEntry(**params)
            self.__dt_entries.append(dt_entry)
            offset += self._DT_ENTRY_HEADER_INTS

    def _read_dtbo_image(self):
        """Parse the input file and instantiate this object."""

        # First check if we have enough to read the header
        file_size = os.fstat(self.__file.fileno()).st_size
        if file_size < self._DT_TABLE_HEADER_SIZE:
            raise ValueError('Invalid DTBO file')

        self.__file.seek(0)
        buf = self.__file.read(self._DT_TABLE_HEADER_SIZE)
        self._read_dtbo_header(buf)

        self.__metadata_size = (self.header_size +
                                self.dt_entry_count * self.dt_entry_size)
        if file_size < self.__metadata_size:
            raise ValueError('Invalid or truncated DTBO file of size %d expected %d' %
                             file_size, self.__metadata_size)

        num_ints = (self._DT_TABLE_HEADER_INTS +
                    self.dt_entry_count * self._DT_ENTRY_HEADER_INTS)
        if self.dt_entries_offset > self._DT_TABLE_HEADER_SIZE:
            num_ints += (self.dt_entries_offset - self._DT_TABLE_HEADER_SIZE) / 4
        format_str = '>' + str(num_ints) + 'I'
        self.__file.seek(0)
        self.__metadata = struct.unpack(format_str,
                                        self.__file.read(self.__metadata_size))
        self._read_dt_entries_from_metadata()

    def _find_dt_entry_with_same_file(self, dt_entry):
        """Finds DT Entry that has identical backing DT file.

        Args:
            dt_entry: DtEntry object whose 'dtfile' we find for existence in the
                current 'dt_entries'.
        Returns:
            If a match by file path is found, the corresponding DtEntry object
            from internal list is returned. If not, 'None' is returned.
        """

        dt_entry_path = os.path.realpath(dt_entry.dt_file.name)
        for entry in self.__dt_entries:
            entry_path = os.path.realpath(entry.dt_file.name)
            if entry_path == dt_entry_path:
                return entry
        return None

    def __init__(self, file_handle, dt_type='dtb', page_size=None, version=0):
        """Constructor for Dtbo Object

        Args:
            file_handle: The Dtbo File handle corresponding to this object.
                The file handle can be used to write to (in case of 'create')
                or read from (in case of 'dump')
        """

        self.__file = file_handle
        self.__dt_entries = []
        self.__metadata = None
        self.__metadata_size = 0

        # if page_size is given, assume the object is being instantiated to
        # create a DTBO file
        if page_size:
            if dt_type == 'acpi':
                self.magic = self._ACPIO_MAGIC
            else:
                self.magic = self._DTBO_MAGIC
            self.total_size = self._DT_TABLE_HEADER_SIZE
            self.header_size = self._DT_TABLE_HEADER_SIZE
            self.dt_entry_size = self._DT_ENTRY_HEADER_SIZE
            self.dt_entry_count = 0
            self.dt_entries_offset = self._DT_TABLE_HEADER_SIZE
            self.page_size = page_size
            self.version = version
            self.__metadata_size = self._DT_TABLE_HEADER_SIZE
        else:
            self._read_dtbo_image()

    def __str__(self):
        sb = []
        sb.append('dt_table_header:')
        _keys = ('magic', 'total_size', 'header_size', 'dt_entry_size',
                 'dt_entry_count', 'dt_entries_offset', 'page_size', 'version')
        for key in _keys:
            if key == 'magic':
                sb.append('{key:>20} = {value:08x}'.format(key=key,
                                                           value=self.__dict__[key]))
            else:
                sb.append('{key:>20} = {value:d}'.format(key=key,
                                                         value=self.__dict__[key]))
        count = 0
        for dt_entry in self.__dt_entries:
            sb.append('dt_table_entry[{0:d}]:'.format(count))
            sb.append(str(dt_entry))
            count = count + 1
        return '\n'.join(sb)

    @property
    def dt_entries(self):
        """Returns a list of DtEntry objects found in DTBO file."""
        return self.__dt_entries

    def compress_dt_entry(self, compression_format, dt_entry_file):
        """Compresses a DT entry.

        Args:
            compression_format: Compression format for DT Entry
            dt_entry_file: File handle to read DT entry from.

        Returns:
            Compressed DT entry and its length.

        Raises:
            ValueError if unrecognized compression format is found.
        """
        compress_zlib = zlib.compressobj()  #  zlib
        compress_gzip = zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION,
                                         zlib.DEFLATED, self._GZIP_COMPRESSION_WBITS)  #  gzip
        compression_obj_dict = {
            CompressionFormat.NO_COMPRESSION: None,
            CompressionFormat.ZLIB_COMPRESSION: compress_zlib,
            CompressionFormat.GZIP_COMPRESSION: compress_gzip,
        }

        if compression_format not in compression_obj_dict:
            ValueError("Bad compression format %d" % compression_format)

        if compression_format is CompressionFormat.NO_COMPRESSION:
            dt_entry = dt_entry_file.read()
        else:
            compression_object = compression_obj_dict[compression_format]
            dt_entry_file.seek(0)
            dt_entry = compression_object.compress(dt_entry_file.read())
            dt_entry += compression_object.flush()
        return dt_entry, len(dt_entry)

    def add_dt_entries(self, dt_entries):
        """Adds DT image files to the DTBO object.

        Adds a list of Dtentry Objects to the DTBO image. The changes are not
        committed to the output file until commit() is called.

        Args:
            dt_entries: List of DtEntry object to be added.

        Returns:
            A buffer containing all DT entries.

        Raises:
            ValueError: if the list of DT entries is empty or if a list of DT entries
                has already been added to the DTBO.
        """
        if not dt_entries:
            raise ValueError('Attempted to add empty list of DT entries')

        if self.__dt_entries:
            raise ValueError('DTBO DT entries can be added only once')

        dt_entry_count = len(dt_entries)
        dt_offset = (self.header_size +
                     dt_entry_count * self.dt_entry_size)

        dt_entry_buf = b""
        for dt_entry in dt_entries:
            if not isinstance(dt_entry, DtEntry):
                raise ValueError('Adding invalid DT entry object to DTBO')
            entry = self._find_dt_entry_with_same_file(dt_entry)
            dt_entry_compression_info = dt_entry.compression_info()
            if entry and (entry.compression_info() == dt_entry_compression_info):
                dt_entry.dt_offset = entry.dt_offset
                dt_entry.size = entry.size
            else:
                dt_entry.dt_offset = dt_offset
                compressed_entry, dt_entry.size = self.compress_dt_entry(dt_entry_compression_info,
                                                                         dt_entry.dt_file)
                dt_entry_buf += compressed_entry
                dt_offset += dt_entry.size
                self.total_size += dt_entry.size
            self.__dt_entries.append(dt_entry)
            self.dt_entry_count += 1
            self.__metadata_size += self.dt_entry_size
            self.total_size += self.dt_entry_size

        return dt_entry_buf

    def extract_dt_file(self, idx, fout, decompress):
        """Extract DT Image files embedded in the DTBO file.

        Extracts Device Tree blob image file at given index into a file handle.

        Args:
            idx: Index of the DT entry in the DTBO file.
            fout: File handle where the DTB at index idx to be extracted into.
            decompress: If a DT entry is compressed, decompress it before writing
                it to the file handle.

        Raises:
            ValueError: if invalid DT entry index or compression format is detected.
        """
        if idx > self.dt_entry_count:
            raise ValueError('Invalid index %d of DtEntry' % idx)

        size = self.dt_entries[idx].size
        offset = self.dt_entries[idx].dt_offset
        self.__file.seek(offset, 0)
        fout.seek(0)
        compression_format = self.dt_entries[idx].compression_info()
        if decompress and compression_format:
            if (compression_format == CompressionFormat.ZLIB_COMPRESSION or
                compression_format == CompressionFormat.GZIP_COMPRESSION):
                fout.write(zlib.decompress(self.__file.read(size), self._ZLIB_DECOMPRESSION_WBITS))
            else:
                raise ValueError("Unknown compression format detected")
        else:
            fout.write(self.__file.read(size))

    def commit(self, dt_entry_buf):
        """Write out staged changes to the DTBO object to create a DTBO file.

        Writes a fully instantiated Dtbo Object into the output file using the
        file handle present in '_file'. No checks are performed on the object
        except for existence of output file handle on the object before writing
        out the file.

        Args:
            dt_entry_buf: Buffer containing all DT entries.
        """
        if not self.__file:
            raise ValueError('No file given to write to.')

        if not self.__dt_entries:
            raise ValueError('No DT image files to embed into DTBO image given.')

        self._update_metadata()

        self.__file.seek(0)
        self.__file.write(self.__metadata)
        self.__file.write(dt_entry_buf)
        self.__file.flush()


def parse_dt_entry(global_args, arglist):
    """Parse arguments for single DT entry file.

    Parses command line arguments for single DT image file while
    creating a Device tree blob overlay (DTBO).

    Args:
        global_args: Dtbo object containing global default values
            for DtEntry attributes.
        arglist: Command line argument list for this DtEntry.

    Returns:
        A Namespace object containing all values to instantiate DtEntry object.
    """

    parser = argparse.ArgumentParser(add_help=False)
    parser.add_argument('dt_file', nargs='?',
                        type=argparse.FileType('rb'),
                        default=None)
    parser.add_argument('--id', type=str, dest='id', action='store',
                        default=global_args.global_id)
    parser.add_argument('--rev', type=str, dest='rev',
                        action='store', default=global_args.global_rev)
    parser.add_argument('--flags', type=str, dest='flags',
                        action='store',
                        default=global_args.global_flags)
    parser.add_argument('--custom0', type=str, dest='custom0',
                        action='store',
                        default=global_args.global_custom0)
    parser.add_argument('--custom1', type=str, dest='custom1',
                        action='store',
                        default=global_args.global_custom1)
    parser.add_argument('--custom2', type=str, dest='custom2',
                        action='store',
                        default=global_args.global_custom2)
    parser.add_argument('--custom3', type=str, dest='custom3',
                        action='store',
                        default=global_args.global_custom3)
    return parser.parse_args(arglist)


def parse_dt_entries(global_args, arg_list):
    """Parse all DT entries from command line.

    Parse all DT image files and their corresponding attribute from
    command line

    Args:
        global_args: Argument containing default global values for _id,
            _rev and customX.
        arg_list: The remainder of the command line after global options
            DTBO creation have been parsed.

    Returns:
        A List of DtEntry objects created after parsing the command line
        given in argument.
    """
    dt_entries = []
    img_file_idx = []
    idx = 0
    # find all positional arguments (i.e. DT image file paths)
    for arg in arg_list:
        if not arg.startswith("--"):
            img_file_idx.append(idx)
        idx = idx + 1

    if not img_file_idx:
        raise ValueError('Input DT images must be provided')

    total_images = len(img_file_idx)
    for idx in range(total_images):
        start_idx = img_file_idx[idx]
        if idx == total_images - 1:
            argv = arg_list[start_idx:]
        else:
            end_idx = img_file_idx[idx + 1]
            argv = arg_list[start_idx:end_idx]
        args = parse_dt_entry(global_args, argv)
        params = vars(args)
        params['version'] = global_args.version
        params['dt_offset'] = 0
        params['dt_size'] = os.fstat(params['dt_file'].fileno()).st_size
        dt_entries.append(DtEntry(**params))

    return dt_entries

def parse_config_option(line, is_global, dt_keys, global_key_types):
    """Parses a single line from the configuration file.

    Args:
        line: String containing the key=value line from the file.
        is_global: Boolean indicating if we should parse global or DT entry
            specific option.
        dt_keys: Tuple containing all valid DT entry and global option strings
            in configuration file.
        global_key_types: A dict of global options and their corresponding types. It
            contains all exclusive valid global option strings in configuration
            file that are not repeated in dt entry options.

    Returns:
        Returns a tuple for parsed key and value for the option. Also, checks
        the key to make sure its valid.
    """

    if line.find('=') == -1:
        raise ValueError('Invalid line (%s) in configuration file' % line)

    key, value = (x.strip() for x in line.split('='))
    if is_global and key in global_key_types:
        if global_key_types[key] is int:
            value = int(value)
    elif key not in dt_keys:
        raise ValueError('Invalid option (%s) in configuration file' % key)

    return key, value

def parse_config_file(fin, dt_keys, global_key_types):
    """Parses the configuration file for creating DTBO image.

    Args:
        fin: File handle for configuration file
        is_global: Boolean indicating if we should parse global or DT entry
            specific option.
        dt_keys: Tuple containing all valid DT entry and global option strings
            in configuration file.
        global_key_types: A dict of global options and their corresponding types. It
            contains all exclusive valid global option strings in configuration
            file that are not repeated in dt entry options.

    Returns:
        global_args, dt_args: Tuple of a dictionary with global arguments
        and a list of dictionaries for all DT entry specific arguments the
        following format.
            global_args:
                {'id' : <value>, 'rev' : <value> ...}
            dt_args:
                [{'filename' : 'dt_file_name', 'id' : <value>,
                 'rev' : <value> ...},
                 {'filename' : 'dt_file_name2', 'id' : <value2>,
                  'rev' : <value2> ...}, ...
                ]
    """

    # set all global defaults
    global_args = dict((k, '0') for k in dt_keys)
    global_args['dt_type'] = 'dtb'
    global_args['page_size'] = 2048
    global_args['version'] = 0

    dt_args = []
    found_dt_entry = False
    count = -1
    for line in fin:
        line = line.rstrip()
        if line.lstrip().startswith('#'):
            continue
        comment_idx = line.find('#')
        line = line if comment_idx == -1 else line[0:comment_idx]
        if not line or line.isspace():
            continue
        if line.startswith((' ', '\t')) and not found_dt_entry:
            # This is a global argument
            key, value = parse_config_option(line, True, dt_keys, global_key_types)
            global_args[key] = value
        elif line.find('=') != -1:
            key, value = parse_config_option(line, False, dt_keys, global_key_types)
            dt_args[-1][key] = value
        else:
            found_dt_entry = True
            count += 1
            dt_args.append({})
            dt_args[-1]['filename'] = line.strip()
    return global_args, dt_args

def parse_create_args(arg_list):
    """Parse command line arguments for 'create' sub-command.

    Args:
        arg_list: All command line arguments except the outfile file name.

    Returns:
        The list of remainder of the command line arguments after parsing
        for 'create'.
    """

    image_arg_index = 0
    for arg in arg_list:
        if not arg.startswith("--"):
            break
        image_arg_index = image_arg_index + 1

    argv = arg_list[0:image_arg_index]
    remainder = arg_list[image_arg_index:]
    parser = argparse.ArgumentParser(prog='create', add_help=False)
    parser.add_argument('--dt_type', type=str, dest='dt_type',
                        action='store', default='dtb')
    parser.add_argument('--page_size', type=int, dest='page_size',
                        action='store', default=2048)
    parser.add_argument('--version', type=int, dest='version',
                        action='store', default=0)
    parser.add_argument('--id', type=str, dest='global_id',
                        action='store', default='0')
    parser.add_argument('--rev', type=str, dest='global_rev',
                        action='store', default='0')
    parser.add_argument('--flags', type=str, dest='global_flags',
                        action='store', default='0')
    parser.add_argument('--custom0', type=str, dest='global_custom0',
                        action='store', default='0')
    parser.add_argument('--custom1', type=str, dest='global_custom1',
                        action='store', default='0')
    parser.add_argument('--custom2', type=str, dest='global_custom2',
                        action='store', default='0')
    parser.add_argument('--custom3', type=str, dest='global_custom3',
                        action='store', default='0')
    args = parser.parse_args(argv)
    return args, remainder

def parse_dump_cmd_args(arglist):
    """Parse command line arguments for 'dump' sub-command.

    Args:
        arglist: List of all command line arguments including the outfile
            file name if exists.

    Returns:
        A namespace object of parsed arguments.
    """

    parser = argparse.ArgumentParser(prog='dump')
    parser.add_argument('--output', '-o', nargs='?',
                        type=argparse.FileType('w'),
                        dest='outfile',
                        default=stdout)
    parser.add_argument('--dtb', '-b', nargs='?', type=str,
                        dest='dtfilename')
    parser.add_argument('--decompress', action='store_true', dest='decompress')
    return parser.parse_args(arglist)

def parse_config_create_cmd_args(arglist):
    """Parse command line arguments for 'cfg_create subcommand.

    Args:
        arglist: A list of all command line arguments including the
            mandatory input configuration file name.

    Returns:
        A Namespace object of parsed arguments.
    """
    parser = argparse.ArgumentParser(prog='cfg_create')
    parser.add_argument('conf_file', nargs='?',
                        type=argparse.FileType('r'),
                        default=None)
    cwd = os.getcwd()
    parser.add_argument('--dtb-dir', '-d', nargs='?', type=str,
                        dest='dtbdir', default=cwd)
    return parser.parse_args(arglist)

def create_dtbo_image(fout, argv):
    """Create Device Tree Blob Overlay image using provided arguments.

    Args:
        fout: Output file handle to write to.
        argv: list of command line arguments.
    """

    global_args, remainder = parse_create_args(argv)
    if not remainder:
        raise ValueError('List of dtimages to add to DTBO not provided')
    dt_entries = parse_dt_entries(global_args, remainder)
    dtbo = Dtbo(fout, global_args.dt_type, global_args.page_size, global_args.version)
    dt_entry_buf = dtbo.add_dt_entries(dt_entries)
    dtbo.commit(dt_entry_buf)
    fout.close()

def dump_dtbo_image(fin, argv):
    """Dump DTBO file.

    Dump Device Tree Blob Overlay metadata as output and the device
    tree image files embedded in the DTBO image into file(s) provided
    as arguments

    Args:
        fin: Input DTBO image files.
        argv: list of command line arguments.
    """
    dtbo = Dtbo(fin)
    args = parse_dump_cmd_args(argv)
    if args.dtfilename:
        num_entries = len(dtbo.dt_entries)
        for idx in range(0, num_entries):
            with open(args.dtfilename + '.{:d}'.format(idx), 'wb') as fout:
                dtbo.extract_dt_file(idx, fout, args.decompress)
    args.outfile.write(str(dtbo) + '\n')
    args.outfile.close()

def create_dtbo_image_from_config(fout, argv):
    """Create DTBO file from a configuration file.

    Args:
        fout: Output file handle to write to.
        argv: list of command line arguments.
    """
    args = parse_config_create_cmd_args(argv)
    if not args.conf_file:
        raise ValueError('Configuration file must be provided')

    _DT_KEYS = ('id', 'rev', 'flags', 'custom0', 'custom1', 'custom2', 'custom3')
    _GLOBAL_KEY_TYPES = {'dt_type': str, 'page_size': int, 'version': int}

    global_args, dt_args = parse_config_file(args.conf_file,
                                             _DT_KEYS, _GLOBAL_KEY_TYPES)
    version = global_args['version']

    params = {}
    params['version'] = version
    dt_entries = []
    for dt_arg in dt_args:
        filepath = dt_arg['filename']
        if not os.path.isabs(filepath):
            for root, dirnames, filenames in os.walk(args.dtbdir):
                for filename in fnmatch.filter(filenames, os.path.basename(filepath)):
                    filepath = os.path.join(root, filename)
        params['dt_file'] = open(filepath, 'rb')
        params['dt_offset'] = 0
        params['dt_size'] = os.fstat(params['dt_file'].fileno()).st_size
        for key in _DT_KEYS:
            if key not in dt_arg:
                params[key] = global_args[key]
            else:
                params[key] = dt_arg[key]
        dt_entries.append(DtEntry(**params))

    # Create and write DTBO file
    dtbo = Dtbo(fout, global_args['dt_type'], global_args['page_size'], version)
    dt_entry_buf = dtbo.add_dt_entries(dt_entries)
    dtbo.commit(dt_entry_buf)
    fout.close()

def print_default_usage(progname):
    """Prints program's default help string.

    Args:
        progname: This program's name.
    """
    sb = []
    sb.append('  ' + progname + ' help all')
    sb.append('  ' + progname + ' help <command>\n')
    sb.append('    commands:')
    sb.append('      help, dump, create, cfg_create')
    print('\n'.join(sb))

def print_dump_usage(progname):
    """Prints usage for 'dump' sub-command.

    Args:
        progname: This program's name.
    """
    sb = []
    sb.append('  ' + progname + ' dump <image_file> (<option>...)\n')
    sb.append('    options:')
    sb.append('      -o, --output <filename>  Output file name.')
    sb.append('                               Default is output to stdout.')
    sb.append('      -b, --dtb <filename>     Dump dtb/dtbo files from image.')
    sb.append('                               Will output to <filename>.0, <filename>.1, etc.')
    print('\n'.join(sb))

def print_create_usage(progname):
    """Prints usage for 'create' subcommand.

    Args:
        progname: This program's name.
    """
    sb = []
    sb.append('  ' + progname + ' create <image_file> (<global_option>...) (<dtb_file> (<entry_option>...) ...)\n')
    sb.append('    global_options:')
    sb.append('      --dt_type=<type>         Device Tree Type (dtb|acpi). Default: dtb')
    sb.append('      --page_size=<number>     Page size. Default: 2048')
    sb.append('      --version=<number>       DTBO/ACPIO version. Default: 0')
    sb.append('      --id=<number>       The default value to set property id in dt_table_entry. Default: 0')
    sb.append('      --rev=<number>')
    sb.append('      --flags=<number>')
    sb.append('      --custom0=<number>')
    sb.append('      --custom1=<number>')
    sb.append('      --custom2=<number>\n')
    sb.append('      --custom3=<number>\n')

    sb.append('      The value could be a number or a DT node path.')
    sb.append('      <number> could be a 32-bits digit or hex value, ex. 68000, 0x6800.')
    sb.append('      <path> format is <full_node_path>:<property_name>, ex. /board/:id,')
    sb.append('      will read the value in given FTB file with the path.')
    print('\n'.join(sb))

def print_cfg_create_usage(progname):
    """Prints usage for 'cfg_create' sub-command.

    Args:
        progname: This program's name.
    """
    sb = []
    sb.append('  ' + progname + ' cfg_create <image_file> <config_file> (<option>...)\n')
    sb.append('    options:')
    sb.append('      -d, --dtb-dir <dir>      The path to load dtb files.')
    sb.append('                               Default is load from the current path.')
    print('\n'.join(sb))

def print_usage(cmd, _):
    """Prints usage for this program.

    Args:
        cmd: The string sub-command for which help (usage) is requested.
    """
    prog_name = os.path.basename(__file__)
    if not cmd:
        print_default_usage(prog_name)
        return

    HelpCommand = namedtuple('HelpCommand', 'help_cmd, help_func')
    help_commands = (HelpCommand('dump', print_dump_usage),
                     HelpCommand('create', print_create_usage),
                     HelpCommand('cfg_create', print_cfg_create_usage),
                     )

    if cmd == 'all':
        print_default_usage(prog_name)

    for help_cmd, help_func in help_commands:
        if cmd == 'all' or cmd == help_cmd:
            help_func(prog_name)
            if cmd != 'all':
                return

    print('Unsupported help command: %s' % cmd, end='\n\n')
    print_default_usage(prog_name)
    return

def main():
    """Main entry point for mkdtboimg."""

    parser = argparse.ArgumentParser()

    subparser = parser.add_subparsers(title='subcommand',
                                      description='Valid subcommands')

    create_parser = subparser.add_parser('create', add_help=False)
    create_parser.add_argument('argfile', nargs='?',
                               action='store', help='Output File',
                               type=argparse.FileType('wb'))
    create_parser.set_defaults(func=create_dtbo_image)

    config_parser = subparser.add_parser('cfg_create', add_help=False)
    config_parser.add_argument('argfile', nargs='?',
                               action='store',
                               type=argparse.FileType('wb'))
    config_parser.set_defaults(func=create_dtbo_image_from_config)

    dump_parser = subparser.add_parser('dump', add_help=False)
    dump_parser.add_argument('argfile', nargs='?',
                             action='store',
                             type=argparse.FileType('rb'))
    dump_parser.set_defaults(func=dump_dtbo_image)

    help_parser = subparser.add_parser('help', add_help=False)
    help_parser.add_argument('argfile', nargs='?', action='store')
    help_parser.set_defaults(func=print_usage)

    (subcmd, subcmd_args) = parser.parse_known_args()
    subcmd.func(subcmd.argfile, subcmd_args)

if __name__ == '__main__':
    main()

```

`aosp/system/tools/mkbootimg/gki/Android.bp`:

```bp
// Copyright (C) 2022 The Android Open Source Project
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package {
    default_applicable_licenses: ["Android-Apache-2.0"],
}

python_test_host {
    name: "certify_bootimg_test",
    defaults: ["mkbootimg_defaults"],
    main: "certify_bootimg_test.py",
    srcs: [
        "certify_bootimg_test.py",
    ],
    data: [
        ":avbtool",
        ":certify_bootimg",
        ":mkbootimg",
        ":unpack_bootimg",
        "testdata/*",
    ],
    test_options: {
        unit_test: true,
    },
}

python_binary_host {
    name: "generate_gki_certificate",
    defaults: ["mkbootimg_defaults"],
    srcs: [
        "generate_gki_certificate.py",
    ],
    required: [
        "avbtool",
    ],
}

```

`aosp/system/tools/mkbootimg/gki/boot_signature_info.sh`:

```sh
#!/bin/bash
#
# Copyright (C) 2022 The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#
# Dump boot signature info of a GKI boot image.
#

set -eo errtrace

die() {
  echo >&2 "ERROR:" "${@}"
  exit 1
}

TEMP_DIR="$(mktemp -d)"
readonly TEMP_DIR

exit_handler() {
  readonly EXIT_CODE="$?"
  rm -rf "${TEMP_DIR}" ||:
  exit "${EXIT_CODE}"
}

trap exit_handler EXIT
trap 'die "line ${LINENO}, ${FUNCNAME:-<main>}(): \"${BASH_COMMAND}\" returned \"$?\"" ' ERR

get_arg() {
  local arg="$1"
  shift
  while [[ "$#" -gt 0 ]]; do
    if [[ "$1" == "${arg}" ]]; then
      shift
      echo "$1"
      return
    fi
    shift
  done
}

readonly VBMETA_IMAGE="${TEMP_DIR}/boot.boot_signature"
readonly VBMETA_IMAGE_TEMP="${VBMETA_IMAGE}.temp"
readonly VBMETA_INFO="${VBMETA_IMAGE}.info"
readonly BOOT_IMAGE="${TEMP_DIR}/boot.img"
readonly BOOT_IMAGE_DIR="${TEMP_DIR}/boot.unpack_dir"
readonly BOOT_IMAGE_ARGS="${TEMP_DIR}/boot.mkbootimg_args"
readonly BOOT_SIGNATURE_SIZE=$(( 16 << 10 ))

[[ -f "$1" ]] ||
  die "expected one input image"
cp "$1" "${BOOT_IMAGE}"

# This could fail if there already is no AVB footer.
avbtool erase_footer --image "${BOOT_IMAGE}" 2>/dev/null ||:

unpack_bootimg --boot_img "${BOOT_IMAGE}" --out "${BOOT_IMAGE_DIR}" \
  --format=mkbootimg -0 > "${BOOT_IMAGE_ARGS}"

declare -a boot_args=()
while IFS= read -r -d '' ARG; do
  boot_args+=("${ARG}")
done < "${BOOT_IMAGE_ARGS}"

BOOT_IMAGE_VERSION="$(get_arg --header_version "${boot_args[@]}")"
if [[ "${BOOT_IMAGE_VERSION}" -ge 4 ]] && [[ -f "${BOOT_IMAGE_DIR}/boot_signature" ]]; then
  cp "${BOOT_IMAGE_DIR}/boot_signature" "${VBMETA_IMAGE}"
else
  tail -c "${BOOT_SIGNATURE_SIZE}" "${BOOT_IMAGE}" > "${VBMETA_IMAGE}"
fi

# Keep carving out vbmeta image from the boot signature until we fail or EOF.
# Failing is fine because there could be padding trailing the boot signature.
while avbtool info_image --image "${VBMETA_IMAGE}" --output "${VBMETA_INFO}" 2>/dev/null; do
  cat "${VBMETA_INFO}"
  echo

  declare -i H A X
  H="$(cat "${VBMETA_INFO}" | grep 'Header Block:' | awk '{print $3}')"
  A="$(cat "${VBMETA_INFO}" | grep 'Authentication Block:' | awk '{print $3}')"
  X="$(cat "${VBMETA_INFO}" | grep 'Auxiliary Block:' | awk '{print $3}')"
  vbmeta_size="$(( ${H} + ${A} + ${X} ))"

  tail -c "+$(( ${vbmeta_size} + 1 ))" "${VBMETA_IMAGE}" > "${VBMETA_IMAGE_TEMP}"
  cp "${VBMETA_IMAGE_TEMP}" "${VBMETA_IMAGE}"
done

```

`aosp/system/tools/mkbootimg/gki/certify_bootimg.py`:

```py
#!/usr/bin/env python3
#
# Copyright 2022, The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

"""Certify a GKI boot image by generating and appending its boot_signature."""

from argparse import ArgumentParser
import glob
import os
import shlex
import shutil
import subprocess
import tempfile

from gki.generate_gki_certificate import generate_gki_certificate
from unpack_bootimg import unpack_bootimg

BOOT_SIGNATURE_SIZE = 16 * 1024


def get_kernel(boot_img):
    """Extracts the kernel from |boot_img| and returns it."""
    with tempfile.TemporaryDirectory() as unpack_dir:
        unpack_bootimg(boot_img, unpack_dir)
        with open(os.path.join(unpack_dir, 'kernel'), 'rb') as kernel:
            kernel_bytes = kernel.read()
            assert len(kernel_bytes) > 0
            return kernel_bytes


def add_certificate(boot_img, algorithm, key, extra_args):
    """Appends certificates to the end of the boot image.

    This functions appends two certificates to the end of the |boot_img|:
    the 'boot' certificate and the 'generic_kernel' certificate. The former
    is to certify the entire |boot_img|, while the latter is to certify
    the kernel inside the |boot_img|.
    """

    def generate_certificate(image, certificate_name):
        """Generates the certificate and returns the certificate content."""
        with tempfile.NamedTemporaryFile() as output_certificate:
            generate_gki_certificate(
                image=image, avbtool='avbtool', name=certificate_name,
                algorithm=algorithm, key=key, salt='d00df00d',
                additional_avb_args=extra_args, output=output_certificate.name)
            output_certificate.seek(os.SEEK_SET, 0)
            return output_certificate.read()

    boot_signature_bytes = b''
    boot_signature_bytes += generate_certificate(boot_img, 'boot')

    with tempfile.NamedTemporaryFile() as kernel_img:
        kernel_img.write(get_kernel(boot_img))
        kernel_img.flush()
        boot_signature_bytes += generate_certificate(kernel_img.name,
                                                     'generic_kernel')

    if len(boot_signature_bytes) > BOOT_SIGNATURE_SIZE:
        raise ValueError(
            f'boot_signature size must be <= {BOOT_SIGNATURE_SIZE}')
    boot_signature_bytes += (
        b'\0' * (BOOT_SIGNATURE_SIZE - len(boot_signature_bytes)))
    assert len(boot_signature_bytes) == BOOT_SIGNATURE_SIZE

    with open(boot_img, 'ab') as f:
        f.write(boot_signature_bytes)


def erase_certificate_and_avb_footer(boot_img):
    """Erases the boot certificate and avb footer.

    A boot image might already contain a certificate and/or a AVB footer.
    This function erases these additional metadata from the |boot_img|.
    """
    # Tries to erase the AVB footer first, which may or may not exist.
    avbtool_cmd = ['avbtool', 'erase_footer', '--image', boot_img]
    subprocess.run(avbtool_cmd, check=False, stderr=subprocess.DEVNULL)
    assert os.path.getsize(boot_img) > 0

    # No boot signature to erase, just return.
    if os.path.getsize(boot_img) <= BOOT_SIGNATURE_SIZE:
        return

    # Checks if the last 16K is a boot signature, then erases it.
    with open(boot_img, 'rb') as image:
        image.seek(-BOOT_SIGNATURE_SIZE, os.SEEK_END)
        boot_signature = image.read(BOOT_SIGNATURE_SIZE)
        assert len(boot_signature) == BOOT_SIGNATURE_SIZE

    with tempfile.NamedTemporaryFile() as signature_tmpfile:
        signature_tmpfile.write(boot_signature)
        signature_tmpfile.flush()
        avbtool_info_cmd = [
            'avbtool', 'info_image', '--image', signature_tmpfile.name]
        result = subprocess.run(avbtool_info_cmd, check=False,
                                stdout=subprocess.DEVNULL,
                                stderr=subprocess.DEVNULL)
        has_boot_signature = (result.returncode == 0)

    if has_boot_signature:
        new_file_size = os.path.getsize(boot_img) - BOOT_SIGNATURE_SIZE
        os.truncate(boot_img, new_file_size)

    assert os.path.getsize(boot_img) > 0


def get_avb_image_size(image):
    """Returns the image size if there is a AVB footer, else return zero."""

    avbtool_info_cmd = ['avbtool', 'info_image', '--image', image]
    result = subprocess.run(avbtool_info_cmd, check=False,
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL)

    if result.returncode == 0:
        return os.path.getsize(image)

    return 0


def add_avb_footer(image, partition_size, extra_footer_args):
    """Appends a AVB hash footer to the image."""

    avbtool_cmd = ['avbtool', 'add_hash_footer', '--image', image,
                   '--partition_name', 'boot']

    if partition_size:
        avbtool_cmd.extend(['--partition_size', str(partition_size)])
    else:
        avbtool_cmd.extend(['--dynamic_partition_size'])

    avbtool_cmd.extend(extra_footer_args)
    subprocess.check_call(avbtool_cmd)


def load_dict_from_file(path):
    """Loads key=value pairs from |path| and returns a dict."""
    d = {}
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            if '=' in line:
                name, value = line.split('=', 1)
                d[name] = value
    return d


def load_gki_info_file(gki_info_file, extra_args, extra_footer_args):
    """Loads extra arguments from the gki info file.

    Args:
        gki_info_file: path to a gki-info.txt.
        extra_args: the extra arguments forwarded to avbtool when creating
          the gki certificate.
        extra_footer_args: the extra arguments forwarded to avbtool when
          creating the avb footer.

    """
    info_dict = load_dict_from_file(gki_info_file)
    if 'certify_bootimg_extra_args' in info_dict:
        extra_args.extend(
            shlex.split(info_dict['certify_bootimg_extra_args']))
    if 'certify_bootimg_extra_footer_args' in info_dict:
        extra_footer_args.extend(
            shlex.split(info_dict['certify_bootimg_extra_footer_args']))


def get_archive_name_and_format_for_shutil(path):
    """Returns archive name and format to shutil.make_archive() for the |path|.

    e.g., returns ('/path/to/boot-img', 'gztar') if |path| is
    '/path/to/boot-img.tar.gz'.
    """
    for format_name, format_extensions, _ in shutil.get_unpack_formats():
        for extension in format_extensions:
            if path.endswith(extension):
                return path[:-len(extension)], format_name

    raise ValueError(f"Unsupported archive format: '{path}'")


def parse_cmdline():
    """Parse command-line options."""
    parser = ArgumentParser(add_help=True)

    # Required args.
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        '--boot_img', help='path to the boot image to certify')
    input_group.add_argument(
        '--boot_img_archive', help='path to the boot images archive to certify')

    parser.add_argument('--algorithm', required=True,
                        help='signing algorithm for the certificate')
    parser.add_argument('--key', required=True,
                        help='path to the RSA private key')
    parser.add_argument('--gki_info',
                        help='path to a gki-info.txt to append additional'
                             'properties into the boot signature')
    parser.add_argument('-o', '--output', required=True,
                        help='output file name')

    # Optional args.
    parser.add_argument('--extra_args', default=[], action='append',
                        help='extra arguments to be forwarded to avbtool')
    parser.add_argument('--extra_footer_args', default=[], action='append',
                        help='extra arguments for adding the avb footer')

    args = parser.parse_args()

    if args.gki_info and args.boot_img_archive:
        parser.error('--gki_info cannot be used with --boot_image_archive. '
                     'The gki_info file should be included in the archive.')

    extra_args = []
    for a in args.extra_args:
        extra_args.extend(shlex.split(a))
    args.extra_args = extra_args

    extra_footer_args = []
    for a in args.extra_footer_args:
        extra_footer_args.extend(shlex.split(a))
    args.extra_footer_args = extra_footer_args

    if args.gki_info:
        load_gki_info_file(args.gki_info,
                           args.extra_args,
                           args.extra_footer_args)

    return args


def certify_bootimg(boot_img, output_img, algorithm, key, extra_args,
                    extra_footer_args):
    """Certify a GKI boot image by generating and appending a boot_signature."""
    with tempfile.TemporaryDirectory() as temp_dir:
        boot_tmp = os.path.join(temp_dir, 'boot.tmp')
        shutil.copy2(boot_img, boot_tmp)

        erase_certificate_and_avb_footer(boot_tmp)
        add_certificate(boot_tmp, algorithm, key, extra_args)

        avb_partition_size = get_avb_image_size(boot_img)
        add_avb_footer(boot_tmp, avb_partition_size, extra_footer_args)

        # We're done, copy the temp image to the final output.
        shutil.copy2(boot_tmp, output_img)


def certify_bootimg_archive(boot_img_archive, output_archive,
                            algorithm, key, extra_args, extra_footer_args):
    """Similar to certify_bootimg(), but for an archive of boot images."""
    with tempfile.TemporaryDirectory() as unpack_dir:
        shutil.unpack_archive(boot_img_archive, unpack_dir)

        gki_info_file = os.path.join(unpack_dir, 'gki-info.txt')
        if os.path.exists(gki_info_file):
            load_gki_info_file(gki_info_file, extra_args, extra_footer_args)

        for boot_img in glob.glob(os.path.join(unpack_dir, 'boot*.img')):
            print(f'Certifying {os.path.basename(boot_img)} ...')
            certify_bootimg(boot_img=boot_img, output_img=boot_img,
                            algorithm=algorithm, key=key, extra_args=extra_args,
                            extra_footer_args=extra_footer_args)

        print(f'Making certified archive: {output_archive}')
        archive_file_name, archive_format = (
            get_archive_name_and_format_for_shutil(output_archive))
        built_archive = shutil.make_archive(archive_file_name,
                                            archive_format,
                                            unpack_dir)
        # shutil.make_archive() builds *.tar.gz when then |archive_format| is
        # 'gztar'. However, the end user might specify |output_archive| with
        # *.tgz. Renaming *.tar.gz to *.tgz for this case.
        if built_archive != os.path.realpath(output_archive):
            print(f'Renaming {built_archive} -> {output_archive} ...')
            os.rename(built_archive, output_archive)


def main():
    """Parse arguments and certify the boot image."""
    args = parse_cmdline()

    if args.boot_img_archive:
        certify_bootimg_archive(args.boot_img_archive, args.output,
                                args.algorithm, args.key, args.extra_args,
                                args.extra_footer_args)
    else:
        certify_bootimg(args.boot_img, args.output, args.algorithm,
                        args.key, args.extra_args, args.extra_footer_args)


if __name__ == '__main__':
    main()

```

`aosp/system/tools/mkbootimg/gki/certify_bootimg_test.py`:

```py
#!/usr/bin/env python3
#
# Copyright 2022, The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests certify_bootimg."""

import logging
import glob
import os
import random
import shutil
import struct
import subprocess
import sys
import tempfile
import unittest

BOOT_SIGNATURE_SIZE = 16 * 1024

TEST_KERNEL_CMDLINE = (
    'printk.devkmsg=on firmware_class.path=/vendor/etc/ init=/init '
    'kfence.sample_interval=500 loop.max_part=7 bootconfig'
)


def generate_test_file(pathname, size, seed=None):
    """Generates a gibberish-filled test file and returns its pathname."""
    random.seed(os.path.basename(pathname) if seed is None else seed)
    with open(pathname, 'wb') as file:
        file.write(random.randbytes(size))
    return pathname


def generate_test_boot_image(boot_img, kernel_size=4096, seed='kernel',
                             avb_partition_size=None):
    """Generates a test boot.img without a ramdisk."""
    with tempfile.NamedTemporaryFile() as kernel_tmpfile:
        generate_test_file(kernel_tmpfile.name, kernel_size, seed)
        kernel_tmpfile.flush()

        mkbootimg_cmds = [
            'mkbootimg',
            '--header_version', '4',
            '--kernel', kernel_tmpfile.name,
            '--cmdline', TEST_KERNEL_CMDLINE,
            '--os_version', '12.0.0',
            '--os_patch_level', '2022-03',
            '--output', boot_img,
        ]
        subprocess.check_call(mkbootimg_cmds)

    if avb_partition_size:
        avbtool_cmd = ['avbtool', 'add_hash_footer', '--image', boot_img,
                       '--partition_name', 'boot',
                       '--partition_size', str(avb_partition_size)]
        subprocess.check_call(avbtool_cmd)


def generate_test_boot_image_archive(archive_file_name, archive_format,
                                     boot_img_info, gki_info=None):
    """Generates an archive of test boot images.

    It also adds a file gki-info.txt, which contains additional settings for
    for `certify_bootimg --extra_args`.

    Args:
        archive_file_name: the name of the archive file to create, including the
          path, minus any format-specific extension.
        archive_format: the |format| parameter for shutil.make_archive().
          e.g., 'zip', 'tar', or 'gztar', etc.
        boot_img_info: a list of (boot_image_name, kernel_size,
          partition_size) tuples. e.g.,
          [('boot.img', 4096, 4 * 1024),
           ('boot-lz4.img', 8192, 8 * 1024)].
        gki_info: the file content to be written into 'gki-info.txt' in the
          created archive.

    Returns:
        The full path of the created archive. e.g., /path/to/boot-img.tar.gz.
    """
    with tempfile.TemporaryDirectory() as temp_out_dir:
        for name, kernel_size, partition_size in boot_img_info:
            boot_img = os.path.join(temp_out_dir, name)
            generate_test_boot_image(boot_img=boot_img,
                                     kernel_size=kernel_size,
                                     seed=name,
                                     avb_partition_size=partition_size)

        if gki_info:
            gki_info_path = os.path.join(temp_out_dir, 'gki-info.txt')
            with open(gki_info_path, 'w', encoding='utf-8') as f:
                f.write(gki_info)

        return shutil.make_archive(archive_file_name,
                                   archive_format,
                                   temp_out_dir)


def has_avb_footer(image):
    """Returns true if the image has a avb footer."""

    avbtool_info_cmd = ['avbtool', 'info_image', '--image', image]
    result = subprocess.run(avbtool_info_cmd, check=False,
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL)

    return result.returncode == 0


def get_vbmeta_size(vbmeta_bytes):
    """Returns the total size of a AvbVBMeta image."""

    # Keep in sync with |AvbVBMetaImageHeader|.
    AVB_MAGIC = b'AVB0'                        # pylint: disable=C0103
    AVB_VBMETA_IMAGE_HEADER_SIZE = 256         # pylint: disable=C0103
    FORMAT_STRING = (                          # pylint: disable=C0103
        '!4s2L'      # magic, 2 x version.
        '2Q'         # 2 x block size: Authentication and Auxiliary blocks.
    )

    if len(vbmeta_bytes) < struct.calcsize(FORMAT_STRING):
        return 0

    data = vbmeta_bytes[:struct.calcsize(FORMAT_STRING)]
    (magic, _, _,
     authentication_block_size,
     auxiliary_data_block_size) = struct.unpack(FORMAT_STRING, data)

    if magic == AVB_MAGIC:
        return (AVB_VBMETA_IMAGE_HEADER_SIZE +
                authentication_block_size +
                auxiliary_data_block_size)
    return 0


def extract_boot_signatures(boot_img, output_dir):
    """Extracts the boot signatures of a boot image.

    This functions extracts the boot signatures of |boot_img| as:
      - |output_dir|/boot_signature1
      - |output_dir|/boot_signature2
    """

    boot_img_copy = os.path.join(output_dir, 'boot_image_copy')
    shutil.copy2(boot_img, boot_img_copy)
    avbtool_cmd = ['avbtool', 'erase_footer', '--image', boot_img_copy]
    subprocess.run(avbtool_cmd, check=False, stderr=subprocess.DEVNULL)

    # The boot signature is assumed to be at the end of boot image, after
    # the AVB footer is erased.
    with open(boot_img_copy, 'rb') as image:
        image.seek(-BOOT_SIGNATURE_SIZE, os.SEEK_END)
        boot_signature_bytes = image.read(BOOT_SIGNATURE_SIZE)
        assert len(boot_signature_bytes) == BOOT_SIGNATURE_SIZE
    os.unlink(boot_img_copy)

    num_signatures = 0
    while True:
        next_signature_size = get_vbmeta_size(boot_signature_bytes)
        if next_signature_size <= 0:
            break

        num_signatures += 1
        next_signature = boot_signature_bytes[:next_signature_size]
        output_path = os.path.join(
            output_dir, 'boot_signature' + str(num_signatures))
        with open(output_path, 'wb') as output:
            output.write(next_signature)

        # Moves to the next signature.
        boot_signature_bytes = boot_signature_bytes[next_signature_size:]


def extract_boot_archive_with_signatures(boot_img_archive, output_dir):
    """Extracts boot images and signatures of a boot images archive.

    Suppose there are two boot images in |boot_img_archive|: boot.img
    and boot-lz4.img. This function then extracts each boot*.img and
    their signatures as:
      - |output_dir|/boot.img
      - |output_dir|/boot-lz4.img
      - |output_dir|/boot/boot_signature1
      - |output_dir|/boot/boot_signature2
      - |output_dir|/boot-lz4/boot_signature1
      - |output_dir|/boot-lz4/boot_signature2
    """
    shutil.unpack_archive(boot_img_archive, output_dir)
    for boot_img in glob.glob(os.path.join(output_dir, 'boot*.img')):
        img_name = os.path.splitext(os.path.basename(boot_img))[0]
        signature_output_dir = os.path.join(output_dir, img_name)
        os.mkdir(signature_output_dir, 0o777)
        extract_boot_signatures(boot_img, signature_output_dir)


class CertifyBootimgTest(unittest.TestCase):
    """Tests the functionalities of certify_bootimg."""

    def setUp(self):
        # Saves the test executable directory so that relative path references
        # to test dependencies don't rely on being manually run from the
        # executable directory.
        # With this, we can just open "./testdata/testkey_rsa2048.pem" in the
        # following tests with subprocess.run(..., cwd=self._exec_dir, ...).
        self._exec_dir = os.path.abspath(os.path.dirname(sys.argv[0]))

        # Set self.maxDiff to None to see full diff in assertion.
        # C0103: invalid-name for maxDiff.
        self.maxDiff = None  # pylint: disable=C0103

        # For AVB footers, we don't sign it so the Authentication block
        # is zero bytes and the Algorithm is NONE. The footer will be
        # replaced by device-specific settings when being incorporated into
        # a device codebase. The footer here is just to pass some GKI
        # pre-release test.
        self._EXPECTED_AVB_FOOTER_BOOT_CERTIFIED = (    # pylint: disable=C0103
            'Footer version:           1.0\n'
            'Image size:               131072 bytes\n'
            'Original image size:      24576 bytes\n'
            'VBMeta offset:            24576\n'
            'VBMeta size:              576 bytes\n'
            '--\n'
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     0 bytes\n'
            'Auxiliary Block:          320 bytes\n'
            'Algorithm:                NONE\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            24576 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'
            '      Salt:                  a11ba11b\n'
            '      Digest:                '
            'c9b4ad78fae6f72f7eff939dee6078ed'
            '8a75132e53f6c11ba1ec0f4b57f9eab0\n'
            '      Flags:                 0\n'
            "    Prop: avb -> 'nice'\n"
            "    Prop: avb_space -> 'nice to meet you'\n"
        )

        self._EXPECTED_AVB_FOOTER_BOOT_CERTIFIED_2 = (  # pylint: disable=C0103
            'Footer version:           1.0\n'
            'Image size:               131072 bytes\n'
            'Original image size:      24576 bytes\n'
            'VBMeta offset:            24576\n'
            'VBMeta size:              576 bytes\n'
            '--\n'
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     0 bytes\n'
            'Auxiliary Block:          320 bytes\n'
            'Algorithm:                NONE\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            24576 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'
            '      Salt:                  a11ba11b\n'
            '      Digest:                '
            'ae2538e78b2a30b1112cede30d858a5f'
            '6f8dc2a1b109dd4a7bb28124b77d2ab0\n'
            '      Flags:                 0\n'
            "    Prop: avb -> 'nice'\n"
            "    Prop: avb_space -> 'nice to meet you'\n"
        )

        self._EXPECTED_AVB_FOOTER_WITH_GKI_INFO = (     # pylint: disable=C0103
            'Footer version:           1.0\n'
            'Image size:               131072 bytes\n'
            'Original image size:      24576 bytes\n'
            'VBMeta offset:            24576\n'
            'VBMeta size:              704 bytes\n'
            '--\n'
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     0 bytes\n'
            'Auxiliary Block:          448 bytes\n'
            'Algorithm:                NONE\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            24576 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'
            '      Salt:                  a11ba11b\n'
            '      Digest:                '
            '363d4f246a4a5e1bba8ba8b86f5eb0cf'
            '9817e4e51663ba26edccf71c3861090a\n'
            '      Flags:                 0\n'
            "    Prop: avb -> 'nice'\n"
            "    Prop: avb_space -> 'nice to meet you'\n"
            "    Prop: com.android.build.boot.os_version -> '13'\n"
            "    Prop: com.android.build.boot.security_patch -> '2022-05-05'\n"
        )

        self._EXPECTED_AVB_FOOTER_BOOT = (              # pylint: disable=C0103
            'Footer version:           1.0\n'
            'Image size:               131072 bytes\n'
            'Original image size:      28672 bytes\n'
            'VBMeta offset:            28672\n'
            'VBMeta size:              704 bytes\n'
            '--\n'
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     0 bytes\n'
            'Auxiliary Block:          448 bytes\n'
            'Algorithm:                NONE\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            28672 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'
            '      Salt:                  a11ba11b\n'
            '      Digest:                '
            'b93084707ba2367120e19547f17f1073'
            '4c7ad8e56008ec2159d5f01b950335ad\n'
            '      Flags:                 0\n'
            "    Prop: avb -> 'nice'\n"
            "    Prop: avb_space -> 'nice to meet you'\n"
            "    Prop: com.android.build.boot.os_version -> '13'\n"
            "    Prop: com.android.build.boot.security_patch -> '2022-05-05'\n"
        )

        self._EXPECTED_AVB_FOOTER_BOOT_LZ4 = (          # pylint: disable=C0103
            'Footer version:           1.0\n'
            'Image size:               262144 bytes\n'
            'Original image size:      36864 bytes\n'
            'VBMeta offset:            36864\n'
            'VBMeta size:              704 bytes\n'
            '--\n'
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     0 bytes\n'
            'Auxiliary Block:          448 bytes\n'
            'Algorithm:                NONE\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            36864 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'
            '      Salt:                  a11ba11b\n'
            '      Digest:                '
            '6b3f583f1bc5fbc284102e0185d02c6b'
            '294f675c95b9337e89ea1e6b743af2ab\n'
            '      Flags:                 0\n'
            "    Prop: avb -> 'nice'\n"
            "    Prop: avb_space -> 'nice to meet you'\n"
            "    Prop: com.android.build.boot.os_version -> '13'\n"
            "    Prop: com.android.build.boot.security_patch -> '2022-05-05'\n"
        )

        self._EXPECTED_AVB_FOOTER_BOOT_GZ = (           # pylint: disable=C0103
            'Footer version:           1.0\n'
            'Image size:               131072 bytes\n'
            'Original image size:      28672 bytes\n'
            'VBMeta offset:            28672\n'
            'VBMeta size:              576 bytes\n'
            '--\n'
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     0 bytes\n'
            'Auxiliary Block:          320 bytes\n'
            'Algorithm:                NONE\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            28672 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'
            '      Salt:                  a11ba11b\n'
            '      Digest:                '
            'd2098d507e039afc6b4d7ec3de129a8d'
            'd0e0cf889c9181ebee65ce2fb25de3f5\n'
            '      Flags:                 0\n'
            "    Prop: avb -> 'nice'\n"
            "    Prop: avb_space -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_SIGNATURE_RSA2048 = (       # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     320 bytes\n'
            'Auxiliary Block:          832 bytes\n'
            'Public key (sha1):        '
            'cdbb77177f731920bbe0a0f94f84d9038ae0617d\n'
            'Algorithm:                SHA256_RSA2048\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            8192 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'           # boot
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            'faf1da72a4fba97ddab0b8f7a410db86'
            '8fb72392a66d1440ff8bff490c73c771\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
        )

        self._EXPECTED_KERNEL_SIGNATURE_RSA2048 = (     # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     320 bytes\n'
            'Auxiliary Block:          832 bytes\n'
            'Public key (sha1):        '
            'cdbb77177f731920bbe0a0f94f84d9038ae0617d\n'
            'Algorithm:                SHA256_RSA2048\n'
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            4096 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        generic_kernel\n' # generic_kernel
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '762c877f3af0d50a4a4fbc1385d5c7ce'
            '52a1288db74b33b72217d93db6f2909f\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_SIGNATURE_RSA4096 = (       # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1344 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            8192 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'           # boot
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            'faf1da72a4fba97ddab0b8f7a410db86'
            '8fb72392a66d1440ff8bff490c73c771\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
        )

        self._EXPECTED_KERNEL_SIGNATURE_RSA4096 = (     # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1344 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            4096 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        generic_kernel\n' # generic_kernel
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '762c877f3af0d50a4a4fbc1385d5c7ce'
            '52a1288db74b33b72217d93db6f2909f\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_SIGNATURE_WITH_GKI_INFO = (  # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1600 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n' # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            8192 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'        # boot
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            'faf1da72a4fba97ddab0b8f7a410db86'
            '8fb72392a66d1440ff8bff490c73c771\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
            "    Prop: KERNEL_RELEASE -> '5.10.42-android13-0-00544-"
            "ged21d463f856'\n"
            "    Prop: BRANCH -> 'android13-5.10-2022-05'\n"
            "    Prop: BUILD_NUMBER -> 'ab8295296'\n"
            "    Prop: GKI_INFO -> 'added here'\n"
        )

        self._EXPECTED_KERNEL_SIGNATURE_WITH_GKI_INFO = (# pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1600 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n' # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            4096 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        generic_kernel\n' # generic_kernel
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '762c877f3af0d50a4a4fbc1385d5c7ce'
            '52a1288db74b33b72217d93db6f2909f\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
            "    Prop: KERNEL_RELEASE -> '5.10.42-android13-0-00544-"
            "ged21d463f856'\n"
            "    Prop: BRANCH -> 'android13-5.10-2022-05'\n"
            "    Prop: BUILD_NUMBER -> 'ab8295296'\n"
            "    Prop: GKI_INFO -> 'added here'\n"
        )

        self._EXPECTED_BOOT_SIGNATURE1_RSA4096 = (       # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1600 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            12288 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'           # boot
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '30208b4d0a6d16db47fc13c9527bfe81'
            'a168d3b3940325d1ca8d3439792bfe18\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
            "    Prop: KERNEL_RELEASE -> '5.10.42-android13-0-00544-"
            "ged21d463f856'\n"
            "    Prop: BRANCH -> 'android13-5.10-2022-05'\n"
            "    Prop: BUILD_NUMBER -> 'ab8295296'\n"
            "    Prop: SPACE -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_SIGNATURE2_RSA4096 = (       # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1600 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            8192 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        generic_kernel\n' # generic_kernel
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            'd4c8847e7d9900a98f77e1f0b5272854'
            '7bf9c1e428fea500d419275f72ec5bd6\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
            "    Prop: KERNEL_RELEASE -> '5.10.42-android13-0-00544-"
            "ged21d463f856'\n"
            "    Prop: BRANCH -> 'android13-5.10-2022-05'\n"
            "    Prop: BUILD_NUMBER -> 'ab8295296'\n"
            "    Prop: SPACE -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_LZ4_SIGNATURE1_RSA4096 = (   # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1600 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            20480 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'           # boot
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '9d3a0670a9fd3de66e940117ef97700f'
            'ed5fd1c6fb90798fd3873af45fc91cb4\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
            "    Prop: KERNEL_RELEASE -> '5.10.42-android13-0-00544-"
            "ged21d463f856'\n"
            "    Prop: BRANCH -> 'android13-5.10-2022-05'\n"
            "    Prop: BUILD_NUMBER -> 'ab8295296'\n"
            "    Prop: SPACE -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_LZ4_SIGNATURE2_RSA4096 = (   # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1600 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            16384 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        generic_kernel\n' # generic_kernel
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '7d109e3dccca9e30e04249162d07e58c'
            '62fdf269804b35857b956fba339b2679\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
            "    Prop: KERNEL_RELEASE -> '5.10.42-android13-0-00544-"
            "ged21d463f856'\n"
            "    Prop: BRANCH -> 'android13-5.10-2022-05'\n"
            "    Prop: BUILD_NUMBER -> 'ab8295296'\n"
            "    Prop: SPACE -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_GZ_SIGNATURE1_RSA4096 = (    # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1344 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            12288 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        boot\n'           # boot
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '6fcddc6167ae3c2037b424d35c3ef107'
            'f586510dbb2d652d7c08b88e6ea52fc6\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
        )

        self._EXPECTED_BOOT_GZ_SIGNATURE2_RSA4096 = (    # pylint: disable=C0103
            'Minimum libavb version:   1.0\n'
            'Header Block:             256 bytes\n'
            'Authentication Block:     576 bytes\n'
            'Auxiliary Block:          1344 bytes\n'
            'Public key (sha1):        '
            '2597c218aae470a130f61162feaae70afd97f011\n'
            'Algorithm:                SHA256_RSA4096\n'    # RSA4096
            'Rollback Index:           0\n'
            'Flags:                    0\n'
            'Rollback Index Location:  0\n'
            "Release String:           'avbtool 1.2.0'\n"
            'Descriptors:\n'
            '    Hash descriptor:\n'
            '      Image Size:            8192 bytes\n'
            '      Hash Algorithm:        sha256\n'
            '      Partition Name:        generic_kernel\n' # generic_kernel
            '      Salt:                  d00df00d\n'
            '      Digest:                '
            '7a6a43eb4048b783346fb6d039103647'
            '6c4313146da521467af282dff1838d0e\n'
            '      Flags:                 0\n'
            "    Prop: gki -> 'nice'\n"
            "    Prop: space -> 'nice to meet you'\n"
        )

    def _test_boot_signatures(self, signatures_dir, expected_signatures_info):
        """Tests the info of each boot signature under the signature directory.

        Args:
            signatures_dir: the directory containing the boot signatures. e.g.,
                - signatures_dir/boot_signature1
                - signatures_dir/boot_signature2
            expected_signatures_info: A dict containing the expected output
                of `avbtool info_image` for each signature under
                |signatures_dir|. e.g.,
                {'boot_signature1': expected_stdout_signature1
                 'boot_signature2': expected_stdout_signature2}
        """
        for signature in expected_signatures_info:
            avbtool_info_cmds = [
                'avbtool', 'info_image', '--image',
                os.path.join(signatures_dir, signature)
            ]
            result = subprocess.run(avbtool_info_cmds, check=True,
                                    capture_output=True, encoding='utf-8')
            self.assertEqual(result.stdout, expected_signatures_info[signature])

    def test_certify_bootimg_without_avb_footer(self):
        """Tests certify_bootimg on a boot image without an AVB footer."""
        with tempfile.TemporaryDirectory() as temp_out_dir:
            boot_img = os.path.join(temp_out_dir, 'boot.img')
            generate_test_boot_image(boot_img)

            # Generates the certified boot image, with a RSA2048 key.
            boot_certified_img = os.path.join(temp_out_dir,
                                              'boot-certified.img')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img', boot_img,
                '--algorithm', 'SHA256_RSA2048',
                '--key', './testdata/testkey_rsa2048.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--output', boot_certified_img,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            extract_boot_signatures(boot_certified_img, temp_out_dir)
            self._test_boot_signatures(
                temp_out_dir,
                {'boot_signature1': self._EXPECTED_BOOT_SIGNATURE_RSA2048,
                 'boot_signature2': self._EXPECTED_KERNEL_SIGNATURE_RSA2048})

            # Generates the certified boot image again, with a RSA4096 key.
            boot_certified2_img = os.path.join(temp_out_dir,
                                              'boot-certified2.img')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img', boot_certified_img,
                '--algorithm', 'SHA256_RSA4096',
                '--key', './testdata/testkey_rsa4096.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--output', boot_certified2_img,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            extract_boot_signatures(boot_certified2_img, temp_out_dir)
            self._test_boot_signatures(
                temp_out_dir,
                {'boot_signature1': self._EXPECTED_BOOT_SIGNATURE_RSA4096,
                 'boot_signature2': self._EXPECTED_KERNEL_SIGNATURE_RSA4096})

    def test_certify_bootimg_with_avb_footer(self):
        """Tests the AVB footer location remains after certify_bootimg."""
        with tempfile.TemporaryDirectory() as temp_out_dir:
            boot_img = os.path.join(temp_out_dir, 'boot.img')
            generate_test_boot_image(boot_img=boot_img,
                                     avb_partition_size=128 * 1024)
            self.assertTrue(has_avb_footer(boot_img))

            # Generates the certified boot image, with a RSA2048 key.
            boot_certified_img = os.path.join(temp_out_dir,
                                              'boot-certified.img')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img', boot_img,
                '--algorithm', 'SHA256_RSA2048',
                '--key', './testdata/testkey_rsa2048.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--extra_footer_args', '--salt a11ba11b --prop avb:nice '
                '--prop avb_space:"nice to meet you"',
                '--output', boot_certified_img,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            # Checks an AVB footer exists and the image size remains.
            self.assertTrue(has_avb_footer(boot_certified_img))
            self.assertEqual(os.path.getsize(boot_img),
                             os.path.getsize(boot_certified_img))
            # Checks the content in the AVB footer.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot-certified.img':
                    self._EXPECTED_AVB_FOOTER_BOOT_CERTIFIED})

            # Checks the content in the GKI certificate.
            extract_boot_signatures(boot_certified_img, temp_out_dir)
            self._test_boot_signatures(
                temp_out_dir,
                {'boot_signature1': self._EXPECTED_BOOT_SIGNATURE_RSA2048,
                 'boot_signature2': self._EXPECTED_KERNEL_SIGNATURE_RSA2048})

            # Generates the certified boot image again, with a RSA4096 key.
            boot_certified2_img = os.path.join(temp_out_dir,
                                              'boot-certified2.img')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img', boot_certified_img,
                '--algorithm', 'SHA256_RSA4096',
                '--key', './testdata/testkey_rsa4096.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--extra_footer_args', '--salt a11ba11b --prop avb:nice '
                '--prop avb_space:"nice to meet you"',
                '--output', boot_certified2_img,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            # Checks an AVB footer exists and the image size remains.
            self.assertTrue(has_avb_footer(boot_certified2_img))
            self.assertEqual(os.path.getsize(boot_certified_img),
                             os.path.getsize(boot_certified2_img))
            # Checks the content in the AVB footer.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot-certified2.img':
                    self._EXPECTED_AVB_FOOTER_BOOT_CERTIFIED_2})

            # Checks the content in the GKI certificate.
            extract_boot_signatures(boot_certified2_img, temp_out_dir)
            self._test_boot_signatures(
                temp_out_dir,
                {'boot_signature1': self._EXPECTED_BOOT_SIGNATURE_RSA4096,
                 'boot_signature2': self._EXPECTED_KERNEL_SIGNATURE_RSA4096})

    def test_certify_bootimg_with_gki_info(self):
        """Tests certify_bootimg with --gki_info."""
        with tempfile.TemporaryDirectory() as temp_out_dir:
            boot_img = os.path.join(temp_out_dir, 'boot.img')
            generate_test_boot_image(boot_img=boot_img,
                                     avb_partition_size=128 * 1024)
            self.assertTrue(has_avb_footer(boot_img))

            gki_info = ('certify_bootimg_extra_args='
                        '--prop KERNEL_RELEASE:5.10.42'
                        '-android13-0-00544-ged21d463f856 '
                        '--prop BRANCH:android13-5.10-2022-05 '
                        '--prop BUILD_NUMBER:ab8295296 '
                        '--prop GKI_INFO:"added here"\n'
                        'certify_bootimg_extra_footer_args='
                        '--prop com.android.build.boot.os_version:13 '
                        '--prop com.android.build.boot.security_patch:'
                        '2022-05-05\n')
            gki_info_path = os.path.join(temp_out_dir, 'gki-info.txt')
            with open(gki_info_path, 'w', encoding='utf-8') as f:
                f.write(gki_info)

            # Certifies the boot image with --gki_info.
            boot_certified_img = os.path.join(temp_out_dir,
                                              'boot-certified.img')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img', boot_img,
                '--algorithm', 'SHA256_RSA4096',
                '--key', './testdata/testkey_rsa4096.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--extra_footer_args', '--salt a11ba11b --prop avb:nice '
                '--prop avb_space:"nice to meet you"',
                '--gki_info', gki_info_path,
                '--output', boot_certified_img,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            # Checks an AVB footer exists and the image size remains.
            self.assertTrue(has_avb_footer(boot_certified_img))
            self.assertEqual(os.path.getsize(boot_img),
                             os.path.getsize(boot_certified_img))

            # Checks the content in the AVB footer.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot-certified.img': self._EXPECTED_AVB_FOOTER_WITH_GKI_INFO})

            # Checks the content in the GKI certificate.
            extract_boot_signatures(boot_certified_img, temp_out_dir)
            self._test_boot_signatures(
                temp_out_dir,
                {'boot_signature1':
                    self._EXPECTED_BOOT_SIGNATURE_WITH_GKI_INFO,
                 'boot_signature2':
                    self._EXPECTED_KERNEL_SIGNATURE_WITH_GKI_INFO})

    def test_certify_bootimg_exceed_size(self):
        """Tests the boot signature size exceeded max size of the signature."""
        with tempfile.TemporaryDirectory() as temp_out_dir:
            boot_img = os.path.join(temp_out_dir, 'boot.img')
            generate_test_boot_image(boot_img)

            # Certifies the boot.img with many --extra_args, and checks
            # it will raise the ValueError() exception.
            boot_certified_img = os.path.join(temp_out_dir,
                                              'boot-certified.img')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img', boot_img,
                '--algorithm', 'SHA256_RSA2048',
                '--key', './testdata/testkey_rsa2048.pem',
                # Makes it exceed the signature max size.
                '--extra_args', '--prop foo:bar --prop gki:nice ' * 128,
                '--output', boot_certified_img,
            ]

            try:
                subprocess.run(certify_bootimg_cmds, check=True,
                               capture_output=True, cwd=self._exec_dir,
                               encoding='utf-8')
                self.fail('Exceeding signature size assertion is not raised')
            except subprocess.CalledProcessError as err:
                self.assertIn('ValueError: boot_signature size must be <= ',
                              err.stderr)

    def test_certify_bootimg_archive(self):
        """Tests certify_bootimg for a boot images archive.."""
        with tempfile.TemporaryDirectory() as temp_out_dir:
            boot_img_archive_name = os.path.join(temp_out_dir, 'boot-img')
            gki_info = ('certify_bootimg_extra_args='
                        '--prop KERNEL_RELEASE:5.10.42'
                        '-android13-0-00544-ged21d463f856 '
                        '--prop BRANCH:android13-5.10-2022-05 '
                        '--prop BUILD_NUMBER:ab8295296 '
                        '--prop SPACE:"nice to meet you"\n'
                        'certify_bootimg_extra_footer_args='
                        '--prop com.android.build.boot.os_version:13 '
                        '--prop com.android.build.boot.security_patch:'
                        '2022-05-05\n')
            boot_img_archive_path = generate_test_boot_image_archive(
                boot_img_archive_name,
                'gztar',
                # A list of (boot_img_name, kernel_size, partition_size).
                [('boot.img', 8 * 1024, 128 * 1024),
                 ('boot-lz4.img', 16 * 1024, 256 * 1024)],
                gki_info)

            # Certify the boot image archive, with a RSA4096 key.
            boot_certified_img_archive = os.path.join(
                temp_out_dir, 'boot-certified-img.tar.gz')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img_archive', boot_img_archive_path,
                '--algorithm', 'SHA256_RSA4096',
                '--key', './testdata/testkey_rsa4096.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--extra_footer_args', '--salt a11ba11b --prop avb:nice '
                '--prop avb_space:"nice to meet you"',
                '--output', boot_certified_img_archive,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            extract_boot_archive_with_signatures(boot_certified_img_archive,
                                                 temp_out_dir)

            # Checks an AVB footer exists and the image size remains.
            boot_img = os.path.join(temp_out_dir, 'boot.img')
            self.assertTrue(has_avb_footer(boot_img))
            self.assertEqual(os.path.getsize(boot_img), 128 * 1024)

            boot_lz4_img = os.path.join(temp_out_dir, 'boot-lz4.img')
            self.assertTrue(has_avb_footer(boot_lz4_img))
            self.assertEqual(os.path.getsize(boot_lz4_img), 256 * 1024)

            # Checks the content in the AVB footer.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot.img': self._EXPECTED_AVB_FOOTER_BOOT,
                 'boot-lz4.img': self._EXPECTED_AVB_FOOTER_BOOT_LZ4})

            # Checks the content in the GKI certificate.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot/boot_signature1':
                    self._EXPECTED_BOOT_SIGNATURE1_RSA4096,
                 'boot/boot_signature2':
                    self._EXPECTED_BOOT_SIGNATURE2_RSA4096,
                 'boot-lz4/boot_signature1':
                    self._EXPECTED_BOOT_LZ4_SIGNATURE1_RSA4096,
                 'boot-lz4/boot_signature2':
                    self._EXPECTED_BOOT_LZ4_SIGNATURE2_RSA4096})

    def test_certify_bootimg_archive_without_gki_info(self):
        """Tests certify_bootimg for a boot images archive."""
        with tempfile.TemporaryDirectory() as temp_out_dir:
            boot_img_archive_name = os.path.join(temp_out_dir, 'boot-img')

            # Checks ceritfy_bootimg works for a boot images archive without a
            # gki-info.txt. Using *.zip -> *.tar.
            boot_img_archive_path = generate_test_boot_image_archive(
                boot_img_archive_name,
                'zip',
                # A list of (boot_img_name, kernel_size, partition_size).
                [('boot-gz.img', 8 * 1024, 128 * 1024)],
                gki_info=None)
            # Certify the boot image archive, with a RSA4096 key.
            boot_certified_img_archive = os.path.join(
                temp_out_dir, 'boot-certified-img.tar')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img_archive', boot_img_archive_path,
                '--algorithm', 'SHA256_RSA4096',
                '--key', './testdata/testkey_rsa4096.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--extra_footer_args', '--salt a11ba11b --prop avb:nice '
                '--prop avb_space:"nice to meet you"',
                '--output', boot_certified_img_archive,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            # Checks ceritfy_bootimg works for a boot images archive with a
            # special gki-info.txt. Using *.tar -> *.tgz.
            boot_img_archive_path = generate_test_boot_image_archive(
                boot_img_archive_name,
                'tar',
                # A list of (boot_img_name, kernel_size, partition_size).
                [('boot-gz.img', 8 * 1024, 128 * 1024)],
                gki_info='a=b\n'
                         'c=d\n')
            # Certify the boot image archive, with a RSA4096 key.
            boot_certified_img_archive2 = os.path.join(
                temp_out_dir, 'boot-certified-img.tgz')
            certify_bootimg_cmds = [
                'certify_bootimg',
                '--boot_img_archive', boot_img_archive_path,
                '--algorithm', 'SHA256_RSA4096',
                '--key', './testdata/testkey_rsa4096.pem',
                '--extra_args', '--prop gki:nice '
                '--prop space:"nice to meet you"',
                '--extra_footer_args', '--salt a11ba11b --prop avb:nice '
                '--prop avb_space:"nice to meet you"',
                '--output', boot_certified_img_archive2,
            ]
            subprocess.run(certify_bootimg_cmds, check=True, cwd=self._exec_dir)

            extract_boot_archive_with_signatures(boot_certified_img_archive2,
                                                 temp_out_dir)

            # Checks an AVB footer exists and the image size remains.
            boot_3_img = os.path.join(temp_out_dir, 'boot-gz.img')
            self.assertTrue(has_avb_footer(boot_3_img))
            self.assertEqual(os.path.getsize(boot_3_img), 128 * 1024)

            # Checks the content in the AVB footer.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot-gz.img': self._EXPECTED_AVB_FOOTER_BOOT_GZ})

            # Checks the content in the GKI certificate.
            self._test_boot_signatures(
                temp_out_dir,
                {'boot-gz/boot_signature1':
                    self._EXPECTED_BOOT_GZ_SIGNATURE1_RSA4096,
                 'boot-gz/boot_signature2':
                    self._EXPECTED_BOOT_GZ_SIGNATURE2_RSA4096})


# I don't know how, but we need both the logger configuration and verbosity
# level > 2 to make atest work. And yes this line needs to be at the very top
# level, not even in the "__main__" indentation block.
logging.basicConfig(stream=sys.stdout)

if __name__ == '__main__':
    unittest.main(verbosity=2)

```

`aosp/system/tools/mkbootimg/gki/generate_gki_certificate.py`:

```py
#!/usr/bin/env python3
#
# Copyright 2021, The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

"""Generate a Generic Boot Image certificate suitable for VTS verification."""

from argparse import ArgumentParser
import shlex
import subprocess


def generate_gki_certificate(image, avbtool, name, algorithm, key, salt,
                             additional_avb_args, output):
    """Shell out to avbtool to generate a GKI certificate."""

    # Need to specify a value of --partition_size for avbtool to work.
    # We use 64 MB below, but avbtool will not resize the boot image to
    # this size because --do_not_append_vbmeta_image is also specified.
    avbtool_cmd = [
        avbtool, 'add_hash_footer',
        '--partition_name', name,
        '--partition_size', str(64 * 1024 * 1024),
        '--image', image,
        '--algorithm', algorithm,
        '--key', key,
        '--do_not_append_vbmeta_image',
        '--output_vbmeta_image', output,
    ]

    if salt is not None:
        avbtool_cmd += ['--salt', salt]

    avbtool_cmd += additional_avb_args

    subprocess.check_call(avbtool_cmd)


def parse_cmdline():
    parser = ArgumentParser(add_help=True)

    # Required args.
    parser.add_argument('image', help='path to the image')
    parser.add_argument('-o', '--output', required=True,
                        help='output certificate file name')
    parser.add_argument('--name', required=True,
                        choices=['boot', 'generic_kernel'],
                        help='name of the image to be certified')
    parser.add_argument('--algorithm', required=True,
                        help='AVB signing algorithm')
    parser.add_argument('--key', required=True,
                        help='path to the RSA private key')

    # Optional args.
    parser.add_argument('--avbtool', default='avbtool',
                        help='path to the avbtool executable')
    parser.add_argument('--salt', help='salt to use when computing image hash')
    parser.add_argument('--additional_avb_args', default=[], action='append',
                        help='additional arguments to be forwarded to avbtool')

    args = parser.parse_args()

    additional_avb_args = []
    for a in args.additional_avb_args:
        additional_avb_args.extend(shlex.split(a))
    args.additional_avb_args = additional_avb_args

    return args


def main():
    args = parse_cmdline()
    generate_gki_certificate(
        image=args.image, avbtool=args.avbtool, name=args.name,
        algorithm=args.algorithm, key=args.key, salt=args.salt,
        additional_avb_args=args.additional_avb_args,
        output=args.output,
    )


if __name__ == '__main__':
    main()

```

`aosp/system/tools/mkbootimg/gki/testdata/testkey_rsa2048.pem`:

```pem
-----BEGIN RSA PRIVATE KEY-----
MIIEowIBAAKCAQEAxlVR3TIkouAOvH79vaJTgFhpfvVKQIeVkFRZPVXK/zY0Gvrh
4JAqGjJoW/PfrQv5sdD36qtHH3a+G5hLZ6Ni+t/mtfjucxZfuLGC3kmJ1T3XqEKZ
gXXI2IR7vVSoImREvDQGEDyJwtHzLANlkbGg0cghVhWZSCAndO8BenalC2v94/rt
DfkPekH6dgU3Sf40T0sBSeSY94mOzTaqOR2pfV1rWlLRdWmo33zeHBv52Rlbt0dM
uXAureXWiHztkm5GCBC1dgM+CaxNtizNEgC91KcD0xuRCCM2WxH+r1lpszyIJDct
YbrFmVEYl/kjQpafhy7Nsk1fqSTyRdriZSYmTQIDAQABAoIBAQC+kJgaCuX8wYAn
SXWQ0fmdZlXnMNRpcF0a0pD0SAzGb1RdYBXMaXiqtyhiwc53PPxsCDdNecjayIMd
jJVXPTwLhTruOgMS/bp3gcgWwV34UHV4LJXGOGAE+jbS0hbDBMiudOYmj6RmVshp
z9G1zZCSQNMXHaWsEYkX59XpzzoB384nRul2QgEtwzUNR9XlpzgtJBLk3SACkvsN
mQ/DW8IWHXLg8vLn1LzVJ2e3B16H4MoE2TCHxqfMgr03IDRRJogkenQuQsFhevYT
o/mJyHSWavVgzMHG9I5m+eepF4Wyhj1Y4WyKAuMI+9dHAX/h7Lt8XFCQCh5DbkVG
zGr34sWBAoGBAOs7n7YZqNaaguovfIdRRsxxZr1yJAyDsr6w3yGImDZYju4c4WY9
5esO2kP3FA4p0c7FhQF5oOb1rBuHEPp36cpL4aGeK87caqTfq63WZAujoTZpr9Lp
BRbkL7w/xG7jpQ/clpA8sHzHGQs/nelxoOtC7E118FiRgvD/jdhlMyL9AoGBANfX
vyoN1pplfT2xR8QOjSZ+Q35S/+SAtMuBnHx3l0qH2bbBjcvM1MNDWjnRDyaYhiRu
i+KA7tqfib09+XpB3g5D6Ov7ls/Ldx0S/VcmVWtia2HK8y8iLGtokoBZKQ5AaFX2
iQU8+tC4h69GnJYQKqNwgCUzh8+gHX5Y46oDiTmRAoGAYpOx8lX+czB8/Da6MNrW
mIZNT8atZLEsDs2ANEVRxDSIcTCZJId7+m1W+nRoaycLTWNowZ1+2ErLvR10+AGY
b7Ys79Wg9idYaY9yGn9lnZsMzAiuLeyIvXcSqgjvAKlVWrhOQFOughvNWvFl85Yy
oWSCMlPiTLtt7CCsCKsgKuECgYBgdIp6GZsIfkgclKe0hqgvRoeU4TR3gcjJlM9A
lBTo+pKhaBectplx9RxR8AnsPobbqwcaHnIfAuKDzjk5mEvKZjClnFXF4HAHbyAF
nRzZEy9XkWFhc80T5rRpZO7C7qdxmu2aiKixM3V3L3/0U58qULEDbubHMw9bEhAT
PudI8QKBgHEEiMm/hr9T41hbQi/LYanWnlFw1ue+osKuF8bXQuxnnHNuFT/c+9/A
vWhgqG6bOEHu+p/IPrYm4tBMYlwsyh4nXCyGgDJLbLIfzKwKAWCtH9LwnyDVhOow
GH9shdR+sW3Ew97xef02KAH4VlNANEmBV4sQNqWWvsYrcFm2rOdL
-----END RSA PRIVATE KEY-----

```

`aosp/system/tools/mkbootimg/gki/testdata/testkey_rsa4096.pem`:

```pem
-----BEGIN RSA PRIVATE KEY-----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-----END RSA PRIVATE KEY-----

```

`aosp/system/tools/mkbootimg/mkbootimg.py`:

```py
#!/usr/bin/env python3
#
# Copyright 2015, The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Creates the boot image."""

from argparse import (ArgumentParser, ArgumentTypeError,
                      FileType, RawDescriptionHelpFormatter)
from hashlib import sha1
from os import fstat
from struct import pack

import array
import collections
import os
import re
import tempfile

from gki.generate_gki_certificate import generate_gki_certificate

# Constant and structure definition is in
# system/tools/mkbootimg/include/bootimg/bootimg.h
BOOT_MAGIC = 'ANDROID!'
BOOT_MAGIC_SIZE = 8
BOOT_NAME_SIZE = 16
BOOT_ARGS_SIZE = 512
BOOT_EXTRA_ARGS_SIZE = 1024
BOOT_IMAGE_HEADER_V1_SIZE = 1648
BOOT_IMAGE_HEADER_V2_SIZE = 1660
BOOT_IMAGE_HEADER_V3_SIZE = 1580
BOOT_IMAGE_HEADER_V3_PAGESIZE = 4096
BOOT_IMAGE_HEADER_V4_SIZE = 1584
BOOT_IMAGE_V4_SIGNATURE_SIZE = 4096

VENDOR_BOOT_MAGIC = 'VNDRBOOT'
VENDOR_BOOT_MAGIC_SIZE = 8
VENDOR_BOOT_NAME_SIZE = BOOT_NAME_SIZE
VENDOR_BOOT_ARGS_SIZE = 2048
VENDOR_BOOT_IMAGE_HEADER_V3_SIZE = 2112
VENDOR_BOOT_IMAGE_HEADER_V4_SIZE = 2128

VENDOR_RAMDISK_TYPE_NONE = 0
VENDOR_RAMDISK_TYPE_PLATFORM = 1
VENDOR_RAMDISK_TYPE_RECOVERY = 2
VENDOR_RAMDISK_TYPE_DLKM = 3
VENDOR_RAMDISK_NAME_SIZE = 32
VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE = 16
VENDOR_RAMDISK_TABLE_ENTRY_V4_SIZE = 108

# Names with special meaning, mustn't be specified in --ramdisk_name.
VENDOR_RAMDISK_NAME_BLOCKLIST = {b'default'}

PARSER_ARGUMENT_VENDOR_RAMDISK_FRAGMENT = '--vendor_ramdisk_fragment'


def filesize(f):
    if f is None:
        return 0
    try:
        return fstat(f.fileno()).st_size
    except OSError:
        return 0


def update_sha(sha, f):
    if f:
        sha.update(f.read())
        f.seek(0)
        sha.update(pack('I', filesize(f)))
    else:
        sha.update(pack('I', 0))


def pad_file(f, padding):
    pad = (padding - (f.tell() & (padding - 1))) & (padding - 1)
    f.write(pack(str(pad) + 'x'))


def get_number_of_pages(image_size, page_size):
    """calculates the number of pages required for the image"""
    return (image_size + page_size - 1) // page_size


def get_recovery_dtbo_offset(args):
    """calculates the offset of recovery_dtbo image in the boot image"""
    num_header_pages = 1 # header occupies a page
    num_kernel_pages = get_number_of_pages(filesize(args.kernel), args.pagesize)
    num_ramdisk_pages = get_number_of_pages(filesize(args.ramdisk),
                                            args.pagesize)
    num_second_pages = get_number_of_pages(filesize(args.second), args.pagesize)
    dtbo_offset = args.pagesize * (num_header_pages + num_kernel_pages +
                                   num_ramdisk_pages + num_second_pages)
    return dtbo_offset


def should_add_legacy_gki_boot_signature(args):
    if args.gki_signing_key and args.gki_signing_algorithm:
        return True
    return False


def write_header_v3_and_above(args):
    if args.header_version > 3:
        boot_header_size = BOOT_IMAGE_HEADER_V4_SIZE
    else:
        boot_header_size = BOOT_IMAGE_HEADER_V3_SIZE

    args.output.write(pack(f'{BOOT_MAGIC_SIZE}s', BOOT_MAGIC.encode()))
    # kernel size in bytes
    args.output.write(pack('I', filesize(args.kernel)))
    # ramdisk size in bytes
    args.output.write(pack('I', filesize(args.ramdisk)))
    # os version and patch level
    args.output.write(pack('I', (args.os_version << 11) | args.os_patch_level))
    args.output.write(pack('I', boot_header_size))
    # reserved
    args.output.write(pack('4I', 0, 0, 0, 0))
    # version of boot image header
    args.output.write(pack('I', args.header_version))
    args.output.write(pack(f'{BOOT_ARGS_SIZE + BOOT_EXTRA_ARGS_SIZE}s',
                           args.cmdline))
    if args.header_version >= 4:
        # The signature used to verify boot image v4.
        boot_signature_size = 0
        if should_add_legacy_gki_boot_signature(args):
            boot_signature_size = BOOT_IMAGE_V4_SIGNATURE_SIZE
        args.output.write(pack('I', boot_signature_size))
    pad_file(args.output, BOOT_IMAGE_HEADER_V3_PAGESIZE)


def write_vendor_boot_header(args):
    if args.header_version > 3:
        vendor_ramdisk_size = args.vendor_ramdisk_total_size
        vendor_boot_header_size = VENDOR_BOOT_IMAGE_HEADER_V4_SIZE
    else:
        vendor_ramdisk_size = filesize(args.vendor_ramdisk)
        vendor_boot_header_size = VENDOR_BOOT_IMAGE_HEADER_V3_SIZE

    args.vendor_boot.write(pack(f'{VENDOR_BOOT_MAGIC_SIZE}s',
                                VENDOR_BOOT_MAGIC.encode()))
    # version of boot image header
    args.vendor_boot.write(pack('I', args.header_version))
    # flash page size
    args.vendor_boot.write(pack('I', args.pagesize))
    # kernel physical load address
    args.vendor_boot.write(pack('I', args.base + args.kernel_offset))
    # ramdisk physical load address
    args.vendor_boot.write(pack('I', args.base + args.ramdisk_offset))
    # ramdisk size in bytes
    args.vendor_boot.write(pack('I', vendor_ramdisk_size))
    args.vendor_boot.write(pack(f'{VENDOR_BOOT_ARGS_SIZE}s',
                                args.vendor_cmdline))
    # kernel tags physical load address
    args.vendor_boot.write(pack('I', args.base + args.tags_offset))
    # asciiz product name
    args.vendor_boot.write(pack(f'{VENDOR_BOOT_NAME_SIZE}s', args.board))

    # header size in bytes
    args.vendor_boot.write(pack('I', vendor_boot_header_size))

    # dtb size in bytes
    args.vendor_boot.write(pack('I', filesize(args.dtb)))
    # dtb physical load address
    args.vendor_boot.write(pack('Q', args.base + args.dtb_offset))

    if args.header_version > 3:
        vendor_ramdisk_table_size = (args.vendor_ramdisk_table_entry_num *
                                     VENDOR_RAMDISK_TABLE_ENTRY_V4_SIZE)
        # vendor ramdisk table size in bytes
        args.vendor_boot.write(pack('I', vendor_ramdisk_table_size))
        # number of vendor ramdisk table entries
        args.vendor_boot.write(pack('I', args.vendor_ramdisk_table_entry_num))
        # vendor ramdisk table entry size in bytes
        args.vendor_boot.write(pack('I', VENDOR_RAMDISK_TABLE_ENTRY_V4_SIZE))
        # bootconfig section size in bytes
        args.vendor_boot.write(pack('I', filesize(args.vendor_bootconfig)))
    pad_file(args.vendor_boot, args.pagesize)


def write_header(args):
    if args.header_version > 4:
        raise ValueError(
            f'Boot header version {args.header_version} not supported')
    if args.header_version in {3, 4}:
        return write_header_v3_and_above(args)

    ramdisk_load_address = ((args.base + args.ramdisk_offset)
                            if filesize(args.ramdisk) > 0 else 0)
    second_load_address = ((args.base + args.second_offset)
                           if filesize(args.second) > 0 else 0)

    args.output.write(pack(f'{BOOT_MAGIC_SIZE}s', BOOT_MAGIC.encode()))
    # kernel size in bytes
    args.output.write(pack('I', filesize(args.kernel)))
    # kernel physical load address
    args.output.write(pack('I', args.base + args.kernel_offset))
    # ramdisk size in bytes
    args.output.write(pack('I', filesize(args.ramdisk)))
    # ramdisk physical load address
    args.output.write(pack('I', ramdisk_load_address))
    # second bootloader size in bytes
    args.output.write(pack('I', filesize(args.second)))
    # second bootloader physical load address
    args.output.write(pack('I', second_load_address))
    # kernel tags physical load address
    args.output.write(pack('I', args.base + args.tags_offset))
    # flash page size
    args.output.write(pack('I', args.pagesize))
    # version of boot image header
    args.output.write(pack('I', args.header_version))
    # os version and patch level
    args.output.write(pack('I', (args.os_version << 11) | args.os_patch_level))
    # asciiz product name
    args.output.write(pack(f'{BOOT_NAME_SIZE}s', args.board))
    args.output.write(pack(f'{BOOT_ARGS_SIZE}s', args.cmdline))

    sha = sha1()
    update_sha(sha, args.kernel)
    update_sha(sha, args.ramdisk)
    update_sha(sha, args.second)

    if args.header_version > 0:
        update_sha(sha, args.recovery_dtbo)
    if args.header_version > 1:
        update_sha(sha, args.dtb)

    img_id = pack('32s', sha.digest())

    args.output.write(img_id)
    args.output.write(pack(f'{BOOT_EXTRA_ARGS_SIZE}s', args.extra_cmdline))

    if args.header_version > 0:
        if args.recovery_dtbo:
            # recovery dtbo size in bytes
            args.output.write(pack('I', filesize(args.recovery_dtbo)))
            # recovert dtbo offset in the boot image
            args.output.write(pack('Q', get_recovery_dtbo_offset(args)))
        else:
            # Set to zero if no recovery dtbo
            args.output.write(pack('I', 0))
            args.output.write(pack('Q', 0))

    # Populate boot image header size for header versions 1 and 2.
    if args.header_version == 1:
        args.output.write(pack('I', BOOT_IMAGE_HEADER_V1_SIZE))
    elif args.header_version == 2:
        args.output.write(pack('I', BOOT_IMAGE_HEADER_V2_SIZE))

    if args.header_version > 1:
        if filesize(args.dtb) == 0:
            raise ValueError('DTB image must not be empty.')

        # dtb size in bytes
        args.output.write(pack('I', filesize(args.dtb)))
        # dtb physical load address
        args.output.write(pack('Q', args.base + args.dtb_offset))

    pad_file(args.output, args.pagesize)
    return img_id


class AsciizBytes:
    """Parses a string and encodes it as an asciiz bytes object.

    >>> AsciizBytes(bufsize=4)('foo')
    b'foo\\x00'
    >>> AsciizBytes(bufsize=4)('foob')
    Traceback (most recent call last):
        ...
    argparse.ArgumentTypeError: Encoded asciiz length exceeded: max 4, got 5
    """

    def __init__(self, bufsize):
        self.bufsize = bufsize

    def __call__(self, arg):
        arg_bytes = arg.encode() + b'\x00'
        if len(arg_bytes) > self.bufsize:
            raise ArgumentTypeError(
                'Encoded asciiz length exceeded: '
                f'max {self.bufsize}, got {len(arg_bytes)}')
        return arg_bytes


class VendorRamdiskTableBuilder:
    """Vendor ramdisk table builder.

    Attributes:
        entries: A list of VendorRamdiskTableEntry namedtuple.
        ramdisk_total_size: Total size in bytes of all ramdisks in the table.
    """

    VendorRamdiskTableEntry = collections.namedtuple(  # pylint: disable=invalid-name
        'VendorRamdiskTableEntry',
        ['ramdisk_path', 'ramdisk_size', 'ramdisk_offset', 'ramdisk_type',
         'ramdisk_name', 'board_id'])

    def __init__(self):
        self.entries = []
        self.ramdisk_total_size = 0
        self.ramdisk_names = set()

    def add_entry(self, ramdisk_path, ramdisk_type, ramdisk_name, board_id):
        # Strip any trailing null for simple comparison.
        stripped_ramdisk_name = ramdisk_name.rstrip(b'\x00')
        if stripped_ramdisk_name in VENDOR_RAMDISK_NAME_BLOCKLIST:
            raise ValueError(
                f'Banned vendor ramdisk name: {stripped_ramdisk_name}')
        if stripped_ramdisk_name in self.ramdisk_names:
            raise ValueError(
                f'Duplicated vendor ramdisk name: {stripped_ramdisk_name}')
        self.ramdisk_names.add(stripped_ramdisk_name)

        if board_id is None:
            board_id = array.array(
                'I', [0] * VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE)
        else:
            board_id = array.array('I', board_id)
        if len(board_id) != VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE:
            raise ValueError('board_id size must be '
                             f'{VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE}')

        with open(ramdisk_path, 'rb') as f:
            ramdisk_size = filesize(f)
        self.entries.append(self.VendorRamdiskTableEntry(
            ramdisk_path, ramdisk_size, self.ramdisk_total_size, ramdisk_type,
            ramdisk_name, board_id))
        self.ramdisk_total_size += ramdisk_size

    def write_ramdisks_padded(self, fout, alignment):
        for entry in self.entries:
            with open(entry.ramdisk_path, 'rb') as f:
                fout.write(f.read())
        pad_file(fout, alignment)

    def write_entries_padded(self, fout, alignment):
        for entry in self.entries:
            fout.write(pack('I', entry.ramdisk_size))
            fout.write(pack('I', entry.ramdisk_offset))
            fout.write(pack('I', entry.ramdisk_type))
            fout.write(pack(f'{VENDOR_RAMDISK_NAME_SIZE}s',
                            entry.ramdisk_name))
            fout.write(entry.board_id)
        pad_file(fout, alignment)


def write_padded_file(f_out, f_in, padding):
    if f_in is None:
        return
    f_out.write(f_in.read())
    pad_file(f_out, padding)


def parse_int(x):
    return int(x, 0)


def parse_os_version(x):
    match = re.search(r'^(\d{1,3})(?:\.(\d{1,3})(?:\.(\d{1,3}))?)?', x)
    if match:
        a = int(match.group(1))
        b = c = 0
        if match.lastindex >= 2:
            b = int(match.group(2))
        if match.lastindex == 3:
            c = int(match.group(3))
        # 7 bits allocated for each field
        assert a < 128
        assert b < 128
        assert c < 128
        return (a << 14) | (b << 7) | c
    return 0


def parse_os_patch_level(x):
    match = re.search(r'^(\d{4})-(\d{2})(?:-(\d{2}))?', x)
    if match:
        y = int(match.group(1)) - 2000
        m = int(match.group(2))
        # 7 bits allocated for the year, 4 bits for the month
        assert 0 <= y < 128
        assert 0 < m <= 12
        return (y << 4) | m
    return 0


def parse_vendor_ramdisk_type(x):
    type_dict = {
        'none': VENDOR_RAMDISK_TYPE_NONE,
        'platform': VENDOR_RAMDISK_TYPE_PLATFORM,
        'recovery': VENDOR_RAMDISK_TYPE_RECOVERY,
        'dlkm': VENDOR_RAMDISK_TYPE_DLKM,
    }
    if x.lower() in type_dict:
        return type_dict[x.lower()]
    return parse_int(x)


def get_vendor_boot_v4_usage():
    return """vendor boot version 4 arguments:
  --ramdisk_type {none,platform,recovery,dlkm}
                        specify the type of the ramdisk
  --ramdisk_name NAME
                        specify the name of the ramdisk
  --board_id{0..15} NUMBER
                        specify the value of the board_id vector, defaults to 0
  --vendor_ramdisk_fragment VENDOR_RAMDISK_FILE
                        path to the vendor ramdisk file

  These options can be specified multiple times, where each vendor ramdisk
  option group ends with a --vendor_ramdisk_fragment option.
  Each option group appends an additional ramdisk to the vendor boot image.
"""


def parse_vendor_ramdisk_args(args, args_list):
    """Parses vendor ramdisk specific arguments.

    Args:
        args: An argparse.Namespace object. Parsed results are stored into this
            object.
        args_list: A list of argument strings to be parsed.

    Returns:
        A list argument strings that are not parsed by this method.
    """
    parser = ArgumentParser(add_help=False)
    parser.add_argument('--ramdisk_type', type=parse_vendor_ramdisk_type,
                        default=VENDOR_RAMDISK_TYPE_NONE)
    parser.add_argument('--ramdisk_name',
                        type=AsciizBytes(bufsize=VENDOR_RAMDISK_NAME_SIZE),
                        required=True)
    for i in range(VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE):
        parser.add_argument(f'--board_id{i}', type=parse_int, default=0)
    parser.add_argument(PARSER_ARGUMENT_VENDOR_RAMDISK_FRAGMENT, required=True)

    unknown_args = []

    vendor_ramdisk_table_builder = VendorRamdiskTableBuilder()
    if args.vendor_ramdisk is not None:
        vendor_ramdisk_table_builder.add_entry(
            args.vendor_ramdisk.name, VENDOR_RAMDISK_TYPE_PLATFORM, b'', None)

    while PARSER_ARGUMENT_VENDOR_RAMDISK_FRAGMENT in args_list:
        idx = args_list.index(PARSER_ARGUMENT_VENDOR_RAMDISK_FRAGMENT) + 2
        vendor_ramdisk_args = args_list[:idx]
        args_list = args_list[idx:]

        ramdisk_args, extra_args = parser.parse_known_args(vendor_ramdisk_args)
        ramdisk_args_dict = vars(ramdisk_args)
        unknown_args.extend(extra_args)

        ramdisk_path = ramdisk_args.vendor_ramdisk_fragment
        ramdisk_type = ramdisk_args.ramdisk_type
        ramdisk_name = ramdisk_args.ramdisk_name
        board_id = [ramdisk_args_dict[f'board_id{i}']
                    for i in range(VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE)]
        vendor_ramdisk_table_builder.add_entry(ramdisk_path, ramdisk_type,
                                               ramdisk_name, board_id)

    if len(args_list) > 0:
        unknown_args.extend(args_list)

    args.vendor_ramdisk_total_size = (vendor_ramdisk_table_builder
                                      .ramdisk_total_size)
    args.vendor_ramdisk_table_entry_num = len(vendor_ramdisk_table_builder
                                              .entries)
    args.vendor_ramdisk_table_builder = vendor_ramdisk_table_builder
    return unknown_args


def parse_cmdline():
    version_parser = ArgumentParser(add_help=False)
    version_parser.add_argument('--header_version', type=parse_int, default=0)
    if version_parser.parse_known_args()[0].header_version < 3:
        # For boot header v0 to v2, the kernel commandline field is split into
        # two fields, cmdline and extra_cmdline. Both fields are asciiz strings,
        # so we minus one here to ensure the encoded string plus the
        # null-terminator can fit in the buffer size.
        cmdline_size = BOOT_ARGS_SIZE + BOOT_EXTRA_ARGS_SIZE - 1
    else:
        cmdline_size = BOOT_ARGS_SIZE + BOOT_EXTRA_ARGS_SIZE

    parser = ArgumentParser(formatter_class=RawDescriptionHelpFormatter,
                            epilog=get_vendor_boot_v4_usage())
    parser.add_argument('--kernel', type=FileType('rb'),
                        help='path to the kernel')
    parser.add_argument('--ramdisk', type=FileType('rb'),
                        help='path to the ramdisk')
    parser.add_argument('--second', type=FileType('rb'),
                        help='path to the second bootloader')
    parser.add_argument('--dtb', type=FileType('rb'), help='path to the dtb')
    dtbo_group = parser.add_mutually_exclusive_group()
    dtbo_group.add_argument('--recovery_dtbo', type=FileType('rb'),
                            help='path to the recovery DTBO')
    dtbo_group.add_argument('--recovery_acpio', type=FileType('rb'),
                            metavar='RECOVERY_ACPIO', dest='recovery_dtbo',
                            help='path to the recovery ACPIO')
    parser.add_argument('--cmdline', type=AsciizBytes(bufsize=cmdline_size),
                        default='', help='kernel command line arguments')
    parser.add_argument('--vendor_cmdline',
                        type=AsciizBytes(bufsize=VENDOR_BOOT_ARGS_SIZE),
                        default='',
                        help='vendor boot kernel command line arguments')
    parser.add_argument('--base', type=parse_int, default=0x10000000,
                        help='base address')
    parser.add_argument('--kernel_offset', type=parse_int, default=0x00008000,
                        help='kernel offset')
    parser.add_argument('--ramdisk_offset', type=parse_int, default=0x01000000,
                        help='ramdisk offset')
    parser.add_argument('--second_offset', type=parse_int, default=0x00f00000,
                        help='second bootloader offset')
    parser.add_argument('--dtb_offset', type=parse_int, default=0x01f00000,
                        help='dtb offset')

    parser.add_argument('--os_version', type=parse_os_version, default=0,
                        help='operating system version')
    parser.add_argument('--os_patch_level', type=parse_os_patch_level,
                        default=0, help='operating system patch level')
    parser.add_argument('--tags_offset', type=parse_int, default=0x00000100,
                        help='tags offset')
    parser.add_argument('--board', type=AsciizBytes(bufsize=BOOT_NAME_SIZE),
                        default='', help='board name')
    parser.add_argument('--pagesize', type=parse_int,
                        choices=[2**i for i in range(11, 15)], default=2048,
                        help='page size')
    parser.add_argument('--id', action='store_true',
                        help='print the image ID on standard output')
    parser.add_argument('--header_version', type=parse_int, default=0,
                        help='boot image header version')
    parser.add_argument('-o', '--output', type=FileType('wb'),
                        help='output file name')
    parser.add_argument('--vendor_boot', type=FileType('wb'),
                        help='vendor boot output file name')
    parser.add_argument('--vendor_ramdisk', type=FileType('rb'),
                        help='path to the vendor ramdisk')
    parser.add_argument('--vendor_bootconfig', type=FileType('rb'),
                        help='path to the vendor bootconfig file')

    gki_2_0_signing_args = parser.add_argument_group(
        '[DEPRECATED] GKI 2.0 signing arguments')
    gki_2_0_signing_args.add_argument(
        '--gki_signing_algorithm', help='GKI signing algorithm to use')
    gki_2_0_signing_args.add_argument(
        '--gki_signing_key', help='path to RSA private key file')
    gki_2_0_signing_args.add_argument(
        '--gki_signing_signature_args', default='',
        help='other hash arguments passed to avbtool')
    gki_2_0_signing_args.add_argument(
        '--gki_signing_avbtool_path', default='avbtool',
        help='path to avbtool for boot signature generation')

    args, extra_args = parser.parse_known_args()
    if args.vendor_boot is not None and args.header_version > 3:
        extra_args = parse_vendor_ramdisk_args(args, extra_args)
    if len(extra_args) > 0:
        raise ValueError(f'Unrecognized arguments: {extra_args}')

    if args.header_version < 3:
        args.extra_cmdline = args.cmdline[BOOT_ARGS_SIZE-1:]
        args.cmdline = args.cmdline[:BOOT_ARGS_SIZE-1] + b'\x00'
        assert len(args.cmdline) <= BOOT_ARGS_SIZE
        assert len(args.extra_cmdline) <= BOOT_EXTRA_ARGS_SIZE

    return args


def add_boot_image_signature(args, pagesize):
    """Adds the boot image signature.

    Note that the signature will only be verified in VTS to ensure a
    generic boot.img is used. It will not be used by the device
    bootloader at boot time. The bootloader should only verify
    the boot vbmeta at the end of the boot partition (or in the top-level
    vbmeta partition) via the Android Verified Boot process, when the
    device boots.
    """
    # Flush the buffer for signature calculation.
    args.output.flush()

    # Outputs the signed vbmeta to a separate file, then append to boot.img
    # as the boot signature.
    with tempfile.TemporaryDirectory() as temp_out_dir:
        boot_signature_output = os.path.join(temp_out_dir, 'boot_signature')
        generate_gki_certificate(
            image=args.output.name, avbtool=args.gki_signing_avbtool_path,
            name='boot', algorithm=args.gki_signing_algorithm,
            key=args.gki_signing_key, salt='d00df00d',
            additional_avb_args=args.gki_signing_signature_args.split(),
            output=boot_signature_output,
        )
        with open(boot_signature_output, 'rb') as boot_signature:
            boot_signature_bytes = boot_signature.read()
            if len(boot_signature_bytes) > BOOT_IMAGE_V4_SIGNATURE_SIZE:
                raise ValueError(
                    f'boot sigature size is > {BOOT_IMAGE_V4_SIGNATURE_SIZE}')
            boot_signature_bytes += b'\x00' * (
                BOOT_IMAGE_V4_SIGNATURE_SIZE - len(boot_signature_bytes))
            assert len(boot_signature_bytes) == BOOT_IMAGE_V4_SIGNATURE_SIZE
            args.output.write(boot_signature_bytes)
            pad_file(args.output, pagesize)


def write_data(args, pagesize):
    write_padded_file(args.output, args.kernel, pagesize)
    write_padded_file(args.output, args.ramdisk, pagesize)
    write_padded_file(args.output, args.second, pagesize)

    if args.header_version > 0 and args.header_version < 3:
        write_padded_file(args.output, args.recovery_dtbo, pagesize)
    if args.header_version == 2:
        write_padded_file(args.output, args.dtb, pagesize)
    if args.header_version >= 4 and should_add_legacy_gki_boot_signature(args):
        add_boot_image_signature(args, pagesize)


def write_vendor_boot_data(args):
    if args.header_version > 3:
        builder = args.vendor_ramdisk_table_builder
        builder.write_ramdisks_padded(args.vendor_boot, args.pagesize)
        write_padded_file(args.vendor_boot, args.dtb, args.pagesize)
        builder.write_entries_padded(args.vendor_boot, args.pagesize)
        write_padded_file(args.vendor_boot, args.vendor_bootconfig,
            args.pagesize)
    else:
        write_padded_file(args.vendor_boot, args.vendor_ramdisk, args.pagesize)
        write_padded_file(args.vendor_boot, args.dtb, args.pagesize)


def main():
    args = parse_cmdline()
    if args.vendor_boot is not None:
        if args.header_version not in {3, 4}:
            raise ValueError(
                '--vendor_boot not compatible with given header version')
        if args.header_version == 3 and args.vendor_ramdisk is None:
            raise ValueError('--vendor_ramdisk missing or invalid')
        write_vendor_boot_header(args)
        write_vendor_boot_data(args)
    if args.output is not None:
        if args.second is not None and args.header_version > 2:
            raise ValueError(
                '--second not compatible with given header version')
        img_id = write_header(args)
        if args.header_version > 2:
            write_data(args, BOOT_IMAGE_HEADER_V3_PAGESIZE)
        else:
            write_data(args, args.pagesize)
        if args.id and img_id is not None:
            print('0x' + ''.join(f'{octet:02x}' for octet in img_id))


if __name__ == '__main__':
    main()

```

`avbImpl/build.gradle`:

```gradle
apply plugin: "c"
apply plugin: "cpp"
apply plugin: "cpp-unit-test"

model {
    buildTypes {
        release
    }

    components {
        avbx(NativeLibrarySpec) {
            sources {
                cpp {
                    lib project: ":aosp:libavb1.2", library: "avb"
                }
            }
            binaries.all {
                cCompiler.args << "-Wall" << "-g"
                cppCompiler.args << "-std=c++17"
            }
        }

        avbVerifier(NativeExecutableSpec) {
            sources {
                cpp {
                    lib project: ":aosp:libavb1.2", library: "avb", linkage: "static"
                    lib project: ":avbImpl", library: "avbx", linkage: "static"
                }
            }
            binaries.all {
                cppCompiler.define "XXX"
                cppCompiler.args << '-std=c++17'
            }
        }
    }
}

task v1(type:Exec) {
    workingDir "."
    environment preloads: "vbmeta boot", requests: "boot dtbo vendor_boot", suffix: ""
    commandLine "./build/exe/avbVerifier/avbVerifier"
}

task v2(type:Exec) {
    description "verify non-AB recovery mode"
    workingDir "."
    environment preloads: "", requests: "recovery", suffix: ""
    commandLine "./build/exe/avbVerifier/avbVerifier"
}

```

`avbImpl/src/avbVerifier/cpp/main.cpp`:

```cpp
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <cstdio>
#include <iostream>
#include <fstream>
#include <cstdlib>
#include <vector>
#include <regex>
#include "CfigAvbOps.h"
#include "helper.hpp"

std::vector<std::string> splitString(const std::string& subject) {
    if (subject.size() == 0) {
        return std::vector<std::string>();
    }
    static const std::regex re{"\\s+"};
    std::vector<std::string> container {
        std::sregex_token_iterator(subject.begin(), subject.end(), re, -1),
        std::sregex_token_iterator()
    };
    return container;
}

int main(int, char**) {
    int flags = AVB_SLOT_VERIFY_FLAGS_NONE;
    //param 1: preload partitions
    auto preloads = getenv("preloads");
    if (preloads == NULL) {
        preloads = (char*) "";
    }
    std::cout << "[" << __FUNCTION__ << "]: partitions to preload: " << preloads << std::endl;

    //param 2: requested partitions
    auto requests = getenv("requests");
    if (requests == NULL) {
        requests = (char*) "";
    }
    std::cout << "[" << __FUNCTION__ << "]: requested partitions: " << requests << std::endl;
    auto requestVec = splitString(requests);
    //example: const char* requestedPartitions[] = { (const char*) "boot", (const char*)NULL };
    const char* requestedPartitions[requestVec.size() + 1];
    for (int i = 0; i< requestVec.size(); i++) {
        requestedPartitions[i] = requestVec[i].c_str();
        if (requestVec[i] == "recovery") {
            flags |= AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION;
            std::cout << "[" << __FUNCTION__ << "]: using NO-VBMETA mode for recovery" << std::endl;
        }
    }
    requestedPartitions[requestVec.size()] = (const char*)NULL;
    //param3: ab_suffix
    auto abSuffix = getenv("suffix");
    if (abSuffix == NULL) {
        abSuffix = (char*) "";
    }
    std::cout << "[" << __FUNCTION__ << "]: ab_suffix: " << abSuffix << std::endl;

    //main
    auto cfigOps = CfigAvbOps();

    {//preload partitions
        auto preloadVec = splitString(preloads);
        for (auto item: preloadVec) {
            cfigOps.preload_partition(item);
        }
    }

    bool isDeviceUnlocked = false;
    cfigOps.avb_ops_.read_is_device_unlocked(NULL, &isDeviceUnlocked);
    if (isDeviceUnlocked) {
        flags |= AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR;
    }
    std::cout << "[" << __FUNCTION__ << "]: flags: " << flags << std::endl;

    AvbSlotVerifyData *slotData = NULL;
    AvbSlotVerifyResult result = avb_slot_verify(
            &(cfigOps.avb_ops_),
            requestedPartitions,
            abSuffix, /* ab_suffix */
            static_cast<AvbSlotVerifyFlags>(flags),    /* AvbSlotVerifyFlags */
            AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE,
            &slotData);
    if (AVB_SLOT_VERIFY_RESULT_OK == result) {
        auto outFile = "verify_result.json";
        std::cout << "Writing result to " << outFile << "... ";
        std::ofstream outJson(outFile);
        outJson << toString(slotData);
        outJson.close();
        std::cout << " done" << std::endl;
        std::cout << "Run:\n  python -m json.tool " << outFile << std::endl;
    }
    if (slotData) { avb_slot_verify_data_free(slotData); }
    std::cout << "\n\tVerify Result: " << toString(result) << std::endl;
    if (isDeviceUnlocked) {
        switch (result) {
            case AVB_SLOT_VERIFY_RESULT_OK:
                std::cout << "\tVerify Flow: [orange] continue";
                break;
            case AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION:
            case AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED:
            case AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX:
                std::cout << "\tVerify Flow: [orange] allowed errors found: " << toString(result) << std::endl;
                break;
            default:
                std::cout<< "\tVerify Flow: [orange] but fatal errors found" << std::endl;
        }
    } else {
        switch (result) {
            case AVB_SLOT_VERIFY_RESULT_OK:
                std::cout << "\tVerify Flow: [green] continue";
                break;
            default:
                std::cout << "\tVerify Flow: [?????] halt";
        }
    }
    return 0;
}

```

`avbImpl/src/avbx/cpp/CfigAvbOps.cpp`:

```cpp
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//
// Created by yu on 8/30/19.
//
#include <set>
#include <string>
#include <system_error>
#include <iostream>
#include <cstring>
#include <unistd.h>
#include <fcntl.h>
#include <fstream>
#include <sstream>
#include <vector>
#include <sys/stat.h>
#include <dirent.h>

#include <CfigAvbOps.h>

static std::set<std::string> validPartitions;
static std::map<std::string, uint8_t *> preloaded_partitions_;
static std::string expected_public_key_;
static std::string expected_public_key_metadata_;

static auto lockStatusFile = "config/locked";
static auto pubkeyFile = "config/pubkey";

static std::string read_line(std::string file);

static size_t get_file_size(const char *filename);

static std::string getPartitionFile(std::string partition) {
    return std::string(partition) + ".img";
}

static size_t get_file_size(const char *filename) {
    struct stat st{};
    if (stat(filename, &st) != 0) {
        return -1;
    }
    return st.st_size;
}

static AvbIOResult read_is_device_unlockedX(AvbOps *, bool *out_is_unlocked) {
    std::string line = read_line(lockStatusFile);
    if ("0" == line) {
        *out_is_unlocked = true;
    } else {
        *out_is_unlocked = false;
    }
    std::cout << "[" << __FUNCTION__ << "], device is " << ((*out_is_unlocked) ? "unlocked" : "locked") << std::endl;

    return AVB_IO_RESULT_OK;
}

static constexpr char hexmap[] = {'0', '1', '2', '3', '4', '5', '6', '7',
                                  '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'};

std::string hexStr(const unsigned char *data, int len) {
    std::string s(len * 2, ' ');
    for (int i = 0; i < len; ++i) {
        s[2 * i] = hexmap[(data[i] & 0xF0) >> 4];
        s[2 * i + 1] = hexmap[data[i] & 0x0F];
    }
    return s;
}

bool write_to_file(std::string file, std::string value) {
    std::cout << "write_to_file(file=" << file << ", value=" << value << ")" << std::endl;
    FILE *fp;
    fp = fopen(file.c_str(), "w");
    if (fp == nullptr) {
        fprintf(stderr, "error opening file for writing:%s, (%s)", file.c_str(), strerror(errno));
        return true;
    }
    fprintf(fp, "%s\n", value.c_str());
    fclose(fp);
    return false;
}

static std::string read_line(std::string file) {
    std::ifstream ifs;
    std::string line;
    ifs.open(file, std::ifstream::in);
    if (ifs.is_open()) {
        std::getline(ifs, line);
        return line;
    } else {
        std::cerr << "can not open file " << file << std::endl;
        return "";
    }
}

//from: libavb_user/avb_ops_user.cpp
static AvbIOResult write_to_partitionX(AvbOps *,
                                       const char *partition,
                                       int64_t offset,
                                       size_t num_bytes,
                                       const void *buffer) {
    int fd;
    off_t where;
    ssize_t num_written;
    AvbIOResult ret;

    auto partitionFile = getPartitionFile(partition);
    fd = open(partitionFile.c_str(), O_WRONLY);
    if (fd == -1) {
        avb_errorv("Error opening \"", partition, "\" partition.\n", NULL);
        ret = AVB_IO_RESULT_ERROR_IO;
        goto out;
    }

    where = lseek(fd, offset, SEEK_SET);
    if (where == -1) {
        avb_error("Error seeking to offset.\n");
        ret = AVB_IO_RESULT_ERROR_IO;
        goto out;
    }
    if (where != offset) {
        avb_error("Error seeking to offset.\n");
        ret = AVB_IO_RESULT_ERROR_RANGE_OUTSIDE_PARTITION;
        goto out;
    }

    /* On Linux, we never get partial writes on block devices. */
    num_written = write(fd, buffer, num_bytes);
    if (num_written == -1) {
        avb_error("Error writing data.\n");
        ret = AVB_IO_RESULT_ERROR_IO;
        goto out;
    }

    ret = AVB_IO_RESULT_OK;

    out:
    if (fd != -1) {
        if (close(fd) != 0) {
            avb_error("Error closing file descriptor.\n");
        }
    }
    return ret;
}

static AvbIOResult get_size_of_partitionX(AvbOps *,
                                          const char *partition,
                                          uint64_t *out_size_num_bytes) {
    auto partitionFile = getPartitionFile(partition);
    if (validPartitions.find(partitionFile) == validPartitions.end()) {
        std::cout << "[" << __FUNCTION__ << "(" << partition << ")]: NO_SUCH_PARTITION" << std::endl;
        return AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION;
    }
    auto file_size = get_file_size(partitionFile.c_str());
    if (-1 == file_size) {
        std::cout << "[" << __FUNCTION__ << "(" << partition << ")]: ";
        std::cout << "error when accessing file [" << partitionFile << "]" << std::endl;
        return AVB_IO_RESULT_ERROR_IO;
    } else {
        std::cout << "[" << __FUNCTION__ << "(" << partition << ")]: ";
        std::cout << "partition " << partitionFile << " size: " << file_size << std::endl;
        if (out_size_num_bytes != nullptr) {
            *out_size_num_bytes = file_size;
        } else {
            std::cerr << "[" << __FUNCTION__ << "(" << partition << ")]: ";
            std::cerr << "size is not passed back" << std::endl;
        }
    }
    return AVB_IO_RESULT_OK;
}

static AvbIOResult read_from_partitionX(AvbOps *,
                                        const char *partition,
                                        int64_t offset,
                                        size_t num_bytes,
                                        void *buffer,
                                        size_t *out_num_read) {
    std::cout << "[" << __FUNCTION__ << "(partition=" << partition << ", offset=" << offset << ", num_bytes = "
              << num_bytes
              << ")]:" << std::endl;
    auto partitionFile = getPartitionFile(partition);
    if (validPartitions.find(partitionFile) == validPartitions.end()) {
        std::cout << "[" << __FUNCTION__ << "(" << partition << ")]: NO_SUCH_PARTITION" << std::endl;
        return AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION;
    }
    if (offset < 0) {
        uint64_t file_size;
        auto ret_get_size = get_size_of_partitionX(nullptr, partition, &file_size);
        if (AVB_IO_RESULT_OK != ret_get_size) {
            return ret_get_size;
        }
        offset = file_size - (-offset);
    }
    //open
    int fd = open(partitionFile.c_str(), O_RDONLY);
    if (fd < 0) {
        fprintf(stderr,
                "[%s()]: Error opening file '%s': %s\n",
                __FUNCTION__,
                partitionFile.c_str(),
                strerror(errno));
        if (errno == ENOENT) {
            return AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION;
        } else {
            return AVB_IO_RESULT_ERROR_IO;
        }
    }
    //seek
    if (lseek(fd, offset, SEEK_SET) != offset) {
        fprintf(stderr,
                "[%s()]: Error seeking to pos %ld in file %s: %s\n",
                __FUNCTION__,
                offset,
                partitionFile.c_str(),
                strerror(errno));
        close(fd);
        return AVB_IO_RESULT_ERROR_IO;
    }
    ssize_t num_read = read(fd, buffer, num_bytes);
    if (num_read < 0) {
        fprintf(stderr,
                "[%s()]: Error reading %zd bytes from pos %" PRId64 " in file %s: %s\n",
                __FUNCTION__,
                num_bytes,
                offset,
                partitionFile.c_str(),
                strerror(errno));
        close(fd);
        return AVB_IO_RESULT_ERROR_IO;
    }
    close(fd);
    if (out_num_read != nullptr) {
        *out_num_read = num_read;
    }
    if (num_read != num_bytes) {
        fprintf(stderr,
                "[%s()]: read fewer bytes from pos %" PRId64 " in file %s: exp=%zd, act=%zd\n",
                __FUNCTION__,
                offset,
                partitionFile.c_str(),
                num_bytes,
                num_read);
    } else {
        fprintf(stdout,
                "[%s()]: Read %ld bytes from partition %s\n",
                __FUNCTION__,
                num_read,
                partition);
    }
//    cout << hexStr((unsigned char *) buffer, num_read) << endl;

    return AVB_IO_RESULT_OK;
}

static AvbIOResult get_preloaded_partitionX(AvbOps *,
                                            const char *partition,
                                            size_t num_bytes,
                                            uint8_t **out_pointer,
                                            size_t *out_num_bytes_preloaded) {
    std::cout << "[" << __FUNCTION__ << "(partition=" << partition << ", num_bytes = " << num_bytes << ")]:"
              << std::endl;
    auto partitionFile = std::string(partition) + ".img";
    if (validPartitions.find(partitionFile) == validPartitions.end()) {
        std::cout << "[" << __FUNCTION__ << "(" << partition << ")]: NO_SUCH_PARTITION" << std::endl;
        return AVB_IO_RESULT_ERROR_NO_SUCH_PARTITION;
    }

    auto it = preloaded_partitions_.find(std::string(partition));
    if (it == preloaded_partitions_.end()) {
        fprintf(stdout, "[%s()]: partition [%s] not preloaded\n", __FUNCTION__, partition);
        *out_pointer = nullptr;
        *out_num_bytes_preloaded = 0;
        return AVB_IO_RESULT_OK;
    }

    uint64_t partSize;
    AvbIOResult result = get_size_of_partitionX(nullptr, partition, &partSize);
    if (result != AVB_IO_RESULT_OK) {
        std::cout << "[" << __FUNCTION__ << "()]: can not get size of partition: (" << partition << ")" << std::endl;
        return result;
    }

    if (num_bytes > partSize) {
        std::cout << "[" << __FUNCTION__ << "()]: size(" << partSize << ") < num_bytes(" << num_bytes << "), can not proceed"
                  << std::endl;
        return AVB_IO_RESULT_ERROR_IO;
    } else if (num_bytes < partSize) {
        *out_num_bytes_preloaded = num_bytes;
    } else {
        //exact match
        *out_num_bytes_preloaded = partSize;
    }

    *out_pointer = it->second;
    return AVB_IO_RESULT_OK;
}

static AvbIOResult validate_vbmeta_public_keyX(AvbOps *,
                                               const uint8_t *public_key_data,
                                               size_t public_key_length,
                                               const uint8_t *public_key_metadata,
                                               size_t public_key_metadata_length,
                                               bool *out_key_is_trusted) {
    if (out_key_is_trusted != nullptr) {
        bool pk_matches = (public_key_length == expected_public_key_.size() &&
                           (memcmp(expected_public_key_.c_str(),
                                   public_key_data,
                                   public_key_length) == 0));
        bool pkmd_matches =
                (public_key_metadata_length == expected_public_key_metadata_.size() &&
                 (memcmp(expected_public_key_metadata_.c_str(),
                         public_key_metadata,
                         public_key_metadata_length) == 0));
        std::cout << "[" << __FUNCTION__ << "(): " << "pk_matches = " << pk_matches << ", pkmd_matches = " << pkmd_matches << std::endl;
        *out_key_is_trusted = pk_matches && pkmd_matches;
    } else {
        std::cout << "[" << __FUNCTION__ << "(out_key_is_trusted = null)]: invalid arg" << std::endl;
    }

    return AVB_IO_RESULT_OK;
}

bool CfigAvbOps::preload_partition(std::string partition) {
    std::cout << "[" << __FUNCTION__ << "(" << partition << ")]:" << std::endl;
    if (preloaded_partitions_.count(partition) > 0) {
        fprintf(stderr, "\t: Partition '%s' already preloaded\n", partition.c_str());
        return false;
    }
    auto partitionFile = getPartitionFile(partition);
    uint64_t file_size;
    auto get_size_ret = get_size_of_partitionX(nullptr, partition.c_str(), &file_size);
    if (get_size_ret != AVB_IO_RESULT_OK) {
        return false;
    }

    int fd = open(partitionFile.c_str(), O_RDONLY);
    if (fd < 0) {
        fprintf(stderr,
                "[%s()]: Error opening file '%s': %s\n",
                __FUNCTION__,
                partitionFile.c_str(),
                strerror(errno));
        return false;
    }

    auto *buffer = static_cast<uint8_t *>(malloc(file_size));
    ssize_t num_read = read(fd, buffer, file_size);
    if (num_read < 0 || num_read != file_size) {
        fprintf(stderr,
                "[%s()]: Error reading %lld bytes from file '%s': %s\n",
                __FUNCTION__,
                file_size,
                partitionFile.c_str(),
                strerror(errno));
        free(buffer);
        return false;
    }
    close(fd);

    preloaded_partitions_[partition] = buffer;

    fprintf(stdout,
            "[%s()]: partition [%s] preloaded\n",
            __FUNCTION__,
            partition.c_str());
    return true;
}

static AvbIOResult read_rollback_indexX(AvbOps *,
                                        size_t rollback_index_location,
                                        uint64_t *out_rollback_index) {
    std::string line = read_line("config/rollbackIndex_" + std::to_string(rollback_index_location));
    if (line.empty()) {
        std::cout << "[" << __FUNCTION__ << "](loc=" << rollback_index_location << "), ret=ERROR_IO" << std::endl;
        return AVB_IO_RESULT_ERROR_IO;
    } else {
        uint64_t value;
        std::istringstream iss(line);
        iss >> value;
        if (out_rollback_index != nullptr) {
            *out_rollback_index = value;
            std::cout << "[" << __FUNCTION__ << "](loc=" << rollback_index_location << "), ret = " << value << std::endl;
        } else {
            std::cout << "[" << __FUNCTION__ << "](loc=" << rollback_index_location << "), ret = " << value
                      << ", value not passed out " << std::endl;
        }
        return AVB_IO_RESULT_OK;
    }
}

static AvbIOResult write_rollback_indexX(AvbOps *,
                                         size_t rollback_index_location,
                                         uint64_t rollback_index) {
    std::cout << "[" << __FUNCTION__ << "](loc=" << rollback_index_location << ", value=" << rollback_index << ")"
              << std::endl;
    if (write_to_file("config/rollbackIndex_" + std::to_string(rollback_index_location),
                      std::to_string(rollback_index))) {
        return AVB_IO_RESULT_OK;
    } else {
        return AVB_IO_RESULT_ERROR_IO;
    }
}

static AvbIOResult get_unique_guid_for_partitionX(AvbOps *,
                                                  const char *partition,
                                                  char *guid_buf,
                                                  size_t guid_buf_size) {
    std::string uuid = "1dddd936-20da-460a-834c-b938a89acab0";
    snprintf(guid_buf, guid_buf_size, "%s-%s", uuid.c_str(), partition);
    std::cout << "[" << __FUNCTION__ << "(" << partition << ")]: set fake value: " << guid_buf << std::endl;
    return AVB_IO_RESULT_OK;
}

//TODO:
static AvbIOResult read_persistent_valueX(AvbOps *,
                                          const char *name,
                                          size_t buffer_size,
                                          uint8_t *out_buffer,
                                          size_t *out_num_bytes_read) {
    std::cout << "[" << __FUNCTION__ << "()]: ret = AVB_IO_RESULT_ERROR_NO_SUCH_VALUE" << std::endl;
    return AVB_IO_RESULT_ERROR_NO_SUCH_VALUE;
}

//TODO:
static AvbIOResult write_persistent_valueX(AvbOps *,
                                           const char *name,
                                           size_t value_size,
                                           const uint8_t *value) {
    std::cout << "[" << __FUNCTION__ << "()]: ret = AVB_IO_RESULT_ERROR_NO_SUCH_VALUE" << std::endl;
    return AVB_IO_RESULT_ERROR_NO_SUCH_VALUE;
}

static AvbIOResult validate_public_key_for_partitionX(
        AvbOps *,
        const char *partition,
        const uint8_t *public_key_data,
        size_t public_key_length,
        const uint8_t *public_key_metadata,
        size_t public_key_metadata_length,
        bool *out_key_is_trusted,
        uint32_t *out_rollback_index_location) {
    std::cout << "[" << __FUNCTION__ << "(partition=" << partition << ")]:" << std::endl;
    if (out_key_is_trusted != nullptr) {
        bool pk_matches = (public_key_length == expected_public_key_.size() &&
                           (memcmp(expected_public_key_.c_str(),
                                   public_key_data,
                                   public_key_length) == 0));
        bool pkmd_matches =
                (public_key_metadata_length == expected_public_key_metadata_.size() &&
                 (memcmp(expected_public_key_metadata_.c_str(),
                         public_key_metadata,
                         public_key_metadata_length) == 0));
        *out_key_is_trusted = pk_matches && pkmd_matches;
    }

    return AVB_IO_RESULT_OK;
}

static void loadPubkey() {
    auto key_file = pubkeyFile;
    std::ifstream ifs(key_file, std::ios::binary | std::ios::ate);
    if (ifs) {
        std::cout << "[" << __FUNCTION__ << "()]:" << "loading key from " << key_file << std::endl;
        std::streamsize size = ifs.tellg();
        ifs.seekg(0, std::ios::beg);
        std::vector<char> buffer(size);
        ifs.read(buffer.data(), size);
        if (ifs.good()) {
            expected_public_key_ = std::string(buffer.begin(), buffer.end());
            std::ofstream ofs("out.key");
            ofs << expected_public_key_;
            ofs.close();
            std::cout << "[" << __FUNCTION__ << "()]:" << "pubkey read finished" << std::endl;
        } else {
            std::cout << "[" << __FUNCTION__ << "()]:" << "error: only " << ifs.gcount() << " could be read";
        }
        ifs.close();
    } else {
        std::cerr << "[" << __FUNCTION__ << "()]:" << "can not open pubkey file: " << pubkeyFile << std::endl;
        abort();
    }
}

static bool startsWith(const std::string &s, const std::string &sub) {
    return s.find(sub) == 0;
}

static bool endsWith(const std::string &s, const std::string &sub) {
    return (s.rfind(sub) == (s.length() - sub.length())) && (s.length() >= sub.length());
}

static void populatePartitions(const char *path) {
    struct dirent *entry;
    DIR *dir = opendir(path);
    if (dir == nullptr) {
        std::cerr << "[" << __FUNCTION__ << "(path=" << path << ")]:";
        std::cerr << ": can not open dir: " << path << std::endl;
        return;
    }
    while ((entry = readdir(dir)) != nullptr) {
        if (entry->d_type == DT_REG) {
            auto dn = std::string(entry->d_name);
            if (endsWith(dn, ".img")) {
                validPartitions.insert(dn);
                //std::cout << "Valid: " << dn << std::endl;
            } else {
                //pass
            }
        } else {
            //pass
        }
    }
    closedir(dir);
    std::cout << "[" << __FUNCTION__ << "(path=" << path << ")]: parts = { ";
    for (const auto &validPartition : validPartitions) {
        std::cout << validPartition << " ";
    }
    std::cout << "}" << std::endl;
}

static bool fileExists(const std::string &name) {
    struct stat buffer;
    return (stat(name.c_str(), &buffer) == 0);
}

CfigAvbOps::CfigAvbOps() {
    memset(&avb_ops_, 0, sizeof(AvbOps));
    avb_ops_.get_size_of_partition = get_size_of_partitionX;
    avb_ops_.get_preloaded_partition = get_preloaded_partitionX;
    avb_ops_.get_unique_guid_for_partition = get_unique_guid_for_partitionX;

    avb_ops_.read_from_partition = read_from_partitionX;
    avb_ops_.read_is_device_unlocked = read_is_device_unlockedX;
    avb_ops_.read_rollback_index = read_rollback_indexX;
    avb_ops_.read_persistent_value = read_persistent_valueX;

    avb_ops_.write_to_partition = write_to_partitionX;
    avb_ops_.write_rollback_index = write_rollback_indexX;
    avb_ops_.write_persistent_value = write_persistent_valueX;

    avb_ops_.validate_vbmeta_public_key = validate_vbmeta_public_keyX;
    avb_ops_.validate_public_key_for_partition = validate_public_key_for_partitionX;

    avb_ops_.user_data = this;

    loadPubkey();
    populatePartitions(".");
    if (!fileExists("config")) {
        std::cout << "init: config/ dir" << std::endl;
        if (-1 == mkdir("config", S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH)) {
            std::cout << "can not make config dir: " << errno << ", msg=" << strerror(errno) << std::endl;
        }
    }
    if (!fileExists(lockStatusFile)) {
        std::cout << __FUNCTION__ << ": lockStatusFile" << std::endl;
        write_to_file(lockStatusFile, "");
    }
    if (!fileExists("config/rollbackIndex_0")) {
        std::cout << "config/rollbackIndex_0" << std::endl;
        write_to_file("config/rollbackIndex_0", "0");
    }
    if (!fileExists("config/rollbackIndex_1")) {
        std::cout << "config/rollbackIndex_1" << std::endl;
        write_to_file("config/rollbackIndex_1", "0");
    }
}

```

`avbImpl/src/avbx/cpp/helper.cpp`:

```cpp
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include "helper.hpp"
#include <sstream>

std::string toString(const AvbSlotVerifyData* slotData) {
    if (!slotData) {
        return "{}";
    }
    std::stringstream ss;
    ss << "{";
    ss << "\"ab_suffix\":\"" << slotData->ab_suffix << "\",";
    ss << "\"num_vbmeta_images\":" <<  slotData->num_vbmeta_images << ",";

    ss << "\"vbmeta_images\":[";
    for (int i = 0; i < slotData->num_vbmeta_images; i++) {
        ss << toString(&((slotData->vbmeta_images)[i]));
        ss << ((i == slotData->num_vbmeta_images - 1) ? "" : ",");
    }
    ss << "],";

    ss << "\"num_loaded_partition\":\"" << slotData->num_loaded_partitions << "\",";

    ss << "\"loaded_partitions\":[";
    for (int i = 0; i < slotData->num_loaded_partitions; i++) {
        ss << toString(&((slotData->loaded_partitions)[i]));
        ss << ((i == slotData->num_loaded_partitions- 1) ? "" : ",");
    }
    ss << "],";

    ss << "\"cmdline\":\"" << slotData->cmdline << "\",";

    ss << "\"rollback_indexes\":[";
    for (int i = 0; i < AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS; i++) {
        ss << (slotData->rollback_indexes)[i];
        ss << ((i == AVB_MAX_NUMBER_OF_ROLLBACK_INDEX_LOCATIONS - 1) ? "" : ",");
    }
    ss << "],";

    ss << "\"resolved_hashtree_error_mode\":\"" << toString(slotData->resolved_hashtree_error_mode) << "\"";
    ss << "}";
    return ss.str();
}

std::string toString(AvbHashtreeErrorMode errorMode) {
    static const char* AvbHashtreeErrorMode_STRING[5] = {
        "AVB_HASHTREE_ERROR_MODE_RESTART_AND_INVALIDATE",
        "AVB_HASHTREE_ERROR_MODE_RESTART",
        "AVB_HASHTREE_ERROR_MODE_EIO",
        "AVB_HASHTREE_ERROR_MODE_LOGGING",
        "AVB_HASHTREE_ERROR_MODE_MANAGED_RESTART_AND_EIO",
    };
    return AvbHashtreeErrorMode_STRING[errorMode];
}

std::string toString(AvbSlotVerifyResult slotVerifyResult) {
    static const char* AvbSlotVerifyResult_STRING[9] = {
        "AVB_SLOT_VERIFY_RESULT_OK",
        "AVB_SLOT_VERIFY_RESULT_ERROR_OOM",
        "AVB_SLOT_VERIFY_RESULT_ERROR_IO",
        "AVB_SLOT_VERIFY_RESULT_ERROR_VERIFICATION",
        "AVB_SLOT_VERIFY_RESULT_ERROR_ROLLBACK_INDEX",
        "AVB_SLOT_VERIFY_RESULT_ERROR_PUBLIC_KEY_REJECTED",
        "AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA",
        "AVB_SLOT_VERIFY_RESULT_ERROR_UNSUPPORTED_VERSION",
        "AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_ARGUMENT",
    };
    return AvbSlotVerifyResult_STRING[slotVerifyResult];
}

std::string toString(const uint8_t* ba, int baSize) {
    //sb.append(Integer.toString((inData[i].toInt().and(0xff)) + 0x100, 16).substring(1))
    char byteStr[8] = { 0 };
    std::stringstream ss;
    for (int i = 0; i < baSize; i++) {
        sprintf(byteStr, "%02x", ba[i]);
        ss << byteStr;
    }
    return ss.str();
}

std::string toString(const AvbVBMetaData* vbmetaData) {
    std::stringstream ss;
    ss << "{";
    ss << "\"_type\":\"AvbVBMetaData\",";
    ss << "\"partition_name\":\"" << vbmetaData->partition_name << "\",";
    ss << "\"vbmeta_data\":\"" << toString((vbmetaData->vbmeta_data), vbmetaData->vbmeta_size) << "\",";
    ss << "\"vbmeta_size\":" << vbmetaData->vbmeta_size << ",";
    ss << "\"verify_result\":\"" << toString(vbmetaData->verify_result) << "\"";
    ss << "}";
    return ss.str();
}

std::string toString(/* enum */ AvbVBMetaVerifyResult metaVerifyResult) {
    static const char* AvbVBMetaVerifyResult_STRING[6] = {
        "AVB_VBMETA_VERIFY_RESULT_OK",
        "AVB_VBMETA_VERIFY_RESULT_OK_NOT_SIGNED",
        "AVB_VBMETA_VERIFY_RESULT_INVALID_VBMETA_HEADER",
        "AVB_VBMETA_VERIFY_RESULT_UNSUPPORTED_VERSION",
        "AVB_VBMETA_VERIFY_RESULT_HASH_MISMATCH",
        "AVB_VBMETA_VERIFY_RESULT_SIGNATURE_MISMATCH",
    };
    return AvbVBMetaVerifyResult_STRING[metaVerifyResult];
}

std::string toString(const AvbPartitionData* partitionData) {
    std::stringstream ss;
    ss << "{";
    ss << "\"partition_name\":\"" << partitionData->partition_name << "\",";
    //ss << "\"data\":\"" << toString(partitionData->data, partitionData->data_size) << "\",";
    ss << "\"data\":\"" << "omitted" << "\",";
    ss << "\"data_size\":\"" << partitionData->data_size << "\",";
    ss << "\"preloaded\":\"" << (partitionData->preloaded ? "true" : "false") << "\"";
    ss << "}";
    return ss.str();
}


```

`avbImpl/src/avbx/headers/CfigAvbOps.h`:

```h
/*
 * Copyright 2021 yuyezhong@gmail.com
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

//
// Created by yu on 8/30/19.
//

#ifndef X1_CFIGAVBOPS_H
#define X1_CFIGAVBOPS_H

#include <map>
#include <libavb.h>

class CfigAvbOps {
public:
    CfigAvbOps();

    bool preload_partition(std::string partition);

    AvbOps avb_ops_{};
};

#endif //X1_CFIGAVBOPS_H

```

`avbImpl/src/avbx/headers/helper.hpp`:

```hpp
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef HELPER_H
#define HELPER_H

#include <string>
#include <libavb.h>

std::string toString(const AvbSlotVerifyData* slotData);
std::string toString(const AvbVBMetaData* vbmetaData);
std::string toString(const AvbPartitionData* partitionData);
std::string toString(const uint8_t* ba, int baSize);
std::string toString(/* enum */ AvbHashtreeErrorMode errorMode);
std::string toString(/* enum */ AvbSlotVerifyResult slotVerifyResult);
std::string toString(/* enum */ AvbVBMetaVerifyResult metaVerifyResult);

#endif /* !HELPER_H */

```

`bbootimg/build.gradle.kts`:

```kts
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import org.jetbrains.kotlin.gradle.tasks.KotlinCompile

plugins {
    kotlin("jvm") version "1.8.0"
    application
}

repositories {
    mavenCentral()
}

dependencies {
    constraints {
        implementation("org.jetbrains.kotlin:kotlin-stdlib-jdk8")
    }

    //kotlin
    implementation(platform("org.jetbrains.kotlin:kotlin-bom"))
    implementation("org.jetbrains.kotlin:kotlin-stdlib-jdk8")
    implementation("org.jetbrains.kotlin:kotlin-reflect")

    implementation("cc.cfig:io:0.2")
    implementation("ch.qos.logback:logback-classic:1.2.11")
    implementation("com.fasterxml.jackson.core:jackson-annotations:2.13.3")
    implementation("com.fasterxml.jackson.core:jackson-databind:2.13.3")
    implementation("com.google.guava:guava:31.1-jre")
    implementation("org.apache.commons:commons-exec:1.3")
    implementation("org.apache.commons:commons-compress:1.21")
    implementation("org.tukaani:xz:1.9")
    implementation("commons-codec:commons-codec:1.15")
    implementation("junit:junit:4.13.2")
    implementation("org.bouncycastle:bcprov-jdk15on:1.70")
    implementation("de.vandermeer:asciitable:0.3.2")
    implementation("com.google.protobuf:protobuf-java:3.21.1")
    implementation(project(":helper"))

    testImplementation("org.jetbrains.kotlin:kotlin-test")
    testImplementation("org.jetbrains.kotlin:kotlin-test-junit")
}

application {
    mainClass.set("cfig.packable.PackableLauncherKt")
}

tasks.withType<KotlinCompile>().all {
    kotlinOptions {
        freeCompilerArgs += "-opt-in=kotlin.RequiresOptIn"
        freeCompilerArgs += "-opt-in=kotlin.ExperimentalUnsignedTypes"
        jvmTarget = "17"
    }
}

tasks {
    jar {
        manifest {
            attributes["Implementation-Title"] = "Android image reverse engineering toolkit"
            attributes["Main-Class"] = "cfig.packable.PackableLauncherKt"
        }
        from(configurations.runtimeClasspath.get().map({ if (it.isDirectory) it else zipTree(it) }))
        excludes.addAll(mutableSetOf("META-INF/*.RSA", "META-INF/*.SF", "META-INF/*.DSA"))
        duplicatesStrategy = DuplicatesStrategy.EXCLUDE
        dependsOn(":helper:jar")
    }
    test {
        testLogging {
            showExceptions = true
            showStackTraces = true
        }
    }
}

```

`bbootimg/gradle.properties`:

```properties
kotlin.code.style=official

```

`bbootimg/src/main/java/chromeos_update_engine/UpdateMetadata.java`:

```java
// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: update_metadata.proto

package chromeos_update_engine;

public final class UpdateMetadata {
  private UpdateMetadata() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface ExtentOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.Extent)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional uint64 start_block = 1;</code>
     * @return Whether the startBlock field is set.
     */
    boolean hasStartBlock();
    /**
     * <code>optional uint64 start_block = 1;</code>
     * @return The startBlock.
     */
    long getStartBlock();

    /**
     * <code>optional uint64 num_blocks = 2;</code>
     * @return Whether the numBlocks field is set.
     */
    boolean hasNumBlocks();
    /**
     * <code>optional uint64 num_blocks = 2;</code>
     * @return The numBlocks.
     */
    long getNumBlocks();
  }
  /**
   * Protobuf type {@code chromeos_update_engine.Extent}
   */
  public static final class Extent extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.Extent)
      ExtentOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Extent.newBuilder() to construct.
    private Extent(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Extent() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Extent();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Extent(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              startBlock_ = input.readUInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numBlocks_ = input.readUInt64();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Extent_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Extent_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.Extent.class, chromeos_update_engine.UpdateMetadata.Extent.Builder.class);
    }

    private int bitField0_;
    public static final int START_BLOCK_FIELD_NUMBER = 1;
    private long startBlock_;
    /**
     * <code>optional uint64 start_block = 1;</code>
     * @return Whether the startBlock field is set.
     */
    @java.lang.Override
    public boolean hasStartBlock() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional uint64 start_block = 1;</code>
     * @return The startBlock.
     */
    @java.lang.Override
    public long getStartBlock() {
      return startBlock_;
    }

    public static final int NUM_BLOCKS_FIELD_NUMBER = 2;
    private long numBlocks_;
    /**
     * <code>optional uint64 num_blocks = 2;</code>
     * @return Whether the numBlocks field is set.
     */
    @java.lang.Override
    public boolean hasNumBlocks() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional uint64 num_blocks = 2;</code>
     * @return The numBlocks.
     */
    @java.lang.Override
    public long getNumBlocks() {
      return numBlocks_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(1, startBlock_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt64(2, numBlocks_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, startBlock_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, numBlocks_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.Extent)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.Extent other = (chromeos_update_engine.UpdateMetadata.Extent) obj;

      if (hasStartBlock() != other.hasStartBlock()) return false;
      if (hasStartBlock()) {
        if (getStartBlock()
            != other.getStartBlock()) return false;
      }
      if (hasNumBlocks() != other.hasNumBlocks()) return false;
      if (hasNumBlocks()) {
        if (getNumBlocks()
            != other.getNumBlocks()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStartBlock()) {
        hash = (37 * hash) + START_BLOCK_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getStartBlock());
      }
      if (hasNumBlocks()) {
        hash = (37 * hash) + NUM_BLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getNumBlocks());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.Extent parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.Extent prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code chromeos_update_engine.Extent}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.Extent)
        chromeos_update_engine.UpdateMetadata.ExtentOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Extent_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Extent_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.Extent.class, chromeos_update_engine.UpdateMetadata.Extent.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.Extent.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        startBlock_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        numBlocks_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Extent_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Extent getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Extent build() {
        chromeos_update_engine.UpdateMetadata.Extent result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Extent buildPartial() {
        chromeos_update_engine.UpdateMetadata.Extent result = new chromeos_update_engine.UpdateMetadata.Extent(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.startBlock_ = startBlock_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.numBlocks_ = numBlocks_;
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.Extent) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.Extent)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.Extent other) {
        if (other == chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance()) return this;
        if (other.hasStartBlock()) {
          setStartBlock(other.getStartBlock());
        }
        if (other.hasNumBlocks()) {
          setNumBlocks(other.getNumBlocks());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.Extent parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.Extent) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long startBlock_ ;
      /**
       * <code>optional uint64 start_block = 1;</code>
       * @return Whether the startBlock field is set.
       */
      @java.lang.Override
      public boolean hasStartBlock() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional uint64 start_block = 1;</code>
       * @return The startBlock.
       */
      @java.lang.Override
      public long getStartBlock() {
        return startBlock_;
      }
      /**
       * <code>optional uint64 start_block = 1;</code>
       * @param value The startBlock to set.
       * @return This builder for chaining.
       */
      public Builder setStartBlock(long value) {
        bitField0_ |= 0x00000001;
        startBlock_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 start_block = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearStartBlock() {
        bitField0_ = (bitField0_ & ~0x00000001);
        startBlock_ = 0L;
        onChanged();
        return this;
      }

      private long numBlocks_ ;
      /**
       * <code>optional uint64 num_blocks = 2;</code>
       * @return Whether the numBlocks field is set.
       */
      @java.lang.Override
      public boolean hasNumBlocks() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint64 num_blocks = 2;</code>
       * @return The numBlocks.
       */
      @java.lang.Override
      public long getNumBlocks() {
        return numBlocks_;
      }
      /**
       * <code>optional uint64 num_blocks = 2;</code>
       * @param value The numBlocks to set.
       * @return This builder for chaining.
       */
      public Builder setNumBlocks(long value) {
        bitField0_ |= 0x00000002;
        numBlocks_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 num_blocks = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearNumBlocks() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numBlocks_ = 0L;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.Extent)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.Extent)
    private static final chromeos_update_engine.UpdateMetadata.Extent DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.Extent();
    }

    public static chromeos_update_engine.UpdateMetadata.Extent getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<Extent>
        PARSER = new com.google.protobuf.AbstractParser<Extent>() {
      @java.lang.Override
      public Extent parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Extent(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Extent> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Extent> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SignaturesOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.Signatures)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature>
        getSignaturesList();
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    chromeos_update_engine.UpdateMetadata.Signatures.Signature getSignatures(int index);
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    int getSignaturesCount();
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
        getSignaturesOrBuilderList();
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder getSignaturesOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code chromeos_update_engine.Signatures}
   */
  public static final class Signatures extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.Signatures)
      SignaturesOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Signatures.newBuilder() to construct.
    private Signatures(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Signatures() {
      signatures_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Signatures();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Signatures(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                signatures_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Signatures.Signature>();
                mutable_bitField0_ |= 0x00000001;
              }
              signatures_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.Signatures.Signature.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          signatures_ = java.util.Collections.unmodifiableList(signatures_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.Signatures.class, chromeos_update_engine.UpdateMetadata.Signatures.Builder.class);
    }

    public interface SignatureOrBuilder extends
        // @@protoc_insertion_point(interface_extends:chromeos_update_engine.Signatures.Signature)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <code>optional uint32 version = 1 [deprecated = true];</code>
       * @return Whether the version field is set.
       */
      @java.lang.Deprecated boolean hasVersion();
      /**
       * <code>optional uint32 version = 1 [deprecated = true];</code>
       * @return The version.
       */
      @java.lang.Deprecated int getVersion();

      /**
       * <code>optional bytes data = 2;</code>
       * @return Whether the data field is set.
       */
      boolean hasData();
      /**
       * <code>optional bytes data = 2;</code>
       * @return The data.
       */
      com.google.protobuf.ByteString getData();

      /**
       * <pre>
       * The DER encoded signature size of EC keys is nondeterministic for
       * different input of sha256 hash. However, we need the size of the
       * serialized signatures protobuf string to be fixed before signing;
       * because this size is part of the content to be signed. Therefore, we
       * always pad the signature data to the maximum possible signature size of
       * a given key. And the payload verifier will truncate the signature to
       * its correct size based on the value of |unpadded_signature_size|.
       * </pre>
       *
       * <code>optional fixed32 unpadded_signature_size = 3;</code>
       * @return Whether the unpaddedSignatureSize field is set.
       */
      boolean hasUnpaddedSignatureSize();
      /**
       * <pre>
       * The DER encoded signature size of EC keys is nondeterministic for
       * different input of sha256 hash. However, we need the size of the
       * serialized signatures protobuf string to be fixed before signing;
       * because this size is part of the content to be signed. Therefore, we
       * always pad the signature data to the maximum possible signature size of
       * a given key. And the payload verifier will truncate the signature to
       * its correct size based on the value of |unpadded_signature_size|.
       * </pre>
       *
       * <code>optional fixed32 unpadded_signature_size = 3;</code>
       * @return The unpaddedSignatureSize.
       */
      int getUnpaddedSignatureSize();
    }
    /**
     * Protobuf type {@code chromeos_update_engine.Signatures.Signature}
     */
    public static final class Signature extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:chromeos_update_engine.Signatures.Signature)
        SignatureOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Signature.newBuilder() to construct.
      private Signature(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Signature() {
        data_ = com.google.protobuf.ByteString.EMPTY;
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Signature();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Signature(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                bitField0_ |= 0x00000001;
                version_ = input.readUInt32();
                break;
              }
              case 18: {
                bitField0_ |= 0x00000002;
                data_ = input.readBytes();
                break;
              }
              case 29: {
                bitField0_ |= 0x00000004;
                unpaddedSignatureSize_ = input.readFixed32();
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_Signature_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_Signature_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.Signatures.Signature.class, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder.class);
      }

      private int bitField0_;
      public static final int VERSION_FIELD_NUMBER = 1;
      private int version_;
      /**
       * <code>optional uint32 version = 1 [deprecated = true];</code>
       * @return Whether the version field is set.
       */
      @java.lang.Override
      @java.lang.Deprecated public boolean hasVersion() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional uint32 version = 1 [deprecated = true];</code>
       * @return The version.
       */
      @java.lang.Override
      @java.lang.Deprecated public int getVersion() {
        return version_;
      }

      public static final int DATA_FIELD_NUMBER = 2;
      private com.google.protobuf.ByteString data_;
      /**
       * <code>optional bytes data = 2;</code>
       * @return Whether the data field is set.
       */
      @java.lang.Override
      public boolean hasData() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes data = 2;</code>
       * @return The data.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getData() {
        return data_;
      }

      public static final int UNPADDED_SIGNATURE_SIZE_FIELD_NUMBER = 3;
      private int unpaddedSignatureSize_;
      /**
       * <pre>
       * The DER encoded signature size of EC keys is nondeterministic for
       * different input of sha256 hash. However, we need the size of the
       * serialized signatures protobuf string to be fixed before signing;
       * because this size is part of the content to be signed. Therefore, we
       * always pad the signature data to the maximum possible signature size of
       * a given key. And the payload verifier will truncate the signature to
       * its correct size based on the value of |unpadded_signature_size|.
       * </pre>
       *
       * <code>optional fixed32 unpadded_signature_size = 3;</code>
       * @return Whether the unpaddedSignatureSize field is set.
       */
      @java.lang.Override
      public boolean hasUnpaddedSignatureSize() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * The DER encoded signature size of EC keys is nondeterministic for
       * different input of sha256 hash. However, we need the size of the
       * serialized signatures protobuf string to be fixed before signing;
       * because this size is part of the content to be signed. Therefore, we
       * always pad the signature data to the maximum possible signature size of
       * a given key. And the payload verifier will truncate the signature to
       * its correct size based on the value of |unpadded_signature_size|.
       * </pre>
       *
       * <code>optional fixed32 unpadded_signature_size = 3;</code>
       * @return The unpaddedSignatureSize.
       */
      @java.lang.Override
      public int getUnpaddedSignatureSize() {
        return unpaddedSignatureSize_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeUInt32(1, version_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          output.writeBytes(2, data_);
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          output.writeFixed32(3, unpaddedSignatureSize_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeUInt32Size(1, version_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(2, data_);
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeFixed32Size(3, unpaddedSignatureSize_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof chromeos_update_engine.UpdateMetadata.Signatures.Signature)) {
          return super.equals(obj);
        }
        chromeos_update_engine.UpdateMetadata.Signatures.Signature other = (chromeos_update_engine.UpdateMetadata.Signatures.Signature) obj;

        if (hasVersion() != other.hasVersion()) return false;
        if (hasVersion()) {
          if (getVersion()
              != other.getVersion()) return false;
        }
        if (hasData() != other.hasData()) return false;
        if (hasData()) {
          if (!getData()
              .equals(other.getData())) return false;
        }
        if (hasUnpaddedSignatureSize() != other.hasUnpaddedSignatureSize()) return false;
        if (hasUnpaddedSignatureSize()) {
          if (getUnpaddedSignatureSize()
              != other.getUnpaddedSignatureSize()) return false;
        }
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasVersion()) {
          hash = (37 * hash) + VERSION_FIELD_NUMBER;
          hash = (53 * hash) + getVersion();
        }
        if (hasData()) {
          hash = (37 * hash) + DATA_FIELD_NUMBER;
          hash = (53 * hash) + getData().hashCode();
        }
        if (hasUnpaddedSignatureSize()) {
          hash = (37 * hash) + UNPADDED_SIGNATURE_SIZE_FIELD_NUMBER;
          hash = (53 * hash) + getUnpaddedSignatureSize();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.Signatures.Signature prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code chromeos_update_engine.Signatures.Signature}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:chromeos_update_engine.Signatures.Signature)
          chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_Signature_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_Signature_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  chromeos_update_engine.UpdateMetadata.Signatures.Signature.class, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder.class);
        }

        // Construct using chromeos_update_engine.UpdateMetadata.Signatures.Signature.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          version_ = 0;
          bitField0_ = (bitField0_ & ~0x00000001);
          data_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000002);
          unpaddedSignatureSize_ = 0;
          bitField0_ = (bitField0_ & ~0x00000004);
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_Signature_descriptor;
        }

        @java.lang.Override
        public chromeos_update_engine.UpdateMetadata.Signatures.Signature getDefaultInstanceForType() {
          return chromeos_update_engine.UpdateMetadata.Signatures.Signature.getDefaultInstance();
        }

        @java.lang.Override
        public chromeos_update_engine.UpdateMetadata.Signatures.Signature build() {
          chromeos_update_engine.UpdateMetadata.Signatures.Signature result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public chromeos_update_engine.UpdateMetadata.Signatures.Signature buildPartial() {
          chromeos_update_engine.UpdateMetadata.Signatures.Signature result = new chromeos_update_engine.UpdateMetadata.Signatures.Signature(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.version_ = version_;
            to_bitField0_ |= 0x00000001;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            to_bitField0_ |= 0x00000002;
          }
          result.data_ = data_;
          if (((from_bitField0_ & 0x00000004) != 0)) {
            result.unpaddedSignatureSize_ = unpaddedSignatureSize_;
            to_bitField0_ |= 0x00000004;
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof chromeos_update_engine.UpdateMetadata.Signatures.Signature) {
            return mergeFrom((chromeos_update_engine.UpdateMetadata.Signatures.Signature)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.Signatures.Signature other) {
          if (other == chromeos_update_engine.UpdateMetadata.Signatures.Signature.getDefaultInstance()) return this;
          if (other.hasVersion()) {
            setVersion(other.getVersion());
          }
          if (other.hasData()) {
            setData(other.getData());
          }
          if (other.hasUnpaddedSignatureSize()) {
            setUnpaddedSignatureSize(other.getUnpaddedSignatureSize());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          chromeos_update_engine.UpdateMetadata.Signatures.Signature parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (chromeos_update_engine.UpdateMetadata.Signatures.Signature) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private int version_ ;
        /**
         * <code>optional uint32 version = 1 [deprecated = true];</code>
         * @return Whether the version field is set.
         */
        @java.lang.Override
        @java.lang.Deprecated public boolean hasVersion() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>optional uint32 version = 1 [deprecated = true];</code>
         * @return The version.
         */
        @java.lang.Override
        @java.lang.Deprecated public int getVersion() {
          return version_;
        }
        /**
         * <code>optional uint32 version = 1 [deprecated = true];</code>
         * @param value The version to set.
         * @return This builder for chaining.
         */
        @java.lang.Deprecated public Builder setVersion(int value) {
          bitField0_ |= 0x00000001;
          version_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional uint32 version = 1 [deprecated = true];</code>
         * @return This builder for chaining.
         */
        @java.lang.Deprecated public Builder clearVersion() {
          bitField0_ = (bitField0_ & ~0x00000001);
          version_ = 0;
          onChanged();
          return this;
        }

        private com.google.protobuf.ByteString data_ = com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>optional bytes data = 2;</code>
         * @return Whether the data field is set.
         */
        @java.lang.Override
        public boolean hasData() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>optional bytes data = 2;</code>
         * @return The data.
         */
        @java.lang.Override
        public com.google.protobuf.ByteString getData() {
          return data_;
        }
        /**
         * <code>optional bytes data = 2;</code>
         * @param value The data to set.
         * @return This builder for chaining.
         */
        public Builder setData(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
          data_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional bytes data = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearData() {
          bitField0_ = (bitField0_ & ~0x00000002);
          data_ = getDefaultInstance().getData();
          onChanged();
          return this;
        }

        private int unpaddedSignatureSize_ ;
        /**
         * <pre>
         * The DER encoded signature size of EC keys is nondeterministic for
         * different input of sha256 hash. However, we need the size of the
         * serialized signatures protobuf string to be fixed before signing;
         * because this size is part of the content to be signed. Therefore, we
         * always pad the signature data to the maximum possible signature size of
         * a given key. And the payload verifier will truncate the signature to
         * its correct size based on the value of |unpadded_signature_size|.
         * </pre>
         *
         * <code>optional fixed32 unpadded_signature_size = 3;</code>
         * @return Whether the unpaddedSignatureSize field is set.
         */
        @java.lang.Override
        public boolean hasUnpaddedSignatureSize() {
          return ((bitField0_ & 0x00000004) != 0);
        }
        /**
         * <pre>
         * The DER encoded signature size of EC keys is nondeterministic for
         * different input of sha256 hash. However, we need the size of the
         * serialized signatures protobuf string to be fixed before signing;
         * because this size is part of the content to be signed. Therefore, we
         * always pad the signature data to the maximum possible signature size of
         * a given key. And the payload verifier will truncate the signature to
         * its correct size based on the value of |unpadded_signature_size|.
         * </pre>
         *
         * <code>optional fixed32 unpadded_signature_size = 3;</code>
         * @return The unpaddedSignatureSize.
         */
        @java.lang.Override
        public int getUnpaddedSignatureSize() {
          return unpaddedSignatureSize_;
        }
        /**
         * <pre>
         * The DER encoded signature size of EC keys is nondeterministic for
         * different input of sha256 hash. However, we need the size of the
         * serialized signatures protobuf string to be fixed before signing;
         * because this size is part of the content to be signed. Therefore, we
         * always pad the signature data to the maximum possible signature size of
         * a given key. And the payload verifier will truncate the signature to
         * its correct size based on the value of |unpadded_signature_size|.
         * </pre>
         *
         * <code>optional fixed32 unpadded_signature_size = 3;</code>
         * @param value The unpaddedSignatureSize to set.
         * @return This builder for chaining.
         */
        public Builder setUnpaddedSignatureSize(int value) {
          bitField0_ |= 0x00000004;
          unpaddedSignatureSize_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * The DER encoded signature size of EC keys is nondeterministic for
         * different input of sha256 hash. However, we need the size of the
         * serialized signatures protobuf string to be fixed before signing;
         * because this size is part of the content to be signed. Therefore, we
         * always pad the signature data to the maximum possible signature size of
         * a given key. And the payload verifier will truncate the signature to
         * its correct size based on the value of |unpadded_signature_size|.
         * </pre>
         *
         * <code>optional fixed32 unpadded_signature_size = 3;</code>
         * @return This builder for chaining.
         */
        public Builder clearUnpaddedSignatureSize() {
          bitField0_ = (bitField0_ & ~0x00000004);
          unpaddedSignatureSize_ = 0;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:chromeos_update_engine.Signatures.Signature)
      }

      // @@protoc_insertion_point(class_scope:chromeos_update_engine.Signatures.Signature)
      private static final chromeos_update_engine.UpdateMetadata.Signatures.Signature DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.Signatures.Signature();
      }

      public static chromeos_update_engine.UpdateMetadata.Signatures.Signature getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final com.google.protobuf.Parser<Signature>
          PARSER = new com.google.protobuf.AbstractParser<Signature>() {
        @java.lang.Override
        public Signature parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Signature(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Signature> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Signature> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int SIGNATURES_FIELD_NUMBER = 1;
    private java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> signatures_;
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> getSignaturesList() {
      return signatures_;
    }
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
        getSignaturesOrBuilderList() {
      return signatures_;
    }
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    @java.lang.Override
    public int getSignaturesCount() {
      return signatures_.size();
    }
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Signatures.Signature getSignatures(int index) {
      return signatures_.get(index);
    }
    /**
     * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder getSignaturesOrBuilder(
        int index) {
      return signatures_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < signatures_.size(); i++) {
        output.writeMessage(1, signatures_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < signatures_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, signatures_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.Signatures)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.Signatures other = (chromeos_update_engine.UpdateMetadata.Signatures) obj;

      if (!getSignaturesList()
          .equals(other.getSignaturesList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getSignaturesCount() > 0) {
        hash = (37 * hash) + SIGNATURES_FIELD_NUMBER;
        hash = (53 * hash) + getSignaturesList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.Signatures parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.Signatures prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code chromeos_update_engine.Signatures}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.Signatures)
        chromeos_update_engine.UpdateMetadata.SignaturesOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.Signatures.class, chromeos_update_engine.UpdateMetadata.Signatures.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.Signatures.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSignaturesFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (signaturesBuilder_ == null) {
          signatures_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          signaturesBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_Signatures_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Signatures getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.Signatures.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Signatures build() {
        chromeos_update_engine.UpdateMetadata.Signatures result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.Signatures buildPartial() {
        chromeos_update_engine.UpdateMetadata.Signatures result = new chromeos_update_engine.UpdateMetadata.Signatures(this);
        int from_bitField0_ = bitField0_;
        if (signaturesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            signatures_ = java.util.Collections.unmodifiableList(signatures_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.signatures_ = signatures_;
        } else {
          result.signatures_ = signaturesBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.Signatures) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.Signatures)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.Signatures other) {
        if (other == chromeos_update_engine.UpdateMetadata.Signatures.getDefaultInstance()) return this;
        if (signaturesBuilder_ == null) {
          if (!other.signatures_.isEmpty()) {
            if (signatures_.isEmpty()) {
              signatures_ = other.signatures_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureSignaturesIsMutable();
              signatures_.addAll(other.signatures_);
            }
            onChanged();
          }
        } else {
          if (!other.signatures_.isEmpty()) {
            if (signaturesBuilder_.isEmpty()) {
              signaturesBuilder_.dispose();
              signaturesBuilder_ = null;
              signatures_ = other.signatures_;
              bitField0_ = (bitField0_ & ~0x00000001);
              signaturesBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSignaturesFieldBuilder() : null;
            } else {
              signaturesBuilder_.addAllMessages(other.signatures_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.Signatures parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.Signatures) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> signatures_ =
        java.util.Collections.emptyList();
      private void ensureSignaturesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          signatures_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Signatures.Signature>(signatures_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Signatures.Signature, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder, chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder> signaturesBuilder_;

      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> getSignaturesList() {
        if (signaturesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(signatures_);
        } else {
          return signaturesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public int getSignaturesCount() {
        if (signaturesBuilder_ == null) {
          return signatures_.size();
        } else {
          return signaturesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature getSignatures(int index) {
        if (signaturesBuilder_ == null) {
          return signatures_.get(index);
        } else {
          return signaturesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder setSignatures(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature value) {
        if (signaturesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSignaturesIsMutable();
          signatures_.set(index, value);
          onChanged();
        } else {
          signaturesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder setSignatures(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder builderForValue) {
        if (signaturesBuilder_ == null) {
          ensureSignaturesIsMutable();
          signatures_.set(index, builderForValue.build());
          onChanged();
        } else {
          signaturesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder addSignatures(chromeos_update_engine.UpdateMetadata.Signatures.Signature value) {
        if (signaturesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSignaturesIsMutable();
          signatures_.add(value);
          onChanged();
        } else {
          signaturesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder addSignatures(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature value) {
        if (signaturesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSignaturesIsMutable();
          signatures_.add(index, value);
          onChanged();
        } else {
          signaturesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder addSignatures(
          chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder builderForValue) {
        if (signaturesBuilder_ == null) {
          ensureSignaturesIsMutable();
          signatures_.add(builderForValue.build());
          onChanged();
        } else {
          signaturesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder addSignatures(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder builderForValue) {
        if (signaturesBuilder_ == null) {
          ensureSignaturesIsMutable();
          signatures_.add(index, builderForValue.build());
          onChanged();
        } else {
          signaturesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder addAllSignatures(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.Signatures.Signature> values) {
        if (signaturesBuilder_ == null) {
          ensureSignaturesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, signatures_);
          onChanged();
        } else {
          signaturesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder clearSignatures() {
        if (signaturesBuilder_ == null) {
          signatures_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          signaturesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public Builder removeSignatures(int index) {
        if (signaturesBuilder_ == null) {
          ensureSignaturesIsMutable();
          signatures_.remove(index);
          onChanged();
        } else {
          signaturesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder getSignaturesBuilder(
          int index) {
        return getSignaturesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder getSignaturesOrBuilder(
          int index) {
        if (signaturesBuilder_ == null) {
          return signatures_.get(index);  } else {
          return signaturesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
           getSignaturesOrBuilderList() {
        if (signaturesBuilder_ != null) {
          return signaturesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(signatures_);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder addSignaturesBuilder() {
        return getSignaturesFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.Signatures.Signature.getDefaultInstance());
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder addSignaturesBuilder(
          int index) {
        return getSignaturesFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.Signatures.Signature.getDefaultInstance());
      }
      /**
       * <code>repeated .chromeos_update_engine.Signatures.Signature signatures = 1;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder>
           getSignaturesBuilderList() {
        return getSignaturesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Signatures.Signature, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder, chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
          getSignaturesFieldBuilder() {
        if (signaturesBuilder_ == null) {
          signaturesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Signatures.Signature, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder, chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>(
                  signatures_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          signatures_ = null;
        }
        return signaturesBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.Signatures)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.Signatures)
    private static final chromeos_update_engine.UpdateMetadata.Signatures DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.Signatures();
    }

    public static chromeos_update_engine.UpdateMetadata.Signatures getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<Signatures>
        PARSER = new com.google.protobuf.AbstractParser<Signatures>() {
      @java.lang.Override
      public Signatures parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Signatures(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Signatures> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Signatures> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Signatures getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PartitionInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.PartitionInfo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional uint64 size = 1;</code>
     * @return Whether the size field is set.
     */
    boolean hasSize();
    /**
     * <code>optional uint64 size = 1;</code>
     * @return The size.
     */
    long getSize();

    /**
     * <code>optional bytes hash = 2;</code>
     * @return Whether the hash field is set.
     */
    boolean hasHash();
    /**
     * <code>optional bytes hash = 2;</code>
     * @return The hash.
     */
    com.google.protobuf.ByteString getHash();
  }
  /**
   * Protobuf type {@code chromeos_update_engine.PartitionInfo}
   */
  public static final class PartitionInfo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.PartitionInfo)
      PartitionInfoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PartitionInfo.newBuilder() to construct.
    private PartitionInfo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PartitionInfo() {
      hash_ = com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PartitionInfo();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PartitionInfo(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              size_ = input.readUInt64();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              hash_ = input.readBytes();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionInfo_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.PartitionInfo.class, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder.class);
    }

    private int bitField0_;
    public static final int SIZE_FIELD_NUMBER = 1;
    private long size_;
    /**
     * <code>optional uint64 size = 1;</code>
     * @return Whether the size field is set.
     */
    @java.lang.Override
    public boolean hasSize() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional uint64 size = 1;</code>
     * @return The size.
     */
    @java.lang.Override
    public long getSize() {
      return size_;
    }

    public static final int HASH_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString hash_;
    /**
     * <code>optional bytes hash = 2;</code>
     * @return Whether the hash field is set.
     */
    @java.lang.Override
    public boolean hasHash() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bytes hash = 2;</code>
     * @return The hash.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getHash() {
      return hash_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt64(1, size_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBytes(2, hash_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, size_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, hash_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.PartitionInfo)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.PartitionInfo other = (chromeos_update_engine.UpdateMetadata.PartitionInfo) obj;

      if (hasSize() != other.hasSize()) return false;
      if (hasSize()) {
        if (getSize()
            != other.getSize()) return false;
      }
      if (hasHash() != other.hasHash()) return false;
      if (hasHash()) {
        if (!getHash()
            .equals(other.getHash())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSize()) {
        hash = (37 * hash) + SIZE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSize());
      }
      if (hasHash()) {
        hash = (37 * hash) + HASH_FIELD_NUMBER;
        hash = (53 * hash) + getHash().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.PartitionInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code chromeos_update_engine.PartitionInfo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.PartitionInfo)
        chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionInfo_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.PartitionInfo.class, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        size_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        hash_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionInfo_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.PartitionInfo build() {
        chromeos_update_engine.UpdateMetadata.PartitionInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.PartitionInfo buildPartial() {
        chromeos_update_engine.UpdateMetadata.PartitionInfo result = new chromeos_update_engine.UpdateMetadata.PartitionInfo(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.size_ = size_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.hash_ = hash_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.PartitionInfo) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.PartitionInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.PartitionInfo other) {
        if (other == chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) return this;
        if (other.hasSize()) {
          setSize(other.getSize());
        }
        if (other.hasHash()) {
          setHash(other.getHash());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.PartitionInfo parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.PartitionInfo) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long size_ ;
      /**
       * <code>optional uint64 size = 1;</code>
       * @return Whether the size field is set.
       */
      @java.lang.Override
      public boolean hasSize() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional uint64 size = 1;</code>
       * @return The size.
       */
      @java.lang.Override
      public long getSize() {
        return size_;
      }
      /**
       * <code>optional uint64 size = 1;</code>
       * @param value The size to set.
       * @return This builder for chaining.
       */
      public Builder setSize(long value) {
        bitField0_ |= 0x00000001;
        size_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 size = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearSize() {
        bitField0_ = (bitField0_ & ~0x00000001);
        size_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.ByteString hash_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes hash = 2;</code>
       * @return Whether the hash field is set.
       */
      @java.lang.Override
      public boolean hasHash() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bytes hash = 2;</code>
       * @return The hash.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getHash() {
        return hash_;
      }
      /**
       * <code>optional bytes hash = 2;</code>
       * @param value The hash to set.
       * @return This builder for chaining.
       */
      public Builder setHash(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        hash_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes hash = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearHash() {
        bitField0_ = (bitField0_ & ~0x00000002);
        hash_ = getDefaultInstance().getHash();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.PartitionInfo)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.PartitionInfo)
    private static final chromeos_update_engine.UpdateMetadata.PartitionInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.PartitionInfo();
    }

    public static chromeos_update_engine.UpdateMetadata.PartitionInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PartitionInfo>
        PARSER = new com.google.protobuf.AbstractParser<PartitionInfo>() {
      @java.lang.Override
      public PartitionInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PartitionInfo(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PartitionInfo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PartitionInfo> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ImageInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.ImageInfo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string board = 1;</code>
     * @return Whether the board field is set.
     */
    boolean hasBoard();
    /**
     * <code>optional string board = 1;</code>
     * @return The board.
     */
    java.lang.String getBoard();
    /**
     * <code>optional string board = 1;</code>
     * @return The bytes for board.
     */
    com.google.protobuf.ByteString
        getBoardBytes();

    /**
     * <code>optional string key = 2;</code>
     * @return Whether the key field is set.
     */
    boolean hasKey();
    /**
     * <code>optional string key = 2;</code>
     * @return The key.
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 2;</code>
     * @return The bytes for key.
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    /**
     * <code>optional string channel = 3;</code>
     * @return Whether the channel field is set.
     */
    boolean hasChannel();
    /**
     * <code>optional string channel = 3;</code>
     * @return The channel.
     */
    java.lang.String getChannel();
    /**
     * <code>optional string channel = 3;</code>
     * @return The bytes for channel.
     */
    com.google.protobuf.ByteString
        getChannelBytes();

    /**
     * <code>optional string version = 4;</code>
     * @return Whether the version field is set.
     */
    boolean hasVersion();
    /**
     * <code>optional string version = 4;</code>
     * @return The version.
     */
    java.lang.String getVersion();
    /**
     * <code>optional string version = 4;</code>
     * @return The bytes for version.
     */
    com.google.protobuf.ByteString
        getVersionBytes();

    /**
     * <pre>
     * If these values aren't present, they should be assumed to match
     * the equivalent value above. They are normally only different for
     * special image types such as nplusone images.
     * </pre>
     *
     * <code>optional string build_channel = 5;</code>
     * @return Whether the buildChannel field is set.
     */
    boolean hasBuildChannel();
    /**
     * <pre>
     * If these values aren't present, they should be assumed to match
     * the equivalent value above. They are normally only different for
     * special image types such as nplusone images.
     * </pre>
     *
     * <code>optional string build_channel = 5;</code>
     * @return The buildChannel.
     */
    java.lang.String getBuildChannel();
    /**
     * <pre>
     * If these values aren't present, they should be assumed to match
     * the equivalent value above. They are normally only different for
     * special image types such as nplusone images.
     * </pre>
     *
     * <code>optional string build_channel = 5;</code>
     * @return The bytes for buildChannel.
     */
    com.google.protobuf.ByteString
        getBuildChannelBytes();

    /**
     * <code>optional string build_version = 6;</code>
     * @return Whether the buildVersion field is set.
     */
    boolean hasBuildVersion();
    /**
     * <code>optional string build_version = 6;</code>
     * @return The buildVersion.
     */
    java.lang.String getBuildVersion();
    /**
     * <code>optional string build_version = 6;</code>
     * @return The bytes for buildVersion.
     */
    com.google.protobuf.ByteString
        getBuildVersionBytes();
  }
  /**
   * <pre>
   * Describe an image we are based on in a human friendly way.
   * Examples:
   *   dev-channel, x86-alex, 1.2.3, mp-v3
   *   nplusone-channel, x86-alex, 1.2.4, mp-v3, dev-channel, 1.2.3
   * All fields will be set, if this message is present.
   * </pre>
   *
   * Protobuf type {@code chromeos_update_engine.ImageInfo}
   */
  public static final class ImageInfo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.ImageInfo)
      ImageInfoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ImageInfo.newBuilder() to construct.
    private ImageInfo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ImageInfo() {
      board_ = "";
      key_ = "";
      channel_ = "";
      version_ = "";
      buildChannel_ = "";
      buildVersion_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ImageInfo();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ImageInfo(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              board_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              key_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              channel_ = bs;
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000008;
              version_ = bs;
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000010;
              buildChannel_ = bs;
              break;
            }
            case 50: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000020;
              buildVersion_ = bs;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_ImageInfo_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_ImageInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.ImageInfo.class, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder.class);
    }

    private int bitField0_;
    public static final int BOARD_FIELD_NUMBER = 1;
    private volatile java.lang.Object board_;
    /**
     * <code>optional string board = 1;</code>
     * @return Whether the board field is set.
     */
    @java.lang.Override
    public boolean hasBoard() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional string board = 1;</code>
     * @return The board.
     */
    @java.lang.Override
    public java.lang.String getBoard() {
      java.lang.Object ref = board_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          board_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string board = 1;</code>
     * @return The bytes for board.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getBoardBytes() {
      java.lang.Object ref = board_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        board_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int KEY_FIELD_NUMBER = 2;
    private volatile java.lang.Object key_;
    /**
     * <code>optional string key = 2;</code>
     * @return Whether the key field is set.
     */
    @java.lang.Override
    public boolean hasKey() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional string key = 2;</code>
     * @return The key.
     */
    @java.lang.Override
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 2;</code>
     * @return The bytes for key.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CHANNEL_FIELD_NUMBER = 3;
    private volatile java.lang.Object channel_;
    /**
     * <code>optional string channel = 3;</code>
     * @return Whether the channel field is set.
     */
    @java.lang.Override
    public boolean hasChannel() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional string channel = 3;</code>
     * @return The channel.
     */
    @java.lang.Override
    public java.lang.String getChannel() {
      java.lang.Object ref = channel_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          channel_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string channel = 3;</code>
     * @return The bytes for channel.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getChannelBytes() {
      java.lang.Object ref = channel_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        channel_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VERSION_FIELD_NUMBER = 4;
    private volatile java.lang.Object version_;
    /**
     * <code>optional string version = 4;</code>
     * @return Whether the version field is set.
     */
    @java.lang.Override
    public boolean hasVersion() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional string version = 4;</code>
     * @return The version.
     */
    @java.lang.Override
    public java.lang.String getVersion() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          version_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string version = 4;</code>
     * @return The bytes for version.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getVersionBytes() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        version_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int BUILD_CHANNEL_FIELD_NUMBER = 5;
    private volatile java.lang.Object buildChannel_;
    /**
     * <pre>
     * If these values aren't present, they should be assumed to match
     * the equivalent value above. They are normally only different for
     * special image types such as nplusone images.
     * </pre>
     *
     * <code>optional string build_channel = 5;</code>
     * @return Whether the buildChannel field is set.
     */
    @java.lang.Override
    public boolean hasBuildChannel() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * If these values aren't present, they should be assumed to match
     * the equivalent value above. They are normally only different for
     * special image types such as nplusone images.
     * </pre>
     *
     * <code>optional string build_channel = 5;</code>
     * @return The buildChannel.
     */
    @java.lang.Override
    public java.lang.String getBuildChannel() {
      java.lang.Object ref = buildChannel_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          buildChannel_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * If these values aren't present, they should be assumed to match
     * the equivalent value above. They are normally only different for
     * special image types such as nplusone images.
     * </pre>
     *
     * <code>optional string build_channel = 5;</code>
     * @return The bytes for buildChannel.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getBuildChannelBytes() {
      java.lang.Object ref = buildChannel_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        buildChannel_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int BUILD_VERSION_FIELD_NUMBER = 6;
    private volatile java.lang.Object buildVersion_;
    /**
     * <code>optional string build_version = 6;</code>
     * @return Whether the buildVersion field is set.
     */
    @java.lang.Override
    public boolean hasBuildVersion() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional string build_version = 6;</code>
     * @return The buildVersion.
     */
    @java.lang.Override
    public java.lang.String getBuildVersion() {
      java.lang.Object ref = buildVersion_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          buildVersion_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string build_version = 6;</code>
     * @return The bytes for buildVersion.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getBuildVersionBytes() {
      java.lang.Object ref = buildVersion_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        buildVersion_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, board_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, key_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, channel_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, version_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, buildChannel_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, buildVersion_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, board_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, key_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, channel_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, version_);
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, buildChannel_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, buildVersion_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.ImageInfo)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.ImageInfo other = (chromeos_update_engine.UpdateMetadata.ImageInfo) obj;

      if (hasBoard() != other.hasBoard()) return false;
      if (hasBoard()) {
        if (!getBoard()
            .equals(other.getBoard())) return false;
      }
      if (hasKey() != other.hasKey()) return false;
      if (hasKey()) {
        if (!getKey()
            .equals(other.getKey())) return false;
      }
      if (hasChannel() != other.hasChannel()) return false;
      if (hasChannel()) {
        if (!getChannel()
            .equals(other.getChannel())) return false;
      }
      if (hasVersion() != other.hasVersion()) return false;
      if (hasVersion()) {
        if (!getVersion()
            .equals(other.getVersion())) return false;
      }
      if (hasBuildChannel() != other.hasBuildChannel()) return false;
      if (hasBuildChannel()) {
        if (!getBuildChannel()
            .equals(other.getBuildChannel())) return false;
      }
      if (hasBuildVersion() != other.hasBuildVersion()) return false;
      if (hasBuildVersion()) {
        if (!getBuildVersion()
            .equals(other.getBuildVersion())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBoard()) {
        hash = (37 * hash) + BOARD_FIELD_NUMBER;
        hash = (53 * hash) + getBoard().hashCode();
      }
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasChannel()) {
        hash = (37 * hash) + CHANNEL_FIELD_NUMBER;
        hash = (53 * hash) + getChannel().hashCode();
      }
      if (hasVersion()) {
        hash = (37 * hash) + VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getVersion().hashCode();
      }
      if (hasBuildChannel()) {
        hash = (37 * hash) + BUILD_CHANNEL_FIELD_NUMBER;
        hash = (53 * hash) + getBuildChannel().hashCode();
      }
      if (hasBuildVersion()) {
        hash = (37 * hash) + BUILD_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getBuildVersion().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.ImageInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.ImageInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Describe an image we are based on in a human friendly way.
     * Examples:
     *   dev-channel, x86-alex, 1.2.3, mp-v3
     *   nplusone-channel, x86-alex, 1.2.4, mp-v3, dev-channel, 1.2.3
     * All fields will be set, if this message is present.
     * </pre>
     *
     * Protobuf type {@code chromeos_update_engine.ImageInfo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.ImageInfo)
        chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_ImageInfo_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_ImageInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.ImageInfo.class, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.ImageInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        board_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        channel_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        version_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        buildChannel_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        buildVersion_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_ImageInfo_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.ImageInfo getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.ImageInfo build() {
        chromeos_update_engine.UpdateMetadata.ImageInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.ImageInfo buildPartial() {
        chromeos_update_engine.UpdateMetadata.ImageInfo result = new chromeos_update_engine.UpdateMetadata.ImageInfo(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.board_ = board_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          to_bitField0_ |= 0x00000002;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          to_bitField0_ |= 0x00000004;
        }
        result.channel_ = channel_;
        if (((from_bitField0_ & 0x00000008) != 0)) {
          to_bitField0_ |= 0x00000008;
        }
        result.version_ = version_;
        if (((from_bitField0_ & 0x00000010) != 0)) {
          to_bitField0_ |= 0x00000010;
        }
        result.buildChannel_ = buildChannel_;
        if (((from_bitField0_ & 0x00000020) != 0)) {
          to_bitField0_ |= 0x00000020;
        }
        result.buildVersion_ = buildVersion_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.ImageInfo) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.ImageInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.ImageInfo other) {
        if (other == chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance()) return this;
        if (other.hasBoard()) {
          bitField0_ |= 0x00000001;
          board_ = other.board_;
          onChanged();
        }
        if (other.hasKey()) {
          bitField0_ |= 0x00000002;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasChannel()) {
          bitField0_ |= 0x00000004;
          channel_ = other.channel_;
          onChanged();
        }
        if (other.hasVersion()) {
          bitField0_ |= 0x00000008;
          version_ = other.version_;
          onChanged();
        }
        if (other.hasBuildChannel()) {
          bitField0_ |= 0x00000010;
          buildChannel_ = other.buildChannel_;
          onChanged();
        }
        if (other.hasBuildVersion()) {
          bitField0_ |= 0x00000020;
          buildVersion_ = other.buildVersion_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.ImageInfo parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.ImageInfo) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object board_ = "";
      /**
       * <code>optional string board = 1;</code>
       * @return Whether the board field is set.
       */
      public boolean hasBoard() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional string board = 1;</code>
       * @return The board.
       */
      public java.lang.String getBoard() {
        java.lang.Object ref = board_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            board_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string board = 1;</code>
       * @return The bytes for board.
       */
      public com.google.protobuf.ByteString
          getBoardBytes() {
        java.lang.Object ref = board_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          board_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string board = 1;</code>
       * @param value The board to set.
       * @return This builder for chaining.
       */
      public Builder setBoard(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        board_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string board = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearBoard() {
        bitField0_ = (bitField0_ & ~0x00000001);
        board_ = getDefaultInstance().getBoard();
        onChanged();
        return this;
      }
      /**
       * <code>optional string board = 1;</code>
       * @param value The bytes for board to set.
       * @return This builder for chaining.
       */
      public Builder setBoardBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        board_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 2;</code>
       * @return Whether the key field is set.
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional string key = 2;</code>
       * @return The key.
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            key_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 2;</code>
       * @return The bytes for key.
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 2;</code>
       * @param value The key to set.
       * @return This builder for chaining.
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000002);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 2;</code>
       * @param value The bytes for key to set.
       * @return This builder for chaining.
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        key_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object channel_ = "";
      /**
       * <code>optional string channel = 3;</code>
       * @return Whether the channel field is set.
       */
      public boolean hasChannel() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional string channel = 3;</code>
       * @return The channel.
       */
      public java.lang.String getChannel() {
        java.lang.Object ref = channel_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            channel_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string channel = 3;</code>
       * @return The bytes for channel.
       */
      public com.google.protobuf.ByteString
          getChannelBytes() {
        java.lang.Object ref = channel_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          channel_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string channel = 3;</code>
       * @param value The channel to set.
       * @return This builder for chaining.
       */
      public Builder setChannel(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        channel_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string channel = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearChannel() {
        bitField0_ = (bitField0_ & ~0x00000004);
        channel_ = getDefaultInstance().getChannel();
        onChanged();
        return this;
      }
      /**
       * <code>optional string channel = 3;</code>
       * @param value The bytes for channel to set.
       * @return This builder for chaining.
       */
      public Builder setChannelBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        channel_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object version_ = "";
      /**
       * <code>optional string version = 4;</code>
       * @return Whether the version field is set.
       */
      public boolean hasVersion() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional string version = 4;</code>
       * @return The version.
       */
      public java.lang.String getVersion() {
        java.lang.Object ref = version_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            version_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string version = 4;</code>
       * @return The bytes for version.
       */
      public com.google.protobuf.ByteString
          getVersionBytes() {
        java.lang.Object ref = version_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          version_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string version = 4;</code>
       * @param value The version to set.
       * @return This builder for chaining.
       */
      public Builder setVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string version = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearVersion() {
        bitField0_ = (bitField0_ & ~0x00000008);
        version_ = getDefaultInstance().getVersion();
        onChanged();
        return this;
      }
      /**
       * <code>optional string version = 4;</code>
       * @param value The bytes for version to set.
       * @return This builder for chaining.
       */
      public Builder setVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        version_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object buildChannel_ = "";
      /**
       * <pre>
       * If these values aren't present, they should be assumed to match
       * the equivalent value above. They are normally only different for
       * special image types such as nplusone images.
       * </pre>
       *
       * <code>optional string build_channel = 5;</code>
       * @return Whether the buildChannel field is set.
       */
      public boolean hasBuildChannel() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * If these values aren't present, they should be assumed to match
       * the equivalent value above. They are normally only different for
       * special image types such as nplusone images.
       * </pre>
       *
       * <code>optional string build_channel = 5;</code>
       * @return The buildChannel.
       */
      public java.lang.String getBuildChannel() {
        java.lang.Object ref = buildChannel_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            buildChannel_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * If these values aren't present, they should be assumed to match
       * the equivalent value above. They are normally only different for
       * special image types such as nplusone images.
       * </pre>
       *
       * <code>optional string build_channel = 5;</code>
       * @return The bytes for buildChannel.
       */
      public com.google.protobuf.ByteString
          getBuildChannelBytes() {
        java.lang.Object ref = buildChannel_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          buildChannel_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * If these values aren't present, they should be assumed to match
       * the equivalent value above. They are normally only different for
       * special image types such as nplusone images.
       * </pre>
       *
       * <code>optional string build_channel = 5;</code>
       * @param value The buildChannel to set.
       * @return This builder for chaining.
       */
      public Builder setBuildChannel(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        buildChannel_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If these values aren't present, they should be assumed to match
       * the equivalent value above. They are normally only different for
       * special image types such as nplusone images.
       * </pre>
       *
       * <code>optional string build_channel = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearBuildChannel() {
        bitField0_ = (bitField0_ & ~0x00000010);
        buildChannel_ = getDefaultInstance().getBuildChannel();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If these values aren't present, they should be assumed to match
       * the equivalent value above. They are normally only different for
       * special image types such as nplusone images.
       * </pre>
       *
       * <code>optional string build_channel = 5;</code>
       * @param value The bytes for buildChannel to set.
       * @return This builder for chaining.
       */
      public Builder setBuildChannelBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        buildChannel_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object buildVersion_ = "";
      /**
       * <code>optional string build_version = 6;</code>
       * @return Whether the buildVersion field is set.
       */
      public boolean hasBuildVersion() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional string build_version = 6;</code>
       * @return The buildVersion.
       */
      public java.lang.String getBuildVersion() {
        java.lang.Object ref = buildVersion_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            buildVersion_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string build_version = 6;</code>
       * @return The bytes for buildVersion.
       */
      public com.google.protobuf.ByteString
          getBuildVersionBytes() {
        java.lang.Object ref = buildVersion_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          buildVersion_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string build_version = 6;</code>
       * @param value The buildVersion to set.
       * @return This builder for chaining.
       */
      public Builder setBuildVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        buildVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string build_version = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearBuildVersion() {
        bitField0_ = (bitField0_ & ~0x00000020);
        buildVersion_ = getDefaultInstance().getBuildVersion();
        onChanged();
        return this;
      }
      /**
       * <code>optional string build_version = 6;</code>
       * @param value The bytes for buildVersion to set.
       * @return This builder for chaining.
       */
      public Builder setBuildVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        buildVersion_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.ImageInfo)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.ImageInfo)
    private static final chromeos_update_engine.UpdateMetadata.ImageInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.ImageInfo();
    }

    public static chromeos_update_engine.UpdateMetadata.ImageInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ImageInfo>
        PARSER = new com.google.protobuf.AbstractParser<ImageInfo>() {
      @java.lang.Override
      public ImageInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ImageInfo(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ImageInfo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ImageInfo> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ImageInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface InstallOperationOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.InstallOperation)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
     * @return Whether the type field is set.
     */
    boolean hasType();
    /**
     * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
     * @return The type.
     */
    chromeos_update_engine.UpdateMetadata.InstallOperation.Type getType();

    /**
     * <pre>
     * Only minor version 6 or newer support 64 bits |data_offset| and
     * |data_length|, older client will read them as uint32.
     * The offset into the delta file (after the protobuf)
     * where the data (if any) is stored
     * </pre>
     *
     * <code>optional uint64 data_offset = 2;</code>
     * @return Whether the dataOffset field is set.
     */
    boolean hasDataOffset();
    /**
     * <pre>
     * Only minor version 6 or newer support 64 bits |data_offset| and
     * |data_length|, older client will read them as uint32.
     * The offset into the delta file (after the protobuf)
     * where the data (if any) is stored
     * </pre>
     *
     * <code>optional uint64 data_offset = 2;</code>
     * @return The dataOffset.
     */
    long getDataOffset();

    /**
     * <pre>
     * The length of the data in the delta file
     * </pre>
     *
     * <code>optional uint64 data_length = 3;</code>
     * @return Whether the dataLength field is set.
     */
    boolean hasDataLength();
    /**
     * <pre>
     * The length of the data in the delta file
     * </pre>
     *
     * <code>optional uint64 data_length = 3;</code>
     * @return The dataLength.
     */
    long getDataLength();

    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.Extent>
        getSrcExtentsList();
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    chromeos_update_engine.UpdateMetadata.Extent getSrcExtents(int index);
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    int getSrcExtentsCount();
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
        getSrcExtentsOrBuilderList();
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getSrcExtentsOrBuilder(
        int index);

    /**
     * <pre>
     * Byte length of src, equal to the number of blocks in src_extents *
     * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
     * pass that external program the number of bytes to read from the blocks we
     * pass it.  This is not used in any other operation.
     * </pre>
     *
     * <code>optional uint64 src_length = 5;</code>
     * @return Whether the srcLength field is set.
     */
    boolean hasSrcLength();
    /**
     * <pre>
     * Byte length of src, equal to the number of blocks in src_extents *
     * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
     * pass that external program the number of bytes to read from the blocks we
     * pass it.  This is not used in any other operation.
     * </pre>
     *
     * <code>optional uint64 src_length = 5;</code>
     * @return The srcLength.
     */
    long getSrcLength();

    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.Extent>
        getDstExtentsList();
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    chromeos_update_engine.UpdateMetadata.Extent getDstExtents(int index);
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    int getDstExtentsCount();
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
        getDstExtentsOrBuilderList();
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getDstExtentsOrBuilder(
        int index);

    /**
     * <pre>
     * Byte length of dst, equal to the number of blocks in dst_extents *
     * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
     * operation.
     * </pre>
     *
     * <code>optional uint64 dst_length = 7;</code>
     * @return Whether the dstLength field is set.
     */
    boolean hasDstLength();
    /**
     * <pre>
     * Byte length of dst, equal to the number of blocks in dst_extents *
     * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
     * operation.
     * </pre>
     *
     * <code>optional uint64 dst_length = 7;</code>
     * @return The dstLength.
     */
    long getDstLength();

    /**
     * <pre>
     * Optional SHA 256 hash of the blob associated with this operation.
     * This is used as a primary validation for http-based downloads and
     * as a defense-in-depth validation for https-based downloads. If
     * the operation doesn't refer to any blob, this field will have
     * zero bytes.
     * </pre>
     *
     * <code>optional bytes data_sha256_hash = 8;</code>
     * @return Whether the dataSha256Hash field is set.
     */
    boolean hasDataSha256Hash();
    /**
     * <pre>
     * Optional SHA 256 hash of the blob associated with this operation.
     * This is used as a primary validation for http-based downloads and
     * as a defense-in-depth validation for https-based downloads. If
     * the operation doesn't refer to any blob, this field will have
     * zero bytes.
     * </pre>
     *
     * <code>optional bytes data_sha256_hash = 8;</code>
     * @return The dataSha256Hash.
     */
    com.google.protobuf.ByteString getDataSha256Hash();

    /**
     * <pre>
     * Indicates the SHA 256 hash of the source data referenced in src_extents at
     * the time of applying the operation. If present, the update_engine daemon
     * MUST read and verify the source data before applying the operation.
     * </pre>
     *
     * <code>optional bytes src_sha256_hash = 9;</code>
     * @return Whether the srcSha256Hash field is set.
     */
    boolean hasSrcSha256Hash();
    /**
     * <pre>
     * Indicates the SHA 256 hash of the source data referenced in src_extents at
     * the time of applying the operation. If present, the update_engine daemon
     * MUST read and verify the source data before applying the operation.
     * </pre>
     *
     * <code>optional bytes src_sha256_hash = 9;</code>
     * @return The srcSha256Hash.
     */
    com.google.protobuf.ByteString getSrcSha256Hash();
  }
  /**
   * Protobuf type {@code chromeos_update_engine.InstallOperation}
   */
  public static final class InstallOperation extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.InstallOperation)
      InstallOperationOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use InstallOperation.newBuilder() to construct.
    private InstallOperation(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private InstallOperation() {
      type_ = 0;
      srcExtents_ = java.util.Collections.emptyList();
      dstExtents_ = java.util.Collections.emptyList();
      dataSha256Hash_ = com.google.protobuf.ByteString.EMPTY;
      srcSha256Hash_ = com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new InstallOperation();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private InstallOperation(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              chromeos_update_engine.UpdateMetadata.InstallOperation.Type value = chromeos_update_engine.UpdateMetadata.InstallOperation.Type.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = rawValue;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              dataOffset_ = input.readUInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              dataLength_ = input.readUInt64();
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                srcExtents_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Extent>();
                mutable_bitField0_ |= 0x00000008;
              }
              srcExtents_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.Extent.PARSER, extensionRegistry));
              break;
            }
            case 40: {
              bitField0_ |= 0x00000008;
              srcLength_ = input.readUInt64();
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) != 0)) {
                dstExtents_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Extent>();
                mutable_bitField0_ |= 0x00000020;
              }
              dstExtents_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.Extent.PARSER, extensionRegistry));
              break;
            }
            case 56: {
              bitField0_ |= 0x00000010;
              dstLength_ = input.readUInt64();
              break;
            }
            case 66: {
              bitField0_ |= 0x00000020;
              dataSha256Hash_ = input.readBytes();
              break;
            }
            case 74: {
              bitField0_ |= 0x00000040;
              srcSha256Hash_ = input.readBytes();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) != 0)) {
          srcExtents_ = java.util.Collections.unmodifiableList(srcExtents_);
        }
        if (((mutable_bitField0_ & 0x00000020) != 0)) {
          dstExtents_ = java.util.Collections.unmodifiableList(dstExtents_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_InstallOperation_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_InstallOperation_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.InstallOperation.class, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder.class);
    }

    /**
     * Protobuf enum {@code chromeos_update_engine.InstallOperation.Type}
     */
    public enum Type
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * Replace destination extents w/ attached data
       * </pre>
       *
       * <code>REPLACE = 0;</code>
       */
      REPLACE(0),
      /**
       * <pre>
       * Replace destination extents w/ attached bzipped data
       * </pre>
       *
       * <code>REPLACE_BZ = 1;</code>
       */
      REPLACE_BZ(1),
      /**
       * <pre>
       * Move source extents to destination extents
       * </pre>
       *
       * <code>MOVE = 2 [deprecated = true];</code>
       */
      @java.lang.Deprecated
      MOVE(2),
      /**
       * <pre>
       * The data is a bsdiff binary diff
       * </pre>
       *
       * <code>BSDIFF = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated
      BSDIFF(3),
      /**
       * <pre>
       * On minor version 2 or newer, these operations are supported:
       * </pre>
       *
       * <code>SOURCE_COPY = 4;</code>
       */
      SOURCE_COPY(4),
      /**
       * <pre>
       * Like BSDIFF, but read from source partition
       * </pre>
       *
       * <code>SOURCE_BSDIFF = 5;</code>
       */
      SOURCE_BSDIFF(5),
      /**
       * <pre>
       * On minor version 3 or newer and on major version 2 or newer, these
       * operations are supported:
       * </pre>
       *
       * <code>REPLACE_XZ = 8;</code>
       */
      REPLACE_XZ(8),
      /**
       * <pre>
       * On minor version 4 or newer, these operations are supported:
       * </pre>
       *
       * <code>ZERO = 6;</code>
       */
      ZERO(6),
      /**
       * <pre>
       * Discard the destination blocks, reading as undefined.
       * </pre>
       *
       * <code>DISCARD = 7;</code>
       */
      DISCARD(7),
      /**
       * <pre>
       * Like SOURCE_BSDIFF, but compressed with brotli.
       * </pre>
       *
       * <code>BROTLI_BSDIFF = 10;</code>
       */
      BROTLI_BSDIFF(10),
      /**
       * <pre>
       * On minor version 5 or newer, these operations are supported:
       * </pre>
       *
       * <code>PUFFDIFF = 9;</code>
       */
      PUFFDIFF(9),
      ;

      /**
       * <pre>
       * Replace destination extents w/ attached data
       * </pre>
       *
       * <code>REPLACE = 0;</code>
       */
      public static final int REPLACE_VALUE = 0;
      /**
       * <pre>
       * Replace destination extents w/ attached bzipped data
       * </pre>
       *
       * <code>REPLACE_BZ = 1;</code>
       */
      public static final int REPLACE_BZ_VALUE = 1;
      /**
       * <pre>
       * Move source extents to destination extents
       * </pre>
       *
       * <code>MOVE = 2 [deprecated = true];</code>
       */
      @java.lang.Deprecated public static final int MOVE_VALUE = 2;
      /**
       * <pre>
       * The data is a bsdiff binary diff
       * </pre>
       *
       * <code>BSDIFF = 3 [deprecated = true];</code>
       */
      @java.lang.Deprecated public static final int BSDIFF_VALUE = 3;
      /**
       * <pre>
       * On minor version 2 or newer, these operations are supported:
       * </pre>
       *
       * <code>SOURCE_COPY = 4;</code>
       */
      public static final int SOURCE_COPY_VALUE = 4;
      /**
       * <pre>
       * Like BSDIFF, but read from source partition
       * </pre>
       *
       * <code>SOURCE_BSDIFF = 5;</code>
       */
      public static final int SOURCE_BSDIFF_VALUE = 5;
      /**
       * <pre>
       * On minor version 3 or newer and on major version 2 or newer, these
       * operations are supported:
       * </pre>
       *
       * <code>REPLACE_XZ = 8;</code>
       */
      public static final int REPLACE_XZ_VALUE = 8;
      /**
       * <pre>
       * On minor version 4 or newer, these operations are supported:
       * </pre>
       *
       * <code>ZERO = 6;</code>
       */
      public static final int ZERO_VALUE = 6;
      /**
       * <pre>
       * Discard the destination blocks, reading as undefined.
       * </pre>
       *
       * <code>DISCARD = 7;</code>
       */
      public static final int DISCARD_VALUE = 7;
      /**
       * <pre>
       * Like SOURCE_BSDIFF, but compressed with brotli.
       * </pre>
       *
       * <code>BROTLI_BSDIFF = 10;</code>
       */
      public static final int BROTLI_BSDIFF_VALUE = 10;
      /**
       * <pre>
       * On minor version 5 or newer, these operations are supported:
       * </pre>
       *
       * <code>PUFFDIFF = 9;</code>
       */
      public static final int PUFFDIFF_VALUE = 9;


      public final int getNumber() {
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Type valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Type forNumber(int value) {
        switch (value) {
          case 0: return REPLACE;
          case 1: return REPLACE_BZ;
          case 2: return MOVE;
          case 3: return BSDIFF;
          case 4: return SOURCE_COPY;
          case 5: return SOURCE_BSDIFF;
          case 8: return REPLACE_XZ;
          case 6: return ZERO;
          case 7: return DISCARD;
          case 10: return BROTLI_BSDIFF;
          case 9: return PUFFDIFF;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Type>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Type> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Type>() {
              public Type findValueByNumber(int number) {
                return Type.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.InstallOperation.getDescriptor().getEnumTypes().get(0);
      }

      private static final Type[] VALUES = values();

      public static Type valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Type(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:chromeos_update_engine.InstallOperation.Type)
    }

    private int bitField0_;
    public static final int TYPE_FIELD_NUMBER = 1;
    private int type_;
    /**
     * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
     * @return Whether the type field is set.
     */
    @java.lang.Override public boolean hasType() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
     * @return The type.
     */
    @java.lang.Override public chromeos_update_engine.UpdateMetadata.InstallOperation.Type getType() {
      @SuppressWarnings("deprecation")
      chromeos_update_engine.UpdateMetadata.InstallOperation.Type result = chromeos_update_engine.UpdateMetadata.InstallOperation.Type.valueOf(type_);
      return result == null ? chromeos_update_engine.UpdateMetadata.InstallOperation.Type.REPLACE : result;
    }

    public static final int DATA_OFFSET_FIELD_NUMBER = 2;
    private long dataOffset_;
    /**
     * <pre>
     * Only minor version 6 or newer support 64 bits |data_offset| and
     * |data_length|, older client will read them as uint32.
     * The offset into the delta file (after the protobuf)
     * where the data (if any) is stored
     * </pre>
     *
     * <code>optional uint64 data_offset = 2;</code>
     * @return Whether the dataOffset field is set.
     */
    @java.lang.Override
    public boolean hasDataOffset() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Only minor version 6 or newer support 64 bits |data_offset| and
     * |data_length|, older client will read them as uint32.
     * The offset into the delta file (after the protobuf)
     * where the data (if any) is stored
     * </pre>
     *
     * <code>optional uint64 data_offset = 2;</code>
     * @return The dataOffset.
     */
    @java.lang.Override
    public long getDataOffset() {
      return dataOffset_;
    }

    public static final int DATA_LENGTH_FIELD_NUMBER = 3;
    private long dataLength_;
    /**
     * <pre>
     * The length of the data in the delta file
     * </pre>
     *
     * <code>optional uint64 data_length = 3;</code>
     * @return Whether the dataLength field is set.
     */
    @java.lang.Override
    public boolean hasDataLength() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * The length of the data in the delta file
     * </pre>
     *
     * <code>optional uint64 data_length = 3;</code>
     * @return The dataLength.
     */
    @java.lang.Override
    public long getDataLength() {
      return dataLength_;
    }

    public static final int SRC_EXTENTS_FIELD_NUMBER = 4;
    private java.util.List<chromeos_update_engine.UpdateMetadata.Extent> srcExtents_;
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.Extent> getSrcExtentsList() {
      return srcExtents_;
    }
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
        getSrcExtentsOrBuilderList() {
      return srcExtents_;
    }
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    @java.lang.Override
    public int getSrcExtentsCount() {
      return srcExtents_.size();
    }
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getSrcExtents(int index) {
      return srcExtents_.get(index);
    }
    /**
     * <pre>
     * Ordered list of extents that are read from (if any) and written to.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getSrcExtentsOrBuilder(
        int index) {
      return srcExtents_.get(index);
    }

    public static final int SRC_LENGTH_FIELD_NUMBER = 5;
    private long srcLength_;
    /**
     * <pre>
     * Byte length of src, equal to the number of blocks in src_extents *
     * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
     * pass that external program the number of bytes to read from the blocks we
     * pass it.  This is not used in any other operation.
     * </pre>
     *
     * <code>optional uint64 src_length = 5;</code>
     * @return Whether the srcLength field is set.
     */
    @java.lang.Override
    public boolean hasSrcLength() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * Byte length of src, equal to the number of blocks in src_extents *
     * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
     * pass that external program the number of bytes to read from the blocks we
     * pass it.  This is not used in any other operation.
     * </pre>
     *
     * <code>optional uint64 src_length = 5;</code>
     * @return The srcLength.
     */
    @java.lang.Override
    public long getSrcLength() {
      return srcLength_;
    }

    public static final int DST_EXTENTS_FIELD_NUMBER = 6;
    private java.util.List<chromeos_update_engine.UpdateMetadata.Extent> dstExtents_;
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.Extent> getDstExtentsList() {
      return dstExtents_;
    }
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
        getDstExtentsOrBuilderList() {
      return dstExtents_;
    }
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    @java.lang.Override
    public int getDstExtentsCount() {
      return dstExtents_.size();
    }
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getDstExtents(int index) {
      return dstExtents_.get(index);
    }
    /**
     * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getDstExtentsOrBuilder(
        int index) {
      return dstExtents_.get(index);
    }

    public static final int DST_LENGTH_FIELD_NUMBER = 7;
    private long dstLength_;
    /**
     * <pre>
     * Byte length of dst, equal to the number of blocks in dst_extents *
     * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
     * operation.
     * </pre>
     *
     * <code>optional uint64 dst_length = 7;</code>
     * @return Whether the dstLength field is set.
     */
    @java.lang.Override
    public boolean hasDstLength() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <pre>
     * Byte length of dst, equal to the number of blocks in dst_extents *
     * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
     * operation.
     * </pre>
     *
     * <code>optional uint64 dst_length = 7;</code>
     * @return The dstLength.
     */
    @java.lang.Override
    public long getDstLength() {
      return dstLength_;
    }

    public static final int DATA_SHA256_HASH_FIELD_NUMBER = 8;
    private com.google.protobuf.ByteString dataSha256Hash_;
    /**
     * <pre>
     * Optional SHA 256 hash of the blob associated with this operation.
     * This is used as a primary validation for http-based downloads and
     * as a defense-in-depth validation for https-based downloads. If
     * the operation doesn't refer to any blob, this field will have
     * zero bytes.
     * </pre>
     *
     * <code>optional bytes data_sha256_hash = 8;</code>
     * @return Whether the dataSha256Hash field is set.
     */
    @java.lang.Override
    public boolean hasDataSha256Hash() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <pre>
     * Optional SHA 256 hash of the blob associated with this operation.
     * This is used as a primary validation for http-based downloads and
     * as a defense-in-depth validation for https-based downloads. If
     * the operation doesn't refer to any blob, this field will have
     * zero bytes.
     * </pre>
     *
     * <code>optional bytes data_sha256_hash = 8;</code>
     * @return The dataSha256Hash.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getDataSha256Hash() {
      return dataSha256Hash_;
    }

    public static final int SRC_SHA256_HASH_FIELD_NUMBER = 9;
    private com.google.protobuf.ByteString srcSha256Hash_;
    /**
     * <pre>
     * Indicates the SHA 256 hash of the source data referenced in src_extents at
     * the time of applying the operation. If present, the update_engine daemon
     * MUST read and verify the source data before applying the operation.
     * </pre>
     *
     * <code>optional bytes src_sha256_hash = 9;</code>
     * @return Whether the srcSha256Hash field is set.
     */
    @java.lang.Override
    public boolean hasSrcSha256Hash() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <pre>
     * Indicates the SHA 256 hash of the source data referenced in src_extents at
     * the time of applying the operation. If present, the update_engine daemon
     * MUST read and verify the source data before applying the operation.
     * </pre>
     *
     * <code>optional bytes src_sha256_hash = 9;</code>
     * @return The srcSha256Hash.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getSrcSha256Hash() {
      return srcSha256Hash_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, type_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt64(2, dataOffset_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(3, dataLength_);
      }
      for (int i = 0; i < srcExtents_.size(); i++) {
        output.writeMessage(4, srcExtents_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeUInt64(5, srcLength_);
      }
      for (int i = 0; i < dstExtents_.size(); i++) {
        output.writeMessage(6, dstExtents_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeUInt64(7, dstLength_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeBytes(8, dataSha256Hash_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeBytes(9, srcSha256Hash_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, dataOffset_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, dataLength_);
      }
      for (int i = 0; i < srcExtents_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, srcExtents_.get(i));
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, srcLength_);
      }
      for (int i = 0; i < dstExtents_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, dstExtents_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(7, dstLength_);
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, dataSha256Hash_);
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(9, srcSha256Hash_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.InstallOperation)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.InstallOperation other = (chromeos_update_engine.UpdateMetadata.InstallOperation) obj;

      if (hasType() != other.hasType()) return false;
      if (hasType()) {
        if (type_ != other.type_) return false;
      }
      if (hasDataOffset() != other.hasDataOffset()) return false;
      if (hasDataOffset()) {
        if (getDataOffset()
            != other.getDataOffset()) return false;
      }
      if (hasDataLength() != other.hasDataLength()) return false;
      if (hasDataLength()) {
        if (getDataLength()
            != other.getDataLength()) return false;
      }
      if (!getSrcExtentsList()
          .equals(other.getSrcExtentsList())) return false;
      if (hasSrcLength() != other.hasSrcLength()) return false;
      if (hasSrcLength()) {
        if (getSrcLength()
            != other.getSrcLength()) return false;
      }
      if (!getDstExtentsList()
          .equals(other.getDstExtentsList())) return false;
      if (hasDstLength() != other.hasDstLength()) return false;
      if (hasDstLength()) {
        if (getDstLength()
            != other.getDstLength()) return false;
      }
      if (hasDataSha256Hash() != other.hasDataSha256Hash()) return false;
      if (hasDataSha256Hash()) {
        if (!getDataSha256Hash()
            .equals(other.getDataSha256Hash())) return false;
      }
      if (hasSrcSha256Hash() != other.hasSrcSha256Hash()) return false;
      if (hasSrcSha256Hash()) {
        if (!getSrcSha256Hash()
            .equals(other.getSrcSha256Hash())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasDataOffset()) {
        hash = (37 * hash) + DATA_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getDataOffset());
      }
      if (hasDataLength()) {
        hash = (37 * hash) + DATA_LENGTH_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getDataLength());
      }
      if (getSrcExtentsCount() > 0) {
        hash = (37 * hash) + SRC_EXTENTS_FIELD_NUMBER;
        hash = (53 * hash) + getSrcExtentsList().hashCode();
      }
      if (hasSrcLength()) {
        hash = (37 * hash) + SRC_LENGTH_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSrcLength());
      }
      if (getDstExtentsCount() > 0) {
        hash = (37 * hash) + DST_EXTENTS_FIELD_NUMBER;
        hash = (53 * hash) + getDstExtentsList().hashCode();
      }
      if (hasDstLength()) {
        hash = (37 * hash) + DST_LENGTH_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getDstLength());
      }
      if (hasDataSha256Hash()) {
        hash = (37 * hash) + DATA_SHA256_HASH_FIELD_NUMBER;
        hash = (53 * hash) + getDataSha256Hash().hashCode();
      }
      if (hasSrcSha256Hash()) {
        hash = (37 * hash) + SRC_SHA256_HASH_FIELD_NUMBER;
        hash = (53 * hash) + getSrcSha256Hash().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.InstallOperation parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.InstallOperation prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code chromeos_update_engine.InstallOperation}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.InstallOperation)
        chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_InstallOperation_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_InstallOperation_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.InstallOperation.class, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.InstallOperation.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getSrcExtentsFieldBuilder();
          getDstExtentsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        type_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        dataOffset_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        dataLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        if (srcExtentsBuilder_ == null) {
          srcExtents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          srcExtentsBuilder_.clear();
        }
        srcLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (dstExtentsBuilder_ == null) {
          dstExtents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          dstExtentsBuilder_.clear();
        }
        dstLength_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        dataSha256Hash_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        srcSha256Hash_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_InstallOperation_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.InstallOperation getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.InstallOperation build() {
        chromeos_update_engine.UpdateMetadata.InstallOperation result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.InstallOperation buildPartial() {
        chromeos_update_engine.UpdateMetadata.InstallOperation result = new chromeos_update_engine.UpdateMetadata.InstallOperation(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.dataOffset_ = dataOffset_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.dataLength_ = dataLength_;
          to_bitField0_ |= 0x00000004;
        }
        if (srcExtentsBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0)) {
            srcExtents_ = java.util.Collections.unmodifiableList(srcExtents_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.srcExtents_ = srcExtents_;
        } else {
          result.srcExtents_ = srcExtentsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.srcLength_ = srcLength_;
          to_bitField0_ |= 0x00000008;
        }
        if (dstExtentsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0)) {
            dstExtents_ = java.util.Collections.unmodifiableList(dstExtents_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.dstExtents_ = dstExtents_;
        } else {
          result.dstExtents_ = dstExtentsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.dstLength_ = dstLength_;
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          to_bitField0_ |= 0x00000020;
        }
        result.dataSha256Hash_ = dataSha256Hash_;
        if (((from_bitField0_ & 0x00000100) != 0)) {
          to_bitField0_ |= 0x00000040;
        }
        result.srcSha256Hash_ = srcSha256Hash_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.InstallOperation) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.InstallOperation)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.InstallOperation other) {
        if (other == chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasDataOffset()) {
          setDataOffset(other.getDataOffset());
        }
        if (other.hasDataLength()) {
          setDataLength(other.getDataLength());
        }
        if (srcExtentsBuilder_ == null) {
          if (!other.srcExtents_.isEmpty()) {
            if (srcExtents_.isEmpty()) {
              srcExtents_ = other.srcExtents_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureSrcExtentsIsMutable();
              srcExtents_.addAll(other.srcExtents_);
            }
            onChanged();
          }
        } else {
          if (!other.srcExtents_.isEmpty()) {
            if (srcExtentsBuilder_.isEmpty()) {
              srcExtentsBuilder_.dispose();
              srcExtentsBuilder_ = null;
              srcExtents_ = other.srcExtents_;
              bitField0_ = (bitField0_ & ~0x00000008);
              srcExtentsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSrcExtentsFieldBuilder() : null;
            } else {
              srcExtentsBuilder_.addAllMessages(other.srcExtents_);
            }
          }
        }
        if (other.hasSrcLength()) {
          setSrcLength(other.getSrcLength());
        }
        if (dstExtentsBuilder_ == null) {
          if (!other.dstExtents_.isEmpty()) {
            if (dstExtents_.isEmpty()) {
              dstExtents_ = other.dstExtents_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureDstExtentsIsMutable();
              dstExtents_.addAll(other.dstExtents_);
            }
            onChanged();
          }
        } else {
          if (!other.dstExtents_.isEmpty()) {
            if (dstExtentsBuilder_.isEmpty()) {
              dstExtentsBuilder_.dispose();
              dstExtentsBuilder_ = null;
              dstExtents_ = other.dstExtents_;
              bitField0_ = (bitField0_ & ~0x00000020);
              dstExtentsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getDstExtentsFieldBuilder() : null;
            } else {
              dstExtentsBuilder_.addAllMessages(other.dstExtents_);
            }
          }
        }
        if (other.hasDstLength()) {
          setDstLength(other.getDstLength());
        }
        if (other.hasDataSha256Hash()) {
          setDataSha256Hash(other.getDataSha256Hash());
        }
        if (other.hasSrcSha256Hash()) {
          setSrcSha256Hash(other.getSrcSha256Hash());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasType()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.InstallOperation parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.InstallOperation) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int type_ = 0;
      /**
       * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
       * @return Whether the type field is set.
       */
      @java.lang.Override public boolean hasType() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
       * @return The type.
       */
      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Type getType() {
        @SuppressWarnings("deprecation")
        chromeos_update_engine.UpdateMetadata.InstallOperation.Type result = chromeos_update_engine.UpdateMetadata.InstallOperation.Type.valueOf(type_);
        return result == null ? chromeos_update_engine.UpdateMetadata.InstallOperation.Type.REPLACE : result;
      }
      /**
       * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
       * @param value The type to set.
       * @return This builder for chaining.
       */
      public Builder setType(chromeos_update_engine.UpdateMetadata.InstallOperation.Type value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .chromeos_update_engine.InstallOperation.Type type = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = 0;
        onChanged();
        return this;
      }

      private long dataOffset_ ;
      /**
       * <pre>
       * Only minor version 6 or newer support 64 bits |data_offset| and
       * |data_length|, older client will read them as uint32.
       * The offset into the delta file (after the protobuf)
       * where the data (if any) is stored
       * </pre>
       *
       * <code>optional uint64 data_offset = 2;</code>
       * @return Whether the dataOffset field is set.
       */
      @java.lang.Override
      public boolean hasDataOffset() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Only minor version 6 or newer support 64 bits |data_offset| and
       * |data_length|, older client will read them as uint32.
       * The offset into the delta file (after the protobuf)
       * where the data (if any) is stored
       * </pre>
       *
       * <code>optional uint64 data_offset = 2;</code>
       * @return The dataOffset.
       */
      @java.lang.Override
      public long getDataOffset() {
        return dataOffset_;
      }
      /**
       * <pre>
       * Only minor version 6 or newer support 64 bits |data_offset| and
       * |data_length|, older client will read them as uint32.
       * The offset into the delta file (after the protobuf)
       * where the data (if any) is stored
       * </pre>
       *
       * <code>optional uint64 data_offset = 2;</code>
       * @param value The dataOffset to set.
       * @return This builder for chaining.
       */
      public Builder setDataOffset(long value) {
        bitField0_ |= 0x00000002;
        dataOffset_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Only minor version 6 or newer support 64 bits |data_offset| and
       * |data_length|, older client will read them as uint32.
       * The offset into the delta file (after the protobuf)
       * where the data (if any) is stored
       * </pre>
       *
       * <code>optional uint64 data_offset = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearDataOffset() {
        bitField0_ = (bitField0_ & ~0x00000002);
        dataOffset_ = 0L;
        onChanged();
        return this;
      }

      private long dataLength_ ;
      /**
       * <pre>
       * The length of the data in the delta file
       * </pre>
       *
       * <code>optional uint64 data_length = 3;</code>
       * @return Whether the dataLength field is set.
       */
      @java.lang.Override
      public boolean hasDataLength() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * The length of the data in the delta file
       * </pre>
       *
       * <code>optional uint64 data_length = 3;</code>
       * @return The dataLength.
       */
      @java.lang.Override
      public long getDataLength() {
        return dataLength_;
      }
      /**
       * <pre>
       * The length of the data in the delta file
       * </pre>
       *
       * <code>optional uint64 data_length = 3;</code>
       * @param value The dataLength to set.
       * @return This builder for chaining.
       */
      public Builder setDataLength(long value) {
        bitField0_ |= 0x00000004;
        dataLength_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The length of the data in the delta file
       * </pre>
       *
       * <code>optional uint64 data_length = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearDataLength() {
        bitField0_ = (bitField0_ & ~0x00000004);
        dataLength_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<chromeos_update_engine.UpdateMetadata.Extent> srcExtents_ =
        java.util.Collections.emptyList();
      private void ensureSrcExtentsIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          srcExtents_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Extent>(srcExtents_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder> srcExtentsBuilder_;

      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Extent> getSrcExtentsList() {
        if (srcExtentsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(srcExtents_);
        } else {
          return srcExtentsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public int getSrcExtentsCount() {
        if (srcExtentsBuilder_ == null) {
          return srcExtents_.size();
        } else {
          return srcExtentsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent getSrcExtents(int index) {
        if (srcExtentsBuilder_ == null) {
          return srcExtents_.get(index);
        } else {
          return srcExtentsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder setSrcExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent value) {
        if (srcExtentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSrcExtentsIsMutable();
          srcExtents_.set(index, value);
          onChanged();
        } else {
          srcExtentsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder setSrcExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (srcExtentsBuilder_ == null) {
          ensureSrcExtentsIsMutable();
          srcExtents_.set(index, builderForValue.build());
          onChanged();
        } else {
          srcExtentsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder addSrcExtents(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (srcExtentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSrcExtentsIsMutable();
          srcExtents_.add(value);
          onChanged();
        } else {
          srcExtentsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder addSrcExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent value) {
        if (srcExtentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSrcExtentsIsMutable();
          srcExtents_.add(index, value);
          onChanged();
        } else {
          srcExtentsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder addSrcExtents(
          chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (srcExtentsBuilder_ == null) {
          ensureSrcExtentsIsMutable();
          srcExtents_.add(builderForValue.build());
          onChanged();
        } else {
          srcExtentsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder addSrcExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (srcExtentsBuilder_ == null) {
          ensureSrcExtentsIsMutable();
          srcExtents_.add(index, builderForValue.build());
          onChanged();
        } else {
          srcExtentsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder addAllSrcExtents(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.Extent> values) {
        if (srcExtentsBuilder_ == null) {
          ensureSrcExtentsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, srcExtents_);
          onChanged();
        } else {
          srcExtentsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder clearSrcExtents() {
        if (srcExtentsBuilder_ == null) {
          srcExtents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          srcExtentsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public Builder removeSrcExtents(int index) {
        if (srcExtentsBuilder_ == null) {
          ensureSrcExtentsIsMutable();
          srcExtents_.remove(index);
          onChanged();
        } else {
          srcExtentsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder getSrcExtentsBuilder(
          int index) {
        return getSrcExtentsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getSrcExtentsOrBuilder(
          int index) {
        if (srcExtentsBuilder_ == null) {
          return srcExtents_.get(index);  } else {
          return srcExtentsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
           getSrcExtentsOrBuilderList() {
        if (srcExtentsBuilder_ != null) {
          return srcExtentsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(srcExtents_);
        }
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder addSrcExtentsBuilder() {
        return getSrcExtentsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance());
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder addSrcExtentsBuilder(
          int index) {
        return getSrcExtentsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance());
      }
      /**
       * <pre>
       * Ordered list of extents that are read from (if any) and written to.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Extent src_extents = 4;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Extent.Builder>
           getSrcExtentsBuilderList() {
        return getSrcExtentsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
          getSrcExtentsFieldBuilder() {
        if (srcExtentsBuilder_ == null) {
          srcExtentsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>(
                  srcExtents_,
                  ((bitField0_ & 0x00000008) != 0),
                  getParentForChildren(),
                  isClean());
          srcExtents_ = null;
        }
        return srcExtentsBuilder_;
      }

      private long srcLength_ ;
      /**
       * <pre>
       * Byte length of src, equal to the number of blocks in src_extents *
       * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
       * pass that external program the number of bytes to read from the blocks we
       * pass it.  This is not used in any other operation.
       * </pre>
       *
       * <code>optional uint64 src_length = 5;</code>
       * @return Whether the srcLength field is set.
       */
      @java.lang.Override
      public boolean hasSrcLength() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <pre>
       * Byte length of src, equal to the number of blocks in src_extents *
       * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
       * pass that external program the number of bytes to read from the blocks we
       * pass it.  This is not used in any other operation.
       * </pre>
       *
       * <code>optional uint64 src_length = 5;</code>
       * @return The srcLength.
       */
      @java.lang.Override
      public long getSrcLength() {
        return srcLength_;
      }
      /**
       * <pre>
       * Byte length of src, equal to the number of blocks in src_extents *
       * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
       * pass that external program the number of bytes to read from the blocks we
       * pass it.  This is not used in any other operation.
       * </pre>
       *
       * <code>optional uint64 src_length = 5;</code>
       * @param value The srcLength to set.
       * @return This builder for chaining.
       */
      public Builder setSrcLength(long value) {
        bitField0_ |= 0x00000010;
        srcLength_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Byte length of src, equal to the number of blocks in src_extents *
       * block_size. It is used for BSDIFF and SOURCE_BSDIFF, because we need to
       * pass that external program the number of bytes to read from the blocks we
       * pass it.  This is not used in any other operation.
       * </pre>
       *
       * <code>optional uint64 src_length = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearSrcLength() {
        bitField0_ = (bitField0_ & ~0x00000010);
        srcLength_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<chromeos_update_engine.UpdateMetadata.Extent> dstExtents_ =
        java.util.Collections.emptyList();
      private void ensureDstExtentsIsMutable() {
        if (!((bitField0_ & 0x00000020) != 0)) {
          dstExtents_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Extent>(dstExtents_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder> dstExtentsBuilder_;

      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Extent> getDstExtentsList() {
        if (dstExtentsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(dstExtents_);
        } else {
          return dstExtentsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public int getDstExtentsCount() {
        if (dstExtentsBuilder_ == null) {
          return dstExtents_.size();
        } else {
          return dstExtentsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent getDstExtents(int index) {
        if (dstExtentsBuilder_ == null) {
          return dstExtents_.get(index);
        } else {
          return dstExtentsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder setDstExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent value) {
        if (dstExtentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDstExtentsIsMutable();
          dstExtents_.set(index, value);
          onChanged();
        } else {
          dstExtentsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder setDstExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (dstExtentsBuilder_ == null) {
          ensureDstExtentsIsMutable();
          dstExtents_.set(index, builderForValue.build());
          onChanged();
        } else {
          dstExtentsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder addDstExtents(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (dstExtentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDstExtentsIsMutable();
          dstExtents_.add(value);
          onChanged();
        } else {
          dstExtentsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder addDstExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent value) {
        if (dstExtentsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDstExtentsIsMutable();
          dstExtents_.add(index, value);
          onChanged();
        } else {
          dstExtentsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder addDstExtents(
          chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (dstExtentsBuilder_ == null) {
          ensureDstExtentsIsMutable();
          dstExtents_.add(builderForValue.build());
          onChanged();
        } else {
          dstExtentsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder addDstExtents(
          int index, chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (dstExtentsBuilder_ == null) {
          ensureDstExtentsIsMutable();
          dstExtents_.add(index, builderForValue.build());
          onChanged();
        } else {
          dstExtentsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder addAllDstExtents(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.Extent> values) {
        if (dstExtentsBuilder_ == null) {
          ensureDstExtentsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, dstExtents_);
          onChanged();
        } else {
          dstExtentsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder clearDstExtents() {
        if (dstExtentsBuilder_ == null) {
          dstExtents_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          dstExtentsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public Builder removeDstExtents(int index) {
        if (dstExtentsBuilder_ == null) {
          ensureDstExtentsIsMutable();
          dstExtents_.remove(index);
          onChanged();
        } else {
          dstExtentsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder getDstExtentsBuilder(
          int index) {
        return getDstExtentsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getDstExtentsOrBuilder(
          int index) {
        if (dstExtentsBuilder_ == null) {
          return dstExtents_.get(index);  } else {
          return dstExtentsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
           getDstExtentsOrBuilderList() {
        if (dstExtentsBuilder_ != null) {
          return dstExtentsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(dstExtents_);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder addDstExtentsBuilder() {
        return getDstExtentsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance());
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder addDstExtentsBuilder(
          int index) {
        return getDstExtentsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance());
      }
      /**
       * <code>repeated .chromeos_update_engine.Extent dst_extents = 6;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Extent.Builder>
           getDstExtentsBuilderList() {
        return getDstExtentsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
          getDstExtentsFieldBuilder() {
        if (dstExtentsBuilder_ == null) {
          dstExtentsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>(
                  dstExtents_,
                  ((bitField0_ & 0x00000020) != 0),
                  getParentForChildren(),
                  isClean());
          dstExtents_ = null;
        }
        return dstExtentsBuilder_;
      }

      private long dstLength_ ;
      /**
       * <pre>
       * Byte length of dst, equal to the number of blocks in dst_extents *
       * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
       * operation.
       * </pre>
       *
       * <code>optional uint64 dst_length = 7;</code>
       * @return Whether the dstLength field is set.
       */
      @java.lang.Override
      public boolean hasDstLength() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <pre>
       * Byte length of dst, equal to the number of blocks in dst_extents *
       * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
       * operation.
       * </pre>
       *
       * <code>optional uint64 dst_length = 7;</code>
       * @return The dstLength.
       */
      @java.lang.Override
      public long getDstLength() {
        return dstLength_;
      }
      /**
       * <pre>
       * Byte length of dst, equal to the number of blocks in dst_extents *
       * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
       * operation.
       * </pre>
       *
       * <code>optional uint64 dst_length = 7;</code>
       * @param value The dstLength to set.
       * @return This builder for chaining.
       */
      public Builder setDstLength(long value) {
        bitField0_ |= 0x00000040;
        dstLength_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Byte length of dst, equal to the number of blocks in dst_extents *
       * block_size. Used for BSDIFF and SOURCE_BSDIFF, but not in any other
       * operation.
       * </pre>
       *
       * <code>optional uint64 dst_length = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearDstLength() {
        bitField0_ = (bitField0_ & ~0x00000040);
        dstLength_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.ByteString dataSha256Hash_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * Optional SHA 256 hash of the blob associated with this operation.
       * This is used as a primary validation for http-based downloads and
       * as a defense-in-depth validation for https-based downloads. If
       * the operation doesn't refer to any blob, this field will have
       * zero bytes.
       * </pre>
       *
       * <code>optional bytes data_sha256_hash = 8;</code>
       * @return Whether the dataSha256Hash field is set.
       */
      @java.lang.Override
      public boolean hasDataSha256Hash() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <pre>
       * Optional SHA 256 hash of the blob associated with this operation.
       * This is used as a primary validation for http-based downloads and
       * as a defense-in-depth validation for https-based downloads. If
       * the operation doesn't refer to any blob, this field will have
       * zero bytes.
       * </pre>
       *
       * <code>optional bytes data_sha256_hash = 8;</code>
       * @return The dataSha256Hash.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getDataSha256Hash() {
        return dataSha256Hash_;
      }
      /**
       * <pre>
       * Optional SHA 256 hash of the blob associated with this operation.
       * This is used as a primary validation for http-based downloads and
       * as a defense-in-depth validation for https-based downloads. If
       * the operation doesn't refer to any blob, this field will have
       * zero bytes.
       * </pre>
       *
       * <code>optional bytes data_sha256_hash = 8;</code>
       * @param value The dataSha256Hash to set.
       * @return This builder for chaining.
       */
      public Builder setDataSha256Hash(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        dataSha256Hash_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional SHA 256 hash of the blob associated with this operation.
       * This is used as a primary validation for http-based downloads and
       * as a defense-in-depth validation for https-based downloads. If
       * the operation doesn't refer to any blob, this field will have
       * zero bytes.
       * </pre>
       *
       * <code>optional bytes data_sha256_hash = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearDataSha256Hash() {
        bitField0_ = (bitField0_ & ~0x00000080);
        dataSha256Hash_ = getDefaultInstance().getDataSha256Hash();
        onChanged();
        return this;
      }

      private com.google.protobuf.ByteString srcSha256Hash_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * Indicates the SHA 256 hash of the source data referenced in src_extents at
       * the time of applying the operation. If present, the update_engine daemon
       * MUST read and verify the source data before applying the operation.
       * </pre>
       *
       * <code>optional bytes src_sha256_hash = 9;</code>
       * @return Whether the srcSha256Hash field is set.
       */
      @java.lang.Override
      public boolean hasSrcSha256Hash() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <pre>
       * Indicates the SHA 256 hash of the source data referenced in src_extents at
       * the time of applying the operation. If present, the update_engine daemon
       * MUST read and verify the source data before applying the operation.
       * </pre>
       *
       * <code>optional bytes src_sha256_hash = 9;</code>
       * @return The srcSha256Hash.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getSrcSha256Hash() {
        return srcSha256Hash_;
      }
      /**
       * <pre>
       * Indicates the SHA 256 hash of the source data referenced in src_extents at
       * the time of applying the operation. If present, the update_engine daemon
       * MUST read and verify the source data before applying the operation.
       * </pre>
       *
       * <code>optional bytes src_sha256_hash = 9;</code>
       * @param value The srcSha256Hash to set.
       * @return This builder for chaining.
       */
      public Builder setSrcSha256Hash(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        srcSha256Hash_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Indicates the SHA 256 hash of the source data referenced in src_extents at
       * the time of applying the operation. If present, the update_engine daemon
       * MUST read and verify the source data before applying the operation.
       * </pre>
       *
       * <code>optional bytes src_sha256_hash = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearSrcSha256Hash() {
        bitField0_ = (bitField0_ & ~0x00000100);
        srcSha256Hash_ = getDefaultInstance().getSrcSha256Hash();
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.InstallOperation)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.InstallOperation)
    private static final chromeos_update_engine.UpdateMetadata.InstallOperation DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.InstallOperation();
    }

    public static chromeos_update_engine.UpdateMetadata.InstallOperation getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<InstallOperation>
        PARSER = new com.google.protobuf.AbstractParser<InstallOperation>() {
      @java.lang.Override
      public InstallOperation parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new InstallOperation(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<InstallOperation> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<InstallOperation> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperation getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PartitionUpdateOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.PartitionUpdate)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * A platform-specific name to identify the partition set being updated. For
     * example, in Chrome OS this could be "ROOT" or "KERNEL".
     * </pre>
     *
     * <code>required string partition_name = 1;</code>
     * @return Whether the partitionName field is set.
     */
    boolean hasPartitionName();
    /**
     * <pre>
     * A platform-specific name to identify the partition set being updated. For
     * example, in Chrome OS this could be "ROOT" or "KERNEL".
     * </pre>
     *
     * <code>required string partition_name = 1;</code>
     * @return The partitionName.
     */
    java.lang.String getPartitionName();
    /**
     * <pre>
     * A platform-specific name to identify the partition set being updated. For
     * example, in Chrome OS this could be "ROOT" or "KERNEL".
     * </pre>
     *
     * <code>required string partition_name = 1;</code>
     * @return The bytes for partitionName.
     */
    com.google.protobuf.ByteString
        getPartitionNameBytes();

    /**
     * <pre>
     * Whether this partition carries a filesystem with post-install program that
     * must be run to finalize the update process. See also |postinstall_path| and
     * |filesystem_type|.
     * </pre>
     *
     * <code>optional bool run_postinstall = 2;</code>
     * @return Whether the runPostinstall field is set.
     */
    boolean hasRunPostinstall();
    /**
     * <pre>
     * Whether this partition carries a filesystem with post-install program that
     * must be run to finalize the update process. See also |postinstall_path| and
     * |filesystem_type|.
     * </pre>
     *
     * <code>optional bool run_postinstall = 2;</code>
     * @return The runPostinstall.
     */
    boolean getRunPostinstall();

    /**
     * <pre>
     * The path of the executable program to run during the post-install step,
     * relative to the root of this filesystem. If not set, the default "postinst"
     * will be used. This setting is only used when |run_postinstall| is set and
     * true.
     * </pre>
     *
     * <code>optional string postinstall_path = 3;</code>
     * @return Whether the postinstallPath field is set.
     */
    boolean hasPostinstallPath();
    /**
     * <pre>
     * The path of the executable program to run during the post-install step,
     * relative to the root of this filesystem. If not set, the default "postinst"
     * will be used. This setting is only used when |run_postinstall| is set and
     * true.
     * </pre>
     *
     * <code>optional string postinstall_path = 3;</code>
     * @return The postinstallPath.
     */
    java.lang.String getPostinstallPath();
    /**
     * <pre>
     * The path of the executable program to run during the post-install step,
     * relative to the root of this filesystem. If not set, the default "postinst"
     * will be used. This setting is only used when |run_postinstall| is set and
     * true.
     * </pre>
     *
     * <code>optional string postinstall_path = 3;</code>
     * @return The bytes for postinstallPath.
     */
    com.google.protobuf.ByteString
        getPostinstallPathBytes();

    /**
     * <pre>
     * The filesystem type as passed to the mount(2) syscall when mounting the new
     * filesystem to run the post-install program. If not set, a fixed list of
     * filesystems will be attempted. This setting is only used if
     * |run_postinstall| is set and true.
     * </pre>
     *
     * <code>optional string filesystem_type = 4;</code>
     * @return Whether the filesystemType field is set.
     */
    boolean hasFilesystemType();
    /**
     * <pre>
     * The filesystem type as passed to the mount(2) syscall when mounting the new
     * filesystem to run the post-install program. If not set, a fixed list of
     * filesystems will be attempted. This setting is only used if
     * |run_postinstall| is set and true.
     * </pre>
     *
     * <code>optional string filesystem_type = 4;</code>
     * @return The filesystemType.
     */
    java.lang.String getFilesystemType();
    /**
     * <pre>
     * The filesystem type as passed to the mount(2) syscall when mounting the new
     * filesystem to run the post-install program. If not set, a fixed list of
     * filesystems will be attempted. This setting is only used if
     * |run_postinstall| is set and true.
     * </pre>
     *
     * <code>optional string filesystem_type = 4;</code>
     * @return The bytes for filesystemType.
     */
    com.google.protobuf.ByteString
        getFilesystemTypeBytes();

    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature>
        getNewPartitionSignatureList();
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    chromeos_update_engine.UpdateMetadata.Signatures.Signature getNewPartitionSignature(int index);
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    int getNewPartitionSignatureCount();
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
        getNewPartitionSignatureOrBuilderList();
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder getNewPartitionSignatureOrBuilder(
        int index);

    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
     * @return Whether the oldPartitionInfo field is set.
     */
    boolean hasOldPartitionInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
     * @return The oldPartitionInfo.
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfo getOldPartitionInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldPartitionInfoOrBuilder();

    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
     * @return Whether the newPartitionInfo field is set.
     */
    boolean hasNewPartitionInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
     * @return The newPartitionInfo.
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfo getNewPartitionInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewPartitionInfoOrBuilder();

    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation>
        getOperationsList();
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    chromeos_update_engine.UpdateMetadata.InstallOperation getOperations(int index);
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    int getOperationsCount();
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
        getOperationsOrBuilderList();
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getOperationsOrBuilder(
        int index);

    /**
     * <pre>
     * Whether a failure in the postinstall step for this partition should be
     * ignored.
     * </pre>
     *
     * <code>optional bool postinstall_optional = 9;</code>
     * @return Whether the postinstallOptional field is set.
     */
    boolean hasPostinstallOptional();
    /**
     * <pre>
     * Whether a failure in the postinstall step for this partition should be
     * ignored.
     * </pre>
     *
     * <code>optional bool postinstall_optional = 9;</code>
     * @return The postinstallOptional.
     */
    boolean getPostinstallOptional();

    /**
     * <pre>
     * The extent for data covered by verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
     * @return Whether the hashTreeDataExtent field is set.
     */
    boolean hasHashTreeDataExtent();
    /**
     * <pre>
     * The extent for data covered by verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
     * @return The hashTreeDataExtent.
     */
    chromeos_update_engine.UpdateMetadata.Extent getHashTreeDataExtent();
    /**
     * <pre>
     * The extent for data covered by verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
     */
    chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getHashTreeDataExtentOrBuilder();

    /**
     * <pre>
     * The extent to store verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
     * @return Whether the hashTreeExtent field is set.
     */
    boolean hasHashTreeExtent();
    /**
     * <pre>
     * The extent to store verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
     * @return The hashTreeExtent.
     */
    chromeos_update_engine.UpdateMetadata.Extent getHashTreeExtent();
    /**
     * <pre>
     * The extent to store verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
     */
    chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getHashTreeExtentOrBuilder();

    /**
     * <pre>
     * The hash algorithm used in verity hash tree.
     * </pre>
     *
     * <code>optional string hash_tree_algorithm = 12;</code>
     * @return Whether the hashTreeAlgorithm field is set.
     */
    boolean hasHashTreeAlgorithm();
    /**
     * <pre>
     * The hash algorithm used in verity hash tree.
     * </pre>
     *
     * <code>optional string hash_tree_algorithm = 12;</code>
     * @return The hashTreeAlgorithm.
     */
    java.lang.String getHashTreeAlgorithm();
    /**
     * <pre>
     * The hash algorithm used in verity hash tree.
     * </pre>
     *
     * <code>optional string hash_tree_algorithm = 12;</code>
     * @return The bytes for hashTreeAlgorithm.
     */
    com.google.protobuf.ByteString
        getHashTreeAlgorithmBytes();

    /**
     * <pre>
     * The salt used for verity hash tree.
     * </pre>
     *
     * <code>optional bytes hash_tree_salt = 13;</code>
     * @return Whether the hashTreeSalt field is set.
     */
    boolean hasHashTreeSalt();
    /**
     * <pre>
     * The salt used for verity hash tree.
     * </pre>
     *
     * <code>optional bytes hash_tree_salt = 13;</code>
     * @return The hashTreeSalt.
     */
    com.google.protobuf.ByteString getHashTreeSalt();

    /**
     * <pre>
     * The extent for data covered by FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
     * @return Whether the fecDataExtent field is set.
     */
    boolean hasFecDataExtent();
    /**
     * <pre>
     * The extent for data covered by FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
     * @return The fecDataExtent.
     */
    chromeos_update_engine.UpdateMetadata.Extent getFecDataExtent();
    /**
     * <pre>
     * The extent for data covered by FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
     */
    chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getFecDataExtentOrBuilder();

    /**
     * <pre>
     * The extent to store FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
     * @return Whether the fecExtent field is set.
     */
    boolean hasFecExtent();
    /**
     * <pre>
     * The extent to store FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
     * @return The fecExtent.
     */
    chromeos_update_engine.UpdateMetadata.Extent getFecExtent();
    /**
     * <pre>
     * The extent to store FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
     */
    chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getFecExtentOrBuilder();

    /**
     * <pre>
     * The number of FEC roots.
     * </pre>
     *
     * <code>optional uint32 fec_roots = 16 [default = 2];</code>
     * @return Whether the fecRoots field is set.
     */
    boolean hasFecRoots();
    /**
     * <pre>
     * The number of FEC roots.
     * </pre>
     *
     * <code>optional uint32 fec_roots = 16 [default = 2];</code>
     * @return The fecRoots.
     */
    int getFecRoots();
  }
  /**
   * <pre>
   * Describes the update to apply to a single partition.
   * </pre>
   *
   * Protobuf type {@code chromeos_update_engine.PartitionUpdate}
   */
  public static final class PartitionUpdate extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.PartitionUpdate)
      PartitionUpdateOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PartitionUpdate.newBuilder() to construct.
    private PartitionUpdate(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PartitionUpdate() {
      partitionName_ = "";
      postinstallPath_ = "";
      filesystemType_ = "";
      newPartitionSignature_ = java.util.Collections.emptyList();
      operations_ = java.util.Collections.emptyList();
      hashTreeAlgorithm_ = "";
      hashTreeSalt_ = com.google.protobuf.ByteString.EMPTY;
      fecRoots_ = 2;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PartitionUpdate();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PartitionUpdate(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              partitionName_ = bs;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              runPostinstall_ = input.readBool();
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              postinstallPath_ = bs;
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000008;
              filesystemType_ = bs;
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) != 0)) {
                newPartitionSignature_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Signatures.Signature>();
                mutable_bitField0_ |= 0x00000010;
              }
              newPartitionSignature_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.Signatures.Signature.PARSER, extensionRegistry));
              break;
            }
            case 50: {
              chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) != 0)) {
                subBuilder = oldPartitionInfo_.toBuilder();
              }
              oldPartitionInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(oldPartitionInfo_);
                oldPartitionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 58: {
              chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) != 0)) {
                subBuilder = newPartitionInfo_.toBuilder();
              }
              newPartitionInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(newPartitionInfo_);
                newPartitionInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
            case 66: {
              if (!((mutable_bitField0_ & 0x00000080) != 0)) {
                operations_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.InstallOperation>();
                mutable_bitField0_ |= 0x00000080;
              }
              operations_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.InstallOperation.PARSER, extensionRegistry));
              break;
            }
            case 72: {
              bitField0_ |= 0x00000040;
              postinstallOptional_ = input.readBool();
              break;
            }
            case 82: {
              chromeos_update_engine.UpdateMetadata.Extent.Builder subBuilder = null;
              if (((bitField0_ & 0x00000080) != 0)) {
                subBuilder = hashTreeDataExtent_.toBuilder();
              }
              hashTreeDataExtent_ = input.readMessage(chromeos_update_engine.UpdateMetadata.Extent.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(hashTreeDataExtent_);
                hashTreeDataExtent_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000080;
              break;
            }
            case 90: {
              chromeos_update_engine.UpdateMetadata.Extent.Builder subBuilder = null;
              if (((bitField0_ & 0x00000100) != 0)) {
                subBuilder = hashTreeExtent_.toBuilder();
              }
              hashTreeExtent_ = input.readMessage(chromeos_update_engine.UpdateMetadata.Extent.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(hashTreeExtent_);
                hashTreeExtent_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000100;
              break;
            }
            case 98: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000200;
              hashTreeAlgorithm_ = bs;
              break;
            }
            case 106: {
              bitField0_ |= 0x00000400;
              hashTreeSalt_ = input.readBytes();
              break;
            }
            case 114: {
              chromeos_update_engine.UpdateMetadata.Extent.Builder subBuilder = null;
              if (((bitField0_ & 0x00000800) != 0)) {
                subBuilder = fecDataExtent_.toBuilder();
              }
              fecDataExtent_ = input.readMessage(chromeos_update_engine.UpdateMetadata.Extent.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(fecDataExtent_);
                fecDataExtent_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000800;
              break;
            }
            case 122: {
              chromeos_update_engine.UpdateMetadata.Extent.Builder subBuilder = null;
              if (((bitField0_ & 0x00001000) != 0)) {
                subBuilder = fecExtent_.toBuilder();
              }
              fecExtent_ = input.readMessage(chromeos_update_engine.UpdateMetadata.Extent.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(fecExtent_);
                fecExtent_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00001000;
              break;
            }
            case 128: {
              bitField0_ |= 0x00002000;
              fecRoots_ = input.readUInt32();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) != 0)) {
          newPartitionSignature_ = java.util.Collections.unmodifiableList(newPartitionSignature_);
        }
        if (((mutable_bitField0_ & 0x00000080) != 0)) {
          operations_ = java.util.Collections.unmodifiableList(operations_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionUpdate_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionUpdate_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.PartitionUpdate.class, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder.class);
    }

    private int bitField0_;
    public static final int PARTITION_NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object partitionName_;
    /**
     * <pre>
     * A platform-specific name to identify the partition set being updated. For
     * example, in Chrome OS this could be "ROOT" or "KERNEL".
     * </pre>
     *
     * <code>required string partition_name = 1;</code>
     * @return Whether the partitionName field is set.
     */
    @java.lang.Override
    public boolean hasPartitionName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * A platform-specific name to identify the partition set being updated. For
     * example, in Chrome OS this could be "ROOT" or "KERNEL".
     * </pre>
     *
     * <code>required string partition_name = 1;</code>
     * @return The partitionName.
     */
    @java.lang.Override
    public java.lang.String getPartitionName() {
      java.lang.Object ref = partitionName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          partitionName_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * A platform-specific name to identify the partition set being updated. For
     * example, in Chrome OS this could be "ROOT" or "KERNEL".
     * </pre>
     *
     * <code>required string partition_name = 1;</code>
     * @return The bytes for partitionName.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getPartitionNameBytes() {
      java.lang.Object ref = partitionName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        partitionName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RUN_POSTINSTALL_FIELD_NUMBER = 2;
    private boolean runPostinstall_;
    /**
     * <pre>
     * Whether this partition carries a filesystem with post-install program that
     * must be run to finalize the update process. See also |postinstall_path| and
     * |filesystem_type|.
     * </pre>
     *
     * <code>optional bool run_postinstall = 2;</code>
     * @return Whether the runPostinstall field is set.
     */
    @java.lang.Override
    public boolean hasRunPostinstall() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Whether this partition carries a filesystem with post-install program that
     * must be run to finalize the update process. See also |postinstall_path| and
     * |filesystem_type|.
     * </pre>
     *
     * <code>optional bool run_postinstall = 2;</code>
     * @return The runPostinstall.
     */
    @java.lang.Override
    public boolean getRunPostinstall() {
      return runPostinstall_;
    }

    public static final int POSTINSTALL_PATH_FIELD_NUMBER = 3;
    private volatile java.lang.Object postinstallPath_;
    /**
     * <pre>
     * The path of the executable program to run during the post-install step,
     * relative to the root of this filesystem. If not set, the default "postinst"
     * will be used. This setting is only used when |run_postinstall| is set and
     * true.
     * </pre>
     *
     * <code>optional string postinstall_path = 3;</code>
     * @return Whether the postinstallPath field is set.
     */
    @java.lang.Override
    public boolean hasPostinstallPath() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * The path of the executable program to run during the post-install step,
     * relative to the root of this filesystem. If not set, the default "postinst"
     * will be used. This setting is only used when |run_postinstall| is set and
     * true.
     * </pre>
     *
     * <code>optional string postinstall_path = 3;</code>
     * @return The postinstallPath.
     */
    @java.lang.Override
    public java.lang.String getPostinstallPath() {
      java.lang.Object ref = postinstallPath_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          postinstallPath_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The path of the executable program to run during the post-install step,
     * relative to the root of this filesystem. If not set, the default "postinst"
     * will be used. This setting is only used when |run_postinstall| is set and
     * true.
     * </pre>
     *
     * <code>optional string postinstall_path = 3;</code>
     * @return The bytes for postinstallPath.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getPostinstallPathBytes() {
      java.lang.Object ref = postinstallPath_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        postinstallPath_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int FILESYSTEM_TYPE_FIELD_NUMBER = 4;
    private volatile java.lang.Object filesystemType_;
    /**
     * <pre>
     * The filesystem type as passed to the mount(2) syscall when mounting the new
     * filesystem to run the post-install program. If not set, a fixed list of
     * filesystems will be attempted. This setting is only used if
     * |run_postinstall| is set and true.
     * </pre>
     *
     * <code>optional string filesystem_type = 4;</code>
     * @return Whether the filesystemType field is set.
     */
    @java.lang.Override
    public boolean hasFilesystemType() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * The filesystem type as passed to the mount(2) syscall when mounting the new
     * filesystem to run the post-install program. If not set, a fixed list of
     * filesystems will be attempted. This setting is only used if
     * |run_postinstall| is set and true.
     * </pre>
     *
     * <code>optional string filesystem_type = 4;</code>
     * @return The filesystemType.
     */
    @java.lang.Override
    public java.lang.String getFilesystemType() {
      java.lang.Object ref = filesystemType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          filesystemType_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The filesystem type as passed to the mount(2) syscall when mounting the new
     * filesystem to run the post-install program. If not set, a fixed list of
     * filesystems will be attempted. This setting is only used if
     * |run_postinstall| is set and true.
     * </pre>
     *
     * <code>optional string filesystem_type = 4;</code>
     * @return The bytes for filesystemType.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getFilesystemTypeBytes() {
      java.lang.Object ref = filesystemType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        filesystemType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NEW_PARTITION_SIGNATURE_FIELD_NUMBER = 5;
    private java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> newPartitionSignature_;
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> getNewPartitionSignatureList() {
      return newPartitionSignature_;
    }
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
        getNewPartitionSignatureOrBuilderList() {
      return newPartitionSignature_;
    }
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    @java.lang.Override
    public int getNewPartitionSignatureCount() {
      return newPartitionSignature_.size();
    }
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Signatures.Signature getNewPartitionSignature(int index) {
      return newPartitionSignature_.get(index);
    }
    /**
     * <pre>
     * If present, a list of signatures of the new_partition_info.hash signed with
     * different keys. If the update_engine daemon requires vendor-signed images
     * and has its public key installed, one of the signatures should be valid
     * for /postinstall to run.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder getNewPartitionSignatureOrBuilder(
        int index) {
      return newPartitionSignature_.get(index);
    }

    public static final int OLD_PARTITION_INFO_FIELD_NUMBER = 6;
    private chromeos_update_engine.UpdateMetadata.PartitionInfo oldPartitionInfo_;
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
     * @return Whether the oldPartitionInfo field is set.
     */
    @java.lang.Override
    public boolean hasOldPartitionInfo() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
     * @return The oldPartitionInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getOldPartitionInfo() {
      return oldPartitionInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldPartitionInfo_;
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldPartitionInfoOrBuilder() {
      return oldPartitionInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldPartitionInfo_;
    }

    public static final int NEW_PARTITION_INFO_FIELD_NUMBER = 7;
    private chromeos_update_engine.UpdateMetadata.PartitionInfo newPartitionInfo_;
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
     * @return Whether the newPartitionInfo field is set.
     */
    @java.lang.Override
    public boolean hasNewPartitionInfo() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
     * @return The newPartitionInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getNewPartitionInfo() {
      return newPartitionInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newPartitionInfo_;
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewPartitionInfoOrBuilder() {
      return newPartitionInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newPartitionInfo_;
    }

    public static final int OPERATIONS_FIELD_NUMBER = 8;
    private java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> operations_;
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> getOperationsList() {
      return operations_;
    }
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
        getOperationsOrBuilderList() {
      return operations_;
    }
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    @java.lang.Override
    public int getOperationsCount() {
      return operations_.size();
    }
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperation getOperations(int index) {
      return operations_.get(index);
    }
    /**
     * <pre>
     * The list of operations to be performed to apply this PartitionUpdate. The
     * associated operation blobs (in operations[i].data_offset, data_length)
     * should be stored contiguously and in the same order.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getOperationsOrBuilder(
        int index) {
      return operations_.get(index);
    }

    public static final int POSTINSTALL_OPTIONAL_FIELD_NUMBER = 9;
    private boolean postinstallOptional_;
    /**
     * <pre>
     * Whether a failure in the postinstall step for this partition should be
     * ignored.
     * </pre>
     *
     * <code>optional bool postinstall_optional = 9;</code>
     * @return Whether the postinstallOptional field is set.
     */
    @java.lang.Override
    public boolean hasPostinstallOptional() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <pre>
     * Whether a failure in the postinstall step for this partition should be
     * ignored.
     * </pre>
     *
     * <code>optional bool postinstall_optional = 9;</code>
     * @return The postinstallOptional.
     */
    @java.lang.Override
    public boolean getPostinstallOptional() {
      return postinstallOptional_;
    }

    public static final int HASH_TREE_DATA_EXTENT_FIELD_NUMBER = 10;
    private chromeos_update_engine.UpdateMetadata.Extent hashTreeDataExtent_;
    /**
     * <pre>
     * The extent for data covered by verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
     * @return Whether the hashTreeDataExtent field is set.
     */
    @java.lang.Override
    public boolean hasHashTreeDataExtent() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <pre>
     * The extent for data covered by verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
     * @return The hashTreeDataExtent.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getHashTreeDataExtent() {
      return hashTreeDataExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeDataExtent_;
    }
    /**
     * <pre>
     * The extent for data covered by verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getHashTreeDataExtentOrBuilder() {
      return hashTreeDataExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeDataExtent_;
    }

    public static final int HASH_TREE_EXTENT_FIELD_NUMBER = 11;
    private chromeos_update_engine.UpdateMetadata.Extent hashTreeExtent_;
    /**
     * <pre>
     * The extent to store verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
     * @return Whether the hashTreeExtent field is set.
     */
    @java.lang.Override
    public boolean hasHashTreeExtent() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <pre>
     * The extent to store verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
     * @return The hashTreeExtent.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getHashTreeExtent() {
      return hashTreeExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeExtent_;
    }
    /**
     * <pre>
     * The extent to store verity hash tree.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getHashTreeExtentOrBuilder() {
      return hashTreeExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeExtent_;
    }

    public static final int HASH_TREE_ALGORITHM_FIELD_NUMBER = 12;
    private volatile java.lang.Object hashTreeAlgorithm_;
    /**
     * <pre>
     * The hash algorithm used in verity hash tree.
     * </pre>
     *
     * <code>optional string hash_tree_algorithm = 12;</code>
     * @return Whether the hashTreeAlgorithm field is set.
     */
    @java.lang.Override
    public boolean hasHashTreeAlgorithm() {
      return ((bitField0_ & 0x00000200) != 0);
    }
    /**
     * <pre>
     * The hash algorithm used in verity hash tree.
     * </pre>
     *
     * <code>optional string hash_tree_algorithm = 12;</code>
     * @return The hashTreeAlgorithm.
     */
    @java.lang.Override
    public java.lang.String getHashTreeAlgorithm() {
      java.lang.Object ref = hashTreeAlgorithm_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          hashTreeAlgorithm_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * The hash algorithm used in verity hash tree.
     * </pre>
     *
     * <code>optional string hash_tree_algorithm = 12;</code>
     * @return The bytes for hashTreeAlgorithm.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getHashTreeAlgorithmBytes() {
      java.lang.Object ref = hashTreeAlgorithm_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        hashTreeAlgorithm_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int HASH_TREE_SALT_FIELD_NUMBER = 13;
    private com.google.protobuf.ByteString hashTreeSalt_;
    /**
     * <pre>
     * The salt used for verity hash tree.
     * </pre>
     *
     * <code>optional bytes hash_tree_salt = 13;</code>
     * @return Whether the hashTreeSalt field is set.
     */
    @java.lang.Override
    public boolean hasHashTreeSalt() {
      return ((bitField0_ & 0x00000400) != 0);
    }
    /**
     * <pre>
     * The salt used for verity hash tree.
     * </pre>
     *
     * <code>optional bytes hash_tree_salt = 13;</code>
     * @return The hashTreeSalt.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getHashTreeSalt() {
      return hashTreeSalt_;
    }

    public static final int FEC_DATA_EXTENT_FIELD_NUMBER = 14;
    private chromeos_update_engine.UpdateMetadata.Extent fecDataExtent_;
    /**
     * <pre>
     * The extent for data covered by FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
     * @return Whether the fecDataExtent field is set.
     */
    @java.lang.Override
    public boolean hasFecDataExtent() {
      return ((bitField0_ & 0x00000800) != 0);
    }
    /**
     * <pre>
     * The extent for data covered by FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
     * @return The fecDataExtent.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getFecDataExtent() {
      return fecDataExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecDataExtent_;
    }
    /**
     * <pre>
     * The extent for data covered by FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getFecDataExtentOrBuilder() {
      return fecDataExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecDataExtent_;
    }

    public static final int FEC_EXTENT_FIELD_NUMBER = 15;
    private chromeos_update_engine.UpdateMetadata.Extent fecExtent_;
    /**
     * <pre>
     * The extent to store FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
     * @return Whether the fecExtent field is set.
     */
    @java.lang.Override
    public boolean hasFecExtent() {
      return ((bitField0_ & 0x00001000) != 0);
    }
    /**
     * <pre>
     * The extent to store FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
     * @return The fecExtent.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.Extent getFecExtent() {
      return fecExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecExtent_;
    }
    /**
     * <pre>
     * The extent to store FEC.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getFecExtentOrBuilder() {
      return fecExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecExtent_;
    }

    public static final int FEC_ROOTS_FIELD_NUMBER = 16;
    private int fecRoots_;
    /**
     * <pre>
     * The number of FEC roots.
     * </pre>
     *
     * <code>optional uint32 fec_roots = 16 [default = 2];</code>
     * @return Whether the fecRoots field is set.
     */
    @java.lang.Override
    public boolean hasFecRoots() {
      return ((bitField0_ & 0x00002000) != 0);
    }
    /**
     * <pre>
     * The number of FEC roots.
     * </pre>
     *
     * <code>optional uint32 fec_roots = 16 [default = 2];</code>
     * @return The fecRoots.
     */
    @java.lang.Override
    public int getFecRoots() {
      return fecRoots_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasPartitionName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getOperationsCount(); i++) {
        if (!getOperations(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, partitionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, runPostinstall_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, postinstallPath_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, filesystemType_);
      }
      for (int i = 0; i < newPartitionSignature_.size(); i++) {
        output.writeMessage(5, newPartitionSignature_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(6, getOldPartitionInfo());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeMessage(7, getNewPartitionInfo());
      }
      for (int i = 0; i < operations_.size(); i++) {
        output.writeMessage(8, operations_.get(i));
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeBool(9, postinstallOptional_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeMessage(10, getHashTreeDataExtent());
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeMessage(11, getHashTreeExtent());
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 12, hashTreeAlgorithm_);
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        output.writeBytes(13, hashTreeSalt_);
      }
      if (((bitField0_ & 0x00000800) != 0)) {
        output.writeMessage(14, getFecDataExtent());
      }
      if (((bitField0_ & 0x00001000) != 0)) {
        output.writeMessage(15, getFecExtent());
      }
      if (((bitField0_ & 0x00002000) != 0)) {
        output.writeUInt32(16, fecRoots_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, partitionName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, runPostinstall_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, postinstallPath_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, filesystemType_);
      }
      for (int i = 0; i < newPartitionSignature_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, newPartitionSignature_.get(i));
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getOldPartitionInfo());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getNewPartitionInfo());
      }
      for (int i = 0; i < operations_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, operations_.get(i));
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(9, postinstallOptional_);
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getHashTreeDataExtent());
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getHashTreeExtent());
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(12, hashTreeAlgorithm_);
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(13, hashTreeSalt_);
      }
      if (((bitField0_ & 0x00000800) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getFecDataExtent());
      }
      if (((bitField0_ & 0x00001000) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getFecExtent());
      }
      if (((bitField0_ & 0x00002000) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(16, fecRoots_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.PartitionUpdate)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.PartitionUpdate other = (chromeos_update_engine.UpdateMetadata.PartitionUpdate) obj;

      if (hasPartitionName() != other.hasPartitionName()) return false;
      if (hasPartitionName()) {
        if (!getPartitionName()
            .equals(other.getPartitionName())) return false;
      }
      if (hasRunPostinstall() != other.hasRunPostinstall()) return false;
      if (hasRunPostinstall()) {
        if (getRunPostinstall()
            != other.getRunPostinstall()) return false;
      }
      if (hasPostinstallPath() != other.hasPostinstallPath()) return false;
      if (hasPostinstallPath()) {
        if (!getPostinstallPath()
            .equals(other.getPostinstallPath())) return false;
      }
      if (hasFilesystemType() != other.hasFilesystemType()) return false;
      if (hasFilesystemType()) {
        if (!getFilesystemType()
            .equals(other.getFilesystemType())) return false;
      }
      if (!getNewPartitionSignatureList()
          .equals(other.getNewPartitionSignatureList())) return false;
      if (hasOldPartitionInfo() != other.hasOldPartitionInfo()) return false;
      if (hasOldPartitionInfo()) {
        if (!getOldPartitionInfo()
            .equals(other.getOldPartitionInfo())) return false;
      }
      if (hasNewPartitionInfo() != other.hasNewPartitionInfo()) return false;
      if (hasNewPartitionInfo()) {
        if (!getNewPartitionInfo()
            .equals(other.getNewPartitionInfo())) return false;
      }
      if (!getOperationsList()
          .equals(other.getOperationsList())) return false;
      if (hasPostinstallOptional() != other.hasPostinstallOptional()) return false;
      if (hasPostinstallOptional()) {
        if (getPostinstallOptional()
            != other.getPostinstallOptional()) return false;
      }
      if (hasHashTreeDataExtent() != other.hasHashTreeDataExtent()) return false;
      if (hasHashTreeDataExtent()) {
        if (!getHashTreeDataExtent()
            .equals(other.getHashTreeDataExtent())) return false;
      }
      if (hasHashTreeExtent() != other.hasHashTreeExtent()) return false;
      if (hasHashTreeExtent()) {
        if (!getHashTreeExtent()
            .equals(other.getHashTreeExtent())) return false;
      }
      if (hasHashTreeAlgorithm() != other.hasHashTreeAlgorithm()) return false;
      if (hasHashTreeAlgorithm()) {
        if (!getHashTreeAlgorithm()
            .equals(other.getHashTreeAlgorithm())) return false;
      }
      if (hasHashTreeSalt() != other.hasHashTreeSalt()) return false;
      if (hasHashTreeSalt()) {
        if (!getHashTreeSalt()
            .equals(other.getHashTreeSalt())) return false;
      }
      if (hasFecDataExtent() != other.hasFecDataExtent()) return false;
      if (hasFecDataExtent()) {
        if (!getFecDataExtent()
            .equals(other.getFecDataExtent())) return false;
      }
      if (hasFecExtent() != other.hasFecExtent()) return false;
      if (hasFecExtent()) {
        if (!getFecExtent()
            .equals(other.getFecExtent())) return false;
      }
      if (hasFecRoots() != other.hasFecRoots()) return false;
      if (hasFecRoots()) {
        if (getFecRoots()
            != other.getFecRoots()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPartitionName()) {
        hash = (37 * hash) + PARTITION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getPartitionName().hashCode();
      }
      if (hasRunPostinstall()) {
        hash = (37 * hash) + RUN_POSTINSTALL_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getRunPostinstall());
      }
      if (hasPostinstallPath()) {
        hash = (37 * hash) + POSTINSTALL_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getPostinstallPath().hashCode();
      }
      if (hasFilesystemType()) {
        hash = (37 * hash) + FILESYSTEM_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + getFilesystemType().hashCode();
      }
      if (getNewPartitionSignatureCount() > 0) {
        hash = (37 * hash) + NEW_PARTITION_SIGNATURE_FIELD_NUMBER;
        hash = (53 * hash) + getNewPartitionSignatureList().hashCode();
      }
      if (hasOldPartitionInfo()) {
        hash = (37 * hash) + OLD_PARTITION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getOldPartitionInfo().hashCode();
      }
      if (hasNewPartitionInfo()) {
        hash = (37 * hash) + NEW_PARTITION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getNewPartitionInfo().hashCode();
      }
      if (getOperationsCount() > 0) {
        hash = (37 * hash) + OPERATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getOperationsList().hashCode();
      }
      if (hasPostinstallOptional()) {
        hash = (37 * hash) + POSTINSTALL_OPTIONAL_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getPostinstallOptional());
      }
      if (hasHashTreeDataExtent()) {
        hash = (37 * hash) + HASH_TREE_DATA_EXTENT_FIELD_NUMBER;
        hash = (53 * hash) + getHashTreeDataExtent().hashCode();
      }
      if (hasHashTreeExtent()) {
        hash = (37 * hash) + HASH_TREE_EXTENT_FIELD_NUMBER;
        hash = (53 * hash) + getHashTreeExtent().hashCode();
      }
      if (hasHashTreeAlgorithm()) {
        hash = (37 * hash) + HASH_TREE_ALGORITHM_FIELD_NUMBER;
        hash = (53 * hash) + getHashTreeAlgorithm().hashCode();
      }
      if (hasHashTreeSalt()) {
        hash = (37 * hash) + HASH_TREE_SALT_FIELD_NUMBER;
        hash = (53 * hash) + getHashTreeSalt().hashCode();
      }
      if (hasFecDataExtent()) {
        hash = (37 * hash) + FEC_DATA_EXTENT_FIELD_NUMBER;
        hash = (53 * hash) + getFecDataExtent().hashCode();
      }
      if (hasFecExtent()) {
        hash = (37 * hash) + FEC_EXTENT_FIELD_NUMBER;
        hash = (53 * hash) + getFecExtent().hashCode();
      }
      if (hasFecRoots()) {
        hash = (37 * hash) + FEC_ROOTS_FIELD_NUMBER;
        hash = (53 * hash) + getFecRoots();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.PartitionUpdate prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Describes the update to apply to a single partition.
     * </pre>
     *
     * Protobuf type {@code chromeos_update_engine.PartitionUpdate}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.PartitionUpdate)
        chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionUpdate_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionUpdate_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.PartitionUpdate.class, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.PartitionUpdate.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNewPartitionSignatureFieldBuilder();
          getOldPartitionInfoFieldBuilder();
          getNewPartitionInfoFieldBuilder();
          getOperationsFieldBuilder();
          getHashTreeDataExtentFieldBuilder();
          getHashTreeExtentFieldBuilder();
          getFecDataExtentFieldBuilder();
          getFecExtentFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        partitionName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        runPostinstall_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        postinstallPath_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        filesystemType_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        if (newPartitionSignatureBuilder_ == null) {
          newPartitionSignature_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          newPartitionSignatureBuilder_.clear();
        }
        if (oldPartitionInfoBuilder_ == null) {
          oldPartitionInfo_ = null;
        } else {
          oldPartitionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        if (newPartitionInfoBuilder_ == null) {
          newPartitionInfo_ = null;
        } else {
          newPartitionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        if (operationsBuilder_ == null) {
          operations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
        } else {
          operationsBuilder_.clear();
        }
        postinstallOptional_ = false;
        bitField0_ = (bitField0_ & ~0x00000100);
        if (hashTreeDataExtentBuilder_ == null) {
          hashTreeDataExtent_ = null;
        } else {
          hashTreeDataExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000200);
        if (hashTreeExtentBuilder_ == null) {
          hashTreeExtent_ = null;
        } else {
          hashTreeExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000400);
        hashTreeAlgorithm_ = "";
        bitField0_ = (bitField0_ & ~0x00000800);
        hashTreeSalt_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00001000);
        if (fecDataExtentBuilder_ == null) {
          fecDataExtent_ = null;
        } else {
          fecDataExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        if (fecExtentBuilder_ == null) {
          fecExtent_ = null;
        } else {
          fecExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        fecRoots_ = 2;
        bitField0_ = (bitField0_ & ~0x00008000);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_PartitionUpdate_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.PartitionUpdate.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate build() {
        chromeos_update_engine.UpdateMetadata.PartitionUpdate result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate buildPartial() {
        chromeos_update_engine.UpdateMetadata.PartitionUpdate result = new chromeos_update_engine.UpdateMetadata.PartitionUpdate(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.partitionName_ = partitionName_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.runPostinstall_ = runPostinstall_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          to_bitField0_ |= 0x00000004;
        }
        result.postinstallPath_ = postinstallPath_;
        if (((from_bitField0_ & 0x00000008) != 0)) {
          to_bitField0_ |= 0x00000008;
        }
        result.filesystemType_ = filesystemType_;
        if (newPartitionSignatureBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            newPartitionSignature_ = java.util.Collections.unmodifiableList(newPartitionSignature_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.newPartitionSignature_ = newPartitionSignature_;
        } else {
          result.newPartitionSignature_ = newPartitionSignatureBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          if (oldPartitionInfoBuilder_ == null) {
            result.oldPartitionInfo_ = oldPartitionInfo_;
          } else {
            result.oldPartitionInfo_ = oldPartitionInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          if (newPartitionInfoBuilder_ == null) {
            result.newPartitionInfo_ = newPartitionInfo_;
          } else {
            result.newPartitionInfo_ = newPartitionInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000020;
        }
        if (operationsBuilder_ == null) {
          if (((bitField0_ & 0x00000080) != 0)) {
            operations_ = java.util.Collections.unmodifiableList(operations_);
            bitField0_ = (bitField0_ & ~0x00000080);
          }
          result.operations_ = operations_;
        } else {
          result.operations_ = operationsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.postinstallOptional_ = postinstallOptional_;
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          if (hashTreeDataExtentBuilder_ == null) {
            result.hashTreeDataExtent_ = hashTreeDataExtent_;
          } else {
            result.hashTreeDataExtent_ = hashTreeDataExtentBuilder_.build();
          }
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          if (hashTreeExtentBuilder_ == null) {
            result.hashTreeExtent_ = hashTreeExtent_;
          } else {
            result.hashTreeExtent_ = hashTreeExtentBuilder_.build();
          }
          to_bitField0_ |= 0x00000100;
        }
        if (((from_bitField0_ & 0x00000800) != 0)) {
          to_bitField0_ |= 0x00000200;
        }
        result.hashTreeAlgorithm_ = hashTreeAlgorithm_;
        if (((from_bitField0_ & 0x00001000) != 0)) {
          to_bitField0_ |= 0x00000400;
        }
        result.hashTreeSalt_ = hashTreeSalt_;
        if (((from_bitField0_ & 0x00002000) != 0)) {
          if (fecDataExtentBuilder_ == null) {
            result.fecDataExtent_ = fecDataExtent_;
          } else {
            result.fecDataExtent_ = fecDataExtentBuilder_.build();
          }
          to_bitField0_ |= 0x00000800;
        }
        if (((from_bitField0_ & 0x00004000) != 0)) {
          if (fecExtentBuilder_ == null) {
            result.fecExtent_ = fecExtent_;
          } else {
            result.fecExtent_ = fecExtentBuilder_.build();
          }
          to_bitField0_ |= 0x00001000;
        }
        if (((from_bitField0_ & 0x00008000) != 0)) {
          to_bitField0_ |= 0x00002000;
        }
        result.fecRoots_ = fecRoots_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.PartitionUpdate) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.PartitionUpdate)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.PartitionUpdate other) {
        if (other == chromeos_update_engine.UpdateMetadata.PartitionUpdate.getDefaultInstance()) return this;
        if (other.hasPartitionName()) {
          bitField0_ |= 0x00000001;
          partitionName_ = other.partitionName_;
          onChanged();
        }
        if (other.hasRunPostinstall()) {
          setRunPostinstall(other.getRunPostinstall());
        }
        if (other.hasPostinstallPath()) {
          bitField0_ |= 0x00000004;
          postinstallPath_ = other.postinstallPath_;
          onChanged();
        }
        if (other.hasFilesystemType()) {
          bitField0_ |= 0x00000008;
          filesystemType_ = other.filesystemType_;
          onChanged();
        }
        if (newPartitionSignatureBuilder_ == null) {
          if (!other.newPartitionSignature_.isEmpty()) {
            if (newPartitionSignature_.isEmpty()) {
              newPartitionSignature_ = other.newPartitionSignature_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureNewPartitionSignatureIsMutable();
              newPartitionSignature_.addAll(other.newPartitionSignature_);
            }
            onChanged();
          }
        } else {
          if (!other.newPartitionSignature_.isEmpty()) {
            if (newPartitionSignatureBuilder_.isEmpty()) {
              newPartitionSignatureBuilder_.dispose();
              newPartitionSignatureBuilder_ = null;
              newPartitionSignature_ = other.newPartitionSignature_;
              bitField0_ = (bitField0_ & ~0x00000010);
              newPartitionSignatureBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getNewPartitionSignatureFieldBuilder() : null;
            } else {
              newPartitionSignatureBuilder_.addAllMessages(other.newPartitionSignature_);
            }
          }
        }
        if (other.hasOldPartitionInfo()) {
          mergeOldPartitionInfo(other.getOldPartitionInfo());
        }
        if (other.hasNewPartitionInfo()) {
          mergeNewPartitionInfo(other.getNewPartitionInfo());
        }
        if (operationsBuilder_ == null) {
          if (!other.operations_.isEmpty()) {
            if (operations_.isEmpty()) {
              operations_ = other.operations_;
              bitField0_ = (bitField0_ & ~0x00000080);
            } else {
              ensureOperationsIsMutable();
              operations_.addAll(other.operations_);
            }
            onChanged();
          }
        } else {
          if (!other.operations_.isEmpty()) {
            if (operationsBuilder_.isEmpty()) {
              operationsBuilder_.dispose();
              operationsBuilder_ = null;
              operations_ = other.operations_;
              bitField0_ = (bitField0_ & ~0x00000080);
              operationsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getOperationsFieldBuilder() : null;
            } else {
              operationsBuilder_.addAllMessages(other.operations_);
            }
          }
        }
        if (other.hasPostinstallOptional()) {
          setPostinstallOptional(other.getPostinstallOptional());
        }
        if (other.hasHashTreeDataExtent()) {
          mergeHashTreeDataExtent(other.getHashTreeDataExtent());
        }
        if (other.hasHashTreeExtent()) {
          mergeHashTreeExtent(other.getHashTreeExtent());
        }
        if (other.hasHashTreeAlgorithm()) {
          bitField0_ |= 0x00000800;
          hashTreeAlgorithm_ = other.hashTreeAlgorithm_;
          onChanged();
        }
        if (other.hasHashTreeSalt()) {
          setHashTreeSalt(other.getHashTreeSalt());
        }
        if (other.hasFecDataExtent()) {
          mergeFecDataExtent(other.getFecDataExtent());
        }
        if (other.hasFecExtent()) {
          mergeFecExtent(other.getFecExtent());
        }
        if (other.hasFecRoots()) {
          setFecRoots(other.getFecRoots());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasPartitionName()) {
          return false;
        }
        for (int i = 0; i < getOperationsCount(); i++) {
          if (!getOperations(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.PartitionUpdate parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.PartitionUpdate) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object partitionName_ = "";
      /**
       * <pre>
       * A platform-specific name to identify the partition set being updated. For
       * example, in Chrome OS this could be "ROOT" or "KERNEL".
       * </pre>
       *
       * <code>required string partition_name = 1;</code>
       * @return Whether the partitionName field is set.
       */
      public boolean hasPartitionName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * A platform-specific name to identify the partition set being updated. For
       * example, in Chrome OS this could be "ROOT" or "KERNEL".
       * </pre>
       *
       * <code>required string partition_name = 1;</code>
       * @return The partitionName.
       */
      public java.lang.String getPartitionName() {
        java.lang.Object ref = partitionName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            partitionName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * A platform-specific name to identify the partition set being updated. For
       * example, in Chrome OS this could be "ROOT" or "KERNEL".
       * </pre>
       *
       * <code>required string partition_name = 1;</code>
       * @return The bytes for partitionName.
       */
      public com.google.protobuf.ByteString
          getPartitionNameBytes() {
        java.lang.Object ref = partitionName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          partitionName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * A platform-specific name to identify the partition set being updated. For
       * example, in Chrome OS this could be "ROOT" or "KERNEL".
       * </pre>
       *
       * <code>required string partition_name = 1;</code>
       * @param value The partitionName to set.
       * @return This builder for chaining.
       */
      public Builder setPartitionName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        partitionName_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A platform-specific name to identify the partition set being updated. For
       * example, in Chrome OS this could be "ROOT" or "KERNEL".
       * </pre>
       *
       * <code>required string partition_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPartitionName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        partitionName_ = getDefaultInstance().getPartitionName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A platform-specific name to identify the partition set being updated. For
       * example, in Chrome OS this could be "ROOT" or "KERNEL".
       * </pre>
       *
       * <code>required string partition_name = 1;</code>
       * @param value The bytes for partitionName to set.
       * @return This builder for chaining.
       */
      public Builder setPartitionNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        partitionName_ = value;
        onChanged();
        return this;
      }

      private boolean runPostinstall_ ;
      /**
       * <pre>
       * Whether this partition carries a filesystem with post-install program that
       * must be run to finalize the update process. See also |postinstall_path| and
       * |filesystem_type|.
       * </pre>
       *
       * <code>optional bool run_postinstall = 2;</code>
       * @return Whether the runPostinstall field is set.
       */
      @java.lang.Override
      public boolean hasRunPostinstall() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Whether this partition carries a filesystem with post-install program that
       * must be run to finalize the update process. See also |postinstall_path| and
       * |filesystem_type|.
       * </pre>
       *
       * <code>optional bool run_postinstall = 2;</code>
       * @return The runPostinstall.
       */
      @java.lang.Override
      public boolean getRunPostinstall() {
        return runPostinstall_;
      }
      /**
       * <pre>
       * Whether this partition carries a filesystem with post-install program that
       * must be run to finalize the update process. See also |postinstall_path| and
       * |filesystem_type|.
       * </pre>
       *
       * <code>optional bool run_postinstall = 2;</code>
       * @param value The runPostinstall to set.
       * @return This builder for chaining.
       */
      public Builder setRunPostinstall(boolean value) {
        bitField0_ |= 0x00000002;
        runPostinstall_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Whether this partition carries a filesystem with post-install program that
       * must be run to finalize the update process. See also |postinstall_path| and
       * |filesystem_type|.
       * </pre>
       *
       * <code>optional bool run_postinstall = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearRunPostinstall() {
        bitField0_ = (bitField0_ & ~0x00000002);
        runPostinstall_ = false;
        onChanged();
        return this;
      }

      private java.lang.Object postinstallPath_ = "";
      /**
       * <pre>
       * The path of the executable program to run during the post-install step,
       * relative to the root of this filesystem. If not set, the default "postinst"
       * will be used. This setting is only used when |run_postinstall| is set and
       * true.
       * </pre>
       *
       * <code>optional string postinstall_path = 3;</code>
       * @return Whether the postinstallPath field is set.
       */
      public boolean hasPostinstallPath() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * The path of the executable program to run during the post-install step,
       * relative to the root of this filesystem. If not set, the default "postinst"
       * will be used. This setting is only used when |run_postinstall| is set and
       * true.
       * </pre>
       *
       * <code>optional string postinstall_path = 3;</code>
       * @return The postinstallPath.
       */
      public java.lang.String getPostinstallPath() {
        java.lang.Object ref = postinstallPath_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            postinstallPath_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The path of the executable program to run during the post-install step,
       * relative to the root of this filesystem. If not set, the default "postinst"
       * will be used. This setting is only used when |run_postinstall| is set and
       * true.
       * </pre>
       *
       * <code>optional string postinstall_path = 3;</code>
       * @return The bytes for postinstallPath.
       */
      public com.google.protobuf.ByteString
          getPostinstallPathBytes() {
        java.lang.Object ref = postinstallPath_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          postinstallPath_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The path of the executable program to run during the post-install step,
       * relative to the root of this filesystem. If not set, the default "postinst"
       * will be used. This setting is only used when |run_postinstall| is set and
       * true.
       * </pre>
       *
       * <code>optional string postinstall_path = 3;</code>
       * @param value The postinstallPath to set.
       * @return This builder for chaining.
       */
      public Builder setPostinstallPath(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        postinstallPath_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The path of the executable program to run during the post-install step,
       * relative to the root of this filesystem. If not set, the default "postinst"
       * will be used. This setting is only used when |run_postinstall| is set and
       * true.
       * </pre>
       *
       * <code>optional string postinstall_path = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearPostinstallPath() {
        bitField0_ = (bitField0_ & ~0x00000004);
        postinstallPath_ = getDefaultInstance().getPostinstallPath();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The path of the executable program to run during the post-install step,
       * relative to the root of this filesystem. If not set, the default "postinst"
       * will be used. This setting is only used when |run_postinstall| is set and
       * true.
       * </pre>
       *
       * <code>optional string postinstall_path = 3;</code>
       * @param value The bytes for postinstallPath to set.
       * @return This builder for chaining.
       */
      public Builder setPostinstallPathBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        postinstallPath_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object filesystemType_ = "";
      /**
       * <pre>
       * The filesystem type as passed to the mount(2) syscall when mounting the new
       * filesystem to run the post-install program. If not set, a fixed list of
       * filesystems will be attempted. This setting is only used if
       * |run_postinstall| is set and true.
       * </pre>
       *
       * <code>optional string filesystem_type = 4;</code>
       * @return Whether the filesystemType field is set.
       */
      public boolean hasFilesystemType() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * The filesystem type as passed to the mount(2) syscall when mounting the new
       * filesystem to run the post-install program. If not set, a fixed list of
       * filesystems will be attempted. This setting is only used if
       * |run_postinstall| is set and true.
       * </pre>
       *
       * <code>optional string filesystem_type = 4;</code>
       * @return The filesystemType.
       */
      public java.lang.String getFilesystemType() {
        java.lang.Object ref = filesystemType_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            filesystemType_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The filesystem type as passed to the mount(2) syscall when mounting the new
       * filesystem to run the post-install program. If not set, a fixed list of
       * filesystems will be attempted. This setting is only used if
       * |run_postinstall| is set and true.
       * </pre>
       *
       * <code>optional string filesystem_type = 4;</code>
       * @return The bytes for filesystemType.
       */
      public com.google.protobuf.ByteString
          getFilesystemTypeBytes() {
        java.lang.Object ref = filesystemType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          filesystemType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The filesystem type as passed to the mount(2) syscall when mounting the new
       * filesystem to run the post-install program. If not set, a fixed list of
       * filesystems will be attempted. This setting is only used if
       * |run_postinstall| is set and true.
       * </pre>
       *
       * <code>optional string filesystem_type = 4;</code>
       * @param value The filesystemType to set.
       * @return This builder for chaining.
       */
      public Builder setFilesystemType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        filesystemType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The filesystem type as passed to the mount(2) syscall when mounting the new
       * filesystem to run the post-install program. If not set, a fixed list of
       * filesystems will be attempted. This setting is only used if
       * |run_postinstall| is set and true.
       * </pre>
       *
       * <code>optional string filesystem_type = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearFilesystemType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        filesystemType_ = getDefaultInstance().getFilesystemType();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The filesystem type as passed to the mount(2) syscall when mounting the new
       * filesystem to run the post-install program. If not set, a fixed list of
       * filesystems will be attempted. This setting is only used if
       * |run_postinstall| is set and true.
       * </pre>
       *
       * <code>optional string filesystem_type = 4;</code>
       * @param value The bytes for filesystemType to set.
       * @return This builder for chaining.
       */
      public Builder setFilesystemTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        filesystemType_ = value;
        onChanged();
        return this;
      }

      private java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> newPartitionSignature_ =
        java.util.Collections.emptyList();
      private void ensureNewPartitionSignatureIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          newPartitionSignature_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.Signatures.Signature>(newPartitionSignature_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Signatures.Signature, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder, chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder> newPartitionSignatureBuilder_;

      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature> getNewPartitionSignatureList() {
        if (newPartitionSignatureBuilder_ == null) {
          return java.util.Collections.unmodifiableList(newPartitionSignature_);
        } else {
          return newPartitionSignatureBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public int getNewPartitionSignatureCount() {
        if (newPartitionSignatureBuilder_ == null) {
          return newPartitionSignature_.size();
        } else {
          return newPartitionSignatureBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature getNewPartitionSignature(int index) {
        if (newPartitionSignatureBuilder_ == null) {
          return newPartitionSignature_.get(index);
        } else {
          return newPartitionSignatureBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder setNewPartitionSignature(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature value) {
        if (newPartitionSignatureBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.set(index, value);
          onChanged();
        } else {
          newPartitionSignatureBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder setNewPartitionSignature(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder builderForValue) {
        if (newPartitionSignatureBuilder_ == null) {
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.set(index, builderForValue.build());
          onChanged();
        } else {
          newPartitionSignatureBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder addNewPartitionSignature(chromeos_update_engine.UpdateMetadata.Signatures.Signature value) {
        if (newPartitionSignatureBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.add(value);
          onChanged();
        } else {
          newPartitionSignatureBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder addNewPartitionSignature(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature value) {
        if (newPartitionSignatureBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.add(index, value);
          onChanged();
        } else {
          newPartitionSignatureBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder addNewPartitionSignature(
          chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder builderForValue) {
        if (newPartitionSignatureBuilder_ == null) {
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.add(builderForValue.build());
          onChanged();
        } else {
          newPartitionSignatureBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder addNewPartitionSignature(
          int index, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder builderForValue) {
        if (newPartitionSignatureBuilder_ == null) {
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.add(index, builderForValue.build());
          onChanged();
        } else {
          newPartitionSignatureBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder addAllNewPartitionSignature(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.Signatures.Signature> values) {
        if (newPartitionSignatureBuilder_ == null) {
          ensureNewPartitionSignatureIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, newPartitionSignature_);
          onChanged();
        } else {
          newPartitionSignatureBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder clearNewPartitionSignature() {
        if (newPartitionSignatureBuilder_ == null) {
          newPartitionSignature_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          newPartitionSignatureBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public Builder removeNewPartitionSignature(int index) {
        if (newPartitionSignatureBuilder_ == null) {
          ensureNewPartitionSignatureIsMutable();
          newPartitionSignature_.remove(index);
          onChanged();
        } else {
          newPartitionSignatureBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder getNewPartitionSignatureBuilder(
          int index) {
        return getNewPartitionSignatureFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder getNewPartitionSignatureOrBuilder(
          int index) {
        if (newPartitionSignatureBuilder_ == null) {
          return newPartitionSignature_.get(index);  } else {
          return newPartitionSignatureBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
           getNewPartitionSignatureOrBuilderList() {
        if (newPartitionSignatureBuilder_ != null) {
          return newPartitionSignatureBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(newPartitionSignature_);
        }
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder addNewPartitionSignatureBuilder() {
        return getNewPartitionSignatureFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.Signatures.Signature.getDefaultInstance());
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder addNewPartitionSignatureBuilder(
          int index) {
        return getNewPartitionSignatureFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.Signatures.Signature.getDefaultInstance());
      }
      /**
       * <pre>
       * If present, a list of signatures of the new_partition_info.hash signed with
       * different keys. If the update_engine daemon requires vendor-signed images
       * and has its public key installed, one of the signatures should be valid
       * for /postinstall to run.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.Signatures.Signature new_partition_signature = 5;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder>
           getNewPartitionSignatureBuilderList() {
        return getNewPartitionSignatureFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Signatures.Signature, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder, chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>
          getNewPartitionSignatureFieldBuilder() {
        if (newPartitionSignatureBuilder_ == null) {
          newPartitionSignatureBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Signatures.Signature, chromeos_update_engine.UpdateMetadata.Signatures.Signature.Builder, chromeos_update_engine.UpdateMetadata.Signatures.SignatureOrBuilder>(
                  newPartitionSignature_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          newPartitionSignature_ = null;
        }
        return newPartitionSignatureBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.PartitionInfo oldPartitionInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder> oldPartitionInfoBuilder_;
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       * @return Whether the oldPartitionInfo field is set.
       */
      public boolean hasOldPartitionInfo() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       * @return The oldPartitionInfo.
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getOldPartitionInfo() {
        if (oldPartitionInfoBuilder_ == null) {
          return oldPartitionInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldPartitionInfo_;
        } else {
          return oldPartitionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      public Builder setOldPartitionInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (oldPartitionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          oldPartitionInfo_ = value;
          onChanged();
        } else {
          oldPartitionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      public Builder setOldPartitionInfo(
          chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder builderForValue) {
        if (oldPartitionInfoBuilder_ == null) {
          oldPartitionInfo_ = builderForValue.build();
          onChanged();
        } else {
          oldPartitionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      public Builder mergeOldPartitionInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (oldPartitionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0) &&
              oldPartitionInfo_ != null &&
              oldPartitionInfo_ != chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) {
            oldPartitionInfo_ =
              chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder(oldPartitionInfo_).mergeFrom(value).buildPartial();
          } else {
            oldPartitionInfo_ = value;
          }
          onChanged();
        } else {
          oldPartitionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      public Builder clearOldPartitionInfo() {
        if (oldPartitionInfoBuilder_ == null) {
          oldPartitionInfo_ = null;
          onChanged();
        } else {
          oldPartitionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder getOldPartitionInfoBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getOldPartitionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldPartitionInfoOrBuilder() {
        if (oldPartitionInfoBuilder_ != null) {
          return oldPartitionInfoBuilder_.getMessageOrBuilder();
        } else {
          return oldPartitionInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldPartitionInfo_;
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_partition_info = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>
          getOldPartitionInfoFieldBuilder() {
        if (oldPartitionInfoBuilder_ == null) {
          oldPartitionInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>(
                  getOldPartitionInfo(),
                  getParentForChildren(),
                  isClean());
          oldPartitionInfo_ = null;
        }
        return oldPartitionInfoBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.PartitionInfo newPartitionInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder> newPartitionInfoBuilder_;
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       * @return Whether the newPartitionInfo field is set.
       */
      public boolean hasNewPartitionInfo() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       * @return The newPartitionInfo.
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getNewPartitionInfo() {
        if (newPartitionInfoBuilder_ == null) {
          return newPartitionInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newPartitionInfo_;
        } else {
          return newPartitionInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      public Builder setNewPartitionInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (newPartitionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          newPartitionInfo_ = value;
          onChanged();
        } else {
          newPartitionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      public Builder setNewPartitionInfo(
          chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder builderForValue) {
        if (newPartitionInfoBuilder_ == null) {
          newPartitionInfo_ = builderForValue.build();
          onChanged();
        } else {
          newPartitionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      public Builder mergeNewPartitionInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (newPartitionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000040) != 0) &&
              newPartitionInfo_ != null &&
              newPartitionInfo_ != chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) {
            newPartitionInfo_ =
              chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder(newPartitionInfo_).mergeFrom(value).buildPartial();
          } else {
            newPartitionInfo_ = value;
          }
          onChanged();
        } else {
          newPartitionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      public Builder clearNewPartitionInfo() {
        if (newPartitionInfoBuilder_ == null) {
          newPartitionInfo_ = null;
          onChanged();
        } else {
          newPartitionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder getNewPartitionInfoBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getNewPartitionInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewPartitionInfoOrBuilder() {
        if (newPartitionInfoBuilder_ != null) {
          return newPartitionInfoBuilder_.getMessageOrBuilder();
        } else {
          return newPartitionInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newPartitionInfo_;
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_partition_info = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>
          getNewPartitionInfoFieldBuilder() {
        if (newPartitionInfoBuilder_ == null) {
          newPartitionInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>(
                  getNewPartitionInfo(),
                  getParentForChildren(),
                  isClean());
          newPartitionInfo_ = null;
        }
        return newPartitionInfoBuilder_;
      }

      private java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> operations_ =
        java.util.Collections.emptyList();
      private void ensureOperationsIsMutable() {
        if (!((bitField0_ & 0x00000080) != 0)) {
          operations_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.InstallOperation>(operations_);
          bitField0_ |= 0x00000080;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder> operationsBuilder_;

      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> getOperationsList() {
        if (operationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(operations_);
        } else {
          return operationsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public int getOperationsCount() {
        if (operationsBuilder_ == null) {
          return operations_.size();
        } else {
          return operationsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation getOperations(int index) {
        if (operationsBuilder_ == null) {
          return operations_.get(index);
        } else {
          return operationsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder setOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (operationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOperationsIsMutable();
          operations_.set(index, value);
          onChanged();
        } else {
          operationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder setOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (operationsBuilder_ == null) {
          ensureOperationsIsMutable();
          operations_.set(index, builderForValue.build());
          onChanged();
        } else {
          operationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder addOperations(chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (operationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOperationsIsMutable();
          operations_.add(value);
          onChanged();
        } else {
          operationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder addOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (operationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOperationsIsMutable();
          operations_.add(index, value);
          onChanged();
        } else {
          operationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder addOperations(
          chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (operationsBuilder_ == null) {
          ensureOperationsIsMutable();
          operations_.add(builderForValue.build());
          onChanged();
        } else {
          operationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder addOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (operationsBuilder_ == null) {
          ensureOperationsIsMutable();
          operations_.add(index, builderForValue.build());
          onChanged();
        } else {
          operationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder addAllOperations(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.InstallOperation> values) {
        if (operationsBuilder_ == null) {
          ensureOperationsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, operations_);
          onChanged();
        } else {
          operationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder clearOperations() {
        if (operationsBuilder_ == null) {
          operations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
          onChanged();
        } else {
          operationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public Builder removeOperations(int index) {
        if (operationsBuilder_ == null) {
          ensureOperationsIsMutable();
          operations_.remove(index);
          onChanged();
        } else {
          operationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder getOperationsBuilder(
          int index) {
        return getOperationsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getOperationsOrBuilder(
          int index) {
        if (operationsBuilder_ == null) {
          return operations_.get(index);  } else {
          return operationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
           getOperationsOrBuilderList() {
        if (operationsBuilder_ != null) {
          return operationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(operations_);
        }
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder addOperationsBuilder() {
        return getOperationsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance());
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder addOperationsBuilder(
          int index) {
        return getOperationsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance());
      }
      /**
       * <pre>
       * The list of operations to be performed to apply this PartitionUpdate. The
       * associated operation blobs (in operations[i].data_offset, data_length)
       * should be stored contiguously and in the same order.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation operations = 8;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation.Builder>
           getOperationsBuilderList() {
        return getOperationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
          getOperationsFieldBuilder() {
        if (operationsBuilder_ == null) {
          operationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>(
                  operations_,
                  ((bitField0_ & 0x00000080) != 0),
                  getParentForChildren(),
                  isClean());
          operations_ = null;
        }
        return operationsBuilder_;
      }

      private boolean postinstallOptional_ ;
      /**
       * <pre>
       * Whether a failure in the postinstall step for this partition should be
       * ignored.
       * </pre>
       *
       * <code>optional bool postinstall_optional = 9;</code>
       * @return Whether the postinstallOptional field is set.
       */
      @java.lang.Override
      public boolean hasPostinstallOptional() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <pre>
       * Whether a failure in the postinstall step for this partition should be
       * ignored.
       * </pre>
       *
       * <code>optional bool postinstall_optional = 9;</code>
       * @return The postinstallOptional.
       */
      @java.lang.Override
      public boolean getPostinstallOptional() {
        return postinstallOptional_;
      }
      /**
       * <pre>
       * Whether a failure in the postinstall step for this partition should be
       * ignored.
       * </pre>
       *
       * <code>optional bool postinstall_optional = 9;</code>
       * @param value The postinstallOptional to set.
       * @return This builder for chaining.
       */
      public Builder setPostinstallOptional(boolean value) {
        bitField0_ |= 0x00000100;
        postinstallOptional_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Whether a failure in the postinstall step for this partition should be
       * ignored.
       * </pre>
       *
       * <code>optional bool postinstall_optional = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearPostinstallOptional() {
        bitField0_ = (bitField0_ & ~0x00000100);
        postinstallOptional_ = false;
        onChanged();
        return this;
      }

      private chromeos_update_engine.UpdateMetadata.Extent hashTreeDataExtent_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder> hashTreeDataExtentBuilder_;
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       * @return Whether the hashTreeDataExtent field is set.
       */
      public boolean hasHashTreeDataExtent() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       * @return The hashTreeDataExtent.
       */
      public chromeos_update_engine.UpdateMetadata.Extent getHashTreeDataExtent() {
        if (hashTreeDataExtentBuilder_ == null) {
          return hashTreeDataExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeDataExtent_;
        } else {
          return hashTreeDataExtentBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      public Builder setHashTreeDataExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (hashTreeDataExtentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          hashTreeDataExtent_ = value;
          onChanged();
        } else {
          hashTreeDataExtentBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      public Builder setHashTreeDataExtent(
          chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (hashTreeDataExtentBuilder_ == null) {
          hashTreeDataExtent_ = builderForValue.build();
          onChanged();
        } else {
          hashTreeDataExtentBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      public Builder mergeHashTreeDataExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (hashTreeDataExtentBuilder_ == null) {
          if (((bitField0_ & 0x00000200) != 0) &&
              hashTreeDataExtent_ != null &&
              hashTreeDataExtent_ != chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance()) {
            hashTreeDataExtent_ =
              chromeos_update_engine.UpdateMetadata.Extent.newBuilder(hashTreeDataExtent_).mergeFrom(value).buildPartial();
          } else {
            hashTreeDataExtent_ = value;
          }
          onChanged();
        } else {
          hashTreeDataExtentBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      public Builder clearHashTreeDataExtent() {
        if (hashTreeDataExtentBuilder_ == null) {
          hashTreeDataExtent_ = null;
          onChanged();
        } else {
          hashTreeDataExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder getHashTreeDataExtentBuilder() {
        bitField0_ |= 0x00000200;
        onChanged();
        return getHashTreeDataExtentFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getHashTreeDataExtentOrBuilder() {
        if (hashTreeDataExtentBuilder_ != null) {
          return hashTreeDataExtentBuilder_.getMessageOrBuilder();
        } else {
          return hashTreeDataExtent_ == null ?
              chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeDataExtent_;
        }
      }
      /**
       * <pre>
       * The extent for data covered by verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_data_extent = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
          getHashTreeDataExtentFieldBuilder() {
        if (hashTreeDataExtentBuilder_ == null) {
          hashTreeDataExtentBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>(
                  getHashTreeDataExtent(),
                  getParentForChildren(),
                  isClean());
          hashTreeDataExtent_ = null;
        }
        return hashTreeDataExtentBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.Extent hashTreeExtent_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder> hashTreeExtentBuilder_;
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       * @return Whether the hashTreeExtent field is set.
       */
      public boolean hasHashTreeExtent() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       * @return The hashTreeExtent.
       */
      public chromeos_update_engine.UpdateMetadata.Extent getHashTreeExtent() {
        if (hashTreeExtentBuilder_ == null) {
          return hashTreeExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeExtent_;
        } else {
          return hashTreeExtentBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      public Builder setHashTreeExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (hashTreeExtentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          hashTreeExtent_ = value;
          onChanged();
        } else {
          hashTreeExtentBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      public Builder setHashTreeExtent(
          chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (hashTreeExtentBuilder_ == null) {
          hashTreeExtent_ = builderForValue.build();
          onChanged();
        } else {
          hashTreeExtentBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      public Builder mergeHashTreeExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (hashTreeExtentBuilder_ == null) {
          if (((bitField0_ & 0x00000400) != 0) &&
              hashTreeExtent_ != null &&
              hashTreeExtent_ != chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance()) {
            hashTreeExtent_ =
              chromeos_update_engine.UpdateMetadata.Extent.newBuilder(hashTreeExtent_).mergeFrom(value).buildPartial();
          } else {
            hashTreeExtent_ = value;
          }
          onChanged();
        } else {
          hashTreeExtentBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      public Builder clearHashTreeExtent() {
        if (hashTreeExtentBuilder_ == null) {
          hashTreeExtent_ = null;
          onChanged();
        } else {
          hashTreeExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000400);
        return this;
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder getHashTreeExtentBuilder() {
        bitField0_ |= 0x00000400;
        onChanged();
        return getHashTreeExtentFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getHashTreeExtentOrBuilder() {
        if (hashTreeExtentBuilder_ != null) {
          return hashTreeExtentBuilder_.getMessageOrBuilder();
        } else {
          return hashTreeExtent_ == null ?
              chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : hashTreeExtent_;
        }
      }
      /**
       * <pre>
       * The extent to store verity hash tree.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent hash_tree_extent = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
          getHashTreeExtentFieldBuilder() {
        if (hashTreeExtentBuilder_ == null) {
          hashTreeExtentBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>(
                  getHashTreeExtent(),
                  getParentForChildren(),
                  isClean());
          hashTreeExtent_ = null;
        }
        return hashTreeExtentBuilder_;
      }

      private java.lang.Object hashTreeAlgorithm_ = "";
      /**
       * <pre>
       * The hash algorithm used in verity hash tree.
       * </pre>
       *
       * <code>optional string hash_tree_algorithm = 12;</code>
       * @return Whether the hashTreeAlgorithm field is set.
       */
      public boolean hasHashTreeAlgorithm() {
        return ((bitField0_ & 0x00000800) != 0);
      }
      /**
       * <pre>
       * The hash algorithm used in verity hash tree.
       * </pre>
       *
       * <code>optional string hash_tree_algorithm = 12;</code>
       * @return The hashTreeAlgorithm.
       */
      public java.lang.String getHashTreeAlgorithm() {
        java.lang.Object ref = hashTreeAlgorithm_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            hashTreeAlgorithm_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The hash algorithm used in verity hash tree.
       * </pre>
       *
       * <code>optional string hash_tree_algorithm = 12;</code>
       * @return The bytes for hashTreeAlgorithm.
       */
      public com.google.protobuf.ByteString
          getHashTreeAlgorithmBytes() {
        java.lang.Object ref = hashTreeAlgorithm_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          hashTreeAlgorithm_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The hash algorithm used in verity hash tree.
       * </pre>
       *
       * <code>optional string hash_tree_algorithm = 12;</code>
       * @param value The hashTreeAlgorithm to set.
       * @return This builder for chaining.
       */
      public Builder setHashTreeAlgorithm(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000800;
        hashTreeAlgorithm_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The hash algorithm used in verity hash tree.
       * </pre>
       *
       * <code>optional string hash_tree_algorithm = 12;</code>
       * @return This builder for chaining.
       */
      public Builder clearHashTreeAlgorithm() {
        bitField0_ = (bitField0_ & ~0x00000800);
        hashTreeAlgorithm_ = getDefaultInstance().getHashTreeAlgorithm();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The hash algorithm used in verity hash tree.
       * </pre>
       *
       * <code>optional string hash_tree_algorithm = 12;</code>
       * @param value The bytes for hashTreeAlgorithm to set.
       * @return This builder for chaining.
       */
      public Builder setHashTreeAlgorithmBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000800;
        hashTreeAlgorithm_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.ByteString hashTreeSalt_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * The salt used for verity hash tree.
       * </pre>
       *
       * <code>optional bytes hash_tree_salt = 13;</code>
       * @return Whether the hashTreeSalt field is set.
       */
      @java.lang.Override
      public boolean hasHashTreeSalt() {
        return ((bitField0_ & 0x00001000) != 0);
      }
      /**
       * <pre>
       * The salt used for verity hash tree.
       * </pre>
       *
       * <code>optional bytes hash_tree_salt = 13;</code>
       * @return The hashTreeSalt.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getHashTreeSalt() {
        return hashTreeSalt_;
      }
      /**
       * <pre>
       * The salt used for verity hash tree.
       * </pre>
       *
       * <code>optional bytes hash_tree_salt = 13;</code>
       * @param value The hashTreeSalt to set.
       * @return This builder for chaining.
       */
      public Builder setHashTreeSalt(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00001000;
        hashTreeSalt_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The salt used for verity hash tree.
       * </pre>
       *
       * <code>optional bytes hash_tree_salt = 13;</code>
       * @return This builder for chaining.
       */
      public Builder clearHashTreeSalt() {
        bitField0_ = (bitField0_ & ~0x00001000);
        hashTreeSalt_ = getDefaultInstance().getHashTreeSalt();
        onChanged();
        return this;
      }

      private chromeos_update_engine.UpdateMetadata.Extent fecDataExtent_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder> fecDataExtentBuilder_;
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       * @return Whether the fecDataExtent field is set.
       */
      public boolean hasFecDataExtent() {
        return ((bitField0_ & 0x00002000) != 0);
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       * @return The fecDataExtent.
       */
      public chromeos_update_engine.UpdateMetadata.Extent getFecDataExtent() {
        if (fecDataExtentBuilder_ == null) {
          return fecDataExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecDataExtent_;
        } else {
          return fecDataExtentBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      public Builder setFecDataExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (fecDataExtentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          fecDataExtent_ = value;
          onChanged();
        } else {
          fecDataExtentBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      public Builder setFecDataExtent(
          chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (fecDataExtentBuilder_ == null) {
          fecDataExtent_ = builderForValue.build();
          onChanged();
        } else {
          fecDataExtentBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      public Builder mergeFecDataExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (fecDataExtentBuilder_ == null) {
          if (((bitField0_ & 0x00002000) != 0) &&
              fecDataExtent_ != null &&
              fecDataExtent_ != chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance()) {
            fecDataExtent_ =
              chromeos_update_engine.UpdateMetadata.Extent.newBuilder(fecDataExtent_).mergeFrom(value).buildPartial();
          } else {
            fecDataExtent_ = value;
          }
          onChanged();
        } else {
          fecDataExtentBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      public Builder clearFecDataExtent() {
        if (fecDataExtentBuilder_ == null) {
          fecDataExtent_ = null;
          onChanged();
        } else {
          fecDataExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder getFecDataExtentBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getFecDataExtentFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getFecDataExtentOrBuilder() {
        if (fecDataExtentBuilder_ != null) {
          return fecDataExtentBuilder_.getMessageOrBuilder();
        } else {
          return fecDataExtent_ == null ?
              chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecDataExtent_;
        }
      }
      /**
       * <pre>
       * The extent for data covered by FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_data_extent = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
          getFecDataExtentFieldBuilder() {
        if (fecDataExtentBuilder_ == null) {
          fecDataExtentBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>(
                  getFecDataExtent(),
                  getParentForChildren(),
                  isClean());
          fecDataExtent_ = null;
        }
        return fecDataExtentBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.Extent fecExtent_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder> fecExtentBuilder_;
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       * @return Whether the fecExtent field is set.
       */
      public boolean hasFecExtent() {
        return ((bitField0_ & 0x00004000) != 0);
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       * @return The fecExtent.
       */
      public chromeos_update_engine.UpdateMetadata.Extent getFecExtent() {
        if (fecExtentBuilder_ == null) {
          return fecExtent_ == null ? chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecExtent_;
        } else {
          return fecExtentBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      public Builder setFecExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (fecExtentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          fecExtent_ = value;
          onChanged();
        } else {
          fecExtentBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      public Builder setFecExtent(
          chromeos_update_engine.UpdateMetadata.Extent.Builder builderForValue) {
        if (fecExtentBuilder_ == null) {
          fecExtent_ = builderForValue.build();
          onChanged();
        } else {
          fecExtentBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      public Builder mergeFecExtent(chromeos_update_engine.UpdateMetadata.Extent value) {
        if (fecExtentBuilder_ == null) {
          if (((bitField0_ & 0x00004000) != 0) &&
              fecExtent_ != null &&
              fecExtent_ != chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance()) {
            fecExtent_ =
              chromeos_update_engine.UpdateMetadata.Extent.newBuilder(fecExtent_).mergeFrom(value).buildPartial();
          } else {
            fecExtent_ = value;
          }
          onChanged();
        } else {
          fecExtentBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      public Builder clearFecExtent() {
        if (fecExtentBuilder_ == null) {
          fecExtent_ = null;
          onChanged();
        } else {
          fecExtentBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      public chromeos_update_engine.UpdateMetadata.Extent.Builder getFecExtentBuilder() {
        bitField0_ |= 0x00004000;
        onChanged();
        return getFecExtentFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ExtentOrBuilder getFecExtentOrBuilder() {
        if (fecExtentBuilder_ != null) {
          return fecExtentBuilder_.getMessageOrBuilder();
        } else {
          return fecExtent_ == null ?
              chromeos_update_engine.UpdateMetadata.Extent.getDefaultInstance() : fecExtent_;
        }
      }
      /**
       * <pre>
       * The extent to store FEC.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.Extent fec_extent = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>
          getFecExtentFieldBuilder() {
        if (fecExtentBuilder_ == null) {
          fecExtentBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.Extent, chromeos_update_engine.UpdateMetadata.Extent.Builder, chromeos_update_engine.UpdateMetadata.ExtentOrBuilder>(
                  getFecExtent(),
                  getParentForChildren(),
                  isClean());
          fecExtent_ = null;
        }
        return fecExtentBuilder_;
      }

      private int fecRoots_ = 2;
      /**
       * <pre>
       * The number of FEC roots.
       * </pre>
       *
       * <code>optional uint32 fec_roots = 16 [default = 2];</code>
       * @return Whether the fecRoots field is set.
       */
      @java.lang.Override
      public boolean hasFecRoots() {
        return ((bitField0_ & 0x00008000) != 0);
      }
      /**
       * <pre>
       * The number of FEC roots.
       * </pre>
       *
       * <code>optional uint32 fec_roots = 16 [default = 2];</code>
       * @return The fecRoots.
       */
      @java.lang.Override
      public int getFecRoots() {
        return fecRoots_;
      }
      /**
       * <pre>
       * The number of FEC roots.
       * </pre>
       *
       * <code>optional uint32 fec_roots = 16 [default = 2];</code>
       * @param value The fecRoots to set.
       * @return This builder for chaining.
       */
      public Builder setFecRoots(int value) {
        bitField0_ |= 0x00008000;
        fecRoots_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The number of FEC roots.
       * </pre>
       *
       * <code>optional uint32 fec_roots = 16 [default = 2];</code>
       * @return This builder for chaining.
       */
      public Builder clearFecRoots() {
        bitField0_ = (bitField0_ & ~0x00008000);
        fecRoots_ = 2;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.PartitionUpdate)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.PartitionUpdate)
    private static final chromeos_update_engine.UpdateMetadata.PartitionUpdate DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.PartitionUpdate();
    }

    public static chromeos_update_engine.UpdateMetadata.PartitionUpdate getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PartitionUpdate>
        PARSER = new com.google.protobuf.AbstractParser<PartitionUpdate>() {
      @java.lang.Override
      public PartitionUpdate parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PartitionUpdate(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PartitionUpdate> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PartitionUpdate> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionUpdate getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DynamicPartitionGroupOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.DynamicPartitionGroup)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the group.
     * </pre>
     *
     * <code>required string name = 1;</code>
     * @return Whether the name field is set.
     */
    boolean hasName();
    /**
     * <pre>
     * Name of the group.
     * </pre>
     *
     * <code>required string name = 1;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the group.
     * </pre>
     *
     * <code>required string name = 1;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * Maximum size of the group. The sum of sizes of all partitions in the group
     * must not exceed the maximum size of the group.
     * </pre>
     *
     * <code>optional uint64 size = 2;</code>
     * @return Whether the size field is set.
     */
    boolean hasSize();
    /**
     * <pre>
     * Maximum size of the group. The sum of sizes of all partitions in the group
     * must not exceed the maximum size of the group.
     * </pre>
     *
     * <code>optional uint64 size = 2;</code>
     * @return The size.
     */
    long getSize();

    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @return A list containing the partitionNames.
     */
    java.util.List<java.lang.String>
        getPartitionNamesList();
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @return The count of partitionNames.
     */
    int getPartitionNamesCount();
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @param index The index of the element to return.
     * @return The partitionNames at the given index.
     */
    java.lang.String getPartitionNames(int index);
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the partitionNames at the given index.
     */
    com.google.protobuf.ByteString
        getPartitionNamesBytes(int index);
  }
  /**
   * Protobuf type {@code chromeos_update_engine.DynamicPartitionGroup}
   */
  public static final class DynamicPartitionGroup extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.DynamicPartitionGroup)
      DynamicPartitionGroupOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DynamicPartitionGroup.newBuilder() to construct.
    private DynamicPartitionGroup(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DynamicPartitionGroup() {
      name_ = "";
      partitionNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DynamicPartitionGroup();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DynamicPartitionGroup(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              name_ = bs;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              size_ = input.readUInt64();
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                partitionNames_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000004;
              }
              partitionNames_.add(bs);
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          partitionNames_ = partitionNames_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionGroup_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionGroup_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.class, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder.class);
    }

    private int bitField0_;
    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the group.
     * </pre>
     *
     * <code>required string name = 1;</code>
     * @return Whether the name field is set.
     */
    @java.lang.Override
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * Name of the group.
     * </pre>
     *
     * <code>required string name = 1;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <pre>
     * Name of the group.
     * </pre>
     *
     * <code>required string name = 1;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SIZE_FIELD_NUMBER = 2;
    private long size_;
    /**
     * <pre>
     * Maximum size of the group. The sum of sizes of all partitions in the group
     * must not exceed the maximum size of the group.
     * </pre>
     *
     * <code>optional uint64 size = 2;</code>
     * @return Whether the size field is set.
     */
    @java.lang.Override
    public boolean hasSize() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * Maximum size of the group. The sum of sizes of all partitions in the group
     * must not exceed the maximum size of the group.
     * </pre>
     *
     * <code>optional uint64 size = 2;</code>
     * @return The size.
     */
    @java.lang.Override
    public long getSize() {
      return size_;
    }

    public static final int PARTITION_NAMES_FIELD_NUMBER = 3;
    private com.google.protobuf.LazyStringList partitionNames_;
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @return A list containing the partitionNames.
     */
    public com.google.protobuf.ProtocolStringList
        getPartitionNamesList() {
      return partitionNames_;
    }
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @return The count of partitionNames.
     */
    public int getPartitionNamesCount() {
      return partitionNames_.size();
    }
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @param index The index of the element to return.
     * @return The partitionNames at the given index.
     */
    public java.lang.String getPartitionNames(int index) {
      return partitionNames_.get(index);
    }
    /**
     * <pre>
     * A list of partitions that belong to the group.
     * </pre>
     *
     * <code>repeated string partition_names = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the partitionNames at the given index.
     */
    public com.google.protobuf.ByteString
        getPartitionNamesBytes(int index) {
      return partitionNames_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt64(2, size_);
      }
      for (int i = 0; i < partitionNames_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, partitionNames_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, size_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < partitionNames_.size(); i++) {
          dataSize += computeStringSizeNoTag(partitionNames_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getPartitionNamesList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup other = (chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup) obj;

      if (hasName() != other.hasName()) return false;
      if (hasName()) {
        if (!getName()
            .equals(other.getName())) return false;
      }
      if (hasSize() != other.hasSize()) return false;
      if (hasSize()) {
        if (getSize()
            != other.getSize()) return false;
      }
      if (!getPartitionNamesList()
          .equals(other.getPartitionNamesList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasSize()) {
        hash = (37 * hash) + SIZE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSize());
      }
      if (getPartitionNamesCount() > 0) {
        hash = (37 * hash) + PARTITION_NAMES_FIELD_NUMBER;
        hash = (53 * hash) + getPartitionNamesList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code chromeos_update_engine.DynamicPartitionGroup}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.DynamicPartitionGroup)
        chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionGroup_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionGroup_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.class, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        size_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        partitionNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionGroup_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup build() {
        chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup buildPartial() {
        chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup result = new chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.size_ = size_;
          to_bitField0_ |= 0x00000002;
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          partitionNames_ = partitionNames_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.partitionNames_ = partitionNames_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup other) {
        if (other == chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasSize()) {
          setSize(other.getSize());
        }
        if (!other.partitionNames_.isEmpty()) {
          if (partitionNames_.isEmpty()) {
            partitionNames_ = other.partitionNames_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensurePartitionNamesIsMutable();
            partitionNames_.addAll(other.partitionNames_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasName()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the group.
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return Whether the name field is set.
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Name of the group.
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            name_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the group.
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the group.
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the group.
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the group.
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      private long size_ ;
      /**
       * <pre>
       * Maximum size of the group. The sum of sizes of all partitions in the group
       * must not exceed the maximum size of the group.
       * </pre>
       *
       * <code>optional uint64 size = 2;</code>
       * @return Whether the size field is set.
       */
      @java.lang.Override
      public boolean hasSize() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Maximum size of the group. The sum of sizes of all partitions in the group
       * must not exceed the maximum size of the group.
       * </pre>
       *
       * <code>optional uint64 size = 2;</code>
       * @return The size.
       */
      @java.lang.Override
      public long getSize() {
        return size_;
      }
      /**
       * <pre>
       * Maximum size of the group. The sum of sizes of all partitions in the group
       * must not exceed the maximum size of the group.
       * </pre>
       *
       * <code>optional uint64 size = 2;</code>
       * @param value The size to set.
       * @return This builder for chaining.
       */
      public Builder setSize(long value) {
        bitField0_ |= 0x00000002;
        size_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Maximum size of the group. The sum of sizes of all partitions in the group
       * must not exceed the maximum size of the group.
       * </pre>
       *
       * <code>optional uint64 size = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearSize() {
        bitField0_ = (bitField0_ & ~0x00000002);
        size_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList partitionNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensurePartitionNamesIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          partitionNames_ = new com.google.protobuf.LazyStringArrayList(partitionNames_);
          bitField0_ |= 0x00000004;
         }
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @return A list containing the partitionNames.
       */
      public com.google.protobuf.ProtocolStringList
          getPartitionNamesList() {
        return partitionNames_.getUnmodifiableView();
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @return The count of partitionNames.
       */
      public int getPartitionNamesCount() {
        return partitionNames_.size();
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @param index The index of the element to return.
       * @return The partitionNames at the given index.
       */
      public java.lang.String getPartitionNames(int index) {
        return partitionNames_.get(index);
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @param index The index of the value to return.
       * @return The bytes of the partitionNames at the given index.
       */
      public com.google.protobuf.ByteString
          getPartitionNamesBytes(int index) {
        return partitionNames_.getByteString(index);
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @param index The index to set the value at.
       * @param value The partitionNames to set.
       * @return This builder for chaining.
       */
      public Builder setPartitionNames(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePartitionNamesIsMutable();
        partitionNames_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @param value The partitionNames to add.
       * @return This builder for chaining.
       */
      public Builder addPartitionNames(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePartitionNamesIsMutable();
        partitionNames_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @param values The partitionNames to add.
       * @return This builder for chaining.
       */
      public Builder addAllPartitionNames(
          java.lang.Iterable<java.lang.String> values) {
        ensurePartitionNamesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, partitionNames_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearPartitionNames() {
        partitionNames_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of partitions that belong to the group.
       * </pre>
       *
       * <code>repeated string partition_names = 3;</code>
       * @param value The bytes of the partitionNames to add.
       * @return This builder for chaining.
       */
      public Builder addPartitionNamesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePartitionNamesIsMutable();
        partitionNames_.add(value);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.DynamicPartitionGroup)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.DynamicPartitionGroup)
    private static final chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup();
    }

    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DynamicPartitionGroup>
        PARSER = new com.google.protobuf.AbstractParser<DynamicPartitionGroup>() {
      @java.lang.Override
      public DynamicPartitionGroup parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DynamicPartitionGroup(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DynamicPartitionGroup> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DynamicPartitionGroup> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DynamicPartitionMetadataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.DynamicPartitionMetadata)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup>
        getGroupsList();
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup getGroups(int index);
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    int getGroupsCount();
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder>
        getGroupsOrBuilderList();
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder getGroupsOrBuilder(
        int index);

    /**
     * <pre>
     * Whether dynamic partitions have snapshots during the update. If this is
     * set to true, the update_engine daemon creates snapshots for all dynamic
     * partitions if possible. If this is unset, the update_engine daemon MUST
     * NOT create snapshots for dynamic partitions.
     * </pre>
     *
     * <code>optional bool snapshot_enabled = 2;</code>
     * @return Whether the snapshotEnabled field is set.
     */
    boolean hasSnapshotEnabled();
    /**
     * <pre>
     * Whether dynamic partitions have snapshots during the update. If this is
     * set to true, the update_engine daemon creates snapshots for all dynamic
     * partitions if possible. If this is unset, the update_engine daemon MUST
     * NOT create snapshots for dynamic partitions.
     * </pre>
     *
     * <code>optional bool snapshot_enabled = 2;</code>
     * @return The snapshotEnabled.
     */
    boolean getSnapshotEnabled();
  }
  /**
   * <pre>
   * Metadata related to all dynamic partitions.
   * </pre>
   *
   * Protobuf type {@code chromeos_update_engine.DynamicPartitionMetadata}
   */
  public static final class DynamicPartitionMetadata extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.DynamicPartitionMetadata)
      DynamicPartitionMetadataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DynamicPartitionMetadata.newBuilder() to construct.
    private DynamicPartitionMetadata(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DynamicPartitionMetadata() {
      groups_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DynamicPartitionMetadata();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DynamicPartitionMetadata(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                groups_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup>();
                mutable_bitField0_ |= 0x00000001;
              }
              groups_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              bitField0_ |= 0x00000001;
              snapshotEnabled_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          groups_ = java.util.Collections.unmodifiableList(groups_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionMetadata_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionMetadata_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.class, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder.class);
    }

    private int bitField0_;
    public static final int GROUPS_FIELD_NUMBER = 1;
    private java.util.List<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup> groups_;
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup> getGroupsList() {
      return groups_;
    }
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder>
        getGroupsOrBuilderList() {
      return groups_;
    }
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    @java.lang.Override
    public int getGroupsCount() {
      return groups_.size();
    }
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup getGroups(int index) {
      return groups_.get(index);
    }
    /**
     * <pre>
     * All updatable groups present in |partitions| of this DeltaArchiveManifest.
     * - If an updatable group is on the device but not in the manifest, it is
     *   not updated. Hence, the group will not be resized, and partitions cannot
     *   be added to or removed from the group.
     * - If an updatable group is in the manifest but not on the device, the group
     *   is added to the device.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder getGroupsOrBuilder(
        int index) {
      return groups_.get(index);
    }

    public static final int SNAPSHOT_ENABLED_FIELD_NUMBER = 2;
    private boolean snapshotEnabled_;
    /**
     * <pre>
     * Whether dynamic partitions have snapshots during the update. If this is
     * set to true, the update_engine daemon creates snapshots for all dynamic
     * partitions if possible. If this is unset, the update_engine daemon MUST
     * NOT create snapshots for dynamic partitions.
     * </pre>
     *
     * <code>optional bool snapshot_enabled = 2;</code>
     * @return Whether the snapshotEnabled field is set.
     */
    @java.lang.Override
    public boolean hasSnapshotEnabled() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * Whether dynamic partitions have snapshots during the update. If this is
     * set to true, the update_engine daemon creates snapshots for all dynamic
     * partitions if possible. If this is unset, the update_engine daemon MUST
     * NOT create snapshots for dynamic partitions.
     * </pre>
     *
     * <code>optional bool snapshot_enabled = 2;</code>
     * @return The snapshotEnabled.
     */
    @java.lang.Override
    public boolean getSnapshotEnabled() {
      return snapshotEnabled_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getGroupsCount(); i++) {
        if (!getGroups(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < groups_.size(); i++) {
        output.writeMessage(1, groups_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(2, snapshotEnabled_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < groups_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, groups_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, snapshotEnabled_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata other = (chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata) obj;

      if (!getGroupsList()
          .equals(other.getGroupsList())) return false;
      if (hasSnapshotEnabled() != other.hasSnapshotEnabled()) return false;
      if (hasSnapshotEnabled()) {
        if (getSnapshotEnabled()
            != other.getSnapshotEnabled()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getGroupsCount() > 0) {
        hash = (37 * hash) + GROUPS_FIELD_NUMBER;
        hash = (53 * hash) + getGroupsList().hashCode();
      }
      if (hasSnapshotEnabled()) {
        hash = (37 * hash) + SNAPSHOT_ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getSnapshotEnabled());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * Protobuf type {@code chromeos_update_engine.DynamicPartitionMetadata}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.DynamicPartitionMetadata)
        chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionMetadata_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionMetadata_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.class, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getGroupsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (groupsBuilder_ == null) {
          groups_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          groupsBuilder_.clear();
        }
        snapshotEnabled_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DynamicPartitionMetadata_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata build() {
        chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata buildPartial() {
        chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata result = new chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (groupsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            groups_ = java.util.Collections.unmodifiableList(groups_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.groups_ = groups_;
        } else {
          result.groups_ = groupsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.snapshotEnabled_ = snapshotEnabled_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata other) {
        if (other == chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance()) return this;
        if (groupsBuilder_ == null) {
          if (!other.groups_.isEmpty()) {
            if (groups_.isEmpty()) {
              groups_ = other.groups_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureGroupsIsMutable();
              groups_.addAll(other.groups_);
            }
            onChanged();
          }
        } else {
          if (!other.groups_.isEmpty()) {
            if (groupsBuilder_.isEmpty()) {
              groupsBuilder_.dispose();
              groupsBuilder_ = null;
              groups_ = other.groups_;
              bitField0_ = (bitField0_ & ~0x00000001);
              groupsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getGroupsFieldBuilder() : null;
            } else {
              groupsBuilder_.addAllMessages(other.groups_);
            }
          }
        }
        if (other.hasSnapshotEnabled()) {
          setSnapshotEnabled(other.getSnapshotEnabled());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getGroupsCount(); i++) {
          if (!getGroups(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup> groups_ =
        java.util.Collections.emptyList();
      private void ensureGroupsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          groups_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup>(groups_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder> groupsBuilder_;

      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup> getGroupsList() {
        if (groupsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(groups_);
        } else {
          return groupsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public int getGroupsCount() {
        if (groupsBuilder_ == null) {
          return groups_.size();
        } else {
          return groupsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup getGroups(int index) {
        if (groupsBuilder_ == null) {
          return groups_.get(index);
        } else {
          return groupsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder setGroups(
          int index, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup value) {
        if (groupsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureGroupsIsMutable();
          groups_.set(index, value);
          onChanged();
        } else {
          groupsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder setGroups(
          int index, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder builderForValue) {
        if (groupsBuilder_ == null) {
          ensureGroupsIsMutable();
          groups_.set(index, builderForValue.build());
          onChanged();
        } else {
          groupsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder addGroups(chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup value) {
        if (groupsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureGroupsIsMutable();
          groups_.add(value);
          onChanged();
        } else {
          groupsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder addGroups(
          int index, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup value) {
        if (groupsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureGroupsIsMutable();
          groups_.add(index, value);
          onChanged();
        } else {
          groupsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder addGroups(
          chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder builderForValue) {
        if (groupsBuilder_ == null) {
          ensureGroupsIsMutable();
          groups_.add(builderForValue.build());
          onChanged();
        } else {
          groupsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder addGroups(
          int index, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder builderForValue) {
        if (groupsBuilder_ == null) {
          ensureGroupsIsMutable();
          groups_.add(index, builderForValue.build());
          onChanged();
        } else {
          groupsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder addAllGroups(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup> values) {
        if (groupsBuilder_ == null) {
          ensureGroupsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, groups_);
          onChanged();
        } else {
          groupsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder clearGroups() {
        if (groupsBuilder_ == null) {
          groups_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          groupsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public Builder removeGroups(int index) {
        if (groupsBuilder_ == null) {
          ensureGroupsIsMutable();
          groups_.remove(index);
          onChanged();
        } else {
          groupsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder getGroupsBuilder(
          int index) {
        return getGroupsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder getGroupsOrBuilder(
          int index) {
        if (groupsBuilder_ == null) {
          return groups_.get(index);  } else {
          return groupsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder>
           getGroupsOrBuilderList() {
        if (groupsBuilder_ != null) {
          return groupsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(groups_);
        }
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder addGroupsBuilder() {
        return getGroupsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.getDefaultInstance());
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder addGroupsBuilder(
          int index) {
        return getGroupsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.getDefaultInstance());
      }
      /**
       * <pre>
       * All updatable groups present in |partitions| of this DeltaArchiveManifest.
       * - If an updatable group is on the device but not in the manifest, it is
       *   not updated. Hence, the group will not be resized, and partitions cannot
       *   be added to or removed from the group.
       * - If an updatable group is in the manifest but not on the device, the group
       *   is added to the device.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.DynamicPartitionGroup groups = 1;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder>
           getGroupsBuilderList() {
        return getGroupsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder>
          getGroupsFieldBuilder() {
        if (groupsBuilder_ == null) {
          groupsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroup.Builder, chromeos_update_engine.UpdateMetadata.DynamicPartitionGroupOrBuilder>(
                  groups_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          groups_ = null;
        }
        return groupsBuilder_;
      }

      private boolean snapshotEnabled_ ;
      /**
       * <pre>
       * Whether dynamic partitions have snapshots during the update. If this is
       * set to true, the update_engine daemon creates snapshots for all dynamic
       * partitions if possible. If this is unset, the update_engine daemon MUST
       * NOT create snapshots for dynamic partitions.
       * </pre>
       *
       * <code>optional bool snapshot_enabled = 2;</code>
       * @return Whether the snapshotEnabled field is set.
       */
      @java.lang.Override
      public boolean hasSnapshotEnabled() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * Whether dynamic partitions have snapshots during the update. If this is
       * set to true, the update_engine daemon creates snapshots for all dynamic
       * partitions if possible. If this is unset, the update_engine daemon MUST
       * NOT create snapshots for dynamic partitions.
       * </pre>
       *
       * <code>optional bool snapshot_enabled = 2;</code>
       * @return The snapshotEnabled.
       */
      @java.lang.Override
      public boolean getSnapshotEnabled() {
        return snapshotEnabled_;
      }
      /**
       * <pre>
       * Whether dynamic partitions have snapshots during the update. If this is
       * set to true, the update_engine daemon creates snapshots for all dynamic
       * partitions if possible. If this is unset, the update_engine daemon MUST
       * NOT create snapshots for dynamic partitions.
       * </pre>
       *
       * <code>optional bool snapshot_enabled = 2;</code>
       * @param value The snapshotEnabled to set.
       * @return This builder for chaining.
       */
      public Builder setSnapshotEnabled(boolean value) {
        bitField0_ |= 0x00000002;
        snapshotEnabled_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Whether dynamic partitions have snapshots during the update. If this is
       * set to true, the update_engine daemon creates snapshots for all dynamic
       * partitions if possible. If this is unset, the update_engine daemon MUST
       * NOT create snapshots for dynamic partitions.
       * </pre>
       *
       * <code>optional bool snapshot_enabled = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearSnapshotEnabled() {
        bitField0_ = (bitField0_ & ~0x00000002);
        snapshotEnabled_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.DynamicPartitionMetadata)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.DynamicPartitionMetadata)
    private static final chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata();
    }

    public static chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DynamicPartitionMetadata>
        PARSER = new com.google.protobuf.AbstractParser<DynamicPartitionMetadata>() {
      @java.lang.Override
      public DynamicPartitionMetadata parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DynamicPartitionMetadata(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DynamicPartitionMetadata> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DynamicPartitionMetadata> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeltaArchiveManifestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:chromeos_update_engine.DeltaArchiveManifest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation>
        getInstallOperationsList();
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    chromeos_update_engine.UpdateMetadata.InstallOperation getInstallOperations(int index);
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    int getInstallOperationsCount();
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
        getInstallOperationsOrBuilderList();
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getInstallOperationsOrBuilder(
        int index);

    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation>
        getKernelInstallOperationsList();
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    chromeos_update_engine.UpdateMetadata.InstallOperation getKernelInstallOperations(int index);
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    int getKernelInstallOperationsCount();
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
        getKernelInstallOperationsOrBuilderList();
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getKernelInstallOperationsOrBuilder(
        int index);

    /**
     * <pre>
     * (At time of writing) usually 4096
     * </pre>
     *
     * <code>optional uint32 block_size = 3 [default = 4096];</code>
     * @return Whether the blockSize field is set.
     */
    boolean hasBlockSize();
    /**
     * <pre>
     * (At time of writing) usually 4096
     * </pre>
     *
     * <code>optional uint32 block_size = 3 [default = 4096];</code>
     * @return The blockSize.
     */
    int getBlockSize();

    /**
     * <pre>
     * If signatures are present, the offset into the blobs, generally
     * tacked onto the end of the file, and the length. We use an offset
     * rather than a bool to allow for more flexibility in future file formats.
     * If either is absent, it means signatures aren't supported in this
     * file.
     * </pre>
     *
     * <code>optional uint64 signatures_offset = 4;</code>
     * @return Whether the signaturesOffset field is set.
     */
    boolean hasSignaturesOffset();
    /**
     * <pre>
     * If signatures are present, the offset into the blobs, generally
     * tacked onto the end of the file, and the length. We use an offset
     * rather than a bool to allow for more flexibility in future file formats.
     * If either is absent, it means signatures aren't supported in this
     * file.
     * </pre>
     *
     * <code>optional uint64 signatures_offset = 4;</code>
     * @return The signaturesOffset.
     */
    long getSignaturesOffset();

    /**
     * <code>optional uint64 signatures_size = 5;</code>
     * @return Whether the signaturesSize field is set.
     */
    boolean hasSignaturesSize();
    /**
     * <code>optional uint64 signatures_size = 5;</code>
     * @return The signaturesSize.
     */
    long getSignaturesSize();

    /**
     * <pre>
     * Only present in major version = 1. Partition metadata used to validate the
     * update. For major version = 2 see the |partitions| field.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
     * @return Whether the oldKernelInfo field is set.
     */
    boolean hasOldKernelInfo();
    /**
     * <pre>
     * Only present in major version = 1. Partition metadata used to validate the
     * update. For major version = 2 see the |partitions| field.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
     * @return The oldKernelInfo.
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfo getOldKernelInfo();
    /**
     * <pre>
     * Only present in major version = 1. Partition metadata used to validate the
     * update. For major version = 2 see the |partitions| field.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldKernelInfoOrBuilder();

    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
     * @return Whether the newKernelInfo field is set.
     */
    boolean hasNewKernelInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
     * @return The newKernelInfo.
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfo getNewKernelInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewKernelInfoOrBuilder();

    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
     * @return Whether the oldRootfsInfo field is set.
     */
    boolean hasOldRootfsInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
     * @return The oldRootfsInfo.
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfo getOldRootfsInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldRootfsInfoOrBuilder();

    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
     * @return Whether the newRootfsInfo field is set.
     */
    boolean hasNewRootfsInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
     * @return The newRootfsInfo.
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfo getNewRootfsInfo();
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewRootfsInfoOrBuilder();

    /**
     * <pre>
     * old_image_info will only be present for delta images.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
     * @return Whether the oldImageInfo field is set.
     */
    boolean hasOldImageInfo();
    /**
     * <pre>
     * old_image_info will only be present for delta images.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
     * @return The oldImageInfo.
     */
    chromeos_update_engine.UpdateMetadata.ImageInfo getOldImageInfo();
    /**
     * <pre>
     * old_image_info will only be present for delta images.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
     */
    chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder getOldImageInfoOrBuilder();

    /**
     * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
     * @return Whether the newImageInfo field is set.
     */
    boolean hasNewImageInfo();
    /**
     * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
     * @return The newImageInfo.
     */
    chromeos_update_engine.UpdateMetadata.ImageInfo getNewImageInfo();
    /**
     * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
     */
    chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder getNewImageInfoOrBuilder();

    /**
     * <pre>
     * The minor version, also referred as "delta version", of the payload.
     * Minor version 0 is full payload, everything else is delta payload.
     * </pre>
     *
     * <code>optional uint32 minor_version = 12 [default = 0];</code>
     * @return Whether the minorVersion field is set.
     */
    boolean hasMinorVersion();
    /**
     * <pre>
     * The minor version, also referred as "delta version", of the payload.
     * Minor version 0 is full payload, everything else is delta payload.
     * </pre>
     *
     * <code>optional uint32 minor_version = 12 [default = 0];</code>
     * @return The minorVersion.
     */
    int getMinorVersion();

    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    java.util.List<chromeos_update_engine.UpdateMetadata.PartitionUpdate>
        getPartitionsList();
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionUpdate getPartitions(int index);
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    int getPartitionsCount();
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    java.util.List<? extends chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder>
        getPartitionsOrBuilderList();
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder getPartitionsOrBuilder(
        int index);

    /**
     * <pre>
     * The maximum timestamp of the OS allowed to apply this payload.
     * Can be used to prevent downgrading the OS.
     * </pre>
     *
     * <code>optional int64 max_timestamp = 14;</code>
     * @return Whether the maxTimestamp field is set.
     */
    boolean hasMaxTimestamp();
    /**
     * <pre>
     * The maximum timestamp of the OS allowed to apply this payload.
     * Can be used to prevent downgrading the OS.
     * </pre>
     *
     * <code>optional int64 max_timestamp = 14;</code>
     * @return The maxTimestamp.
     */
    long getMaxTimestamp();

    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
     * @return Whether the dynamicPartitionMetadata field is set.
     */
    boolean hasDynamicPartitionMetadata();
    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
     * @return The dynamicPartitionMetadata.
     */
    chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata getDynamicPartitionMetadata();
    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
     */
    chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder getDynamicPartitionMetadataOrBuilder();

    /**
     * <pre>
     * If the payload only updates a subset of partitions on the device.
     * </pre>
     *
     * <code>optional bool partial_update = 16;</code>
     * @return Whether the partialUpdate field is set.
     */
    boolean hasPartialUpdate();
    /**
     * <pre>
     * If the payload only updates a subset of partitions on the device.
     * </pre>
     *
     * <code>optional bool partial_update = 16;</code>
     * @return The partialUpdate.
     */
    boolean getPartialUpdate();
  }
  /**
   * Protobuf type {@code chromeos_update_engine.DeltaArchiveManifest}
   */
  public static final class DeltaArchiveManifest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:chromeos_update_engine.DeltaArchiveManifest)
      DeltaArchiveManifestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeltaArchiveManifest.newBuilder() to construct.
    private DeltaArchiveManifest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeltaArchiveManifest() {
      installOperations_ = java.util.Collections.emptyList();
      kernelInstallOperations_ = java.util.Collections.emptyList();
      blockSize_ = 4096;
      partitions_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DeltaArchiveManifest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DeltaArchiveManifest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                installOperations_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.InstallOperation>();
                mutable_bitField0_ |= 0x00000001;
              }
              installOperations_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.InstallOperation.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                kernelInstallOperations_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.InstallOperation>();
                mutable_bitField0_ |= 0x00000002;
              }
              kernelInstallOperations_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.InstallOperation.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000001;
              blockSize_ = input.readUInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000002;
              signaturesOffset_ = input.readUInt64();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000004;
              signaturesSize_ = input.readUInt64();
              break;
            }
            case 50: {
              chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) != 0)) {
                subBuilder = oldKernelInfo_.toBuilder();
              }
              oldKernelInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(oldKernelInfo_);
                oldKernelInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 58: {
              chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) != 0)) {
                subBuilder = newKernelInfo_.toBuilder();
              }
              newKernelInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(newKernelInfo_);
                newKernelInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 66: {
              chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) != 0)) {
                subBuilder = oldRootfsInfo_.toBuilder();
              }
              oldRootfsInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(oldRootfsInfo_);
                oldRootfsInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
            case 74: {
              chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) != 0)) {
                subBuilder = newRootfsInfo_.toBuilder();
              }
              newRootfsInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(newRootfsInfo_);
                newRootfsInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 82: {
              chromeos_update_engine.UpdateMetadata.ImageInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000080) != 0)) {
                subBuilder = oldImageInfo_.toBuilder();
              }
              oldImageInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.ImageInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(oldImageInfo_);
                oldImageInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000080;
              break;
            }
            case 90: {
              chromeos_update_engine.UpdateMetadata.ImageInfo.Builder subBuilder = null;
              if (((bitField0_ & 0x00000100) != 0)) {
                subBuilder = newImageInfo_.toBuilder();
              }
              newImageInfo_ = input.readMessage(chromeos_update_engine.UpdateMetadata.ImageInfo.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(newImageInfo_);
                newImageInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000100;
              break;
            }
            case 96: {
              bitField0_ |= 0x00000200;
              minorVersion_ = input.readUInt32();
              break;
            }
            case 106: {
              if (!((mutable_bitField0_ & 0x00001000) != 0)) {
                partitions_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.PartitionUpdate>();
                mutable_bitField0_ |= 0x00001000;
              }
              partitions_.add(
                  input.readMessage(chromeos_update_engine.UpdateMetadata.PartitionUpdate.PARSER, extensionRegistry));
              break;
            }
            case 112: {
              bitField0_ |= 0x00000400;
              maxTimestamp_ = input.readInt64();
              break;
            }
            case 122: {
              chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder subBuilder = null;
              if (((bitField0_ & 0x00000800) != 0)) {
                subBuilder = dynamicPartitionMetadata_.toBuilder();
              }
              dynamicPartitionMetadata_ = input.readMessage(chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(dynamicPartitionMetadata_);
                dynamicPartitionMetadata_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000800;
              break;
            }
            case 128: {
              bitField0_ |= 0x00001000;
              partialUpdate_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          installOperations_ = java.util.Collections.unmodifiableList(installOperations_);
        }
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          kernelInstallOperations_ = java.util.Collections.unmodifiableList(kernelInstallOperations_);
        }
        if (((mutable_bitField0_ & 0x00001000) != 0)) {
          partitions_ = java.util.Collections.unmodifiableList(partitions_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DeltaArchiveManifest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DeltaArchiveManifest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.class, chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.Builder.class);
    }

    private int bitField0_;
    public static final int INSTALL_OPERATIONS_FIELD_NUMBER = 1;
    private java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> installOperations_;
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> getInstallOperationsList() {
      return installOperations_;
    }
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
        getInstallOperationsOrBuilderList() {
      return installOperations_;
    }
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    @java.lang.Override
    public int getInstallOperationsCount() {
      return installOperations_.size();
    }
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperation getInstallOperations(int index) {
      return installOperations_.get(index);
    }
    /**
     * <pre>
     * Only present in major version = 1. List of install operations for the
     * kernel and rootfs partitions. For major version = 2 see the |partitions|
     * field.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getInstallOperationsOrBuilder(
        int index) {
      return installOperations_.get(index);
    }

    public static final int KERNEL_INSTALL_OPERATIONS_FIELD_NUMBER = 2;
    private java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> kernelInstallOperations_;
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> getKernelInstallOperationsList() {
      return kernelInstallOperations_;
    }
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
        getKernelInstallOperationsOrBuilderList() {
      return kernelInstallOperations_;
    }
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    @java.lang.Override
    public int getKernelInstallOperationsCount() {
      return kernelInstallOperations_.size();
    }
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperation getKernelInstallOperations(int index) {
      return kernelInstallOperations_.get(index);
    }
    /**
     * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getKernelInstallOperationsOrBuilder(
        int index) {
      return kernelInstallOperations_.get(index);
    }

    public static final int BLOCK_SIZE_FIELD_NUMBER = 3;
    private int blockSize_;
    /**
     * <pre>
     * (At time of writing) usually 4096
     * </pre>
     *
     * <code>optional uint32 block_size = 3 [default = 4096];</code>
     * @return Whether the blockSize field is set.
     */
    @java.lang.Override
    public boolean hasBlockSize() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * (At time of writing) usually 4096
     * </pre>
     *
     * <code>optional uint32 block_size = 3 [default = 4096];</code>
     * @return The blockSize.
     */
    @java.lang.Override
    public int getBlockSize() {
      return blockSize_;
    }

    public static final int SIGNATURES_OFFSET_FIELD_NUMBER = 4;
    private long signaturesOffset_;
    /**
     * <pre>
     * If signatures are present, the offset into the blobs, generally
     * tacked onto the end of the file, and the length. We use an offset
     * rather than a bool to allow for more flexibility in future file formats.
     * If either is absent, it means signatures aren't supported in this
     * file.
     * </pre>
     *
     * <code>optional uint64 signatures_offset = 4;</code>
     * @return Whether the signaturesOffset field is set.
     */
    @java.lang.Override
    public boolean hasSignaturesOffset() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * If signatures are present, the offset into the blobs, generally
     * tacked onto the end of the file, and the length. We use an offset
     * rather than a bool to allow for more flexibility in future file formats.
     * If either is absent, it means signatures aren't supported in this
     * file.
     * </pre>
     *
     * <code>optional uint64 signatures_offset = 4;</code>
     * @return The signaturesOffset.
     */
    @java.lang.Override
    public long getSignaturesOffset() {
      return signaturesOffset_;
    }

    public static final int SIGNATURES_SIZE_FIELD_NUMBER = 5;
    private long signaturesSize_;
    /**
     * <code>optional uint64 signatures_size = 5;</code>
     * @return Whether the signaturesSize field is set.
     */
    @java.lang.Override
    public boolean hasSignaturesSize() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional uint64 signatures_size = 5;</code>
     * @return The signaturesSize.
     */
    @java.lang.Override
    public long getSignaturesSize() {
      return signaturesSize_;
    }

    public static final int OLD_KERNEL_INFO_FIELD_NUMBER = 6;
    private chromeos_update_engine.UpdateMetadata.PartitionInfo oldKernelInfo_;
    /**
     * <pre>
     * Only present in major version = 1. Partition metadata used to validate the
     * update. For major version = 2 see the |partitions| field.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
     * @return Whether the oldKernelInfo field is set.
     */
    @java.lang.Override
    public boolean hasOldKernelInfo() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <pre>
     * Only present in major version = 1. Partition metadata used to validate the
     * update. For major version = 2 see the |partitions| field.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
     * @return The oldKernelInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getOldKernelInfo() {
      return oldKernelInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldKernelInfo_;
    }
    /**
     * <pre>
     * Only present in major version = 1. Partition metadata used to validate the
     * update. For major version = 2 see the |partitions| field.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldKernelInfoOrBuilder() {
      return oldKernelInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldKernelInfo_;
    }

    public static final int NEW_KERNEL_INFO_FIELD_NUMBER = 7;
    private chromeos_update_engine.UpdateMetadata.PartitionInfo newKernelInfo_;
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
     * @return Whether the newKernelInfo field is set.
     */
    @java.lang.Override
    public boolean hasNewKernelInfo() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
     * @return The newKernelInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getNewKernelInfo() {
      return newKernelInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newKernelInfo_;
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewKernelInfoOrBuilder() {
      return newKernelInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newKernelInfo_;
    }

    public static final int OLD_ROOTFS_INFO_FIELD_NUMBER = 8;
    private chromeos_update_engine.UpdateMetadata.PartitionInfo oldRootfsInfo_;
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
     * @return Whether the oldRootfsInfo field is set.
     */
    @java.lang.Override
    public boolean hasOldRootfsInfo() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
     * @return The oldRootfsInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getOldRootfsInfo() {
      return oldRootfsInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldRootfsInfo_;
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldRootfsInfoOrBuilder() {
      return oldRootfsInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldRootfsInfo_;
    }

    public static final int NEW_ROOTFS_INFO_FIELD_NUMBER = 9;
    private chromeos_update_engine.UpdateMetadata.PartitionInfo newRootfsInfo_;
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
     * @return Whether the newRootfsInfo field is set.
     */
    @java.lang.Override
    public boolean hasNewRootfsInfo() {
      return ((bitField0_ & 0x00000040) != 0);
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
     * @return The newRootfsInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfo getNewRootfsInfo() {
      return newRootfsInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newRootfsInfo_;
    }
    /**
     * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewRootfsInfoOrBuilder() {
      return newRootfsInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newRootfsInfo_;
    }

    public static final int OLD_IMAGE_INFO_FIELD_NUMBER = 10;
    private chromeos_update_engine.UpdateMetadata.ImageInfo oldImageInfo_;
    /**
     * <pre>
     * old_image_info will only be present for delta images.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
     * @return Whether the oldImageInfo field is set.
     */
    @java.lang.Override
    public boolean hasOldImageInfo() {
      return ((bitField0_ & 0x00000080) != 0);
    }
    /**
     * <pre>
     * old_image_info will only be present for delta images.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
     * @return The oldImageInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ImageInfo getOldImageInfo() {
      return oldImageInfo_ == null ? chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : oldImageInfo_;
    }
    /**
     * <pre>
     * old_image_info will only be present for delta images.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder getOldImageInfoOrBuilder() {
      return oldImageInfo_ == null ? chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : oldImageInfo_;
    }

    public static final int NEW_IMAGE_INFO_FIELD_NUMBER = 11;
    private chromeos_update_engine.UpdateMetadata.ImageInfo newImageInfo_;
    /**
     * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
     * @return Whether the newImageInfo field is set.
     */
    @java.lang.Override
    public boolean hasNewImageInfo() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
     * @return The newImageInfo.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ImageInfo getNewImageInfo() {
      return newImageInfo_ == null ? chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : newImageInfo_;
    }
    /**
     * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder getNewImageInfoOrBuilder() {
      return newImageInfo_ == null ? chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : newImageInfo_;
    }

    public static final int MINOR_VERSION_FIELD_NUMBER = 12;
    private int minorVersion_;
    /**
     * <pre>
     * The minor version, also referred as "delta version", of the payload.
     * Minor version 0 is full payload, everything else is delta payload.
     * </pre>
     *
     * <code>optional uint32 minor_version = 12 [default = 0];</code>
     * @return Whether the minorVersion field is set.
     */
    @java.lang.Override
    public boolean hasMinorVersion() {
      return ((bitField0_ & 0x00000200) != 0);
    }
    /**
     * <pre>
     * The minor version, also referred as "delta version", of the payload.
     * Minor version 0 is full payload, everything else is delta payload.
     * </pre>
     *
     * <code>optional uint32 minor_version = 12 [default = 0];</code>
     * @return The minorVersion.
     */
    @java.lang.Override
    public int getMinorVersion() {
      return minorVersion_;
    }

    public static final int PARTITIONS_FIELD_NUMBER = 13;
    private java.util.List<chromeos_update_engine.UpdateMetadata.PartitionUpdate> partitions_;
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    @java.lang.Override
    public java.util.List<chromeos_update_engine.UpdateMetadata.PartitionUpdate> getPartitionsList() {
      return partitions_;
    }
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    @java.lang.Override
    public java.util.List<? extends chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder>
        getPartitionsOrBuilderList() {
      return partitions_;
    }
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    @java.lang.Override
    public int getPartitionsCount() {
      return partitions_.size();
    }
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionUpdate getPartitions(int index) {
      return partitions_.get(index);
    }
    /**
     * <pre>
     * Only present in major version &gt;= 2. List of partitions that will be
     * updated, in the order they will be updated. This field replaces the
     * |install_operations|, |kernel_install_operations| and the
     * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
     * array can have more than two partitions if needed, and they are identified
     * by the partition name.
     * </pre>
     *
     * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder getPartitionsOrBuilder(
        int index) {
      return partitions_.get(index);
    }

    public static final int MAX_TIMESTAMP_FIELD_NUMBER = 14;
    private long maxTimestamp_;
    /**
     * <pre>
     * The maximum timestamp of the OS allowed to apply this payload.
     * Can be used to prevent downgrading the OS.
     * </pre>
     *
     * <code>optional int64 max_timestamp = 14;</code>
     * @return Whether the maxTimestamp field is set.
     */
    @java.lang.Override
    public boolean hasMaxTimestamp() {
      return ((bitField0_ & 0x00000400) != 0);
    }
    /**
     * <pre>
     * The maximum timestamp of the OS allowed to apply this payload.
     * Can be used to prevent downgrading the OS.
     * </pre>
     *
     * <code>optional int64 max_timestamp = 14;</code>
     * @return The maxTimestamp.
     */
    @java.lang.Override
    public long getMaxTimestamp() {
      return maxTimestamp_;
    }

    public static final int DYNAMIC_PARTITION_METADATA_FIELD_NUMBER = 15;
    private chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata dynamicPartitionMetadata_;
    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
     * @return Whether the dynamicPartitionMetadata field is set.
     */
    @java.lang.Override
    public boolean hasDynamicPartitionMetadata() {
      return ((bitField0_ & 0x00000800) != 0);
    }
    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
     * @return The dynamicPartitionMetadata.
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata getDynamicPartitionMetadata() {
      return dynamicPartitionMetadata_ == null ? chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance() : dynamicPartitionMetadata_;
    }
    /**
     * <pre>
     * Metadata related to all dynamic partitions.
     * </pre>
     *
     * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
     */
    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder getDynamicPartitionMetadataOrBuilder() {
      return dynamicPartitionMetadata_ == null ? chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance() : dynamicPartitionMetadata_;
    }

    public static final int PARTIAL_UPDATE_FIELD_NUMBER = 16;
    private boolean partialUpdate_;
    /**
     * <pre>
     * If the payload only updates a subset of partitions on the device.
     * </pre>
     *
     * <code>optional bool partial_update = 16;</code>
     * @return Whether the partialUpdate field is set.
     */
    @java.lang.Override
    public boolean hasPartialUpdate() {
      return ((bitField0_ & 0x00001000) != 0);
    }
    /**
     * <pre>
     * If the payload only updates a subset of partitions on the device.
     * </pre>
     *
     * <code>optional bool partial_update = 16;</code>
     * @return The partialUpdate.
     */
    @java.lang.Override
    public boolean getPartialUpdate() {
      return partialUpdate_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getInstallOperationsCount(); i++) {
        if (!getInstallOperations(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getKernelInstallOperationsCount(); i++) {
        if (!getKernelInstallOperations(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getPartitionsCount(); i++) {
        if (!getPartitions(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasDynamicPartitionMetadata()) {
        if (!getDynamicPartitionMetadata().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < installOperations_.size(); i++) {
        output.writeMessage(1, installOperations_.get(i));
      }
      for (int i = 0; i < kernelInstallOperations_.size(); i++) {
        output.writeMessage(2, kernelInstallOperations_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeUInt32(3, blockSize_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt64(4, signaturesOffset_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeUInt64(5, signaturesSize_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(6, getOldKernelInfo());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(7, getNewKernelInfo());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeMessage(8, getOldRootfsInfo());
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        output.writeMessage(9, getNewRootfsInfo());
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        output.writeMessage(10, getOldImageInfo());
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        output.writeMessage(11, getNewImageInfo());
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        output.writeUInt32(12, minorVersion_);
      }
      for (int i = 0; i < partitions_.size(); i++) {
        output.writeMessage(13, partitions_.get(i));
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        output.writeInt64(14, maxTimestamp_);
      }
      if (((bitField0_ & 0x00000800) != 0)) {
        output.writeMessage(15, getDynamicPartitionMetadata());
      }
      if (((bitField0_ & 0x00001000) != 0)) {
        output.writeBool(16, partialUpdate_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < installOperations_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, installOperations_.get(i));
      }
      for (int i = 0; i < kernelInstallOperations_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, kernelInstallOperations_.get(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(3, blockSize_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, signaturesOffset_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, signaturesSize_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getOldKernelInfo());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getNewKernelInfo());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getOldRootfsInfo());
      }
      if (((bitField0_ & 0x00000040) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getNewRootfsInfo());
      }
      if (((bitField0_ & 0x00000080) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getOldImageInfo());
      }
      if (((bitField0_ & 0x00000100) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getNewImageInfo());
      }
      if (((bitField0_ & 0x00000200) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(12, minorVersion_);
      }
      for (int i = 0; i < partitions_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, partitions_.get(i));
      }
      if (((bitField0_ & 0x00000400) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(14, maxTimestamp_);
      }
      if (((bitField0_ & 0x00000800) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getDynamicPartitionMetadata());
      }
      if (((bitField0_ & 0x00001000) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(16, partialUpdate_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest)) {
        return super.equals(obj);
      }
      chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest other = (chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest) obj;

      if (!getInstallOperationsList()
          .equals(other.getInstallOperationsList())) return false;
      if (!getKernelInstallOperationsList()
          .equals(other.getKernelInstallOperationsList())) return false;
      if (hasBlockSize() != other.hasBlockSize()) return false;
      if (hasBlockSize()) {
        if (getBlockSize()
            != other.getBlockSize()) return false;
      }
      if (hasSignaturesOffset() != other.hasSignaturesOffset()) return false;
      if (hasSignaturesOffset()) {
        if (getSignaturesOffset()
            != other.getSignaturesOffset()) return false;
      }
      if (hasSignaturesSize() != other.hasSignaturesSize()) return false;
      if (hasSignaturesSize()) {
        if (getSignaturesSize()
            != other.getSignaturesSize()) return false;
      }
      if (hasOldKernelInfo() != other.hasOldKernelInfo()) return false;
      if (hasOldKernelInfo()) {
        if (!getOldKernelInfo()
            .equals(other.getOldKernelInfo())) return false;
      }
      if (hasNewKernelInfo() != other.hasNewKernelInfo()) return false;
      if (hasNewKernelInfo()) {
        if (!getNewKernelInfo()
            .equals(other.getNewKernelInfo())) return false;
      }
      if (hasOldRootfsInfo() != other.hasOldRootfsInfo()) return false;
      if (hasOldRootfsInfo()) {
        if (!getOldRootfsInfo()
            .equals(other.getOldRootfsInfo())) return false;
      }
      if (hasNewRootfsInfo() != other.hasNewRootfsInfo()) return false;
      if (hasNewRootfsInfo()) {
        if (!getNewRootfsInfo()
            .equals(other.getNewRootfsInfo())) return false;
      }
      if (hasOldImageInfo() != other.hasOldImageInfo()) return false;
      if (hasOldImageInfo()) {
        if (!getOldImageInfo()
            .equals(other.getOldImageInfo())) return false;
      }
      if (hasNewImageInfo() != other.hasNewImageInfo()) return false;
      if (hasNewImageInfo()) {
        if (!getNewImageInfo()
            .equals(other.getNewImageInfo())) return false;
      }
      if (hasMinorVersion() != other.hasMinorVersion()) return false;
      if (hasMinorVersion()) {
        if (getMinorVersion()
            != other.getMinorVersion()) return false;
      }
      if (!getPartitionsList()
          .equals(other.getPartitionsList())) return false;
      if (hasMaxTimestamp() != other.hasMaxTimestamp()) return false;
      if (hasMaxTimestamp()) {
        if (getMaxTimestamp()
            != other.getMaxTimestamp()) return false;
      }
      if (hasDynamicPartitionMetadata() != other.hasDynamicPartitionMetadata()) return false;
      if (hasDynamicPartitionMetadata()) {
        if (!getDynamicPartitionMetadata()
            .equals(other.getDynamicPartitionMetadata())) return false;
      }
      if (hasPartialUpdate() != other.hasPartialUpdate()) return false;
      if (hasPartialUpdate()) {
        if (getPartialUpdate()
            != other.getPartialUpdate()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getInstallOperationsCount() > 0) {
        hash = (37 * hash) + INSTALL_OPERATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getInstallOperationsList().hashCode();
      }
      if (getKernelInstallOperationsCount() > 0) {
        hash = (37 * hash) + KERNEL_INSTALL_OPERATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getKernelInstallOperationsList().hashCode();
      }
      if (hasBlockSize()) {
        hash = (37 * hash) + BLOCK_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getBlockSize();
      }
      if (hasSignaturesOffset()) {
        hash = (37 * hash) + SIGNATURES_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSignaturesOffset());
      }
      if (hasSignaturesSize()) {
        hash = (37 * hash) + SIGNATURES_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSignaturesSize());
      }
      if (hasOldKernelInfo()) {
        hash = (37 * hash) + OLD_KERNEL_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getOldKernelInfo().hashCode();
      }
      if (hasNewKernelInfo()) {
        hash = (37 * hash) + NEW_KERNEL_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getNewKernelInfo().hashCode();
      }
      if (hasOldRootfsInfo()) {
        hash = (37 * hash) + OLD_ROOTFS_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getOldRootfsInfo().hashCode();
      }
      if (hasNewRootfsInfo()) {
        hash = (37 * hash) + NEW_ROOTFS_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getNewRootfsInfo().hashCode();
      }
      if (hasOldImageInfo()) {
        hash = (37 * hash) + OLD_IMAGE_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getOldImageInfo().hashCode();
      }
      if (hasNewImageInfo()) {
        hash = (37 * hash) + NEW_IMAGE_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getNewImageInfo().hashCode();
      }
      if (hasMinorVersion()) {
        hash = (37 * hash) + MINOR_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getMinorVersion();
      }
      if (getPartitionsCount() > 0) {
        hash = (37 * hash) + PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getPartitionsList().hashCode();
      }
      if (hasMaxTimestamp()) {
        hash = (37 * hash) + MAX_TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMaxTimestamp());
      }
      if (hasDynamicPartitionMetadata()) {
        hash = (37 * hash) + DYNAMIC_PARTITION_METADATA_FIELD_NUMBER;
        hash = (53 * hash) + getDynamicPartitionMetadata().hashCode();
      }
      if (hasPartialUpdate()) {
        hash = (37 * hash) + PARTIAL_UPDATE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getPartialUpdate());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code chromeos_update_engine.DeltaArchiveManifest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:chromeos_update_engine.DeltaArchiveManifest)
        chromeos_update_engine.UpdateMetadata.DeltaArchiveManifestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DeltaArchiveManifest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DeltaArchiveManifest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.class, chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.Builder.class);
      }

      // Construct using chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getInstallOperationsFieldBuilder();
          getKernelInstallOperationsFieldBuilder();
          getOldKernelInfoFieldBuilder();
          getNewKernelInfoFieldBuilder();
          getOldRootfsInfoFieldBuilder();
          getNewRootfsInfoFieldBuilder();
          getOldImageInfoFieldBuilder();
          getNewImageInfoFieldBuilder();
          getPartitionsFieldBuilder();
          getDynamicPartitionMetadataFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (installOperationsBuilder_ == null) {
          installOperations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          installOperationsBuilder_.clear();
        }
        if (kernelInstallOperationsBuilder_ == null) {
          kernelInstallOperations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          kernelInstallOperationsBuilder_.clear();
        }
        blockSize_ = 4096;
        bitField0_ = (bitField0_ & ~0x00000004);
        signaturesOffset_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        signaturesSize_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (oldKernelInfoBuilder_ == null) {
          oldKernelInfo_ = null;
        } else {
          oldKernelInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        if (newKernelInfoBuilder_ == null) {
          newKernelInfo_ = null;
        } else {
          newKernelInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        if (oldRootfsInfoBuilder_ == null) {
          oldRootfsInfo_ = null;
        } else {
          oldRootfsInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        if (newRootfsInfoBuilder_ == null) {
          newRootfsInfo_ = null;
        } else {
          newRootfsInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        if (oldImageInfoBuilder_ == null) {
          oldImageInfo_ = null;
        } else {
          oldImageInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000200);
        if (newImageInfoBuilder_ == null) {
          newImageInfo_ = null;
        } else {
          newImageInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000400);
        minorVersion_ = 0;
        bitField0_ = (bitField0_ & ~0x00000800);
        if (partitionsBuilder_ == null) {
          partitions_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00001000);
        } else {
          partitionsBuilder_.clear();
        }
        maxTimestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00002000);
        if (dynamicPartitionMetadataBuilder_ == null) {
          dynamicPartitionMetadata_ = null;
        } else {
          dynamicPartitionMetadataBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        partialUpdate_ = false;
        bitField0_ = (bitField0_ & ~0x00008000);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return chromeos_update_engine.UpdateMetadata.internal_static_chromeos_update_engine_DeltaArchiveManifest_descriptor;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest getDefaultInstanceForType() {
        return chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.getDefaultInstance();
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest build() {
        chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest buildPartial() {
        chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest result = new chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (installOperationsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            installOperations_ = java.util.Collections.unmodifiableList(installOperations_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.installOperations_ = installOperations_;
        } else {
          result.installOperations_ = installOperationsBuilder_.build();
        }
        if (kernelInstallOperationsBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            kernelInstallOperations_ = java.util.Collections.unmodifiableList(kernelInstallOperations_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.kernelInstallOperations_ = kernelInstallOperations_;
        } else {
          result.kernelInstallOperations_ = kernelInstallOperationsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.blockSize_ = blockSize_;
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.signaturesOffset_ = signaturesOffset_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.signaturesSize_ = signaturesSize_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          if (oldKernelInfoBuilder_ == null) {
            result.oldKernelInfo_ = oldKernelInfo_;
          } else {
            result.oldKernelInfo_ = oldKernelInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          if (newKernelInfoBuilder_ == null) {
            result.newKernelInfo_ = newKernelInfo_;
          } else {
            result.newKernelInfo_ = newKernelInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          if (oldRootfsInfoBuilder_ == null) {
            result.oldRootfsInfo_ = oldRootfsInfo_;
          } else {
            result.oldRootfsInfo_ = oldRootfsInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000020;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          if (newRootfsInfoBuilder_ == null) {
            result.newRootfsInfo_ = newRootfsInfo_;
          } else {
            result.newRootfsInfo_ = newRootfsInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000040;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          if (oldImageInfoBuilder_ == null) {
            result.oldImageInfo_ = oldImageInfo_;
          } else {
            result.oldImageInfo_ = oldImageInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000080;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          if (newImageInfoBuilder_ == null) {
            result.newImageInfo_ = newImageInfo_;
          } else {
            result.newImageInfo_ = newImageInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000100;
        }
        if (((from_bitField0_ & 0x00000800) != 0)) {
          result.minorVersion_ = minorVersion_;
          to_bitField0_ |= 0x00000200;
        }
        if (partitionsBuilder_ == null) {
          if (((bitField0_ & 0x00001000) != 0)) {
            partitions_ = java.util.Collections.unmodifiableList(partitions_);
            bitField0_ = (bitField0_ & ~0x00001000);
          }
          result.partitions_ = partitions_;
        } else {
          result.partitions_ = partitionsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00002000) != 0)) {
          result.maxTimestamp_ = maxTimestamp_;
          to_bitField0_ |= 0x00000400;
        }
        if (((from_bitField0_ & 0x00004000) != 0)) {
          if (dynamicPartitionMetadataBuilder_ == null) {
            result.dynamicPartitionMetadata_ = dynamicPartitionMetadata_;
          } else {
            result.dynamicPartitionMetadata_ = dynamicPartitionMetadataBuilder_.build();
          }
          to_bitField0_ |= 0x00000800;
        }
        if (((from_bitField0_ & 0x00008000) != 0)) {
          result.partialUpdate_ = partialUpdate_;
          to_bitField0_ |= 0x00001000;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest) {
          return mergeFrom((chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest other) {
        if (other == chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest.getDefaultInstance()) return this;
        if (installOperationsBuilder_ == null) {
          if (!other.installOperations_.isEmpty()) {
            if (installOperations_.isEmpty()) {
              installOperations_ = other.installOperations_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureInstallOperationsIsMutable();
              installOperations_.addAll(other.installOperations_);
            }
            onChanged();
          }
        } else {
          if (!other.installOperations_.isEmpty()) {
            if (installOperationsBuilder_.isEmpty()) {
              installOperationsBuilder_.dispose();
              installOperationsBuilder_ = null;
              installOperations_ = other.installOperations_;
              bitField0_ = (bitField0_ & ~0x00000001);
              installOperationsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getInstallOperationsFieldBuilder() : null;
            } else {
              installOperationsBuilder_.addAllMessages(other.installOperations_);
            }
          }
        }
        if (kernelInstallOperationsBuilder_ == null) {
          if (!other.kernelInstallOperations_.isEmpty()) {
            if (kernelInstallOperations_.isEmpty()) {
              kernelInstallOperations_ = other.kernelInstallOperations_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureKernelInstallOperationsIsMutable();
              kernelInstallOperations_.addAll(other.kernelInstallOperations_);
            }
            onChanged();
          }
        } else {
          if (!other.kernelInstallOperations_.isEmpty()) {
            if (kernelInstallOperationsBuilder_.isEmpty()) {
              kernelInstallOperationsBuilder_.dispose();
              kernelInstallOperationsBuilder_ = null;
              kernelInstallOperations_ = other.kernelInstallOperations_;
              bitField0_ = (bitField0_ & ~0x00000002);
              kernelInstallOperationsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getKernelInstallOperationsFieldBuilder() : null;
            } else {
              kernelInstallOperationsBuilder_.addAllMessages(other.kernelInstallOperations_);
            }
          }
        }
        if (other.hasBlockSize()) {
          setBlockSize(other.getBlockSize());
        }
        if (other.hasSignaturesOffset()) {
          setSignaturesOffset(other.getSignaturesOffset());
        }
        if (other.hasSignaturesSize()) {
          setSignaturesSize(other.getSignaturesSize());
        }
        if (other.hasOldKernelInfo()) {
          mergeOldKernelInfo(other.getOldKernelInfo());
        }
        if (other.hasNewKernelInfo()) {
          mergeNewKernelInfo(other.getNewKernelInfo());
        }
        if (other.hasOldRootfsInfo()) {
          mergeOldRootfsInfo(other.getOldRootfsInfo());
        }
        if (other.hasNewRootfsInfo()) {
          mergeNewRootfsInfo(other.getNewRootfsInfo());
        }
        if (other.hasOldImageInfo()) {
          mergeOldImageInfo(other.getOldImageInfo());
        }
        if (other.hasNewImageInfo()) {
          mergeNewImageInfo(other.getNewImageInfo());
        }
        if (other.hasMinorVersion()) {
          setMinorVersion(other.getMinorVersion());
        }
        if (partitionsBuilder_ == null) {
          if (!other.partitions_.isEmpty()) {
            if (partitions_.isEmpty()) {
              partitions_ = other.partitions_;
              bitField0_ = (bitField0_ & ~0x00001000);
            } else {
              ensurePartitionsIsMutable();
              partitions_.addAll(other.partitions_);
            }
            onChanged();
          }
        } else {
          if (!other.partitions_.isEmpty()) {
            if (partitionsBuilder_.isEmpty()) {
              partitionsBuilder_.dispose();
              partitionsBuilder_ = null;
              partitions_ = other.partitions_;
              bitField0_ = (bitField0_ & ~0x00001000);
              partitionsBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getPartitionsFieldBuilder() : null;
            } else {
              partitionsBuilder_.addAllMessages(other.partitions_);
            }
          }
        }
        if (other.hasMaxTimestamp()) {
          setMaxTimestamp(other.getMaxTimestamp());
        }
        if (other.hasDynamicPartitionMetadata()) {
          mergeDynamicPartitionMetadata(other.getDynamicPartitionMetadata());
        }
        if (other.hasPartialUpdate()) {
          setPartialUpdate(other.getPartialUpdate());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getInstallOperationsCount(); i++) {
          if (!getInstallOperations(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getKernelInstallOperationsCount(); i++) {
          if (!getKernelInstallOperations(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getPartitionsCount(); i++) {
          if (!getPartitions(i).isInitialized()) {
            return false;
          }
        }
        if (hasDynamicPartitionMetadata()) {
          if (!getDynamicPartitionMetadata().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> installOperations_ =
        java.util.Collections.emptyList();
      private void ensureInstallOperationsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          installOperations_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.InstallOperation>(installOperations_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder> installOperationsBuilder_;

      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> getInstallOperationsList() {
        if (installOperationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(installOperations_);
        } else {
          return installOperationsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public int getInstallOperationsCount() {
        if (installOperationsBuilder_ == null) {
          return installOperations_.size();
        } else {
          return installOperationsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation getInstallOperations(int index) {
        if (installOperationsBuilder_ == null) {
          return installOperations_.get(index);
        } else {
          return installOperationsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder setInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (installOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInstallOperationsIsMutable();
          installOperations_.set(index, value);
          onChanged();
        } else {
          installOperationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder setInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (installOperationsBuilder_ == null) {
          ensureInstallOperationsIsMutable();
          installOperations_.set(index, builderForValue.build());
          onChanged();
        } else {
          installOperationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder addInstallOperations(chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (installOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInstallOperationsIsMutable();
          installOperations_.add(value);
          onChanged();
        } else {
          installOperationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder addInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (installOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInstallOperationsIsMutable();
          installOperations_.add(index, value);
          onChanged();
        } else {
          installOperationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder addInstallOperations(
          chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (installOperationsBuilder_ == null) {
          ensureInstallOperationsIsMutable();
          installOperations_.add(builderForValue.build());
          onChanged();
        } else {
          installOperationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder addInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (installOperationsBuilder_ == null) {
          ensureInstallOperationsIsMutable();
          installOperations_.add(index, builderForValue.build());
          onChanged();
        } else {
          installOperationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder addAllInstallOperations(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.InstallOperation> values) {
        if (installOperationsBuilder_ == null) {
          ensureInstallOperationsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, installOperations_);
          onChanged();
        } else {
          installOperationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder clearInstallOperations() {
        if (installOperationsBuilder_ == null) {
          installOperations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          installOperationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public Builder removeInstallOperations(int index) {
        if (installOperationsBuilder_ == null) {
          ensureInstallOperationsIsMutable();
          installOperations_.remove(index);
          onChanged();
        } else {
          installOperationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder getInstallOperationsBuilder(
          int index) {
        return getInstallOperationsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getInstallOperationsOrBuilder(
          int index) {
        if (installOperationsBuilder_ == null) {
          return installOperations_.get(index);  } else {
          return installOperationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
           getInstallOperationsOrBuilderList() {
        if (installOperationsBuilder_ != null) {
          return installOperationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(installOperations_);
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder addInstallOperationsBuilder() {
        return getInstallOperationsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance());
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder addInstallOperationsBuilder(
          int index) {
        return getInstallOperationsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance());
      }
      /**
       * <pre>
       * Only present in major version = 1. List of install operations for the
       * kernel and rootfs partitions. For major version = 2 see the |partitions|
       * field.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.InstallOperation install_operations = 1;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation.Builder>
           getInstallOperationsBuilderList() {
        return getInstallOperationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
          getInstallOperationsFieldBuilder() {
        if (installOperationsBuilder_ == null) {
          installOperationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>(
                  installOperations_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          installOperations_ = null;
        }
        return installOperationsBuilder_;
      }

      private java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> kernelInstallOperations_ =
        java.util.Collections.emptyList();
      private void ensureKernelInstallOperationsIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          kernelInstallOperations_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.InstallOperation>(kernelInstallOperations_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder> kernelInstallOperationsBuilder_;

      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation> getKernelInstallOperationsList() {
        if (kernelInstallOperationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(kernelInstallOperations_);
        } else {
          return kernelInstallOperationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public int getKernelInstallOperationsCount() {
        if (kernelInstallOperationsBuilder_ == null) {
          return kernelInstallOperations_.size();
        } else {
          return kernelInstallOperationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation getKernelInstallOperations(int index) {
        if (kernelInstallOperationsBuilder_ == null) {
          return kernelInstallOperations_.get(index);
        } else {
          return kernelInstallOperationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder setKernelInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (kernelInstallOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.set(index, value);
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder setKernelInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (kernelInstallOperationsBuilder_ == null) {
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.set(index, builderForValue.build());
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder addKernelInstallOperations(chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (kernelInstallOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.add(value);
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder addKernelInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation value) {
        if (kernelInstallOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.add(index, value);
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder addKernelInstallOperations(
          chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (kernelInstallOperationsBuilder_ == null) {
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.add(builderForValue.build());
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder addKernelInstallOperations(
          int index, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder builderForValue) {
        if (kernelInstallOperationsBuilder_ == null) {
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.add(index, builderForValue.build());
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder addAllKernelInstallOperations(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.InstallOperation> values) {
        if (kernelInstallOperationsBuilder_ == null) {
          ensureKernelInstallOperationsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, kernelInstallOperations_);
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder clearKernelInstallOperations() {
        if (kernelInstallOperationsBuilder_ == null) {
          kernelInstallOperations_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public Builder removeKernelInstallOperations(int index) {
        if (kernelInstallOperationsBuilder_ == null) {
          ensureKernelInstallOperationsIsMutable();
          kernelInstallOperations_.remove(index);
          onChanged();
        } else {
          kernelInstallOperationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder getKernelInstallOperationsBuilder(
          int index) {
        return getKernelInstallOperationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder getKernelInstallOperationsOrBuilder(
          int index) {
        if (kernelInstallOperationsBuilder_ == null) {
          return kernelInstallOperations_.get(index);  } else {
          return kernelInstallOperationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
           getKernelInstallOperationsOrBuilderList() {
        if (kernelInstallOperationsBuilder_ != null) {
          return kernelInstallOperationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(kernelInstallOperations_);
        }
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder addKernelInstallOperationsBuilder() {
        return getKernelInstallOperationsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance());
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public chromeos_update_engine.UpdateMetadata.InstallOperation.Builder addKernelInstallOperationsBuilder(
          int index) {
        return getKernelInstallOperationsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.InstallOperation.getDefaultInstance());
      }
      /**
       * <code>repeated .chromeos_update_engine.InstallOperation kernel_install_operations = 2;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.InstallOperation.Builder>
           getKernelInstallOperationsBuilderList() {
        return getKernelInstallOperationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>
          getKernelInstallOperationsFieldBuilder() {
        if (kernelInstallOperationsBuilder_ == null) {
          kernelInstallOperationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.InstallOperation, chromeos_update_engine.UpdateMetadata.InstallOperation.Builder, chromeos_update_engine.UpdateMetadata.InstallOperationOrBuilder>(
                  kernelInstallOperations_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          kernelInstallOperations_ = null;
        }
        return kernelInstallOperationsBuilder_;
      }

      private int blockSize_ = 4096;
      /**
       * <pre>
       * (At time of writing) usually 4096
       * </pre>
       *
       * <code>optional uint32 block_size = 3 [default = 4096];</code>
       * @return Whether the blockSize field is set.
       */
      @java.lang.Override
      public boolean hasBlockSize() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * (At time of writing) usually 4096
       * </pre>
       *
       * <code>optional uint32 block_size = 3 [default = 4096];</code>
       * @return The blockSize.
       */
      @java.lang.Override
      public int getBlockSize() {
        return blockSize_;
      }
      /**
       * <pre>
       * (At time of writing) usually 4096
       * </pre>
       *
       * <code>optional uint32 block_size = 3 [default = 4096];</code>
       * @param value The blockSize to set.
       * @return This builder for chaining.
       */
      public Builder setBlockSize(int value) {
        bitField0_ |= 0x00000004;
        blockSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (At time of writing) usually 4096
       * </pre>
       *
       * <code>optional uint32 block_size = 3 [default = 4096];</code>
       * @return This builder for chaining.
       */
      public Builder clearBlockSize() {
        bitField0_ = (bitField0_ & ~0x00000004);
        blockSize_ = 4096;
        onChanged();
        return this;
      }

      private long signaturesOffset_ ;
      /**
       * <pre>
       * If signatures are present, the offset into the blobs, generally
       * tacked onto the end of the file, and the length. We use an offset
       * rather than a bool to allow for more flexibility in future file formats.
       * If either is absent, it means signatures aren't supported in this
       * file.
       * </pre>
       *
       * <code>optional uint64 signatures_offset = 4;</code>
       * @return Whether the signaturesOffset field is set.
       */
      @java.lang.Override
      public boolean hasSignaturesOffset() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <pre>
       * If signatures are present, the offset into the blobs, generally
       * tacked onto the end of the file, and the length. We use an offset
       * rather than a bool to allow for more flexibility in future file formats.
       * If either is absent, it means signatures aren't supported in this
       * file.
       * </pre>
       *
       * <code>optional uint64 signatures_offset = 4;</code>
       * @return The signaturesOffset.
       */
      @java.lang.Override
      public long getSignaturesOffset() {
        return signaturesOffset_;
      }
      /**
       * <pre>
       * If signatures are present, the offset into the blobs, generally
       * tacked onto the end of the file, and the length. We use an offset
       * rather than a bool to allow for more flexibility in future file formats.
       * If either is absent, it means signatures aren't supported in this
       * file.
       * </pre>
       *
       * <code>optional uint64 signatures_offset = 4;</code>
       * @param value The signaturesOffset to set.
       * @return This builder for chaining.
       */
      public Builder setSignaturesOffset(long value) {
        bitField0_ |= 0x00000008;
        signaturesOffset_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If signatures are present, the offset into the blobs, generally
       * tacked onto the end of the file, and the length. We use an offset
       * rather than a bool to allow for more flexibility in future file formats.
       * If either is absent, it means signatures aren't supported in this
       * file.
       * </pre>
       *
       * <code>optional uint64 signatures_offset = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearSignaturesOffset() {
        bitField0_ = (bitField0_ & ~0x00000008);
        signaturesOffset_ = 0L;
        onChanged();
        return this;
      }

      private long signaturesSize_ ;
      /**
       * <code>optional uint64 signatures_size = 5;</code>
       * @return Whether the signaturesSize field is set.
       */
      @java.lang.Override
      public boolean hasSignaturesSize() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional uint64 signatures_size = 5;</code>
       * @return The signaturesSize.
       */
      @java.lang.Override
      public long getSignaturesSize() {
        return signaturesSize_;
      }
      /**
       * <code>optional uint64 signatures_size = 5;</code>
       * @param value The signaturesSize to set.
       * @return This builder for chaining.
       */
      public Builder setSignaturesSize(long value) {
        bitField0_ |= 0x00000010;
        signaturesSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 signatures_size = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearSignaturesSize() {
        bitField0_ = (bitField0_ & ~0x00000010);
        signaturesSize_ = 0L;
        onChanged();
        return this;
      }

      private chromeos_update_engine.UpdateMetadata.PartitionInfo oldKernelInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder> oldKernelInfoBuilder_;
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       * @return Whether the oldKernelInfo field is set.
       */
      public boolean hasOldKernelInfo() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       * @return The oldKernelInfo.
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getOldKernelInfo() {
        if (oldKernelInfoBuilder_ == null) {
          return oldKernelInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldKernelInfo_;
        } else {
          return oldKernelInfoBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      public Builder setOldKernelInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (oldKernelInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          oldKernelInfo_ = value;
          onChanged();
        } else {
          oldKernelInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      public Builder setOldKernelInfo(
          chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder builderForValue) {
        if (oldKernelInfoBuilder_ == null) {
          oldKernelInfo_ = builderForValue.build();
          onChanged();
        } else {
          oldKernelInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      public Builder mergeOldKernelInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (oldKernelInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0) &&
              oldKernelInfo_ != null &&
              oldKernelInfo_ != chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) {
            oldKernelInfo_ =
              chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder(oldKernelInfo_).mergeFrom(value).buildPartial();
          } else {
            oldKernelInfo_ = value;
          }
          onChanged();
        } else {
          oldKernelInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      public Builder clearOldKernelInfo() {
        if (oldKernelInfoBuilder_ == null) {
          oldKernelInfo_ = null;
          onChanged();
        } else {
          oldKernelInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder getOldKernelInfoBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getOldKernelInfoFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldKernelInfoOrBuilder() {
        if (oldKernelInfoBuilder_ != null) {
          return oldKernelInfoBuilder_.getMessageOrBuilder();
        } else {
          return oldKernelInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldKernelInfo_;
        }
      }
      /**
       * <pre>
       * Only present in major version = 1. Partition metadata used to validate the
       * update. For major version = 2 see the |partitions| field.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.PartitionInfo old_kernel_info = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>
          getOldKernelInfoFieldBuilder() {
        if (oldKernelInfoBuilder_ == null) {
          oldKernelInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>(
                  getOldKernelInfo(),
                  getParentForChildren(),
                  isClean());
          oldKernelInfo_ = null;
        }
        return oldKernelInfoBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.PartitionInfo newKernelInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder> newKernelInfoBuilder_;
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       * @return Whether the newKernelInfo field is set.
       */
      public boolean hasNewKernelInfo() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       * @return The newKernelInfo.
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getNewKernelInfo() {
        if (newKernelInfoBuilder_ == null) {
          return newKernelInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newKernelInfo_;
        } else {
          return newKernelInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      public Builder setNewKernelInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (newKernelInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          newKernelInfo_ = value;
          onChanged();
        } else {
          newKernelInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      public Builder setNewKernelInfo(
          chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder builderForValue) {
        if (newKernelInfoBuilder_ == null) {
          newKernelInfo_ = builderForValue.build();
          onChanged();
        } else {
          newKernelInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      public Builder mergeNewKernelInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (newKernelInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000040) != 0) &&
              newKernelInfo_ != null &&
              newKernelInfo_ != chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) {
            newKernelInfo_ =
              chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder(newKernelInfo_).mergeFrom(value).buildPartial();
          } else {
            newKernelInfo_ = value;
          }
          onChanged();
        } else {
          newKernelInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      public Builder clearNewKernelInfo() {
        if (newKernelInfoBuilder_ == null) {
          newKernelInfo_ = null;
          onChanged();
        } else {
          newKernelInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder getNewKernelInfoBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getNewKernelInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewKernelInfoOrBuilder() {
        if (newKernelInfoBuilder_ != null) {
          return newKernelInfoBuilder_.getMessageOrBuilder();
        } else {
          return newKernelInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newKernelInfo_;
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_kernel_info = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>
          getNewKernelInfoFieldBuilder() {
        if (newKernelInfoBuilder_ == null) {
          newKernelInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>(
                  getNewKernelInfo(),
                  getParentForChildren(),
                  isClean());
          newKernelInfo_ = null;
        }
        return newKernelInfoBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.PartitionInfo oldRootfsInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder> oldRootfsInfoBuilder_;
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       * @return Whether the oldRootfsInfo field is set.
       */
      public boolean hasOldRootfsInfo() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       * @return The oldRootfsInfo.
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getOldRootfsInfo() {
        if (oldRootfsInfoBuilder_ == null) {
          return oldRootfsInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldRootfsInfo_;
        } else {
          return oldRootfsInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      public Builder setOldRootfsInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (oldRootfsInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          oldRootfsInfo_ = value;
          onChanged();
        } else {
          oldRootfsInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      public Builder setOldRootfsInfo(
          chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder builderForValue) {
        if (oldRootfsInfoBuilder_ == null) {
          oldRootfsInfo_ = builderForValue.build();
          onChanged();
        } else {
          oldRootfsInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      public Builder mergeOldRootfsInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (oldRootfsInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000080) != 0) &&
              oldRootfsInfo_ != null &&
              oldRootfsInfo_ != chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) {
            oldRootfsInfo_ =
              chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder(oldRootfsInfo_).mergeFrom(value).buildPartial();
          } else {
            oldRootfsInfo_ = value;
          }
          onChanged();
        } else {
          oldRootfsInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      public Builder clearOldRootfsInfo() {
        if (oldRootfsInfoBuilder_ == null) {
          oldRootfsInfo_ = null;
          onChanged();
        } else {
          oldRootfsInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder getOldRootfsInfoBuilder() {
        bitField0_ |= 0x00000080;
        onChanged();
        return getOldRootfsInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getOldRootfsInfoOrBuilder() {
        if (oldRootfsInfoBuilder_ != null) {
          return oldRootfsInfoBuilder_.getMessageOrBuilder();
        } else {
          return oldRootfsInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : oldRootfsInfo_;
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo old_rootfs_info = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>
          getOldRootfsInfoFieldBuilder() {
        if (oldRootfsInfoBuilder_ == null) {
          oldRootfsInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>(
                  getOldRootfsInfo(),
                  getParentForChildren(),
                  isClean());
          oldRootfsInfo_ = null;
        }
        return oldRootfsInfoBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.PartitionInfo newRootfsInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder> newRootfsInfoBuilder_;
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       * @return Whether the newRootfsInfo field is set.
       */
      public boolean hasNewRootfsInfo() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       * @return The newRootfsInfo.
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo getNewRootfsInfo() {
        if (newRootfsInfoBuilder_ == null) {
          return newRootfsInfo_ == null ? chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newRootfsInfo_;
        } else {
          return newRootfsInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      public Builder setNewRootfsInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (newRootfsInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          newRootfsInfo_ = value;
          onChanged();
        } else {
          newRootfsInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      public Builder setNewRootfsInfo(
          chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder builderForValue) {
        if (newRootfsInfoBuilder_ == null) {
          newRootfsInfo_ = builderForValue.build();
          onChanged();
        } else {
          newRootfsInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      public Builder mergeNewRootfsInfo(chromeos_update_engine.UpdateMetadata.PartitionInfo value) {
        if (newRootfsInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000100) != 0) &&
              newRootfsInfo_ != null &&
              newRootfsInfo_ != chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance()) {
            newRootfsInfo_ =
              chromeos_update_engine.UpdateMetadata.PartitionInfo.newBuilder(newRootfsInfo_).mergeFrom(value).buildPartial();
          } else {
            newRootfsInfo_ = value;
          }
          onChanged();
        } else {
          newRootfsInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      public Builder clearNewRootfsInfo() {
        if (newRootfsInfoBuilder_ == null) {
          newRootfsInfo_ = null;
          onChanged();
        } else {
          newRootfsInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder getNewRootfsInfoBuilder() {
        bitField0_ |= 0x00000100;
        onChanged();
        return getNewRootfsInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder getNewRootfsInfoOrBuilder() {
        if (newRootfsInfoBuilder_ != null) {
          return newRootfsInfoBuilder_.getMessageOrBuilder();
        } else {
          return newRootfsInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.PartitionInfo.getDefaultInstance() : newRootfsInfo_;
        }
      }
      /**
       * <code>optional .chromeos_update_engine.PartitionInfo new_rootfs_info = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>
          getNewRootfsInfoFieldBuilder() {
        if (newRootfsInfoBuilder_ == null) {
          newRootfsInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionInfo, chromeos_update_engine.UpdateMetadata.PartitionInfo.Builder, chromeos_update_engine.UpdateMetadata.PartitionInfoOrBuilder>(
                  getNewRootfsInfo(),
                  getParentForChildren(),
                  isClean());
          newRootfsInfo_ = null;
        }
        return newRootfsInfoBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.ImageInfo oldImageInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.ImageInfo, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder, chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder> oldImageInfoBuilder_;
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       * @return Whether the oldImageInfo field is set.
       */
      public boolean hasOldImageInfo() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       * @return The oldImageInfo.
       */
      public chromeos_update_engine.UpdateMetadata.ImageInfo getOldImageInfo() {
        if (oldImageInfoBuilder_ == null) {
          return oldImageInfo_ == null ? chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : oldImageInfo_;
        } else {
          return oldImageInfoBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      public Builder setOldImageInfo(chromeos_update_engine.UpdateMetadata.ImageInfo value) {
        if (oldImageInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          oldImageInfo_ = value;
          onChanged();
        } else {
          oldImageInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      public Builder setOldImageInfo(
          chromeos_update_engine.UpdateMetadata.ImageInfo.Builder builderForValue) {
        if (oldImageInfoBuilder_ == null) {
          oldImageInfo_ = builderForValue.build();
          onChanged();
        } else {
          oldImageInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      public Builder mergeOldImageInfo(chromeos_update_engine.UpdateMetadata.ImageInfo value) {
        if (oldImageInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000200) != 0) &&
              oldImageInfo_ != null &&
              oldImageInfo_ != chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance()) {
            oldImageInfo_ =
              chromeos_update_engine.UpdateMetadata.ImageInfo.newBuilder(oldImageInfo_).mergeFrom(value).buildPartial();
          } else {
            oldImageInfo_ = value;
          }
          onChanged();
        } else {
          oldImageInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000200;
        return this;
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      public Builder clearOldImageInfo() {
        if (oldImageInfoBuilder_ == null) {
          oldImageInfo_ = null;
          onChanged();
        } else {
          oldImageInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ImageInfo.Builder getOldImageInfoBuilder() {
        bitField0_ |= 0x00000200;
        onChanged();
        return getOldImageInfoFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder getOldImageInfoOrBuilder() {
        if (oldImageInfoBuilder_ != null) {
          return oldImageInfoBuilder_.getMessageOrBuilder();
        } else {
          return oldImageInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : oldImageInfo_;
        }
      }
      /**
       * <pre>
       * old_image_info will only be present for delta images.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.ImageInfo old_image_info = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.ImageInfo, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder, chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder>
          getOldImageInfoFieldBuilder() {
        if (oldImageInfoBuilder_ == null) {
          oldImageInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.ImageInfo, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder, chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder>(
                  getOldImageInfo(),
                  getParentForChildren(),
                  isClean());
          oldImageInfo_ = null;
        }
        return oldImageInfoBuilder_;
      }

      private chromeos_update_engine.UpdateMetadata.ImageInfo newImageInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.ImageInfo, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder, chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder> newImageInfoBuilder_;
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       * @return Whether the newImageInfo field is set.
       */
      public boolean hasNewImageInfo() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       * @return The newImageInfo.
       */
      public chromeos_update_engine.UpdateMetadata.ImageInfo getNewImageInfo() {
        if (newImageInfoBuilder_ == null) {
          return newImageInfo_ == null ? chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : newImageInfo_;
        } else {
          return newImageInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      public Builder setNewImageInfo(chromeos_update_engine.UpdateMetadata.ImageInfo value) {
        if (newImageInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          newImageInfo_ = value;
          onChanged();
        } else {
          newImageInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      public Builder setNewImageInfo(
          chromeos_update_engine.UpdateMetadata.ImageInfo.Builder builderForValue) {
        if (newImageInfoBuilder_ == null) {
          newImageInfo_ = builderForValue.build();
          onChanged();
        } else {
          newImageInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      public Builder mergeNewImageInfo(chromeos_update_engine.UpdateMetadata.ImageInfo value) {
        if (newImageInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000400) != 0) &&
              newImageInfo_ != null &&
              newImageInfo_ != chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance()) {
            newImageInfo_ =
              chromeos_update_engine.UpdateMetadata.ImageInfo.newBuilder(newImageInfo_).mergeFrom(value).buildPartial();
          } else {
            newImageInfo_ = value;
          }
          onChanged();
        } else {
          newImageInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000400;
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      public Builder clearNewImageInfo() {
        if (newImageInfoBuilder_ == null) {
          newImageInfo_ = null;
          onChanged();
        } else {
          newImageInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000400);
        return this;
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ImageInfo.Builder getNewImageInfoBuilder() {
        bitField0_ |= 0x00000400;
        onChanged();
        return getNewImageInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      public chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder getNewImageInfoOrBuilder() {
        if (newImageInfoBuilder_ != null) {
          return newImageInfoBuilder_.getMessageOrBuilder();
        } else {
          return newImageInfo_ == null ?
              chromeos_update_engine.UpdateMetadata.ImageInfo.getDefaultInstance() : newImageInfo_;
        }
      }
      /**
       * <code>optional .chromeos_update_engine.ImageInfo new_image_info = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.ImageInfo, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder, chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder>
          getNewImageInfoFieldBuilder() {
        if (newImageInfoBuilder_ == null) {
          newImageInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.ImageInfo, chromeos_update_engine.UpdateMetadata.ImageInfo.Builder, chromeos_update_engine.UpdateMetadata.ImageInfoOrBuilder>(
                  getNewImageInfo(),
                  getParentForChildren(),
                  isClean());
          newImageInfo_ = null;
        }
        return newImageInfoBuilder_;
      }

      private int minorVersion_ ;
      /**
       * <pre>
       * The minor version, also referred as "delta version", of the payload.
       * Minor version 0 is full payload, everything else is delta payload.
       * </pre>
       *
       * <code>optional uint32 minor_version = 12 [default = 0];</code>
       * @return Whether the minorVersion field is set.
       */
      @java.lang.Override
      public boolean hasMinorVersion() {
        return ((bitField0_ & 0x00000800) != 0);
      }
      /**
       * <pre>
       * The minor version, also referred as "delta version", of the payload.
       * Minor version 0 is full payload, everything else is delta payload.
       * </pre>
       *
       * <code>optional uint32 minor_version = 12 [default = 0];</code>
       * @return The minorVersion.
       */
      @java.lang.Override
      public int getMinorVersion() {
        return minorVersion_;
      }
      /**
       * <pre>
       * The minor version, also referred as "delta version", of the payload.
       * Minor version 0 is full payload, everything else is delta payload.
       * </pre>
       *
       * <code>optional uint32 minor_version = 12 [default = 0];</code>
       * @param value The minorVersion to set.
       * @return This builder for chaining.
       */
      public Builder setMinorVersion(int value) {
        bitField0_ |= 0x00000800;
        minorVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The minor version, also referred as "delta version", of the payload.
       * Minor version 0 is full payload, everything else is delta payload.
       * </pre>
       *
       * <code>optional uint32 minor_version = 12 [default = 0];</code>
       * @return This builder for chaining.
       */
      public Builder clearMinorVersion() {
        bitField0_ = (bitField0_ & ~0x00000800);
        minorVersion_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<chromeos_update_engine.UpdateMetadata.PartitionUpdate> partitions_ =
        java.util.Collections.emptyList();
      private void ensurePartitionsIsMutable() {
        if (!((bitField0_ & 0x00001000) != 0)) {
          partitions_ = new java.util.ArrayList<chromeos_update_engine.UpdateMetadata.PartitionUpdate>(partitions_);
          bitField0_ |= 0x00001000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionUpdate, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder, chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder> partitionsBuilder_;

      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.PartitionUpdate> getPartitionsList() {
        if (partitionsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(partitions_);
        } else {
          return partitionsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public int getPartitionsCount() {
        if (partitionsBuilder_ == null) {
          return partitions_.size();
        } else {
          return partitionsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate getPartitions(int index) {
        if (partitionsBuilder_ == null) {
          return partitions_.get(index);
        } else {
          return partitionsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder setPartitions(
          int index, chromeos_update_engine.UpdateMetadata.PartitionUpdate value) {
        if (partitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePartitionsIsMutable();
          partitions_.set(index, value);
          onChanged();
        } else {
          partitionsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder setPartitions(
          int index, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder builderForValue) {
        if (partitionsBuilder_ == null) {
          ensurePartitionsIsMutable();
          partitions_.set(index, builderForValue.build());
          onChanged();
        } else {
          partitionsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder addPartitions(chromeos_update_engine.UpdateMetadata.PartitionUpdate value) {
        if (partitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePartitionsIsMutable();
          partitions_.add(value);
          onChanged();
        } else {
          partitionsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder addPartitions(
          int index, chromeos_update_engine.UpdateMetadata.PartitionUpdate value) {
        if (partitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePartitionsIsMutable();
          partitions_.add(index, value);
          onChanged();
        } else {
          partitionsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder addPartitions(
          chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder builderForValue) {
        if (partitionsBuilder_ == null) {
          ensurePartitionsIsMutable();
          partitions_.add(builderForValue.build());
          onChanged();
        } else {
          partitionsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder addPartitions(
          int index, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder builderForValue) {
        if (partitionsBuilder_ == null) {
          ensurePartitionsIsMutable();
          partitions_.add(index, builderForValue.build());
          onChanged();
        } else {
          partitionsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder addAllPartitions(
          java.lang.Iterable<? extends chromeos_update_engine.UpdateMetadata.PartitionUpdate> values) {
        if (partitionsBuilder_ == null) {
          ensurePartitionsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, partitions_);
          onChanged();
        } else {
          partitionsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder clearPartitions() {
        if (partitionsBuilder_ == null) {
          partitions_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00001000);
          onChanged();
        } else {
          partitionsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public Builder removePartitions(int index) {
        if (partitionsBuilder_ == null) {
          ensurePartitionsIsMutable();
          partitions_.remove(index);
          onChanged();
        } else {
          partitionsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder getPartitionsBuilder(
          int index) {
        return getPartitionsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder getPartitionsOrBuilder(
          int index) {
        if (partitionsBuilder_ == null) {
          return partitions_.get(index);  } else {
          return partitionsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public java.util.List<? extends chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder>
           getPartitionsOrBuilderList() {
        if (partitionsBuilder_ != null) {
          return partitionsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(partitions_);
        }
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder addPartitionsBuilder() {
        return getPartitionsFieldBuilder().addBuilder(
            chromeos_update_engine.UpdateMetadata.PartitionUpdate.getDefaultInstance());
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder addPartitionsBuilder(
          int index) {
        return getPartitionsFieldBuilder().addBuilder(
            index, chromeos_update_engine.UpdateMetadata.PartitionUpdate.getDefaultInstance());
      }
      /**
       * <pre>
       * Only present in major version &gt;= 2. List of partitions that will be
       * updated, in the order they will be updated. This field replaces the
       * |install_operations|, |kernel_install_operations| and the
       * |{old,new}_{kernel,rootfs}_info| fields used in major version = 1. This
       * array can have more than two partitions if needed, and they are identified
       * by the partition name.
       * </pre>
       *
       * <code>repeated .chromeos_update_engine.PartitionUpdate partitions = 13;</code>
       */
      public java.util.List<chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder>
           getPartitionsBuilderList() {
        return getPartitionsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.PartitionUpdate, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder, chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder>
          getPartitionsFieldBuilder() {
        if (partitionsBuilder_ == null) {
          partitionsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.PartitionUpdate, chromeos_update_engine.UpdateMetadata.PartitionUpdate.Builder, chromeos_update_engine.UpdateMetadata.PartitionUpdateOrBuilder>(
                  partitions_,
                  ((bitField0_ & 0x00001000) != 0),
                  getParentForChildren(),
                  isClean());
          partitions_ = null;
        }
        return partitionsBuilder_;
      }

      private long maxTimestamp_ ;
      /**
       * <pre>
       * The maximum timestamp of the OS allowed to apply this payload.
       * Can be used to prevent downgrading the OS.
       * </pre>
       *
       * <code>optional int64 max_timestamp = 14;</code>
       * @return Whether the maxTimestamp field is set.
       */
      @java.lang.Override
      public boolean hasMaxTimestamp() {
        return ((bitField0_ & 0x00002000) != 0);
      }
      /**
       * <pre>
       * The maximum timestamp of the OS allowed to apply this payload.
       * Can be used to prevent downgrading the OS.
       * </pre>
       *
       * <code>optional int64 max_timestamp = 14;</code>
       * @return The maxTimestamp.
       */
      @java.lang.Override
      public long getMaxTimestamp() {
        return maxTimestamp_;
      }
      /**
       * <pre>
       * The maximum timestamp of the OS allowed to apply this payload.
       * Can be used to prevent downgrading the OS.
       * </pre>
       *
       * <code>optional int64 max_timestamp = 14;</code>
       * @param value The maxTimestamp to set.
       * @return This builder for chaining.
       */
      public Builder setMaxTimestamp(long value) {
        bitField0_ |= 0x00002000;
        maxTimestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum timestamp of the OS allowed to apply this payload.
       * Can be used to prevent downgrading the OS.
       * </pre>
       *
       * <code>optional int64 max_timestamp = 14;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxTimestamp() {
        bitField0_ = (bitField0_ & ~0x00002000);
        maxTimestamp_ = 0L;
        onChanged();
        return this;
      }

      private chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata dynamicPartitionMetadata_;
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder> dynamicPartitionMetadataBuilder_;
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       * @return Whether the dynamicPartitionMetadata field is set.
       */
      public boolean hasDynamicPartitionMetadata() {
        return ((bitField0_ & 0x00004000) != 0);
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       * @return The dynamicPartitionMetadata.
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata getDynamicPartitionMetadata() {
        if (dynamicPartitionMetadataBuilder_ == null) {
          return dynamicPartitionMetadata_ == null ? chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance() : dynamicPartitionMetadata_;
        } else {
          return dynamicPartitionMetadataBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      public Builder setDynamicPartitionMetadata(chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata value) {
        if (dynamicPartitionMetadataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          dynamicPartitionMetadata_ = value;
          onChanged();
        } else {
          dynamicPartitionMetadataBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      public Builder setDynamicPartitionMetadata(
          chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder builderForValue) {
        if (dynamicPartitionMetadataBuilder_ == null) {
          dynamicPartitionMetadata_ = builderForValue.build();
          onChanged();
        } else {
          dynamicPartitionMetadataBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      public Builder mergeDynamicPartitionMetadata(chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata value) {
        if (dynamicPartitionMetadataBuilder_ == null) {
          if (((bitField0_ & 0x00004000) != 0) &&
              dynamicPartitionMetadata_ != null &&
              dynamicPartitionMetadata_ != chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance()) {
            dynamicPartitionMetadata_ =
              chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.newBuilder(dynamicPartitionMetadata_).mergeFrom(value).buildPartial();
          } else {
            dynamicPartitionMetadata_ = value;
          }
          onChanged();
        } else {
          dynamicPartitionMetadataBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      public Builder clearDynamicPartitionMetadata() {
        if (dynamicPartitionMetadataBuilder_ == null) {
          dynamicPartitionMetadata_ = null;
          onChanged();
        } else {
          dynamicPartitionMetadataBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder getDynamicPartitionMetadataBuilder() {
        bitField0_ |= 0x00004000;
        onChanged();
        return getDynamicPartitionMetadataFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      public chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder getDynamicPartitionMetadataOrBuilder() {
        if (dynamicPartitionMetadataBuilder_ != null) {
          return dynamicPartitionMetadataBuilder_.getMessageOrBuilder();
        } else {
          return dynamicPartitionMetadata_ == null ?
              chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.getDefaultInstance() : dynamicPartitionMetadata_;
        }
      }
      /**
       * <pre>
       * Metadata related to all dynamic partitions.
       * </pre>
       *
       * <code>optional .chromeos_update_engine.DynamicPartitionMetadata dynamic_partition_metadata = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder>
          getDynamicPartitionMetadataFieldBuilder() {
        if (dynamicPartitionMetadataBuilder_ == null) {
          dynamicPartitionMetadataBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadata.Builder, chromeos_update_engine.UpdateMetadata.DynamicPartitionMetadataOrBuilder>(
                  getDynamicPartitionMetadata(),
                  getParentForChildren(),
                  isClean());
          dynamicPartitionMetadata_ = null;
        }
        return dynamicPartitionMetadataBuilder_;
      }

      private boolean partialUpdate_ ;
      /**
       * <pre>
       * If the payload only updates a subset of partitions on the device.
       * </pre>
       *
       * <code>optional bool partial_update = 16;</code>
       * @return Whether the partialUpdate field is set.
       */
      @java.lang.Override
      public boolean hasPartialUpdate() {
        return ((bitField0_ & 0x00008000) != 0);
      }
      /**
       * <pre>
       * If the payload only updates a subset of partitions on the device.
       * </pre>
       *
       * <code>optional bool partial_update = 16;</code>
       * @return The partialUpdate.
       */
      @java.lang.Override
      public boolean getPartialUpdate() {
        return partialUpdate_;
      }
      /**
       * <pre>
       * If the payload only updates a subset of partitions on the device.
       * </pre>
       *
       * <code>optional bool partial_update = 16;</code>
       * @param value The partialUpdate to set.
       * @return This builder for chaining.
       */
      public Builder setPartialUpdate(boolean value) {
        bitField0_ |= 0x00008000;
        partialUpdate_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the payload only updates a subset of partitions on the device.
       * </pre>
       *
       * <code>optional bool partial_update = 16;</code>
       * @return This builder for chaining.
       */
      public Builder clearPartialUpdate() {
        bitField0_ = (bitField0_ & ~0x00008000);
        partialUpdate_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:chromeos_update_engine.DeltaArchiveManifest)
    }

    // @@protoc_insertion_point(class_scope:chromeos_update_engine.DeltaArchiveManifest)
    private static final chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest();
    }

    public static chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DeltaArchiveManifest>
        PARSER = new com.google.protobuf.AbstractParser<DeltaArchiveManifest>() {
      @java.lang.Override
      public DeltaArchiveManifest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeltaArchiveManifest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DeltaArchiveManifest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DeltaArchiveManifest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public chromeos_update_engine.UpdateMetadata.DeltaArchiveManifest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_Extent_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_Extent_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_Signatures_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_Signatures_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_Signatures_Signature_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_Signatures_Signature_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_PartitionInfo_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_PartitionInfo_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_ImageInfo_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_ImageInfo_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_InstallOperation_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_InstallOperation_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_PartitionUpdate_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_PartitionUpdate_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_DynamicPartitionGroup_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_DynamicPartitionGroup_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_DynamicPartitionMetadata_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_DynamicPartitionMetadata_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_chromeos_update_engine_DeltaArchiveManifest_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_chromeos_update_engine_DeltaArchiveManifest_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\025update_metadata.proto\022\026chromeos_update" +
      "_engine\"1\n\006Extent\022\023\n\013start_block\030\001 \001(\004\022\022" +
      "\n\nnum_blocks\030\002 \001(\004\"\237\001\n\nSignatures\022@\n\nsig" +
      "natures\030\001 \003(\0132,.chromeos_update_engine.S" +
      "ignatures.Signature\032O\n\tSignature\022\023\n\007vers" +
      "ion\030\001 \001(\rB\002\030\001\022\014\n\004data\030\002 \001(\014\022\037\n\027unpadded_" +
      "signature_size\030\003 \001(\007\"+\n\rPartitionInfo\022\014\n" +
      "\004size\030\001 \001(\004\022\014\n\004hash\030\002 \001(\014\"w\n\tImageInfo\022\r" +
      "\n\005board\030\001 \001(\t\022\013\n\003key\030\002 \001(\t\022\017\n\007channel\030\003 " +
      "\001(\t\022\017\n\007version\030\004 \001(\t\022\025\n\rbuild_channel\030\005 " +
      "\001(\t\022\025\n\rbuild_version\030\006 \001(\t\"\356\003\n\020InstallOp" +
      "eration\022;\n\004type\030\001 \002(\0162-.chromeos_update_" +
      "engine.InstallOperation.Type\022\023\n\013data_off" +
      "set\030\002 \001(\004\022\023\n\013data_length\030\003 \001(\004\0223\n\013src_ex" +
      "tents\030\004 \003(\0132\036.chromeos_update_engine.Ext" +
      "ent\022\022\n\nsrc_length\030\005 \001(\004\0223\n\013dst_extents\030\006" +
      " \003(\0132\036.chromeos_update_engine.Extent\022\022\n\n" +
      "dst_length\030\007 \001(\004\022\030\n\020data_sha256_hash\030\010 \001" +
      "(\014\022\027\n\017src_sha256_hash\030\t \001(\014\"\255\001\n\004Type\022\013\n\007" +
      "REPLACE\020\000\022\016\n\nREPLACE_BZ\020\001\022\014\n\004MOVE\020\002\032\002\010\001\022" +
      "\016\n\006BSDIFF\020\003\032\002\010\001\022\017\n\013SOURCE_COPY\020\004\022\021\n\rSOUR" +
      "CE_BSDIFF\020\005\022\016\n\nREPLACE_XZ\020\010\022\010\n\004ZERO\020\006\022\013\n" +
      "\007DISCARD\020\007\022\021\n\rBROTLI_BSDIFF\020\n\022\014\n\010PUFFDIF" +
      "F\020\t\"\327\005\n\017PartitionUpdate\022\026\n\016partition_nam" +
      "e\030\001 \002(\t\022\027\n\017run_postinstall\030\002 \001(\010\022\030\n\020post" +
      "install_path\030\003 \001(\t\022\027\n\017filesystem_type\030\004 " +
      "\001(\t\022M\n\027new_partition_signature\030\005 \003(\0132,.c" +
      "hromeos_update_engine.Signatures.Signatu" +
      "re\022A\n\022old_partition_info\030\006 \001(\0132%.chromeo" +
      "s_update_engine.PartitionInfo\022A\n\022new_par" +
      "tition_info\030\007 \001(\0132%.chromeos_update_engi" +
      "ne.PartitionInfo\022<\n\noperations\030\010 \003(\0132(.c" +
      "hromeos_update_engine.InstallOperation\022\034" +
      "\n\024postinstall_optional\030\t \001(\010\022=\n\025hash_tre" +
      "e_data_extent\030\n \001(\0132\036.chromeos_update_en" +
      "gine.Extent\0228\n\020hash_tree_extent\030\013 \001(\0132\036." +
      "chromeos_update_engine.Extent\022\033\n\023hash_tr" +
      "ee_algorithm\030\014 \001(\t\022\026\n\016hash_tree_salt\030\r \001" +
      "(\014\0227\n\017fec_data_extent\030\016 \001(\0132\036.chromeos_u" +
      "pdate_engine.Extent\0222\n\nfec_extent\030\017 \001(\0132" +
      "\036.chromeos_update_engine.Extent\022\024\n\tfec_r" +
      "oots\030\020 \001(\r:\0012\"L\n\025DynamicPartitionGroup\022\014" +
      "\n\004name\030\001 \002(\t\022\014\n\004size\030\002 \001(\004\022\027\n\017partition_" +
      "names\030\003 \003(\t\"s\n\030DynamicPartitionMetadata\022" +
      "=\n\006groups\030\001 \003(\0132-.chromeos_update_engine" +
      ".DynamicPartitionGroup\022\030\n\020snapshot_enabl" +
      "ed\030\002 \001(\010\"\311\006\n\024DeltaArchiveManifest\022D\n\022ins" +
      "tall_operations\030\001 \003(\0132(.chromeos_update_" +
      "engine.InstallOperation\022K\n\031kernel_instal" +
      "l_operations\030\002 \003(\0132(.chromeos_update_eng" +
      "ine.InstallOperation\022\030\n\nblock_size\030\003 \001(\r" +
      ":\0044096\022\031\n\021signatures_offset\030\004 \001(\004\022\027\n\017sig" +
      "natures_size\030\005 \001(\004\022>\n\017old_kernel_info\030\006 " +
      "\001(\0132%.chromeos_update_engine.PartitionIn" +
      "fo\022>\n\017new_kernel_info\030\007 \001(\0132%.chromeos_u" +
      "pdate_engine.PartitionInfo\022>\n\017old_rootfs" +
      "_info\030\010 \001(\0132%.chromeos_update_engine.Par" +
      "titionInfo\022>\n\017new_rootfs_info\030\t \001(\0132%.ch" +
      "romeos_update_engine.PartitionInfo\0229\n\016ol" +
      "d_image_info\030\n \001(\0132!.chromeos_update_eng" +
      "ine.ImageInfo\0229\n\016new_image_info\030\013 \001(\0132!." +
      "chromeos_update_engine.ImageInfo\022\030\n\rmino" +
      "r_version\030\014 \001(\r:\0010\022;\n\npartitions\030\r \003(\0132\'" +
      ".chromeos_update_engine.PartitionUpdate\022" +
      "\025\n\rmax_timestamp\030\016 \001(\003\022T\n\032dynamic_partit" +
      "ion_metadata\030\017 \001(\01320.chromeos_update_eng" +
      "ine.DynamicPartitionMetadata\022\026\n\016partial_" +
      "update\030\020 \001(\010B\002H\003"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        });
    internal_static_chromeos_update_engine_Extent_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_chromeos_update_engine_Extent_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_Extent_descriptor,
        new java.lang.String[] { "StartBlock", "NumBlocks", });
    internal_static_chromeos_update_engine_Signatures_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_chromeos_update_engine_Signatures_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_Signatures_descriptor,
        new java.lang.String[] { "Signatures", });
    internal_static_chromeos_update_engine_Signatures_Signature_descriptor =
      internal_static_chromeos_update_engine_Signatures_descriptor.getNestedTypes().get(0);
    internal_static_chromeos_update_engine_Signatures_Signature_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_Signatures_Signature_descriptor,
        new java.lang.String[] { "Version", "Data", "UnpaddedSignatureSize", });
    internal_static_chromeos_update_engine_PartitionInfo_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_chromeos_update_engine_PartitionInfo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_PartitionInfo_descriptor,
        new java.lang.String[] { "Size", "Hash", });
    internal_static_chromeos_update_engine_ImageInfo_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_chromeos_update_engine_ImageInfo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_ImageInfo_descriptor,
        new java.lang.String[] { "Board", "Key", "Channel", "Version", "BuildChannel", "BuildVersion", });
    internal_static_chromeos_update_engine_InstallOperation_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_chromeos_update_engine_InstallOperation_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_InstallOperation_descriptor,
        new java.lang.String[] { "Type", "DataOffset", "DataLength", "SrcExtents", "SrcLength", "DstExtents", "DstLength", "DataSha256Hash", "SrcSha256Hash", });
    internal_static_chromeos_update_engine_PartitionUpdate_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_chromeos_update_engine_PartitionUpdate_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_PartitionUpdate_descriptor,
        new java.lang.String[] { "PartitionName", "RunPostinstall", "PostinstallPath", "FilesystemType", "NewPartitionSignature", "OldPartitionInfo", "NewPartitionInfo", "Operations", "PostinstallOptional", "HashTreeDataExtent", "HashTreeExtent", "HashTreeAlgorithm", "HashTreeSalt", "FecDataExtent", "FecExtent", "FecRoots", });
    internal_static_chromeos_update_engine_DynamicPartitionGroup_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_chromeos_update_engine_DynamicPartitionGroup_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_DynamicPartitionGroup_descriptor,
        new java.lang.String[] { "Name", "Size", "PartitionNames", });
    internal_static_chromeos_update_engine_DynamicPartitionMetadata_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_chromeos_update_engine_DynamicPartitionMetadata_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_DynamicPartitionMetadata_descriptor,
        new java.lang.String[] { "Groups", "SnapshotEnabled", });
    internal_static_chromeos_update_engine_DeltaArchiveManifest_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_chromeos_update_engine_DeltaArchiveManifest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_chromeos_update_engine_DeltaArchiveManifest_descriptor,
        new java.lang.String[] { "InstallOperations", "KernelInstallOperations", "BlockSize", "SignaturesOffset", "SignaturesSize", "OldKernelInfo", "NewKernelInfo", "OldRootfsInfo", "NewRootfsInfo", "OldImageInfo", "NewImageInfo", "MinorVersion", "Partitions", "MaxTimestamp", "DynamicPartitionMetadata", "PartialUpdate", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}

```

`bbootimg/src/main/kotlin/avb/AVBInfo.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb

import avb.alg.Algorithms
import avb.blob.AuthBlob
import avb.blob.AuxBlob
import avb.blob.Footer
import avb.blob.Header
import avb.desc.UnknownDescriptor
import cfig.Avb
import cfig.helper.Helper
import cfig.helper.Helper.Companion.paddingWith
import cfig.helper.Dumpling
import com.fasterxml.jackson.databind.ObjectMapper
import org.apache.commons.codec.binary.Hex
import org.slf4j.LoggerFactory
import java.io.ByteArrayInputStream
import java.io.File

/*
    a wonderful base64 encoder/decoder: https://cryptii.com/base64-to-hex
 */
class AVBInfo(
    var header: Header? = null,
    var authBlob: AuthBlob? = null,
    var auxBlob: AuxBlob? = null,
    var footer: Footer? = null,
) {
    fun encode(): ByteArray {
        val alg = Algorithms.get(header!!.algorithm_type)!!
        //3 - whole aux blob
        val newAuxBlob = auxBlob?.encode(alg) ?: byteArrayOf()
        //1 - whole header blob
        val headerBlob = this.header!!.apply {
            auxiliary_data_block_size = newAuxBlob.size.toLong()
            authentication_data_block_size = Helper.round_to_multiple(
                (alg.hash_num_bytes + alg.signature_num_bytes).toLong(), 64
            )

            descriptors_offset = 0
            descriptors_size = auxBlob?.descriptorSize?.toLong() ?: 0

            hash_offset = 0
            hash_size = alg.hash_num_bytes.toLong()

            signature_offset = alg.hash_num_bytes.toLong()
            signature_size = alg.signature_num_bytes.toLong()

            public_key_offset = descriptors_size
            public_key_size = AuxBlob.encodePubKey(alg).size.toLong()

            public_key_metadata_size = auxBlob!!.pubkeyMeta?.pkmd?.size?.toLong() ?: 0L
            public_key_metadata_offset = public_key_offset + public_key_size
            log.debug("pkmd size: $public_key_metadata_size, pkmd offset : $public_key_metadata_offset")
        }.encode()
        //2 - auth blob
        val authBlob = AuthBlob.createBlob(headerBlob, newAuxBlob, alg.name)
        val ret = Helper.join(headerBlob, authBlob, newAuxBlob)
        //Helper.dumpToFile("_debug_vbmeta_", ret)
        return ret
    }

    fun encodePadded(): ByteArray {
        return encode().paddingWith(Avb.BLOCK_SIZE.toUInt())
    }

    fun dumpDefault(imageFile: String): AVBInfo {
        val jsonFile = Avb.getJsonFileName(imageFile)
        mapper.writerWithDefaultPrettyPrinter().writeValue(File(jsonFile), this)
        log.info("VBMeta: $imageFile -> $jsonFile")
        return this
    }

    companion object {
        private val log = LoggerFactory.getLogger(AVBInfo::class.java)
        private val mapper = ObjectMapper()

        data class Glance(
            var footer: Footer?,
            var vbMetaOffset: Long
        )

        private fun imageGlance(dp: Dumpling<*>): Glance {
            val ret = Glance(null, 0)
            try {
                ret.footer = Footer(dp.readFully(Pair(-Footer.SIZE.toLong(), Footer.SIZE)))
                ret.vbMetaOffset = ret.footer!!.vbMetaOffset
                log.info("${dp.getName()}: $ret.footer")
            } catch (e: IllegalArgumentException) {
                log.info("image ${dp.getName()} has no AVB Footer")
            }
            return ret
        }

        fun parseFrom(dp: Dumpling<*>): AVBInfo {
            log.info("parseFrom(${dp.getName()}) ...")
            // glance
            val (footer, vbMetaOffset) = imageGlance(dp)
            // header
            val vbMetaHeader = Header(dp.readFully(Pair(vbMetaOffset, Header.SIZE)))
            log.debug(mapper.writerWithDefaultPrettyPrinter().writeValueAsString(vbMetaHeader))

            val atlas = mutableMapOf<String, Pair<Long, Int>>()
            atlas["auth"] =
                Pair(vbMetaOffset + Header.SIZE, vbMetaHeader.authentication_data_block_size.toInt())
            atlas["auth.hash"] =
                Pair(atlas["auth"]!!.first + vbMetaHeader.hash_offset, vbMetaHeader.hash_size.toInt())
            atlas["auth.sig"] =
                Pair(atlas["auth.hash"]!!.first + atlas["auth.hash"]!!.second, vbMetaHeader.signature_size.toInt())
            atlas["aux"] =
                Pair(atlas["auth"]!!.first + atlas["auth"]!!.second, vbMetaHeader.auxiliary_data_block_size.toInt())

            val ai = AVBInfo(vbMetaHeader, null, AuxBlob(), footer)
            // Auth blob
            if (vbMetaHeader.authentication_data_block_size > 0) {
                val ba = dp.readFully(atlas["auth.hash"]!!)
                log.debug("Parsed Auth Hash (Header & Aux Blob): " + Hex.encodeHexString(ba))
                val bb = dp.readFully(atlas["auth.sig"]!!)
                log.debug("Parsed Auth Signature (of hash): " + Hex.encodeHexString(bb))
                ai.authBlob = AuthBlob()
                ai.authBlob!!.offset = atlas["auth"]!!.first
                ai.authBlob!!.size = atlas["auth"]!!.second.toLong()
                ai.authBlob!!.hash = Hex.encodeHexString(ba)
                ai.authBlob!!.signature = Hex.encodeHexString(bb)
            }
            // aux
            val rawAuxBlob = dp.readFully(atlas["aux"]!!)
            // aux - desc
            if (vbMetaHeader.descriptors_size > 0) {
                val descriptors = UnknownDescriptor.parseDescriptors(
                    ByteArrayInputStream(
                        rawAuxBlob.copyOfRange(vbMetaHeader.descriptors_offset.toInt(), rawAuxBlob.size)
                    ),
                    vbMetaHeader.descriptors_size
                )
                ai.auxBlob!!.populateDescriptors(descriptors)
            } else {
                log.warn("no descriptors in AVB aux blob")
            }
            // aux - pubkey
            if (vbMetaHeader.public_key_size > 0) {
                ai.auxBlob!!.pubkey = AuxBlob.PubKeyInfo()
                ai.auxBlob!!.pubkey!!.offset = vbMetaHeader.public_key_offset
                ai.auxBlob!!.pubkey!!.size = vbMetaHeader.public_key_size
                ai.auxBlob!!.pubkey!!.pubkey = rawAuxBlob.copyOfRange(
                    vbMetaHeader.public_key_offset.toInt(),
                    (vbMetaHeader.public_key_offset + vbMetaHeader.public_key_size).toInt()
                )
                log.debug("Parsed Pub Key: " + Hex.encodeHexString(ai.auxBlob!!.pubkey!!.pubkey))
            }
            // aux - pkmd
            if (vbMetaHeader.public_key_metadata_size > 0) {
                ai.auxBlob!!.pubkeyMeta = AuxBlob.PubKeyMetadataInfo()
                ai.auxBlob!!.pubkeyMeta!!.offset = vbMetaHeader.public_key_metadata_offset
                ai.auxBlob!!.pubkeyMeta!!.size = vbMetaHeader.public_key_metadata_size
                ai.auxBlob!!.pubkeyMeta!!.pkmd = rawAuxBlob.copyOfRange(
                    vbMetaHeader.public_key_metadata_offset.toInt(),
                    (vbMetaHeader.public_key_metadata_offset + vbMetaHeader.public_key_metadata_size).toInt()
                )
                log.debug("Parsed Pub Key Metadata: " + Helper.toHexString(ai.auxBlob!!.pubkeyMeta!!.pkmd))
            }
            log.debug("vbmeta info of [${dp.getName()}] has been analyzed")
            return ai
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/Avb.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig

import avb.AVBInfo
import avb.alg.Algorithms
import avb.blob.AuthBlob
import avb.blob.AuxBlob
import avb.blob.Footer
import avb.blob.Header
import avb.desc.HashDescriptor
import cfig.helper.CryptoHelper
import cfig.helper.Helper
import cfig.helper.Helper.Companion.paddingWith
import cfig.helper.Dumpling
import com.fasterxml.jackson.core.type.TypeReference
import com.fasterxml.jackson.databind.ObjectMapper
import org.apache.commons.codec.binary.Hex
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.nio.file.Files
import java.nio.file.Paths
import java.nio.file.StandardOpenOption

class Avb {
    private val MAX_VBMETA_SIZE = 64 * 1024
    private val MAX_FOOTER_SIZE = 4096

    //migrated from: avbtool::Avb::addHashFooter
    fun addHashFooter(
        image_file: String, //file to be hashed and signed
        partition_size: Long, //aligned by Avb::BLOCK_SIZE
        partition_name: String,
        newAvbInfo: AVBInfo
    ) {
        log.info("addHashFooter($image_file) ...")

        imageSizeCheck(partition_size, image_file)

        //truncate AVB footer if there is. Then addHashFooter() is idempotent
        trimFooter(image_file)
        val newImageSize = File(image_file).length()

        //VBmeta blob: update hash descriptor
        newAvbInfo.apply {
            val itr = this.auxBlob!!.hashDescriptors.iterator()
            var hd = HashDescriptor()
            while (itr.hasNext()) {//remove previous hd entry
                val itrValue = itr.next()
                if (itrValue.partition_name == partition_name) {
                    itr.remove()
                    hd = itrValue
                }
            }
            //HashDescriptor
            hd.update(image_file)
            log.info("updated hash descriptor:" + Hex.encodeHexString(hd.encode()))
            this.auxBlob!!.hashDescriptors.add(hd)
        }

        // image + padding
        val imgPaddingNeeded = Helper.round_to_multiple(newImageSize.toInt(), BLOCK_SIZE) - newImageSize

        // + vbmeta + padding
        val vbmetaBlob = newAvbInfo.encode()
        val vbmetaOffset = newImageSize + imgPaddingNeeded
        val vbmetaBlobWithPadding = newAvbInfo.encodePadded()

        // + DONT_CARE chunk
        val vbmetaEndOffset = vbmetaOffset + vbmetaBlobWithPadding.size
        val dontCareChunkSize = partition_size - vbmetaEndOffset - 1 * BLOCK_SIZE

        // + AvbFooter + padding
        newAvbInfo.footer!!.apply {
            originalImageSize = newImageSize
            vbMetaOffset = vbmetaOffset
            vbMetaSize = vbmetaBlob.size.toLong()
        }
        log.info(newAvbInfo.footer.toString())
        val footerBlobWithPadding = newAvbInfo.footer!!.encode().paddingWith(BLOCK_SIZE.toUInt(), true)

        FileOutputStream(image_file, true).use { fos ->
            log.info("1/4 Padding image with $imgPaddingNeeded bytes ...")
            fos.write(ByteArray(imgPaddingNeeded.toInt()))

            log.info("2/4 Appending vbmeta (${vbmetaBlobWithPadding.size} bytes)...")
            fos.write(vbmetaBlobWithPadding)

            log.info("3/4 Appending DONT CARE CHUNK ($dontCareChunkSize bytes) ...")
            fos.write(ByteArray(dontCareChunkSize.toInt()))

            log.info("4/4 Appending AVB footer (${footerBlobWithPadding.size} bytes)...")
            fos.write(footerBlobWithPadding)
        }
        check(partition_size == File(image_file).length()) { "generated file size mismatch" }
        log.info("addHashFooter($image_file) done.")
    }

    private fun trimFooter(image_file: String) {
        var footer: Footer? = null
        FileInputStream(image_file).use {
            it.skip(File(image_file).length() - 64)
            try {
                footer = Footer(it)
                log.info("original image $image_file has AVB footer")
            } catch (e: IllegalArgumentException) {
                log.info("original image $image_file doesn't have AVB footer")
            }
        }
        footer?.let {
            FileOutputStream(File(image_file), true).channel.use { fc ->
                log.info(
                    "original image $image_file has AVB footer, " +
                            "truncate it to original SIZE: ${it.originalImageSize}"
                )
                fc.truncate(it.originalImageSize)
            }
        }
    }

    private fun imageSizeCheck(partition_size: Long, image_file: String) {
        //image size sanity check
        val maxMetadataSize = MAX_VBMETA_SIZE + MAX_FOOTER_SIZE
        if (partition_size < maxMetadataSize) {
            throw IllegalArgumentException(
                "Parition SIZE of $partition_size is too small. " +
                        "Needs to be at least $maxMetadataSize"
            )
        }
        val maxImageSize = partition_size - maxMetadataSize
        log.info("max_image_size: $maxImageSize")

        //TODO: typical block size = 4096L, from avbtool::Avb::ImageHandler::block_size
        //since boot.img is not in sparse format, we are safe to hardcode it to 4096L for now
        if (partition_size % BLOCK_SIZE != 0L) {
            throw IllegalArgumentException(
                "Partition SIZE of $partition_size is not " +
                        "a multiple of the image block SIZE 4096"
            )
        }

        val originalFileSize = File(image_file).length()
        if (originalFileSize > maxImageSize) {
            throw IllegalArgumentException(
                "Image size of $originalFileSize exceeds maximum image size " +
                        "of $maxImageSize in order to fit in a partition size of $partition_size."
            )
        }
    }

    companion object {
        private val log = LoggerFactory.getLogger(Avb::class.java)
        const val BLOCK_SIZE = 4096
        const val AVB_VERSION_MAJOR = 1
        const val AVB_VERSION_MINOR = 1
        const val AVB_VERSION_SUB = 0

        fun getJsonFileName(image_file: String): String {
            val jsonFile = File(image_file).name.removeSuffix(".img") + ".avb.json"
            return Helper.prop("workDir") + jsonFile
        }

        fun hasAvbFooter(fileName: String): Boolean {
            val expectedBf = "AVBf".toByteArray()
            FileInputStream(fileName).use { fis ->
                fis.skip(File(fileName).length() - 64)
                val bf = ByteArray(4)
                fis.read(bf)
                return bf.contentEquals(expectedBf)
            }
        }

        fun verifyAVBIntegrity(fileName: String, avbtool: String): Boolean {
            val cmdline = "python $avbtool verify_image --image $fileName"
            log.info(cmdline)
            try {
                DefaultExecutor().execute(CommandLine.parse(cmdline))
            } catch (e: Exception) {
                log.error("$fileName failed integrity check by \"$cmdline\"")
                return false
            }
            return true
        }

        fun updateVbmeta(fileName: String) {
            if (File("vbmeta.img").exists()) {
                log.info("Updating vbmeta.img side by side ...")
                val partitionName =
                    ObjectMapper().readValue(File(getJsonFileName(fileName)), AVBInfo::class.java).let {
                        it.auxBlob!!.hashDescriptors.get(0).partition_name
                    }
                //read hashDescriptor from image
                val newHashDesc = AVBInfo.parseFrom(Dumpling("$fileName.signed"))
                check(newHashDesc.auxBlob!!.hashDescriptors.size == 1)
                var seq = -1 //means not found
                //main vbmeta
                ObjectMapper().readValue(File(getJsonFileName("vbmeta.img")), AVBInfo::class.java).apply {
                    val itr = this.auxBlob!!.hashDescriptors.iterator()
                    while (itr.hasNext()) {
                        val itrValue = itr.next()
                        if (itrValue.partition_name == partitionName) {
                            log.info("Found $partitionName in vbmeta, update it")
                            seq = itrValue.sequence
                            itr.remove()
                            break
                        }
                    }
                    if (-1 == seq) {
                        log.warn("main vbmeta doesn't have $partitionName hashDescriptor, won't update vbmeta.img")
                    } else {
                        //add hashDescriptor back to main vbmeta
                        val hd = newHashDesc.auxBlob!!.hashDescriptors.get(0).apply { this.sequence = seq }
                        this.auxBlob!!.hashDescriptors.add(hd)
                        log.info("Writing padded vbmeta to file: vbmeta.img.signed")
                        Files.write(Paths.get("vbmeta.img.signed"), encodePadded(), StandardOpenOption.CREATE)
                        log.info("Updating vbmeta.img side by side (partition=$partitionName, seq=$seq) done")
                    }
                }
            } else {
                log.debug("no companion vbmeta.img")
            }
        }

        fun verify(ai: AVBInfo, dp: Dumpling<*>, parent: String = ""): Array<Any> {
            val ret: Array<Any> = arrayOf(true, "")
            val localParent = parent.ifEmpty { dp.getLabel() }
            //header
            val rawHeaderBlob = dp.readFully(Pair(ai.footer?.vbMetaOffset ?: 0, Header.SIZE))
            // aux
            val vbOffset = ai.footer?.vbMetaOffset ?: 0
            //@formatter:off
            val rawAuxBlob = dp.readFully(
                Pair(vbOffset + Header.SIZE + ai.header!!.authentication_data_block_size,
                    ai.header!!.auxiliary_data_block_size.toInt()))
            //@formatter:on
            //integrity check
            val declaredAlg = Algorithms.get(ai.header!!.algorithm_type)
            if (declaredAlg!!.public_key_num_bytes > 0) {
                inspectKey(ai)
                val calcHash =
                    Helper.join(declaredAlg.padding, AuthBlob.calcHash(rawHeaderBlob, rawAuxBlob, declaredAlg.name))
                val readHash = Helper.join(declaredAlg.padding, Helper.fromHexString(ai.authBlob!!.hash!!))
                if (calcHash.contentEquals(readHash)) {
                    log.info("VERIFY($localParent->AuthBlob): verify hash... PASS")
                    val readPubKey = CryptoHelper.KeyBox.decodeRSAkey(ai.auxBlob!!.pubkey!!.pubkey)
                    val hashFromSig =
                        CryptoHelper.Signer.rawRsa(readPubKey, Helper.fromHexString(ai.authBlob!!.signature!!))
                    if (hashFromSig.contentEquals(readHash)) {
                        log.info("VERIFY($localParent->AuthBlob): verify signature... PASS")
                    } else {
                        ret[0] = false
                        ret[1] = ret[1] as String + " verify signature fail;"
                        log.warn("read=" + Helper.toHexString(readHash) + ", calc=" + Helper.toHexString(calcHash))
                        log.warn("VERIFY($localParent->AuthBlob): verify signature... FAIL")
                    }
                } else {
                    ret[0] = false
                    ret[1] = ret[1] as String + " verify hash fail"
                    log.warn("read=" + ai.authBlob!!.hash!! + ", calc=" + Helper.toHexString(calcHash))
                    log.warn("VERIFY($localParent->AuthBlob): verify hash... FAIL")
                }
            } else {
                log.warn("VERIFY($localParent->AuthBlob): algorithm=[${declaredAlg.name}], no signature, skip")
            }

            val prefixes = setOf(System.getenv("more"), System.getProperty("more")).filterNotNull()
                .map { Paths.get(it).toString() + "/" }.toMutableList().apply { add("") }
            ai.auxBlob!!.chainPartitionDescriptors.forEach {
                val vRet = it.verify(
                    prefixes.map { prefix -> "$prefix${it.partition_name}.img" },
                    dp.getLabel() + "->Chain[${it.partition_name}]"
                )
                if (vRet[0] as Boolean) {
                    log.info("VERIFY($localParent->Chain[${it.partition_name}]): " + "PASS")
                } else {
                    ret[0] = false
                    ret[1] = ret[1] as String + "; " + vRet[1] as String
                    log.info("VERIFY($localParent->Chain[${it.partition_name}]): " + vRet[1] as String + "... FAIL")
                }
            }

            ai.auxBlob!!.hashDescriptors.forEach {
                val vRet = it.verify(
                    prefixes.map { prefix -> "$prefix${it.partition_name}.img" },
                    dp.getLabel() + "->HashDescriptor[${it.partition_name}]"
                )
                if (vRet[0] as Boolean) {
                    log.info("VERIFY($localParent->HashDescriptor[${it.partition_name}]): ${it.hash_algorithm} " + "PASS")
                } else {
                    ret[0] = false
                    ret[1] = ret[1] as String + "; " + vRet[1] as String
                    log.info("VERIFY($localParent->HashDescriptor[${it.partition_name}]): ${it.hash_algorithm} " + vRet[1] as String + "... FAIL")
                }
            }

            ai.auxBlob!!.hashTreeDescriptors.forEach {
                val vRet = it.verify(
                    prefixes.map { prefix -> "$prefix${it.partition_name}.img" },
                    dp.getLabel() + "->HashTreeDescriptor[${it.partition_name}]"
                )
                if (vRet[0] as Boolean) {
                    log.info("VERIFY($localParent->HashTreeDescriptor[${it.partition_name}]): ${it.hash_algorithm} " + "PASS")
                } else {
                    ret[0] = false
                    ret[1] = ret[1] as String + "; " + vRet[1] as String
                    log.info("VERIFY($localParent->HashTreeDescriptor[${it.partition_name}]): ${it.hash_algorithm} " + vRet[1] as String + "... FAIL")
                }
            }

            return ret
        }

        fun inspectKey(ai: AVBInfo): String {
            var ret = "NONE"
            if (ai.auxBlob!!.pubkey == null) {
                log.info("vbmeta blob is unsigned")
                return ret
            }
            val declaredAlg = Algorithms.get(ai.header!!.algorithm_type)
            val gkiPubKey = if (declaredAlg!!.algorithm_type == 1) AuxBlob.encodePubKey(
                declaredAlg,
                File("aosp/make/target/product/gsi/testkey_rsa2048.pem").readBytes()
            ) else null
            if (AuxBlob.encodePubKey(declaredAlg).contentEquals(ai.auxBlob!!.pubkey!!.pubkey)) {
                log.info("signed with dev key: " + declaredAlg.defaultKey)
                ret = declaredAlg.defaultKey
            } else if (gkiPubKey.contentEquals(ai.auxBlob!!.pubkey!!.pubkey)) {
                log.info("signed with dev GKI key: " + declaredAlg.defaultKey)
                ret = declaredAlg.defaultKey
            } else {
                val keys = ObjectMapper().readValue(
                    this::class.java.classLoader.getResource("known_keys.json"),
                    object : TypeReference<List<KnownPublicKey>>() {})
                val found = keys.filter { it.pubk.contentEquals(ai.auxBlob!!.pubkey!!.pubkey) }
                if (found.isNotEmpty()) {
                    log.info("signed with release key: '${found[0].device}' by ${found[0].manufacturer}")
                    log.warn("Found key: ${found[0].toShortString()}")
                    ret = "${found[0].device} by ${found[0].manufacturer}"
                } else {
                    log.info("signed with release key")
                    ret = "private release key"
                }
            }
            return ret
        }

        data class KnownPublicKey(
            var device: String = "",
            var manufacturer: String = "",
            var algorithm: String = "",
            var pubk: ByteArray = byteArrayOf(),
            var sha1: String = ""
        ) {
            fun toShortString(): String {
                return "PublicKey(device='$device' by '$manufacturer', algorithm='$algorithm', sha1='$sha1')"
            }
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/alg/Algorithm.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.alg

data class Algorithm(
        val name: String = "NONE",
        val algorithm_type: Int = 0,
        val hash_name: String = "",
        val hash_num_bytes: Int = 0,
        val signature_num_bytes: Int = 0,
        val public_key_num_bytes: Int = 0,
        val padding: ByteArray = byteArrayOf(),
        val defaultKey: String ="")
```

`bbootimg/src/main/kotlin/avb/alg/Algorithms.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.alg

import cc.cfig.io.Struct

class Algorithms {
    companion object {
        private val algMap = mutableMapOf<String, Algorithm>()
        fun get(name: String): Algorithm? {
            return algMap[name]
        }

        fun get(algorithm_type: Int): Algorithm? {
            for (item in algMap) {
                if (item.value.algorithm_type == algorithm_type) {
                    return item.value
                }
            }
            return null
        }

        init {
            val NONE = Algorithm(name = "NONE")

            val SHA256_RSA2048 = Algorithm(
                    algorithm_type = 1,
                    name = "SHA256_RSA2048",
                    hash_name = "sha256",
                    hash_num_bytes = 32,
                    signature_num_bytes = 256,
                    public_key_num_bytes = 8 + 2 * 2048 / 8,
                    padding = Struct("2b202x1b19B").pack(
                            byteArrayOf(0x00, 0x01),
                            0xff,
                            byteArrayOf(0x00),
                            intArrayOf(0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                                    0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                                    0x00, 0x04, 0x20)),
                    defaultKey = "aosp/avb/data/testkey_rsa2048.pem")

            val SHA256_RSA4096 = Algorithm(
                    name = "SHA256_RSA4096",
                    algorithm_type = 2,
                    hash_name = "sha256",
                    hash_num_bytes = 32,
                    signature_num_bytes = 512,
                    public_key_num_bytes = 8 + 2 * 4096 / 8,
                    padding = Struct("2b458x1x19B").pack(
                            byteArrayOf(0x00, 0x01),
                            0xff,
                            0x00,
                            intArrayOf(0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                                    0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                                    0x00, 0x04, 0x20)
                    ),
                    defaultKey = "aosp/avb/data/testkey_rsa4096.pem"
            )

            val SHA256_RSA8192 = Algorithm(
                    name = "SHA256_RSA8192",
                    algorithm_type = 3,
                    hash_name = "sha256",
                    hash_num_bytes = 32,
                    signature_num_bytes = 1024,
                    public_key_num_bytes = 8 + 2 * 8192 / 8,
                    padding = Struct("2b970x1x19B").pack(
                            intArrayOf(0x00, 0x01),
                            0xff,
                            0x00,
                            intArrayOf(0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                                    0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
                                    0x00, 0x04, 0x20)),
                    defaultKey = "aosp/avb/data/testkey_rsa8192.pem")

            val SHA512_RSA2048 = Algorithm(
                    name = "SHA512_RSA2048",
                    algorithm_type = 4,
                    hash_name = "sha512",
                    hash_num_bytes = 64,
                    signature_num_bytes = 256,
                    public_key_num_bytes = 8 + 2 * 2048 / 8,
                    padding = Struct("2b170x1x19B").pack(
                            intArrayOf(0x00, 0x01),
                            0xff,
                            0x00,
                            intArrayOf(0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                                    0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                                    0x00, 0x04, 0x40)),
                    defaultKey = "aosp/avb/data/testkey_rsa2048.pem")

            val SHA512_RSA4096 = Algorithm(
                    name = "SHA512_RSA4096",
                    algorithm_type = 5,
                    hash_name = "sha512",
                    hash_num_bytes = 64,
                    signature_num_bytes = 512,
                    public_key_num_bytes = 8 + 2 * 4096 / 8,
                    padding = Struct("2b426x1x19B").pack(
                            intArrayOf(0x00, 0x01),
                            0xff,
                            0x00,
                            intArrayOf(0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                                    0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                                    0x00, 0x04, 0x40)),
                    defaultKey = "aosp/avb/data/testkey_rsa4096.pem")

            val SHA512_RSA8192 = Algorithm(
                    name = "SHA512_RSA8192",
                    algorithm_type = 6,
                    hash_name = "sha512",
                    hash_num_bytes = 64,
                    signature_num_bytes = 1024,
                    public_key_num_bytes = 8 + 2 * 8192 / 8,

                    padding = Struct("2b938x1x19B").pack(
                            intArrayOf(0x00, 0x01),
                            0xff,
                            0x00,
                            intArrayOf(0x30, 0x51, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
                                    0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03, 0x05,
                                    0x00, 0x04, 0x40)),
                    defaultKey = "aosp/avb/data/testkey_rsa8192.pem")

            algMap[NONE.name] = NONE

            algMap[SHA256_RSA2048.name] = SHA256_RSA2048
            algMap[SHA256_RSA4096.name] = SHA256_RSA4096
            algMap[SHA256_RSA8192.name] = SHA256_RSA8192

            algMap[SHA512_RSA2048.name] = SHA512_RSA2048
            algMap[SHA512_RSA4096.name] = SHA512_RSA4096
            algMap[SHA512_RSA8192.name] = SHA512_RSA8192
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/blob/AuthBlob.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.blob

import avb.alg.Algorithms
import cfig.helper.CryptoHelper
import cfig.helper.Helper
import cc.cfig.io.Struct
import org.slf4j.LoggerFactory
import java.nio.file.Files
import java.nio.file.Paths
import java.security.MessageDigest
import java.security.PrivateKey

data class AuthBlob(
    var offset: Long = 0,
    var size: Long = 0,
    var hash: String? = null,
    var signature: String? = null
) {
    companion object {
        fun calcHash(
            header_data_blob: ByteArray,
            aux_data_blob: ByteArray,
            algorithm_name: String
        ): ByteArray {
            val alg = Algorithms.get(algorithm_name)!!
            return if (alg.name == "NONE") {
                log.debug("calc hash: NONE")
                byteArrayOf()
            } else {
                MessageDigest.getInstance(CryptoHelper.Hasher.pyAlg2java(alg.hash_name)).apply {
                    update(header_data_blob)
                    update(aux_data_blob)
                }.digest().apply {
                    log.debug("calc hash = " + Helper.toHexString(this))
                }
            }
        }

        private fun calcSignature(hash: ByteArray, algorithm_name: String): ByteArray {
            val alg = Algorithms.get(algorithm_name)!!
            return if (alg.name == "NONE") {
                byteArrayOf()
            } else {
                val k = CryptoHelper.KeyBox.parse4(Files.readAllBytes(Paths.get(alg.defaultKey.replace(".pem", ".pk8"))))
                CryptoHelper.Signer.rawRsa(k.key as PrivateKey, Helper.join(alg.padding, hash))
            }
        }

        fun createBlob(
            header_data_blob: ByteArray,
            aux_data_blob: ByteArray,
            algorithm_name: String
        ): ByteArray {
            val alg = Algorithms.get(algorithm_name)!!
            val authBlockSize = Helper.round_to_multiple((alg.hash_num_bytes + alg.signature_num_bytes).toLong(), 64)
            if (0L == authBlockSize) {
                log.info("No auth blob for algorithm " + alg.name)
                return byteArrayOf()
            }

            //hash & signature
            val binaryHash = calcHash(header_data_blob, aux_data_blob, algorithm_name)
            val binarySignature = calcSignature(binaryHash, algorithm_name)
            val authData = Helper.join(binaryHash, binarySignature)
            return Helper.join(authData, Struct("${authBlockSize - authData.size}x").pack(0))
        }

        private val log = LoggerFactory.getLogger(AuthBlob::class.java)
    }
}

```

`bbootimg/src/main/kotlin/avb/blob/AuxBlob.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.blob

import avb.alg.Algorithm
import avb.desc.*
import cc.cfig.io.Struct
import cfig.helper.CryptoHelper
import cfig.helper.Helper
import com.fasterxml.jackson.annotation.JsonIgnoreProperties
import org.bouncycastle.asn1.pkcs.RSAPrivateKey
import org.slf4j.LoggerFactory
import java.io.File

@JsonIgnoreProperties("descriptorSize")
class AuxBlob(
    var pubkey: PubKeyInfo? = null,
    var pubkeyMeta: PubKeyMetadataInfo? = null,
    var propertyDescriptors: MutableList<PropertyDescriptor> = mutableListOf(),
    var hashTreeDescriptors: MutableList<HashTreeDescriptor> = mutableListOf(),
    var hashDescriptors: MutableList<HashDescriptor> = mutableListOf(),
    var kernelCmdlineDescriptors: MutableList<KernelCmdlineDescriptor> = mutableListOf(),
    var chainPartitionDescriptors: MutableList<ChainPartitionDescriptor> = mutableListOf(),
    var unknownDescriptors: MutableList<UnknownDescriptor> = mutableListOf()
) {

    val descriptorSize: Int
        get(): Int {
            return this.encodeDescriptors().size
        }

    data class PubKeyInfo(
        var offset: Long = 0L,
        var size: Long = 0L,
        var pubkey: ByteArray = byteArrayOf()
    )

    data class PubKeyMetadataInfo(
        var offset: Long = 0L,
        var size: Long = 0L,
        var pkmd: ByteArray = byteArrayOf()
    )

    private fun encodeDescriptors(): ByteArray {
        return mutableListOf<Descriptor>().let { descList ->
            arrayOf(
                this.propertyDescriptors,        //tag 0
                this.hashTreeDescriptors,        //tag 1
                this.hashDescriptors,            //tag 2
                this.kernelCmdlineDescriptors,   //tag 3
                this.chainPartitionDescriptors,  //tag 4
                this.unknownDescriptors          //tag X
            ).forEach { typedList ->
                typedList.forEach { descList.add(it) }
            }
            var ret = byteArrayOf()
            descList.sortBy { it.sequence }
            descList.forEach { ret = Helper.join(ret, it.encode()) }
            ret
        }
    }

    //encoded_descriptors + encoded_key + pkmd_blob + (padding)
    fun encode(alg: Algorithm): ByteArray {
        //descriptors
        val encodedDesc = this.encodeDescriptors()
        //pubkey
        val encodedKey = encodePubKey(alg)
        if (this.pubkey != null) {
            if (encodedKey.contentEquals(this.pubkey!!.pubkey)) {
                log.info("Using the same key as original vbmeta")
            } else {
                log.warn("Using different key from original vbmeta")
            }
        } else {
            log.info("no pubkey in auxBlob")
        }
        //pkmd
        var encodedPkmd = byteArrayOf()
        if (this.pubkeyMeta != null) {
            encodedPkmd = this.pubkeyMeta!!.pkmd
            log.warn("adding pkmd [size=${this.pubkeyMeta!!.pkmd.size}]...")
        } else {
            log.info("no pubkey metadata in auxBlob")
        }

        val auxSize = Helper.round_to_multiple(
            (encodedDesc.size + encodedKey.size + encodedPkmd.size).toLong(),
            64
        )
        return Struct("${auxSize}b").pack(Helper.join(encodedDesc, encodedKey, encodedPkmd))
    }

    fun populateDescriptors(descriptors: List<Descriptor>): AuxBlob {
        descriptors.forEach {
            log.debug(it.toString())
            when (it) {
                is PropertyDescriptor -> {
                    this.propertyDescriptors.add(it)
                }
                is HashDescriptor -> {
                    this.hashDescriptors.add(it)
                }
                is KernelCmdlineDescriptor -> {
                    this.kernelCmdlineDescriptors.add(it)
                }
                is HashTreeDescriptor -> {
                    this.hashTreeDescriptors.add(it)
                }
                is ChainPartitionDescriptor -> {
                    this.chainPartitionDescriptors.add(it)
                }
                is UnknownDescriptor -> {
                    this.unknownDescriptors.add(it)
                }
                else -> {
                    throw IllegalArgumentException("invalid descriptor: $it")
                }
            }
        }
        return this
    }

    companion object {
        fun encodePubKey(alg: Algorithm, key: ByteArray? = null): ByteArray {
            var encodedKey = byteArrayOf()
            if (alg.public_key_num_bytes > 0) {
                val algKey: ByteArray = key ?: File(alg.defaultKey).readBytes()
                val rsa = CryptoHelper.KeyBox.parse4(algKey).key as RSAPrivateKey //BC RSA
                encodedKey = CryptoHelper.KeyBox.encodeRSAkey(rsa)
                check(alg.public_key_num_bytes == encodedKey.size)
            } else {
                log.info("encodePubKey(): No key to encode for algorithm " + alg.name)
            }
            return encodedKey
        }

        private val log = LoggerFactory.getLogger(AuxBlob::class.java)
    }
}

```

`bbootimg/src/main/kotlin/avb/blob/Footer.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.blob

import cc.cfig.io.Struct
import java.io.ByteArrayInputStream
import java.io.File
import java.io.FileInputStream
import java.io.InputStream

/*
https://github.com/cfig/Android_boot_image_editor/blob/master/doc/layout.md#32-avb-footer-vboot-20

+---------------------------------------+-------------------------+ --> partition_size - block_size
| Padding                               | block_size - 64         |
+---------------------------------------+-------------------------+ --> partition_size - 64
| AVB Footer                            | total 64                |
|                                       |                         |
|   - Footer Magic "AVBf"               |     4                   |
|   - Footer Major Version              |     4                   |
|   - Footer Minor Version              |     4                   |
|   - Original image size               |     8                   |
|   - VBMeta offset                     |     8                   |
|   - VBMeta size                       |     8                   |
|   - Padding                           |     28                  |
+---------------------------------------+-------------------------+ --> partition_size
 */

data class Footer constructor(
        var versionMajor: Int = FOOTER_VERSION_MAJOR,
        var versionMinor: Int = FOOTER_VERSION_MINOR,
        var originalImageSize: Long = 0,
        var vbMetaOffset: Long = 0,
        var vbMetaSize: Long = 0
) {
    @Throws(IllegalArgumentException::class)
    constructor(iS: InputStream) : this() {
        val info = Struct(FORMAT_STRING).unpack(iS)
        check(7 == info.size)
        if (MAGIC != (info[0] as String)) {
            throw IllegalArgumentException("stream doesn't look like valid AVB Footer")
        }
        versionMajor = (info[1] as UInt).toInt()
        versionMinor = (info[2] as UInt).toInt()
        originalImageSize = (info[3] as ULong).toLong()
        vbMetaOffset = (info[4] as ULong).toLong()
        vbMetaSize = (info[5] as ULong).toLong()
    }

    @Throws(IllegalArgumentException::class)
    constructor(data: ByteArray) : this(ByteArrayInputStream(data))

    constructor(originalImageSize: Long, vbMetaOffset: Long, vbMetaSize: Long)
            : this(FOOTER_VERSION_MAJOR, FOOTER_VERSION_MINOR, originalImageSize, vbMetaOffset, vbMetaSize)

    @Throws(IllegalArgumentException::class)
    constructor(image_file: String) : this() {
        FileInputStream(image_file).use { fis ->
            fis.skip(File(image_file).length() - SIZE)
            val footer = Footer(fis)
            this.versionMajor = footer.versionMajor
            this.versionMinor = footer.versionMinor
            this.originalImageSize = footer.originalImageSize
            this.vbMetaOffset = footer.vbMetaOffset
            this.vbMetaSize = footer.vbMetaSize
        }
    }

    fun encode(): ByteArray {
        return Struct(FORMAT_STRING).pack(MAGIC, //4s
                this.versionMajor,                //L
                this.versionMinor,                //L
                this.originalImageSize,           //Q
                this.vbMetaOffset,                //Q
                this.vbMetaSize,                  //Q
                null)                             //${RESERVED}x
    }

    companion object {
        private const val MAGIC = "AVBf"
        const val SIZE = 64
        private const val RESERVED = 28
        private const val FOOTER_VERSION_MAJOR = 1
        private const val FOOTER_VERSION_MINOR = 0
        private const val FORMAT_STRING = "!4s2L3Q${RESERVED}x"

        init {
            check(SIZE == Struct(FORMAT_STRING).calcSize())
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/blob/Header.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.blob

import cfig.Avb
import cc.cfig.io.Struct
import java.io.ByteArrayInputStream
import java.io.InputStream

//avbtool::AvbVBMetaHeader
data class Header(
        var required_libavb_version_major: Int = Avb.AVB_VERSION_MAJOR,
        var required_libavb_version_minor: Int = 0,
        var authentication_data_block_size: Long = 0,
        var auxiliary_data_block_size: Long = 0,
        var algorithm_type: Int = 0,
        var hash_offset: Long = 0,
        var hash_size: Long = 0,
        var signature_offset: Long = 0,
        var signature_size: Long = 0,
        var public_key_offset: Long = 0,
        var public_key_size: Long = 0,
        var public_key_metadata_offset: Long = 0,
        var public_key_metadata_size: Long = 0,
        var descriptors_offset: Long = 0,
        var descriptors_size: Long = 0,
        var rollback_index: Long = 0,
        var flags: Int = 0,
        var release_string: String = "avbtool ${Avb.AVB_VERSION_MAJOR}.${Avb.AVB_VERSION_MINOR}.${Avb.AVB_VERSION_SUB}") {
    @Throws(IllegalArgumentException::class)
    constructor(iS: InputStream) : this() {
        val info = Struct(FORMAT_STRING).unpack(iS)
        check(22 == info.size)
        if (info[0] != magic) {
            throw IllegalArgumentException("stream doesn't look like valid VBMeta Header")
        }
        this.required_libavb_version_major = (info[1] as UInt).toInt()
        this.required_libavb_version_minor = (info[2] as UInt).toInt()
        this.authentication_data_block_size = (info[3] as ULong).toLong()
        this.auxiliary_data_block_size = (info[4] as ULong).toLong()
        this.algorithm_type = (info[5] as UInt).toInt()
        this.hash_offset = (info[6] as ULong).toLong()
        this.hash_size = (info[7] as ULong).toLong()
        this.signature_offset = (info[8] as ULong).toLong()
        this.signature_size = (info[9] as ULong).toLong()
        this.public_key_offset = (info[10] as ULong).toLong()
        this.public_key_size = (info[11] as ULong).toLong()
        this.public_key_metadata_offset = (info[12] as ULong).toLong()
        this.public_key_metadata_size = (info[13] as ULong).toLong()
        this.descriptors_offset = (info[14] as ULong).toLong()
        this.descriptors_size = (info[15] as ULong).toLong()
        this.rollback_index = (info[16] as ULong).toLong()
        this.flags = (info[17] as UInt).toInt()
        //padding: info[18]
        this.release_string = info[19] as String
    }

    @Throws(IllegalArgumentException::class)
    constructor(data: ByteArray) : this(ByteArrayInputStream(data))

    fun encode(): ByteArray {
        return Struct(FORMAT_STRING).pack(
                magic,                                                                  //4s
                this.required_libavb_version_major, this.required_libavb_version_minor, //2L
                this.authentication_data_block_size, this.auxiliary_data_block_size,    //2Q
                this.algorithm_type,                                                    //L
                this.hash_offset, this.hash_size,                                       //hash 2Q
                this.signature_offset, this.signature_size,                             //sig 2Q
                this.public_key_offset, this.public_key_size,                           //pubkey 2Q
                this.public_key_metadata_offset, this.public_key_metadata_size,         //pkmd 2Q
                this.descriptors_offset, this.descriptors_size,                         //desc 2Q
                this.rollback_index,                                                    //Q
                this.flags,                                                             //L
                null,                                                                   //${REVERSED0}x
                this.release_string,                                                    //47s
                null,                                                                   //x
                null)                                                                   //${REVERSED}x
    }

    fun bump_required_libavb_version_minor(minor: Int) {
        this.required_libavb_version_minor = maxOf(required_libavb_version_minor, minor)
    }

    //toplevel flags
    enum class AvbVBMetaImageFlags(val inFlags: Int) {
        AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED(1),          //disable hashtree image verification, for system/vendor/product etc.
        AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED(2 shl 1) //disable all verification, do not parse descriptors
    }

    //verify flags
    enum class AvbSlotVerifyFlags(val inFlags: Int) {
        AVB_SLOT_VERIFY_FLAGS_NONE(0),
        AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR(1),
        AVB_SLOT_VERIFY_FLAGS_RESTART_CAUSED_BY_HASHTREE_CORRUPTION(2),
        AVB_SLOT_VERIFY_FLAGS_NO_VBMETA_PARTITION(4)
    }

    //hash descriptor flags
    enum class HashDescriptorFlags(val inFlags: Int) {
        AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB(1)
    }

    //hash tree descriptor flags
    enum class HashTreeDescriptorFlags(val inFlags: Int) {
        AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB(1)
    }

    companion object {
        private const val magic: String = "AVB0"
        const val SIZE = 256
        private const val REVERSED0 = 4
        private const val REVERSED = 80
        private const val FORMAT_STRING = ("!4s2L2QL11QL${REVERSED0}x47sx" + "${REVERSED}x")

        init {
            check(SIZE == Struct(FORMAT_STRING).calcSize())
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/desc/ChainPartitionDescriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import avb.AVBInfo
import cfig.Avb
import cfig.helper.Helper
import cfig.helper.Dumpling
import cc.cfig.io.Struct
import java.io.File
import java.io.InputStream
import java.security.MessageDigest
import org.slf4j.LoggerFactory

class ChainPartitionDescriptor(
        var rollback_index_location: Int = 0,
        var partition_name_len: Int = 0,
        var public_key_len: Int = 0,
        var partition_name: String = "",
        var pubkey: ByteArray = byteArrayOf(),
        var pubkey_sha1: String = ""
) : Descriptor(TAG, 0, 0) {
    override fun encode(): ByteArray {
        this.partition_name_len = this.partition_name.length
        this.public_key_len = this.pubkey.size
        this.num_bytes_following = SIZE + this.partition_name_len + this.public_key_len - 16
        val nbf_with_padding = Helper.round_to_multiple(this.num_bytes_following, 8).toULong()
        val padding_size = nbf_with_padding - this.num_bytes_following.toUInt()
        val desc = Struct(FORMAT_STRING + "${RESERVED}x").pack(
                TAG,
                nbf_with_padding,
                this.rollback_index_location,
                this.partition_name.length.toUInt(),
                this.public_key_len,
                null)
        val padding = Struct("${padding_size}x").pack(null)
        return Helper.join(desc, this.partition_name.toByteArray(), this.pubkey, padding)
    }

    companion object {
        const val TAG: Long = 4L
        const val RESERVED = 64
        const val SIZE = 28L + RESERVED
        const val FORMAT_STRING = "!2Q3L"
        private val log = LoggerFactory.getLogger(ChainPartitionDescriptor::class.java)
    }

    constructor(data: InputStream, seq: Int = 0) : this() {
        if (SIZE - RESERVED != Struct(FORMAT_STRING).calcSize().toLong()) {
            throw RuntimeException("ChainPartitionDescriptor size check failed")
        }
        this.sequence = seq
        val info = Struct(FORMAT_STRING + "${RESERVED}s").unpack(data)
        this.tag = (info[0] as ULong).toLong()
        this.num_bytes_following = (info[1] as ULong).toLong()
        this.rollback_index_location = (info[2] as UInt).toInt()
        this.partition_name_len = (info[3] as UInt).toInt()
        this.public_key_len = (info[4] as UInt).toInt()
        val expectedSize = Helper.round_to_multiple(SIZE - 16 + this.partition_name_len + this.public_key_len, 8)
        if (this.tag != TAG || this.num_bytes_following != expectedSize) {
            throw IllegalArgumentException("Given data does not look like a chain/delegation descriptor")
        }
        val info2 = Struct("${this.partition_name_len}s${this.public_key_len}b").unpack(data)
        this.partition_name = info2[0] as String
        this.pubkey = info2[1] as ByteArray
        val md = MessageDigest.getInstance("SHA1").let {
            it.update(this.pubkey)
            it.digest()
        }
        this.pubkey_sha1 = Helper.toHexString(md)
    }

    fun verify(image_files: List<String>, parent: String = ""): Array<Any> {
        val ret: Array<Any> = arrayOf(false, "file not found")
        for (item in image_files) {
            if (File(item).exists()) {
                val subAi = AVBInfo.parseFrom(Dumpling(item))
                if (pubkey.contentEquals(subAi.auxBlob!!.pubkey!!.pubkey)) {
                    log.info("VERIFY($parent): public key matches, PASS")
                    return Avb.verify(subAi, Dumpling(item), parent)
                } else {
                    log.info("VERIFY($parent): public key mismatch, FAIL")
                    ret[1] = "public key mismatch"
                    return ret
                }
            }
        }
        log.info("VERIFY($parent): " + ret[1] as String + "... FAIL")
        return ret
    }

    override fun toString(): String {
        return "ChainPartitionDescriptor(partition=${this.partition_name}, pubkey=${this.pubkey.contentToString()}"
    }
}

```

`bbootimg/src/main/kotlin/avb/desc/Descriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

abstract class Descriptor(var tag: Long, var num_bytes_following: Long, var sequence: Int = 0) {
    abstract fun encode(): ByteArray
}

```

`bbootimg/src/main/kotlin/avb/desc/HashDescriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import avb.blob.Header
import cfig.helper.Helper
import cc.cfig.io.Struct
import cfig.helper.CryptoHelper.Hasher
import org.apache.commons.codec.binary.Hex
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.InputStream
import java.security.MessageDigest

class HashDescriptor(var flags: Int = 0,
                     var partition_name: String = "",
                     var hash_algorithm: String = "",
                     var image_size: Long = 0,
                     var salt: ByteArray = byteArrayOf(),
                     var digest: ByteArray = byteArrayOf(),
                     var partition_name_len: Int = 0,
                     var salt_len: Int = 0,
                     var digest_len: Int = 0)
    : Descriptor(TAG, 0, 0) {
    var flagsInterpretation: String = ""
        get() {
            return if (this.flags and Header.HashDescriptorFlags.AVB_HASH_DESCRIPTOR_FLAGS_DO_NOT_USE_AB.inFlags == 1) {
                "1:no-A/B system"
            } else {
                "0:A/B system"
            }
        }

    constructor(data: InputStream, seq: Int = 0) : this() {
        val info = Struct(FORMAT_STRING).unpack(data)
        this.tag = (info[0] as ULong).toLong()
        this.num_bytes_following = (info[1] as ULong).toLong()
        this.image_size = (info[2] as ULong).toLong()
        this.hash_algorithm = info[3] as String
        this.partition_name_len = (info[4] as UInt).toInt()
        this.salt_len = (info[5] as UInt).toInt()
        this.digest_len = (info[6] as UInt).toInt()
        this.flags = (info[7] as UInt).toInt()
        this.sequence = seq
        val expectedSize = Helper.round_to_multiple(
                SIZE - 16 + (partition_name_len + salt_len + digest_len).toLong(), 8)
        if (this.tag != TAG || expectedSize != this.num_bytes_following) {
            throw IllegalArgumentException("Given data does not look like a |hash| descriptor")
        }
        val payload = Struct("${this.partition_name_len}s${this.salt_len}b${this.digest_len}b").unpack(data)
        check(3 == payload.size)
        this.partition_name = payload[0] as String
        this.salt = payload[1] as ByteArray
        this.digest = payload[2] as ByteArray
    }

    override fun encode(): ByteArray {
        val payload_bytes_following = SIZE + this.partition_name.length + this.salt.size + this.digest.size - 16L
        this.num_bytes_following = Helper.round_to_multiple(payload_bytes_following, 8)
        val padding_size = num_bytes_following - payload_bytes_following
        val desc = Struct(FORMAT_STRING).pack(
                TAG,
                this.num_bytes_following,
                this.image_size,
                this.hash_algorithm,
                this.partition_name.length,
                this.salt.size,
                this.digest.size,
                this.flags,
                null)
        val padding = Struct("${padding_size}x").pack(null)
        return Helper.join(desc, partition_name.toByteArray(), this.salt, this.digest, padding)
    }

    fun verify(image_files: List<String>, parent: String = ""): Array<Any> {
        val ret: Array<Any> = arrayOf(false, "file not found")
        for (item in image_files) {
            if (File(item).exists()) {
                val hasher = MessageDigest.getInstance(Hasher.pyAlg2java(hash_algorithm))
                hasher.update(this.salt)
                FileInputStream(item).use { fis ->
                    val data = ByteArray(this.image_size.toInt())
                    fis.read(data)
                    hasher.update(data)
                }
                val dg = hasher.digest()
                if (dg.contentEquals(this.digest)) {
                    ret[0] = true
                    ret[1] = "PASS"
                } else {
                    ret[1] = "hash mismatch"
                }
                return ret
            }
        }
        return ret
    }

    fun update(image_file: String, use_persistent_digest: Boolean = false): HashDescriptor {
        //salt
        if (this.salt.isEmpty()) {
            //If salt is not explicitly specified, choose a hash that's the same size as the hash size
            val expectedDigestSize = MessageDigest.getInstance(Hasher.pyAlg2java(hash_algorithm)).digest().size
            FileInputStream(File("/dev/urandom")).use {
                val randomSalt = ByteArray(expectedDigestSize)
                it.read(randomSalt)
                log.warn("salt is empty, using random salt[$expectedDigestSize]: " + Helper.toHexString(randomSalt))
                this.salt = randomSalt
                this.salt_len = this.salt.size
            }
        } else {
            log.info("preset salt[${this.salt.size}] is valid: ${Hex.encodeHexString(this.salt)}")
        }

        //size
        this.image_size = File(image_file).length()

        //flags
        if (this.flags and 1 == 1) {
            log.info("flag: use_ab = 0")
        } else {
            log.info("flag: use_ab = 1")
        }

        if (!use_persistent_digest) {
            //hash digest
            val newDigest = MessageDigest.getInstance(Hasher.pyAlg2java(hash_algorithm)).apply {
                update(salt)
                update(File(image_file).readBytes())
            }.digest()
            log.info("Digest(salt + file): " + Helper.toHexString(newDigest))
            this.digest = newDigest
            this.digest_len = this.digest.size
        }

        return this
    }

    companion object {
        const val TAG: Long = 2L
        private const val RESERVED = 60
        private const val SIZE = 72 + RESERVED
        private const val FORMAT_STRING = "!3Q32s4L${RESERVED}x"
        private val log = LoggerFactory.getLogger(HashDescriptor::class.java)
    }

    override fun toString(): String {
        return "HashDescriptor(TAG=$TAG, image_size=$image_size, hash_algorithm=$hash_algorithm, flags=$flags, partition_name='$partition_name', salt=${Helper.toHexString(salt)}, digest=${Helper.toHexString(digest)})"
    }
}

```

`bbootimg/src/main/kotlin/avb/desc/HashTreeDescriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import avb.blob.Header
import cfig.helper.CryptoHelper
import cfig.helper.Helper
import cfig.helper.Dumpling
import cc.cfig.io.Struct
import org.slf4j.LoggerFactory
import java.io.*
import java.security.MessageDigest
import java.util.*

class HashTreeDescriptor(
    var flags: Int = 0,
    var dm_verity_version: Int = 0,
    var image_size: Long = 0,
    var tree_offset: Long = 0,
    var tree_size: Long = 0,
    var data_block_size: Int = 0,
    var hash_block_size: Int = 0,
    var fec_num_roots: Int = 0,
    var fec_offset: Long = 0,
    var fec_size: Long = 0,
    var hash_algorithm: String = "",
    var partition_name: String = "",
    var salt: ByteArray = byteArrayOf(),
    var root_digest: ByteArray = byteArrayOf()
) : Descriptor(TAG, 0, 0) {
    var flagsInterpretation: String = ""
        get() {
            var ret = ""
            if (this.flags and Header.HashTreeDescriptorFlags.AVB_HASHTREE_DESCRIPTOR_FLAGS_DO_NOT_USE_AB.inFlags == 1) {
                ret += "1:no-A/B system"
            } else {
                ret += "0:A/B system"
            }
            return ret
        }

    constructor(data: InputStream, seq: Int = 0) : this() {
        this.sequence = seq
        val info = Struct(FORMAT_STRING).unpack(data)
        this.tag = (info[0] as ULong).toLong()
        this.num_bytes_following = (info[1] as ULong).toLong()
        this.dm_verity_version = (info[2] as UInt).toInt()
        this.image_size = (info[3] as ULong).toLong()
        this.tree_offset = (info[4] as ULong).toLong()
        this.tree_size = (info[5] as ULong).toLong()
        this.data_block_size = (info[6] as UInt).toInt()
        this.hash_block_size = (info[7] as UInt).toInt()
        this.fec_num_roots = (info[8] as UInt).toInt()
        this.fec_offset = (info[9] as ULong).toLong()
        this.fec_size = (info[10] as ULong).toLong()
        this.hash_algorithm = info[11] as String
        val partition_name_len = info[12] as UInt
        val salt_len = info[13] as UInt
        val root_digest_len = info[14] as UInt
        this.flags = (info[15] as UInt).toInt()
        val expectedSize =
            Helper.round_to_multiple(SIZE.toUInt() - 16U + partition_name_len + salt_len + root_digest_len, 8U)
        if (this.tag != TAG || this.num_bytes_following != expectedSize.toLong()) {
            throw IllegalArgumentException("Given data does not look like a hashtree descriptor")
        }

        val info2 = Struct("${partition_name_len}s${salt_len}b${root_digest_len}b").unpack(data)
        this.partition_name = info2[0] as String
        this.salt = info2[1] as ByteArray
        this.root_digest = info2[2] as ByteArray
    }

    override fun encode(): ByteArray {
        this.num_bytes_following = SIZE + this.partition_name.length + this.salt.size + this.root_digest.size - 16
        val nbf_with_padding = Helper.round_to_multiple(this.num_bytes_following.toLong(), 8)
        val padding_size = nbf_with_padding - this.num_bytes_following.toLong()
        val desc = Struct(FORMAT_STRING).pack(
            TAG,
            nbf_with_padding.toULong(),
            this.dm_verity_version,
            this.image_size,
            this.tree_offset,
            this.tree_size,
            this.data_block_size,
            this.hash_block_size,
            this.fec_num_roots,
            this.fec_offset,
            this.fec_size,
            this.hash_algorithm,
            this.partition_name.length,
            this.salt.size,
            this.root_digest.size,
            this.flags,
            null
        )
        val padding = Struct("${padding_size}x").pack(null)
        return Helper.join(desc, this.partition_name.toByteArray(), this.salt, this.root_digest, padding)
    }

    fun verify(fileNames: List<String>, parent: String = ""): Array<Any> {
        for (item in fileNames) {
            if (File(item).exists()) {
                val trimmedHash = this.genMerkleTree(item, "hash.tree")
                val readTree = Dumpling(item).readFully(Pair(this.tree_offset, this.tree_size.toInt()))
                val ourHtHash = CryptoHelper.Hasher.sha256(File("hash.tree").readBytes())
                val diskHtHash = CryptoHelper.Hasher.sha256(readTree)
                if (!ourHtHash.contentEquals(diskHtHash)) {
                    return arrayOf(false, "MerkleTree corrupted")
                } else {
                    log.info("VERIFY($parent): MerkleTree integrity check... PASS")
                }
                if (!this.root_digest.contentEquals(trimmedHash)) {
                    return arrayOf(false, "MerkleTree root hash mismatch")
                } else {
                    log.info("VERIFY($parent): MerkleTree root hash check... PASS")
                }
                return arrayOf(true, "")
            }
        }
        return arrayOf(false, "file not found")
    }

    private fun calcSingleHashSize(padded: Boolean = false): Int {
        val digSize = MessageDigest.getInstance(CryptoHelper.Hasher.pyAlg2java(this.hash_algorithm)).digest().size
        val padSize = Helper.round_to_pow2(digSize.toLong()) - digSize
        return (digSize + (if (padded) padSize else 0)).toInt()
    }

    private fun calcStreamHashSize(inStreamSize: Long, inBlockSize: Int): Long {
        val blockCount = (inStreamSize + inBlockSize - 1) / inBlockSize
        return Helper.round_to_multiple(blockCount * calcSingleHashSize(true), inBlockSize.toLong())
    }

    fun hashStream(
        inputStream: InputStream,
        streamSz: Long,
        blockSz: Int
    ): ByteArray {
        val hashSize = calcStreamHashSize(streamSz, blockSz)
        val bos = ByteArrayOutputStream(hashSize.toInt())
        run hashing@{
            val padSz = calcSingleHashSize(true) - calcSingleHashSize(false)
            val padding = Struct("${padSz}x").pack(0)
            var totalRead = 0L
            while (true) {
                val data = ByteArray(blockSz)
                MessageDigest.getInstance(CryptoHelper.Hasher.pyAlg2java(this.hash_algorithm)).let {
                    val bytesRead = inputStream.read(data)
                    if (bytesRead <= 0) {
                        return@hashing
                    }
                    totalRead += bytesRead
                    if (totalRead > streamSz) {
                        return@hashing
                    }
                    it.update(this.salt)
                    it.update(data)
                    val dg = it.digest()
                    bos.write(dg)
                    bos.write(padding)
                    //log.info(Helper.toHexString(dg))
                }
            }
        }//hashing

        if (hashSize > bos.size()) {
            bos.write(Struct("${hashSize - bos.size()}x").pack(0))
        }
        return bos.toByteArray()
    }

    fun genMerkleTree(fileName: String, treeFile: String? = null): ByteArray {
        log.info("generate Merkle tree()")
        val plannedTree = calcMerkleTree(this.image_size, this.hash_block_size, calcSingleHashSize(true))
        val calcRootHash: ByteArray
        treeFile?.let { File(treeFile).let { if (it.exists()) it.delete() }}
        val raf = if (treeFile.isNullOrBlank()) null else RandomAccessFile(treeFile, "rw")
        val l0: ByteArray
        log.info("Hashing Level #${plannedTree.size}..." + plannedTree.get(plannedTree.size - 1))
        FileInputStream(fileName).use { fis ->
            l0 = hashStream(
                fis, this.image_size,
                this.data_block_size
            )
        }
        if (DEBUG) FileOutputStream("hash.file" + plannedTree.size).use { it.write(l0) }
        raf?.seek(plannedTree.get(plannedTree.size - 1).hashOffset)
        raf?.write(l0)
        var dataToHash: ByteArray = l0
        var i = plannedTree.size - 1
        while (true) {
            val levelHash = hashStream(dataToHash.inputStream(), dataToHash.size.toLong(), this.hash_block_size)
            if (DEBUG) FileOutputStream("hash.file$i").use { it.write(levelHash) }
            if (dataToHash.size <= this.hash_block_size) {
                log.debug("Got root hash: " + Helper.toHexString(levelHash))
                calcRootHash = levelHash
                break
            }
            log.info("Hashing Level #$i..." + plannedTree.get(i - 1))
            raf?.seek(plannedTree.get(i - 1).hashOffset)
            raf?.write(levelHash)
            dataToHash = levelHash
            i--
        }
        raf?.close()
        raf?.let { log.info("MerkleTree(${this.partition_name}) saved to $treeFile") }
        return calcRootHash.sliceArray(0 until calcSingleHashSize(false))
    }

    override fun toString(): String {
        return "HashTreeDescriptor(dm_verity_version=$dm_verity_version, image_size=$image_size, " +
                "tree_offset=$tree_offset, tree_size=$tree_size, data_block_size=$data_block_size, " +
                "hash_block_size=$hash_block_size, fec_num_roots=$fec_num_roots, fec_offset=$fec_offset, " +
                "fec_size=$fec_size, hash_algorithm='$hash_algorithm', partition_name='$partition_name', " +
                "salt=${salt.contentToString()}, root_digest=${Arrays.toString(root_digest)}, flags=$flags)"
    }

    companion object {
        const val TAG: Long = 1L
        private const val RESERVED = 60L
        private const val SIZE = 120 + RESERVED
        private const val FORMAT_STRING = "!2QL3Q3L2Q32s4L${RESERVED}x"
        private val log = LoggerFactory.getLogger(HashTreeDescriptor::class.java)
        private const val DEBUG = false

        class MerkleTree(
            var dataSize: Long = 0,
            var dataBlockCount: Long = 0,
            var hashSize: Long = 0,
            var hashOffset: Long = 0
        ) {
            override fun toString(): String {
                return String.format(Locale.getDefault(),
                    "MT{data: %10s(%6s blocks), hash: %7s @%-5s}",
                    dataSize,
                    dataBlockCount,
                    hashSize,
                    hashOffset
                )
            }
        }

        fun calcMerkleTree(fileSize: Long, blockSize: Int, digestSize: Int): List<MerkleTree> {
            var levelDataSize: Long = fileSize
            var levelNo = 0
            val tree: MutableList<MerkleTree> = mutableListOf()
            while (true) {
                //raw data in page of blockSize
                val blockCount = (levelDataSize + blockSize - 1) / blockSize
                if (1L == blockCount) {
                    break
                }
                //digest size in page of blockSize
                val hashSize = Helper.round_to_multiple(blockCount * digestSize, blockSize.toLong())
                tree.add(0, MerkleTree(levelDataSize, blockCount, hashSize))
                levelDataSize = hashSize
                levelNo++
            }
            for (i in 1 until tree.size) {
                tree[i].hashOffset = tree[i - 1].hashOffset + tree[i - 1].hashSize
            }
            tree.forEachIndexed { index, merkleTree ->
                log.info("Level #${index + 1}: $merkleTree")
            }
            val treeSize = tree.sumOf { it.hashSize }
            log.info("tree size: $treeSize(" + Helper.humanReadableByteCountBin(treeSize) + ")")
            return tree
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/desc/KernelCmdlineDescriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import cfig.helper.Helper
import cc.cfig.io.Struct
import java.io.InputStream

class KernelCmdlineDescriptor(
        var flags: Int = 0,
        var cmdlineLength: Int = 0,
        var cmdline: String = "")
    : Descriptor(TAG, 0, 0) {
    var flagsInterpretation: String = ""
        get() {
            var ret = ""
            if (this.flags and flagHashTreeEnabled == flagHashTreeEnabled) {
                ret += "$flagHashTreeEnabled: hashTree Enabled"
            } else if (this.flags and flagHashTreeDisabled == flagHashTreeDisabled) {
                ret += "$flagHashTreeDisabled: hashTree Disabled"
            }
            return ret
        }

    @Throws(IllegalArgumentException::class)
    constructor(data: InputStream, seq: Int = 0) : this() {
        val info = Struct(FORMAT_STRING).unpack(data)
        this.tag = (info[0] as ULong).toLong()
        this.num_bytes_following = (info[1] as ULong).toLong()
        this.flags = (info[2] as UInt).toInt()
        this.cmdlineLength = (info[3] as UInt).toInt()
        this.sequence = seq
        val expectedSize = Helper.round_to_multiple(SIZE - 16 + this.cmdlineLength, 8)
        if ((this.tag != TAG) || (this.num_bytes_following != expectedSize.toLong())) {
            throw IllegalArgumentException("Given data does not look like a kernel cmdline descriptor")
        }
        this.cmdline = Struct("${this.cmdlineLength}s").unpack(data)[0] as String
    }

    override fun encode(): ByteArray {
        val num_bytes_following = SIZE - 16 + cmdline.toByteArray().size
        val nbf_with_padding = Helper.round_to_multiple(num_bytes_following.toLong(), 8)
        val padding_size = nbf_with_padding - num_bytes_following
        val desc = Struct(FORMAT_STRING).pack(
                TAG,
                nbf_with_padding,
                this.flags,
                cmdline.length)
        val padding = Struct("${padding_size}x").pack(null)
        return Helper.join(desc, cmdline.toByteArray(), padding)
    }

    companion object {
        const val TAG: Long = 3L
        const val SIZE = 24
        const val FORMAT_STRING = "!2Q2L" //# tag, num_bytes_following (descriptor header), flags, cmdline length (bytes)
        //AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_NOT_DISABLED
        const val flagHashTreeEnabled = 1
        //AVB_KERNEL_CMDLINE_FLAGS_USE_ONLY_IF_HASHTREE_DISABLED
        const val flagHashTreeDisabled = 2

        init {
            check(SIZE == Struct(FORMAT_STRING).calcSize())
        }
    }
}

```

`bbootimg/src/main/kotlin/avb/desc/PropertyDescriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import cfig.helper.Helper
import cc.cfig.io.Struct
import java.io.InputStream

class PropertyDescriptor(
        var key: String = "",
        var value: String = "") : Descriptor(TAG, 0, 0) {
    override fun encode(): ByteArray {
        if (SIZE != Struct(FORMAT_STRING).calcSize().toUInt()) {
            throw RuntimeException("PropertyDesc size check failed")
        }
        this.num_bytes_following = (SIZE + this.key.length.toUInt() + this.value.length.toUInt() + 2U - 16U).toLong()
        val nbfWithPadding = Helper.round_to_multiple(this.num_bytes_following.toLong(), 8).toULong()
        val paddingSize = nbfWithPadding - num_bytes_following.toUInt()
        val padding = Struct("${paddingSize}x").pack(0)
        val desc = Struct(FORMAT_STRING).pack(
                TAG,
                nbfWithPadding,
                this.key.length,
                this.value.length)
        return Helper.join(desc,
                this.key.toByteArray(), ByteArray(1),
                this.value.toByteArray(), ByteArray(1),
                padding)
    }

    constructor(data: InputStream, seq: Int = 0) : this() {
        val info = Struct(FORMAT_STRING).unpack(data)
        this.tag = (info[0] as ULong).toLong()
        this.num_bytes_following = (info[1] as ULong).toLong()
        val keySize = (info[2] as ULong).toUInt()
        val valueSize = (info[3] as ULong).toUInt()
        val expectedSize = Helper.round_to_multiple(SIZE - 16U + keySize + 1U + valueSize + 1U, 8U)
        if (this.tag != TAG || expectedSize.toLong() != this.num_bytes_following) {
            throw IllegalArgumentException("Given data does not look like a |property| descriptor")
        }
        this.sequence = seq

        val info2 = Struct("${keySize}sx${valueSize}s").unpack(data)
        this.key = info2[0] as String
        this.value = info2[2] as String
    }

    companion object {
        const val TAG: Long = 0L
        const val SIZE = 32U
        const val FORMAT_STRING = "!4Q"
    }
}

```

`bbootimg/src/main/kotlin/avb/desc/UnknownDescriptor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import cc.cfig.io.Struct
import cfig.helper.Helper
import org.apache.commons.codec.binary.Hex
import org.slf4j.LoggerFactory
import java.io.ByteArrayInputStream
import java.io.InputStream

class UnknownDescriptor(var data: ByteArray = byteArrayOf()) : Descriptor(0, 0, 0) {
    @Throws(IllegalArgumentException::class)
    constructor(stream: InputStream, seq: Int = 0) : this() {
        this.sequence = seq
        val info = Struct(FORMAT).unpack(stream)
        this.tag = (info[0] as ULong).toLong()
        this.num_bytes_following = (info[1] as ULong).toLong()
        log.debug("UnknownDescriptor: tag = $tag, len = ${this.num_bytes_following}")
        this.data = ByteArray(this.num_bytes_following.toInt())
        if (this.num_bytes_following.toInt() != stream.read(data)) {
            throw IllegalArgumentException("descriptor SIZE mismatch")
        }
    }

    override fun encode(): ByteArray {
        return Helper.join(Struct(FORMAT).pack(this.tag, this.data.size.toLong()), data)
    }

    override fun toString(): String {
        return "UnknownDescriptor(tag=$tag, SIZE=${data.size}, data=${Hex.encodeHexString(data)}"
    }

    fun analyze(): Descriptor {
        return when (this.tag.toUInt()) {
            0U -> {
                PropertyDescriptor(ByteArrayInputStream(this.encode()), this.sequence)
            }
            1U -> {
                HashTreeDescriptor(ByteArrayInputStream(this.encode()), this.sequence)
            }
            2U -> {
                HashDescriptor(ByteArrayInputStream(this.encode()), this.sequence)
            }
            3U -> {
                KernelCmdlineDescriptor(ByteArrayInputStream(this.encode()), this.sequence)
            }
            4U -> {
                ChainPartitionDescriptor(ByteArrayInputStream(this.encode()), this.sequence)
            }
            else -> {
                this
            }
        }
    }

    companion object {
        private const val SIZE = 16
        private const val FORMAT = "!QQ"
        private val log = LoggerFactory.getLogger(UnknownDescriptor::class.java)

        fun parseDescriptors(stream: InputStream, totalSize: Long): List<Descriptor> {
            log.debug("Parse descriptors stream, SIZE = $totalSize")
            val ret: MutableList<Descriptor> = mutableListOf()
            var currentSize = 0L
            var seq = 0
            while (true) {
                val desc = UnknownDescriptor(stream, ++seq)
                currentSize += desc.data.size + SIZE
                log.debug("current SIZE = $currentSize")
                log.debug(desc.toString())
                ret.add(desc.analyze())
                if (currentSize == totalSize) {
                    log.debug("parse descriptor done")
                    break
                } else if (currentSize > totalSize) {
                    log.error("Read more than expected")
                    throw IllegalStateException("Read more than expected")
                } else {
                    log.debug(desc.toString())
                    log.debug("read another descriptor")
                }
            }
            return ret
        }

        init {
            check(SIZE == Struct(FORMAT).calcSize())
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/Common.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg

import cc.cfig.io.Struct
import cfig.utils.EnvironmentVerifier
import cfig.bootimg.cpio.AndroidCpio
import cfig.utils.DTC
import cfig.helper.Helper
import cfig.helper.ZipHelper
import cfig.utils.KernelExtractor
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.PumpStreamHandler
import org.slf4j.LoggerFactory
import java.io.ByteArrayInputStream
import java.io.ByteArrayOutputStream
import java.io.File
import java.nio.file.Files
import java.nio.file.Paths
import java.io.FileInputStream
import java.lang.NumberFormatException
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.security.MessageDigest
import java.util.*
import java.util.regex.Pattern

class Common {
    data class VeritySignature(
        var type: String = "dm-verity",
        var path: String = "/boot",
        var verity_pk8: String = "",
        var verity_pem: String = "",
        var jarPath: String = ""
    )

    companion object {
        private val log = LoggerFactory.getLogger(Common::class.java)
        private const val MAX_ANDROID_VER = 11

        @Throws(IllegalArgumentException::class)
        fun packOsVersion(x: String?): Int {
            if (x.isNullOrBlank()) return 0
            val pattern = Pattern.compile("^(\\d{1,3})(?:\\.(\\d{1,3})(?:\\.(\\d{1,3}))?)?")
            val m = pattern.matcher(x)
            if (m.find()) {
                val a = Integer.decode(m.group(1))
                var b = 0
                var c = 0
                if (m.groupCount() >= 2) {
                    b = Integer.decode(m.group(2))
                }
                if (m.groupCount() == 3) {
                    c = Integer.decode(m.group(3))
                }
                check(a < 128)
                check(b < 128)
                check(c < 128)
                return (a shl 14) or (b shl 7) or c
            } else {
                throw IllegalArgumentException("invalid os_version")
            }
        }

        fun parseOsVersion(x: Int): String {
            val a = x shr 14
            val b = x - (a shl 14) shr 7
            val c = x and 0x7f
            return String.format(Locale.getDefault(), "%d.%d.%d", a, b, c)
        }

        fun packOsPatchLevel(x: String?): Int {
            if (x.isNullOrBlank()) return 0
            val ret: Int
            val pattern = Pattern.compile("^(\\d{4})-(\\d{2})-(\\d{2})")
            val matcher = pattern.matcher(x)
            if (matcher.find()) {
                val y = Integer.parseInt(matcher.group(1), 10) - 2000
                val m = Integer.parseInt(matcher.group(2), 10)
                // 7 bits allocated for the year, 4 bits for the month
                check(y in 0..127)
                check(m in 1..12)
                ret = (y shl 4) or m
            } else {
                throw IllegalArgumentException("invalid os_patch_level")
            }

            return ret
        }

        fun parseOsPatchLevel(x: Int): String {
            var y = x shr 4
            val m = x and 0xf
            y += 2000
            return String.format("%d-%02d-%02d", y, m, 0)
        }

        fun parseKernelInfo(kernelFile: String): List<String> {
            KernelExtractor().let { ke ->
                if (ke.envCheck()) {
                    return ke.run(kernelFile, File("."))
                }
            }
            return listOf()
        }

        fun dumpKernel(s: Helper.Slice) {
            Helper.extractFile(s.srcFile, s.dumpFile, s.offset.toLong(), s.length)
            parseKernelInfo(s.dumpFile)
        }

        fun dumpRamdisk(s: Helper.Slice, root: String, unpackCpio: Boolean = true): String {
            var ret = "gz"
            Helper.extractFile(s.srcFile, s.dumpFile, s.offset.toLong(), s.length)
            when {
                ZipHelper.isGZ(s.dumpFile) -> {
                    Files.move(
                        Paths.get(s.dumpFile), Paths.get(s.dumpFile + ".gz"),
                        java.nio.file.StandardCopyOption.REPLACE_EXISTING
                    )
                    ZipHelper.zcat(s.dumpFile + ".gz", s.dumpFile)
                }
                ZipHelper.isXz(s.dumpFile) -> {
                    log.info("ramdisk is compressed xz")
                    Files.move(
                        Paths.get(s.dumpFile), Paths.get(s.dumpFile + ".xz"),
                        java.nio.file.StandardCopyOption.REPLACE_EXISTING
                    )
                    ZipHelper.xzcat(s.dumpFile + ".xz", s.dumpFile)
                    ret = "xz"
                }
                ZipHelper.isLzma(s.dumpFile) -> {
                    log.info("ramdisk is compressed lzma")
                    Files.move(
                            Paths.get(s.dumpFile), Paths.get(s.dumpFile + ".lzma"),
                            java.nio.file.StandardCopyOption.REPLACE_EXISTING
                    )
                    ZipHelper.lzcat(s.dumpFile + ".lzma", s.dumpFile)
                    ret = "lzma"
                }
                ZipHelper.isLz4(s.dumpFile) -> {
                    log.info("ramdisk is compressed lz4")
                    Files.move(
                        Paths.get(s.dumpFile), Paths.get(s.dumpFile + ".lz4"),
                        java.nio.file.StandardCopyOption.REPLACE_EXISTING
                    )
                    ZipHelper.lz4cat(s.dumpFile + ".lz4", s.dumpFile)
                    ret = "lz4"
                }
                ZipHelper.isAndroidCpio(s.dumpFile) -> {
                    log.info("ramdisk is uncompressed cpio")
                    Files.copy(
                        Paths.get(s.dumpFile), Paths.get(s.dumpFile + ".cpio"),
                        java.nio.file.StandardCopyOption.REPLACE_EXISTING
                    )
                    ret = "cpio"
                }
                else -> {
                    throw IllegalArgumentException("ramdisk is in unknown format")
                }
            }
            if (unpackCpio) {
                unpackRamdisk(s.dumpFile, root)
            }
            return ret
        }

        fun dumpDtb(s: Helper.Slice) {
            Helper.extractFile(s.srcFile, s.dumpFile, s.offset.toLong(), s.length)
            //extract DTB
            if (EnvironmentVerifier().hasDtc) {
                DTC().decompile(s.dumpFile, s.dumpFile + "." + Helper.prop("config.dts_suffix"))
            }
        }

        fun getPaddingSize(position: UInt, pageSize: UInt): UInt {
            return (pageSize - (position and pageSize - 1U)) and (pageSize - 1U)
        }

        fun getPaddingSize(position: Int, pageSize: Int): Int {
            return (pageSize - (position and pageSize - 1)) and (pageSize - 1)
        }

        @Throws(CloneNotSupportedException::class)
        fun hashFileAndSize(vararg inFiles: String?): ByteArray {
            val md = MessageDigest.getInstance("SHA1")
            for (item in inFiles) {
                if (null == item) {
                    md.update(
                        ByteBuffer.allocate(4).order(ByteOrder.LITTLE_ENDIAN)
                            .putInt(0)
                            .array()
                    )
                    log.debug("update null $item: " + Helper.toHexString((md.clone() as MessageDigest).digest()))
                } else {
                    val currentFile = File(item)
                    FileInputStream(currentFile).use { iS ->
                        var byteRead: Int
                        val dataRead = ByteArray(1024)
                        while (true) {
                            byteRead = iS.read(dataRead)
                            if (-1 == byteRead) {
                                break
                            }
                            md.update(dataRead, 0, byteRead)
                        }
                        log.debug("update file $item: " + Helper.toHexString((md.clone() as MessageDigest).digest()))
                        md.update(
                            ByteBuffer.allocate(4).order(ByteOrder.LITTLE_ENDIAN)
                                .putInt(currentFile.length().toInt())
                                .array()
                        )
                        log.debug("update SIZE $item: " + Helper.toHexString((md.clone() as MessageDigest).digest()))
                    }
                }
            }

            return md.digest()
        }

        //using mkbootfs
        fun packRootfs(rootDir: String, ramdiskGz: String, osMajor: Int = 10) {
            val mkbootfs = String.format(Locale.getDefault(), Helper.prop("mkbootfsBin"), osMajor)
            log.info("Packing rootfs $rootDir ...")
            val outputStream = ByteArrayOutputStream()
            DefaultExecutor().let { exec ->
                exec.streamHandler = PumpStreamHandler(outputStream)
                val cmdline = "$mkbootfs $rootDir"
                log.info("CMD: $cmdline -> PIPE -> $ramdiskGz")
                exec.execute(CommandLine.parse(cmdline))
            }
            when {
                ramdiskGz.endsWith(".gz") -> {
                    ZipHelper.minigzip(ramdiskGz, ByteArrayInputStream(outputStream.toByteArray()))
                }
                ramdiskGz.endsWith(".lz4") -> {
                    ZipHelper.lz4(ramdiskGz, ByteArrayInputStream(outputStream.toByteArray()))
                }
                else -> {
                    throw IllegalArgumentException("$ramdiskGz is not supported")
                }
            }
            log.info("$ramdiskGz is ready")
        }

        //using preset fs_config
        fun packRootfs(rootDir: String, ramdiskGz: String) {
            val root = File(rootDir).path
            log.info("Packing rootfs $root ...")
            when {
                ramdiskGz.endsWith(".gz") -> {
                    val f = ramdiskGz.removeSuffix(".gz")
                    AndroidCpio().pack(root, f, "${f}_filelist.txt")
                    FileInputStream(f).use { ZipHelper.minigzip(ramdiskGz, it) }
                }
                ramdiskGz.endsWith(".lz4") -> {
                    val f = ramdiskGz.removeSuffix(".lz4")
                    AndroidCpio().pack(root, f, "${f}_filelist.txt")
                    FileInputStream(f).use { ZipHelper.lz4(ramdiskGz, it) }
                }
                ramdiskGz.endsWith(".lzma") -> {
                    val f = ramdiskGz.removeSuffix(".lzma")
                    AndroidCpio().pack(root, f, "${f}_filelist.txt")
                    FileInputStream(f).use { ZipHelper.lzma(ramdiskGz, it) }
                }
                ramdiskGz.endsWith(".xz") -> {
                    val f = ramdiskGz.removeSuffix(".xz")
                    AndroidCpio().pack(root, f, "${f}_filelist.txt")
                    FileInputStream(f).use { ZipHelper.xz(ramdiskGz, it) }
                }
                ramdiskGz.endsWith(".cpio") -> {
                    val f = ramdiskGz.removeSuffix(".cpio")
                    AndroidCpio().pack(root, f, "${f}_filelist.txt")
                    File(f).copyTo(File(ramdiskGz), true)
                }
                else -> {
                    throw IllegalArgumentException("$ramdiskGz is not supported")
                }
            }
            log.info("$ramdiskGz is ready")
        }

        fun padFile(inBF: ByteBuffer, padding: Int) {
            val pad = padding - (inBF.position() and padding - 1) and padding - 1
            inBF.put(ByteArray(pad))
        }

        fun File.deleleIfExists() {
            if (this.exists()) {
                if (!this.isFile) {
                    throw IllegalStateException("${this.canonicalPath} should be regular file")
                }
                log.info("Deleting ${this.path} ...")
                this.delete()
            }
        }

        fun writePaddedFile(inBF: ByteBuffer, srcFile: String, padding: UInt) {
            log.info("adding $srcFile into buffer ...")
            check(padding < Int.MAX_VALUE.toUInt())
            writePaddedFile(inBF, srcFile, padding.toInt())
        }

        fun writePaddedFile(inBF: ByteBuffer, srcFile: String, padding: Int) {
            FileInputStream(srcFile).use { iS ->
                var byteRead: Int
                val dataRead = ByteArray(128)
                while (true) {
                    byteRead = iS.read(dataRead)
                    if (-1 == byteRead) {
                        break
                    }
                    inBF.put(dataRead, 0, byteRead)
                }
                padFile(inBF, padding)
            }
        }

        fun writePaddedFiles(inBF: ByteBuffer, srcFiles: List<String>, padding: Int) {
            srcFiles.forEach { srcFile ->
                FileInputStream(srcFile).use { iS ->
                    var byteRead: Int
                    val dataRead = ByteArray(128)
                    while (true) {
                        byteRead = iS.read(dataRead)
                        if (-1 == byteRead) {
                            break
                        }
                        inBF.put(dataRead, 0, byteRead)
                    }
                }
            }
            padFile(inBF, padding)
        }

        private fun unpackRamdisk(ramdisk: String, root: String) {
            val rootFile = File(root).apply {
                if (exists()) {
                    log.info("Cleaning [$root] before ramdisk unpacking")
                    deleteRecursively()
                }
                mkdirs()
            }

            AndroidCpio.decompressCPIO(
                File(ramdisk).canonicalPath,
                rootFile.canonicalPath,
                File(ramdisk).canonicalPath + "_filelist.txt"
            )
            log.info(" ramdisk extracted : $ramdisk -> $rootFile")
        }

        fun probeHeaderVersion(fileName: String): Int {
            return FileInputStream(fileName).let { fis ->
                fis.skip(40)
                Struct.IntShip().get(fis, ByteOrder.LITTLE_ENDIAN)
            }
        }

        fun parseOsMajor(osVersion: String): Int {
            return try {
                log.info("OS Major: " + osVersion.split(".")[0])
                val ret = Integer.parseInt(osVersion.split(".")[0])
                when {
                    ret > MAX_ANDROID_VER -> {
                        log.warn("Os Major exceeds current max $MAX_ANDROID_VER")
                        MAX_ANDROID_VER
                    }
                    ret < 10 -> {
                        10
                    }
                    else -> {
                        ret
                    }
                }
            } catch (e: NumberFormatException) {
                log.warn("can not parse osVersion from $osVersion")
                10
            }
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/Signer.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg

import avb.AVBInfo
import avb.alg.Algorithms
import cfig.Avb
import cfig.Avb.Companion.getJsonFileName
import cfig.helper.Helper
import com.fasterxml.jackson.databind.ObjectMapper
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File
import cfig.utils.EnvironmentVerifier

class Signer {
    companion object {
        private val log = LoggerFactory.getLogger(Signer::class.java)

        fun signAVB(output: String, imageSize: Long, avbtool: String) {
            log.info("Adding hash_footer with verified-boot 2.0 style")
            val ai = ObjectMapper().readValue(File(getJsonFileName(output)), AVBInfo::class.java)
            val alg = Algorithms.get(ai.header!!.algorithm_type)
            val bootDesc = ai.auxBlob!!.hashDescriptors[0]
            val newAvbInfo = ObjectMapper().readValue(File(getJsonFileName(output)), AVBInfo::class.java)

            //our signer
            File("$output.clear").copyTo(File("$output.signed"), overwrite = true)
            Avb().addHashFooter("$output.signed",
                    imageSize,
                    partition_name = bootDesc.partition_name,
                    newAvbInfo = newAvbInfo)
            //original signer
            val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
            CommandLine.parse("$cmdPrefix$avbtool add_hash_footer").apply {
                addArguments("--image ${output}.signed2")
                addArguments("--flags ${ai.header!!.flags}")
                addArguments("--partition_size ${imageSize}")
                addArguments("--salt ${Helper.toHexString(bootDesc.salt)}")
                addArguments("--partition_name ${bootDesc.partition_name}")
                addArguments("--hash_algorithm ${bootDesc.hash_algorithm}")
                addArguments("--algorithm ${alg!!.name}")
                addArguments("--rollback_index ${ai.header!!.rollback_index}")
                if (alg.defaultKey.isNotBlank()) {
                    addArguments("--key ${alg.defaultKey}")
                }
                newAvbInfo.auxBlob?.let { newAuxblob ->
                    newAuxblob.propertyDescriptors.forEach { newProp ->
                        addArguments(arrayOf("--prop", "${newProp.key}:${newProp.value}"))
                    }
                }
                addArgument("--internal_release_string")
                addArgument(ai.header!!.release_string, false)
                log.info(this.toString())

                File("$output.clear").copyTo(File("$output.signed2"), overwrite = true)
                DefaultExecutor().execute(this)
            }
            Helper.assertFileEquals("$output.signed", "$output.signed2")
            File("$output.signed2").delete()
            //TODO: decide what to verify
            //Parser.verifyAVBIntegrity(cfg.info.output + ".signed", avbtool)
            //Parser.verifyAVBIntegrity(cfg.info.output + ".signed2", avbtool)
        }

        fun signVB1(src: String, tgt: String) {
            val bootSigner = Helper.prop("bootSigner")
            log.info("Signing with verified-boot 1.0 style")
            val sig = Common.VeritySignature(
                    verity_pk8 = Helper.prop("verity_pk8"),
                    verity_pem = Helper.prop("verity_pem"),
                    jarPath = Helper.prop("bootSigner")
            )
            val bootSignCmd = "java -jar $bootSigner " +
                    "${sig.path} $src " +
                    "${sig.verity_pk8} ${sig.verity_pem} " +
                    "$tgt"
            log.info(bootSignCmd)
            DefaultExecutor().execute(CommandLine.parse(bootSignCmd))
        }

        fun mapToJson(m: LinkedHashMap<*, *>): String {
            val sb = StringBuilder()
            m.forEach { k, v ->
                if (sb.isNotEmpty()) sb.append(", ")
                sb.append("\"$k\": \"$v\"")
            }
            return "{ $sb }"
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/cpio/AndroidCpio.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.cpio

import cfig.helper.Helper
import cfig.utils.EnvironmentVerifier
import com.fasterxml.jackson.core.JsonParser
import com.fasterxml.jackson.databind.ObjectMapper
import org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream
import org.apache.commons.compress.archivers.cpio.CpioConstants
import org.slf4j.LoggerFactory
import java.io.*
import java.nio.file.Files
import java.nio.file.Paths
import java.util.*
import java.util.regex.Pattern

class AndroidCpio {
    private var inodeNumber: Long = 0L
    private val fsConfig: MutableSet<AndroidCpioEntry> = mutableSetOf()
    private val fsConfigTemplate: List<FsConfigTemplate> = loadFsConfigTemplate()

    data class FsConfigTemplate(
        var type: String = "REG",
        var mode: String = "",
        var uid: Int = 0,
        var gid: Int = 0,
        var prefix: String = ""
    )

    private fun packItem(root: File, item: File, outStream: OutputStream) {
        if ((item.path == root.path) && !Files.isDirectory(item.toPath())) {
            throw IllegalArgumentException("root path is not dir")
        }

        if (item.path == root.path) { //first visit to root
            val fileList = item.listFiles()?.apply { sortBy { it.name } }
            if (fileList != null) {
                for (subItem in fileList) {
                    packItem(root, subItem, outStream)
                }
            }
        } else { //later visit
            val newOutname = if (EnvironmentVerifier().isWindows) {
                item.path.substring(root.path.length + 1).replace("\\", "/")
            } else {
                item.path.substring(root.path.length + 1) //remove leading slash
            }
            log.debug(item.path + " ~ " + root.path + " => " + newOutname)
            val entry = when {
                Files.isSymbolicLink(item.toPath()) -> {
                    val target = Files.readSymbolicLink(Paths.get(item.path))
                    log.debug("LNK: " + item.path + " --> " + target)
                    AndroidCpioEntry(
                        name = newOutname,
                        statMode = java.lang.Long.valueOf("120644", 8),
                        data = target.toString().toByteArray(),
                        ino = inodeNumber++
                    )
                }
                Files.isDirectory(item.toPath()) -> {
                    log.debug("DIR: " + item.path + ", " + item.toPath())
                    AndroidCpioEntry(
                        name = newOutname,
                        statMode = java.lang.Long.valueOf("40755", 8),
                        data = byteArrayOf(),
                        ino = inodeNumber++
                    )
                }
                Files.isRegularFile(item.toPath()) -> {
                    log.debug("REG: " + item.path)
                    AndroidCpioEntry(
                        name = newOutname,
                        statMode = java.lang.Long.valueOf("100644", 8),
                        data = item.readBytes(),
                        ino = inodeNumber++
                    )
                }
                else -> {
                    throw IllegalArgumentException("do not support file " + item.name)
                }
            }
            log.debug("_eject: " + item.path)
            //fix_stat
            fixStat(entry)
            outStream.write(entry.encode())
            if (Files.isDirectory(item.toPath()) && !Files.isSymbolicLink(item.toPath())) {
                val fileList = item.listFiles()?.apply { sortBy { it.name } }
                if (fileList != null) {
                    for (subItem in fileList) {
                        packItem(root, subItem, outStream)
                    }
                }
            }
        }
    }

    private fun fnmatch(fileName: String, pattern: String): Boolean {
        return if (fileName == pattern) {
            true
        } else {
            Pattern.compile(
                "^" + pattern.replace(".", "\\.")
                    .replace("/", "\\/")
                    .replace("*", ".*") + "$"
            ).matcher(fileName).find()
        }
    }

    private fun fixStat(entry: AndroidCpioEntry) {
        val itemConfig = fsConfig.filter { it.name == entry.name }
        when (itemConfig.size) {
            0 -> { /* do nothing */
                val matches = fsConfigTemplate
                    .filter { fnmatch(entry.name, it.prefix) }
                    .sortedByDescending { it.prefix.length }
                if (matches.isNotEmpty()) {
                    val ftBits = NewAsciiCpio(c_mode = entry.statMode).let {
                        when {
                            it.isSymbolicLink() -> CpioConstants.C_ISLNK
                            it.isRegularFile() -> CpioConstants.C_ISREG
                            it.isDirectory() -> CpioConstants.C_ISDIR
                            else -> throw IllegalArgumentException("unsupported st_mode " + it.c_mode)
                        }
                    }
                    entry.statMode = ftBits.toLong() or java.lang.Long.valueOf(matches[0].mode, 8)
                    log.warn("${entry.name} ~ " + matches.map { it.prefix }.reduce { acc, s -> "$acc, $s" }
                            + ", stMode=" + java.lang.Long.toOctalString(entry.statMode))
                } else {
                    log.warn("${entry.name} has NO fsconfig/prefix match")
                }
            }
            1 -> {
                log.debug("${entry.name} == preset fsconfig")
                entry.statMode = itemConfig[0].statMode
            }
            else -> {
                //Issue #75: https://github.com/cfig/Android_boot_image_editor/issues/75
                //Reason: cpio may have multiple entries with the same name, that's caused by man-made errors
                val msg = "(${entry.name} has multiple exact-match fsConfig, " +
                        "check https://github.com/cfig/Android_boot_image_editor/issues/75"
                errLog.warn("IllegalArgumentException$msg")
                if (Helper.prop("config.allow_cpio_duplicate") == "true") {
                    log.warn("IllegalArgumentException$msg")
                    entry.statMode = itemConfig[0].statMode
                } else {
                    throw IllegalArgumentException(msg)
                }
            }
        }
    }

    fun pack(inDir: String, outFile: String, propFile: String? = null) {
        inodeNumber = 300000L
        fsConfig.clear()
        propFile?.let {
            if (File(propFile).exists()) {
                log.info("loading $propFile")
                File(propFile).readLines().forEach { line ->
                    fsConfig.add(ObjectMapper().readValue(line, AndroidCpioEntry::class.java))
                }
            } else {
                log.warn("fsConfig file $propFile has been deleted, using fsConfig prefix matcher")
            }
        }
        FileOutputStream(outFile).use { fos ->
            packItem(File(inDir), File(inDir), fos)
            val trailer = AndroidCpioEntry(
                name = "TRAILER!!!",
                statMode = java.lang.Long.valueOf("0755", 8),
                ino = inodeNumber++
            )
            fixStat(trailer)
            fos.write(trailer.encode())
        }
        val len = File(outFile).length()
        val rounded = Helper.round_to_multiple(len, 256) //file in page 256
        if (len != rounded) {
            FileOutputStream(outFile, true).use { fos ->
                fos.write(ByteArray((rounded - len).toInt()))
            }
        }
    }

    private fun loadFsConfigTemplate(): List<FsConfigTemplate> {
        val reader =
            BufferedReader(InputStreamReader(AndroidCpio::class.java.classLoader.getResourceAsStream("fsconfig.txt")!!))
        val oM = ObjectMapper().apply {
            configure(JsonParser.Feature.ALLOW_UNQUOTED_FIELD_NAMES, true)
        }
        return reader.readLines().map { oM.readValue(it, FsConfigTemplate::class.java) }
    }

    companion object {
        private val log = LoggerFactory.getLogger(AndroidCpio::class.java)
        private val errLog = LoggerFactory.getLogger("uiderrors")
        private val PERM_MASK = java.lang.Long.valueOf("777", 8)
        fun decompressCPIO(cpioFile: String, outDir: String, fileList: String? = null) {
            run { //clean up
                if (File(outDir).exists()) {
                    log.info("Cleaning $outDir ...")
                    File(outDir).deleteRecursively()
                }
                File(outDir).mkdir()
            }
            val cis = CpioArchiveInputStream(FileInputStream(cpioFile))
            val fileListDump = if (fileList != null) FileOutputStream(fileList) else null

            while (true) {
                val entry = cis.nextCPIOEntry ?: break
                val entryInfo = AndroidCpioEntry(
                    name = entry.name,
                    statMode = entry.mode,
                    ino = entry.inode,
                    note = String.format(Locale.getDefault(), "%6s", java.lang.Long.toOctalString(entry.mode))
                )
                if (!cis.canReadEntryData(entry)) {
                    throw RuntimeException("can not read entry ??")
                }
                val buffer = ByteArray(entry.size.toInt())
                cis.read(buffer)
                val outEntryName = File(outDir + "/" + entry.name).path
                if (((entry.mode and PERM_MASK).shr(7)).toInt() != 0b11) {
                    //@formatter:off
                    log.warn("  root/${entry.name} has improper file mode "
                            + String.format(Locale.getDefault(), "%03o, ", entry.mode and PERM_MASK) + "fix it"
                    )
                    //@formatter:on
                }
                when {
                    entry.isSymbolicLink -> {
                        entryInfo.note = ("LNK " + entryInfo.note)
                        if (EnvironmentVerifier().isWindows) {
                            File(outEntryName).writeBytes(buffer)
                        } else {
                            Files.createSymbolicLink(Paths.get(outEntryName), Paths.get(String(buffer)))
                        }
                    }
                    entry.isRegularFile -> {
                        entryInfo.note = ("REG " + entryInfo.note)
                        File(outEntryName).also { it.parentFile.mkdirs() }.writeBytes(buffer)
                        if (EnvironmentVerifier().isWindows) {
                            //Windows: Posix not supported
                        } else {
                            Files.setPosixFilePermissions(
                                Paths.get(outEntryName),
                                Helper.modeToPermissions(((entry.mode and PERM_MASK) or 0b111_000_000).toInt())
                            )
                        }
                    }
                    entry.isDirectory -> {
                        entryInfo.note = ("DIR " + entryInfo.note)
                        File(outEntryName).mkdir()
                        if (!EnvironmentVerifier().isWindows) {
                            Files.setPosixFilePermissions(
                                Paths.get(outEntryName),
                                Helper.modeToPermissions(((entry.mode and PERM_MASK) or 0b111_000_000).toInt())
                            )
                        } else {
                            //Windows
                        }
                    }
                    else -> throw IllegalArgumentException("??? type unknown")
                }
                File(outEntryName).setLastModified(entry.time)
                log.debug(entryInfo.toString())
                fileListDump?.write(ObjectMapper().writeValueAsString(entryInfo).toByteArray())
                fileListDump?.write("\n".toByteArray())
            }
            val bytesRead = cis.bytesRead
            cis.close()
            val remaining = FileInputStream(cpioFile).use { fis ->
                fis.skip(bytesRead - 128)
                fis.readBytes()
            }
            val foundIndex = String(remaining, Charsets.UTF_8).lastIndexOf("070701")
            val entryInfo = AndroidCpioEntry(
                name = CpioConstants.CPIO_TRAILER,
                statMode = java.lang.Long.valueOf("755", 8)
            )
            if (foundIndex != -1) {
                val statusModeStr = String(remaining, Charsets.UTF_8).substring(foundIndex + 14, foundIndex + 22)
                entryInfo.statMode = java.lang.Long.valueOf(statusModeStr, 16)
                log.info("cpio trailer found, mode=$statusModeStr")
            } else {
                log.error("no cpio trailer found")
            }
            fileListDump?.write(ObjectMapper().writeValueAsString(entryInfo).toByteArray())
            fileListDump?.close()
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/cpio/AndroidCpioEntry.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.cpio

import cfig.helper.Helper
import com.fasterxml.jackson.annotation.JsonIgnore
import org.apache.commons.compress.archivers.cpio.CpioArchiveEntry
import org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream
import org.apache.commons.compress.archivers.cpio.CpioConstants
import org.slf4j.LoggerFactory
import java.io.ByteArrayOutputStream

class AndroidCpioEntry(
    var name: String = "",
    var statMode: Long = 0,// stat.st_mode
    @JsonIgnore
    val data: ByteArray = byteArrayOf(),
    var ino: Long = 0,
    var note: String = ""
) {
    fun encode(): ByteArray {
        //new ascii cpio
        var header = Helper.join(
            NewAsciiCpio(
                c_ino = ino,
                c_mode = statMode,
                c_filesize = data.size,
                c_namesize = name.length + 1
            ).encode(),
            name.toByteArray(),
            ByteArray(1)
        ) //NULL terminated c-string
        //padding header if necessary
        Helper.round_to_multiple(header.size, 4).let { roundedSize ->
            if (roundedSize != header.size) {
                log.debug("header: meta ${header.size - 1 - name.length}, name ${name.length}, null 1, pad ${roundedSize - header.size} -> $roundedSize")
                header = Helper.join(header, ByteArray(roundedSize - header.size))
            }
        }
        var payload = data
        //padding data if necessary
        Helper.round_to_multiple(payload.size, 4).let { roundedSize ->
            if (roundedSize != payload.size) {
                log.debug("data  : payload ${payload.size}, pad ${roundedSize - payload.size} -> $roundedSize")
                payload = Helper.join(payload, ByteArray(roundedSize - payload.size))
            }
        }
        log.debug("entry($name): header ${header.size} + data ${payload.size} = ${header.size + payload.size}")
        return Helper.join(header, payload)
    }

    fun encode2(): ByteArray {
        val baos = ByteArrayOutputStream()
        val cpio = CpioArchiveOutputStream(baos)
        val entry = CpioArchiveEntry(CpioConstants.FORMAT_NEW, name).apply {
            inode = ino
            uid = 0
            gid = 0
            mode = statMode
            numberOfLinks = 1
            time = 0
            size = data.size.toLong()
            deviceMaj = 0
            deviceMin = 0
            remoteDeviceMaj = 0
            remoteDeviceMin = 0
            chksum = 0
        }
        cpio.putArchiveEntry(entry)
        cpio.write(data)
        cpio.closeArchiveEntry()
        return baos.toByteArray()
    }

    data class FileMode(
        var type: String = "",
        var sbits: String = "", //suid, sgid, sticky
        var perm: String = ""
    )

    companion object {
        private val log = LoggerFactory.getLogger(AndroidCpioEntry::class.java)
        private val S_IFDIR = java.lang.Long.valueOf("040000", 8)
        private val S_IFCHR = java.lang.Long.valueOf("020000", 8)
        private val S_IFBLK = java.lang.Long.valueOf("060000", 8)
        private val S_IFREG = java.lang.Long.valueOf("100000", 8)
        private val S_IFIFO = java.lang.Long.valueOf("010000", 8)
        private val S_IFLNK = java.lang.Long.valueOf("120000", 8)
        private val S_IFSOCK = java.lang.Long.valueOf("140000", 8)

        private val S_ISUID = java.lang.Long.valueOf("4000", 8)
        private val S_ISGID = java.lang.Long.valueOf("2000", 8)
        private val S_ISVTX = java.lang.Long.valueOf("1000", 8)

        private val S_IREAD = java.lang.Long.valueOf("400", 8)
        private val S_IWRITE = java.lang.Long.valueOf("200", 8)
        private val S_IEXEC = java.lang.Long.valueOf("100", 8)

        private val MASK_S_IRWXU = S_IREAD or S_IWRITE or S_IEXEC
        private val MASK_S_IRWXG = MASK_S_IRWXU shr 3
        private val MASK_S_IRWXO = MASK_S_IRWXG shr 3
        private val MASK_ACCESSPERMS = MASK_S_IRWXU or MASK_S_IRWXG or MASK_S_IRWXO

        fun interpretMode(mode: Long): FileMode {
            return FileMode().let { fm ->
                val m = mode and java.lang.Long.valueOf("0170000", 8) // S_IFMT
                fm.type = when (m) {
                    S_IFREG -> "REG"
                    S_IFCHR -> "CHR"
                    S_IFBLK -> "BLK"
                    S_IFDIR -> "DIR"
                    S_IFIFO -> "FIFO"
                    S_IFLNK -> "LNK"
                    S_IFSOCK -> "SOCK"
                    else -> throw IllegalArgumentException("unknown file type " + java.lang.Long.toOctalString(m))
                }
                if ((mode and S_ISUID) != 0L) {
                    fm.sbits += if (fm.sbits.isEmpty()) "suid" else "|suid"
                }
                if ((mode and S_ISGID) != 0L) {
                    fm.sbits += if (fm.sbits.isEmpty()) "sgid" else "|sgid"
                }
                if ((mode and S_ISVTX) != 0L) {
                    fm.sbits += if (fm.sbits.isEmpty()) "sticky" else "|sticky"
                }
                fm.perm = java.lang.Long.toOctalString(mode and MASK_ACCESSPERMS)
                fm
            }
        }
    }
}
```

`bbootimg/src/main/kotlin/bootimg/cpio/NewAsciiCpio.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.cpio

import cc.cfig.io.Struct
import org.apache.commons.compress.archivers.cpio.CpioConstants
import java.util.*

/*
    cpio "New ASCII Format" with 070701 as magic
 */
class NewAsciiCpio(
    var c_magic: String = "070701", //start-of-header
    var c_ino: Long = 0,//var
    var c_mode: Long = 0,//var
    var c_uid: Int = 0,
    var c_gid: Int = 0,
    var c_nlink: Int = 1,
    var c_mtime: Long = 0,
    var c_filesize: Int = 0,//var
    var c_devmajor: Int = 0,
    var c_devminor: Int = 0,
    var c_rdevmajor: Int = 0,
    var c_rdevminor: Int = 0, //end-of-header
    var c_namesize: Int = 0, //c_string name with '\0', aka. name_len + 1
    var c_check: Int = 0
) {
    init {
        if (SIZE != Struct(FORMAT_STRING).calcSize()) {
            throw RuntimeException("cpio format check failed")
        }
    }

    fun encode(): ByteArray {
        return Struct(FORMAT_STRING).pack(
            String.format(Locale.getDefault(), "%s", c_magic),
            String.format(Locale.getDefault(), "%08x", c_ino),
            String.format(Locale.getDefault(), "%08x", c_mode),
            String.format(Locale.getDefault(),"%08x", c_uid),
            String.format(Locale.getDefault(),"%08x", c_gid),
            String.format(Locale.getDefault(),"%08x", c_nlink),
            String.format(Locale.getDefault(),"%08x", c_mtime),
            String.format(Locale.getDefault(),"%08x", c_filesize),
            String.format(Locale.getDefault(),"%08x", c_devmajor),
            String.format(Locale.getDefault(),"%08x", c_devminor),
            String.format(Locale.getDefault(),"%08x", c_rdevmajor),
            String.format(Locale.getDefault(),"%08x", c_rdevminor),
            String.format(Locale.getDefault(),"%08x", c_namesize),
            String.format(Locale.getDefault(),"%08x", c_check),
        )
    }

    private fun fileType(): Long {
        return c_mode and CpioConstants.S_IFMT.toLong()
    }

    fun isRegularFile(): Boolean {
        return fileType() == CpioConstants.C_ISREG.toLong()
    }

    fun isDirectory(): Boolean {
        return fileType() == CpioConstants.C_ISDIR.toLong()
    }

    fun isSymbolicLink(): Boolean {
        return fileType() == CpioConstants.C_ISLNK.toLong()
    }

    companion object {
        const val SIZE = 110
        const val FORMAT_STRING = "6s8s8s8s8s8s8s8s8s8s8s8s8s8s" //6 + 8 *13
    }
}

/*      <bits/stat.h>
    /* File types.  */
#define __S_IFDIR   0040000 /* Directory.  */
#define __S_IFCHR   0020000 /* Character device.  */
#define __S_IFBLK   0060000 /* Block device.  */
#define __S_IFREG   0100000 /* Regular file.  */
#define __S_IFIFO   0010000 /* FIFO.  */
#define __S_IFLNK   0120000 /* Symbolic link.  */
#define __S_IFSOCK  0140000 /* Socket.  */

    /* Protection bits.  */
#define __S_ISUID   04000   /* Set user ID on execution.  */
#define __S_ISGID   02000   /* Set group ID on execution.  */
#define __S_ISVTX   01000   /* Save swapped text after use (sticky).  */
#define __S_IREAD   0400    /* Read by owner.  */
#define __S_IWRITE  0200    /* Write by owner.  */
#define __S_IEXEC   0100    /* Execute by owner.  */
/* Read, write, and execute by owner.  */
#define S_IRWXU (__S_IREAD|__S_IWRITE|__S_IEXEC)

#define S_IRGRP (S_IRUSR >> 3)  /* Read by group.  */
#define S_IWGRP (S_IWUSR >> 3)  /* Write by group.  */
#define S_IXGRP (S_IXUSR >> 3)  /* Execute by group.  */
Read, write, and execute by group.
#define S_IRWXG (S_IRWXU >> 3)

#define S_IROTH (S_IRGRP >> 3)  /* Read by others.  */
#define S_IWOTH (S_IWGRP >> 3)  /* Write by others.  */
#define S_IXOTH (S_IXGRP >> 3)  /* Execute by others.  */
Read, write, and execute by others.
#define S_IRWXO (S_IRWXG >> 3)

# define ACCESSPERMS (S_IRWXU|S_IRWXG|S_IRWXO) 0777

 */

```

`bbootimg/src/main/kotlin/bootimg/v2/BootHeaderV2.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v2

import cc.cfig.io.Struct
import cfig.helper.Helper
import cfig.bootimg.Common
import org.slf4j.LoggerFactory
import java.io.InputStream
import kotlin.math.pow

open class BootHeaderV2(
        var kernelLength: Int = 0,
        var kernelOffset: Long = 0L, //UInt

        var ramdiskLength: Int = 0,
        var ramdiskOffset: Long = 0L, //UInt

        var secondBootloaderLength: Int = 0,
        var secondBootloaderOffset: Long = 0L, //UInt

        var recoveryDtboLength: Int = 0,
        var recoveryDtboOffset: Long = 0L,//Q

        var dtbLength: Int = 0,
        var dtbOffset: Long = 0L,//Q

        var tagsOffset: Long = 0L, //UInt

        var pageSize: Int = 0,

        var headerSize: Int = 0,
        var headerVersion: Int = 0,

        var board: String = "",

        var cmdline: String = "",

        var hash: ByteArray? = null,

        var osVersion: String? = null,
        var osPatchLevel: String? = null) {
    @Throws(IllegalArgumentException::class)
    constructor(iS: InputStream?) : this() {
        if (iS == null) {
            return
        }
        log.warn("BootImgHeader constructor")
        val info = Struct(FORMAT_STRING).unpack(iS)
        check(20 == info.size)
        if (info[0] != magic) {
            throw IllegalArgumentException("stream doesn't look like Android Boot Image Header")
        }
        this.kernelLength = (info[1] as UInt).toInt()
        this.kernelOffset = (info[2] as UInt).toLong()
        this.ramdiskLength = (info[3] as UInt).toInt()
        this.ramdiskOffset = (info[4] as UInt).toLong()
        this.secondBootloaderLength = (info[5] as UInt).toInt()
        this.secondBootloaderOffset = (info[6] as UInt).toLong()
        this.tagsOffset = (info[7] as UInt).toLong()
        this.pageSize = (info[8] as UInt).toInt()
        this.headerVersion = (info[9] as UInt).toInt()
        val osNPatch = info[10] as UInt
        if (0U != osNPatch) { //treated as 'reserved' in this boot image
            this.osVersion = Common.parseOsVersion(osNPatch.toInt() shr 11)
            this.osPatchLevel = Common.parseOsPatchLevel((osNPatch and 0x7ff.toUInt()).toInt())
        }
        this.board = info[11] as String
        this.cmdline = (info[12] as String) + (info[14] as String)
        this.hash = info[13] as ByteArray

        if (this.headerVersion > 0) {
            this.recoveryDtboLength = (info[15] as UInt).toInt()
            this.recoveryDtboOffset = (info[16] as ULong).toLong()
        }

        this.headerSize = (info[17] as UInt).toInt()
        check(this.headerSize.toInt() in intArrayOf(BOOT_IMAGE_HEADER_V2_SIZE,
                BOOT_IMAGE_HEADER_V1_SIZE, BOOT_IMAGE_HEADER_V0_SIZE)) {
            "header size ${this.headerSize} illegal"
        }

        if (this.headerVersion > 1) {
            this.dtbLength = (info[18] as UInt).toInt()
            this.dtbOffset = (info[19] as ULong).toLong()
        }
    }

    private fun get_recovery_dtbo_offset(): Long {
        return Helper.round_to_multiple(this.headerSize.toLong(), pageSize.toLong()) +
                Helper.round_to_multiple(this.kernelLength, pageSize) +
                Helper.round_to_multiple(this.ramdiskLength, pageSize) +
                Helper.round_to_multiple(this.secondBootloaderLength, pageSize)
    }

    fun encode(): ByteArray {
        val pageSizeChoices: MutableSet<Long> = mutableSetOf<Long>().apply {
            (11..14).forEach { add(2.0.pow(it).toLong()) }
        }
        check(pageSizeChoices.contains(pageSize.toLong())) { "invalid parameter [pageSize=$pageSize], (choose from $pageSizeChoices)" }
        return Struct(FORMAT_STRING).pack(
                magic,
                //10I
                kernelLength,
                kernelOffset,
                ramdiskLength,
                ramdiskOffset,
                secondBootloaderLength,
                secondBootloaderOffset,
                tagsOffset,
                pageSize,
                headerVersion,
                (Common.packOsVersion(osVersion) shl 11) or Common.packOsPatchLevel(osPatchLevel),
                //16s
                board,
                //512s
                cmdline.substring(0, minOf(512, cmdline.length)),
                //32b
                hash!!,
                //1024s
                if (cmdline.length > 512) cmdline.substring(512) else "",
                //I
                recoveryDtboLength,
                //Q
                if (headerVersion > 0) recoveryDtboOffset else 0,
                //I
                when (headerVersion) {
                    0 -> BOOT_IMAGE_HEADER_V0_SIZE
                    1 -> BOOT_IMAGE_HEADER_V1_SIZE
                    2 -> BOOT_IMAGE_HEADER_V2_SIZE
                    else -> java.lang.IllegalArgumentException("headerVersion $headerVersion illegal")
                },
                //I
                dtbLength,
                //Q
                if (headerVersion > 1) dtbOffset else 0
        )
    }

    companion object {
        internal val log = LoggerFactory.getLogger(BootHeaderV2::class.java)
        const val magic = "ANDROID!"
        const val FORMAT_STRING = "8s" + //"ANDROID!"
                "10I" +
                "16s" +     //board name
                "512s" +    //cmdline part 1
                "32b" +     //hash digest
                "1024s" +   //cmdline part 2
                "I" +       //dtbo length [v1]
                "Q" +       //dtbo offset [v1]
                "I" +       //header size [v1]
                "I" +       //dtb length [v2]
                "Q"         //dtb offset [v2]
        const val BOOT_IMAGE_HEADER_V2_SIZE = 1660
        const val BOOT_IMAGE_HEADER_V1_SIZE = 1648
        const val BOOT_IMAGE_HEADER_V0_SIZE = 0

        init {
            check(BOOT_IMAGE_HEADER_V2_SIZE == Struct(FORMAT_STRING).calcSize())
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/v2/BootV2.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v2

import avb.AVBInfo
import cfig.Avb
import cfig.bootimg.Common
import cfig.bootimg.Common.Companion.deleleIfExists
import cfig.bootimg.Signer
import cfig.bootimg.v3.BootV3
import cfig.bootimg.v3.VendorBoot
import cfig.helper.Helper
import cfig.helper.Dumpling
import cfig.packable.VBMetaParser
import cfig.utils.EnvironmentVerifier
import cfig.utils.DTC
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder

data class BootV2(
    var info: MiscInfo = MiscInfo(),
    var kernel: CommArgs = CommArgs(),
    var ramdisk: CommArgs = CommArgs(),
    var secondBootloader: CommArgs? = null,
    var recoveryDtbo: CommArgsLong? = null,
    var dtb: CommArgsLong? = null,
) {
    data class MiscInfo(
        var output: String = "",
        var json: String = "",
        var headerVersion: Int = 0,
        var headerSize: Int = 0,
        var loadBase: Long = 0,
        var tagsOffset: Long = 0,
        var board: String? = null,
        var pageSize: Int = 0,
        var cmdline: String = "",
        var osVersion: String? = null,
        var osPatchLevel: String? = null,
        var hash: ByteArray? = byteArrayOf(),
        var verify: String = "",
        var imageSize: Long = 0,
    )

    data class CommArgs(
        var file: String? = null,
        var position: Long = 0,
        var size: Int = 0,
        var loadOffset: Long = 0,
    )

    data class CommArgsLong(
        var file: String? = null,
        var position: Long = 0,
        var size: Int = 0,
        var loadOffset: Long = 0,
    )

    companion object {
        private val log = LoggerFactory.getLogger(BootV2::class.java)
        private val workDir = Helper.prop("workDir")
        private val mapper = ObjectMapper()
        private val dtsSuffix = Helper.prop("config.dts_suffix")

        fun parse(fileName: String): BootV2 {
            val ret = BootV2()
            FileInputStream(fileName).use { fis ->
                val bh2 = BootHeaderV2(fis)
                ret.info.let { theInfo ->
                    theInfo.output = File(fileName).name
                    theInfo.json = File(fileName).name.removeSuffix(".img") + ".json"
                    theInfo.pageSize = bh2.pageSize
                    theInfo.headerSize = bh2.headerSize
                    theInfo.headerVersion = bh2.headerVersion
                    theInfo.board = bh2.board
                    theInfo.cmdline = bh2.cmdline
                    theInfo.imageSize = File(fileName).length()
                    theInfo.tagsOffset = bh2.tagsOffset
                    theInfo.hash = bh2.hash
                    theInfo.osVersion = bh2.osVersion
                    theInfo.osPatchLevel = bh2.osPatchLevel
                    if (Avb.hasAvbFooter(fileName)) {
                        theInfo.verify = "VB2.0"
                        if (Avb.verifyAVBIntegrity(fileName, String.format(Helper.prop("avbtool"), "v1.2"))) {
                            theInfo.verify += " PASS"
                        } else {
                            theInfo.verify += " FAIL"
                        }
                    } else {
                        theInfo.verify = "VB1.0"
                    }
                }
                ret.kernel.let { theKernel ->
                    theKernel.file = "${workDir}kernel"
                    theKernel.size = bh2.kernelLength
                    theKernel.loadOffset = bh2.kernelOffset
                    theKernel.position = ret.getKernelPosition()
                }
                ret.ramdisk.let { theRamdisk ->
                    theRamdisk.size = bh2.ramdiskLength
                    theRamdisk.loadOffset = bh2.ramdiskOffset
                    theRamdisk.position = ret.getRamdiskPosition()
                    if (bh2.ramdiskLength > 0) {
                        theRamdisk.file = "${workDir}ramdisk.img"
                    }
                }
                if (bh2.secondBootloaderLength > 0) {
                    ret.secondBootloader = CommArgs()
                    ret.secondBootloader!!.size = bh2.secondBootloaderLength
                    ret.secondBootloader!!.loadOffset = bh2.secondBootloaderOffset
                    ret.secondBootloader!!.file = "${workDir}second"
                    ret.secondBootloader!!.position = ret.getSecondBootloaderPosition()
                }
                if (bh2.recoveryDtboLength > 0) {
                    ret.recoveryDtbo = CommArgsLong()
                    ret.recoveryDtbo!!.size = bh2.recoveryDtboLength
                    ret.recoveryDtbo!!.loadOffset = bh2.recoveryDtboOffset //Q
                    ret.recoveryDtbo!!.file = "${workDir}recoveryDtbo"
                    ret.recoveryDtbo!!.position = ret.getRecoveryDtboPosition()
                }
                if (bh2.dtbLength > 0) {
                    ret.dtb = CommArgsLong()
                    ret.dtb!!.size = bh2.dtbLength
                    ret.dtb!!.loadOffset = bh2.dtbOffset //Q
                    ret.dtb!!.file = "${workDir}dtb"
                    ret.dtb!!.position = ret.getDtbPosition()
                }
            }
            return ret
        }
    }

    private fun getHeaderSize(pageSize: Int): Int {
        val pad = (pageSize - (1648 and (pageSize - 1))) and (pageSize - 1)
        return pad + 1648
    }

    private fun getKernelPosition(): Long {
        return getHeaderSize(info.pageSize).toLong()
    }

    private fun getRamdiskPosition(): Long {
        return (getKernelPosition() + kernel.size +
                Common.getPaddingSize(kernel.size, info.pageSize))
    }

    private fun getSecondBootloaderPosition(): Long {
        return getRamdiskPosition() + ramdisk.size +
                Common.getPaddingSize(ramdisk.size, info.pageSize)
    }

    private fun getRecoveryDtboPosition(): Long {
        return if (this.secondBootloader == null) {
            getSecondBootloaderPosition()
        } else {
            getSecondBootloaderPosition() + secondBootloader!!.size +
                    Common.getPaddingSize(secondBootloader!!.size, info.pageSize)
        }
    }

    private fun getDtbPosition(): Long {
        return if (this.recoveryDtbo == null) {
            getRecoveryDtboPosition()
        } else {
            getRecoveryDtboPosition() + recoveryDtbo!!.size +
                    Common.getPaddingSize(recoveryDtbo!!.size, info.pageSize)
        }
    }

    fun extractImages(): BootV2 {
        //info
        mapper.writerWithDefaultPrettyPrinter().writeValue(File(workDir + info.json), this)
        //kernel
        Common.dumpKernel(Helper.Slice(info.output, kernel.position.toInt(), kernel.size, kernel.file!!))
        //ramdisk
        if (this.ramdisk.size > 0) {
            val fmt = Common.dumpRamdisk(
                Helper.Slice(info.output, ramdisk.position.toInt(), ramdisk.size, ramdisk.file!!), "${workDir}root"
            )
            this.ramdisk.file = this.ramdisk.file!! + ".$fmt"
            //dump info again
            mapper.writerWithDefaultPrettyPrinter().writeValue(File(workDir + this.info.json), this)
        }
        //second bootloader
        secondBootloader?.let {
            Helper.extractFile(
                info.output,
                secondBootloader!!.file!!,
                secondBootloader!!.position,
                secondBootloader!!.size
            )
        }
        //recovery dtbo
        recoveryDtbo?.let {
            Helper.extractFile(
                info.output,
                recoveryDtbo!!.file!!,
                recoveryDtbo!!.position,
                recoveryDtbo!!.size
            )
        }
        //dtb
        this.dtb?.let { _ ->
            Common.dumpDtb(Helper.Slice(info.output, dtb!!.position.toInt(), dtb!!.size, dtb!!.file!!))
        }

        return this
    }

    fun extractVBMeta(): BootV2 {
        if (this.info.verify.startsWith("VB2.0")) {
            AVBInfo.parseFrom(Dumpling(info.output)).dumpDefault(info.output)
            if (File("vbmeta.img").exists()) {
                log.warn("Found vbmeta.img, parsing ...")
                VBMetaParser().unpack("vbmeta.img")
            }
        } else {
            log.info("verify type is ${this.info.verify}, skip AVB parsing")
        }
        return this
    }

    fun printSummary(): BootV2 {
        val tableHeader = AsciiTable().apply {
            addRule()
            addRow("What", "Where")
            addRule()
        }
        val tab = AsciiTable().let {
            it.addRule()
            it.addRow("image info", workDir + info.output.removeSuffix(".img") + ".json")
            if (this.info.verify.startsWith("VB2.0")) {
                it.addRule()
                val verifyStatus = if (this.info.verify.contains("PASS")) {
                    "verified"
                } else {
                    "verify fail"
                }
                Avb.getJsonFileName(info.output).let { jsonFile ->
                    it.addRow("AVB info [$verifyStatus]", jsonFile)
                    if (File(jsonFile).exists()) {
                        mapper.readValue(File(jsonFile), AVBInfo::class.java).let { ai ->
                            val inspectRet = Avb.inspectKey(ai)
                            if (inspectRet != "NONE") {
                                it.addRow("\\-- signing key", inspectRet)
                            }
                        }
                    }
                }
            }
            //kernel
            it.addRule()
            it.addRow("kernel", this.kernel.file)
            File(Helper.prop("kernelVersionFile")).let { kernelVersionFile ->
                if (kernelVersionFile.exists()) {
                    it.addRow("\\-- version " + kernelVersionFile.readLines().toString(), kernelVersionFile.path)
                }
            }
            File(Helper.prop("kernelConfigFile")).let { kernelConfigFile ->
                if (kernelConfigFile.exists()) {
                    it.addRow("\\-- config", kernelConfigFile.path)
                }
            }
            //ramdisk
            if (this.ramdisk.size > 0) {
                it.addRule()
                it.addRow("ramdisk", this.ramdisk.file)
                it.addRow("\\-- extracted ramdisk rootfs", "${workDir}root")
            }
            //second
            this.secondBootloader?.let { theSecondBootloader ->
                if (theSecondBootloader.size > 0) {
                    it.addRule()
                    it.addRow("second bootloader", theSecondBootloader.file)
                }
            }
            //dtbo
            this.recoveryDtbo?.let { theDtbo ->
                if (theDtbo.size > 0) {
                    it.addRule()
                    it.addRow("recovery dtbo", theDtbo.file)
                }
            }
            //dtb
            this.dtb?.let { theDtb ->
                if (theDtb.size > 0) {
                    it.addRule()
                    it.addRow("dtb", theDtb.file)
                    if (File(theDtb.file + ".${dtsSuffix}").exists()) {
                        it.addRow("\\-- decompiled dts", theDtb.file + ".${dtsSuffix}")
                    }
                }
            }
            //END
            it.addRule()
            it
        }
        val tabVBMeta = AsciiTable().let {
            if (File("vbmeta.img").exists()) {
                it.addRule()
                it.addRow("vbmeta.img", Avb.getJsonFileName("vbmeta.img"))
                it.addRule()
                "\n" + it.render()
            } else {
                ""
            }
        }
        log.info(
            "\n\t\t\tUnpack Summary of ${info.output}\n{}\n{}{}",
            tableHeader.render(), tab.render(), tabVBMeta
        )
        return this
    }

    private fun toHeader(): BootHeaderV2 {
        return BootHeaderV2(
            kernelLength = kernel.size,
            kernelOffset = kernel.loadOffset,
            ramdiskLength = ramdisk.size,
            ramdiskOffset = ramdisk.loadOffset,
            secondBootloaderLength = if (secondBootloader != null) secondBootloader!!.size else 0,
            secondBootloaderOffset = if (secondBootloader != null) secondBootloader!!.loadOffset else 0,
            recoveryDtboLength = if (recoveryDtbo != null) recoveryDtbo!!.size else 0,
            recoveryDtboOffset = if (recoveryDtbo != null) recoveryDtbo!!.loadOffset else 0,
            dtbLength = if (dtb != null) dtb!!.size else 0,
            dtbOffset = if (dtb != null) dtb!!.loadOffset else 0,
            tagsOffset = info.tagsOffset,
            pageSize = info.pageSize,
            headerSize = info.headerSize,
            headerVersion = info.headerVersion,
            board = info.board.toString(),
            cmdline = info.cmdline,
            hash = info.hash,
            osVersion = info.osVersion,
            osPatchLevel = info.osPatchLevel
        )
    }

    fun pack(): BootV2 {
        //refresh kernel size
        this.kernel.size = File(this.kernel.file!!).length().toInt()
        //refresh ramdisk size
        if (this.ramdisk.file.isNullOrBlank()) {
            ramdisk.file = null
            ramdisk.loadOffset = 0
        } else {
            if (File(this.ramdisk.file!!).exists() && !File(workDir + "root").exists()) {
                //do nothing if we have ramdisk.img.gz but no /root
                log.warn("Use prebuilt ramdisk file: ${this.ramdisk.file}")
            } else {
                File(this.ramdisk.file!!).deleleIfExists()
                File(this.ramdisk.file!!.removeSuffix(".gz")).deleleIfExists()
                //Common.packRootfs("${workDir}/root", this.ramdisk.file!!, Common.parseOsMajor(info.osVersion.toString()))
                Common.packRootfs("${workDir}/root", this.ramdisk.file!!)
            }
            this.ramdisk.size = File(this.ramdisk.file!!).length().toInt()
        }
        //refresh second bootloader size
        secondBootloader?.let { theSecond ->
            theSecond.size = File(theSecond.file!!).length().toInt()
        }
        //refresh recovery dtbo size
        recoveryDtbo?.let { theDtbo ->
            theDtbo.size = File(theDtbo.file!!).length().toInt()
            theDtbo.loadOffset = getRecoveryDtboPosition()
            log.warn("using fake recoveryDtboOffset ${theDtbo.loadOffset} (as is in AOSP avbtool)")
        }
        //refresh dtb size
        dtb?.let { theDtb ->
            if (File(theDtb.file!! + ".${dtsSuffix}").exists()) {
                check(DTC().compile(theDtb.file!! + ".${dtsSuffix}", theDtb.file!!)) { "fail to compile dts" }
            }
            theDtb.size = File(theDtb.file!!).length().toInt()
        }
        //refresh image hash
        info.hash = when (info.headerVersion) {
            0 -> {
                Common.hashFileAndSize(kernel.file, ramdisk.file, secondBootloader?.file)
            }
            1 -> {
                Common.hashFileAndSize(
                    kernel.file, ramdisk.file,
                    secondBootloader?.file, recoveryDtbo?.file
                )
            }
            2 -> {
                Common.hashFileAndSize(
                    kernel.file, ramdisk.file,
                    secondBootloader?.file, recoveryDtbo?.file, dtb?.file
                )
            }
            else -> {
                throw IllegalArgumentException("headerVersion ${info.headerVersion} illegal")
            }
        }

        val encodedHeader = this.toHeader().encode()

        //write
        FileOutputStream("${info.output}.clear", false).use { fos ->
            fos.write(encodedHeader)
            fos.write(ByteArray((Helper.round_to_multiple(encodedHeader.size, info.pageSize) - encodedHeader.size)))
        }

        log.info("Writing data ...")
        //boot image size may > 64MB. Fix issue #57
        val bytesV2 = ByteBuffer.allocate(maxOf(1024 * 1024 * 64, info.imageSize.toInt()))
            .let { bf ->
                bf.order(ByteOrder.LITTLE_ENDIAN)
                Common.writePaddedFile(bf, kernel.file!!, info.pageSize)
                if (ramdisk.size > 0) {
                    Common.writePaddedFile(bf, ramdisk.file!!, info.pageSize)
                }
                secondBootloader?.let {
                    Common.writePaddedFile(bf, secondBootloader!!.file!!, info.pageSize)
                }
                recoveryDtbo?.let {
                    Common.writePaddedFile(bf, recoveryDtbo!!.file!!, info.pageSize)
                }
                dtb?.let {
                    Common.writePaddedFile(bf, dtb!!.file!!, info.pageSize)
                }
                bf
            }
        //write
        FileOutputStream("${info.output}.clear", true).use { fos ->
            fos.write(bytesV2.array(), 0, bytesV2.position())
        }

        this.toCommandLine().apply {
            addArgument("${info.output}.google")
            log.info(this.toString())
            DefaultExecutor().execute(this)
        }

        Helper.assertFileEquals("${info.output}.clear", "${info.output}.google")

        return this
    }

    private fun toCommandLine(): CommandLine {
        val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
        val ret = CommandLine.parse(cmdPrefix + Helper.prop("mkbootimg"))
        ret.addArgument(" --header_version ")
        ret.addArgument(info.headerVersion.toString())
        ret.addArgument(" --base ")
        ret.addArgument("0x" + java.lang.Long.toHexString(0))
        ret.addArgument(" --kernel ")
        ret.addArgument(kernel.file!!)
        ret.addArgument(" --kernel_offset ")
        ret.addArgument("0x" + Integer.toHexString(kernel.loadOffset.toInt()))
        if (this.ramdisk.size > 0) {
            ret.addArgument(" --ramdisk ")
            ret.addArgument(ramdisk.file)
        }
        ret.addArgument(" --ramdisk_offset ")
        ret.addArgument("0x" + Integer.toHexString(ramdisk.loadOffset.toInt()))
        if (secondBootloader != null) {
            ret.addArgument(" --second ")
            ret.addArgument(secondBootloader!!.file!!)
            ret.addArgument(" --second_offset ")
            ret.addArgument("0x" + Integer.toHexString(secondBootloader!!.loadOffset.toInt()))
        }
        if (!info.board.isNullOrBlank()) {
            ret.addArgument(" --board ")
            ret.addArgument(info.board)
        }
        if (info.headerVersion > 0) {
            if (recoveryDtbo != null) {
                ret.addArgument(" --recovery_dtbo ")
                ret.addArgument(recoveryDtbo!!.file!!)
            }
        }
        if (info.headerVersion > 1) {
            if (dtb != null) {
                ret.addArgument("--dtb ")
                ret.addArgument(dtb!!.file!!)
                ret.addArgument("--dtb_offset ")
                ret.addArgument("0x" + java.lang.Long.toHexString(dtb!!.loadOffset))
            }
        }
        ret.addArgument(" --pagesize ")
        ret.addArgument(info.pageSize.toString())
        ret.addArgument(" --cmdline ")
        ret.addArgument(info.cmdline, false)
        if (!info.osVersion.isNullOrBlank()) {
            ret.addArgument(" --os_version ")
            ret.addArgument(info.osVersion)
        }
        if (!info.osPatchLevel.isNullOrBlank()) {
            ret.addArgument(" --os_patch_level ")
            ret.addArgument(info.osPatchLevel)
        }
        ret.addArgument(" --tags_offset ")
        ret.addArgument("0x" + Integer.toHexString(info.tagsOffset.toInt()))
        ret.addArgument(" --id ")
        ret.addArgument(" --output ")
        //ret.addArgument("boot.img" + ".google")

        log.debug("To Commandline: $ret")

        return ret
    }

    fun sign(): BootV2 {
        //unify with v1.1/v1.2 avbtool
        val avbtool = String.format(Helper.prop("avbtool"), "v1.2")
        if (info.verify.startsWith("VB2.0")) {
            Signer.signAVB(info.output, this.info.imageSize, avbtool)
            log.info("Adding hash_footer with verified-boot 2.0 style")
        } else {
            Signer.signVB1(info.output + ".clear", info.output + ".signed")
        }
        return this
    }

    fun printPackSummary(): BootV2 {
        VendorBoot.printPackSummary(info.output)
        return this
    }

    fun updateVbmeta(): BootV2 {
        Avb.updateVbmeta(info.output)
        return this
    }
}

```

`bbootimg/src/main/kotlin/bootimg/v2/BootV2Dialects.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v2

import avb.AVBInfo
import cfig.Avb
import cfig.bootimg.Common
import cfig.bootimg.Common.Companion.deleleIfExists
import cfig.bootimg.Signer
import cfig.bootimg.v3.VendorBoot
import cfig.helper.Helper
import cfig.helper.Dumpling
import cfig.packable.VBMetaParser
import cfig.utils.EnvironmentVerifier
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder

data class BootV2Dialects(
    var info: MiscInfo = MiscInfo(),
    var kernel: CommArgs = CommArgs(),
    var ramdisk: CommArgs = CommArgs(),
    var secondBootloader: CommArgs? = null,
    var recoveryDtbo: CommArgsLong? = null,
    var dtb: CommArgsLong? = null,
    var unknownLand: CommArgsLong? = null,
) {
    data class MiscInfo(
        var output: String = "",
        var json: String = "",
        var headerVersion: Int = 0,
        var headerSize: Int = 0,
        var loadBase: Long = 0,
        var tagsOffset: Long = 0,
        var board: String? = null,
        var pageSize: Int = 0,
        var cmdline: String = "",
        var osVersion: String? = null,
        var osPatchLevel: String? = null,
        var hash: ByteArray? = byteArrayOf(),
        var verify: String = "",
        var imageSize: Long = 0,
    )

    data class CommArgs(
        var file: String? = null,
        var position: Long = 0,
        var size: Int = 0,
        var loadOffset: Long = 0,
    )

    data class CommArgsLong(
        var file: String? = null,
        var position: Long = 0,
        var size: Int = 0,
        var loadOffset: Long = 0,
    )

    companion object {
        private val log = LoggerFactory.getLogger(BootV2Dialects::class.java)
        private val workDir = Helper.prop("workDir")
        private val dtsSuffix = Helper.prop("config.dts_suffix")

        fun parse(fileName: String): BootV2Dialects {
            val ret = BootV2Dialects()
            FileInputStream(fileName).use { fis ->
                val bh2 = BootHeaderV2(fis)
                ret.info.let { theInfo ->
                    theInfo.output = File(fileName).name
                    theInfo.json = File(fileName).name.removeSuffix(".img") + ".json"
                    theInfo.pageSize = bh2.pageSize
                    theInfo.headerSize = bh2.headerSize
                    if (true) {
                        bh2.dtbLength = bh2.headerVersion
                        bh2.headerVersion = 0
                        theInfo.headerVersion = 0
                        log.warn("dtb len = " + bh2.dtbLength)
                    } else {
                        //theInfo.headerVersion = bh2.headerVersion
                    }
                    theInfo.board = bh2.board
                    theInfo.cmdline = bh2.cmdline
                    theInfo.imageSize = File(fileName).length()
                    theInfo.tagsOffset = bh2.tagsOffset
                    theInfo.hash = bh2.hash
                    theInfo.osVersion = bh2.osVersion
                    theInfo.osPatchLevel = bh2.osPatchLevel
                    if (Avb.hasAvbFooter(fileName)) {
                        theInfo.verify = "VB2.0"
                        if (Avb.verifyAVBIntegrity(fileName, String.format(Helper.prop("avbtool"), "v1.2"))) {
                            theInfo.verify += " PASS"
                        } else {
                            theInfo.verify += " FAIL"
                        }
                    } else {
                        theInfo.verify = "VB1.0"
                    }
                }
                ret.kernel.let { theKernel ->
                    theKernel.file = "${workDir}kernel"
                    theKernel.size = bh2.kernelLength
                    theKernel.loadOffset = bh2.kernelOffset
                    theKernel.position = ret.getKernelPosition()
                }
                ret.ramdisk.let { theRamdisk ->
                    theRamdisk.size = bh2.ramdiskLength
                    theRamdisk.loadOffset = bh2.ramdiskOffset
                    theRamdisk.position = ret.getRamdiskPosition()
                    if (bh2.ramdiskLength > 0) {
                        theRamdisk.file = "${workDir}ramdisk.img"
                    }
                }
                if (bh2.secondBootloaderLength > 0) {
                    ret.secondBootloader = CommArgs()
                    ret.secondBootloader!!.size = bh2.secondBootloaderLength
                    ret.secondBootloader!!.loadOffset = bh2.secondBootloaderOffset
                    ret.secondBootloader!!.file = "${workDir}second"
                    ret.secondBootloader!!.position = ret.getSecondBootloaderPosition()
                }
                if (bh2.recoveryDtboLength > 0) {
                    ret.recoveryDtbo = CommArgsLong()
                    ret.recoveryDtbo!!.size = bh2.recoveryDtboLength
                    ret.recoveryDtbo!!.loadOffset = bh2.recoveryDtboOffset //Q
                    ret.recoveryDtbo!!.file = "${workDir}recoveryDtbo"
                    ret.recoveryDtbo!!.position = ret.getRecoveryDtboPosition()
                }
                if (bh2.dtbLength > 0) {
                    ret.dtb = CommArgsLong()
                    ret.dtb!!.size = bh2.dtbLength
                    ret.dtb!!.loadOffset = bh2.dtbOffset //Q
                    ret.dtb!!.file = "${workDir}dtb"
                    ret.dtb!!.position = ret.getDtbPosition()
                }
            }
            log.warn("Land Unknown: " + ret.getUnknownLandPosision())
            return ret
        }
    }

    private fun getHeaderSize(pageSize: Int): Int {
        val pad = (pageSize - (1648 and (pageSize - 1))) and (pageSize - 1)
        return pad + 1648
    }

    private fun getKernelPosition(): Long {
        return getHeaderSize(info.pageSize).toLong()
    }

    private fun getRamdiskPosition(): Long {
        return (getKernelPosition() + kernel.size +
                Common.getPaddingSize(kernel.size, info.pageSize))
    }

    private fun getSecondBootloaderPosition(): Long {
        return getRamdiskPosition() + ramdisk.size +
                Common.getPaddingSize(ramdisk.size, info.pageSize)
    }

    private fun getRecoveryDtboPosition(): Long {
        return if (this.secondBootloader == null) {
            getSecondBootloaderPosition()
        } else {
            getSecondBootloaderPosition()
            getSecondBootloaderPosition() + secondBootloader!!.size +
                    Common.getPaddingSize(secondBootloader!!.size, info.pageSize)
        }
    }

    private fun getDtbPosition(): Long {
        return if (this.recoveryDtbo == null) {
            getRecoveryDtboPosition()
        } else {
            getRecoveryDtboPosition() + recoveryDtbo!!.size +
                    Common.getPaddingSize(recoveryDtbo!!.size, info.pageSize)
        }
    }

    private fun getUnknownLandPosision(): Long {
        return if (this.dtb == null) {
            getDtbPosition()
        } else {
            getDtbPosition() + dtb!!.size +
                    Common.getPaddingSize(dtb!!.size, info.pageSize)
        }
    }

    fun extractImages(): BootV2Dialects {
        val workDir = Helper.prop("workDir")
        //info
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File(workDir + info.json), this)
        //kernel
        Common.dumpKernel(Helper.Slice(info.output, kernel.position.toInt(), kernel.size, kernel.file!!))
        //ramdisk
        if (this.ramdisk.size > 0) {
            val fmt = Common.dumpRamdisk(
                Helper.Slice(info.output, ramdisk.position.toInt(), ramdisk.size, ramdisk.file!!), "${workDir}root"
            )
            this.ramdisk.file = this.ramdisk.file!! + ".$fmt"
            //dump info again
            ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File(workDir + this.info.json), this)
        }
        //second bootloader
        secondBootloader?.let {
            Helper.extractFile(
                info.output,
                secondBootloader!!.file!!,
                secondBootloader!!.position,
                secondBootloader!!.size
            )
        }
        //recovery dtbo
        recoveryDtbo?.let {
            Helper.extractFile(
                info.output,
                recoveryDtbo!!.file!!,
                recoveryDtbo!!.position,
                recoveryDtbo!!.size
            )
        }
        //dtb
        this.dtb?.let { _ ->
            Common.dumpDtb(Helper.Slice(info.output, dtb!!.position.toInt(), dtb!!.size, dtb!!.file!!))
        }

        return this
    }

    fun extractVBMeta(): BootV2Dialects {
        if (this.info.verify.startsWith("VB2.0")) {
            AVBInfo.parseFrom(Dumpling(info.output)).dumpDefault(info.output)
            if (File("vbmeta.img").exists()) {
                log.warn("Found vbmeta.img, parsing ...")
                VBMetaParser().unpack("vbmeta.img")
            }
        } else {
            log.info("verify type is ${this.info.verify}, skip AVB parsing")
        }
        return this
    }

    fun printSummary(): BootV2Dialects {
        val workDir = Helper.prop("workDir")
        val tableHeader = AsciiTable().apply {
            addRule()
            addRow("What", "Where")
            addRule()
        }
        val tab = AsciiTable().let {
            it.addRule()
            it.addRow("image info", workDir + info.output.removeSuffix(".img") + ".json")
            if (this.info.verify.startsWith("VB2.0")) {
                it.addRule()
                val verifyStatus = if (this.info.verify.contains("PASS")) {
                    "verified"
                } else {
                    "verify fail"
                }
                it.addRow("AVB info [$verifyStatus]", Avb.getJsonFileName(info.output))
            }
            //kernel
            it.addRule()
            it.addRow("kernel", this.kernel.file)
            File(Helper.prop("kernelVersionFile")).let { kernelVersionFile ->
                if (kernelVersionFile.exists()) {
                    it.addRow("\\-- version " + kernelVersionFile.readLines().toString(), kernelVersionFile.path)
                }
            }
            File(Helper.prop("kernelConfigFile")).let { kernelConfigFile ->
                if (kernelConfigFile.exists()) {
                    it.addRow("\\-- config", kernelConfigFile.path)
                }
            }
            //ramdisk
            if (this.ramdisk.size > 0) {
                it.addRule()
                it.addRow("ramdisk", this.ramdisk.file)
                it.addRow("\\-- extracted ramdisk rootfs", "${workDir}root")
            }
            //second
            this.secondBootloader?.let { theSecondBootloader ->
                if (theSecondBootloader.size > 0) {
                    it.addRule()
                    it.addRow("second bootloader", theSecondBootloader.file)
                }
            }
            //dtbo
            this.recoveryDtbo?.let { theDtbo ->
                if (theDtbo.size > 0) {
                    it.addRule()
                    it.addRow("recovery dtbo", theDtbo.file)
                }
            }
            //dtb
            this.dtb?.let { theDtb ->
                if (theDtb.size > 0) {
                    it.addRule()
                    it.addRow("dtb", theDtb.file)
                    if (File(theDtb.file + ".${dtsSuffix}").exists()) {
                        it.addRow("\\-- decompiled dts", theDtb.file + ".${dtsSuffix}")
                    }
                }
            }
            //END
            it.addRule()
            it
        }
        val tabVBMeta = AsciiTable().let {
            if (File("vbmeta.img").exists()) {
                it.addRule()
                it.addRow("vbmeta.img", Avb.getJsonFileName("vbmeta.img"))
                it.addRule()
                "\n" + it.render()
            } else {
                ""
            }
        }
        log.info(
            "\n\t\t\tUnpack Summary of ${info.output}\n{}\n{}{}",
            tableHeader.render(), tab.render(), tabVBMeta
        )
        return this
    }

    private fun toHeader(): BootHeaderV2 {
        return BootHeaderV2(
            kernelLength = kernel.size,
            kernelOffset = kernel.loadOffset,
            ramdiskLength = ramdisk.size,
            ramdiskOffset = ramdisk.loadOffset,
            secondBootloaderLength = if (secondBootloader != null) secondBootloader!!.size else 0,
            secondBootloaderOffset = if (secondBootloader != null) secondBootloader!!.loadOffset else 0,
            recoveryDtboLength = if (recoveryDtbo != null) recoveryDtbo!!.size else 0,
            recoveryDtboOffset = if (recoveryDtbo != null) recoveryDtbo!!.loadOffset else 0,
            dtbLength = if (dtb != null) dtb!!.size else 0,
            dtbOffset = if (dtb != null) dtb!!.loadOffset else 0,
            tagsOffset = info.tagsOffset,
            pageSize = info.pageSize,
            headerSize = info.headerSize,
            headerVersion = info.headerVersion,
            board = info.board.toString(),
            cmdline = info.cmdline,
            hash = info.hash,
            osVersion = info.osVersion,
            osPatchLevel = info.osPatchLevel
        )
    }

    fun pack(): BootV2Dialects {
        //refresh kernel size
        this.kernel.size = File(this.kernel.file!!).length().toInt()
        //refresh ramdisk size
        if (this.ramdisk.file.isNullOrBlank()) {
            ramdisk.file = null
            ramdisk.loadOffset = 0
        } else {
            if (File(this.ramdisk.file!!).exists() && !File(workDir + "root").exists()) {
                //do nothing if we have ramdisk.img.gz but no /root
                log.warn("Use prebuilt ramdisk file: ${this.ramdisk.file}")
            } else {
                File(this.ramdisk.file!!).deleleIfExists()
                File(this.ramdisk.file!!.removeSuffix(".gz")).deleleIfExists()
                //Common.packRootfs("${workDir}/root", this.ramdisk.file!!, Common.parseOsMajor(info.osVersion.toString()))
                Common.packRootfs("${workDir}/root", this.ramdisk.file!!)
            }
            this.ramdisk.size = File(this.ramdisk.file!!).length().toInt()
        }
        //refresh second bootloader size
        secondBootloader?.let { theSecond ->
            theSecond.size = File(theSecond.file!!).length().toInt()
        }
        //refresh recovery dtbo size
        recoveryDtbo?.let { theDtbo ->
            theDtbo.size = File(theDtbo.file!!).length().toInt()
            theDtbo.loadOffset = getRecoveryDtboPosition()
            log.warn("using fake recoveryDtboOffset ${theDtbo.loadOffset} (as is in AOSP avbtool)")
        }
        //refresh dtb size
        dtb?.let { theDtb ->
            theDtb.size = File(theDtb.file!!).length().toInt()
        }
        //refresh image hash
        info.hash = when (info.headerVersion) {
            0 -> {
                Common.hashFileAndSize(kernel.file, ramdisk.file, secondBootloader?.file)
            }
            1 -> {
                Common.hashFileAndSize(
                    kernel.file, ramdisk.file,
                    secondBootloader?.file, recoveryDtbo?.file
                )
            }
            2 -> {
                Common.hashFileAndSize(
                    kernel.file, ramdisk.file,
                    secondBootloader?.file, recoveryDtbo?.file, dtb?.file
                )
            }
            else -> {
                throw IllegalArgumentException("headerVersion ${info.headerVersion} illegal")
            }
        }

        val encodedHeader = this.toHeader().encode()

        //write
        FileOutputStream("${info.output}.clear", false).use { fos ->
            fos.write(encodedHeader)
            fos.write(ByteArray((Helper.round_to_multiple(encodedHeader.size, info.pageSize) - encodedHeader.size)))
        }

        log.info("Writing data ...")
        //boot image size may > 64MB. Fix issue #57
        val bytesV2 = ByteBuffer.allocate(maxOf(1024 * 1024 * 64, info.imageSize.toInt()))
            .let { bf ->
                bf.order(ByteOrder.LITTLE_ENDIAN)
                Common.writePaddedFile(bf, kernel.file!!, info.pageSize)
                if (ramdisk.size > 0) {
                    Common.writePaddedFile(bf, ramdisk.file!!, info.pageSize)
                }
                secondBootloader?.let {
                    Common.writePaddedFile(bf, secondBootloader!!.file!!, info.pageSize)
                }
                recoveryDtbo?.let {
                    Common.writePaddedFile(bf, recoveryDtbo!!.file!!, info.pageSize)
                }
                dtb?.let {
                    Common.writePaddedFile(bf, dtb!!.file!!, info.pageSize)
                }
                bf
            }
        //write
        FileOutputStream("${info.output}.clear", true).use { fos ->
            fos.write(bytesV2.array(), 0, bytesV2.position())
        }

        this.toCommandLine().apply {
            addArgument("${info.output}.google")
            log.info(this.toString())
            DefaultExecutor().execute(this)
        }

        Helper.assertFileEquals("${info.output}.clear", "${info.output}.google")

        return this
    }

    private fun toCommandLine(): CommandLine {
        val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
        val ret = CommandLine.parse(cmdPrefix + Helper.prop("mkbootimg"))
        ret.addArgument(" --header_version ")
        ret.addArgument(info.headerVersion.toString())
        ret.addArgument(" --base ")
        ret.addArgument("0x" + java.lang.Long.toHexString(0))
        ret.addArgument(" --kernel ")
        ret.addArgument(kernel.file!!)
        ret.addArgument(" --kernel_offset ")
        ret.addArgument("0x" + Integer.toHexString(kernel.loadOffset.toInt()))
        if (this.ramdisk.size > 0) {
            ret.addArgument(" --ramdisk ")
            ret.addArgument(ramdisk.file)
        }
        ret.addArgument(" --ramdisk_offset ")
        ret.addArgument("0x" + Integer.toHexString(ramdisk.loadOffset.toInt()))
        if (secondBootloader != null) {
            ret.addArgument(" --second ")
            ret.addArgument(secondBootloader!!.file!!)
            ret.addArgument(" --second_offset ")
            ret.addArgument("0x" + Integer.toHexString(secondBootloader!!.loadOffset.toInt()))
        }
        if (!info.board.isNullOrBlank()) {
            ret.addArgument(" --board ")
            ret.addArgument(info.board)
        }
        if (info.headerVersion > 0) {
            if (recoveryDtbo != null) {
                ret.addArgument(" --recovery_dtbo ")
                ret.addArgument(recoveryDtbo!!.file!!)
            }
        }
        if (info.headerVersion > 1) {
            if (dtb != null) {
                ret.addArgument("--dtb ")
                ret.addArgument(dtb!!.file!!)
                ret.addArgument("--dtb_offset ")
                ret.addArgument("0x" + java.lang.Long.toHexString(dtb!!.loadOffset))
            }
        }
        ret.addArgument(" --pagesize ")
        ret.addArgument(info.pageSize.toString())
        ret.addArgument(" --cmdline ")
        ret.addArgument(info.cmdline, false)
        if (!info.osVersion.isNullOrBlank()) {
            ret.addArgument(" --os_version ")
            ret.addArgument(info.osVersion)
        }
        if (!info.osPatchLevel.isNullOrBlank()) {
            ret.addArgument(" --os_patch_level ")
            ret.addArgument(info.osPatchLevel)
        }
        ret.addArgument(" --tags_offset ")
        ret.addArgument("0x" + Integer.toHexString(info.tagsOffset.toInt()))
        ret.addArgument(" --id ")
        ret.addArgument(" --output ")
        //ret.addArgument("boot.img" + ".google")

        log.debug("To Commandline: $ret")

        return ret
    }

    fun sign(): BootV2Dialects {
        //unify with v1.1/v1.2 avbtool
        val avbtool = String.format(Helper.prop("avbtool"), "v1.2")
        if (info.verify.startsWith("VB2.0")) {
            Signer.signAVB(info.output, this.info.imageSize, avbtool)
            log.info("Adding hash_footer with verified-boot 2.0 style")
        } else {
            Signer.signVB1(info.output + ".clear", info.output + ".signed")
        }
        return this
    }

    fun printPackSummary(): BootV2Dialects {
        VendorBoot.printPackSummary(info.output)
        return this
    }

    fun updateVbmeta(): BootV2Dialects {
        Avb.updateVbmeta(info.output)
        return this
    }
}

```

`bbootimg/src/main/kotlin/bootimg/v3/BootHeaderV3.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v3

import cc.cfig.io.Struct
import cfig.bootimg.Common
import org.slf4j.LoggerFactory
import java.io.InputStream

class BootHeaderV3(
    var kernelSize: Int = 0,
    var ramdiskSize: Int = 0,
    var osVersion: String = "",
    var osPatchLevel: String = "",
    var headerSize: Int = 0,
    var headerVersion: Int = 0,
    var cmdline: String = "",
    var signatureSize: Int = 0
) {
    @Throws(IllegalArgumentException::class)
    constructor(iS: InputStream?) : this() {
        if (iS == null) {
            return
        }
        log.warn("BootImgHeaderV3/V4 constructor")
        val info = Struct(FORMAT_STRING).unpack(iS)
        check(12 == info.size)
        if (info[0] != magic) {
            throw IllegalArgumentException("stream doesn't look like Android Boot Image V3 Header")
        }
        this.kernelSize = (info[1] as UInt).toInt()
        this.ramdiskSize = (info[2] as UInt).toInt()
        val osNPatch = info[3] as UInt
        if (0U != osNPatch) { //treated as 'reserved' in this boot image
            this.osVersion = Common.parseOsVersion(osNPatch.toInt() shr 11)
            this.osPatchLevel = Common.parseOsPatchLevel((osNPatch and 0x7ff.toUInt()).toInt())
        }
        this.headerSize = (info[4] as UInt).toInt()
        //5,6,7,8 reserved
        this.headerVersion = (info[9] as UInt).toInt()
        this.cmdline = info[10] as String
        this.signatureSize = (info[11] as UInt).toInt()
        check(this.headerSize in intArrayOf(BOOT_IMAGE_HEADER_V3_SIZE, BOOT_IMAGE_HEADER_V4_SIZE))
    }

    fun encode(): ByteArray {
        return Struct(FORMAT_STRING).pack(
            magic,
            kernelSize,
            ramdiskSize,
            (Common.packOsVersion(osVersion) shl 11) or Common.packOsPatchLevel(osPatchLevel),
            headerSize,
            0,
            0,
            0,
            0,
            headerVersion,
            cmdline,
            signatureSize
        )
    }

    fun feature67(): BootHeaderV3 {
        val newHeaderSize = when (headerVersion) {
            3 -> BOOT_IMAGE_HEADER_V3_SIZE
            else -> BOOT_IMAGE_HEADER_V4_SIZE
        }
        if (newHeaderSize != headerSize) {
            log.warn("wrong headerSize, fixed.($headerSize -> $newHeaderSize)")
            headerSize = newHeaderSize
        }
        if (signatureSize != 0 && headerVersion == 3) {
            log.warn("trim bootSignature for headerVersion=3")
            signatureSize = 0
        }
        return this
    }

    override fun toString(): String {
        return "BootImgHeaderV3(kernelSize=$kernelSize, ramdiskSize=$ramdiskSize, osVersion=$osVersion, osPatchLevel=$osPatchLevel, headerSize=$headerSize, headerVersion=$headerVersion, cmdline='$cmdline')"
    }

    companion object {
        internal val log = LoggerFactory.getLogger(BootHeaderV3::class.java)
        const val magic = "ANDROID!"
        const val FORMAT_STRING = "8s" + //"ANDROID!"
                "4I" +    //kernel size, ramdisk size, os_version/patch, header size
                "4I" +    //reserved
                "I" +     //header version
                "1536s" + //cmdline
                "I"       //signature size
        private const val BOOT_IMAGE_HEADER_V3_SIZE = 1580
        private const val BOOT_IMAGE_HEADER_V4_SIZE = 1584
        const val pageSize: Int = 4096

        init {
            check(BOOT_IMAGE_HEADER_V4_SIZE == Struct(FORMAT_STRING).calcSize()) {
                "internal error: expected size $BOOT_IMAGE_HEADER_V4_SIZE "
            }
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/v3/BootV3.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v3

import avb.AVBInfo
import avb.alg.Algorithms
import avb.blob.AuxBlob
import cfig.Avb
import cfig.utils.EnvironmentVerifier
import cfig.bootimg.Common.Companion.deleleIfExists
import cfig.bootimg.Common.Companion.getPaddingSize
import cfig.bootimg.Signer
import cfig.helper.Helper
import cfig.helper.Dumpling
import cfig.packable.VBMetaParser
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import cfig.bootimg.Common as C

data class BootV3(
    var info: MiscInfo = MiscInfo(),
    var kernel: CommArgs = CommArgs(),
    val ramdisk: CommArgs = CommArgs(),
    var bootSignature: CommArgs = CommArgs(),
) {
    companion object {
        private val log = LoggerFactory.getLogger(BootV3::class.java)
        private val errLog = LoggerFactory.getLogger("uiderrors")
        private val mapper = ObjectMapper()
        private val workDir = Helper.prop("workDir")

        fun parse(fileName: String): BootV3 {
            val ret = BootV3()
            FileInputStream(fileName).use { fis ->
                val header = BootHeaderV3(fis)
                //info
                ret.info.output = File(fileName).name
                ret.info.json = File(fileName).name.removeSuffix(".img") + ".json"
                ret.info.cmdline = header.cmdline
                ret.info.headerSize = header.headerSize
                ret.info.headerVersion = header.headerVersion
                ret.info.osVersion = header.osVersion
                ret.info.osPatchLevel = header.osPatchLevel
                ret.info.pageSize = BootHeaderV3.pageSize
                ret.info.signatureSize = header.signatureSize
                //kernel
                ret.kernel.file = workDir + "kernel"
                ret.kernel.size = header.kernelSize
                ret.kernel.position = BootHeaderV3.pageSize
                //ramdisk
                ret.ramdisk.file = workDir + "ramdisk.img"
                ret.ramdisk.size = header.ramdiskSize
                ret.ramdisk.position = ret.kernel.position + header.kernelSize +
                        getPaddingSize(header.kernelSize, BootHeaderV3.pageSize)
                //boot signature
                if (header.signatureSize > 0) {
                    ret.bootSignature.file = workDir + "bootsig"
                    ret.bootSignature.size = header.signatureSize
                    ret.bootSignature.position = ret.ramdisk.position + ret.ramdisk.size +
                            getPaddingSize(header.ramdiskSize, BootHeaderV3.pageSize)
                }
            }
            ret.info.imageSize = File(fileName).length()
            return ret
        }
    }

    data class MiscInfo(
        var output: String = "",
        var json: String = "",
        var headerVersion: Int = 0,
        var headerSize: Int = 0,
        var pageSize: Int = 0,
        var cmdline: String = "",
        var osVersion: String = "",
        var osPatchLevel: String = "",
        var imageSize: Long = 0,
        var signatureSize: Int = 0,
    )

    data class CommArgs(
        var file: String = "",
        var position: Int = 0,
        var size: Int = 0,
    )

    fun pack(): BootV3 {
        if (this.kernel.size > 0) {
            this.kernel.size = File(this.kernel.file).length().toInt()
        }
        if (this.ramdisk.size > 0) {
            if (File(this.ramdisk.file).exists() && !File(workDir + "root").exists()) {
                //do nothing if we have ramdisk.img.gz but no /root
                log.warn("Use prebuilt ramdisk file: ${this.ramdisk.file}")
            } else {
                File(this.ramdisk.file).deleleIfExists()
                File(this.ramdisk.file.replaceFirst("[.][^.]+$", "")).deleleIfExists()
                //TODO: remove cpio in C/C++
                //C.packRootfs("$workDir/root", this.ramdisk.file, C.parseOsMajor(info.osVersion))
                // enable advance JAVA cpio
                C.packRootfs("$workDir/root", this.ramdisk.file)
            }
            this.ramdisk.size = File(this.ramdisk.file).length().toInt()
        }

        //header
        FileOutputStream(this.info.output + ".clear", false).use { fos ->
            //trim bootSig if it's not parsable
            //https://github.com/cfig/Android_boot_image_editor/issues/88
            File(Avb.getJsonFileName(this.bootSignature.file)).let { bootSigJson ->
                if (!bootSigJson.exists()) {
                    errLog.info(
                        "erase unparsable boot signature in header. Refer to https://github.com/cfig/Android_boot_image_editor/issues/88"
                    )
                    this.info.signatureSize = 0
                }
            }
            val encodedHeader = this.toHeader().encode()
            fos.write(encodedHeader)
            fos.write(
                ByteArray(Helper.round_to_multiple(encodedHeader.size, this.info.pageSize) - encodedHeader.size)
            )
        }

        //data
        log.info("Writing data ...")
        //BootV3 should have correct image size
        val bf = ByteBuffer.allocate(maxOf(info.imageSize.toInt(), 64 * 1024 * 1024))
        bf.order(ByteOrder.LITTLE_ENDIAN)
        if (kernel.size > 0) {
            C.writePaddedFile(bf, this.kernel.file, this.info.pageSize)
        }
        if (ramdisk.size > 0) {
            C.writePaddedFile(bf, this.ramdisk.file, this.info.pageSize)
        }
        //write V3 data
        FileOutputStream("${this.info.output}.clear", true).use { fos ->
            fos.write(bf.array(), 0, bf.position())
        }

        //write V4 boot sig
        if (this.info.headerVersion > 3) {
            val bootSigJson = File(Avb.getJsonFileName(this.bootSignature.file))
            var bootSigBytes = ByteArray(this.bootSignature.size)
            if (bootSigJson.exists()) {
                log.warn("V4 BootImage has GKI boot signature")
                val readBackBootSig = mapper.readValue(bootSigJson, AVBInfo::class.java)
                val alg = Algorithms.get(readBackBootSig.header!!.algorithm_type)!!
                //replace new pub key
                readBackBootSig.auxBlob!!.pubkey!!.pubkey = AuxBlob.encodePubKey(alg)
                //update hash and sig
                readBackBootSig.auxBlob!!.hashDescriptors.get(0).update(this.info.output + ".clear")
                bootSigBytes = readBackBootSig.encodePadded()
            }
            if (this.info.signatureSize > 0) {
                //write V4 data
                FileOutputStream("${this.info.output}.clear", true).use { fos ->
                    fos.write(bootSigBytes)
                }
            } else {
                errLog.info("ignore bootsig for v4 boot.img")
            }
        }

        //google way
        this.toCommandLine().addArgument(this.info.output + ".google").let {
            log.info(it.toString())
            DefaultExecutor().execute(it)
        }

        Helper.assertFileEquals(this.info.output + ".clear", this.info.output + ".google")
        File(this.info.output + ".google").delete()
        return this
    }

    fun sign(fileName: String): BootV3 {
        if (File(Avb.getJsonFileName(info.output)).exists()) {
            Signer.signAVB(fileName, this.info.imageSize, String.format(Helper.prop("avbtool"), "v1.2"))
        } else {
            log.warn("no AVB info found, assume it's clear image")
        }
        return this
    }

    private fun toHeader(): BootHeaderV3 {
        return BootHeaderV3(
            kernelSize = kernel.size,
            ramdiskSize = ramdisk.size,
            headerVersion = info.headerVersion,
            osVersion = info.osVersion,
            osPatchLevel = info.osPatchLevel,
            headerSize = info.headerSize,
            cmdline = info.cmdline,
            signatureSize = info.signatureSize
        ).feature67()
    }

    fun extractImages(): BootV3 {
        val workDir = Helper.prop("workDir")
        //info
        mapper.writerWithDefaultPrettyPrinter().writeValue(File(workDir + this.info.json), this)
        //kernel
        if (kernel.size > 0) {
            C.dumpKernel(Helper.Slice(info.output, kernel.position, kernel.size, kernel.file))
        } else {
            log.warn("${this.info.output} has no kernel")
        }
        //ramdisk
        if (ramdisk.size > 0) {
            val fmt = C.dumpRamdisk(
                Helper.Slice(info.output, ramdisk.position, ramdisk.size, ramdisk.file), "${workDir}root"
            )
            this.ramdisk.file = this.ramdisk.file + ".$fmt"
        }
        //bootsig

        //dump info again
        mapper.writerWithDefaultPrettyPrinter().writeValue(File(workDir + this.info.json), this)
        return this
    }

    fun extractVBMeta(): BootV3 {
        // vbmeta in image
        try {
            val ai = AVBInfo.parseFrom(Dumpling(info.output)).dumpDefault(info.output)
            if (File("vbmeta.img").exists()) {
                log.warn("Found vbmeta.img, parsing ...")
                VBMetaParser().unpack("vbmeta.img")
            }
        } catch (e: IllegalArgumentException) {
            log.warn(e.message)
            log.warn("failed to parse vbmeta info")
        }

        //GKI 1.0 bootsig
        if (info.signatureSize > 0) {
            log.info("GKI 1.0 signature")
            Dumpling(info.output).readFully(Pair(this.bootSignature.position.toLong(), this.bootSignature.size))
                .let { bootsigData ->
                    File(this.bootSignature.file).writeBytes(bootsigData)
                    if (bootsigData.any { it.toInt() != 0 }) {
                        try {
                            val bootsig = AVBInfo.parseFrom(Dumpling(bootsigData)).dumpDefault(this.bootSignature.file)
                            Avb.verify(bootsig, Dumpling(bootsigData, "bootsig"))
                        } catch (e: IllegalArgumentException) {
                            log.warn("GKI 1.0 boot signature is invalid")
                        }
                    } else {
                        log.warn("GKI 1.0 boot signature has only NULL data")
                    }
                }
            return this
        }

        //GKI 2.0 bootsig
        if (!File(Avb.getJsonFileName(info.output)).exists()) {
            log.info("no AVB info found in ${info.output}")
            return this
        }
        log.info("probing 16KB boot signature ...")
        val mainBlob = ObjectMapper().readValue(
            File(Avb.getJsonFileName(info.output)),
            AVBInfo::class.java
        )
        val bootSig16kData =
            Dumpling(Dumpling(info.output).readFully(Pair(mainBlob.footer!!.originalImageSize - 16 * 1024, 16 * 1024)))
        try {
            val blob1 = AVBInfo.parseFrom(bootSig16kData)
                .also { check(it.auxBlob!!.hashDescriptors[0].partition_name == "boot") }
                .also { it.dumpDefault("sig.boot") }
            val blob2 =
                AVBInfo.parseFrom(Dumpling(bootSig16kData.readFully(blob1.encode().size until bootSig16kData.getLength())))
                    .also { check(it.auxBlob!!.hashDescriptors[0].partition_name == "generic_kernel") }
                    .also { it.dumpDefault("sig.kernel") }
            val gkiAvbData = bootSig16kData.readFully(blob1.encode().size until bootSig16kData.getLength())
            File("${workDir}kernel.img").let { gki ->
                File("${workDir}kernel").copyTo(gki)
                System.setProperty("more", workDir)
                Avb.verify(blob2, Dumpling(gkiAvbData))
                gki.delete()
            }
            log.info(blob1.auxBlob!!.hashDescriptors[0].partition_name)
            log.info(blob2.auxBlob!!.hashDescriptors[0].partition_name)
        } catch (e: IllegalArgumentException) {
            log.warn("can not find boot signature: " + e.message)
        }

        return this
    }

    fun printSummary(): BootV3 {
        val workDir = Helper.prop("workDir")
        val tableHeader = AsciiTable().apply {
            addRule()
            addRow("What", "Where")
            addRule()
        }
        val tab = AsciiTable().let {
            it.addRule()
            it.addRow("image info", workDir + info.output.removeSuffix(".img") + ".json")
            it.addRule()
            if (this.kernel.size > 0) {
                it.addRow("kernel", this.kernel.file)
                File(Helper.prop("kernelVersionFile")).let { kernelVersionFile ->
                    if (kernelVersionFile.exists()) {
                        it.addRow("\\-- version " + kernelVersionFile.readLines().toString(), kernelVersionFile.path)
                    }
                }
                File(Helper.prop("kernelConfigFile")).let { kernelConfigFile ->
                    if (kernelConfigFile.exists()) {
                        it.addRow("\\-- config", kernelConfigFile.path)
                    }
                }
                it.addRule()
            }
            if (this.ramdisk.size > 0) {
                it.addRow("ramdisk", this.ramdisk.file)
                it.addRow("\\-- extracted ramdisk rootfs", "${workDir}root")
                it.addRule()
            }
            if (this.info.signatureSize > 0) {
                it.addRow("GKI signature 1.0", this.bootSignature.file)
                File(Avb.getJsonFileName(this.bootSignature.file)).let { jsFile ->
                    it.addRow("\\-- decoded boot signature", if (jsFile.exists()) jsFile.path else "N/A")
                    if (jsFile.exists()) {
                        it.addRow("\\------ signing key", Avb.inspectKey(mapper.readValue(jsFile, AVBInfo::class.java)))
                    }
                }
                it.addRule()
            }

            //GKI signature 2.0
            File(Avb.getJsonFileName("sig.boot")).let { jsonFile ->
                if (jsonFile.exists()) {
                    it.addRow("GKI signature 2.0", this.bootSignature.file)
                    it.addRow("\\-- boot", jsonFile.path)
                    it.addRow("\\------ signing key", Avb.inspectKey(mapper.readValue(jsonFile, AVBInfo::class.java)))
                }
            }
            File(Avb.getJsonFileName("sig.kernel")).let { jsonFile ->
                if (jsonFile.exists()) {
                    val readBackAvb = mapper.readValue(jsonFile, AVBInfo::class.java)
                    it.addRow("\\-- kernel", jsonFile.path)
                    it.addRow("\\------ signing key", Avb.inspectKey(readBackAvb))
                    it.addRule()
                }
            }

            //AVB info
            Avb.getJsonFileName(info.output).let { jsonFile ->
                it.addRow("AVB info", if (File(jsonFile).exists()) jsonFile else "NONE")
                if (File(jsonFile).exists()) {
                    mapper.readValue(File(jsonFile), AVBInfo::class.java).let { ai ->
                        it.addRow("\\------ signing key", Avb.inspectKey(ai))
                    }
                }
            }
            it.addRule()
            it
        }
        val tabVBMeta = AsciiTable().let {
            if (File("vbmeta.img").exists()) {
                it.addRule()
                it.addRow("vbmeta.img", Avb.getJsonFileName("vbmeta.img"))
                it.addRule()
                "\n" + it.render()
            } else {
                ""
            }
        }
        log.info(
            "\n\t\t\tUnpack Summary of ${info.output}\n{}\n{}{}",
            tableHeader.render(), tab.render(), tabVBMeta
        )
        return this
    }

    fun printPackSummary(): BootV3 {
        VendorBoot.printPackSummary(info.output)
        return this
    }

    fun updateVbmeta(): BootV3 {
        Avb.updateVbmeta(info.output)
        return this
    }

    private fun toCommandLine(): CommandLine {
        val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
        return CommandLine.parse(cmdPrefix + Helper.prop("mkbootimg")).let { ret ->
            ret.addArgument("--header_version")
            ret.addArgument(info.headerVersion.toString())
            if (kernel.size > 0) {
                ret.addArgument("--kernel")
                ret.addArgument(this.kernel.file)
            }
            if (ramdisk.size > 0) {
                ret.addArgument("--ramdisk")
                ret.addArgument(this.ramdisk.file)
            }
            if (info.cmdline.isNotBlank()) {
                ret.addArgument(" --cmdline ")
                ret.addArgument(info.cmdline, false)
            }
            if (info.osVersion.isNotBlank()) {
                ret.addArgument(" --os_version")
                ret.addArgument(info.osVersion)
            }
            if (info.osPatchLevel.isNotBlank()) {
                ret.addArgument(" --os_patch_level")
                ret.addArgument(info.osPatchLevel)
            }
            if (this.bootSignature.size > 0 && File(Avb.getJsonFileName(this.bootSignature.file)).exists()) {
                val origSig = mapper.readValue(File(Avb.getJsonFileName(this.bootSignature.file)), AVBInfo::class.java)
                val alg = Algorithms.get(origSig.header!!.algorithm_type)!!
                ret.addArgument("--gki_signing_algorithm").addArgument(alg.name)
                ret.addArgument("--gki_signing_key").addArgument(alg.defaultKey)
                ret.addArgument("--gki_signing_avbtool_path").addArgument(String.format(Helper.prop("avbtool"), "v1.2"))
            }
            ret.addArgument(" --id ")
            ret.addArgument(" --output ")
            //ret.addArgument("boot.img" + ".google")

            log.debug("To Commandline: $ret")
            ret
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/v3/VendorBoot.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v3

import avb.AVBInfo
import cc.cfig.io.Struct
import cfig.Avb
import cfig.utils.EnvironmentVerifier
import cfig.bootimg.Common.Companion.deleleIfExists
import cfig.bootimg.Signer
import cfig.helper.Helper
import cfig.helper.Dumpling
import cfig.packable.VBMetaParser
import cfig.utils.DTC
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.*
import java.nio.ByteBuffer
import java.nio.ByteOrder
import cfig.bootimg.Common as C

data class VendorBoot(
    var info: MiscInfo = MiscInfo(),
    var ramdisk: CommArgs = CommArgs(),
    var dtb: CommArgs = CommArgs(),
    var ramdisk_table: Vrt = Vrt(),
    var bootconfig: CommArgs = CommArgs(),
) {
    data class CommArgs(
        var file: String = "",
        var position: Long = 0,
        var size: Int = 0,
        var loadAddr: Long = 0,
    )

    data class MiscInfo(
        var output: String = "",
        var json: String = "",
        var headerVersion: Int = 0,
        var product: String = "",
        var headerSize: Int = 0,
        var pageSize: Int = 0,
        var cmdline: String = "",
        var tagsLoadAddr: Long = 0,
        var kernelLoadAddr: Long = 0,
        var imageSize: Long = 0,
    )

    enum class VrtType {
        NONE,
        PLATFORM,
        RECOVERY,
        DLKM;

        companion object {
            fun fromInt(value: Int): VrtType {
                return when (value) {
                    NONE.ordinal -> NONE
                    PLATFORM.ordinal -> PLATFORM
                    RECOVERY.ordinal -> RECOVERY
                    DLKM.ordinal -> DLKM
                    else -> throw IllegalArgumentException("illegal VrtType $value")
                }
            }
        }
    }

    class Vrt(
        var size: Int = 0,
        var eachEntrySize: Int = 0,
        var position: Long = 0,
        var ramdidks: MutableList<VrtEntry> = mutableListOf(),
    ) {
        fun update(): Vrt {
            var totalSz = 0
            this.ramdidks.forEachIndexed { _, vrtEntry ->
                vrtEntry.offset = totalSz
                vrtEntry.size = File(vrtEntry.file).length().toInt()
                totalSz += vrtEntry.size
            }
            return this
        }

        fun encode(inPageSize: Int): ByteArray {
            val bf = ByteBuffer.allocate(8192)
            this.ramdidks.forEach {
                bf.put(it.encode())
            }
            val realSize = bf.position()
            val ret = ByteArray(Helper.round_to_multiple(realSize, inPageSize))
            bf.array().copyInto(ret, 0, 0, realSize)
            return ret
        }
    }

    class VrtEntry(
        var size: Int = 0,
        var offset: Int = 0,
        var type: VrtType = VrtType.NONE,
        var name: String = "", //32s
        var boardId: ByteArray = byteArrayOf(), //16I (aka. 64 bytes)
        var boardIdStr: String = "",
        var file: String = "",
    ) {
        companion object {
            private const val VENDOR_RAMDISK_NAME_SIZE = 32
            const val VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE = 16

            //const val FORMAT_STRING = "3I${VENDOR_RAMDISK_NAME_SIZE}s${VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE}I"
            const val FORMAT_STRING = "3I${VENDOR_RAMDISK_NAME_SIZE}s${VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE * 4}b"
            const val SIZE = 108

            init {
                check(Struct(FORMAT_STRING).calcSize() == SIZE)
            }
        }

        constructor(iS: InputStream?, dumpFile: String) : this() {
            if (iS == null) {
                return
            }
            val info = Struct(FORMAT_STRING).unpack(iS)
            check((3 + 1 + 1) == info.size)
            this.size = (info[0] as UInt).toInt()
            this.offset = (info[1] as UInt).toInt()
            this.type = VrtType.fromInt((info[2] as UInt).toInt())
            this.name = info[3] as String
            this.boardId = info[4] as ByteArray
            this.boardIdStr = Struct.StringFleet().get(boardId, ByteOrder.LITTLE_ENDIAN)
            this.file = dumpFile
        }

        fun encode(): ByteArray {
            return Struct(FORMAT_STRING).pack(this.size, this.offset, this.type.ordinal, this.name, this.boardId)
        }

        override fun toString(): String {
            return "VrtEntry(size=$size, offset=$offset, type=$type, name='$name', boardIdStr='$boardIdStr', file='$file')"
        }
    }

    companion object {
        private val log = LoggerFactory.getLogger(VendorBoot::class.java)
        private val workDir = Helper.prop("workDir")
        private val mapper = ObjectMapper()
        private val dtsSuffix = Helper.prop("config.dts_suffix")
        fun parse(fileName: String): VendorBoot {
            val ret = VendorBoot()
            FileInputStream(fileName).use { fis ->
                val header = VendorBootHeader(fis)
                ret.info.output = File(fileName).name
                ret.info.json = File(fileName).name.removeSuffix(".img") + ".json"
                ret.info.headerSize = header.headerSize
                ret.info.product = header.product
                ret.info.tagsLoadAddr = header.tagsLoadAddr
                ret.info.cmdline = header.cmdline
                ret.info.kernelLoadAddr = header.kernelLoadAddr
                ret.info.pageSize = header.pageSize
                ret.info.headerVersion = header.headerVersion
                //ramdisk
                ret.ramdisk.file = workDir + "ramdisk.img"
                ret.ramdisk.size = header.vndRamdiskTotalSize
                ret.ramdisk.loadAddr = header.ramdiskLoadAddr
                ret.ramdisk.position = Helper.round_to_multiple(
                    VendorBootHeader.VENDOR_BOOT_IMAGE_HEADER_V3_SIZE, header.pageSize
                ).toLong()
                //dtb
                ret.dtb.file = workDir + "dtb"
                ret.dtb.size = header.dtbSize
                ret.dtb.loadAddr = header.dtbLoadAddr
                ret.dtb.position = ret.ramdisk.position + Helper.round_to_multiple(ret.ramdisk.size, header.pageSize)
                //vrt
                if (header.vrtSize > 0) {
                    ret.ramdisk_table.size = header.vrtSize
                    ret.ramdisk_table.eachEntrySize = header.vrtEntrySize
                    ret.ramdisk_table.position =
                        ret.dtb.position + Helper.round_to_multiple(ret.dtb.size, header.pageSize)
                    FileInputStream(ret.info.output).use {
                        it.skip(ret.ramdisk_table.position)
                        for (item in 0 until header.vrtEntryNum) {
                            ret.ramdisk_table.ramdidks.add(VrtEntry(it, workDir + "ramdisk.${item + 1}"))
                        }
                    }
                    ret.ramdisk_table.ramdidks.forEach {
                        log.warn(it.toString())
                    }
                }
                //bootconfig
                if (header.bootconfigSize > 0) {
                    ret.bootconfig.file = workDir + "bootconfig"
                    ret.bootconfig.size = header.bootconfigSize
                    ret.bootconfig.position =
                        ret.ramdisk_table.position + Helper.round_to_multiple(ret.bootconfig.size, header.pageSize)
                }
            }
            ret.info.imageSize = File(fileName).length()
            return ret
        }

        fun printPackSummary(imageName: String) {
            val tableHeader = AsciiTable().apply {
                addRule()
                addRow("What", "Where")
                addRule()
            }
            val tab = AsciiTable().let {
                it.addRule()
                if (File("$imageName.signed").exists()) {
                    it.addRow("re-packed $imageName", "$imageName.signed")
                } else {
                    it.addRow("re-packed $imageName", "$imageName.clear")
                }
                it.addRule()
                it
            }
            if (File("vbmeta.img").exists()) {
                if (File("vbmeta.img.signed").exists()) {
                    tab.addRow("re-packed vbmeta", "vbmeta.img.signed")
                } else {
                    tab.addRow("re-packed vbmeta", "-")
                }
                tab.addRule()
            }
            log.info("\n\t\t\tPack Summary of ${imageName}\n{}\n{}", tableHeader.render(), tab.render())
        }

    }

    fun pack(): VendorBoot {
        when (this.info.headerVersion) {
            3 -> {
                if (File(workDir + this.ramdisk.file).exists() && !File(workDir + "root").exists()) {
                    //do nothing if we have ramdisk.img.gz but no /root
                    log.warn("Use prebuilt ramdisk file: ${this.ramdisk.file}")
                } else {
                    File(this.ramdisk.file).deleleIfExists()
                    File(this.ramdisk.file.removeSuffix(".gz")).deleleIfExists()
                    //Fixed: remove cpio in C/C++
                    //C.packRootfs("$workDir/root", this.ramdisk.file, parseOsMajor())
                    //enable advance JAVA cpio
                    C.packRootfs("$workDir/root", this.ramdisk.file)
                }
                this.ramdisk.size = File(this.ramdisk.file).length().toInt()
            }
            else -> {
                this.ramdisk_table.ramdidks.forEachIndexed { index, it ->
                    File(it.file).deleleIfExists()
                    log.info(workDir + "root.${index + 1} -> " + it.file)
                    C.packRootfs(workDir + "root.${index + 1}", it.file)
                }
                this.ramdisk.size = this.ramdisk_table.ramdidks.sumOf { File(it.file).length() }.toInt()
            }
        }
        //update dtb
        if (File(this.dtb.file + ".${dtsSuffix}").exists()) {
            check(DTC().compile(this.dtb.file + ".${dtsSuffix}", this.dtb.file)) { "fail to compile dts" }
        }
        this.dtb.size = File(this.dtb.file).length().toInt()
        //header
        FileOutputStream(this.info.output + ".clear", false).use { fos ->
            val encodedHeader = this.toHeader().encode()
            fos.write(encodedHeader)
            fos.write(ByteArray(Helper.round_to_multiple(encodedHeader.size, this.info.pageSize) - encodedHeader.size))
        }
        //data
        log.info("Writing data ...")
        val bf = when (this.info.headerVersion) {
            //assume total SIZE is smaller than 128MB
            3 -> {
                ByteBuffer.allocate(1024 * 1024 * 128).let {
                    it.order(ByteOrder.LITTLE_ENDIAN)
                    //1. vendor ramdisks and dtb
                    C.writePaddedFile(it, this.ramdisk.file, this.info.pageSize)
                    C.writePaddedFile(it, this.dtb.file, this.info.pageSize)
                    it
                }
            }
            else -> {
                ByteBuffer.allocate(1024 * 1024 * 128).let {
                    it.order(ByteOrder.LITTLE_ENDIAN)
                    //1. vendor ramdisks and dtb
                    C.writePaddedFiles(it, this.ramdisk_table.ramdidks.map { rd -> rd.file }, this.info.pageSize)
                    C.writePaddedFile(it, this.dtb.file, this.info.pageSize)
                    //2. vrt
                    it.put(this.ramdisk_table.update().encode(this.info.pageSize))
                    //3. bootconfig
                    if (this.bootconfig.file.isNotBlank()) {
                        C.writePaddedFile(it, this.bootconfig.file, this.info.pageSize)
                    }
                    it
                }
            }
        }
        //write
        FileOutputStream("${this.info.output}.clear", true).use { fos ->
            fos.write(bf.array(), 0, bf.position())
        }

        //google way
        this.toCommandLine().addArgument(this.info.output + ".google").let {
            log.info(it.toString())
            DefaultExecutor().execute(it)
        }

        Helper.assertFileEquals(this.info.output + ".clear", this.info.output + ".google")
        return this
    }

    fun sign(): VendorBoot {
        val avbtool = String.format(Helper.prop("avbtool"), "v1.2")
        File(Avb.getJsonFileName(info.output)).let {
            if (it.exists()) {
                Signer.signAVB(info.output, this.info.imageSize, avbtool)
            } else {
                log.warn("skip signing of ${info.output}")
            }
        }
        return this
    }

    fun updateVbmeta(): VendorBoot {
        Avb.updateVbmeta(info.output)
        return this
    }

    private fun toHeader(): VendorBootHeader {
        return VendorBootHeader(
            headerVersion = info.headerVersion,
            pageSize = info.pageSize,
            kernelLoadAddr = info.kernelLoadAddr,
            ramdiskLoadAddr = ramdisk.loadAddr,
            vndRamdiskTotalSize = ramdisk.size,
            cmdline = info.cmdline,
            tagsLoadAddr = info.tagsLoadAddr,
            product = info.product,
            headerSize = info.headerSize,
            dtbSize = dtb.size,
            dtbLoadAddr = dtb.loadAddr,
            vrtSize = ramdisk_table.eachEntrySize * ramdisk_table.ramdidks.size,
            vrtEntryNum = ramdisk_table.ramdidks.size,
            vrtEntrySize = ramdisk_table.eachEntrySize,
            bootconfigSize = File(bootconfig.file).length().toInt()
        ).feature67()
    }

    fun extractImages(): VendorBoot {
        //header
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File(workDir + this.info.json), this)
        //ramdisk
        //@formatter:off
        val fmt = C.dumpRamdisk(
            Helper.Slice(info.output, ramdisk.position.toInt(), ramdisk.size, ramdisk.file), "${workDir}root",
            this.ramdisk_table.ramdidks.isEmpty())
        //@formatter:on
        this.ramdisk.file = this.ramdisk.file + ".$fmt"
        //dtb
        C.dumpDtb(Helper.Slice(info.output, dtb.position.toInt(), dtb.size, dtb.file))
        //vrt
        this.ramdisk_table.ramdidks.forEachIndexed { index, it ->
            log.info("dumping vendor ramdisk ${index + 1}/${this.ramdisk_table.ramdidks.size} ...")
            val s = Helper.Slice(ramdisk.file, it.offset, it.size, it.file)
            C.dumpRamdisk(s, workDir + "root.${index + 1}")
            it.file = it.file + ".$fmt"
        }
        //bootconfig
        if (bootconfig.size > 0) {
            Helper.Slice(info.output, bootconfig.position.toInt(), bootconfig.size, bootconfig.file).let { s ->
                Helper.extractFile(s.srcFile, s.dumpFile, s.offset.toLong(), s.length)
            }
        }
        //dump info again
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File(workDir + this.info.json), this)
        return this
    }

    fun extractVBMeta(): VendorBoot {
        try {
            AVBInfo.parseFrom(Dumpling(info.output)).dumpDefault(info.output)
        } catch (e: Exception) {
            log.error("extraceVBMeta(): $e")
        }
        if (File("vbmeta.img").exists()) {
            log.warn("Found vbmeta.img, parsing ...")
            VBMetaParser().unpack("vbmeta.img")
        }
        return this
    }

    fun printUnpackSummary(): VendorBoot {
        val tableHeader = AsciiTable().apply {
            addRule()
            addRow("What", "Where")
            addRule()
        }
        val tab = AsciiTable().let {
            it.addRule()
            it.addRow("image info", workDir + info.output.removeSuffix(".img") + ".json")
            it.addRule()
            it.addRow("ramdisk", this.ramdisk.file)
            if (this.ramdisk_table.size > 0) {
                this.ramdisk_table.ramdidks.forEachIndexed { index, entry ->
                    it.addRow("-- ${entry.type} ramdisk[${index + 1}/${this.ramdisk_table.ramdidks.size}]", entry.file)
                    it.addRow("------- extracted rootfs", "${workDir}root.${index + 1}")
                }
            } else {
                it.addRow("\\-- extracted ramdisk rootfs", "${workDir}root")
            }
            it.addRule()
            it.addRow("dtb", this.dtb.file)
            if (File(this.dtb.file + ".${dtsSuffix}").exists()) {
                it.addRow("\\-- decompiled dts", dtb.file + ".${dtsSuffix}")
            }
            if (this.bootconfig.size > 0) {
                it.addRule()
                it.addRow("bootconfig", this.bootconfig.file)
            }
            it.addRule()
            Avb.getJsonFileName(info.output).let { jsonFile ->
                if (File(jsonFile).exists()) {
                    it.addRow("AVB info", jsonFile)
                    mapper.readValue(File(jsonFile), AVBInfo::class.java).let { ai ->
                        it.addRow("\\-- signing key", Avb.inspectKey(ai))
                    }
                } else {
                    it.addRow("AVB info", "none")
                }
                it.addRule()
            }
            it
        }
        val tabVBMeta = AsciiTable().let {
            if (File("vbmeta.img").exists()) {
                it.addRule()
                it.addRow("vbmeta.img", Avb.getJsonFileName("vbmeta.img"))
                it.addRule()
                "\n" + it.render()
            } else {
                ""
            }
        }
        log.info("\n\t\t\tUnpack Summary of ${info.output}\n{}\n{}{}", tableHeader.render(), tab.render(), tabVBMeta)
        return this
    }

    fun printPackSummary(): VendorBoot {
        printPackSummary(info.output)
        return this
    }

    private fun toCommandLine(): CommandLine {
        val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
        return CommandLine.parse(cmdPrefix + Helper.prop("mkbootimg")).apply {
            when (info.headerVersion) {
                3 -> {
                    addArgument("--vendor_ramdisk").addArgument(ramdisk.file)
                }
                else -> {
                    ramdisk_table.ramdidks.forEachIndexed { index, it ->
                        log.info("dumping vendor ramdisk ${index + 1}/${ramdisk_table.ramdidks.size} ...")
                        addArgument("--ramdisk_type").addArgument(it.type.toString())
                        Struct("${VrtEntry.VENDOR_RAMDISK_TABLE_ENTRY_BOARD_ID_SIZE}i").unpack(ByteArrayInputStream(it.boardId))
                            .forEachIndexed { boardIdIndex, boardIdValue ->
                                addArgument("--board_id$boardIdIndex")
                                addArgument("0x" + Integer.toHexString((boardIdValue as Int)))
                            }
                        if (EnvironmentVerifier().isWindows) {
                            addArgument("--ramdisk_name").addArgument("\"${it.name}\"", false)
                        } else {
                            addArgument("--ramdisk_name").addArgument(it.name, true)
                        }
                        addArgument("--vendor_ramdisk_fragment").addArgument(it.file)
                    }
                    if (bootconfig.file.isNotBlank()) {
                        addArgument("--vendor_bootconfig").addArgument(bootconfig.file)
                    }
                }
            }
            if (info.product.isNotBlank()) {
                addArgument("--board").addArgument(info.product)
            }
            addArgument("--dtb").addArgument(dtb.file)
            addArgument("--vendor_cmdline").addArgument(info.cmdline, false)
            addArgument("--header_version").addArgument(info.headerVersion.toString())
            addArgument("--base").addArgument("0")
            addArgument("--tags_offset").addArgument(info.tagsLoadAddr.toString())
            addArgument("--kernel_offset").addArgument(info.kernelLoadAddr.toString())
            addArgument("--ramdisk_offset").addArgument(ramdisk.loadAddr.toString())
            addArgument("--dtb_offset").addArgument(dtb.loadAddr.toString())
            addArgument("--pagesize").addArgument(info.pageSize.toString())
            addArgument("--vendor_boot")
        }
    }
}

```

`bbootimg/src/main/kotlin/bootimg/v3/VendorBootHeader.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bootimg.v3

import cc.cfig.io.Struct
import org.slf4j.LoggerFactory
import java.io.InputStream

class VendorBootHeader(
    var headerVersion: Int = 0,
    var pageSize: Int = 0,
    var kernelLoadAddr: Long = 0,
    var ramdiskLoadAddr: Long = 0,
    var vndRamdiskTotalSize: Int = 0,
    var cmdline: String = "",
    var tagsLoadAddr: Long = 0,
    var product: String = "",
    var headerSize: Int = 0,
    var dtbSize: Int = 0,
    var dtbLoadAddr: Long = 0,
    var vrtSize: Int = 0,
    var vrtEntryNum: Int = 0,
    var vrtEntrySize: Int = 0,
    var bootconfigSize: Int = 0
) {
    @Throws(IllegalArgumentException::class)
    constructor(iS: InputStream?) : this() {
        if (iS == null) {
            return
        }
        log.warn("VendorBootHeader constructor")
        val info = Struct(FORMAT_STRING).unpack(iS)
        check(16 == info.size)
        if (info[0] != magic) {
            throw IllegalArgumentException("stream doesn't look like Android Vendor Boot Image")
        }
        this.headerVersion = (info[1] as UInt).toInt()
        this.pageSize = (info[2] as UInt).toInt()
        this.kernelLoadAddr = (info[3] as UInt).toLong()
        this.ramdiskLoadAddr = (info[4] as UInt).toLong()
        this.vndRamdiskTotalSize = (info[5] as UInt).toInt()
        this.cmdline = info[6] as String
        this.tagsLoadAddr = (info[7] as UInt).toLong()
        this.product = info[8] as String
        this.headerSize = (info[9] as UInt).toInt()
        this.dtbSize = (info[10] as UInt).toInt()
        this.dtbLoadAddr = (info[11] as ULong).toLong()
        this.vrtSize = (info[12] as UInt).toInt()
        this.vrtEntryNum = (info[13] as UInt).toInt()
        this.vrtEntrySize = (info[14] as UInt).toInt()
        this.bootconfigSize = (info[15] as UInt).toInt()

        if (this.headerSize !in arrayOf(VENDOR_BOOT_IMAGE_HEADER_V3_SIZE, VENDOR_BOOT_IMAGE_HEADER_V4_SIZE)) {
            throw IllegalArgumentException("header size " + this.headerSize + " invalid")
        }
        if (this.headerVersion !in 3..4) {
            throw IllegalArgumentException("header version " + this.headerVersion + " invalid")
        }
    }

    // https://github.com/cfig/Android_boot_image_editor/issues/67
    // support vendor_boot headerVersion downgrade from 4 to 3 during re-pack
    fun feature67(): VendorBootHeader {
        val newHeaderSize = when (this.headerVersion) {
            3 -> VendorBootHeader.VENDOR_BOOT_IMAGE_HEADER_V3_SIZE
            else -> VendorBootHeader.VENDOR_BOOT_IMAGE_HEADER_V4_SIZE
        }
        if (newHeaderSize != headerSize) {
            log.warn("wrong headerSize, fixed.($headerSize -> $newHeaderSize)")
            headerSize = newHeaderSize
        }
        if (vrtSize != 0 && headerVersion == 3) {
            log.warn("trim vrt for headerVersion=3")
            vrtSize = 0
            vrtEntryNum = 0
            vrtEntrySize = 0
        }
        return this
    }

    fun encode(): ByteArray {
        return Struct(FORMAT_STRING).pack(
            magic,
            headerVersion,
            pageSize,
            kernelLoadAddr,
            ramdiskLoadAddr,
            vndRamdiskTotalSize,
            cmdline,
            tagsLoadAddr,
            product,
            headerSize,
            dtbSize,
            dtbLoadAddr,
            vrtSize,
            vrtEntryNum,
            vrtEntrySize,
            bootconfigSize
        )
    }

    companion object {
        private val log = LoggerFactory.getLogger(VendorBootHeader::class.java)
        const val magic = "VNDRBOOT"
        const val VENDOR_BOOT_IMAGE_HEADER_V3_SIZE = 2112
        const val VENDOR_BOOT_IMAGE_HEADER_V4_SIZE = 2128
        const val FORMAT_STRING = "8s" + //magic
                "I" + //header version
                "I" + //page size
                "I" + //kernel physical load addr
                "I" + //ramdisk physical load addr
                "I" + //vendor ramdisk size
                "2048s" + //cmdline
                "I" + //kernel tag load addr
                "16s" + //product name
                "I" + //header size
                "I" + //dtb size
                "Q" + //dtb physical load addr
                "I" + //[v4] vendor ramdisk table size
                "I" + //[v4] vendor ramdisk table entry num
                "I" + //[v4] vendor ramdisk table entry size
                "I"   //[v4] bootconfig size

        init {
            check(Struct(FORMAT_STRING).calcSize() == VENDOR_BOOT_IMAGE_HEADER_V4_SIZE)
        }
    }

    override fun toString(): String {
        return "VendorBootHeader(headerVersion=$headerVersion, pageSize=$pageSize, kernelLoadAddr=$kernelLoadAddr, ramdiskLoadAddr=$ramdiskLoadAddr, vndRamdiskSize=$vndRamdiskTotalSize, cmdline='$cmdline', tagsLoadAddr=$tagsLoadAddr, product='$product', headerSize=$headerSize, dtbSize=$dtbSize, dtbLoadAddr=$dtbLoadAddr, vrtSize=$vrtSize, vrtEntryNum=$vrtEntryNum, vrtEntrySize=$vrtEntrySize, bootconfigSize=$bootconfigSize)"
    }


}

```

`bbootimg/src/main/kotlin/init/BootReason.kt`:

```kt
package init

class BootReason {
    /*
    Canonical boot reason format
        <reason>,<subreason>,<detail>…
     */
    class Reason private constructor(private val reason: String, subReason: String?, detail: String?) {
        companion object {
            val kernelSet = listOf("watchdog", "kernel_panic")
            val strongSet = listOf("recovery", "bootloader")
            val bluntSet = listOf("cold", "hard", "warm", "shutdown", "reboot")
            fun create(
                firstSpanReason: String,
                secondSpanReason: String? = null,
                detailReason: String? = null
            ): Reason {
                if (firstSpanReason !in mutableListOf<String>().apply {
                        addAll(kernelSet)
                        addAll(strongSet)
                        addAll(bluntSet)
                    }) {
                    throw IllegalArgumentException("$firstSpanReason is not allowd first span boot reason in Android")
                }
                return Reason(firstSpanReason, secondSpanReason, detailReason)
            }
        }//end-of-companion
    } //end-of-Reason
} //EOF

```

`bbootimg/src/main/kotlin/init/Reboot.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.init

import miscimg.MiscImage
import org.slf4j.LoggerFactory
import java.util.*

class Reboot {
    enum class RB_TYPE {
        ANDROID_RB_RESTART,
        ANDROID_RB_POWEROFF,
        ANDROID_RB_RESTART2,
        ANDROID_RB_THERMOFF
    }

    companion object {
        private val log = LoggerFactory.getLogger(Reboot::class.java)
        const val dynamicPartitionKey = "ro.boot.dynamic_partitions"
        const val lastRebootReasonKey = "persist.sys.boot.reason"

        private fun doReboot(cmd: RB_TYPE, reason: String, rebootTarget: String) {
            log.info("DoReboot: cmd=$cmd, reason=$reason, tgt=$rebootTarget")
            val reasons = reason.split(",").toTypedArray()
            val props = Properties()
            props.setProperty(lastRebootReasonKey, reason)
            if (reasons.size > 1 && reasons[0] == "reboot") {
                if (reasons[1] in setOf("recovery", "bootloader", "cold", "hard", "warn")) {
                    props.setProperty(lastRebootReasonKey, reason.substring(7))
                } else {
                    //pass
                }
            }
        }

        private fun doReboot(cmd: String, rebootTarget: String) {
            log.info("cmd=[$cmd], rebootTarget=[$rebootTarget]")
        }

        // setprop sys.powerctl <value>
        fun handlePowerctlMessage(inValue: String, props: Properties? = null) {
            log.info("handlePowerctlMessage($inValue)")
            val args = inValue.split(",").toTypedArray()
            var cmd: String
            var rebootTarget = ""
            if (args.size > 4) {
                throw java.lang.IllegalArgumentException("powerctl: unrecognized command $args")
            }
            when (args[0]) {
                "shutdown" -> {
                    cmd = "ANDROID_RB_POWEROFF"
                    if (args.size == 2) {
                        when (args[1]) {
                            "userrequested" -> {
                                log.info("need to run_fsck")
                            }
                            "thermal" -> {
                                cmd = "ANDROID_RB_THERMOFF"
                                log.info("TurnOffBacklight()")
                            }
                            else -> {
                                //pass
                            }
                        }
                    } else {
                        //pass
                    }
                }
                "reboot" -> {
                    cmd = "ANDROID_RB_RESTART2"
                    if (args.size >= 2) {
                        rebootTarget = args[1]
                        val bDynamicPartition: Boolean? = props?.let { propsNotNull ->
                            propsNotNull.get(dynamicPartitionKey)?.let { if (it == "true") true else null }
                        }
                        when (rebootTarget) {
                            "fastboot" -> {
                                val bcb: MiscImage.BootloaderMessage
                                if (bDynamicPartition == null || bDynamicPartition == false) {
                                    log.warn("$dynamicPartitionKey=false, using 'bootloader fastboot' instead of 'fastbootd'")
                                    rebootTarget = "bootloader"
                                    bcb = MiscImage.BootloaderMessage.rebootBootloader()
                                    log.info(bcb.toString())
                                } else {
                                    log.info("$dynamicPartitionKey=true, using fastbootd")
                                    bcb = MiscImage.BootloaderMessage.rebootFastboot2()
                                    rebootTarget = "recovery"
                                }
                                log.info(bcb.toString())
                            }
                            "bootloader" -> {
                                val bcb = MiscImage.BootloaderMessage.rebootBootloader()
                                log.info(bcb.toString())
                            }
                            "sideload", "sideload-auto-reboot" -> {
                                val bcb = MiscImage.BootloaderMessage().apply {
                                    updateBootloaderMessageInStruct(arrayOf("--" + rebootTarget.replace("-", "_")))
                                }
                                log.info(bcb.toString())
                                rebootTarget = "recovery"
                            }
                            else -> {
                            }
                        }//end-of-when-rebootTarget

                        for (i in 2 until args.size) {
                            log.info("rebootTarget: append " + args[i])
                            rebootTarget += ("," + args[i])
                        }
                    }//end-of-cmd
                }//end-of-cmd=reboot
                else -> {//not shutdown/reboot
                    throw java.lang.IllegalArgumentException("powerctl: unrecognized command $args")
                }
            }//end-of-args[0]

            log.debug("ActionManager::GetInstance().ClearQueue()")
            log.debug("ActionManager::GetInstance().QueueEventTrigger(\"shutdown\")")
            log.debug("ActionManager::GetInstance().QueueBuiltinAction(shutdown_handler, \"shutdown_done\")")
            doReboot(cmd, rebootTarget)
        }//end-of-handlePowerctlMessage
    }//end-of-companion
}

```

`bbootimg/src/main/kotlin/miscimg/BootControl.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.bcb

class BootControl {
    data class SlotMetadata(//size: 16
            var priority: Int = 0,
            var triesRemaining: Int = 0,
            var successfulBoot: Boolean = false,
            var verityCorrupted: Boolean = false,
            var reserved: ByteArray = byteArrayOf()
    )

    class BootloaderControl(
            var slotSuffix: String = "",
            var magic: ByteArray = byteArrayOf(),
            var version: Int = 0,
            var slots: Int = 0,
            var recoveryTriesRemaining: Int = 0,
            var mergeStatus: Int = 0,
            var slotMetaData: ByteArray= byteArrayOf(),
            var reserved: ByteArray = byteArrayOf(),
            var crc32: Int = 0
    )
}

```

`bbootimg/src/main/kotlin/miscimg/MiscImage.kt`:

```kt
package miscimg

import cc.cfig.io.Struct
import cfig.helper.Helper
import org.slf4j.LoggerFactory
import java.io.FileInputStream

data class MiscImage(
    var bcb: BootloaderMessage = BootloaderMessage(),
    var virtualAB: VirtualABMessage? = null
) {
    companion object {
        private val log = LoggerFactory.getLogger(MiscImage::class.java)

        fun parse(fileName: String): MiscImage {
            val ret = MiscImage()
            FileInputStream(fileName).use { fis ->
                ret.bcb = BootloaderMessage(fis)
            }
            FileInputStream(fileName).use { fis ->
                fis.skip(32 * 1024)
                try {
                    ret.virtualAB = VirtualABMessage(fis)
                } catch (e: IllegalArgumentException) {
                    log.info(e.toString())
                }
            }
            return ret
        }
    }

    //offset 0, size 2k
    data class BootloaderMessage(
        var command: String = "",
        var status: String = "",
        var recovery: String = "",
        var stage: String = "",
        var reserved: ByteArray = byteArrayOf()
    ) {
        constructor(fis: FileInputStream) : this() {
            val info = Struct(FORMAT_STRING).unpack(fis)
            this.command = info[0] as String
            this.status = info[1] as String
            this.recovery = info[2] as String
            this.stage = info[3] as String
            this.reserved = info[4] as ByteArray
        }

        fun encode(): ByteArray {
            return Struct(FORMAT_STRING).pack(
                this.command,
                this.stage,
                this.recovery,
                this.stage,
                this.reserved,
            )
        }

        fun updateBootloaderMessageInStruct(options: Array<String>) {
            this.command = "boot-recovery"
            this.recovery = "recovery\n"
            options.forEach {
                this.recovery += if (it.endsWith("\n")) {
                    it
                } else {
                    it + "\n"
                }
            }
        }

        fun updateBootloaderMessage(command: String, recovery: String, options: Array<String>?) {
            this.command = command
            this.recovery = "$recovery\n"
            options?.forEach {
                this.recovery += if (it.endsWith("\n")) {
                    it
                } else {
                    it + "\n"
                }
            }
        }

        companion object {
            private const val FORMAT_STRING = "32s32s768s32s1184b"
            const val SIZE = 2048

            init {
                check(SIZE == Struct(FORMAT_STRING).calcSize())
            }

            /*
                https://android-review.googlesource.com/c/platform/bootable/recovery/+/735984
             */
            fun rebootFastboot1(): BootloaderMessage {
                return BootloaderMessage().apply {
                    command = "boot-fastboot"
                }
            }

            fun rebootFastboot2(): BootloaderMessage {
                return BootloaderMessage().apply {
                    updateBootloaderMessageInStruct(arrayOf("--fastboot"))
                }
            }

            fun rebootBootloader(): BootloaderMessage {
                return BootloaderMessage().apply {
                    command = "bootonce-bootloader"
                }
            }

            fun rebootRecovery(): BootloaderMessage {
                return BootloaderMessage().apply {
                    this.updateBootloaderMessageInStruct(arrayOf())
                }
            }

            fun rebootCrash(): BootloaderMessage {
                return BootloaderMessage().apply {
                    //@formatter:off
                    updateBootloaderMessageInStruct(arrayOf(
                        "--prompt_and_wipe_data",
                        "--reason=RescueParty",
                        "--locale=en_US"))
                    //@formatter:on
                }
            }

            fun rebootOTA(): BootloaderMessage {
                return BootloaderMessage().apply {
                    updateBootloaderMessageInStruct(arrayOf("--update_package=/cache/update.zip", "--security"))
                }
            }

            fun rebootWipeData(): BootloaderMessage {
                return BootloaderMessage().apply {
                    //@formatter:off
                    updateBootloaderMessageInStruct(arrayOf(
                        "--wipe_data",
                        "--reason=convert_fbe",
                        "--locale=en_US"))
                    //@formatter:on
                }
            }

            fun rebootWipeAb(): BootloaderMessage {
                return BootloaderMessage().apply {
                    //@formatter:off
                    updateBootloaderMessageInStruct(arrayOf(
                        "--wipe_ab",
                        "--wipe_package_size=1024",
                        "--locale=en_US"))
                    //@formatter:on
                }
            }

            fun generateSamples(): MutableList<BootloaderMessage> {
                return mutableListOf(
                    rebootFastboot1(),
                    rebootFastboot2(),
                    rebootBootloader(),
                    rebootRecovery(),
                    rebootCrash(),
                    rebootOTA(),
                    rebootWipeData(),
                    rebootWipeAb()
                )
            }
        }
    }

    //offset 32KB, size 64B
    data class VirtualABMessage(
        var version: Int = 0,
        var magic: ByteArray = byteArrayOf(),
        var mergeStatus: Int = 0,
        var sourceSlot: Int = 0,
        var reserved: ByteArray = byteArrayOf()
    ) {
        companion object {
            private const val FORMAT_STRING = "b4bbb57b"
            private val log = LoggerFactory.getLogger("VirtualABMsg")
            private const val MAGIC = "b00a7456"
            const val SIZE = 64

            init {
                check(SIZE == Struct(FORMAT_STRING).calcSize())
            }
        }

        constructor(fis: FileInputStream) : this() {
            val info = Struct(FORMAT_STRING).unpack(fis)
            this.version = (info[0] as ByteArray)[0].toInt()
            this.magic = info[1] as ByteArray
            this.mergeStatus = (info[2] as ByteArray)[0].toInt()
            this.sourceSlot = (info[3] as ByteArray)[0].toInt()
            this.reserved = info[4] as ByteArray
            if (MAGIC != Helper.Companion.toHexString(this.magic)) {
                throw IllegalArgumentException("stream is not VirtualAB message")
            }
        }

        fun encode(): ByteArray {
            return Struct(FORMAT_STRING).pack(
                byteArrayOf(this.version.toByte()),
                this.magic,
                byteArrayOf(this.mergeStatus.toByte()),
                byteArrayOf(this.sourceSlot.toByte()),
                byteArrayOf(0)
            )
        }

        override fun toString(): String {
            return "VABMsg(v=$version, magic=${Helper.toHexString(magic)}, mergeStatus=$mergeStatus:${
                MergeStatus.values().get(this.mergeStatus)
            }, sourceSlot=$sourceSlot)"
        }

        enum class MergeStatus(val status: Int) {
            NONE(0),
            UNKNOWN(1),
            SNAPSHOTTED(2),
            MERGING(3),
            CANCELLED(4)
        }
    }
}

```

`bbootimg/src/main/kotlin/ota/BrilloProp.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cc.cfig.droid.ota

import cfig.helper.ZipHelper.Companion.getEntryOffset
import org.apache.commons.compress.archivers.zip.ZipFile
import org.slf4j.LoggerFactory
import java.io.File

// tuple(name, offset, size) of an zip entry
class BrilloProp(
    var name: String,
    var offset: Long,
    var size: Long
) {
    constructor(zf: ZipFile, entryName: String) : this("", 0, 0) {
        val entry = zf.getEntry(entryName)
        name = File(entryName).name
        offset = entry.getEntryOffset()
        size = entry.size
        log.debug("extra size = " + entry.localFileDataExtra.size)
        log.debug("file name len = " + entry.name.length)
    }

    companion object {
        private val log = LoggerFactory.getLogger(BrilloProp::class.java)
    }

    override fun toString(): String {
        return if (offset == 0L && size == 0L) {
            name + " ".repeat(15)
        } else {
            "$name:$offset:$size"
        }
    }

    override fun equals(other: Any?): Boolean {
        if (this === other) return true
        if (javaClass != other?.javaClass) return false
        other as BrilloProp
        if (name != other.name) return false
        if (offset != other.offset) return false
        if (size != other.size) return false
        return true
    }

    override fun hashCode(): Int {
        var result = name.hashCode()
        result = 31 * result + offset.hashCode()
        result = 31 * result + size.hashCode()
        return result
    }
}

```

`bbootimg/src/main/kotlin/ota/BrilloPropString.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cc.cfig.droid.ota

import cc.cfig.io.Struct
import cfig.helper.ZipHelper
import cfig.helper.ZipHelper.Companion.getEntryOffset
import org.apache.commons.compress.archivers.zip.ZipFile
import org.slf4j.LoggerFactory
import java.io.File
import java.lang.IllegalArgumentException
import java.util.*

open class BrilloPropString {
    open val name: String = ""
    open val required: MutableList<String> = mutableListOf()
    open val optional: MutableList<String> = mutableListOf()

    companion object {
        private val log = LoggerFactory.getLogger(BrilloPropString::class.qualifiedName)
        const val metaDataName = "META-INF/com/android/metadata"

        fun Properties.toBrilloString(): String {
            val metaValueList = this.map { "${it.key}=${it.value}\n" }.sorted()
            return metaValueList.reduce { acc, s -> "$acc$s" }
        }

        fun computeAllPropertyStrings(fileName: String, inPropertyStrings: List<BrilloPropString>): Properties {
            return Properties().let { metadata ->
                inPropertyStrings.forEach {
                    metadata[it.name] = it.preCompute(fileName)
                }
                metadata
            }
        }

        fun finalizeAllPropertyFiles(
            fileName: String,
            inPropertyStrings: List<BrilloPropString>,
            preComputed: Properties
        ): Properties {
            val metadata = Properties()
            val zf = ZipFile(fileName)
            inPropertyStrings.forEach {
                metadata[it.name] = it.postCompute(fileName, (preComputed[it.name] as String).length)
            }
            zf.close()
            return metadata
        }

        fun rmMetaData(fileName: String) {
            ZipFile(fileName).use { zf ->
                val metadataEntry = zf.getEntry(metaDataName)
                if (metadataEntry != null) {
                    log.info("$metaDataName exists, needs to be erased")
                    ZipHelper.zipDelete(File(fileName), metaDataName)
                } else {
                    log.info("$metaDataName doesn't exist")
                }
            }
        }
    }

    /*
        pre-compute: with mimiced "metadata"
     */
    fun preCompute(fileName: String): String {
        return this.fromZipFile(fileName, reserveSpace = true)
    }

    /*
        finalize return string with padding spaces
     */
    fun postCompute(fileName: String, reservedLen: Int): String {
        val result = fromZipFile(fileName, reserveSpace = false)
        if (result.length > reservedLen) {
            throw IllegalArgumentException("Insufficient reserved space: reserved=$reservedLen, actual=${result.length}")
        }
        return result + " ".repeat(reservedLen - result.length)
    }

    fun verify(fileName: String, expected: String) {
        log.info("verifying $fileName:${this.name} ...")
        val actual = fromZipFile(fileName, reserveSpace = false)
        if (actual != expected.trim()) {
            throw RuntimeException("Mismatching streaming metadata: [$actual] vs [$expected]")
        } else {
            log.info("Verified $fileName:${this.name} against [$expected]")
        }
    }

    private fun fromZipFile(fileName: String, reserveSpace: Boolean = false): String {
        ZipFile(fileName).use { zf ->
            val token: MutableList<BrilloProp> = computePrivateProps(fileName)
            this.required.forEach {
                token.add(BrilloProp(zf, it))
            }
            this.optional.filter { zf.getEntry(it) != null }.forEach {
                token.add(BrilloProp(zf, it))
            }
            if (reserveSpace) {
                token.add(BrilloProp("metadata", 0L, 0L))
            } else {
                log.info("$metaDataName is " + BrilloProp(zf, metaDataName).toString())
                token.add(BrilloProp(zf, metaDataName))
            }
            val ret = token.map { it.toString() }.reduce { acc, s -> "$acc,$s" }
            log.info("fromZipFile($fileName) = [$ret]")
            return ret
        }
    }

    open fun computePrivateProps(fileName: String): MutableList<BrilloProp> {
        return mutableListOf()
    }
}

open class StreamingBrilloPropString : BrilloPropString() {
    override val name: String = "ota-streaming-property-files"
    override val required: MutableList<String> = mutableListOf("payload.bin", "payload_properties.txt")

    //care_map is available only if dm-verity is enabled
    //compatibility.zip is available only if target supports Treble
    override val optional: MutableList<String> = mutableListOf("care_map.pb", "care_map.txt", "compatibility.zip")
}

class NonAbBrilloPropString : BrilloPropString() {
    override val name: String = "ota-property-files"
}

/*
    AbBrilloPropString will replace StreamingBrilloPropString after P-timeframe
 */
@OptIn(ExperimentalUnsignedTypes::class)
class AbBrilloPropString : StreamingBrilloPropString() {
    override val name: String = "ota-property-files"

    override fun computePrivateProps(fileName: String): MutableList<BrilloProp> {
        ZipFile(fileName).use { zf ->
            val pb = zf.getEntry("payload.bin")
            val headerFormat = Struct("!IQQL")
            val header = headerFormat.unpack(zf.getInputStream(pb))
            val magic = header[0] as UInt
            val manifestSize = header[2] as ULong
            val metaSigSize = header[3] as UInt
            if (0x43724155U != magic) {//'CrAU'
                throw IllegalArgumentException("Invalid magic 0x" + magic.toString(16))
            }
            val metaTotal = headerFormat.calcSize().toULong() + manifestSize + metaSigSize
            if (metaTotal >= pb.size.toUInt()) {
                throw IllegalArgumentException("metadata total size >= payload size")
            }
            return mutableListOf(BrilloProp("payload_metadata.bin", pb.getEntryOffset(), metaTotal.toLong()))
        }
    }
}

```

`bbootimg/src/main/kotlin/ota/Common.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
package cc.cfig.droid.ota

import org.apache.commons.compress.archivers.zip.ZipFile
import org.slf4j.LoggerFactory
import java.io.InputStream
import java.nio.charset.StandardCharsets
import java.util.*

class Common {
    companion object {
        private val log = LoggerFactory.getLogger(Common::class.java)
        private val PARTITIONS_WITH_CARE_MAP =
            mutableListOf("system", "vendor", "product", "system_ext", "odm", "vendor_dlkm", "odm_dlkm")
        val PARTITIONS_WITH_BUILD_PROP = PARTITIONS_WITH_CARE_MAP.apply { add("boot") }

        private fun getEntryStream(zipFile: ZipFile, entryName: String): InputStream {
            return zipFile.getInputStream(zipFile.getEntry(entryName))
        }

        fun Properties.getBuildProp(k: String): String? {
            return (this.get("build.prop") as Properties).getProperty(k)
        }

        fun loadInfoDict(fileName: String): Properties {
            val d = Properties()
            ZipFile(fileName).use { zf ->
                log.info("loading META/misc_info.txt ...")
                //1: misc_info.txt
                d.load(getEntryStream(zf, "META/misc_info.txt"))
                if (null == d.getProperty("recovery_api_version")) {
                    throw IllegalArgumentException("Failed to find 'recovery_api_version'")
                }
                if (null == d.getProperty("fstab_version")) {
                    throw IllegalArgumentException("Failed to find 'fstab_version'")
                }
                if ("true" == d.getProperty("system_root_image")) {
                    throw IllegalArgumentException("BOARD_BUILD_SYSTEM_ROOT_IMAGE no longer supported")
                }
                val recoveryFstabPath = "BOOT/RAMDISK/system/etc/recovery.fstab"
                val recoveryFstabPath2 = "VENDOR_BOOT/RAMDISK/system/etc/recovery.fstab"
                val validFstab = if (zf.getEntry(recoveryFstabPath) != null) {
                    recoveryFstabPath
                } else {
                    recoveryFstabPath2
                }
                //2: .fstab
                d.put("fstab", loadRecoveryFstab(zf, validFstab, false))

                //load all build.prop
                PARTITIONS_WITH_BUILD_PROP.forEach { part ->
                    val subProps = Properties()
                    if (part == "boot") {
                        arrayOf("BOOT/RAMDISK/system/etc/ramdisk/build.prop",
                            "BOOT/RAMDISK/prop.default").forEach { bootBuildProp ->
                            zf.getEntry(bootBuildProp)?.let { entry ->
                                log.info("loading /$bootBuildProp ...")
                                subProps.load(zf.getInputStream(entry))
                            }
                        }
                    } else {
                        zf.getEntry("${part.uppercase(Locale.getDefault())}/build.prop")?.let { entry ->
                            log.info("loading /$part/build.prop ...")
                            subProps.load(zf.getInputStream(entry))
                        }
                        zf.getEntry("${part.uppercase(Locale.getDefault())}/etc/build.prop")?.let { entry ->
                            log.info("loading /$part/etc/build.prop ...")
                            subProps.load(zf.getInputStream(entry))
                        }
                    }
                    //3: .$part.build.prop
                    d.put("$part.build.prop", subProps)
                }
                //4: .build.prop == .system.build.prop
                log.info("duplicating system.build.prop -> build.prop")
                d.put("build.prop", d.get("system.build.prop"))
            }
            if (d.get("avb_enable") == "true") {
                // 5: avb related
                (d.get("build.prop") as Properties).let { buildprop ->
                    var fp: String?
                    fp = buildprop.get("ro.build.fingerprint") as String?
                    if (fp == null) {
                        fp = buildprop.get("ro.build.thumbprint") as String?
                    }
                    fp?.let {
                        log.warn("adding avb_salt from fingerprint ...")
                        d.put("avb_salt", "fp")
                    }
                }
            }
            return d
        }

        private fun loadRecoveryFstab(zf: ZipFile, fstabPath: String, bSystemRoot: Boolean = false) {
            class Partition(
                var mount_point: String = "",
                var fs_type: String = "",
                var device: String = "",
                var length: Long = 0,
                var selinuxContext: String = "",
            )
            log.info("loading $fstabPath ...")
            val ret: MutableMap<String, Partition> = mutableMapOf()
            val rs = getEntryStream(zf, fstabPath).readBytes().toString(StandardCharsets.UTF_8)
            log.debug(rs)
            rs.lines().forEach rs@{ line ->
                val item = line.trim()
                if (item.isEmpty() || item.startsWith("#")) {
                    log.debug("ignore empty/comment line")
                    return@rs
                }
                val pieces = item.split("\\s+".toRegex())
                if (pieces.size != 5) {
                    throw IllegalArgumentException("malformed recovery.fstab line: [$item]")
                }
                if (pieces[4].contains("voldmanaged=")) {
                    log.info("Ignore entries that are managed by vold: [$item]")
                    return@rs
                }
                val lengthOption = pieces[4].split(",").filter { it.startsWith("length=") }
                val length = when (lengthOption.size) {
                    0 -> 0
                    1 -> lengthOption[0].substring(7).toLong()
                    else -> throw IllegalArgumentException("multiple 'length=' in options")
                }

                val mountFlags = pieces[3]
                val mountContextFlags = mountFlags.split(",").filter { it.startsWith("context=") }
                val context = if (mountContextFlags.size == 1) mountContextFlags[0] else ""

                ret.put(pieces[1], Partition(pieces[1], pieces[2], pieces[0], length, context))
            }
            if (bSystemRoot) {
                if (ret.keys.contains("/system") || !ret.keys.contains("/")) {
                    throw IllegalArgumentException("not allowed")
                }
                val systemPartition = ret.get("/") as Partition
                systemPartition.mount_point = "/"
                log.info("adding /system for system_as_root devices")
                ret.put("/system", systemPartition)
            }
        }
    }
}

```

`bbootimg/src/main/kotlin/ota/DeltaGenerator.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
package cc.cfig.droid.ota

import cfig.helper.Helper
import cfig.helper.ZipHelper
import chromeos_update_engine.UpdateMetadata
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.util.*
import chromeos_update_engine.UpdateMetadata.InstallOperation.Type
import java.io.ByteArrayInputStream

class DeltaGenerator {
    class ChunkProcessor(
        val name: String,
        val op: UpdateMetadata.InstallOperation,
        val blockSize: Int,
        val partFile: String,
    ) {
        fun ProcessChunk() {
            log.info("ChunkProcessor: $name")
            FileInputStream(partFile).use { fis ->
                val dst0 = op.getDstExtents(0)
                fis.skip(dst0.startBlock * blockSize)
                val data = ByteArray((dst0.numBlocks * blockSize).toInt())
                if (data.size != fis.read(data)) {
                    throw RuntimeException("$name: read size != expected size")
                }
                val bestOp = GenerateBestFullOperation(data)
                if (bestOp[0] as Boolean) {
                    log.info("bestType=" + bestOp[1] as Type + ", bestSize=" + bestOp[2] as Int)
                } else {
                    throw IllegalStateException("GenerateBestFullOperation fail")
                }
            }
        }

        companion object {
            fun GenerateBestFullOperation(inData: ByteArray): Array<Any> {
                val ret: Array<Any> = Array(3) { 0 }
                var bestType: Type = Type.REPLACE
                var bestSize: Int = inData.size
                //buffer MUST be valid
                if (inData.isEmpty()) {
                    ret[0] = false
                    return ret
                }
                //zero
                if (inData.all { it.toInt() == 0 }) {
                    bestType = Type.ZERO
                    log.info("raw=${inData.size}, ZERO")
                    ret[0] = true
                    ret[1] = bestType
                    return ret
                }
                //try xz
                File.createTempFile("pre", "suf").let { tempFile ->
                    tempFile.deleteOnExit()
                    ZipHelper.xz(tempFile.absolutePath, ByteArrayInputStream(inData))
                    log.debug("raw=${inData.size}, xz=" + tempFile.length())
                    if (bestSize > tempFile.length()) {
                        bestType = Type.REPLACE_XZ
                        bestSize = tempFile.length().toInt()
                    }
                }
                //try bz
                File.createTempFile("pre", "suf").let { tempFile ->
                    tempFile.deleteOnExit()
                    ZipHelper.bzip2(tempFile.absolutePath, ByteArrayInputStream(inData))
                    log.debug("raw=${inData.size}, bzip2=" + tempFile.length())
                    if (bestSize > tempFile.length()) {
                        bestType = Type.REPLACE_BZ
                        bestSize = tempFile.length().toInt()
                    }
                }
                ret[0] = true
                ret[1] = bestType
                ret[2] = bestSize
                return ret
            }
        }
    }

    class FullPayloadGenerator {
        fun GenerateOperations(partName: String, partFile: String) {
            val config = Properties().apply {
                put("full_chunk_size", (2 * 1024 * 1024).toInt())
                put("block_size", (4 * 1024).toInt())
            }
            val fullChunkSize = config.get("full_chunk_size") as Int
            val blockSize = config.get("block_size") as Int
            if (fullChunkSize % blockSize != 0) {
                throw IllegalArgumentException("BUG: illegal (chunk_size, block_size)=($fullChunkSize, $blockSize)")
            }
            val fileLen = File(partFile).length()
            log.warn("fcs=$fullChunkSize, file size=$fileLen")
            val partitionBlocks: Long = fileLen / blockSize
            val chunkBloks: Long = (fullChunkSize / blockSize).toLong() //typically 512
            val numChunks = Helper.Companion.round_to_multiple(partitionBlocks, chunkBloks) / chunkBloks
            log.warn("partitionBlocks=$partitionBlocks,  numChunks=$numChunks")
            for (i in 0 until numChunks) {
                val startBlock = i * chunkBloks
                val numBlocks = minOf(chunkBloks, partitionBlocks - i * chunkBloks)
                val dstExtent = UpdateMetadata.Extent.newBuilder()
                    .setStartBlock(startBlock)
                    .setNumBlocks(numBlocks)
                    .build()
                val op = UpdateMetadata.InstallOperation.newBuilder()
                    .setType(Type.REPLACE)
                    .addDstExtents(dstExtent)
                    .build()
                log.info("op<${i}> $op")
                ChunkProcessor("$partName-operation-${i}/$numChunks", op, blockSize, partFile).ProcessChunk()
            }
        }

        fun appendData() {

        }
    }

    companion object {
        val log = LoggerFactory.getLogger(DeltaGenerator::class.java.name)
    }
}
```

`bbootimg/src/main/kotlin/ota/OtaOptions.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
package cc.cfig.droid.ota

data class OtaOptions(
    var wipe_user_data: Boolean = false,
    var skip_postinstall: Boolean = false,
    var include_secondary: Boolean = false,
    var downgrade: Boolean = false
)

```

`bbootimg/src/main/kotlin/ota/Payload.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cc.cfig.droid.ota

import cc.cfig.io.Struct
import cfig.helper.CryptoHelper.Hasher
import cfig.helper.Helper
import cfig.helper.Dumpling
import chromeos_update_engine.UpdateMetadata
import com.fasterxml.jackson.annotation.JsonInclude
import com.fasterxml.jackson.databind.ObjectMapper
import com.google.protobuf.ByteString
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.PumpStreamHandler
import org.slf4j.LoggerFactory
import java.io.*
import java.nio.file.Files
import java.nio.file.Paths
import java.time.Instant
import java.time.ZoneId
import java.time.format.DateTimeFormatter

class Payload {
    var fileName: String = ""
    var header = PayloadHeader()
    var manifest: UpdateMetadata.DeltaArchiveManifest = UpdateMetadata.DeltaArchiveManifest.newBuilder().build()
    var metaSig: UpdateMetadata.Signatures = UpdateMetadata.Signatures.newBuilder().build()
    var metaSize: Int = 0
    var dataOffset: Long = 0L
    var dataSig: UpdateMetadata.Signatures = UpdateMetadata.Signatures.newBuilder().build()

    companion object {
        private val log = LoggerFactory.getLogger(Payload::class.java)
        val workDir = Helper.prop("payloadDir")

        fun parse(inFileName: String): Payload {
            val ret = Payload()
            ret.fileName = inFileName
            FileInputStream(inFileName).use { fis ->
                ret.header = PayloadHeader(fis)
                ret.metaSize = ret.header.headerSize + ret.header.manifestLen.toInt()
                ret.dataOffset = (ret.metaSize + ret.header.metaSigLen).toLong()
                //manifest
                ret.manifest = ByteArray(ret.header.manifestLen.toInt()).let { buf ->
                    fis.read(buf)
                    UpdateMetadata.DeltaArchiveManifest.parseFrom(buf)
                }
                //meta sig
                ret.metaSig = ByteArray(ret.header.metaSigLen).let { buf2 ->
                    fis.read(buf2)
                    UpdateMetadata.Signatures.parseFrom(buf2)
                }

                //data sig
                if (ret.manifest.hasSignaturesOffset()) {
                    log.debug("payload sig offset = " + ret.manifest.signaturesOffset)
                    log.debug("payload sig size = " + ret.manifest.signaturesSize)
                    fis.skip(ret.manifest.signaturesOffset)
                    ret.dataSig = ByteArray(ret.manifest.signaturesSize.toInt()).let { buf ->
                        fis.read(buf)
                        UpdateMetadata.Signatures.parseFrom(buf)
                    }
                } else {
                    log.warn("payload has no signatures")
                }
            } //end-of-fis

            run {//CHECK_EQ(payload.size(), signatures_offset + manifest.signatures_size())
                val calculatedSize = ret.header.headerSize + ret.header.manifestLen + ret.header.metaSigLen +
                        ret.manifest.signaturesOffset + ret.manifest.signaturesSize
                if (File(inFileName).length() == calculatedSize) {
                    log.info("payload.bin size info check PASS")
                } else {
                    throw IllegalStateException("calculated payload size doesn't match file size")
                }
            }

            val calcMetadataHash =
                Hasher.hash(Dumpling(inFileName), listOf(Pair(0L, ret.metaSize.toLong())), "sha-256")
            log.info("calc meta hash: " + Helper.toHexString(calcMetadataHash))
            val calcPayloadHash = Hasher.hash(
                Dumpling(inFileName), listOf(
                    Pair(0L, ret.metaSize.toLong()),
                    Pair(ret.metaSize.toLong() + ret.header.metaSigLen, ret.manifest.signaturesOffset)
                ), "sha-256"
            )
            check(calcPayloadHash.size == 32)
            log.info("calc payload hash: " + Helper.toHexString(calcPayloadHash))

            val readPayloadSignature = UpdateMetadata.Signatures.parseFrom(
                Helper.readFully(
                    inFileName,
                    ret.dataOffset + ret.manifest.signaturesOffset,
                    ret.manifest.signaturesSize.toInt()
                )
            )
            log.info("Found sig count: " + readPayloadSignature.signaturesCount)
            readPayloadSignature.signaturesList.forEach {
                //pass
                log.info(it.data.toString())
                log.info("sig_data size = " + it.data.toByteArray().size)
                log.info(Helper.toHexString(it.data.toByteArray()))
                Files.write(Paths.get("sig_data"), it.data.toByteArray())
            }

            return ret
        }

        class PayloadVerifier {
            fun getRawHashFromSignature(sig_data: ByteString, pubkey: String, sigHash: ByteArray) {
            }
        }

        fun displaySignatureBlob(sigName: String, sig: UpdateMetadata.Signatures): String {
            return StringBuilder().let { sb ->
                sb.append(String.format("%s signatures: (%d entries)\n", sigName, sig.signaturesCount))
                sig.signaturesList.forEach {
                    sb.append(String.format("  hex_data: (%d bytes)\n", it.data.size()))
                    sb.append("  Data: " + Helper.toHexString(it.data.toByteArray()) + "\n")
                }
                sb
            }.toString()
        }
    }

    fun printInfo() {
        val mi = ManifestInfo(blockSize = this.manifest.blockSize,
            minorVersion = this.manifest.minorVersion,
            maxTimeStamp = this.manifest.maxTimestamp,
            signatureOffset = this.manifest.signaturesOffset,
            signatureSize = this.manifest.signaturesSize,
            partialUpdate = this.manifest.hasPartialUpdate(),
            partsToUpdate = this.manifest.partitionsList.map {
                ManifestInfo.PartitionToUpdate(
                    it.partitionName, it.operationsCount,
                    if (it.hasRunPostinstall()) it.runPostinstall else null,
                    if (it.hasPostinstallPath()) it.postinstallPath else null
                )
            },
            enableSnapshot = this.manifest.dynamicPartitionMetadata.hasSnapshotEnabled(),
            dynamicGroups = this.manifest.dynamicPartitionMetadata.groupsList.map {
                ManifestInfo.DynamicPartGroup(name = it.name, size = it.size, partName = it.partitionNamesList)
            })
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File("$workDir/header.json"), this.header)
        log.info("  header  info dumped to ${workDir}header.json")
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File("$workDir/manifest.json"), mi)
        log.info(" manifest info dumped to ${workDir}manifest.json")

        val signatureFile = "${workDir}signatures.txt"
        FileOutputStream(signatureFile, false).use { fos ->
            fos.writer().use { fWriter ->
                fWriter.write("<Metadata> signatures: offset=" + this.header.manifestLen + ", size=" + this.header.metaSigLen + "\n")
                fWriter.write(Payload.displaySignatureBlob("<Metadata>", this.metaSig))
                fWriter.write("<Payload> signatures: base= offset=" + manifest.signaturesOffset + ", size=" + this.header.metaSigLen + "\n")
                fWriter.write((Payload.displaySignatureBlob("<Payload>", this.dataSig)))
            }
        }
        log.info("signature info dumped to $signatureFile")
    }

    private fun decompress(inBytes: ByteArray, opType: UpdateMetadata.InstallOperation.Type): ByteArray {
        val baosO = ByteArrayOutputStream()
        val baosE = ByteArrayOutputStream()
        val bais = ByteArrayInputStream(inBytes)
        DefaultExecutor().let { exec ->
            exec.streamHandler = PumpStreamHandler(baosO, baosE, bais)
            val cmd = when (opType) {
                UpdateMetadata.InstallOperation.Type.REPLACE_XZ -> CommandLine("xzcat")
                UpdateMetadata.InstallOperation.Type.REPLACE_BZ -> CommandLine("bzcat")
                UpdateMetadata.InstallOperation.Type.REPLACE -> return inBytes
                else -> throw IllegalArgumentException(opType.toString())
            }
            cmd.addArgument("-")
            exec.execute(cmd)
        }
        return baosO.toByteArray()
    }

    private fun unpackInternal(ras: RandomAccessFile, pu: UpdateMetadata.PartitionUpdate, logPrefix: String = "") {
        log.info(String.format("[%s] extracting %13s.img (%d ops)", logPrefix, pu.partitionName, pu.operationsCount))
        FileOutputStream("$workDir/${pu.partitionName}.img").use { outFile ->
            val ops = pu.operationsList.toMutableList().apply {
                sortBy { it.getDstExtents(0).startBlock }
            }
            ops.forEach { op ->
                log.debug(pu.partitionName + ": " + (op.getDstExtents(0).startBlock * this.manifest.blockSize) + ", size=" + op.dataLength)
                val piece = ByteArray(op.dataLength.toInt()).let {
                    ras.seek(this.dataOffset + op.dataOffset)
                    ras.read(it)
                    it
                }
                outFile.write(decompress(piece, op.type))
            }
        }
    }

    fun setUp() {
        File(workDir).let {
            if (it.exists()) {
               log.info("Removing $workDir")
                it.deleteRecursively()
            }
            log.info("Creating $workDir")
            it.mkdirs()
        }
    }

    fun unpack() {
        RandomAccessFile(this.fileName, "r").use { ras ->
            var currentNum = 1
            val totalNum = this.manifest.partitionsCount
            val parts = this.manifest.partitionsList.map { it.partitionName }
            log.info("There are $totalNum partitions $parts")
            log.info("dumping images to $workDir")
            this.manifest.partitionsList.forEach { pu ->
                unpackInternal(ras, pu, String.format("%2d/%d", currentNum, totalNum))
                currentNum++
            }
        }
    }

    data class PayloadHeader(
        var version: Long = 0,
        var manifestLen: Long = 0,
        var metaSigLen: Int = 0,
        var headerSize: Int = 0
    ) {
        private val magic = "CrAU"
        private val FORMAT_STRING = ">4sqq" //magic, version, manifestLen
        private val CHROMEOS_MAJOR_PAYLOAD_VERSION = 1L
        private val BRILLO_MAJOR_PAYLOAD_VERSION = 2L
        val typeOfVersion: String
            get() = when (version) {
                CHROMEOS_MAJOR_PAYLOAD_VERSION -> "chromeOs"
                BRILLO_MAJOR_PAYLOAD_VERSION -> "brillo"
                else -> throw IllegalArgumentException()
            }

        constructor(fis: InputStream) : this() {
            val info = Struct(FORMAT_STRING).unpack(fis)
            check((info[0] as String) == magic) { "${info[0]} is not payload magic" }
            version = info[1] as Long
            manifestLen = info[2] as Long
            headerSize = Struct(FORMAT_STRING).calcSize()

            if (version == BRILLO_MAJOR_PAYLOAD_VERSION) {
                headerSize += Int.SIZE_BYTES
                metaSigLen = Struct(">i").unpack(fis)[0] as Int
            }
        }
    }

    @JsonInclude(JsonInclude.Include.NON_NULL)
    data class ManifestInfo(
        var blockSize: Int? = null,
        var minorVersion: Int? = null,
        var maxTimeStamp: Long = 0L,
        var maxTimeReadable: String? = null,
        var partialUpdate: Boolean? = null,
        val signatureOffset: Long? = null,
        val signatureSize: Long? = null,
        var dynamicGroups: List<DynamicPartGroup> = listOf(),
        var enableSnapshot: Boolean? = null,
        var partsToUpdate: List<PartitionToUpdate> = listOf()
    ) {
        init {
            val ldt = Instant.ofEpochMilli(maxTimeStamp * 1000)
                .atZone(ZoneId.systemDefault())
                .toLocalDateTime()
            maxTimeReadable = DateTimeFormatter.ISO_LOCAL_DATE_TIME.format(ldt) + " (${ZoneId.systemDefault()})"
        }

        @JsonInclude(JsonInclude.Include.NON_NULL)
        data class PartitionToUpdate(
            var name: String = "",
            var ops: Int = 0,
            var runPostInstall: Boolean? = null,
            var postInstallPath: String? = null
        )

        data class DynamicPartGroup(
            var name: String = "",
            var size: Long = 0L,
            var partName: List<String> = listOf()
        )
    }
}

```

`bbootimg/src/main/kotlin/ota/PayloadGenerator.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
package cc.cfig.droid.ota

import cc.cfig.io.Struct
import cfig.helper.Helper.Companion.check_call
import cfig.helper.ZipHelper.Companion.dumpEntry
import org.apache.commons.compress.archivers.zip.ZipFile
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.nio.file.Files
import java.nio.file.Paths
import java.nio.file.StandardOpenOption
import java.util.*
import kotlin.system.exitProcess

@OptIn(ExperimentalUnsignedTypes::class)
class PayloadGenerator {
    private val log = LoggerFactory.getLogger(PayloadGenerator::class.java)
    val workDir = "build/staging_ota"
    val signedPayload = "$workDir/signed-payload.bin"
    val propertiesFile = "$workDir/payload-properties.txt"

    fun generate(maxTs: String, targetFile: String, payload: String) {
        ("brillo_update_payload generate" +
                " --max_timestamp $maxTs" +
                " --target_image $targetFile" +
                " --payload $payload").check_call()
    }

    fun sign(inSigner: PayloadSigner, options: OtaOptions) {
        // 1. Generate hashes of the payload and metadata files
        ("brillo_update_payload hash" +
                " --unsigned_payload $workDir/payload.bin" +
                " --signature_size " + inSigner.keySize +
                " --metadata_hash_file $workDir/meta.hash" +
                " --payload_hash_file $workDir/payload.hash").check_call()

        // 2. Sign the hashes.
        inSigner.sign("$workDir/meta.hash", "$workDir/signed-meta.hash")
        inSigner.sign("$workDir/payload.hash", "$workDir/signed-payload.hash")

        // 3. Insert the signatures back into the payload file.
        ("brillo_update_payload sign" +
                " --unsigned_payload $workDir/payload.bin" +
                " --payload $signedPayload" +
                " --signature_size " + inSigner.keySize +
                " --metadata_signature_file $workDir/signed-meta.hash" +
                " --payload_signature_file $workDir/signed-payload.hash").check_call()

        // 4. Dump the signed payload properties.
        ("brillo_update_payload properties" +
                " --payload $signedPayload" +
                " --properties_file $propertiesFile").check_call()

        // 5.
        if (options.wipe_user_data) {
            FileOutputStream(propertiesFile, true).use {
                it.write("POWERWASH=1\n".toByteArray())
            }
        }
        options.include_secondary.let { includeSec ->
            if (includeSec) {
                FileOutputStream(propertiesFile, true).use {
                    it.write("SWITCH_SLOT_ON_REBOOT=0\n".toByteArray())
                }
            }
        }
    }

    fun tryToDumpEntry(inputFile: ZipFile, entryItem: String, outFile: String) {
        val entry = inputFile.getEntry(entryItem)
        if (entry != null) {
            inputFile.dumpEntry(entry.name, File(outFile))
        } else {
            log.info("$entryItem not found")
        }
    }

    fun generateMine(maxTs: String, inTargetFile: String, payload: String, infoDict: Properties) {
        val targetFile = ZipFile(inTargetFile)
        val abPartitions =
            String(targetFile.getInputStream(targetFile.getEntry("META/ab_partitions.txt")).readBytes())
                .lines().filter { it.isNotBlank() }
        log.info("Dumping ${abPartitions.size} images from target file ...")

        abPartitions.forEach { part ->
            val partEntryName = listOfNotNull(
                targetFile.getEntry("IMAGES/$part.img"), targetFile.getEntry("RADIO/$part.img")
            )
                .let { parts ->
                    if (parts.size != 1) {
                        log.error("Found multiple images for partition $part")
                        exitProcess(1)
                    }
                    parts[0].name
                }
            //dump image
            targetFile.dumpEntry(partEntryName, File("$workDir/$part.img"))

            run {//unsparse image
                Struct(">I").unpack(FileInputStream("$workDir/$part.img")).let { fileHeader ->
                    if (fileHeader[0] as UInt == 0x3aff26ed.toUInt()) {
                        log.debug("$part is sparse, convert to raw image")
                        "simg2img $workDir/$part.img $workDir/tmp.img".check_call()
                        File("$workDir/tmp.img").renameTo(File("$workDir/$part.img"))
                    }
                }
            }

            run {//dump map file
                val mapFile = targetFile.getEntry(partEntryName.replace(".img", ".map"))
                if (mapFile != null) {
                    log.debug("$part.map found, dump it to $workDir/$part.map")
                    targetFile.dumpEntry(mapFile.name, File("$workDir/$part.map"))
                } else {
                    log.debug("$part.map not found")
                }
            }
            File("$workDir/$part.img").let { partFile ->
                val partSize = partFile.length()
                if (partSize % 4096 != 0L) {
                    log.info("Padding $workDir/$part.img ...")
                    Files.write(
                        Paths.get("$workDir/$part.img"),
                        ByteArray(4096 - (partSize % 4096).toInt()),
                        StandardOpenOption.APPEND
                    )
                }
            }
        }
        targetFile.dumpEntry("META/postinstall_config.txt", File("$workDir/postinstall_config.txt"))
        targetFile.dumpEntry("META/dynamic_partitions_info.txt", File("$workDir/dynamic_partitions_info.txt"))
        tryToDumpEntry(targetFile, "META/apex_info.pb", "$workDir/apex_info.pb")
        targetFile.close()

        data class DeltaGenParam(
            var partitionNames: String = "",
            var newImages: String = "",
            var newMapFiles: String = "",
            var newPostInstallConfig: String = "",
            var dynamicPartitionInfo: String = "",
            var apexInfoFile: String = "",
            var partitionTimeStamps: String = "",
        )

        //partition timestamps
        val pTs: MutableList<Pair<String, String>> = mutableListOf()
        Common.PARTITIONS_WITH_BUILD_PROP.forEach { it ->
            val item: Pair<String, String?> = Pair(it,
                when (it) {
                    "boot" -> {
                        log.info("boot:" + infoDict.get("$it.build.prop") as Properties)
                        (infoDict.get("$it.build.prop") as Properties).getProperty("ro.${it}image.build.date.utc")
                    }
                    else -> (infoDict.get("$it.build.prop") as Properties).getProperty("ro.${it}.build.date.utc")
                })
            if (item.second != null) {
                pTs.add(item as Pair<String, String>)
            }
        }

        val dp = DeltaGenParam().apply {
            partitionNames = abPartitions.reduce { acc, s -> "$acc:$s" }
            newImages = abPartitions.map { "$workDir/$it.img" }.reduce { acc, s -> "$acc:$s" }
            newMapFiles = abPartitions
                .map { if (File("$workDir/$it.map").exists()) "$workDir/$it.map" else "" }
                .reduce { acc, s -> "$acc:$s" }
            newPostInstallConfig = "$workDir/postinstall_config.txt"
            dynamicPartitionInfo = "$workDir/dynamic_partitions_info.txt"
            if (File("$workDir/apex_info.pb").exists()) {
                apexInfoFile = "$workDir/apex_info.pb"
            }
            partitionTimeStamps = pTs.map { it.first + ":" + it.second }.reduce { acc, s -> "$s,$acc" }
        }

        ("delta_generator" +
                " --out_file=$payload" +
                " --partition_names=${dp.partitionNames}" +
                " --new_partitions=${dp.newImages}" +
                " --new_mapfiles=${dp.newMapFiles}" +
                " --major_version=2" +
                " --max_timestamp=$maxTs" +
                " --partition_timestamps=${dp.partitionTimeStamps}" +
                " --new_postinstall_config_file=${dp.newPostInstallConfig}" +
                " --dynamic_partition_info_file=${dp.dynamicPartitionInfo}" +
                if (dp.apexInfoFile.isNotBlank()) " --apex_info_file=${dp.apexInfoFile}" else ""
                ).check_call()
    }

    fun signMine(inSigner: PayloadSigner, options: OtaOptions) {
        //1: hash and meta of payload
        ("delta_generator" +
                " --in_file=$workDir/payload.bin.mine" +
                " --signature_size=${inSigner.keySize}" +
                " --out_hash_file=$workDir/payload.hash.mine" +
                " --out_metadata_hash_file=$workDir/meta.hash.mine").check_call()
        //Helper.assertFileEquals("$workDir/meta.hash", "$workDir/meta.hash.mine")
        //Helper.assertFileEquals("$workDir/payload.hash", "$workDir/payload.hash.mine")

        //2: sign hash and meta
        inSigner.sign("$workDir/meta.hash.mine", "$workDir/signed-meta.hash.mine")
        inSigner.sign("$workDir/payload.hash.mine", "$workDir/signed-payload.hash.mine")
        //Helper.assertFileEquals("$workDir/signed-meta.hash", "$workDir/signed-meta.hash.mine")
        //Helper.assertFileEquals("$workDir/payload.hash", "$workDir/payload.hash.mine")

        //3: hash, meta, payload.bin -> signed-payload.bin
        ("delta_generator" +
                " --in_file=$workDir/payload.bin.mine" +
                " --signature_size=" + inSigner.keySize +
                " --payload_signature_file=$workDir/signed-payload.hash.mine" +
                " --metadata_signature_file=$workDir/signed-meta.hash.mine" +
                " --out_file=$signedPayload.mine").check_call()
        //Helper.assertFileEquals(signedPayload, "$signedPayload.mine")

        //4: payload-properties.txt
        ("delta_generator" +
                " --in_file=$signedPayload.mine" +
                " --properties_file=$propertiesFile.mine").check_call()
        //Helper.assertFileEquals(propertiesFile, "$propertiesFile.mine")

        // 5: payload-properties.txt appending
        if (options.wipe_user_data) {
            FileOutputStream(propertiesFile, true).use {
                it.write("POWERWASH=1\n".toByteArray())
            }
        }
        if (options.include_secondary) {
            FileOutputStream(propertiesFile, true).use {
                it.write("SWITCH_SLOT_ON_REBOOT=0\n".toByteArray())
            }
        }
    }
}

```

`bbootimg/src/main/kotlin/ota/PayloadSigner.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
package cc.cfig.droid.ota

import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File

class PayloadSigner {
    private val log = LoggerFactory.getLogger(PayloadSigner::class.java)
    var keySize = 0
    private val workDir = "build/staging_ota"
    val signingKey = "signing.key"
    val privKey = "aosp/security/testkey.pk8"
    val modulusFile = "$workDir/modulus.file"

    init {
        CommandLine.parse("openssl pkcs8 -in $privKey -inform DER -nocrypt -out $workDir/$signingKey").let { cmd ->
            log.info(cmd.toString())
            DefaultExecutor().execute(cmd)
        }

        CommandLine.parse("openssl rsa -inform PEM -in $workDir/$signingKey -modulus -noout -out $modulusFile").let { cmd ->
            log.info(cmd.toString())
            DefaultExecutor().execute(cmd)
        }

        val modulusString = File(modulusFile).readText()
        log.info(modulusString)
        val MODULUS_PREFIX = "Modulus="
        if (!modulusString.startsWith(MODULUS_PREFIX)) {
            throw IllegalArgumentException("Invalid modulus string")
        }
        keySize = modulusString.substring(MODULUS_PREFIX.length).length / 2
        log.info("key size = $keySize bytes")
        if (keySize !in listOf(256, 512)) {
            throw IllegalArgumentException("Unsupported key size")
        }
    }

    fun sign(inFile: String, outFile: String) {
        CommandLine.parse("openssl pkeyutl -sign").let { cmd ->
            cmd.addArguments("-inkey $workDir/$signingKey -pkeyopt digest:sha256")
            cmd.addArguments("-in $inFile")
            cmd.addArguments("-out $outFile")
            log.info(cmd.toString())
            DefaultExecutor().execute(cmd)
        }
    }
}

```

`bbootimg/src/main/kotlin/packable/BootImgParser.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import avb.blob.Footer
import cfig.bootimg.Common.Companion.probeHeaderVersion
import cfig.bootimg.v2.BootV2
import cfig.bootimg.v2.BootV2Dialects
import cfig.bootimg.v3.BootV3
import cfig.helper.Helper
import cfig.helper.Helper.Companion.deleteIfExists
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream

class BootImgParser : IPackable {
    override val loopNo: Int
        get() = 0

    override fun capabilities(): List<String> {
        return listOf("^boot(-debug)?\\.img$", "^recovery\\.img$", "^recovery-two-step\\.img$", "^init_boot\\.img$")
    }

    override fun unpack(fileName: String) {
        clear()
        val hv = probeHeaderVersion(fileName)
        log.info("header version $hv")
        when (hv) {
            in 0..2 -> {
                val b2 = BootV2
                    .parse(fileName)
                    .extractImages()
                    .extractVBMeta()
                    .printSummary()
                log.debug(b2.toString())
            }
            in 3..4 -> {
                val b3 = BootV3
                    .parse(fileName)
                    .extractImages()
                    .extractVBMeta()
                    .printSummary()
                log.debug(b3.toString())
            }
            else -> {
                val b2 = BootV2Dialects
                    .parse(fileName)
                    .extractImages()
                    .extractVBMeta()
                    .printSummary()
                log.debug(b2.toString())
            }
        }
    }

    override fun pack(fileName: String) {
        val cfgFile = outDir + fileName.removeSuffix(".img") + ".json"
        log.info("Loading config from $cfgFile")
        if (!File(cfgFile).exists()) {
            val tab = AsciiTable().let {
                it.addRule()
                it.addRow("'$cfgFile' doesn't exist, did you forget to 'unpack' ?")
                it.addRule()
                it
            }
            log.info("\n{}", tab.render())
            return
        }
        when (val hv = probeHeaderVersion(fileName)) {
            0, 1, 2 ->
                ObjectMapper().readValue(File(cfgFile), BootV2::class.java)
                    .pack()
                    .sign()
                    .updateVbmeta()
                    .printPackSummary()
            3, 4 ->
                ObjectMapper().readValue(File(cfgFile), BootV3::class.java)
                    .pack()
                    .sign(fileName)
                    .updateVbmeta()
                    .printPackSummary()
            else -> throw IllegalArgumentException("do not support header version $hv")
        }
    }

    override fun flash(fileName: String, deviceName: String) {
        val stem = fileName.substring(0, fileName.indexOf("."))
        super.flash("$fileName.signed", stem)

        if (File("vbmeta.img.signed").exists()) {
            super.flash("vbmeta.img.signed", "vbmeta")
        }
    }

    // invoked solely by reflection
    fun `@footer`(image_file: String) {
        FileInputStream(image_file).use { fis ->
            fis.skip(File(image_file).length() - Footer.SIZE)
            try {
                val footer = Footer(fis)
                log.info("\n" + ObjectMapper().writerWithDefaultPrettyPrinter().writeValueAsString(footer))
            } catch (e: IllegalArgumentException) {
                log.info("image $image_file has no AVB Footer")
            }
        }
    }

    override fun `@verify`(fileName: String) {
        File(Helper.prop("workDir")).let {
            if (!it.exists()) {
                it.mkdirs()
            }
        }

        super.`@verify`(fileName)
    }

    override fun pull(fileName: String, deviceName: String) {
        super.pull(fileName, deviceName)
        super.pull("vbmeta.img", "vbmeta")
    }

    fun clear(fileName: String) {
        super.clear()
        listOf("", ".clear", ".google", ".clear", ".signed", ".signed2").forEach {
            "$fileName$it".deleteIfExists()
        }
        VBMetaParser().clear("vbmeta.img")
    }

    companion object {
        private val log = LoggerFactory.getLogger(BootImgParser::class.java)
    }
}

```

`bbootimg/src/main/kotlin/packable/DtboParser.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import cfig.helper.Helper
import cfig.helper.Helper.Companion.deleteIfExists
import cfig.utils.DTC
import cfig.utils.EnvironmentVerifier
import com.fasterxml.jackson.databind.ObjectMapper
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import utils.Dtbo
import java.io.File
import java.io.FileInputStream
import java.util.*

class DtboParser(val workDir: File) : IPackable {
    override val loopNo: Int
        get() = 0

    constructor() : this(File("."))

    private val log = LoggerFactory.getLogger(DtboParser::class.java)
    private val envv = EnvironmentVerifier()
    private val dtboMaker = Helper.prop("dtboMaker")
    private val dtsSuffix = Helper.prop("config.dts_suffix")

    override fun capabilities(): List<String> {
        return listOf("^dtbo\\.img$")
    }

    override fun unpack(fileName: String) {
        clear()
        Dtbo.parse(fileName)
            .unpack(outDir)
            .extractVBMeta()
            .printSummary()
    }

    override fun pack(fileName: String) {
        ObjectMapper().readValue(File(outDir + "dtbo.json"), Dtbo::class.java)
            .pack()
            .sign()
            .updateVbmeta()
            .printPackSummary()
    }

    override fun pull(fileName: String, deviceName: String) {
        super.pull(fileName, deviceName)
    }

    override fun flash(fileName: String, deviceName: String) {
        val stem = fileName.substring(0, fileName.indexOf("."))
        super.flash("$fileName.signed", stem)

        if (File("vbmeta.img.signed").exists()) {
            super.flash("vbmeta.img.signed", "vbmeta")
        }
    }

    override fun `@verify`(fileName: String) {
        super.`@verify`(fileName)
    }

    fun clear(fileName: String) {
        super.clear()
        listOf("", ".clear", ".google", ".clear", ".signed", ".signed2").forEach {
            "$fileName$it".deleteIfExists()
        }
        VBMetaParser().clear("vbmeta.img")
    }

    private fun execInDirectory(cmd: CommandLine, inWorkDir: File) {
        DefaultExecutor().let {
            it.workingDirectory = inWorkDir
            try {
                log.info(cmd.toString())
                it.execute(cmd)
            } catch (e: org.apache.commons.exec.ExecuteException) {
                log.error("can not exec command")
                return
            }
        }
    }

    @Deprecated("for debugging purpose only")
    fun packLegacy(fileName: String) {
        if (!envv.hasDtc) {
            log.error("'dtc' is unavailable, task aborted")
            return
        }

        val headerPath = File("${outDir}/dtbo.header").path
        val props = Properties().apply {
            FileInputStream(File(headerPath)).use { fis ->
                load(fis)
            }
        }
        val cmd = CommandLine.parse("$dtboMaker create $fileName.clear").let {
            it.addArguments("--version=1")
            for (i in 0 until Integer.parseInt(props.getProperty("dt_entry_count"))) {
                val dtsName = File("$outDir/dtb.$i").path
                it.addArguments(dtsName)
            }
            it
        }
        execInDirectory(cmd, this.workDir)
    }

    @Deprecated("for debugging purpose only")
    fun unpackLegacy(fileName: String) {
        clear()
        val dtbPath = File("$outDir/dtb").path
        val headerPath = File("$outDir/dtbo.header").path
        val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
        val cmd = CommandLine.parse("$cmdPrefix$dtboMaker dump $fileName").let {
            it.addArguments("--dtb $dtbPath")
            it.addArguments("--output $headerPath")
        }
        execInDirectory(cmd, this.workDir)

        val props = Properties().apply {
            FileInputStream(File(headerPath)).use { fis ->
                load(fis)
            }
        }
        if (envv.hasDtc) {
            for (i in 0 until Integer.parseInt(props.getProperty("dt_entry_count"))) {
                val inputDtb = "$dtbPath.$i"
                val outputSrc = File(outDir + "/" + File(inputDtb).name + ".${dtsSuffix}").path
                DTC().decompile(inputDtb, outputSrc)
            }
        } else {
            log.error("'dtc' is unavailable, task aborted")
        }
    }
}

```

`bbootimg/src/main/kotlin/packable/IPackable.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import avb.AVBInfo
import cfig.Avb
import cfig.helper.Helper
import cfig.helper.Dumpling
import cfig.helper.Helper.Companion.check_call
import cfig.helper.Helper.Companion.check_output
import cfig.helper.Helper.Companion.deleteIfExists
import org.slf4j.Logger
import org.slf4j.LoggerFactory
import java.io.File

interface IPackable {
    val loopNo: Int
    val outDir: String
        get() = Helper.prop("workDir")

    fun capabilities(): List<String> {
        return listOf("^dtbo\\.img$")
    }

    fun unpack(fileName: String = "dtbo.img")
    fun pack(fileName: String = "dtbo.img")
    fun flash(fileName: String = "dtbo.img", deviceName: String = "dtbo") {
        "adb root".check_call()
        val abUpdateProp = "adb shell getprop ro.build.ab_update".check_output()
        log.info("ro.build.ab_update=$abUpdateProp")
        val slotSuffix = if (abUpdateProp == "true" && !fileName.startsWith("misc.img")) {
            "adb shell getprop ro.boot.slot_suffix".check_output()
        } else {
            ""
        }
        log.info("slot suffix = $slotSuffix")
        "adb push $fileName /mnt/file.to.burn".check_call()
        "adb shell dd if=/mnt/file.to.burn of=/dev/block/by-name/$deviceName$slotSuffix".check_call()
        "adb shell rm /mnt/file.to.burn".check_call()
    }

    fun pull(fileName: String = "dtbo.img", deviceName: String = "dtbo") {
        "adb root".check_call()
        val abUpdateProp = "adb shell getprop ro.build.ab_update".check_output()
        log.info("ro.build.ab_update=$abUpdateProp")
        val slotSuffix = if (abUpdateProp == "true" && !fileName.startsWith("misc.img")) {
            "adb shell getprop ro.boot.slot_suffix".check_output()
        } else {
            ""
        }
        log.info("slot suffix = $slotSuffix")
        "adb shell dd if=/dev/block/by-name/$deviceName$slotSuffix of=/mnt/file.to.pull".check_call()
        "adb pull /mnt/file.to.pull $fileName".check_call()
        "adb shell rm /mnt/file.to.pull".check_call()
    }

    // invoked solely by reflection
    fun `@verify`(fileName: String) {
        val ai = AVBInfo.parseFrom(Dumpling(fileName)).dumpDefault(fileName)
        Avb.verify(ai, Dumpling(fileName, fileName))
    }

    fun clear() {
        val workDir = Helper.prop("workDir")
        if (File(workDir).exists()) {
            log.info("deleting $workDir ...")
            File(workDir).deleteRecursively()
        }
        File(workDir).mkdirs()
        "uiderrors".deleteIfExists()
    }

    companion object {
        val log: Logger = LoggerFactory.getLogger(IPackable::class.java)
    }
}

```

`bbootimg/src/main/kotlin/packable/MiscImgParser.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import cfig.helper.Helper
import miscimg.MiscImage
import cfig.helper.Helper.Companion.deleteIfExists
import com.fasterxml.jackson.databind.ObjectMapper
import org.slf4j.LoggerFactory
import java.io.File
import java.io.RandomAccessFile

class MiscImgParser : IPackable {
    override val loopNo: Int
        get() = 0

    override fun capabilities(): List<String> {
        return listOf("^misc\\.img$")
    }

    private fun getOutputFile(fileName: String): File {
        return File(workDir + "/" + File(fileName).name.removeSuffix(".img") + ".json")
    }

    override fun unpack(fileName: String) {
        clear()
        val misc = MiscImage.parse(fileName)
        log.info(misc.toString())
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(getOutputFile(fileName), misc)
        ObjectMapper().writerWithDefaultPrettyPrinter()
            .writeValue(getOutputFile("sample.img"), MiscImage.BootloaderMessage.generateSamples())
        log.info(getOutputFile(fileName).path + " is ready")
    }

    override fun pack(fileName: String) {
        val misc = ObjectMapper().readValue(getOutputFile(fileName), MiscImage::class.java)
        val out = File("$fileName.new")
        File(fileName).copyTo(out, true)
        RandomAccessFile(out.name, "rw").use { raf ->
            raf.write(misc.bcb.encode())
            raf.seek(32 * 1024)
            if (misc.virtualAB != null) {
                raf.write(misc.virtualAB!!.encode())
            }
        }
        log.info("${out.name} is ready")
    }

    override fun flash(fileName: String, deviceName: String) {
        val stem = fileName.substring(0, fileName.indexOf("."))
        super.flash("$fileName.new", stem)
    }

    override fun `@verify`(fileName: String) {
        super.`@verify`(fileName)
    }

    override fun pull(fileName: String, deviceName: String) {
        super.pull(fileName, deviceName)
    }

    fun clear(fileName: String) {
        super.clear()
        listOf("", ".new").forEach {
            "$fileName$it".deleteIfExists()
        }
    }

    companion object {
        private val log = LoggerFactory.getLogger(MiscImgParser::class.java)
        private val workDir = Helper.prop("workDir")
    }
}

```

`bbootimg/src/main/kotlin/packable/PackableLauncher.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import cfig.utils.SparseImgParser
import org.slf4j.LoggerFactory
import java.io.File
import java.util.regex.Pattern
import kotlin.reflect.KClass
import kotlin.reflect.full.createInstance
import kotlin.reflect.full.declaredFunctions
import kotlin.system.exitProcess

class PackableLauncher

fun main(args: Array<String>) {
    val log = LoggerFactory.getLogger(PackableLauncher::class.java)
    val packablePool = mutableMapOf<List<String>, KClass<IPackable>>()
    listOf(
        DtboParser(), VBMetaParser(), BootImgParser(), SparseImgParser(), VendorBootParser(), PayloadBinParser(),
        MiscImgParser()
    ).forEach {
        @Suppress("UNCHECKED_CAST")
        packablePool.put(it.capabilities(), it::class as KClass<IPackable>)
    }
    packablePool.forEach {
        log.debug("" + it.key + "/" + it.value)
    }
    var targetFile: String? = null
    var targetHandler: KClass<IPackable>? = null
    run found@{
        for (currentLoopNo in 0..1) { //currently we have only 2 loops
            File(".").listFiles()!!.forEach { file ->
                packablePool
                    .filter { it.value.createInstance().loopNo == currentLoopNo }
                    .forEach { p ->
                        for (item in p.key) {
                            if (Pattern.compile(item).matcher(file.name).matches()) {
                                log.debug("Found: " + file.name + ", " + item)
                                targetFile = file.name
                                targetHandler = p.value
                                return@found
                            }
                        }
                    }
            }//end-of-file-traversing
        }//end-of-range-loop
    }//end-of-found@

    // /* 1 */ no-args & no-handler: help for IPackable
    // /* 2 */ no-args & handler   : help for Handler
    // /* 3 */ args    & no-handler: do nothing
    // /* 4 */ args    & handler   : work
    when (listOf(args.isEmpty(), targetHandler == null)) {
        listOf(true, true) -> { /* 1 */
            log.info("help:")
            log.info("available IPackable subcommands are:")
            IPackable::class.declaredFunctions.forEach {
                log.info("\t" + it.name)
            }
            exitProcess(1)
        }
        listOf(true, false) -> {/* 2 */
            log.info("available ${targetHandler!!.simpleName} subcommands are:")
            targetHandler!!.declaredFunctions.forEach {
                log.info("\t" + it.name)
            }
            exitProcess(1)
        }
        listOf(false, true) -> {/* 3 */
            log.warn("No handler is activated, DO NOTHING!")
            exitProcess(2)
        }
        listOf(false, false) -> {/* 4 */
            log.debug("continue ...")
        }
    }

    targetHandler?.let {
        log.warn("[$targetFile] will be handled by [${it.simpleName}]")
        val functions = it.declaredFunctions.filter { funcItem -> funcItem.name == args[0] }
        if (functions.size != 1) {
            log.error("command '${args[0]}' can not be recognized")
            log.info("available ${it.simpleName} subcommands are:")
            it.declaredFunctions.forEach { theFunc ->
                log.info("\t" + theFunc.name)
            }
            exitProcess(3)
        }
        log.warn("'${args[0]}' sequence initialized")
        val reflectRet = when (functions[0].parameters.size) {
            1 -> {
                functions[0].call(it.createInstance())
            }
            2 -> {
                functions[0].call(it.createInstance(), targetFile!!)
            }
            3 -> {
                if (args.size != 2) {
                    log.info("invoke: ${it.qualifiedName}, $targetFile, " + targetFile!!.removeSuffix(".img"))
                    functions[0].call(it.createInstance(), targetFile!!, targetFile!!.removeSuffix(".img"))
                } else {
                    log.info("invoke: ${it.qualifiedName}, $targetFile, " + args[1])
                    functions[0].call(it.createInstance(), targetFile!!, args[1])
                }
            }
            else -> {
                functions[0].parameters.forEach { kp ->
                    println("Param: " + kp.index + " " + kp.type + " " + kp.name)
                }
                log.error("I am confused by so many parameters")
                exitProcess(4)
            }
        }
        if (functions[0].returnType.toString() != Unit.toString()) {
            log.info("ret: $reflectRet")
        }
        log.warn("'${args[0]}' sequence completed")
    }
}

```

`bbootimg/src/main/kotlin/packable/PayloadBinParser.kt`:

```kt
// Copyright 2022 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import cc.cfig.droid.ota.Payload
import org.slf4j.LoggerFactory

class PayloadBinParser : IPackable {
    override val loopNo: Int = 0
    private val log = LoggerFactory.getLogger(PayloadBinParser::class.java)
    override fun capabilities(): List<String> {
        return listOf("^payload\\.bin$")
    }

    override fun unpack(fileName: String) {
        clear()
        Payload.parse(fileName).let { pl ->
            pl.setUp()
            pl.printInfo()
            pl.unpack()
        }
    }

    override fun pack(fileName: String) {
    }

    override fun `@verify`(fileName: String) {
        super.`@verify`(fileName)
    }

    override fun pull(fileName: String, deviceName: String) {
        super.pull(fileName, deviceName)
    }

    fun clear(fileName: String) {
    }

    override fun flash(fileName: String, deviceName: String) {
    }
}

```

`bbootimg/src/main/kotlin/packable/VBMetaParser.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import avb.AVBInfo
import avb.alg.Algorithms
import cfig.Avb
import cfig.helper.CryptoHelper
import cfig.helper.Dumpling
import cfig.helper.Helper
import cfig.helper.Helper.Companion.deleteIfExists
import com.fasterxml.jackson.core.type.TypeReference
import com.fasterxml.jackson.databind.ObjectMapper
import org.slf4j.LoggerFactory
import java.io.File
import java.nio.file.Files
import java.nio.file.Paths
import java.nio.file.StandardOpenOption

class VBMetaParser : IPackable {
    override val loopNo: Int
        get() = 1

    override fun capabilities(): List<String> {
        return listOf("^vbmeta\\.img$", "^vbmeta\\_[a-z]+.img$")
    }

    override fun unpack(fileName: String) {
        File(Helper.prop("workDir")).let {
            if (!it.exists()) {
                it.mkdirs()
            }
        }
        val ai = AVBInfo.parseFrom(Dumpling(fileName)).dumpDefault(fileName)
        log.info("Signing Key: " + Avb.inspectKey(ai))
    }

    override fun pack(fileName: String) {
        val blob = ObjectMapper().readValue(File(Avb.getJsonFileName(fileName)), AVBInfo::class.java).encodePadded()
        log.info("Writing padded vbmeta to file: $fileName.signed")
        Files.write(Paths.get("$fileName.signed"), blob, StandardOpenOption.CREATE)
    }

    override fun flash(fileName: String, deviceName: String) {
        val stem = fileName.substring(0, fileName.indexOf("."))
        super.flash("$fileName.signed", stem)
    }

    override fun `@verify`(fileName: String) {
        super.`@verify`(fileName)
    }

    override fun pull(fileName: String, deviceName: String) {
        super.pull(fileName, deviceName)
    }

    fun clear(fileName: String) {
        super.clear()
        listOf("", ".signed").forEach {
            "$fileName$it".deleteIfExists()
        }
    }

    private val log = LoggerFactory.getLogger(VBMetaParser::class.java)
}

```

`bbootimg/src/main/kotlin/packable/VendorBootParser.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.packable

import cfig.bootimg.v3.VendorBoot
import cfig.helper.Helper.Companion.deleteIfExists
import com.fasterxml.jackson.databind.ObjectMapper
import org.slf4j.LoggerFactory
import java.io.File

class VendorBootParser : IPackable {
    override val loopNo: Int = 0
    private val log = LoggerFactory.getLogger(VendorBootParser::class.java)
    override fun capabilities(): List<String> {
        return listOf("^vendor_boot(-debug)?\\.img$")
    }

    override fun unpack(fileName: String) {
        clear()
        val vb = VendorBoot
            .parse(fileName)
            .extractImages()
            .extractVBMeta()
            .printUnpackSummary()
        log.debug(vb.toString())
    }

    override fun pack(fileName: String) {
        val cfgFile = "$outDir/${fileName.removeSuffix(".img")}.json"
        log.info("Loading config from $cfgFile")
        ObjectMapper().readValue(File(cfgFile), VendorBoot::class.java)
            .pack()
            .sign()
            .updateVbmeta()
            .printPackSummary()
    }

    override fun `@verify`(fileName: String) {
        super.`@verify`(fileName)
    }

    override fun pull(fileName: String, deviceName: String) {
        super.pull(fileName, deviceName)
        super.pull("vbmeta.img", "vbmeta")
    }

    fun clear(fileName: String) {
        super.clear()
        listOf("", ".clear", ".google", ".clear", ".signed", ".signed2").forEach {
            "$fileName$it".deleteIfExists()
        }
        VBMetaParser().clear("vbmeta.img")
    }

    override fun flash(fileName: String, deviceName: String) {
        val stem = fileName.substring(0, fileName.indexOf("."))
        super.flash("$fileName.signed", stem)

        if (File("vbmeta.img.signed").exists()) {
            super.flash("vbmeta.img.signed", "vbmeta")
        }
    }
}

```

`bbootimg/src/main/kotlin/utils/DTC.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.utils

import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory

class DTC {
    private val log = LoggerFactory.getLogger(DTC::class.java)

    fun decompile(dtbFile: String, outFile: String): Boolean {
        log.info("parsing DTB: $dtbFile")
        //CommandLine.parse("fdtdump").let {
        //    it.addArguments("$dtbFile")
        //}
        //dtb-> dts
        DefaultExecutor().let {
            try {
                val cmd = CommandLine.parse("dtc -q -I dtb -O dts").apply {
                    addArguments(dtbFile)
                    addArguments("-o $outFile")
                }
                it.execute(cmd)
                log.info(cmd.toString())
            } catch (e: org.apache.commons.exec.ExecuteException) {
                log.error("can not parse DTB: $dtbFile")
                return false
            }
        }
        //dts -> yaml
        DefaultExecutor().let {
            try {
                val cmd = CommandLine.parse("dtc -q -I dts -O yaml").apply {
                    addArguments(outFile)
                    addArguments("-o $outFile.yaml")
                }
                it.execute(cmd)
                log.info(cmd.toString())
            } catch (e: org.apache.commons.exec.ExecuteException) {
                log.error("can not transform DTS: $outFile")
                return false
            }
        }
        return true
    }

    fun compile(dtsFile: String, outFile: String): Boolean {
        log.info("compiling DTS: $dtsFile")
        val cmd = CommandLine.parse("dtc -q -I dts -O dtb").let {
            it.addArguments(dtsFile)
            it.addArguments("-o $outFile")
        }

        DefaultExecutor().let {
            try {
                it.execute(cmd)
                log.info(cmd.toString())
            } catch (e: org.apache.commons.exec.ExecuteException) {
                log.error("can not compile DTB: $dtsFile")
                return false
            }
        }
        return true
    }
}

```

`bbootimg/src/main/kotlin/utils/Dtbo.kt`:

```kt
package utils

import avb.AVBInfo
import cc.cfig.io.Struct
import cfig.Avb
import cfig.bootimg.Common
import cfig.bootimg.Signer
import cfig.bootimg.v3.VendorBoot
import cfig.helper.Helper
import cfig.helper.Dumpling
import cfig.packable.VBMetaParser
import cfig.utils.DTC
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.io.InputStream

class Dtbo(
    var info: DtboInfo = DtboInfo(),
    var header: DtboHeader = DtboHeader(),
    var dtEntries: MutableList<DeviceTreeTableEntry> = mutableListOf()
) {
    class DtboInfo(
        var output: String = "",
        var json: String = "",
        var imageSize: Int = 0
    )

    // part I: header
    data class DtboHeader(
        var totalSize: Int = 0,
        var headerSize: Int = 0,
        var entrySize: Int = 0,
        var entryCount: Int = 0,
        var entryOffset: Int = 0,
        var pageSize: Int = 0,
        var version: Int = 0
    ) {
        companion object {
            const val magic = 0xd7b7ab1e
            private const val FORMAT_STRING = ">I7i"
            internal const val SIZE = 32

            init {
                check(Struct(FORMAT_STRING).calcSize() == SIZE)
            }
        }

        constructor(iS: InputStream?) : this() {
            if (iS == null) {
                return
            }
            val info = Struct(FORMAT_STRING).unpack(iS)
            check(8 == info.size)
            if ((info[0] as UInt).toLong() != magic) {
                throw IllegalArgumentException("stream doesn't look like DTBO header")
            }
            totalSize = info[1] as Int
            headerSize = info[2] as Int
            if (headerSize != DtboHeader.SIZE) {
                log.warn("headerSize $headerSize != ${DtboHeader.SIZE}")
            }
            entrySize = info[3] as Int
            if (entrySize != DeviceTreeTableEntry.SIZE) {
                log.warn("entrySize $entrySize != ${DeviceTreeTableEntry.SIZE}")
            }
            entryCount = info[4] as Int
            entryOffset = info[5] as Int
            pageSize = info[6] as Int
            version = info[7] as Int
        }

        fun encode(): ByteArray {
            return Struct(FORMAT_STRING).pack(
                magic,
                totalSize,
                headerSize,
                entrySize,
                entryCount,
                entryOffset,
                pageSize,
                version
            )
        }
    }

    // part II: dt entry table
    data class DeviceTreeTableEntry(
        var sequenceNo: Int = 0,
        var entrySize: Int = 0,
        var entryOffset: Int = 0,
        var id: Int = 0,
        var rev: Int = 0,
        var flags: Int = 0,
        var reserved1: Int = 0,
        var reserved2: Int = 0,
        var reserved3: Int = 0,
    ) {
        companion object {
            private const val FORMAT_STRING = ">8i"
            internal const val SIZE = 32

            init {
                check(Struct(FORMAT_STRING).calcSize() == SIZE)
            }
        }

        constructor(iS: InputStream) : this() {
            val info = Struct(FORMAT_STRING).unpack(iS)
            check(8 == info.size)
            entrySize = info[0] as Int
            entryOffset = info[1] as Int
            id = info[2] as Int
            rev = info[3] as Int
            flags = info[4] as Int
            reserved1 = info[5] as Int
            reserved2 = info[6] as Int
            reserved3 = info[7] as Int
        }

        fun encode(): ByteArray {
            return Struct(FORMAT_STRING).pack(
                entrySize,
                entryOffset,
                id,
                rev,
                flags,
                reserved1,
                reserved2,
                reserved3
            )
        }
    }

    companion object {
        fun parse(fileName: String): Dtbo {
            val ret = Dtbo()
            ret.info.output = fileName
            ret.info.imageSize = File(fileName).length().toInt()
            ret.info.json = fileName.removeSuffix(".img") + ".json"
            FileInputStream(fileName).use { fis ->
                ret.header = DtboHeader(fis)
                for (i in 0 until ret.header.entryCount) {
                    ret.dtEntries.add(DeviceTreeTableEntry(fis).apply { sequenceNo = i })
                }
            }
            return ret
        }

        private val log = LoggerFactory.getLogger(Dtbo::class.java)
        private val outDir = Helper.prop("workDir")
        private val dtsSuffix = Helper.prop("config.dts_suffix")
    }

    fun extractVBMeta(): Dtbo {
        try {
            AVBInfo.parseFrom(Dumpling(info.output)).dumpDefault(info.output)
        } catch (e: Exception) {
            log.error("extraceVBMeta(): $e")
        }
        if (File("vbmeta.img").exists()) {
            log.warn("Found vbmeta.img, parsing ...")
            VBMetaParser().unpack("vbmeta.img")
        }
        return this
    }

    fun unpack(outDir: String): Dtbo {
        File("${outDir}dt").mkdir()
        ObjectMapper().writerWithDefaultPrettyPrinter().writeValue(File("${outDir}dtbo.json"), this)
        dtEntries.forEach {
            Common.dumpDtb(Helper.Slice(info.output, it.entryOffset, it.entrySize, "${outDir}dt/dt.${it.sequenceNo}"))
        }
        return this
    }

    fun pack(): Dtbo {
        FileOutputStream(info.output + ".clear").use { fos ->
            // Part I
            this.header.entryCount = this.dtEntries.size
            this.header.totalSize = (DtboHeader.SIZE
                    + (header.entryCount * DeviceTreeTableEntry.SIZE)
                    + this.dtEntries.sumOf { File("${outDir}dt/dt.${it.sequenceNo}").length() })
                .toInt()
            // Part II - a
            for (index in 0 until dtEntries.size) {
                DTC().compile("${outDir}dt/dt.${index}.${dtsSuffix}", "${outDir}dt/dt.${index}")
            }
            // Part II - b
            var offset = DtboHeader.SIZE + (header.entryCount * DeviceTreeTableEntry.SIZE)
            this.dtEntries.forEachIndexed { index, deviceTreeTableEntry ->
                deviceTreeTableEntry.entrySize = File("${outDir}dt/dt.${index}").length().toInt()
                deviceTreeTableEntry.entryOffset = offset
                offset += deviceTreeTableEntry.entrySize
            }

            // + Part I
            fos.write(header.encode())
            // + Part II
            this.dtEntries.forEach {
                fos.write(it.encode())
            }
            // + Part III
            for (index in 0 until dtEntries.size) {
                fos.write(File("${outDir}dt/dt.${index}").readBytes())
            }
        }
        return this
    }

    fun printSummary(): Dtbo {
        val tableHeader = AsciiTable().apply {
            addRule()
            addRow("What", "Where")
            addRule()
        }
        val tab = AsciiTable().let {
            it.addRule()
            it.addRow("image info", outDir + info.output.removeSuffix(".img") + ".json")
            it.addRule()
            it.addRow("device-tree blob   (${this.header.entryCount} blobs)", "${outDir}dt/dt.*")
            it.addRow("\\-- device-tree source ", "${outDir}dt/dt.*.${dtsSuffix}")
            it.addRule()
            it.addRow("AVB info", Avb.getJsonFileName(info.output))
            it.addRule()
            it
        }
        val tabVBMeta = AsciiTable().let {
            if (File("vbmeta.img").exists()) {
                it.addRule()
                it.addRow("vbmeta.img", Avb.getJsonFileName("vbmeta.img"))
                it.addRule()
                "\n" + it.render()
            } else {
                ""
            }
        }
        log.info("\n\t\t\tUnpack Summary of ${info.output}\n{}\n{}{}", tableHeader.render(), tab.render(), tabVBMeta)
        return this
    }

    fun sign(): Dtbo {
        val avbtool = String.format(Helper.prop("avbtool"), "v1.2")
        Signer.signAVB(info.output, info.imageSize.toLong(), avbtool)
        return this
    }

    fun updateVbmeta(): Dtbo {
        Avb.updateVbmeta(info.output)
        return this
    }

    fun printPackSummary(): Dtbo {
        VendorBoot.printPackSummary(info.output)
        return this
    }
}

```

`bbootimg/src/main/kotlin/utils/EnvironmentVerifier.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.utils

import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.PumpStreamHandler
import org.slf4j.LoggerFactory
import java.io.ByteArrayOutputStream
import kotlin.system.exitProcess

class EnvironmentVerifier {
    val hasXz: Boolean
        get() : Boolean {
            try {
                val outputStream = ByteArrayOutputStream()
                val exec = DefaultExecutor()
                exec.streamHandler = PumpStreamHandler(outputStream)
                exec.execute(CommandLine.parse("xz --version"))
                val os = outputStream.toString().trim()
                log.debug(os)
                log.debug("xz available")
            } catch (e: Exception) {
                log.warn("'xz' not installed. Please install it manually to analyze DTB files")
                if (isMacOS) {
                    log.warn("For Mac OS: \n\n\tbrew install xz\n")
                }
                return false
            }
            return true
        }

    val hasGzip: Boolean
        get(): Boolean {
            try {
                Runtime.getRuntime().exec("gzip -V")
                log.debug("gzip available")
            } catch (e: Exception) {
                log.warn("gzip unavailable")
                return false
            }
            return true
        }

    val hasLz4: Boolean
        get() : Boolean {
            try {
                Runtime.getRuntime().exec("lz4 --version")
                log.debug("lz4 available")
            } catch (e: Exception) {
                log.warn("lz4 not installed")
                if (isMacOS) {
                    log.warn("For Mac OS: \n\n\tbrew install lz4\n")
                }
                return false
            }
            return true
        }

    val has7z: Boolean
        get(): Boolean {
            try {
                Runtime.getRuntime().exec("7z i")
                log.debug("7z available")
            } catch (e: Exception) {
                log.warn("7z not installed")
                return false
            }
            return true
        }

    val hasDtc: Boolean
        get(): Boolean {
            try {
                Runtime.getRuntime().exec("dtc --version")
                log.debug("dtc available")
            } catch (e: Exception) {
                log.warn("'dtc' not installed. Please install it manually to analyze DTB files")
                if (isMacOS) {
                    log.warn("For Mac OS: \n\tbrew install dtc\n")
                } else if (isLinux) {
                    log.warn("Like this: \n\t$ sudo apt install device-tree-compiler")
                }
                return false
            }
            return true
        }

    val isMacOS: Boolean
        get() = System.getProperty("os.name").contains("Mac")

    val isLinux: Boolean
        get() = System.getProperty("os.name").contains("Linux")

    val isWindows: Boolean
        get() = System.getProperty("os.name").contains("Windows")

    private fun getJavaVersion(): Int {
        return System.getProperty("java.version").let { version ->
            if (version.startsWith("1.")) {
                version.substring(2, 3)
            } else {
                val dot = version.indexOf(".")
                if (dot != -1) {
                    version.substring(0, dot)
                } else {
                    version
                }
            }
        }.toInt()
    }

    init {
        if (getJavaVersion() < 9) {
            log.error("Java 9+ is required, while it's " + System.getProperty("java.version"))
            exitProcess(1)
        } else {
            log.debug("Java version " + System.getProperty("java.version"))
        }
    }

    companion object {
        private val log = LoggerFactory.getLogger("EnvironmentVerifier")
    }
}

```

`bbootimg/src/main/kotlin/utils/KernelExtractor.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.utils

import cfig.helper.Helper
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.Logger
import org.slf4j.LoggerFactory
import java.io.File

class KernelExtractor {
    val log: Logger = LoggerFactory.getLogger("KernelExtractor")

    fun envCheck(): Boolean {
        val envv = EnvironmentVerifier()
        return envv.hasLz4 && envv.hasXz && envv.hasGzip
    }

    fun run(fileName: String, workDir: File? = null): List<String> {
        val ret: MutableList<String> = mutableListOf()
        val kernelVersionFile = Helper.prop("kernelVersionFile")
        val kernelConfigFile = Helper.prop("kernelConfigFile")
        val cmdPrefix = if (EnvironmentVerifier().isWindows) "python " else ""
        val cmd = CommandLine.parse(cmdPrefix + Helper.prop("kernelExtracter")).let {
            it.addArgument("--input")
            it.addArgument(fileName)
            it.addArgument("--output-configs")
            it.addArgument(kernelConfigFile)
            it.addArgument("--output-version")
            it.addArgument(kernelVersionFile)
        }
        DefaultExecutor().let { it ->
            it.workingDirectory = workDir ?: File("../")
            try {
                it.execute(cmd)
                log.info(cmd.toString())
                val kernelVersion = File(kernelVersionFile).readLines()
                log.info("kernel version: $kernelVersion")
                log.info("kernel config dumped to : $kernelConfigFile")
                ret.add(kernelVersion.toString())
                ret.add(kernelVersionFile)
                ret.add(kernelConfigFile)
            } catch (e: org.apache.commons.exec.ExecuteException) {
                listOf(kernelConfigFile, kernelVersionFile).forEach { fn ->
                    File(fn).let { f ->
                        if (f.exists()) f.delete()
                    }
                }
                log.warn("can not parse kernel info")
            }
        }
        return ret
    }
}

```

`bbootimg/src/main/kotlin/utils/SparseImgParser.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.utils

import avb.blob.Footer
import cc.cfig.io.Struct
import cfig.bootimg.Common.Companion.deleleIfExists
import cfig.helper.Helper
import cfig.helper.Helper.Companion.check_call
import cfig.helper.Helper.Companion.check_output
import cfig.packable.IPackable
import com.fasterxml.jackson.databind.ObjectMapper
import de.vandermeer.asciitable.AsciiTable
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.util.*

class SparseImgParser : IPackable {
    override val loopNo: Int
        get() = 0
    private val log = LoggerFactory.getLogger(SparseImgParser::class.java)
    private val simg2imgBin: String
    private val img2simgBin: String

    init {
        val osSuffix = if (EnvironmentVerifier().isMacOS) "macos" else "linux"
        simg2imgBin = "./aosp/libsparse/simg2img/build/install/main/release/$osSuffix/simg2img"
        img2simgBin = "./aosp/libsparse/img2simg/build/install/main/release/$osSuffix/img2simg"
    }

    override fun capabilities(): List<String> {
        return listOf(
            "^(system|system_ext|system_other|system_dlkm)\\.img$",
            "^(vendor|vendor_dlkm|product|cache|userdata|super|oem|odm|odm_dlkm)\\.img$"
        )
    }

    override fun unpack(fileName: String) {
        clear()
        var target = fileName
        if (isSparse(fileName)) {
            val tempFile = UUID.randomUUID().toString()
            outerFsType = "sparse"
            val rawFile = "$workDir${File(fileName).nameWithoutExtension}"
            simg2img(fileName, tempFile)
            target = if (isExt4(tempFile)) {
                innerFsType = "ext4"
                "$rawFile.ext4"
            } else if (isErofs(tempFile)) {
                innerFsType = "erofs"
                "$rawFile.erofs"
            } else {
                "$rawFile.raw"
            }
            File(tempFile).renameTo(File(target))
        } else if (isExt4(fileName)) {
            outerFsType = "ext4"
            innerFsType = "ext4"
        } else if (isErofs(fileName)) {
            outerFsType = "erofs"
            innerFsType = "erofs"
        }
        when (innerFsType) {
            "ext4" -> {
                extractExt4(target)
            }

            "erofs" -> {
                extraceErofs(target)
            }

            else -> {
                log.warn("unsuported image type: $innerFsType")
            }
        }
        File("${workDir}mount").mkdir()
        printSummary(fileName)
    }

    override fun pack(fileName: String) {
        TODO("not implemented")
    }

    // invoked solely by reflection
    fun `@footer`(fileName: String) {
        FileInputStream(fileName).use { fis ->
            fis.skip(File(fileName).length() - Footer.SIZE)
            try {
                val footer = Footer(fis)
                log.info("\n" + ObjectMapper().writerWithDefaultPrettyPrinter().writeValueAsString(footer))
            } catch (e: IllegalArgumentException) {
                log.info("image $fileName has no AVB Footer")
            }
        }
    }

    override fun `@verify`(fileName: String) {
        super.`@verify`(fileName)
    }

    private fun simg2img(sparseIn: String, flatOut: String) {
        log.info("parsing Android sparse image $sparseIn ...")
        "$simg2imgBin $sparseIn $flatOut".check_call()
        log.info("parsed Android sparse image $sparseIn -> $flatOut")
    }

    private fun img2simg(flatIn: String, sparseOut: String) {
        log.info("transforming image to Android sparse format: $flatIn ...")
        "$img2simgBin $flatIn $sparseOut".check_call()
        log.info("transformed Android sparse image: $flatIn -> $sparseOut")
    }

    override fun flash(fileName: String, deviceName: String) {
        TODO("not implemented")
    }

    fun clear(fileName: String) {
        super.clear()
        File(fileName).deleleIfExists()
    }

    private fun isSparse(fileName: String): Boolean {
        val magic = Helper.Companion.readFully(fileName, 0, 4)
        return Struct(">I").pack(SPARSE_MAGIC).contentEquals(magic)
    }

    private fun isExt4(fileName: String): Boolean {
        val superBlock = Helper.readFully(fileName, 1024, 64)
        val magic = byteArrayOf(superBlock[0x38], superBlock[0x39])
        return Struct(">h").pack(0x53ef).contentEquals(magic)
    }

    // https://elixir.bootlin.com/linux/latest/source/include/uapi/linux/magic.h#L23
    private fun isErofs(fileName: String): Boolean {
        val magic = Helper.readFully(fileName, 1024, 4)
        return Struct(">I").pack(0xe2e1f5e0).contentEquals(magic)
    }

    private fun extractExt4(fileName: String) {
        if (EnvironmentVerifier().has7z) {
            val stem = File(fileName).nameWithoutExtension
            val outStr = "7z x $fileName -y -o$workDir$stem".check_output()
            File("$workDir/$stem.log").writeText(outStr)
        } else {
            log.warn("Please install 7z for ext4 extraction")
        }
    }

    private fun extraceErofs(fileName: String) {
        log.info("sudo mount $fileName -o loop -t erofs ${workDir}mount")
    }

    private fun printSummary(fileName: String) {
        val stem = File(fileName).nameWithoutExtension
        val tail = AsciiTable().apply {
            addRule()
            addRow("To view erofs contents:")
        }
        val tab = AsciiTable().apply {
            addRule()
            addRow("What", "Where")
            addRule()
            addRow("image ($outerFsType)", fileName)
            ("$workDir$stem.ext4").let { ext4 ->
                if (File(ext4).exists()) {
                    addRule()
                    addRow("converted image (ext4)", ext4)
                }
            }
            ("$workDir$stem.erofs").let {
                if (File(it).exists()) {
                    addRule()
                    addRow("converted image (erofs)", it)
                    tail.addRule()
                    tail.addRow("sudo mount $it -o loop -t erofs ${workDir}mount")
                    tail.addRule()
                } else if (innerFsType == "erofs") {
                    tail.addRule()
                    tail.addRow("sudo mount $fileName -o loop -t erofs ${workDir}mount")
                    tail.addRule()
                }
            }
            ("$workDir$stem").let {
                if (File(it).exists()) {
                    addRule()
                    if (File(it).isFile) {
                        addRow("converted image (raw)", it)
                    } else {
                        addRow("extracted content", it)
                    }
                }
            }
            ("$workDir$stem.log").let {
                if (File(it).exists()) {
                    addRule()
                    addRow("log", it)
                }
            }
            if (innerFsType == "erofs") {
                addRule()
                addRow("mount point", "${workDir}mount")
            }
            addRule()
        }
        log.info("\n" + tab.render() + "\n" + if (innerFsType == "erofs") tail.render() else "")
    }

    companion object {
        private val SPARSE_MAGIC: UInt = 0x3aff26edu
        private val workDir = Helper.prop("workDir")
        private var outerFsType = "raw"
        private var innerFsType = "raw"
    }
}

```

`bbootimg/src/main/resources/fsconfig.txt`:

```txt
{ type:"REG", mode:"770", uid:1000, gid:2001, prefix:"cache" }
{ type:"REG", mode:"555", uid:0, gid:0, prefix:"config" }
{ type:"REG", mode:"771", uid:1000, gid:1000, prefix:"data/app" }
{ type:"REG", mode:"771", uid:1000, gid:1000, prefix:"data/app-private" }
{ type:"REG", mode:"771", uid:1000, gid:1000, prefix:"data/app-ephemeral" }
{ type:"REG", mode:"771", uid:0, gid:0, prefix:"data/dalvik-cache" }
{ type:"REG", mode:"771", uid:1000, gid:1000, prefix:"data/data" }
{ type:"REG", mode:"771", uid:2000, gid:2000, prefix:"data/local/tmp" }
{ type:"REG", mode:"771", uid:2000, gid:2000, prefix:"data/local" }
{ type:"REG", mode:"770", uid:1014, gid:1014, prefix:"data/misc/dhcp" }
{ type:"REG", mode:"771", uid:1037, gid:1037, prefix:"data/misc/shared_relro" }
{ type:"REG", mode:"1771", uid:1000, gid:9998, prefix:"data/misc" }
{ type:"REG", mode:"775", uid:1023, gid:1023, prefix:"data/media/Music" }
{ type:"REG", mode:"775", uid:1023, gid:1023, prefix:"data/media" }
{ type:"REG", mode:"750", uid:0, gid:2000, prefix:"data/nativetest" }
{ type:"REG", mode:"750", uid:0, gid:2000, prefix:"data/nativetest64" }
{ type:"REG", mode:"750", uid:0, gid:2000, prefix:"data/benchmarktest" }
{ type:"REG", mode:"750", uid:0, gid:2000, prefix:"data/benchmarktest64" }
{ type:"REG", mode:"775", uid:0, gid:0, prefix:"data/preloads" }
{ type:"REG", mode:"771", uid:1000, gid:1000, prefix:"data" }
{ type:"REG", mode:"755", uid:0, gid:1000, prefix:"mnt" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"product/bin" }
{ type:"REG", mode:"777", uid:0, gid:0, prefix:"sdcard" }
{ type:"REG", mode:"751", uid:0, gid:1028, prefix:"storage" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"system/bin" }
{ type:"REG", mode:"755", uid:0, gid:0, prefix:"system/etc/ppp" }
{ type:"REG", mode:"755", uid:0, gid:2000, prefix:"system/vendor" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"system/xbin" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"system/apex/*/bin" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"system_ext/bin" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"system_ext/apex/*/bin" }
{ type:"REG", mode:"751", uid:0, gid:2000, prefix:"vendor/bin" }
{ type:"REG", mode:"755", uid:0, gid:2000, prefix:"vendor" }
{ type:"DIR", mode:"644", uid:1000, gid:1000, prefix:"data/app/*" }
{ type:"DIR", mode:"644", uid:1000, gid:1000, prefix:"data/app-ephemeral/*" }
{ type:"DIR", mode:"644", uid:1000, gid:1000, prefix:"data/app-private/*" }
{ type:"DIR", mode:"644", uid:10000, gid:10000, prefix:"data/data/*" }
{ type:"DIR", mode:"644", uid:1023, gid:1023, prefix:"data/media/*" }
{ type:"DIR", mode:"640", uid:0, gid:2000, prefix:"data/nativetest/tests.txt" }
{ type:"DIR", mode:"640", uid:0, gid:2000, prefix:"data/nativetest64/tests.txt" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"data/nativetest/*" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"data/nativetest64/*" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"data/benchmarktest/*" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"data/benchmarktest64/*" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"default.prop" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"system/etc/prop.default" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"odm/build.prop" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"odm/default.prop" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"odm/etc/build.prop" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"odm/etc/fs_config_dirs" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"odm/etc/fs_config_files" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"oem/etc/fs_config_dirs" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"oem/etc/fs_config_files" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"product/build.prop" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"product/etc/fs_config_dirs" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"product/etc/fs_config_files" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"system_ext/build.prop" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"system_ext/etc/fs_config_dirs" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"system_ext/etc/fs_config_files" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system/bin/crash_dump32" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system/bin/crash_dump64" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system/bin/debuggerd" }
{ type:"DIR", mode:"550", uid:1036, gid:1036, prefix:"system/bin/logd" }
{ type:"DIR", mode:"700", uid:0, gid:0, prefix:"system/bin/secilc" }
{ type:"DIR", mode:"750", uid:0, gid:0, prefix:"system/bin/uncrypt" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"system/build.prop" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"system/etc/fs_config_dirs" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"system/etc/fs_config_files" }
{ type:"DIR", mode:"440", uid:0, gid:2000, prefix:"system/etc/init.goldfish.rc" }
{ type:"DIR", mode:"550", uid:0, gid:2000, prefix:"system/etc/init.goldfish.sh" }
{ type:"DIR", mode:"550", uid:0, gid:2000, prefix:"system/etc/init.ril" }
{ type:"DIR", mode:"555", uid:0, gid:0, prefix:"system/etc/ppp/*" }
{ type:"DIR", mode:"555", uid:0, gid:0, prefix:"system/etc/rc.*" }
{ type:"DIR", mode:"750", uid:0, gid:0, prefix:"vendor/bin/install-recovery.sh" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"vendor/build.prop" }
{ type:"DIR", mode:"600", uid:0, gid:0, prefix:"vendor/default.prop" }
{ type:"DIR", mode:"440", uid:0, gid:0, prefix:"vendor/etc/recovery.img" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"vendor/etc/fs_config_dirs" }
{ type:"DIR", mode:"444", uid:0, gid:0, prefix:"vendor/etc/fs_config_files" }
{ type:"DIR", mode:"6755", uid:0, gid:0, prefix:"system/xbin/procmem" }
{ type:"DIR", mode:"4750", uid:0, gid:2000, prefix:"system/xbin/su" }
{ type:"DIR", mode:"700", uid:1000, gid:2000, prefix:"system/bin/inputflinger" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"system/bin/run-as" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"system/bin/simpleperf_app_runner" }
{ type:"DIR", mode:"755", uid:0, gid:0, prefix:"first_stage_ramdisk/system/bin/e2fsck" }
{ type:"DIR", mode:"755", uid:0, gid:0, prefix:"first_stage_ramdisk/system/bin/tune2fs" }
{ type:"DIR", mode:"755", uid:0, gid:0, prefix:"first_stage_ramdisk/system/bin/resize2fs" }
{ type:"DIR", mode:"755", uid:0, gid:0, prefix:"bin/*" }
{ type:"DIR", mode:"640", uid:0, gid:2000, prefix:"fstab.*" }
{ type:"DIR", mode:"750", uid:0, gid:2000, prefix:"init*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"odm/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"product/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system/xbin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system/apex/*/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system_ext/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"system_ext/apex/*/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"vendor/bin/*" }
{ type:"DIR", mode:"755", uid:0, gid:2000, prefix:"vendor/xbin/*" }

```

`bbootimg/src/main/resources/general.cfg`:

```cfg
workDir = build/unzip_boot/
mkbootfsBin = aosp/mkbootfs.%d/build/exe/mkbootfs/mkbootfs
avbtool = aosp/avb/avbtool.%s.py
bootSigner = aosp/boot_signer/build/libs/boot_signer.jar
verity_pk8 = aosp/security/verity.pk8
verity_pem = aosp/security/verity.x509.pem
kernelVersionFile = build/unzip_boot/kernel_version.txt
kernelConfigFile = build/unzip_boot/kernel_configs.txt
kernelExtracter = aosp/make/tools/extract_kernel.py
mkbootimg = aosp/system/tools/mkbootimg/mkbootimg.py
dtboMaker = aosp/system/libufdt/utils/src/mkdtboimg.py
payloadDir = build/payload/
config.allow_cpio_duplicate = true
config.dts_suffix = dts
```

`bbootimg/src/main/resources/known_keys.json`:

```json
[{
  "device" : "ADT-3",
  "manufacturer" : "amlogic",
  "algorithm" : "SHA256_RSA2048",
  "pubk" : "AAAIAJHD1q2K7QEFh5MBfReSuk2oQ9vQLC1/kdSBfizd0iFTyNiVd57KUIjCzfN2uMJWiLtNUYa7gK+1TxMt8wkFZq61Mob563hmPl8FbNn2qb4+/g/DsaeZstuptD9L9pBVuIyUskl8hZ3GFO3Xn9BXW19NAhXYdi5qUxGsWsInRSqqASLxmV/zEQGFhhEVh9ZlCEyYukqaVaUunEDdkcAABRpcaT61QOww5QbZe8T8K/FgVxz1Mz4eF1plphSaah94TCG5Wc+RFeZ5QYATuBqsKPU7t9BAmnxXBbhAGiSkKUpI9Ln9N42MLvR9R+NBAiCZCoUOKPYBirqcyp48TZJiLuY4MgLbYr0mJ3OKgxUF6Q0MLPPrdKca/KagLkojDnshDTFmejPEWJS1b5snCI0lH3mr7HRVNfst4e8l4IfS5AxX2YLuAhWvjHql7Yvhdysy7toGZapQw6REjOgvleIUwI6QGBSHlr2PQ8zCgJFFk3dAo2EYuk3hjNEWRGkW8DB4l4ij2yMYI8w4vFVg5iacdfVL4lfgItQb6OYSJJZADOcCrHhqR+OWOLftyjFP/oSZC3T6I30F/PIBAb+i0FSm+np2yycv7T0GgxZQD3ESx1Vsm4QtXIy5E1ToLumXWUN2++yi30XM+wfqpargU0vNdG5pgWg2DR7SGcKjIkWqJ+LJ2B283A==",
  "sha1" : "294dbb09016c013c57750edce0df0187409d56ce"
},
{
  "device" : "GKI",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA4096",
  "pubk" : "AAAQAN3haYGQPHFa9yJAviIpp5Feoyn9fr9IEOXPfDzY+SzDr0drrCjO5gY59btYOt/RbVhiXRZK3uSwN3OSiQ98CtECYG9AxUu+3m7o0W+y/UiQkvbbLN+gnbZjiAqWWBIdT0RUTdIf98eMBdgzbdpbDn7uzmwDjLvCkrc/rsWcYYeD6VuS0qKiw/Bzm/8hp7lqqtW0fgn4Y7OBPXRfckyNExjkSvktZZKDFFKp/Xcio5coGLBqXc+1g0Lmo2osbx4bSP4cwJSxKtEeSfH51DLPSc8w+tba/8Jmp+j0KAf5jowNzRKyxyjxavzs0c0Us087MkHN4MaBeLIRH4twUtBRUVKNwacmC3vkFjgnVhpATzXHQa6OYQdV6I8Hu1GyKJ1mr85vEOroNB710Kr7r4Y6YhkW4TpYJQzQ0YZGVQXgp0q00qAQGa9BANrsBaPHFLfLMt/oxGWmIIEeJPKMJ20VTojJqC0XJp39Ujbn0UXC/5V9lU94BQYwog84FOVh2THwcMYsDFb/WlJkF6ERKDYjQwEcIPwR18E1oM3nBM3x5TJpeCV929gxBKYVdf3uoPwiq/tJmM6m+HcHrqjnwN17i1SyG54Hg5rXRQG98Zx+jh4mam1j6dD9dnm0UYNbU24Bca5QhfSR9gwTXxj+9owvyNhKFF41/LcEeaIl+4W0azzj0Mcpf45+UlP0vG5mxKpzlasQthS8m6nPdkYrKrSTClWueuZRhiW0lnPF7PCj8n9jccJ2xYoqcdKRja3hQuBp5u6cRjZi0ACimdTwAMjw7IVkyNlJsTEHPCcQCMknWp5sncJtqady+BbO4W4AfGqSdi6zEZQc3bP5QdQsrnT3rocNHoX3gNwh+hDaED5Rj3MzPXFclb0xfLf1yMSIVuGCePKAcOqwlVbQIeoo2yfHPWX02EvS1JbBrkBCAJ6HRw3e5t/JQXm+faSBaTWGrSBwqaG/ykXgEDzjdeTsGnVr5g9vazd3Z3Lr6F7HqTIYvMZ+ovkIwiBC6dapTX0Ow35m+NjYSTUd15igmaqxjxq4zq2wxE5T5DQhF5ria8cp+0AJhWkfl35oxPWPnLworlDjvu2BdEb0RtfkHM8/po1BBlHzYqqTyV1NqkQq9nO6gVCyGW/X8XufeXKg1CDUiGfjn3IhIIXVcmjW4NxAgdCZdAjGNqIyaYR/LOksw0uaB1IFh0VQNjj300LOXUbJMXdaxzx1sQpw+nFSNYtTX6Uck/XfeBJDSiae5kbVQcey0hhbj1CDWT/u05hVvtxbmmcqVcS+pXk3wjJ/nnWJNga+DYtzK678/u9Fcj0dC+fsWXlEgRen9i4hDynaB7nkOFsnrweA014TLwuSSOmdEDnO0NMnxeQH",
  "sha1" : "144820003f9d46c96e9090dcf0e4feb84ca84810"
},
{
  "device" : "Pixel 3",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA2048",
  "pubk" : "AAAIAH0QbcWadnydcrOvnaY8DvH/VQVZ4o2h/uUahVy2SY+E8krdSWU9Wcg0CZl/AvHPPL2rD1i6KoLDzqgS9cyybSJYH2LA+J7MIlBTV7+z0tMT+rYT7NkxcC+5AZjkQsmL+fbS1q0VIEtCM/ugPnOY1Imympq3rOxrGee8I/bNm5GxCT//2xUIjQn5D/1oQ6eCtBGBMgY4B2/r6ooUM8Dhp+xiuwxSs6iEoZuh5Ba/xWh6neRe7AHT54axGdXz50B8aQx3DXlvVjuz8LA9aUrlD9o6qYftNgg4hfaKPx5Vi0zw4teIL86F6Plte1F7HDgyjPDxYyAKsEk+PJPGexGJHeEPg3bzgRR3+ss18VcmMgL9Dk2afbuf2VANcxfNA5J7e4J3YGapPwILLMLlojIACk0b1gBclH1hffkQZ4O/SYC0AGsMJDI45kauUWJmYglONmqxgh+rDI5xQP1KiDkRDtBWjocGcf7mHlxvI0E7X+oK7V+cEFEbAK5sEvSs4QDGlb+bjFS+WRYpodO/HzF5M0Cinbn7izvek3uP+LMogj6ELEnZqe9u7ubmgKv/BIhQY/RiRx0goLkwXzVwaAp7y6vh/Vi6YB2pzR6IiItRCkoPK6U1xnVJY/oElv0icqDA2ynXbxZcc6D6OXqTcueKEmeuSGe7jan0y4oDnMLd3k5MaYn5iQ==",
  "sha1" : "ad8569837cc06521720a35357475f87283b59234"
},
{
  "device" : "Pixel 4",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA4096",
  "pubk" : "AAAQANeIn3+J2UI8Yc4LIB5gWoLlw4d/OHXZv0M5zfchR9JB/RNaGhW1ffN4AgsdQJ4vLBSdf4i5QNlzMTC7sQ5eFjKCGrAp20cht69eDM94UTmTEizWDTH3tGRNL0Z7qyQUA4p21QY0GCcsMYt/r3XY6OSpbSz9iqu6bByX6u1mZzv/Tbd4C5SyA8hHHuTth6/PqAUhKvkfzg8MhVfGYx2hVTvZlun5jnXJyZXX4tqbzE2hZbpSSdTG2LvvJ9fBCuqeTs9UQTVaRZsp07l4OKReIlHDZrcyt01Gq+HrvWtpnX8JxgBLSMtO88BAfS8sgTQjtE/OC5jcRbrr7b7WYVpwUjeUa5hxgEnMJbcWn3fE2RxWWTQUFJM99UTUuSQm6xygc2u7cBcphdnQdqHyrT+DL6WQHFxGo9wbhXuq4MChvOsilqyWmml3tjUYlfv8CqP88ltb56bFD3Igk1cyaLrIE01sPs7tdfrKQf8t4ljW6cAPSwf16VKKCR5dBx250S5ru76+dqdVk3h2XY3eAp2EjiSSSfFVW+ZyOy22+4b10pZCe1ruqdc6sUE0Y4QzgRGBy6Ek9MjXEijVjc+5X9ALS8ED6N0cgmWaclk/cw8AHQKCcBP3HlnccjK4dQXBOw97YolYSYNJFWljJUpm69TgFfyf2RyWeN2kCHqzRBDS105UOsjfgUf9yf8ubHKFITlyqhvMzl6dCBfUDgQgcMFccnMxXPEZy3g24m/kjyB9WiBI2KBn6SbC4BkiAOqjLB9f/pb1nn/6aILeY+iqirs77ucWkMz/H3Xlk5lCNos57g70r5gCBtjnTbWMFHs1m6X43v9iOsr3I4zPq4/QdEwpXnz9gBLz63n+kR/IT54ugiliYMdFRSyrTNyGd1L2mCczdxk5AapxVVZTQHdl3bMU1/Mu1YjGLh1F/ipug35VvlIfL+Y1Wded3vdFB0DAciG/8m0na6mQyfHYxEurt4Fq4ifkxMOP2NVh5CXOHCSbnHyqTDj5XvMT6fcnEEHE+Z25ALC4GI4kkHsMfoejdINmiJePTYDjCSgSBAoFCCul0HVeTH/VUBMotlf3LPhRuWGWuT3/Tk/yIR0JASSeCc03YUR0lsf1rCZEyWhPc1n1e6Rwlp8fCEa3J/Q7i/pHNXSWE5EJKlU8Jm4VH8J/oetSa+7NKgCeSUFtBcg00zg2YBfuam/dd53LM1FyJYRWV4ONWpL3Mhxi0TuSVb9j3BJL7R56wiMuuq/tVgsNzujhWdezYVo1oZTJrFj6LLdK4DHD51BK3erc62FlSGw7vcHFRVhgE8y6EJFcqKTVBhqJ0Qmr6XgTBA12BKArAjs4QG5/AwrDrImDqrB7udkAutzx2vHQ2ytR",
  "sha1" : "8c44014b96f0f41f3daa3825d4af410233372b65"
},
{
  "device" : "Pixel 5",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA4096",
  "pubk" : "AAAQAJQ75c2T8qdhsNTAlO37M/QNDoIIS7jUkIqOINM+UygqTj8/BVbIih31wOT7oglvXR+3baLR90iAqrTCBhhMrWPw6cdFE5IrpIho+4y7heWCc8VCkR4MBsygEHuseYtB0WJegHnI3YxNOx9HyDo3HuWFkYx8VNlOSNCep6Ce2Xbn1BYjOTIUeWOzee0UY0lLCyriFAf6YkLDmplI1jYBWs4R0TANTJQlMzOThratZXW39IDLuCmlX6r0Wg5ljT25tb767ZG2NHUTQJoLHV95iOyUwuKZa/hvUOmOM0JGVDcVXpzwUX0HN2Q5i4LBulxtQVFrol5yHO1jbK+el76FMhlgZHjEto6peUmZodwLzXybAgbakK3vF8V91DOy0dnkbyHiejzgMhPCCat6wNjhtYs0EMsOtS+WOzxdxFUZMp+gPQrT3f+5HTBkfpTNHdvhiyxZsM+Xqyi4O5OX8LSszWMEviq67OkQawgc9tbsNX6tCc0gH9EiYro/ecOcI/JA5yfJce5gJlIUvavgFzsi9DFQqHcnVevd/C0D6CderCwv5QuGqGfSkt3FJv6ITmFAG7IhYU4Y9A/OkLInZChiQ4nxL+c63K1dVFmNidwQpFwo0+49hvZ9VJ5HsL6px7Z167VAVOkReFjBbqOPYAeq0Xy3wZoCxQapuqxO+VUtR4H5S6xw+ygZzGpXfJJA0BNIdxsOEO3DRlv1lx4Sa6efHYBhodtelrayF19izHpHHRifFMwQgDz1mOU9AcM4cvpqYKIhFaH9d6wRMsBif0L+rT1LJh691bfLR5P5EyPhrb28+1/agYI6EIt83Aaz3d9SnamqAqyGR2E86o8HXGo8x5NAPdp7UM1yt7rOyhNwcG+dVj535XsS2hzHsaUn+PWWanLF/bSuoOYwCbLf22eCmE08uCZW2JHJdzRCwMXy3ZSGbYxOCfaMcaHOpl//4KcHZNBd4j07ODKXiE8rueB/hfMx2NMmxpkeCIf1dxQsFgnC3iHtixgMVRkxuQTAh7ePOu9yEgj17ImTFOVLm1BaBBnd7dDdg7bgiOMloH8+1HvPWerDnz8ghLE044nz73NSsixKvEAm8wAeWbbG8/uOjCsi5opYh1oBgdjUTQEjsu8CApbvjrh8//f8/46n+/SJgBB0AJKY+F9pRk0p2duX2a1R/zbpM4Fa06qjvwRycyGw8A4gdmwFt7189dYjYAukPoQ4qONJn7BXQMFM2EhNLOUyfdz8SmekEL5d9NVG2UB0m9mYdYCbwgPvCZQAsqH3i2pNslx/9GbRS59Q6dSqsDDk2TSFst/2biBiAyl7glFoN/bggoGESxPc3t43Mi/O/ym3l1qd7oQGav7wZL0J8iZ/I575",
  "sha1" : "6908461c2ccd5568d1f39016a9da5aec5b10a785"
},
{
  "device" : "Pixel 5a",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA4096",
  "pubk" : "AAAQAP2EZ6+lhRYjp4cE4WW11okXlC20K5OJWj7iX0bmAGcmPMtWNJt3Jq/w+5ZvfRMa5xy3CMZeJICV1XeD7R/Pwcs9Wadd+DR+Lsai209qJiuMv6R4Y+eF+EacD7NunRpDdaDGnTxdaWJUbYDSFDrwLO1PHBavewd3ujVCmuh1zaQ2CW3Y1lo0UvmO0tISRr4yvR5Ia+zaufQ0TtmlWwX6se7jJ0/ap9Z4wQYJS9R8WDRqV+XX9QUDuOU/w6TI4hB9oYDjiysCtzJe9zibK6jSNq1/3CfOm4GuaCLQEJseoqgsNh25MkTqg4rmmPsk+5Kcylr2gDFRmu4NOJ/sCRIVDXkigrz2WDaB3UaBTN/JZMjuFvxk6LAQSURE4oFuljzfTvnp2bIYbqZ8NUTHuzhEDwelj0eChAkW9hQ85OBTs23lJmAYQxJ+WqYixrB1lpmgz7MUzc/2PJBXLh96FdLJcU2jCzCfrAAepELWsutPfVcE8rOFAdrAF6PPeHUN87pfrbGZx/oj1Nkf0kOic77dqHERqWw//7WngbzHPahjyX33OheZK+xK5tzx2EUX09yXMK84d25UipJuHQ0SsBMM3EmI1b9U2IDEHfhIg5QpJFO5xF1DQyLTu5lG9mAqJcGAjnIt47Jkv3s5i6zBlmXWJJicgnnbDjN7sn/w4LiZY2Uu8ZSwsSobI5EDG5vIdD7NlueFB5zDoqhm19eG2z/QfywOdFlgsfYPDmg1JikeWnpDb3Yy5xPb1ua5TFYItduid0aM+VkoL/KbPt2oVgh4O2uZTFebUHMMCnyGw2zwfjeh4xrD9mD5xWdcjo3KYB1nuv/GtkNEDXpsUxIII4E3ipjfnNHJBz0UPlYnuxDB34KpvHoa/GG8wEWJCDcL0dZX5/KaaiTHwlypWUXnSi3rlm+qcMivO14f8LFmmabMEetiA2YIVqtIXB4MCIYKYr5aF6879LpHA2bFI/LXyGf6pL0tM1CAiQXZwNc+WHC24ujCngT/QD2nRdqWDKuwycG/DtRJVnn+Z5WVD28PZotv/6ODT/4f1OLgM9ufq38Vm2SETZNYCZr4Zcn5bgR7ObqyTnD+vCcpfTDifVp8xPlHT1iY7gdb0gSV8ZIIXpcxUB0kBpM6jO2HJST9hVOBQfMo3V5xjBJYkFwcrCI0bC58zf344C145YuUKchByC5NCkJXHe7YcD9Hut2fIxcZqO08w5XDgJucfS6hMOaspt7XhibxwsE/xF33pgqRz9kFOJ6DnjhGbvbWo3VfNpGdeBfu8vmSpNKI3plaxImWEaK360KHCBVgwqLrhoIgf91FdT6MSO7gGVOHbB+o41UZ8mjE71yrIWA4Opp4/qpVUJhVR0aR6z8d",
  "sha1" : "14e3fd68feb4fe7c9837787ed218d083050574da"
},
{
  "device" : "Pixel 6",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA4096",
  "pubk" : "AAAQAPzSq6nF6uIU7cpTp90ATW+SFDH+L1Rv8NBew/USm5nNdFNhm+HXbWwz6cADn/dtUEd+eksUc6uxisT4EwziErAMbgYyN81+W1ndYFhp4zU1C0YhlS+LnlPxY+rNPmShpFvMIvMCH8GK24tO50FjjTBZrz5kwGfJt0kF7jQwZKQr6e3PMaKYZH11jeAdasEoxwsMjX31U74N8T4r92H8caaLzGJm2qaXn2Nec1HIWwUn7GSigG9yDf6RSzlc6PhKYZvcNG8AmiqghBxuN9HrBc4zo5z2IIm0+W2zxzoPkoRQrKR5LLRoBAifw9zO/xTiiuz/LcDjOesFrdk/vWKH1BJN3bx2etaH7qpqqQo3gjfc//VBZrZu1GelxL1KBNYQ+somh1NGUUKm3WDHtDBzMOrCph4zUyKLU5sqQIzVaqk3mjD4QpLM3nhsuZfheSDEFv38fmX34w0Y34bdogOqM7qsWOAEkxX4SugVrEakxuNoTDaXi765vxnrXcsgyWaalMZpsNra9AJujXATlfvBSRLqd/++B83voe41rnCLJUR3TRIy5PQiE7Zvpv2HZn0ix7EVg0ZRVRKBjubcAVFrtD8pXStqA5v6Jt4sy4g8QKHecgmKj3oad37ubWFDEQIRiEYceAA1xYRwCbMrJoFaBysNUuYp4a68FeZiRqbIg5pxC8LXZ5WfbGOcq4xzXkqk327J/1UxdTLvQT/HKkcefRPbrCh7yEFYSn+XCNCx+w+/GdYyKJ6X3sYPP6Ko4R2O+N7FC7SPfn7qfl9yIOeRcvX6EHaXXMfA4PG8EW7dNZvPXa5Sp1g79w2aFEIRWolj6czvgPfC0fHvflFrd60t1K9WiqxvcQFG5spOUrhqltobGjHo6FS7ohWiX5sE9mJxUZap7AR7avAkAWibFBSyv59uxt4KzXZGqsZJw2vuEWeImXAIc14xSkLLJgeoI0ZIfxqrs+sctno4HMwr7tdzMKpTS8Ni/sJSVplmSzdTJ01V74uDLC7VreL+rjXvYLcBV9363/knhX0Os+O01aTSVwGsYBbKwpEuiqonS4yNs5G2NydQvHoDaXUNAzztMd/UmC4WHZOV+vM/daqXAniafJx3lXi+Zgxw3nl/vU2mgNNek2U1Y5xmefhKjBwVhqmIzZY4Lab6Cobs7sEmXrwOe+578PjnFzzs0MDEaJd6vJExVOe5pLvWhUk4vBFb0eK8JcbY65rXWfOJhm0DKlMd7yIidIQaYK0drCNhCM4Fr33YJmQcFBo2QgLsmESnayMJgmPU/KhK3BwZU0OdUJbsGupzvoJIGdnFrp+0oTxO/X4Mr5ArUmoMSFx+rq6x0sMBJNt/kxvvFKcETHN9oRn15V8pRpDl",
  "sha1" : "85322346680a860c091fa14a64cef1fe4a3ffe31"
},
{
  "device" : "Pixel 6pro",
  "manufacturer" : "google",
  "algorithm" : "SHA256_RSA4096",
  "pubk" : "AAAQAAw4tB+0tXQVo8gxwKDukkqG5UfUBSsSy/Y46e/wBitpPv6EwpFsTzg8Jw+Xlgw1wXDJPk0nWnAWk2CrxI//64nVRiOMYquuL4PlUyB0JHkeDH9+2EH6YsOZABRUHkj8KvKovqFWxjXyS7pGbFTYxrZn2f04A1GfYJK9sG0TvW2CvuJs2/MgflXLie4N8V1hpjiuP5Qsu7xEzh/uJrzWDBKLEdgC8FjkxufHK366KaYqfrUuuX/bgQpO5MfzynFaf+PysG3YR2+JN2rnd4hpgqFt73qILm8EQ6Ls4gWijloA6M+MV4QW+jMtKjKhBCNITPLSjZx/0GgZNN5MS2/7kq4dNgmjBCP5qFL8V1xa+r1sdDG2WA3n5uEnW4WxddHgrTVg0F6owpHyaQ28uyNFRwKbUK5td7rS5RDFOS4f3Qpy9Gp0VAFXVylxUtpzJqU8e4UkgfdXDgOVcZrH80NtGasEKgZjvuvTVxv4WBVsyOqIxwv/rpMKm/zNUXxRLeX57UFRfhHTXi/Oyjz+ImGFeMSuv3vS3tIE1bH89sKDL9u6KshjqClK5Gv0p47XSSMaHzh2WDG7SM4Lf3zuqwOv1v1iN2QECaYeBDRuroMItmpqftP4D09p3SylEnK8DeJ8MHPFJHbjfMCo0S1GIs6maKNycYKr2SBKPGnjFaPpFqPLIXY4IU5bEKur+soemPDVylpRL2wV4UnUdhMgQAaESRTNqln4rIyNUCZRJPROshq5F4R8dX7Iy+XIb1B1ctI/njVNP+87qirrJmol71qnRPRSJ02SXUb48/cAjXVKqb678/9MoTwjW/t0XXDWPWJFnXC/zc0gATFz8oZdLtnizCkjeXZkkM4v916lvcQ2Zha2GXT2ZC11NU/K20rYjgtyRg2RT3MRfgwtwymjGMl3lI4PG4m0DL63foVpBvG6TDnIp2FJXbBoBZLfaSquP1A8Yqr0fcMfRPeWiTCfCiKIaXVN09SAsJA/ZB+VjeC3hX5hO/PMDfYBzgaJFOCfpLCqaEVZi0MKPgFoXcCc+wyIt2aW5LyplUEB7DS4BKnckZM1SP6MJZfBBalEcpbsB0g2koZHBDtC6I0C0F7pEJedATUCG8jHNha8wOTKZf2+I/nvJP7UMER+kjADHuyqr6TFvSbch3H7zOqT+oVPaxTqLA8tQ45cTNjeGPLb4CghfHrvKqDqQDkpF+w0zBLFbrzs0Ab3OKfaF7nhVPn7Qp/g41pF3Xo7pv/HVXwIL6WnbQhyJmQsdxFnVjndzFzkNwoL+it2v/cBXhAFbacm385E44DEZNTSehxgofGn5Y4ShVeVd2t3hC167vpBMsyxf9ilvn0jYeA8CTK7+ec2H0jrCBNyBxY5",
  "sha1" : "5f9cdcb2a3e84c93eb031529eb7b3a05b1887861"
},
{
  "device" : "Xiaomi Phone",
  "manufacturer" : "Mi",
  "algorithm" : "SHA256_RSA2048",
  "pubk" : "AAAIAN3C1onuaVOoEOIIpxRB4slj0xuKT7t2yrvDzvHQhOAlM8vz+rnR//6imJ+ET07/dMvAE893FM5LnFQLNcUJ+FYIGjbYdzFCVSYErfVTq96e37/sxVT86Zuz392q8OBkY4UFzpNdwwzWq6J+0tAsEyu778ECITiPceTJgol7IxzjIljHccK3ffP9dQf1FziB6BBTOQBKj26J2KCqtSmXM3Kk4GeV0wdCMZUUcuWXGrt0UjmrD+xHa8jSj9+YRb7BWe+RfYCXtqrAaree/Q24GAm4nSznDjfSH4T50JiNBkaeOf9YZwQlh67JtFZbueUP5prlQ3eXmubddodnA0LdDkOJooBHvMZAM/73+AWtsf145vMRUdtuvj5Dp9shR+kHaBoB78kQ2vUcrT7eetQynrH1TtwpXzXqAfzHRfv1tw2icvPnjFYV7m3njNcrb05Bx/oMvqKzrx99kCZEWuVm8un3gC/ucW9cXkAB+onTQnfJbeS5XcbEPcZkuQ0b7BepCScYnMrlOMSClYYl8OPNK576YRa2KQxdWEbdukihNIhaZhBN/tqdszA2w2960rO70ektljBVPP6m2jcT5iV0spMiers5KtqZ8cy++Urhvg0mWiuPcnue4L7W59lf9bJVlkaFrBfOHvxMdgmmrHCgZd9278zJrYDgFK17kojwSqqqwCkoFQ==",
  "sha1" : "b2a02f1e56e366d727a1a8e089762fe0b91bbc84"
}
]

```

`bbootimg/src/main/resources/logback.xml`:

```xml
<configuration debug="false">
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="SOME_ERRORS" class="ch.qos.logback.core.FileAppender">
        <file>uiderrors</file>
        <encoder>
            <pattern>%date %level [%thread] %logger{10} [%file:%line] %msg%n</pattern>
        </encoder>
    </appender>

    <logger name="uiderrors" level="DEBUG" additivity="false">
        <appender-ref ref="SOME_ERRORS"/>
    </logger>
    <root level="info">
        <appender-ref ref="STDOUT" />
    </root>
</configuration>

```

`bbootimg/src/test/kotlin/AvbTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import avb.desc.UnknownDescriptor
import avb.desc.HashDescriptor
import org.apache.commons.codec.binary.Hex
import org.junit.Test

import org.junit.Assert.*
import org.slf4j.LoggerFactory
import java.io.ByteArrayInputStream

class AvbTest {
    private val log = LoggerFactory.getLogger(AvbTest::class.java)

    @Test
    fun readDescriptors() {
        //output by "xxd -p <file>"
        val descStr = "000000000000000200000000000000b800000000017b9000736861323536" +
                "000000000000000000000000000000000000000000000000000000000004" +
                "000000200000002000000000000000000000000000000000000000000000" +
                "000000000000000000000000000000000000000000000000000000000000" +
                "000000000000000000000000626f6f7428f6d60b554d9532bd45874ab0cd" +
                "cb2219c4f437c9350f484fa189a881878ab6156408cd763ff119635ec9db" +
                "2a9656e220fa1dc27e26e59bd3d85025b412ffc3"
        val desc = UnknownDescriptor(ByteArrayInputStream(Hex.decodeHex(descStr)))
        val hashdDesc = HashDescriptor(ByteArrayInputStream(Hex.decodeHex(descStr)))
        log.info(desc.toString())
        log.info(hashdDesc.toString())
        val descAnalyzed = desc.analyze()
        assertTrue(descAnalyzed is HashDescriptor)
    }
}

```

`bbootimg/src/test/kotlin/CVEtest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import org.junit.Test
import java.math.BigInteger
import java.util.concurrent.Callable
import java.util.regex.Matcher
import java.util.regex.Pattern

class CVEtest {
    private val printkFormat = """
0xffffff8008cce7ee : "Rescheduling interrupts"
0xffffff8008cce806 : "Function call interrupts"
0xffffff8008cce81f : "CPU stop interrupts"
0xffffff8008cce833 : "CPU stop (for crash dump) interrupts"
0xffffff8008cce858 : "Timer broadcast interrupts"
0xffffff8008cce873 : "IRQ work interrupts"
0xffffff8008cce887 : "CPU wake-up interrupts"
0xffffff8009070140 : "rcu_sched"
0xffffff8009070500 : "rcu_bh"
0xffffff8009070920 : "rcu_preempt"
"""

    private val printkFormatPatch = """
0x0 : "Rescheduling interrupts"
0x0 : "Function call interrupts"
0x0 : "CPU stop interrupts"
0x0 : "Timer broadcast interrupts"
0x0 : "IRQ work interrupts"
0x0 : "CPU wake-up interrupts"
0x0 : "CPU backtrace"
0x0 : "rcu_bh"
0x0 : "rcu_preempt"
0x0 : "rcu_sched"
""".trimIndent()

    @Test
    fun testPocCVE_2017_0630() {
        val printkFormats: String = printkFormatPatch
        val pointerStrings = printkFormats.split("\n").toTypedArray()
        assertNotKernelPointer(object : Callable<String?> {
            var index = 0
            override fun call(): String? {
                while (index < pointerStrings.size) {
                    val line = pointerStrings[index]
                    val pattern = "0x"
                    val startIndex = line.indexOf(pattern)
                    if (startIndex == -1) {
                        index++
                        continue
                    }
                    return line.substring(startIndex + pattern.length)
                }
                return null
            }
        }, null)
    }

    fun assertNotKernelPointer(getPtrFunction: Callable<String?>, deviceToReboot: String?) {
        var ptr: String? = null
        for (i in 0..3) { // ~0.4% chance of false positive
            ptr = getPtrFunction.call()
            if (ptr == null) {
                return
            }
            if (!isKptr(ptr)) {
                // quit early because the ptr is likely hashed or zeroed.
                return
            }
        }
        throw IllegalArgumentException("\"$ptr\" is an exposed kernel pointer.")
    }

    private fun isKptr(ptr: String): Boolean {
        val RADIX_HEX = 16
        val m: Matcher = Pattern.compile("[0-9a-fA-F]*").matcher(ptr)
        if (!m.find() || m.start() != 0) {
            // ptr string is malformed
            return false
        }
        val length: Int = m.end()
        if (length == 8) {
            // 32-bit pointer
            val address = BigInteger(ptr.substring(0, length), RADIX_HEX)
            // 32-bit kernel memory range: 0xC0000000 -> 0xffffffff
            // 0x3fffffff bytes = 1GB /  0xffffffff = 4 GB
            // 1 in 4 collision for hashed pointers
            return address >= BigInteger("C0000000", RADIX_HEX)
        } else if (length == 16) {
            // 64-bit pointer
            val address = BigInteger(ptr.substring(0, length), RADIX_HEX)
            // 64-bit kernel memory range: 0x8000000000000000 -> 0xffffffffffffffff
            // 48-bit implementation: 0xffff800000000000; 1 in 131,072 collision
            // 56-bit implementation: 0xff80000000000000; 1 in 512 collision
            // 64-bit implementation: 0x8000000000000000; 1 in 2 collision
            return address >= BigInteger("ff80000000000000", RADIX_HEX)
        }
        return false
    }
}
```

`bbootimg/src/test/kotlin/EnvironmentVerifierTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import cfig.utils.EnvironmentVerifier
import org.junit.Test

class EnvironmentVerifierTest {
    private val envv = EnvironmentVerifier()

    @Test
    fun getHasLz4() {
        val hasLz4 = envv.hasLz4
        println("hasLz4 = $hasLz4")
    }

    @Test
    fun getHasDtc() {
        val hasDtc = envv.hasDtc
        println("hasDtc = $hasDtc")

    }

    @Test
    fun getHasXz() {
        val hasXz = envv.hasXz
        println("hasXz = $hasXz")
    }

    @Test
    fun getGzip() {
        val h = envv.hasGzip
        println("hasGzip = $h")
    }
}

```

`bbootimg/src/test/kotlin/KeyUtilTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import avb.alg.Algorithms
import cfig.helper.CryptoHelper
import cfig.helper.Helper
import com.google.common.math.BigIntegerMath
import org.bouncycastle.jce.provider.BouncyCastleProvider
import org.junit.Assert.assertEquals
import org.junit.Test
import java.io.File
import java.math.BigInteger
import java.math.RoundingMode
import java.nio.file.Files
import java.nio.file.Paths
import java.security.*
import java.security.spec.PKCS8EncodedKeySpec
import java.security.spec.X509EncodedKeySpec
import javax.crypto.Cipher

class KeyUtilTest {
    @Test
    fun parseKeys() {
        val keyFile = "../" + Algorithms.get("SHA256_RSA2048")!!.defaultKey
        println("Key: $keyFile")
        val pk8File = keyFile.replace("pem", "pk8")
        val k3 = CryptoHelper.KeyBox.parse4(File(pk8File).readBytes())
        //println((k3.key as RSAPrivateKey).privateExponent)
        //println((k3.key as RSAPrivateKey).modulus)
        println("Key: $pk8File")
        val k2 = CryptoHelper.KeyBox.parse4(File(keyFile).readBytes()).key as org.bouncycastle.asn1.pkcs.RSAPrivateKey
        //println(k2.privateExponent)
        //println(k2.modulus)
        //KeyHelper2.parseRsaPk8(FileInputStream(keyFile).readAllBytes())
    }

    @Test
    fun x1() {
        val p = BigInteger.valueOf(61L)
        val q = BigInteger.valueOf(53L)
        val modulus = p * q
        println(modulus)
        val exponent = 17
        val x = calcPrivateKey(p, q, exponent)
        println(x)
        //private key: modulus, x
        //public key: modulus, exponent

        val data = 123L
        val encryptedData = enc(data, exponent, modulus)
        println("enc2 = " + encryptedData)
        val decryptedData = dec(encryptedData, x, modulus)
        println("dec2 data = " + decryptedData)
    }

    fun calcPrivateKey(p: BigInteger, q: BigInteger, exponent: Int): Int {
        val modulus = p * q
        val phi = (p - BigInteger.ONE) * (q - BigInteger.ONE)
        return BigInteger.valueOf(exponent.toLong()).modInverse(phi).toInt()
    }

    //data^{exp}
    fun enc(data: Long, exponent: Int, modulus: BigInteger): Long {
        return BigInteger.valueOf(data).pow(exponent).rem(modulus).toLong()
    }

    //data^{privateKey}
    fun dec(data: Long, privateKey: Int, modulus: BigInteger): Long {
        return BigInteger.valueOf(data).pow(privateKey).rem(modulus).toLong()
    }

    @Test
    fun rawSignTest() {
        val data =
            Helper.fromHexString("0001ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff003031300d0609608648016503040201050004206317a4c8d86accc8258c1ac23ef0ebd18bc33010d7afb43b241802646360b4ab")
        val expectedSig =
            "28e17bc57406650ed78785fd558e7c1861cc4014c900d72b61c03cdbab1039e713b5bb19b556d04d276b46aae9b8a3999ccbac533a1cce00f83cfb83e2beb35ed7329f71ffec04fc2839a9b44e50abd66ea6c3d3bea6705e93e9139ecd0331170db18eba36a85a78bc49a5447260a30ed19d956cb2f8a71f6b19e57fdca43e052d1bb7840bf4c3efb47111f4d77764236d2e013fbf3b2577e4a3e01c9d166a5e890ef96210882e6e88ceca2fe3a2201f4961210d4ec6167f5dfd0e038e4a146f960caecab7d15ba65f6edcf5dbd25f5af543cfb8da4338bdbc872eec3f8e72aa8db679099e70952d3f7176c0b9111bf20ad1390eab1d09a859105816fdf92fbb"
        val privkFile = "../" + Algorithms.get("SHA256_RSA2048")!!.defaultKey.replace("pem", "pk8")
        val k = CryptoHelper.KeyBox.parse4(Files.readAllBytes(Paths.get(privkFile))).key as PrivateKey
        val encData = CryptoHelper.Signer.rawRsa(k, data)
        assertEquals(expectedSig, Helper.toHexString(encData))
    }

    @Test
    fun rawSignOpenSslTest() {
        val data =
            Helper.fromHexString("0001ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff003031300d0609608648016503040201050004206317a4c8d86accc8258c1ac23ef0ebd18bc33010d7afb43b241802646360b4ab")
        val expectedSig =
            "28e17bc57406650ed78785fd558e7c1861cc4014c900d72b61c03cdbab1039e713b5bb19b556d04d276b46aae9b8a3999ccbac533a1cce00f83cfb83e2beb35ed7329f71ffec04fc2839a9b44e50abd66ea6c3d3bea6705e93e9139ecd0331170db18eba36a85a78bc49a5447260a30ed19d956cb2f8a71f6b19e57fdca43e052d1bb7840bf4c3efb47111f4d77764236d2e013fbf3b2577e4a3e01c9d166a5e890ef96210882e6e88ceca2fe3a2201f4961210d4ec6167f5dfd0e038e4a146f960caecab7d15ba65f6edcf5dbd25f5af543cfb8da4338bdbc872eec3f8e72aa8db679099e70952d3f7176c0b9111bf20ad1390eab1d09a859105816fdf92fbb"
        val sig = CryptoHelper.Signer.rawSignOpenSsl("../" + Algorithms.get("SHA256_RSA2048")!!.defaultKey, data)
        assertEquals(expectedSig, Helper.toHexString(sig))
    }

    @Test
    fun test3() {
        val data =
            Helper.fromHexString("0001ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff003031300d0609608648016503040201050004206317a4c8d86accc8258c1ac23ef0ebd18bc3301033")
        val signature = Signature.getInstance("NONEwithRSA")
        val keyFile = "../" + Algorithms.get("SHA256_RSA2048")!!.defaultKey.replace("pem", "pk8")
        val k = CryptoHelper.KeyBox.parse4(Files.readAllBytes(Paths.get(keyFile))).key as PrivateKey
        signature.initSign(k)
        signature.update(data)
        println("data size " + data.size)
        println(signature.provider)
        val sig = signature.sign()
        println(sig)
    }

    @Test
    fun testCipher() {
        Security.addProvider(BouncyCastleProvider())
        for (p in Security.getProviders()) {
            println(p.toString())
            for (entry in p.entries) {
                println("\t" + entry.key.toString() + "   ->   " + entry.value)
            }
            println()
        }
    }

    @Test
    fun testKeys() {
        val kp = KeyPairGenerator.getInstance("rsa")
            .apply { this.initialize(2048) }
            .generateKeyPair()
        val pk8Spec = PKCS8EncodedKeySpec(kp.private.encoded) //kp.private.format == PKCS#8
        val x509Spec = X509EncodedKeySpec(kp.public.encoded) //kp.public.format == X.509

        val kf = KeyFactory.getInstance("rsa")
        val privk = kf.generatePrivate(pk8Spec)
        val pubk = kf.generatePublic(x509Spec)
        println(pubk)

        val cipher = Cipher.getInstance("RSA").apply {
            this.init(Cipher.ENCRYPT_MODE, privk)
            this.update("Good".toByteArray())
        }
        val encryptedText = Helper.toHexString(cipher.doFinal())
        println(encryptedText)
    }

    @Test
    fun testRSA() {
//        val r = BigIntegerMath.log2(BigInteger.valueOf(1024), RoundingMode.CEILING)
//        println(r)
//        println(BigInteger.valueOf(1024).mod(BigInteger.valueOf(2)))

        val p = BigInteger.valueOf(3)
        val q = BigInteger.valueOf(7)
        val modulus = p.multiply(q)

        val keyLength = BigIntegerMath.log2(modulus, RoundingMode.CEILING)
        println("keyLength = $keyLength")

        //r = phi(n) = phi(p) * phi(q) = (p - 1)*(q - 1)
        val r = (p.subtract(BigInteger.ONE)).multiply(q - BigInteger.ONE)

        //r ~ e
        //e is released as the public key exponent
        //most commonly e = 2^16 + 1 = 65,537
        val e = BigInteger.valueOf(5)

        //(d * e).mod(r) == 1
        //d is kept as the private key exponent
        val d = e.modInverse(r)

        println("p = $p, q = $q, modulus = $modulus , r = $r, e = $e, d = $d")
        assertEquals(1, d.multiply(e).mod(r).toInt())
        //private key: (modulus, d), d is calculated
        //pub key: (modulus, e) , e is chosen

        val clearMsg = BigInteger.valueOf(10)
        val encMsg = clearMsg.pow(e.toInt()).mod(modulus)
        println("clear: $clearMsg, enc: $encMsg")
    }

    @Test
    fun listAll() {
        CryptoHelper.listAll()
    }

    @Test
    fun signData() {
        val data = KeyUtilTest::class.java.classLoader.getResourceAsStream("data").readAllBytes()
        println(Helper.toHexString(data))
        //@formatter:off
        val keyData = KeyUtilTest::class.java.classLoader.getResourceAsStream("testkey.pk8").readAllBytes()
        val privKey = CryptoHelper.KeyBox.parse4(keyData).key as PrivateKey
        //@formatter:on
        println("sha256=" + Helper.toHexString(CryptoHelper.Hasher.sha256(data)))
        val signedHash = CryptoHelper.Signer.sha256rsa(data, privKey)
        println("Signed Hash: " + Helper.toHexString(signedHash))
    }
}


```

`bbootimg/src/test/kotlin/ReadTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import org.junit.Test
import java.io.File
import java.util.regex.Matcher
import java.util.regex.Pattern

class ReadTest {
    data class Trigger(
            var trigger: String = "",
            var actions: MutableList<String> = mutableListOf()
    )

    data class Import(
            var initrc: String = ""
    )

    data class Service(
            var name: String = "",
            var cmd: String = "",
            var theClass: String = "default",
            var theUser: String? = null,
            var theGroup: String? = null,
            var theSeclabel: String? = null,
            var theMiscAttr: MutableList<String> = mutableListOf(),
            var theCaps: MutableList<String> = mutableListOf(),
            var theSocket: String? = null,
            var theWritePid: String? = null,
            var theKeycodes: String? = null,
            var thePriority: Int? = null,
            var theIOPriority: String? = null,
            var theOnRestart: MutableList<String> = mutableListOf()
    )

    fun parseConfig(inRootDir: String, inPath: String,
                    triggers: MutableList<Trigger>,
                    services: MutableList<Service>) {
        if (!File(inRootDir + inPath).exists()) {
            println("Parsing " + inPath + " fail: 404");
        }
        if (File(inRootDir + inPath).isFile()) {
            parseConfigFile(inRootDir, inPath, triggers, services)
        } else if (File(inRootDir + inPath).isDirectory()) {
            parseConfigDir(inRootDir, inPath, triggers, services)
        }
    }

    fun parseConfigDir(inRootDir: String, inPath: String,
                       triggers: MutableList<Trigger>,
                       services: MutableList<Service>) {
        println("Parsing directory $inPath ...")
        File(inRootDir + inPath).listFiles().forEach {
            parseConfig(inRootDir,
                    it.path.substring(inRootDir.length - 1),
                    triggers, services)
        }
    }

    fun parseConfigFile(inRootDir: String, inPath: String,
                        triggers: MutableList<Trigger>,
                        services: MutableList<Service>) {
        if (!File(inRootDir + inPath).exists()) {
            println("Parsing $inPath fail: 404")
            return
        }
        println("Parsing file $inPath ...")
        var imports: MutableList<Import> = mutableListOf()
        var aTrigger: Trigger? = null
        var aService: Service? = null
        var aImport: Import? = null
        var toBeContinued = false
        val lines = File(inRootDir + inPath).readLines()
        for (item in lines) {
            val line = item.trim();
            //comment
            if (line.startsWith("#") || line.isEmpty()) {
                continue
            }
            //continue
            if (toBeContinued) {
                if (line.endsWith("\\")) {
                    aService!!.cmd += " "
                    aService!!.cmd += line.substring(0, line.length - 1)
                    println("    CONTINUE:" + line.substring(0, line.length - 1))
                } else {
                    toBeContinued = false
                    aService!!.cmd += " "
                    aService!!.cmd += line
                    println("    END     :$line")
                }
                continue
            }

            val finderOn = Pattern.compile("^(on)\\s+(\\S+.*$)").matcher(line)
            val finderService = Pattern.compile("^service\\s+(\\S+)\\s+(.*$)").matcher(line)
            val finderImport = Pattern.compile("^import\\s+(\\S+)$").matcher(line)
            if (finderOn.matches() || finderService.matches() || finderImport.matches()) {
                //flush start >>
                aTrigger?.let { /* println("[add] " + aTrigger); */ triggers.add(aTrigger!!); aTrigger = null }
                aService?.let { /* println("[add] " + aService); */ services.add(aService!!); aService = null }
                aImport?.let { /* println("[add] " + aImport); */ imports.add(aImport!!); aImport = null }
                // << flush end
            }
            finderOn.reset()
            finderService.reset()
            finderImport.reset()

            if (finderOn.find()) {
                //println("  |on| " + line)
                //println("  group.cnt = " + finderOn.groupCount())
                //println("  " + line.substring(finderOn.start(), finderOn.end()))
                //println("  >" + finderOn.group(1))
                //println("  >" + finderOn.group(2))
                aTrigger = Trigger(trigger = finderOn.group(2))
            } else if (finderService.find()) {
                aService = Service()
                aService!!.name = finderService.group(1)
                aService!!.cmd = finderService.group(2)
                if (finderService.group(2).endsWith("\\")) { //remove trailing slash
                    toBeContinued = true
                    aService!!.cmd = aService!!.cmd.substring(0, aService!!.cmd.length - 1)
                }
            } else if (finderImport.find()) {
                aImport = Import()
                aImport!!.initrc = finderImport.group(1)
                if (aImport!!.initrc.startsWith("/")) {
                    aImport!!.initrc = aImport!!.initrc.substring(1)
                } else {
                    //do nothing
                }
                val ro_hardware = "\${ro.hardware}"
                val ro_zygote = "\${ro.zygote}"
                aImport!!.initrc = aImport!!.initrc.replace(ro_hardware, "sequoia")
                aImport!!.initrc = aImport!!.initrc.replace(ro_zygote, "zygote32")
            } else {
                if (aTrigger != null) {
                    aTrigger!!.actions.add(line)
                } else if (aService != null) {
                    //class
                    var bParsed = false
                    lateinit var mm: Matcher
                    if (!bParsed) {
                        mm = Pattern.compile("^class\\s+(.*)").matcher(line)
                        if (mm.matches()) {
                            aService!!.theClass = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //user
                        mm = Pattern.compile("^user\\s+(.*)").matcher(line)
                        if (mm.matches()) {
                            aService!!.theUser = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //capabilities
                        mm = Pattern.compile("^capabilities\\s+(.*)").matcher(line)
                        if (mm.matches()) {
                            aService!!.theCaps.add(mm.group(1))
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //group
                        mm = Pattern.compile("^group\\s+(.*)").matcher(line)
                        if (mm.matches()) {
                            aService!!.theGroup = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //seclabel
                        mm = Pattern.compile("^seclabel\\s+(.*)").matcher(line)
                        if (mm.matches()) {
                            aService!!.theSeclabel = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //writepid
                        mm = Pattern.compile("^writepid\\s+(.*)$").matcher(line)
                        if (mm.matches()) {
                            aService!!.theWritePid = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //onrestart
                        mm = Pattern.compile("^onrestart\\s+(.*)$").matcher(line)
                        if (mm.matches()) {
                            aService!!.theOnRestart.add(mm.group(1))
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //socket
                        mm = Pattern.compile("^socket\\s+(.*)$").matcher(line)
                        if (mm.matches()) {
                            aService!!.theSocket = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //ioprio
                        mm = Pattern.compile("^ioprio\\s+(.*)$").matcher(line)
                        if (mm.matches()) {
                            aService!!.theIOPriority = mm.group(1)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //priority
                        mm = Pattern.compile("^priority\\s+(\\S+)$").matcher(line)
                        if (mm.matches()) {
                            aService!!.thePriority = Integer.parseInt(mm.group(1))
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        //check space
                        mm = Pattern.compile("^\\S+$").matcher(line)
                        if (mm.matches()) {
                            aService!!.theMiscAttr.add(line)
                            bParsed = true
                        }
                    }
                    if (!bParsed) {
                        println("<< Dangling << $line")
                    }
                } else {
                    println("<< Dangling << $line")
                }
            }
        }

        //flush start >>
        aTrigger?.let { /* println("[add] " + aTrigger); */ triggers.add(aTrigger!!); aTrigger = null }
        aService?.let { /* println("[add] " + aService); */ services.add(aService!!); aService = null }
        aImport?.let { /* println("[add] " + aImport); */ imports.add(aImport!!); aImport = null }
        // << flush end

        imports.forEach { println(it) }

        //parse imports again
        val iteratorImport: Iterator<Import> = imports.iterator()
        while (iteratorImport.hasNext()) {
            val item: Import = iteratorImport.next()
            parseConfigFile(inRootDir, item.initrc, triggers, services)
        }
        println("Parsing file $inPath done")
    }

    fun queueEventTrigger(inServices: MutableList<Service>,
                          inTriggers: List<Trigger>, inTriggerName: String,
                          inIndent: String = "") {
        val aPre = inIndent
        inTriggers.filter { it.trigger == inTriggerName }.forEach { aTrigger ->
            println(aPre + " (on+${aTrigger.trigger})")
            aTrigger.actions.forEach { aAction ->
                aAction.executeCmd(inServices, inTriggers, aPre + "  ")
            }
        }
    }

    fun String.executeCmd(inServices: MutableList<Service>,
                          inTriggers: List<Trigger>, inIndent: String) {
        val aPre = "$inIndent  "
        if (this.startsWith("trigger ")) {
            println("$aPre|-- $this")
            queueEventTrigger(inServices, inTriggers, this.substring(8).trim(), aPre + "|  ")
        } else if (this.startsWith("chmod")) {
            //ignore
        } else if (this.startsWith("chown")) {
            //ignore
        } else if (this.startsWith("mkdir")) {
            //ignore
        } else if (this.startsWith("write")) {
            //ignore
        } else if (Pattern.compile("class_start\\s+\\S+").matcher(this).find()) {
            println("$aPre|-- $this")
            val m = Pattern.compile("class_start\\s+(\\S+)$").matcher(this)
            if (m.find()) {
                inServices
                        .filter {
                            it.theClass.split(" ").contains(m.group(1))
                        }
                        .forEach {
                            println(aPre + "|    \\-- Starting " + it.name + "...")
                        }
            } else {
                println("error")
            }
        } else if (this.startsWith("start")) {
            println("$aPre|-- $this")
            println("""$aPre|    \-- Starting ${this.substring(5).trim()}...""")
        } else {
            println("$aPre|-- $this")
        }
    }

    @Test
    fun parseTest() {
        System.out.println(System.getProperty("user.dir"))
        val gTriggers: MutableList<Trigger> = mutableListOf()
        val gServices: MutableList<Service> = mutableListOf()

        parseConfig("__temp/", "/init.rc", gTriggers, gServices)
        parseConfig("__temp/", "/system/etc/init", gTriggers, gServices)
        parseConfig("__temp/", "/vendor/etc/init", gTriggers, gServices)
        parseConfig("__temp/", "/odm/etc/init", gTriggers, gServices)

        gTriggers.forEach { println(it) }
        gServices.forEach { println(it) }

        println("Trigger count:" + gTriggers.size)
        println("Service count:" + gServices.size)

        queueEventTrigger(gServices, gTriggers, "early-init")
        queueEventTrigger(gServices, gTriggers, "init")
        queueEventTrigger(gServices, gTriggers, "late-init")
//        println(">> mount_all() returned 0, trigger nonencrypted")
//        queueEventTrigger(gServices, gTriggers, "nonencrypted")
    }
}
```

`bbootimg/src/test/kotlin/avb/BlobTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb

import avb.alg.Algorithms
import avb.blob.AuxBlob
import cfig.helper.CryptoHelper
import cfig.helper.Helper
import org.apache.commons.codec.binary.Hex
import org.bouncycastle.asn1.pkcs.RSAPrivateKey
import org.junit.Assert.assertEquals
import org.junit.Test

class BlobTest {
    @Test
    fun testEncodedKey2048() {
        val keyStr =
            "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"
        val encodedKey = AuxBlob.encodePubKey(Algorithms.get("SHA512_RSA2048")!!, Helper.fromHexString(keyStr))
        val expectedKeyEnc =
            "00000800c9d87d7bc65551dd3224a2e00ebc7efdbda2538058697ef54a4087959054593d55caff36341afae1e0902a1a32685bf3dfad0bf9b1d0f7eaab471f76be1b984b67a362fadfe6b5f8ee73165fb8b182de4989d53dd7a842998175c8d8847bbd54a8226444bc3406103c89c2d1f32c036591b1a0d1c82156159948202774ef017a76a50b6bfde3faed0df90f7a41fa76053749fe344f4b0149e498f7898ecd36aa391da97d5d6b5a52d17569a8df7cde1c1bf9d9195bb7474cb9702eade5d6887ced926e460810b576033e09ac4db62ccd1200bdd4a703d31b910823365b11feaf5969b33c8824372d61bac599511897f92342969f872ecdb24d5fa924f245dae26526264d1efa3b53abc5d379532f66b82194669a936f3526438c8f96b9ffaccdf4006ebeb673548450854653d5dd43feb26a784079569f86f3d3813b3d409035329a517ff8c34bc7d6a1ca30fb1bfd270ab8644134c117dea1769aebcf0c50d913f50d0b2c9924cbb5b4f8c60ad026b15bfd4d44669db076aa799dc05c3b9436c18ffec9d25a6aa046e1a28b2f516151a3369183b4fbcda9403446988a1a91dfd92c3abf573a464620f2f0bc315e29fe5890325c6697999a8e1523eba947d363c618bb8ed2209f78af71b32e0889a1f17db130a0e61bbd6ec8f633e1dab0bd1641fe076f6e978b6a33d2d780036a4de70582281fef6aa9757ee14ee2955b4fe6dc03b981"
        assertEquals(expectedKeyEnc, Helper.toHexString(encodedKey))
        run {//decode pub key and check
            val decodedKey = CryptoHelper.KeyBox.decodeRSAkey(encodedKey)
            val rsa = CryptoHelper.KeyBox.parse4(Helper.fromHexString(keyStr)).key as RSAPrivateKey //BC RSA
            assert(rsa.modulus.equals(decodedKey.modulus))
            assert(rsa.publicExponent.equals(decodedKey.publicExponent))
        }
    }

    @Test
    fun testEncodeKey4096() {
        val keyStr =
            "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"
        val encodedKey = AuxBlob.encodePubKey(Algorithms.get("SHA256_RSA4096")!!, Hex.decodeHex(keyStr))
        val expectedKeyEnc =
            "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"
        assertEquals(expectedKeyEnc, Hex.encodeHexString(encodedKey))
    }

    @Test
    fun testEncodeKey8192() {
        val keyStr =
            "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"
        val encodedKey = AuxBlob.encodePubKey(Algorithms.get("SHA256_RSA8192")!!, Hex.decodeHex(keyStr))
        val expectedKeyEnc =
            "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"
        assertEquals(expectedKeyEnc, Hex.encodeHexString(encodedKey))
    }
}

```

`bbootimg/src/test/kotlin/avb/FooterTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb

import avb.blob.Footer
import org.apache.commons.codec.binary.Hex
import org.junit.Assert.assertEquals
import org.junit.Test
import java.io.ByteArrayInputStream

class FooterTest {
    @Test
    fun readAVBfooter() {
        val footerBytes = this.javaClass.classLoader.getResourceAsStream("taimen.avbfooter").readBytes()
        ByteArrayInputStream(footerBytes).use {
            it.skip(footerBytes.size - 64L)
            val footer = Footer(it)
            println(footer.toString())
            assertEquals(1, footer.versionMajor)
            assertEquals(0, footer.versionMinor)
            assertEquals(512, footer.vbMetaSize)
            assertEquals(28983296, footer.vbMetaOffset)
            assertEquals(28983296, footer.originalImageSize)
        }
    }

    @Test
    fun readInvalidFooterShouldFail() {
        val vbmetaHeaderStr = "4156423000000001000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000c8000000000000000000000000000000c80000000000000000000000000000000000000000000000c800000000000000000000000000000000617662746f6f6c20312e312e3000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"
        ByteArrayInputStream(Hex.decodeHex(vbmetaHeaderStr)).use {
            try {
                Footer(it)
                assertEquals("Should never reach here", true, false)
            } catch (e: IllegalArgumentException) {
                //expected
            }
        }
    }
}

```

`bbootimg/src/test/kotlin/avb/HeaderTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb

import avb.blob.Header
import org.apache.commons.codec.binary.Hex
import org.junit.Test
import java.io.ByteArrayInputStream

class HeaderTest {

    @Test
    fun readHeader() {
        val vbmetaHeaderStr = "4156423000000001000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000c8000000000000000000000000000000c80000000000000000000000000000000000000000000000c800000000000000000000000000000000617662746f6f6c20312e312e3000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"
        val header2 = Header(ByteArrayInputStream(Hex.decodeHex(vbmetaHeaderStr)))
        println(header2.toString())
    }
}

```

`bbootimg/src/test/kotlin/avb/alg/AlgorithmsTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.alg

import cfig.helper.Helper
import org.junit.Assert
import org.junit.Test

class AlgorithmsTest {
    @Test
    fun test1() {
        Assert.assertEquals(
            Helper.toHexString(Algorithms.get("SHA256_RSA4096")!!.padding),
            "0001ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff003031300d060960864801650304020105000420"
        )
        println(Algorithms.get("NONE")!!)
    }
}

```

`bbootimg/src/test/kotlin/avb/desc/HashDescriptorTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import org.apache.commons.codec.binary.Hex
import org.junit.Assert
import org.junit.Test
import org.slf4j.LoggerFactory
import java.io.ByteArrayInputStream

class HashDescriptorTest {
    private val log = LoggerFactory.getLogger(HashDescriptorTest::class.java)

    @Test
    fun parseHashDescriptor() {
        val descStr = "000000000000000200000000000000b80000000001ba4000736861323536000000000000000000000000000000000000000000000000000000000004000000200000002000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000626f6f74fbfb8e13c8082e0a16582163ad5075668903cc1237c6c007fed69de05957432103ae125531271eeeb83662cbe21543e3025f2d65268fb6b53c8718a90e3b03c7"
        val desc = HashDescriptor(ByteArrayInputStream(Hex.decodeHex(descStr)))
        log.info(desc.toString())
        Assert.assertEquals(descStr, Hex.encodeHexString(desc.encode()))
    }
}

```

`bbootimg/src/test/kotlin/avb/desc/HashTreeDescriptorTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import cfig.helper.CryptoHelper
import com.fasterxml.jackson.databind.ObjectMapper
import org.apache.commons.codec.binary.Hex
import org.junit.Assert.assertEquals
import org.junit.Test
import java.io.ByteArrayInputStream
import java.security.MessageDigest

class HashTreeDescriptorTest {

    @Test
    fun encode() {
        val treeStr1 =
            "000000000000000100000000000000e000000001000000009d787000000000009d78700000000000013d9000000010000000100000000002000000009eb60000000000000141400073686131000000000000000000000000000000000000000000000000000000000000000600000020000000140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000073797374656d28f6d60b554d9532bd45874ab0cdcb2219c4f437c9350f484fa189a881878ab609c2b0ad5852fc0f4a2d03ef9d2be5372e2bd1390000"
        val treeStr2 =
            "000000000000000100000000000000e000000001000000001ec09000000000001ec0900000000000003e2000000010000000100000000002000000001efeb00000000000003ec00073686131000000000000000000000000000000000000000000000000000000000000000600000020000000140000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000076656e646f7228f6d60b554d9532bd45874ab0cdcb2219c4f437c9350f484fa189a881878ab698cea1ea79a3fa7277255355d42f19af3378b0110000"

        val tree1 = HashTreeDescriptor(ByteArrayInputStream(Hex.decodeHex(treeStr1)), 0)
        println(ObjectMapper().writerWithDefaultPrettyPrinter().writeValueAsString(tree1))
        assertEquals(treeStr1, Hex.encodeHexString(tree1.encode()))

        val reDecoded = HashTreeDescriptor(ByteArrayInputStream(tree1.encode()), 0)
        println(ObjectMapper().writerWithDefaultPrettyPrinter().writeValueAsString(reDecoded))

        val tree2 = HashTreeDescriptor(ByteArrayInputStream(Hex.decodeHex(treeStr2)), 0)
        println(ObjectMapper().writerWithDefaultPrettyPrinter().writeValueAsString(tree2))
        assertEquals(treeStr2, Hex.encodeHexString(tree2.encode()))
    }

    @Test
    fun x1() {
        HashTreeDescriptor.calcMerkleTree(120721408, 4096, 32)
        println(MessageDigest.getInstance(CryptoHelper.Hasher.pyAlg2java("sha1")).digest().size)
        println(MessageDigest.getInstance(CryptoHelper.Hasher.pyAlg2java("sha256")).digest().size)
    }
}

```

`bbootimg/src/test/kotlin/avb/desc/KernelCmdlineDescriptorTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import org.apache.commons.codec.binary.Hex
import org.junit.Assert.assertEquals
import org.junit.Test
import java.io.ByteArrayInputStream

class KernelCmdlineDescriptorTest {
    @Test
    fun encode() {
        val cmdStr1 = "000000000000000300000000000001a8000000010000019b646d3d22312076726f6f74206e6f6e6520726f20312c3020353135393939322076657269747920312050415254555549443d2428414e44524f49445f53595354454d5f5041525455554944292050415254555549443d2428414e44524f49445f53595354454d5f504152545555494429203430393620343039362036343439393920363434393939207368613120303963326230616435383532666330663461326430336566396432626535333732653262643133392032386636643630623535346439353332626434353837346162306364636232323139633466343337633933353066343834666131383961383831383738616236203130202428414e44524f49445f5645524954595f4d4f4445292069676e6f72655f7a65726f5f626c6f636b73207573655f6665635f66726f6d5f6465766963652050415254555549443d2428414e44524f49445f53595354454d5f504152545555494429206665635f726f6f74732032206665635f626c6f636b7320363530303830206665635f7374617274203635303038302220726f6f743d2f6465762f646d2d300000000000"
        val cmdStr2 = "000000000000000300000000000000300000000200000028726f6f743d50415254555549443d2428414e44524f49445f53595354454d5f504152545555494429"
        val cmd1 = KernelCmdlineDescriptor(ByteArrayInputStream(Hex.decodeHex(cmdStr1)), 0)
        assertEquals(cmdStr1, Hex.encodeHexString(cmd1.encode()))

        val cmd2 = KernelCmdlineDescriptor(ByteArrayInputStream(Hex.decodeHex(cmdStr2)), 0)
        assertEquals(cmdStr2, Hex.encodeHexString(cmd2.encode()))
    }
}

```

`bbootimg/src/test/kotlin/avb/desc/UnknownDescriptorTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package avb.desc

import org.apache.commons.codec.binary.Hex
import org.junit.Test

import org.slf4j.LoggerFactory
import java.io.ByteArrayInputStream

class UnknownDescriptorTest {
    private val log = LoggerFactory.getLogger(UnknownDescriptorTest::class.java)

    @Test
    fun readDescriptors() {
        //output by "xxd -p <file>"
        val descStr = "000000000000000200000000000000b800000000017b9000736861323536" +
                "000000000000000000000000000000000000000000000000000000000004" +
                "000000200000002000000000000000000000000000000000000000000000" +
                "000000000000000000000000000000000000000000000000000000000000" +
                "000000000000000000000000626f6f7428f6d60b554d9532bd45874ab0cd" +
                "cb2219c4f437c9350f484fa189a881878ab6156408cd763ff119635ec9db" +
                "2a9656e220fa1dc27e26e59bd3d85025b412ffc3"
        val descBA = Hex.decodeHex(descStr + descStr)
        val descList = UnknownDescriptor.parseDescriptors(ByteArrayInputStream(descBA), descBA.size.toLong())
        descList.forEach{
            log.info(it.toString())
        }
    }
}

```

`bbootimg/src/test/kotlin/bootimg/AndroidCpioEntryTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package bootimg

import cfig.bootimg.cpio.AndroidCpio
import cfig.bootimg.cpio.AndroidCpioEntry
import cfig.helper.Helper
import org.junit.Assert.assertTrue
import org.junit.Test
import java.io.File

class AndroidCpioEntryTest {
    @Test
    fun dirEntry() {
        run {//dir, fileMode 040755
            val entry1 = AndroidCpioEntry(name = "acct", statMode = 0x41ed, data = byteArrayOf(), ino = 300000)
            val exp =
                Helper.fromHexString("3037303730313030303439336530303030303431656430303030303030303030303030303030303030303030303130303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030353030303030303030616363740000")
            assertTrue(entry1.encode().contentEquals(exp))
            assertTrue(entry1.encode2().contentEquals(exp))
        }

        run {//dir, fileMode 040755
            val entry2 = AndroidCpioEntry(name = "apex", statMode = 0x41ed, data = byteArrayOf(), ino = 300001)
            val exp2 =
                Helper.fromHexString("3037303730313030303439336531303030303431656430303030303030303030303030303030303030303030303130303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030303030353030303030303030617065780000")
            assertTrue(entry2.encode().contentEquals(exp2))
            assertTrue(entry2.encode2().contentEquals(exp2))
        }
    }

    @Test
    fun linkEntry() {
        run {//link, fileMode 0120777
            val entry3 =
                AndroidCpioEntry(name = "bin", statMode = 0xa1a4, data = "/system/bin".toByteArray(), ino = 300002)
            val exp3 =
                Helper.fromHexString("303730373031303030343933653230303030613161343030303030303030303030303030303030303030303030313030303030303030303030303030306230303030303030303030303030303030303030303030303030303030303030303030303030303034303030303030303062696e0000002f73797374656d2f62696e00")
            entry3.encode()
            entry3.encode2()
            entry3.encode()
            entry3.encode2()
            assertTrue(exp3.contentEquals(entry3.encode()))
            assertTrue(exp3.contentEquals(entry3.encode2()))
        }
    }

    @Test
    fun fileEntry() {
        //init.environ.rc
        val initrc =
            "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"
        println("<" + String(Helper.fromHexString(initrc)) + ">")
        val entry = AndroidCpioEntry(
            name = "/init.environ.rc",
            statMode = java.lang.Long.valueOf("100644", 8),
            data = Helper.fromHexString(initrc),
            ino = 300003
        )
        assertTrue(entry.encode().contentEquals(entry.encode2()))
    }

    @Test
    fun specialFilePermTest() {
        val rd = "src/test/resources/filemode_000_ramdisk.img"
        AndroidCpio.decompressCPIO(rd, "temp", null)
        File("temp").deleteRecursively()
    }

    fun packTest() {
        val dir = "/home/yu/work/boot/build/unzip_boot/root"
        val oF = "/home/yu/work/boot/root.cpio"
        val acpio = AndroidCpio()
        acpio.pack(dir, oF, "/home/yu/work/boot/build/unzip_boot/ramdisk_filelist.txt")
    }
}

```

`bbootimg/src/test/kotlin/init/RebootTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package init

import miscimg.MiscImage
import org.junit.Test
import org.junit.After
import java.util.*
import cfig.init.Reboot
import org.slf4j.LoggerFactory

class RebootTest {
    private val log = LoggerFactory.getLogger(RebootTest::class.java)

    @After
    fun tearDown() {
    }

    @Test
    fun testDifferentModes() {
        Reboot.handlePowerctlMessage("reboot")
        Reboot.handlePowerctlMessage("reboot,safemode")
        Reboot.handlePowerctlMessage("reboot,dynsystem")
        Reboot.handlePowerctlMessage("reboot,cold")
        Reboot.handlePowerctlMessage("reboot,ota")
        Reboot.handlePowerctlMessage("reboot,factory_reset")
        Reboot.handlePowerctlMessage("reboot,shell")
        Reboot.handlePowerctlMessage("reboot,adb")
        Reboot.handlePowerctlMessage("reboot,userrequested")
        Reboot.handlePowerctlMessage("reboot,rescueparty")
        Reboot.handlePowerctlMessage("reboot,powerloss")
        Reboot.handlePowerctlMessage("reboot,undervoltage")
        Reboot.handlePowerctlMessage("reboot,tool") //151
        Reboot.handlePowerctlMessage("reboot,wdt") //152
        Reboot.handlePowerctlMessage("reboot,unknown") //153

        Reboot.handlePowerctlMessage("reboot,quiescent") //170
        Reboot.handlePowerctlMessage("reboot,rtc") //171
        Reboot.handlePowerctlMessage("reboot,dm-verity_device_corrupted") //172
        Reboot.handlePowerctlMessage("reboot,dm-verity_enforcing") //173

        Reboot.handlePowerctlMessage("reboot,userrequested,fastboot") //178
        Reboot.handlePowerctlMessage("reboot,userrequested,recovery") //179
        Reboot.handlePowerctlMessage("reboot,userrequested,recovery,ui") //180
    }

    @Test
    fun shutdown() {
        Reboot.handlePowerctlMessage("shutdown")
        Reboot.handlePowerctlMessage("shutdown,userrequested")
        Reboot.handlePowerctlMessage("shutdown,thermal")
        Reboot.handlePowerctlMessage("shutdown,battery")
        Reboot.handlePowerctlMessage("shutdown,container")
        Reboot.handlePowerctlMessage("shutdown,thermal,battery")
        Reboot.handlePowerctlMessage("shutdown,suspend") // Suspend to RAM
        Reboot.handlePowerctlMessage("shutdown,hibernate") // Suspend to DISK
        Reboot.handlePowerctlMessage("shutdown,userrequested,fastboot")
        Reboot.handlePowerctlMessage("shutdown,userrequested,recovery")
    }

    @Test
    fun bootloader() {
        Reboot.handlePowerctlMessage("reboot,bootloader")
    }

    @Test
    fun fastbootd() {
        log.info("fastbootd test 1")
        Reboot.handlePowerctlMessage("reboot,fastboot",
            Properties().apply {
                put(Reboot.dynamicPartitionKey, "true")
            })
        log.info("fastbootd test 2")
        val bcb = MiscImage.BootloaderMessage(command = "boot-fastboot", recovery = "recovery")
        log.info(bcb.toString())
        log.info("fastbootd test 3: not supported, change to bootloader")
        Reboot.handlePowerctlMessage("reboot,fastboot", Properties())
    }

    @Test
    fun recovery() {
        log.info("recovery test 1")
        Reboot.handlePowerctlMessage("reboot,recovery")
    }

    @Test
    fun recovery_rescue() {
        log.info("recovery test 1: rescue")
        val bcb = MiscImage.BootloaderMessage(command = "boot-rescue", recovery = "recovery")
        log.info(bcb.toString())
        log.info("recovery test 2: rescue")
        Reboot.handlePowerctlMessage("reboot,rescue")
    }

    @Test
    fun recovery_sideload() {
        log.info("recovery test 3: sideload")
        Reboot.handlePowerctlMessage("reboot,sideload-auto-reboot")
        Reboot.handlePowerctlMessage("reboot,sideload")
    }
}

```

`build.gradle.kts`:

```kts
import java.util.regex.Matcher
import java.util.regex.Pattern
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.PumpStreamHandler

val GROUP_ANDROID = "android"
val bHackingMode = false
if (parseGradleVersion(gradle.gradleVersion) < 6) {
    logger.error("ERROR: Gradle Version MUST >= 6.0, current is {}", gradle.gradleVersion)
    throw RuntimeException("ERROR: Gradle Version")
} else {
    logger.info("Gradle Version {}", gradle.gradleVersion)
}

buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath("org.apache.commons:commons-exec:1.3")
    }
}

tasks {
    register("rr") {
        this.group = GROUP_ANDROID
        this.description = "reboot to recovery"
        this.doLast {
            logger.warn("Rebooting to recovery ...")
            Runtime.getRuntime().exec("adb root")
            Runtime.getRuntime().exec("adb reboot recovery")
        }
    }
    val unpackTask by register<JavaExec>("unpack") {
        group = GROUP_ANDROID
        main = "cfig.packable.PackableLauncherKt"
        classpath = files("bbootimg/build/libs/bbootimg.jar")
        this.maxHeapSize = "128m"
        enableAssertions = true
        args("unpack")
    }
    unpackTask.dependsOn("bbootimg:jar")

    val packTask by register<JavaExec>("pack") {
        group = GROUP_ANDROID
        main = "cfig.packable.PackableLauncherKt"
        classpath = files("bbootimg/build/libs/bbootimg.jar")
        this.maxHeapSize = "512m"
        enableAssertions = true
        args("pack")
    }
    packTask.dependsOn("bbootimg:jar", "aosp:boot_signer:build")

    val flashTask by register("flash", JavaExec::class) {
        group = GROUP_ANDROID
        main = "cfig.packable.PackableLauncherKt"
        classpath = files("bbootimg/build/libs/bbootimg.jar")
        this.maxHeapSize = "512m"
        enableAssertions = true
        args("flash")
    }
    flashTask.dependsOn("bbootimg:jar")


    val pullTask by register("pull", JavaExec::class) {
        group = GROUP_ANDROID
        main = "cfig.packable.PackableLauncherKt"
        classpath = files("bbootimg/build/libs/bbootimg.jar")
        this.maxHeapSize = "512m"
        enableAssertions = true
        args("pull")
    }
    pullTask.dependsOn("bbootimg:jar")

    val clearTask by register("clear", JavaExec::class) {
        group = GROUP_ANDROID
        main = "cfig.packable.PackableLauncherKt"
        classpath = files("bbootimg/build/libs/bbootimg.jar")
        this.maxHeapSize = "512m"
        enableAssertions = true
        args("clear")
    }
    clearTask.dependsOn("bbootimg:jar")

    //sparse image dependencies
    if (bHackingMode) {
        logger.info("Hacking mode!")
        //C++ mkbootfs
        if (System.getProperty("os.name").contains("Mac")) {
            //mac
            unpackTask.dependsOn("aosp:libsparse:simg2img:installReleaseMacos")
            packTask.dependsOn("aosp:libsparse:img2simg:installReleaseMacos")
            // common
            packTask.dependsOn("aosp:mkbootfs.10:mkbootfsExecutable")
            packTask.dependsOn("aosp:mkbootfs.11:mkbootfsExecutable")
            unpackTask.dependsOn("aosp:mkbootfs.10:mkbootfsExecutable")
            unpackTask.dependsOn("aosp:mkbootfs.11:mkbootfsExecutable")
        } else if (System.getProperty("os.name").contains("Linux")) {
            //linux
            unpackTask.dependsOn("aosp:libsparse:simg2img:installReleaseLinux")
            packTask.dependsOn("aosp:libsparse:img2simg:installReleaseLinux")
            // common
            packTask.dependsOn("aosp:mkbootfs.10:mkbootfsExecutable")
            packTask.dependsOn("aosp:mkbootfs.11:mkbootfsExecutable")
            unpackTask.dependsOn("aosp:mkbootfs.10:mkbootfsExecutable")
            unpackTask.dependsOn("aosp:mkbootfs.11:mkbootfsExecutable")
        } else {
            logger.info("Disable C++ modules on Window$")
        }
    } else {
        logger.info("Release mode")
    }
}

fun parseGradleVersion(version: String): Int {
    val VERSION_PATTERN = Pattern.compile("((\\d+)(\\.\\d+)+)(-(\\p{Alpha}+)-(\\w+))?(-(SNAPSHOT|\\d{14}([-+]\\d{4})?))?")
    val matcher = VERSION_PATTERN.matcher(version)
    if (!matcher.matches()) {
        throw IllegalArgumentException(String.format("'%s' is not a valid Gradle version string (examples: '1.0', '1.0-rc-1')", version))
    }
    val versionPart: String = matcher.group(1)
    val majorPart = Integer.parseInt(matcher.group(2), 10)
    logger.info("Gradle: versionPart {}, majorPart {}", versionPart, majorPart)
    return majorPart
}

```

`doc/Pixel6_vbmeta.puml`:

```puml
@startmindmap
'https://plantuml.com/mindmap-diagram

caption oriole vbmeta structure
title Pixel 6 vbmeta

* <&flag>main vbmeta
**[#Orange] <&pulse>boot
***[#lightgreen]  <&star>boot
**[#Orange] <&pulse>vbmeta_system
***[#lightblue]  <&people>system
***[#lightblue]  <&people>system_ext
***[#lightblue]  <&people>product
**[#Orange]  <&pulse>vbmeta_vendor
***[#lightblue]  <&people>vendor
**[#lightblue]  <&people>vendor_dlkm
**[#lightgreen]  <&star>vendor_boot
**[#lightgreen]  <&star>dtbo
**[#lightgreen]  <&star>abl
**[#lightgreen]  <&star>bl1
**[#lightgreen]  <&star>bl2
**[#lightgreen]  <&star>bl31
**[#lightgreen]  <&star>gsa
**[#lightgreen]  <&star>ldfw
**[#lightgreen]  <&star>pbl
**[#lightgreen]  <&star>tzsw

header
Pixel 6 - oriole
endheader

center footer oriole

legend right
|BG Color| Type |
|<#FFA500>| Chain Partition|
|<#90EE90>| Hash Descriptor|
|<#ADD8E6>| HashTree Descriptor|
endlegend

@endmindmap

```

`doc/Struct3.md`:

```md
'Struct3' formats

 | Format | C Type | Python type | Standard size | Type | Parameter | Size |
 | -- | -- | -- | -- | -- | -- | -- |
 | x | pad byte | no value |  | Type.Padding | "null,Byte,Int (only lower 8 bits are kept)" | 1 |
 | c | char | bytes of length 1 | 1 | kotlin.Char | "Character.class (only lower 8 bits are kept, higher 8 bits are discarded)" | 1 |
 | b | signed char | integer | 1 | kotlin.Byte | byte[] (item range: [-128~127]) | n |
 | s | char[] | bytes |  | kotlin.String | String.class | n |
 | B | unsigned char | integer | 1 | Kotlin.UByte | byte[] (item range: [0~255]) | n |
 | ? | _Bool | bool | 1 |  |  |  |
 | h | short | integer | 2 | kotlin.Short | "Int,Short, (range [-32768 , 32767])" | 2 |
 | H | unsigned short | integer | 2 | kotlin.UShort | "Int,Short,UShort,(range [0 , 65535])" | 2 |
 | i | int | integer | 4 | kotlin.Int | "[-2^31 , 2^31 - 1]" | 4 |
 | l | long | integer | 4 | kotlin.Int | "[-2^31 , 2^31 - 1]" | 4 |
 | I | unsigned int | integer | 4 | kotlin.UInt | "[0 , 2^32-1]" |  |
 | L | unsigned long | integer | 4 | kotlin.UInt | "[0 , 2^32-1]" |  |
 | q | long long | integer | 8 | kotlin.Long |  |  |  |
 | Q | unsigned long long | integer | 8 | kotlin.ULong |  |  |
 | e | (7) | float | 2 |  |  |  |
 | f | float | float | 4 |  |  |  |
 | d | double | float | 8 |  |  |  |

```

`doc/additional_tricks.md`:

```md
## tricks for Nexus 9(volantis)

**volantis** has a dummy header of size 256 bytes, which looks like this:

    0000000: 78 56 34 12 00 00 00 00 00 ba 86 00 00 01 00 00  xV4.............
    0000010: 00 01 00 00 00 b8 86 00 00 b9 86 00 00 01 00 00  ................
    0000020: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000030: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000040: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000050: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000060: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000070: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000080: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000090: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    00000a0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    00000b0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    00000c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    00000d0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    00000e0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    00000f0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
    0000100: 41 4e 44 52 4f 49 44 21 72 64 6d 00 00 80 00 10  ANDROID!rdm.....
    0000110: d0 41 19 00 00 00 00 11 00 00 00 00 00 00 f0 10  .A..............

We have to trim the header before it can be recognized by our toy.

    $ dd if=boot.img of=raw_boot bs=256 skip=1

Now we can work with 'raw\_boot'

    $ cp raw_boot boot.img
    $ gradle unpack
    $ gradle pack

## Pixel XL (marlin)

**marlin** is a profile that adopts A/B system schema while still using Verified Boot 1.0 style boot image.

Due to the configuration "BOARD_BUILD_SYSTEM_ROOT_IMAGE := true", the embeded ramdisk in boot.img is actually used in recovery mode.

## Pixel 3 (blueline)

Fickle Google removed "BOARD_BUILD_SYSTEM_ROOT_IMAGE" and added "ro.boot.dynamic_partitions=true", which means normal mode ramdisk is back. Besides, it also packed DTB inside boot.img.

## NX606J

Thanks to the work by [CallMESuper], ZTE NX606J boot.img is also verified to be compatible with this toolkit.

ROM download page: [http://ui.nubia.cn/rom/detail/56](http://ui.nubia.cn/rom/detail/56)

## K3 (CPH1955)

`boot.img` extracted from OTA zip file doesn't work properly but `recovery.img` works fine. In order to obtain `recovery.img`, a `bsdiff` patch from `system/recovery-from-boot.p` is applied to `boot.img`. Ex: ```bspatch boot.img recovery.img system/recovery-from-boot.p```

This part is contributed by @Surendrajat, thanks!

## about porting

#### libsparse: output\_file.cpp

*typeof* is missing in macos clang++, need to change it to *decltype* instead.

## using pre-packed ramdisk.img.gz
place 'ramdisk.img.gz' in directory, delete "root/", program will use it as prebuilt.

## cpio
decompress cpio with commandline `cpio -idmv -F <file>`

Some file system(also java) doesn't support special file permissions, https://docs.oracle.com/cd/E19455-01/805-7229/secfiles-69/index.html
So we have to save the file perms in `build/unzip_boot/ramdisk_filelist.txt`, and use it when doing 'pack'.

### cpio on windows
* got `java.nio.file.FileSystemException` and says "A required privilege is not held by the client"
```
 java.base/java.nio.file.Files.createSymbolicLink(Files.java:1058)
```
Solution:
Avoid using this feature on Windows, create regular file instead.

* File.renameTo() is problematic, use Files.move() instead.

* remember to close File streams to avoid any potential problems

## Boot image signature in BootImage V4
"boot signature" is designed for GKI, it's to be verified by VTS, not bootloader, so this part can be seen as part of the raw boot.img for bootloader.

Emulate creating GKI image:
```
out/host/linux-x86/bin/mkbootimg --kernel out/target/product/vsoc_arm64/kernel  --ramdisk out/target/product/vsoc_arm64/ramdisk.img --gki_signing_key external/avb/test/data/testkey_rsa4096.pem --gki_signing_algorithm SHA256_RSA4096 --os_version 11 --os_patch_level 2021-03-05 --header_version 4 --output out/target/product/vsoc_arm64/boot.img
out/host/linux-x86/bin/avbtool add_hash_footer --image out/target/product/vsoc_arm64/boot.img --partition_size   67108864 --partition_name boot --algorithm SHA256_RSA2048 --key external/avb/test/data/testkey_rsa2048.pem --prop com.android.build.boot.fingerprint:nicefinger --prop com.android.build.boot.os_version:11 --rollback_index 1614902400
```

## bootconfig in VendorBoot V4
Depends on kernel 5.6+
https://cateee.net/lkddb/web-lkddb/BOOT_CONFIG.html

VTS requirement:
if (S-launched, Kernel 5.10+), no "androidboot." should be placed in kernel commandline.

```

`doc/eth0_up.puml`:

```puml
@startuml
'comment

autonumber

box "Framework"
participant "EthernetTracker.java" as EthernetTracker
participant "NetworkManagementService.java" as NetworkManagementService
end box

EthernetTracker -> EthernetTracker: maybeTrackInterface(eth0)
EthernetTracker -> EthernetTracker: addInterface(eth0)
EthernetTracker -> NetworkManagementService: INetworkManagementService\n::setInterfaceUp(eth0)

box "Netd"
participant "NetdNativeService.cpp" as NetdNativeService
NetworkManagementService -> NetworkManagementService: setInterfaceConfig(iface, ifcg)
NetworkManagementService -> NetworkManagementService: INetd.interfaceSetCfg(cfgParcel)
NetworkManagementService --[#green]> NetdNativeService: NetdNativeService\n::interfaceSetCfg()
participant "InterfaceController.cpp" as InterfaceController
end box

entity "kernel" as kernel

NetdNativeService -> InterfaceController: InterfaceController\n::setCfg(cfg)
InterfaceController -[#green]> kernel: ioctl()
@enduml

```

`doc/hidl_boot_control.puml`:

```puml
@startuml

package services {
    class android_hardware_boot_1_1_service {
        *cc_binary
    }
    class android_hardware_boot_1_0_service {
        *cc_binary
    }
}


package impls {
    class android_hardware_boot_1_0_impl {
        *cc_library
    }

    class android_hardware_boot_1_1_impl {
        *cc_library
    }
}


package hidl_interface {
    class android_hardware_boot_1_0 {
        *hidl_interface
    }

    class android_hardware_boot_1_1 {
        *hidl_interface
    }
}


android_hardware_boot_1_0_impl --> android_hardware_boot_1_0

android_hardware_boot_1_0_service --> android_hardware_boot_1_0



android_hardware_boot_1_1_impl --> android_hardware_boot_1_0
android_hardware_boot_1_1_impl --> android_hardware_boot_1_1
android_hardware_boot_1_1_impl --> libboot_control
android_hardware_boot_1_1_impl ..> libboot_control_defaults


android_hardware_boot_1_1_service --> android_hardware_boot_1_0
android_hardware_boot_1_1_service --> android_hardware_boot_1_1
class libboot_control_defaults {
    *cc_defaults
}
libboot_control_defaults --> android_hardware_boot_1_1
libboot_control_defaults --> libbootloader_message_vendor
class libboot_control {
    *cc_library_static
}
libboot_control ..> libboot_control_defaults
class bootctrl_default {
    *cc_library
}
bootctrl_default --> libboot_control
bootctrl_default ..> libboot_control_defaults
@enduml

```

`doc/layout.md`:

```md
# layout of [vendor\_]boot.img

[1. boot.img v0-v2](#1-bootimg-v0-v2)

[2. boot.img v3-v4](#2-bootimg-v3-v4)

[3. vendor_boot.img v3-v4](#3-vendor_bootimg-v3-v4)

[4. signature part](#4-signature-part)

 - [4.1 Boot Image Signature](#41-boot-image-signature-vboot-10)

 - [4.2 AVB Footer](#42-avb-footer-vboot-20)

[5. boot in memory](#5-boot-in-memory)

## 1. boot.img v0-v2
### header
Value at 0x28 is one of {0x00,0x01,0x02,0x03,0x04}, this filed should be read first to identify header version.

              item                        size in bytes             position
    +-----------------------------------------------------------+    --> 0
    |<MAGIC HEADER>                  |     8 (value=ANDROID!)   |
    |--------------------------------+--------------------------|    --> 8
    |<kernel length>                 |     4                    |
    |--------------------------------+--------------------------|    --> 12
    |<kernel offset>                 |     4                    |
    |--------------------------------+--------------------------|    --> 16 (0x10)
    |<ramdisk length>                |     4                    |
    |--------------------------------+--------------------------|    --> 20
    |<ramdisk offset>                |     4                    |
    |--------------------------------+--------------------------|    --> 24
    |<second bootloader length>      |     4                    |
    |--------------------------------+--------------------------|    --> 28
    |<second bootloader offset>      |     4                    |
    |--------------------------------+--------------------------|    --> 32 (0x20)
    |<tags offset>                   |     4                    |
    |--------------------------------+--------------------------|    --> 36
    |<page size>                     |     4                    |
    |--------------------------------+--------------------------|    --> 40 (0x28)
    |<header version>                |     4 (value in [0,1,2]) |
    |--------------------------------+--------------------------|    --> 44
    |<os version & os patch level>   |     4                    |
    |--------------------------------+--------------------------|    --> 48 (0x30)
    |<board name>                    |     16                   |
    |--------------------------------+--------------------------|    --> 64 (0x40)
    |<cmdline part 1>                |     512                  |
    |--------------------------------+--------------------------|    --> 576 (0x240)
    |<hash digest>                   |     32                   |
    |--------------------------------+--------------------------|    --> 608 (0x260)
    |<cmdline part 2>                |     1024                 |
    |--------------------------------+--------------------------|    --> 1632 (0x660)
    |<recovery dtbo length>   [v1]   |     4                    |
    |--------------------------------+--------------------------|    --> 1636
    |<recovery dtbo offset>   [v1]   |     8                    |
    |--------------------------------+--------------------------|    --> 1644
    |<header size>            [v1]   |     4 (v1: value=1648)   |
    |                                |       (v2: value=1660)   |
    |--------------------------------+--------------------------|    --> 1648 (0x670)
    |<dtb  length>            [v2]   |     4                    |
    |--------------------------------+--------------------------|    --> 1652
    |<dtb  offset>            [v2]   |     8                    |
    |--------------------------------+--------------------------|    --> 1660 (0x67c)
    |<padding>                       | min(n * page_size        |
    |                                |           - header_size) |
    +--------------------------------+--------------------------+    --> pagesize

### data

    +-----------------------------------------------------------+    --> pagesize
    |<kernel>                        |   kernel length          |
    |--------------------------------+--------------------------|
    |<padding>                       | min(n * page_size - len) |
    +-----------------------------------------------------------+

    +-----------------------------------------------------------+
    |<ramdisk>                       |   ramdisk length         |
    |--------------------------------+--------------------------|
    |<padding>                       | min(n * page_size - len) |
    +-----------------------------------------------------------+

    +-----------------------------------------------------------+
    |<second bootloader>             | second bootloader length |
    |--------------------------------+--------------------------|
    |<padding>                       | min(n * page_size - len) |
    +-----------------------------------------------------------+

    +-----------------------------------------------------------+
    |<recovery dtbo>          [v1]   | recovery dtbo length     |
    |--------------------------------+--------------------------|
    |<padding>                [v1]   | min(n * page_size - len) |
    +-----------------------------------------------------------+

    +-----------------------------------------------------------+
    |<dtb>                    [v2]   | dtb length               |
    |--------------------------------+--------------------------|
    |<padding>                [v2]   | min(n * page_size - len) |
    +-----------------------------------------------------------+    --> end of data part

## 2. boot.img v3-v4

For partitions: `/boot` and `/init_boot`.

### header

              item                        size in bytes             position
    +-----------------------------------------------------------+    --> 0
    |<MAGIC HEADER>                  |     8 (value=ANDROID!)   |
    |--------------------------------+--------------------------|    --> 8
    |<kernel size>                   |     4                    |
    |--------------------------------+--------------------------|    --> 12
    |<ramdisk size>                  |     4                    |
    |--------------------------------+--------------------------|    --> 16
    |<os version & os patch level>   |     4                    |
    |--------------------------------+--------------------------|    --> 20
    |<header size>                   |     4                    |
    |--------------------------------+--------------------------|    --> 24
    |<reserved>                      |     4 * 4                |
    |--------------------------------+--------------------------|    --> 40 (0x28)
    |<header version>                |     4 (value in [3|4])   |
    |--------------------------------+--------------------------|    --> 44
    |<cmdline>                       |     1024+512=1536        |
    |--------------------------------+--------------------------|    --> 1580
    |<signature_size>   (v4 only)    |     4                    |
    |--------------------------------+--------------------------|    --> 1584
    |<padding>                       | min(n * page_size        |
    |                                |           - header_size) |
    +--------------------------------+--------------------------+    --> pagesize=4096

### data

    +-----------------------------------------------------------+    --> pagesize
    |<kernel>                        |   kernel length          |
    +-----------------------------------------------------------+
    |<ramdisk>                       |   ramdisk length         |
    +-----------------------------------------------------------+
    |<boot signature>   (v4 only)    |   boot signature length  |
    +--------------------------------+--------------------------+
    |<padding>                       | min(n * page_size - len) |
    +-----------------------------------------------------------+

## 3. vendor\_boot.img v3-v4

For partitions: `/vendor_boot`.

### header

              item                        size in bytes             position
    +-----------------------------------------------------------+    --> 0
    |<MAGIC HEADER>                  |     8 (vaue=VNDRBOOT)    |
    |--------------------------------+--------------------------|    --> 8
    |<header version>                |     4 (value=3)          |
    |--------------------------------+--------------------------|    --> 12
    |<page size>                     |     4                    |
    |--------------------------------+--------------------------|    --> 16
    |<kernel load addr>              |     4                    |
    |--------------------------------+--------------------------|    --> 20
    |<ramdisk load addr>             |     4                    |
    |--------------------------------+--------------------------|    --> 24
    |<vendor ramdisk total size>     |     4                    |
    |--------------------------------+--------------------------|    --> 28
    |<vendor cmdline>                |     2048                 |
    |--------------------------------+--------------------------|    --> 2076
    |<tags offset>                   |     4                    |
    |--------------------------------+--------------------------|    --> 2080
    |<board name>                    |     16                   |
    |--------------------------------+--------------------------|    --> 2096
    |<header size>                   |     4 (v3: value=2112)   |
    |                                |     4 (v4: value=2128)   |
    |--------------------------------+--------------------------|    --> 2100
    |<dtb size>                      |     4                    |
    |--------------------------------+--------------------------|    --> 2104
    |<dtb load addr>                 |     8                    |
    |--------------------------------+--------------------------|    --> 2112
    |<vendor ramdisk table size>     |     4   (v4 only)        |
    |--------------------------------+--------------------------|    --> 2116
    |<vendor ramdisk table entry num>|     4   (v4 only)        |
    |--------------------------------+--------------------------|    --> 2120
    |<vendor ramdisk table entry size|     4   (v4 only)        |
    |--------------------------------+--------------------------|    --> 2124
    |<bootconfig size>               |     4   (v4 only)        |
    |--------------------------------+--------------------------|    --> 2128
    |<padding>                       | min(n * page_size        |
    |                                |           - header_size) |
    +--------------------------------+--------------------------+    --> pagesize

### data


    +------------------+-------------+--------------------------+    --> pagesize
    |                  | ramdisk 1   |                          |
    |                  |-------------+                          |
    |                  | ramdisk 2   |                          |
    |<vendor ramdisks> |-------------+   padded len             |
    |                  | ramdisk n   |                          |
    |                  |-------------+                          |    --> pagesize + vendor_ramdisk_total_size
    |                  | padding     |                          |
    +------------------+-------------+--------------------------+    --> pagesize + vendor_ramdisk_total_size + padding
    |                  |   dtb       |                          |
    |<dtb>             |-------------+   padded len             |
    |                  | padding     |                          |
    +------------------+-------------+--------------------------+    --> dtb offset + dtb size + padding
    |<vendor ramdisk > | entry 1     |                          |
    |     table>       |-------------+                          |
    |                  | entry 2     |   padded len             |
    |                  |-------------+                          |
    |                  | entry n     |                          |
    |      (v4)        |-------------+                          |
    |                  | padding     |                          |
    +------------------+----------------------------------------+    --> vrt offset + vrt size + padding
    |<bootconfig>            (v4)    |   padded len             |
    +--------------------------------+--------------------------+



## 4. signature part

### 4.1 Boot Image Signature (VBoot 1.0)

    +--------------------------------+--------------------------+    --> end of data part
    |<signature>                     | signature length         |
    |--------------------------------+--------------------------+
    |<padding>                       | defined by boot_signer   |
    +--------------------------------+--------------------------+

### 4.2 AVB Footer (VBoot 2.0)

                         item                        size in bytes             position
    +------+--------------------------------+-------------------------+ --> end of data part (say locaton +0)
    |      | VBMeta Header                  | total 256               |
    |      |                                |                         |
    |      |   - Header Magic "AVB0"        |     4                   |
    |      |   - avb_version Major          |     4                   |
    |      |   - avb_version Minor          |     4                   |
    |      |   - authentication_blob_size   |     8                   |
    |      |   - auxiliary blob size        |     8                   |
    |      |   - algorithm type             |     4                   |
    |      |   - hash_offset                |     8                   |
    |      |   - hash_size                  |     8                   |
    |      |   - signature_offset           |     8                   |
    |      |   - signature_size             |     8                   |
    |      |   - pub_key_offset             |     8                   |
    |VBMeta|   - pub_key_size               |     8                   |
    | Blob |   - pub_key_metadata_offset    |     8                   |
    |      |   - pub_key_metadata_size      |     8                   |
    |      |   - descriptors_offset         |     8                   |
    |      |   - descriptors_size           |     8                   |
    |      |   - rollback_index             |     8                   |
    |      |   - flags                      |     4                   |
    |      |   - RESERVED                   |     4                   |
    |      |   - release string             |     47                  |
    |      |   - NULL                       |     1                   |
    |      |   - RESERVED                   |     80                  |
    |      |--------------------------------+-------------------------+ --> + 256
    |      | Authentication Blob            |                         |
    |      |   - Hash of Header & Aux Blob  | alg.hash_num_bytes      | --> + 256 + hash_offset
    |      |   - Signature of Hash          | alg.signature_num_bytes | --> + 256 + signature_offset
    |      |   - Padding                    | align by 64             |
    |      +--------------------------------+-------------------------+
    |      | Auxiliary Blob                 |                         |
    |      |   - descriptors                |                         | --> + 256 + authentication_blob_size + descriptors_offset
    |      |   - pub key                    |                         | --> + 256 + authentication_blob_size + pub_key_offset
    |      |   - pub key meta data          |                         | --> + 256 + authentication_blob_size + pub_key_metadata_offset
    |      |   - padding                    | align by 64             |
    |      +--------------------------------+-------------------------+
    |      | Padding                        | align by block_size     |
    +------+--------------------------------+-------------------------+ --> + (block_size * n)

    +---------------------------------------+-------------------------+
    |                                       |                         |
    |                                       |                         |
    | DONOT CARE CHUNK                      |                         |
    |                                       |                         |
    |                                       |                         |
    +---------------------------------------+-------------------------+

    +---------------------------------------+-------------------------+ --> partition_size - block_size
    | Padding                               | block_size - 64         |
    +---------------------------------------+-------------------------+ --> partition_size - 64
    | AVB Footer                            | total 64                |
    |                                       |                         |
    |   - Footer Magic "AVBf"               |     4                   |
    |   - Footer Major Version              |     4                   |
    |   - Footer Minor Version              |     4                   |
    |   - Original image size               |     8                   |
    |   - VBMeta offset                     |     8                   |
    |   - VBMeta size                       |     8                   |
    |   - Padding                           |     28                  |
    +---------------------------------------+-------------------------+ --> partition_size

## 5. boot in memory

```
       ┌────────────────────────────────────────┐
       │           kernel                       │
       ├──────────────────┬─────────────────────┤
       │                  │ vendor ramdisk 1    │
       │                  ├─────────────────────┤
       │                  │ vendor ramdisk 2    │
       │  vendor ramdisks ├─────────────────────┤
       │                  │   ...               │
       │                  ├─────────────────────┤
       │                  │ vendor ramdisk n    │
       ├──────────────────┴─────────────────────┤
       │  generic ramdisk (from init_boot/boot) │
       ├──────────────────┬─────────────────────┤
       │                  │parameters           │
       │                  ├─────────────────────┤
       │                  │param size  (4)      │
       │   bootconfig     ├─────────────────────┤
       │                  │param checksum (4)   │
       │                  ├─────────────────────┤
       │                  │bootconfig magic(12) │ --> "#BOOTCONFIG\n"
       └──────────────────┴─────────────────────┘
```

```

`doc/misc_image_layout.md`:

```md
# /misc partition layout

| - | - | - | Size |  description | Offset |
| :---- | :------ | :---- | :---- | ----- | ----- |
| Legacy      | bootloader_message |   | (2K) |   | --> 0 |
| | |command | 32 |updated by linux/bootloader | |
| | |status | 32 |deprecated | |
| | |recovery |768 |talking channel between normal/recovery modes | |
| |                                              |stage | 32 |format "#/#", eg, "1/3" | |
| | |reserved | 1184| | |
| - | - |- | - | - |  |
| Vendor Area | vendor bootloader msg | N/A | 2K | Vendor Area                                                  | -->2KB                                           |
|             | vendor bootloader msg | N/A | 12K | pure Vendor area                                             | -->4KB                                       |
| -           | - | - | - | - |  |
| Wipe        | wipe_package info                            | | 16K | offset 16KB, Used by uncrypt and recovery to store wipe_package for A/B devices | -->16KB |
| -           | -                                            | - | - | - |  |
| System      | system_space -> 1<br>misc_virtual_ab_message | | (64) | | -->32KB |
| |  | version | 1 | |  |
| |  | magic | 4 | | |
| |  | merge_status | 1 | | |
| |  | source_slot | 1 | | |
| |  | reserved | 57 | | |
| |  |  | | | |
| |  |  |  | | |

### vendor area implementation example from Google: 


#### bootctrl.default.so (link libboot_control.a)貌似没人用


使用legacy_boot_control.cpp, 把libboot_control.a的实现的类android::bootable::BootControl包装进去



### android.hardware.boot@1.1-impl

使用BootControl.cpp

```
android::hardware::boot::V1_1::implementation::BootControl
```
直接使用"android::bootable::BootControl"的实现








#### libboot_control.a

code location:

```hardware/interfaces/boot/1.1/default/boot_control```

https://android.googlesource.com/platform/hardware/interfaces/+/refs/heads/master/boot/1.1/default/boot_control/

| - | - | - | Offset | Size |  description |
| :---- | :------ | :---- | :---- | :---- | ----- |
| Vendor Area | bootloader_message_ab | | 2K | (2K) | Vendor Area                                                  |
| |                                              | slot_suffix | | 32| |
| |                                              | update_channel | |128 | |
| | | reserved | | 1888| |



### 32 BYTES "slot_suffix" part details:

| - | - | - | Offset | Size |  description |
| :---- | :------ | :---- | :---- | :---- | ----- |
| | bootloader_control |  | | (32) | |
| |  | slot_suffix | | 4 | |
| |  | magic | | 4 | |
| |  | version | | 1 | |
| |  | nb_slot | | 3bits | number slots |
| |  | recovery_tries_remaining | | 3bits | |
| |  | merge_status | | 3bits | |
| |  | reserved0 | | 1 | |
| |  | slot_info | | 8 | slot_metadata * 4 |
| |  | reverved1 | | 8 | |
| |  | crc32_le | | 4 | |
| |  |  | |  | |
| | slot_metadata | | | (2) | |
| | | priority |  | 4bits | |
| | | tries_remaining |  | 3bits | |
| | | successful_boot | | 1bit | |
| | | verity_corrupted | | 1bit | |
| | | reserved | | 7bits | |
| | | | |  | |


```

`doc/reboot.puml`:

```puml
@startuml
'comment

autonumber

participant "system/core/reboot/reboot.c" as reboot_c
participant "init/reboot.cpp" as init_reboot
participant "init/reboot_utils.cpp" as init_reboot_utils
entity "kernel/reboot.c" as kernel

reboot_c -> init_reboot : property_set()\nargs="sys.powerctl",\n "reboot,recovery"
note left: reboot recovery
init_reboot -> init_reboot_utils: HandlePowerctlMessage()\nargs="reboot,recovery"
init_reboot_utils -> kernel: RebootSystem(cmd, rebootTarget)
init_reboot_utils -> kernel: syscall(__NR_reboot,\n  LINUX_REBOOT_MAGIC1,\n  LINUX_REBOOT_MAGIC2,\n  LINUX_REBOOT_CMD_RESTART2,\n  rebootTarget.c_str())
note right: void kernel_restart(rebootTarget)
@enduml

```

`doc/reboot_states.puml`:

```puml
@startuml
state fastboot

normal -right-> recovery: 1
recovery -down-> fastbootd: 2
fastbootd -left-> fastboot: 3
fastboot -up-> normal: 4

'self
normal -[dashed]> normal: a
recovery -[dashed]> recovery: b
fastboot -[dashed]> fastboot: c
fastbootd -[dashed]> fastbootd: d

'normal
normal -> fastbootd: 5

'recovery
recovery -[#blue]> fastboot: 6
@enduml
```

`doc/recovery_adb.md`:

```md
# 打开recovery模式下的adb

###1. 解开vbmeta.img， 关闭AVB
修改 build/unzip_boot/vbmeta.img.avb.json, Line #19
```diff
-    "flags" : 0,
-    "flags" : 2,
```
重新打包，刷回去

###2. 先解开boot.img, 然后做修改如下

修改**prop.default**,打开debuggable, 注意ro.debuggable出现两次，得全改了, 或者删一个
```diff
-ro.debuggable=0
+ro.debuggable=1
```
关闭adb secure, 防止出现adb devices之后的unauthorized 状态
```diff
-ro.adb.secure=1
+ro.adb.secure=0
```

重新打包，刷回去

```

`doc/short.md`:

```md
# 中文快速说明

## 解包boot.img
boot.img放在当前目录, 然后

    $ ./gradlew unpack

解出来的文件在build/unzip_boot/, 可以自行更换kernel或者修改rootfs内容和打包参数

## 重新打包

    $ ./gradlew pack

新生成的文件名boot.img.signed


```

`doc/shutdown.puml`:

```puml
@startuml
'comment

autonumber

participant "system/core/reboot/reboot.c" as reboot_c
participant "init/reboot.cpp" as init_reboot
participant "init/reboot_utils.cpp" as init_reboot_utils
participant "bionic/libc/bionic/reboot.cpp" as bionic_reboot
entity "kernel/reboot.c" as kernel

reboot_c -> init_reboot : property_set()\nargs="sys.powerctl","shutdown,tired"
note left: reboot -p tired
init_reboot -> init_reboot_utils: HandlePowerctlMessage()\nargs="shutdown,tired"
init_reboot_utils -> bionic_reboot: RebootSystem()
init_reboot_utils -> bionic_reboot: reboot(RB_POWER_OFF)
bionic_reboot -> kernel: reboot()\nmode=LINUX_REBOOT_CMD_POWER_OFF
bionic_reboot -> kernel: __reboot()\n  args=(LINUX_REBOOT_MAGIC1,\n  LINUX_REBOOT_MAGIC2,\n  mode,  nullptr)
note right: kernel_power_off()
@enduml

```

`doc/system_core_libs.puml`:

```puml
@startuml
'Android system libs

class libbase {
2
}
class liblog {
1
}
class libprocinfo {
3
}
class libcutils {
5
* libcutils_sockets (4)
}
class libfstab {
6
}
class libutils {
L.1
}
class libdm {
7
}
class libavb {
* avb_crypto_ops_impl_sha
}
libbase --|> liblog
libprocinfo --|> libbase
libcutils --|> libbase
libcutils --|> liblog
libfstab --|> liblog
libfstab --|> libbase
libutils --|> libcutils
libutils --|> liblog
libdm --|> libbase
@enduml

```

`gradle/wrapper/gradle-wrapper.properties`:

```properties
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-7.6-bin.zip
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists

```

`gradlew`:

```
#!/usr/bin/env sh

#
# Copyright 2015 the original author or authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

##############################################################################
##
##  Gradle start up script for UN*X
##
##############################################################################

# Attempt to set APP_HOME
# Resolve links: $0 may be a link
PRG="$0"
# Need this for relative symlinks.
while [ -h "$PRG" ] ; do
    ls=`ls -ld "$PRG"`
    link=`expr "$ls" : '.*-> \(.*\)$'`
    if expr "$link" : '/.*' > /dev/null; then
        PRG="$link"
    else
        PRG=`dirname "$PRG"`"/$link"
    fi
done
SAVED="`pwd`"
cd "`dirname \"$PRG\"`/" >/dev/null
APP_HOME="`pwd -P`"
cd "$SAVED" >/dev/null

APP_NAME="Gradle"
APP_BASE_NAME=`basename "$0"`

# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
DEFAULT_JVM_OPTS='"-Xmx64m" "-Xms64m"'

# Use the maximum available, or set MAX_FD != -1 to use that value.
MAX_FD="maximum"

warn () {
    echo "$*"
}

die () {
    echo
    echo "$*"
    echo
    exit 1
}

# OS specific support (must be 'true' or 'false').
cygwin=false
msys=false
darwin=false
nonstop=false
case "`uname`" in
  CYGWIN* )
    cygwin=true
    ;;
  Darwin* )
    darwin=true
    ;;
  MINGW* )
    msys=true
    ;;
  NONSTOP* )
    nonstop=true
    ;;
esac

CLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar


# Determine the Java command to use to start the JVM.
if [ -n "$JAVA_HOME" ] ; then
    if [ -x "$JAVA_HOME/jre/sh/java" ] ; then
        # IBM's JDK on AIX uses strange locations for the executables
        JAVACMD="$JAVA_HOME/jre/sh/java"
    else
        JAVACMD="$JAVA_HOME/bin/java"
    fi
    if [ ! -x "$JAVACMD" ] ; then
        die "ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
else
    JAVACMD="java"
    which java >/dev/null 2>&1 || die "ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
fi

# Increase the maximum file descriptors if we can.
if [ "$cygwin" = "false" -a "$darwin" = "false" -a "$nonstop" = "false" ] ; then
    MAX_FD_LIMIT=`ulimit -H -n`
    if [ $? -eq 0 ] ; then
        if [ "$MAX_FD" = "maximum" -o "$MAX_FD" = "max" ] ; then
            MAX_FD="$MAX_FD_LIMIT"
        fi
        ulimit -n $MAX_FD
        if [ $? -ne 0 ] ; then
            warn "Could not set maximum file descriptor limit: $MAX_FD"
        fi
    else
        warn "Could not query maximum file descriptor limit: $MAX_FD_LIMIT"
    fi
fi

# For Darwin, add options to specify how the application appears in the dock
if $darwin; then
    GRADLE_OPTS="$GRADLE_OPTS \"-Xdock:name=$APP_NAME\" \"-Xdock:icon=$APP_HOME/media/gradle.icns\""
fi

# For Cygwin or MSYS, switch paths to Windows format before running java
if [ "$cygwin" = "true" -o "$msys" = "true" ] ; then
    APP_HOME=`cygpath --path --mixed "$APP_HOME"`
    CLASSPATH=`cygpath --path --mixed "$CLASSPATH"`

    JAVACMD=`cygpath --unix "$JAVACMD"`

    # We build the pattern for arguments to be converted via cygpath
    ROOTDIRSRAW=`find -L / -maxdepth 1 -mindepth 1 -type d 2>/dev/null`
    SEP=""
    for dir in $ROOTDIRSRAW ; do
        ROOTDIRS="$ROOTDIRS$SEP$dir"
        SEP="|"
    done
    OURCYGPATTERN="(^($ROOTDIRS))"
    # Add a user-defined pattern to the cygpath arguments
    if [ "$GRADLE_CYGPATTERN" != "" ] ; then
        OURCYGPATTERN="$OURCYGPATTERN|($GRADLE_CYGPATTERN)"
    fi
    # Now convert the arguments - kludge to limit ourselves to /bin/sh
    i=0
    for arg in "$@" ; do
        CHECK=`echo "$arg"|egrep -c "$OURCYGPATTERN" -`
        CHECK2=`echo "$arg"|egrep -c "^-"`                                 ### Determine if an option

        if [ $CHECK -ne 0 ] && [ $CHECK2 -eq 0 ] ; then                    ### Added a condition
            eval `echo args$i`=`cygpath --path --ignore --mixed "$arg"`
        else
            eval `echo args$i`="\"$arg\""
        fi
        i=`expr $i + 1`
    done
    case $i in
        0) set -- ;;
        1) set -- "$args0" ;;
        2) set -- "$args0" "$args1" ;;
        3) set -- "$args0" "$args1" "$args2" ;;
        4) set -- "$args0" "$args1" "$args2" "$args3" ;;
        5) set -- "$args0" "$args1" "$args2" "$args3" "$args4" ;;
        6) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" ;;
        7) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" ;;
        8) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" "$args7" ;;
        9) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" "$args7" "$args8" ;;
    esac
fi

# Escape application args
save () {
    for i do printf %s\\n "$i" | sed "s/'/'\\\\''/g;1s/^/'/;\$s/\$/' \\\\/" ; done
    echo " "
}
APP_ARGS=`save "$@"`

# Collect all arguments for the java command, following the shell quoting and substitution rules
eval set -- $DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS "\"-Dorg.gradle.appname=$APP_BASE_NAME\"" -classpath "\"$CLASSPATH\"" org.gradle.wrapper.GradleWrapperMain "$APP_ARGS"

exec "$JAVACMD" "$@"

```

`gradlew.bat`:

```bat
@rem
@rem Copyright 2015 the original author or authors.
@rem
@rem Licensed under the Apache License, Version 2.0 (the "License");
@rem you may not use this file except in compliance with the License.
@rem You may obtain a copy of the License at
@rem
@rem      https://www.apache.org/licenses/LICENSE-2.0
@rem
@rem Unless required by applicable law or agreed to in writing, software
@rem distributed under the License is distributed on an "AS IS" BASIS,
@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
@rem See the License for the specific language governing permissions and
@rem limitations under the License.
@rem

@rem set path for lz4
@IF EXIST tools\bin SET PATH=%PATH%;tools\bin


@if "%DEBUG%" == "" @echo off
@rem ##########################################################################
@rem
@rem  Gradle startup script for Windows
@rem
@rem ##########################################################################

@rem Set local scope for the variables with windows NT shell
if "%OS%"=="Windows_NT" setlocal

set DIRNAME=%~dp0
if "%DIRNAME%" == "" set DIRNAME=.
set APP_BASE_NAME=%~n0
set APP_HOME=%DIRNAME%

@rem Resolve any "." and ".." in APP_HOME to make it shorter.
for %%i in ("%APP_HOME%") do set APP_HOME=%%~fi

@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
set DEFAULT_JVM_OPTS="-Xmx64m" "-Xms64m"

@rem Find java.exe
if defined JAVA_HOME goto findJavaFromJavaHome

set JAVA_EXE=java.exe
%JAVA_EXE% -version >NUL 2>&1
if "%ERRORLEVEL%" == "0" goto execute

echo.
echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.
echo.
echo Please set the JAVA_HOME variable in your environment to match the
echo location of your Java installation.

goto fail

:findJavaFromJavaHome
set JAVA_HOME=%JAVA_HOME:"=%
set JAVA_EXE=%JAVA_HOME%/bin/java.exe

if exist "%JAVA_EXE%" goto execute

echo.
echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%
echo.
echo Please set the JAVA_HOME variable in your environment to match the
echo location of your Java installation.

goto fail

:execute
@rem Setup the command line

set CLASSPATH=%APP_HOME%\gradle\wrapper\gradle-wrapper.jar


@rem Execute Gradle
"%JAVA_EXE%" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% "-Dorg.gradle.appname=%APP_BASE_NAME%" -classpath "%CLASSPATH%" org.gradle.wrapper.GradleWrapperMain %*

:end
@rem End local scope for the variables with windows NT shell
if "%ERRORLEVEL%"=="0" goto mainEnd

:fail
rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of
rem the _cmd.exe /c_ return code!
if  not "" == "%GRADLE_EXIT_CONSOLE%" exit 1
exit /b 1

:mainEnd
if "%OS%"=="Windows_NT" endlocal

:omega

```

`helper/build.gradle.kts`:

```kts
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import org.jetbrains.kotlin.gradle.tasks.KotlinCompile

plugins {
    kotlin("jvm") version "1.8.0"
    `java-library`
    application
}

repositories {
    mavenCentral()
}

dependencies {
    constraints {
        implementation("org.jetbrains.kotlin:kotlin-stdlib-jdk8")
    }
    //kotlin
    implementation(platform("org.jetbrains.kotlin:kotlin-bom"))
    implementation("org.jetbrains.kotlin:kotlin-stdlib-jdk8")
    implementation("org.jetbrains.kotlin:kotlin-reflect")

    implementation("cc.cfig:io:0.2")
    implementation("com.google.guava:guava:31.1-jre")
    implementation("ch.qos.logback:logback-classic:1.2.11")
    implementation("org.apache.commons:commons-exec:1.3")
    implementation("org.bouncycastle:bcprov-jdk15on:1.70")
    implementation("org.bouncycastle:bcpkix-jdk15on:1.70") //org.bouncycastle.pkcs
    implementation("org.apache.commons:commons-compress:1.21")
    implementation("org.tukaani:xz:1.9")
    implementation("com.github.freva:ascii-table:1.2.0")

    testImplementation("org.jetbrains.kotlin:kotlin-test")
    testImplementation("org.jetbrains.kotlin:kotlin-test-junit")
    testImplementation("com.fasterxml.jackson.core:jackson-annotations:2.13.3")
    testImplementation("com.fasterxml.jackson.core:jackson-databind:2.13.3")
}

tasks.withType<KotlinCompile>().all {
    kotlinOptions {
        freeCompilerArgs += "-opt-in=kotlin.RequiresOptIn"
        freeCompilerArgs += "-opt-in=kotlin.ExperimentalUnsignedTypes"
        jvmTarget = "17"
    }
}

application {
    mainClass.set("cfig.helper.LauncherKt")
}
tasks {
    jar {
        manifest {
            attributes["Implementation-Title"] = "Helper"
            attributes["Main-Class"] = "cfig.helper.LauncherKt"
        }
        from(configurations.runtimeClasspath.get().map({ if (it.isDirectory) it else zipTree(it) }))
        excludes.addAll(mutableSetOf("META-INF/*.RSA", "META-INF/*.SF", "META-INF/*.DSA"))
        duplicatesStrategy = DuplicatesStrategy.EXCLUDE
    }
    test {
        testLogging {
            showExceptions = true
            showStackTraces = true
        }
    }
}

```

`helper/src/main/kotlin/cfig/helper/AndroidHelper.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.helper

import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory

class AndroidHelper {
    companion object {
        private val log = LoggerFactory.getLogger(AndroidHelper::class.java)

        fun signFile(signer: String,
                     inFile: String,
                     outFile: String,
                     pemKey: String = "aosp/security/testkey.x509.pem",
                     pk8Key: String = "aosp/security/testkey.pk8") {
            var cmd = "java -Xmx2048m -jar $signer "
            cmd += " -w "
            cmd += " $pemKey "
            cmd += " $pk8Key "
            cmd += " $inFile "
            cmd += " $outFile "
            log.info("signFile: $cmd")
            DefaultExecutor().execute(CommandLine.parse(cmd))
        }
    }
}

```

`helper/src/main/kotlin/cfig/helper/CryptoHelper.kt`:

```kt
@file:Suppress("JAVA_MODULE_DOES_NOT_EXPORT_PACKAGE")

package cfig.helper

import cc.cfig.io.Struct
import com.google.common.math.BigIntegerMath
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.ExecuteException
import org.apache.commons.exec.PumpStreamHandler
import org.bouncycastle.pkcs.PKCS10CertificationRequest
import org.bouncycastle.util.io.pem.PemReader
import org.slf4j.LoggerFactory
import java.io.*
import java.math.BigInteger
import java.math.RoundingMode
import java.security.*
import java.security.cert.Certificate
import java.security.cert.CertificateFactory
import java.security.spec.PKCS8EncodedKeySpec
import java.security.spec.RSAPrivateKeySpec
import java.security.spec.RSAPublicKeySpec
import java.security.spec.X509EncodedKeySpec
import java.util.*
import javax.crypto.Cipher
import kotlin.reflect.KClass

class CryptoHelper {
    enum class KeyFormat {
        PEM,  //header + metadata + base64 der
        DER, // der format
    }

    class KeyBox(val fmt: KeyFormat, val clazz: KClass<*>, val key: Any) {
        companion object {
            fun parse4(data: ByteArray): KeyBox {
                var ret: Any = false
                var retClazz: KClass<*>

                val p = PemReader(InputStreamReader(ByteArrayInputStream(data))).readPemObject()
                if (p != null) {
                    log.debug("parse PEM: " + p.type)
                    ret = when (p.type) {
                        "RSA PUBLIC KEY", "PUBLIC KEY" -> {
                            try {
                                retClazz = org.bouncycastle.asn1.pkcs.RSAPublicKey::class
                                org.bouncycastle.asn1.pkcs.RSAPublicKey.getInstance(p.content) as org.bouncycastle.asn1.pkcs.RSAPublicKey
                            } catch (e: Exception) {
                                val keySpec = X509EncodedKeySpec(p.content)
                                retClazz = java.security.interfaces.RSAPublicKey::class
                                KeyFactory.getInstance("RSA")
                                    .generatePublic(keySpec) as java.security.interfaces.RSAPublicKey
                            }
                        }
                        "RSA PRIVATE KEY", "PRIVATE KEY" -> {
                            try {
                                retClazz = org.bouncycastle.asn1.pkcs.RSAPrivateKey::class
                                org.bouncycastle.asn1.pkcs.RSAPrivateKey.getInstance(p.content) as org.bouncycastle.asn1.pkcs.RSAPrivateKey
                            } catch (e: Exception) {
                                retClazz = sun.security.rsa.RSAPrivateCrtKeyImpl::class
                                val keySpec = PKCS8EncodedKeySpec(p.content)
                                KeyFactory.getInstance("RSA")
                                    .generatePrivate(keySpec) as sun.security.rsa.RSAPrivateCrtKeyImpl
                            }
                        }
                        "CERTIFICATE REQUEST" -> {
                            retClazz = PKCS10CertificationRequest::class
                            PKCS10CertificationRequest(p.content)
                        }
                        "CERTIFICATE" -> {
                            retClazz = Certificate::class
                            CertificateFactory.getInstance("X.509").generateCertificate(ByteArrayInputStream(p.content))
                        }
                        else -> throw IllegalArgumentException("unsupported type: ${p.type}")
                    }
                    return KeyBox(KeyFormat.PEM, retClazz, ret)
                } else {
                    var bSuccess = false
                    //try 1
                    try {
                        val spec = PKCS8EncodedKeySpec(data)
                        val privateKey = KeyFactory.getInstance("RSA").generatePrivate(spec)
                        log.debug("Parse PKCS8:Private")
                        ret = privateKey
                        bSuccess = true
                    } catch (e: java.security.spec.InvalidKeySpecException) {
                        log.info("not PKCS8:Private")
                    }
                    if (bSuccess) return KeyBox(
                        KeyFormat.DER,
                        PrivateKey::class,
                        ret
                    )
                    //try 2
                    try {
                        log.debug("Parse X509:Public")
                        val spec = X509EncodedKeySpec(data)
                        ret = KeyFactory.getInstance("RSA").generatePublic(spec)
                        bSuccess = true
                    } catch (e: java.security.spec.InvalidKeySpecException) {
                        log.debug(e.toString())
                        log.debug("not X509:Public")
                    }
                    if (bSuccess) return KeyBox(KeyFormat.DER, String::class, ret)

                    //try 3: jks
                    try {
                        val envPassword = System.getProperty("password") ?: "secretpassword"
                        log.warn("trying with password=$envPassword")
                        val ks = KeyStore.getInstance("JKS")
                        ks.load(ByteArrayInputStream(data), envPassword.toCharArray())
                        ret = ks
                        bSuccess = true
                    } catch (e: IOException) {
                        if (e.toString().contains("Keystore was tampered with, or password was incorrect")) {
                            log.info("JKS password wrong #1")
                            bSuccess = false
                            ret = KeyStore.getInstance("JKS")
                        }
                        if (e.toString().contains("keystore password was incorrect")) {
                            log.info("JKS password wrong #2")
                            bSuccess = false
                            ret = KeyStore.getInstance("JKS")
                        }
                    }
                    //at last
                    return KeyBox(KeyFormat.DER, String::class, ret)
                }
            }

            fun getPemContent(keyText: String): ByteArray {
                val publicKeyPEM = keyText
                    .replace("-----BEGIN PUBLIC KEY-----", "")
                    .replace("-----END PUBLIC KEY-----", "")
                    .replace("-----BEGIN RSA PRIVATE KEY-----", "")
                    .replace("-----END RSA PRIVATE KEY-----", "")
                    .replace(System.lineSeparator().toRegex(), "")
                    .replace("\n", "")
                    .replace("\r", "")
                return Base64.getDecoder().decode(publicKeyPEM)
            }

            /*
              in: modulus, public expo
              out: PublicKey

              in: modulus, private expo
              out: PrivateKey
            */
            fun makeKey(modulus: BigInteger, exponent: BigInteger, isPublicExpo: Boolean): Any {
                return if (isPublicExpo) {
                    KeyFactory.getInstance("RSA").generatePublic(RSAPublicKeySpec(modulus, exponent))
                } else {
                    KeyFactory.getInstance("RSA").generatePrivate(RSAPrivateKeySpec(modulus, exponent))
                }
            }


            /*
                read RSA private key
                assert exp == 65537
                num_bits = log2(modulus)

                @return: AvbRSAPublicKeyHeader formatted bytearray
                        https://android.googlesource.com/platform/external/avb/+/master/libavb/avb_crypto.h#158
                from avbtool::encode_rsa_key()
             */
            fun encodeRSAkey(rsa: org.bouncycastle.asn1.pkcs.RSAPrivateKey): ByteArray {
                require(65537.toBigInteger() == rsa.publicExponent)
                val numBits: Int = BigIntegerMath.log2(rsa.modulus, RoundingMode.CEILING)
                require(rsa.modulus.bitLength() == numBits)
                val b = BigInteger.valueOf(2).pow(32)
                val n0inv = b.minus(rsa.modulus.modInverse(b)).toLong()
                val rrModn = BigInteger.valueOf(4).pow(numBits).rem(rsa.modulus).toByteArray().let {
                    it.sliceArray(it.size - numBits/8 until it.size)
                }
                val unsignedModulo = rsa.modulus.toByteArray().let {
                    it.sliceArray(it.size - numBits/8 until it.size)
                }
                return Struct("!II${numBits / 8}b${numBits / 8}b").pack(
                    numBits,
                    n0inv,
                    unsignedModulo,
                    rrModn
                )
            }

            fun decodeRSAkey(key: ByteArray): java.security.interfaces.RSAPublicKey {
                val ret = Struct("!II").unpack(ByteArrayInputStream(key))
                val numBits = (ret[0] as UInt).toInt()
                val n0inv = (ret[1] as UInt).toLong()
                val ret2 = Struct("!II${numBits / 8}b${numBits / 8}b").unpack(ByteArrayInputStream(key))
                val unsignedModulo = ret2[2] as ByteArray
                val rrModn = BigInteger(ret2[3] as ByteArray)
                log.debug("n0inv=$n0inv, unsignedModulo=${Helper.toHexString(unsignedModulo)}, rrModn=$rrModn")
                val exponent = 65537L
                val modulus = BigInteger(Helper.join(Struct("x").pack(0), unsignedModulo))
                val keySpec = RSAPublicKeySpec(modulus, BigInteger.valueOf(exponent))
                return KeyFactory.getInstance("RSA").generatePublic(keySpec) as java.security.interfaces.RSAPublicKey
            }

            fun decodePem(keyText: String): ByteArray {
                val publicKeyPEM = keyText
                    .replace("-----BEGIN .*-----".toRegex(), "")
                    .replace(System.lineSeparator().toRegex(), "")
                    .replace("\n", "")
                    .replace("\r", "")
                    .replace("-----END .*-----".toRegex(), "")
                return Base64.getDecoder().decode(publicKeyPEM)
            }
        } //end-companion
    }

    class Hasher {
        companion object {
            fun pyAlg2java(alg: String): String {
                return when (alg) {
                    "sha1" -> "sha-1"
                    "sha224" -> "sha-224"
                    "sha256" -> "sha-256"
                    "sha384" -> "sha-384"
                    "sha512" -> "sha-512"
                    else -> throw IllegalArgumentException("unknown algorithm: [$alg]")
                }
            }

            /*
                openssl dgst -sha256 <file>
            */
            fun sha256(inData: ByteArray): ByteArray {
                return MessageDigest.getInstance("SHA-256").digest(inData)
            }

            fun hash(ds: Dumpling<*>, coordinates: List<Pair<Long, Long>>, algorithm: String): ByteArray {
                require(coordinates.isNotEmpty())
                coordinates.forEach {
                    require(it.first >= 0 && it.second > 0)
                }
                return MessageDigest.getInstance(algorithm).let { md ->
                    coordinates.forEach { coordinate ->
                        ds.getInputStream().use { fis ->
                            fis.skip(coordinate.first)
                            val ibs = 1024 * 1024
                            val buffer = ByteArray(ibs)
                            var bytesRemaining = coordinate.second
                            while (bytesRemaining > 0) {
                                log.debug("Remain $bytesRemaining, reading ...")
                                val bytesRead = fis.read(buffer)
                                if (bytesRemaining > ibs) {
                                    check(bytesRead == ibs)
                                    md.update(buffer, 0, bytesRead)
                                } else {
                                    check(bytesRead >= bytesRemaining)
                                    md.update(buffer, 0, bytesRemaining.toInt())
                                }
                                bytesRemaining -= bytesRead
                                log.debug("Read $bytesRead, remain $bytesRemaining")
                            }
                        }
                    }
                    md
                }.digest()
            }

            fun hash(file: String, algorithm: String): ByteArray {
                return hash(Dumpling(file), listOf(Pair(0, File(file).length())), algorithm)
            }

            fun hash(ds: Dumpling<*>, algorithm: String): ByteArray {
                return hash(ds, listOf(Pair(0, ds.getLength())), algorithm)
            }
        }
    }

    class Signer {
        companion object {
            /* inspired by
             https://stackoverflow.com/questions/40242391/how-can-i-sign-a-raw-message-without-first-hashing-it-in-bouncy-castle
             "specifying Cipher.ENCRYPT mode or Cipher.DECRYPT mode doesn't make a difference;
                  both simply perform modular exponentiation"

            python counterpart:
              import Crypto.PublicKey.RSA
              key = Crypto.PublicKey.RSA.construct((modulus, exponent))
              vRet = key.verify(decode_long(padding_and_digest), (decode_long(sig_blob), None))
              print("verify padded digest: %s" % binascii.hexlify(padding_and_digest))
              print("verify sig: %s" % binascii.hexlify(sig_blob))
              print("X: Verify: %s" % vRet)
             */
            fun rawRsa(key: java.security.Key, data: ByteArray): ByteArray {
                return Cipher.getInstance("RSA/ECB/NoPadding").let { cipher ->
                    cipher.init(Cipher.ENCRYPT_MODE, key)
                    cipher.update(data)
                    cipher.doFinal()
                }
            }

            fun rawSignOpenSsl(keyPath: String, data: ByteArray): ByteArray {
                log.debug("raw input: " + Helper.toHexString(data))
                log.debug("Raw sign data size = ${data.size}, key = $keyPath")
                var ret = byteArrayOf()
                val exe = DefaultExecutor()
                val stdin = ByteArrayInputStream(data)
                val stdout = ByteArrayOutputStream()
                val stderr = ByteArrayOutputStream()
                exe.streamHandler = PumpStreamHandler(stdout, stderr, stdin)
                try {
                    exe.execute(CommandLine.parse("openssl rsautl -sign -inkey $keyPath -raw"))
                    ret = stdout.toByteArray()
                    log.debug("Raw signature size = " + ret.size)
                } catch (e: ExecuteException) {
                    log.error("Execute error")
                } finally {
                    log.debug("OUT: " + Helper.toHexString(stdout.toByteArray()))
                    log.debug("ERR: " + String(stderr.toByteArray()))
                }

                if (ret.isEmpty()) throw RuntimeException("raw sign failed")

                return ret
            }

            fun rsa(inData: ByteArray, inKey: java.security.PrivateKey): ByteArray {
                return Cipher.getInstance("RSA").let {
                    it.init(Cipher.ENCRYPT_MODE, inKey)
                    it.doFinal(inData)
                }
            }

            fun sha256rsa(inData: ByteArray, inKey: java.security.PrivateKey): ByteArray {
                return rsa(Hasher.sha256(inData), inKey)
            }
        }
    }

    companion object {
        private val log = LoggerFactory.getLogger(CryptoHelper::class.java)
        fun listAll() {
            Security.getProviders().forEach {
                val sb = StringBuilder("Provider: " + it.name + "{")
                it.stringPropertyNames().forEach { key ->
                    sb.append(" (k=" + key + ",v=" + it.getProperty(key) + "), ")
                }
                sb.append("}")
                log.info(sb.toString())
            }

            for ((i, item) in Security.getAlgorithms("Cipher").withIndex()) {
                log.info("Cipher: $i -> $item")
            }
        }
    }
}

```

`helper/src/main/kotlin/cfig/helper/Dumpling.kt`:

```kt
package cfig.helper

import java.io.ByteArrayInputStream
import java.io.File
import java.io.FileInputStream
import java.io.InputStream

class Dumpling<in T>(private val filling: T, private val label: String? = null) {
    fun getLabel(): String {
        return label ?: getName()
    }

    fun getName(): String {
        return if (filling is String) "FILE:$filling" else "ByteArray"
    }

    fun getInputStream(): InputStream {
        return when (filling) {
            is String -> {
                FileInputStream(filling)
            }
            is ByteArray -> {
                ByteArrayInputStream(filling)
            }
            else -> {
                throw IllegalArgumentException("type ${filling!!::class} is not supported")
            }
        }
    }

    fun getLength(): Long {
        return when (filling) {
            is String -> {
                File(filling).length()
            }
            is ByteArray -> {
                filling.size.toLong()
            }
            else -> {
                throw IllegalArgumentException("type ${filling!!::class} is not supported")
            }
        }
    }

    @Throws(IllegalArgumentException::class)
    fun readFully(range: LongRange): ByteArray {
        when (filling) {
            is String -> {
                return ByteArray(range.count()).apply {
                    FileInputStream(filling).use { fis ->
                        fis.skip(range.first)
                        fis.read(this)
                    }
                }
            }
            is ByteArray -> {
                return filling.sliceArray(range.first.toInt()..range.last.toInt())
            }
            else -> {
                throw IllegalArgumentException("type ${filling!!::class} is not supported")
            }
        }
    }

    @Throws(IllegalArgumentException::class)
    fun readFully(loc: Pair<Long, Int>): ByteArray {
        when (filling) {
            is String -> {
                return ByteArray(loc.second).apply {
                    FileInputStream(filling).use { fis ->
                        if (loc.first < 0) {
                            fis.skip(getLength() + loc.first)
                        } else {
                            fis.skip(loc.first)
                        }
                        fis.read(this)
                    }
                }
            }
            is ByteArray -> {
                val subRangeStart = if (loc.first < 0) {
                    (getLength() + loc.first).toInt()
                } else {
                    loc.first.toInt()
                }
                return filling.sliceArray(subRangeStart until (subRangeStart + loc.second).toInt())
            }
            else -> {
                throw IllegalArgumentException("type ${filling!!::class} is not supported")
            }
        }
    }
}

```

`helper/src/main/kotlin/cfig/helper/Helper.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.helper

import cc.cfig.io.Struct
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.ExecuteException
import org.apache.commons.exec.PumpStreamHandler
import org.slf4j.LoggerFactory
import java.io.*
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.file.attribute.PosixFilePermission
import java.security.MessageDigest
import java.util.*
import kotlin.math.pow
import java.text.StringCharacterIterator
import java.text.CharacterIterator

class Helper {
    data class Slice(
        var srcFile: String,
        var offset: Int,
        var length: Int,
        var dumpFile: String
    )

    companion object {
        private val gcfg: Properties = Properties().apply {
            load(Helper::class.java.classLoader.getResourceAsStream("general.cfg"))
        }

        fun prop(k: String): String {
            return gcfg.getProperty(k)
        }

        fun joinWithNulls(vararg source: ByteArray?): ByteArray {
            val baos = ByteArrayOutputStream()
            for (src in source) {
                src?.let {
                    if (src.isNotEmpty()) baos.write(src)
                }
            }
            return baos.toByteArray()
        }

        fun ByteArray.paddingWith(pageSize: UInt, paddingHead: Boolean = false): ByteArray {
            val paddingNeeded = round_to_multiple(this.size.toUInt(), pageSize) - this.size.toUInt()
            return if (paddingNeeded > 0u) {
                if (paddingHead) {
                    join(Struct("${paddingNeeded}x").pack(null), this)
                } else {
                    join(this, Struct("${paddingNeeded}x").pack(null))
                }
            } else {
                this
            }
        }

        fun join(vararg source: ByteArray): ByteArray {
            val baos = ByteArrayOutputStream()
            for (src in source) {
                if (src.isNotEmpty()) baos.write(src)
            }
            return baos.toByteArray()
        }

        fun toHexString(inData: UByteArray): String {
            val sb = StringBuilder()
            for (i in inData.indices) {
                sb.append(Integer.toString((inData[i].toInt().and(0xff)) + 0x100, 16).substring(1))
            }
            return sb.toString()
        }

        fun toHexString(inData: ByteArray): String {
            val sb = StringBuilder()
            for (i in inData.indices) {
                sb.append(Integer.toString((inData[i].toInt().and(0xff)) + 0x100, 16).substring(1))
            }
            return sb.toString()
        }

        fun fromHexString(s: String): ByteArray {
            val len = s.length
            val data = ByteArray(len / 2)
            var i = 0
            while (i < len) {
                data[i / 2] = ((Character.digit(s[i], 16) shl 4) + Character.digit(s[i + 1], 16)).toByte()
                i += 2
            }
            return data
        }

        fun extractFile(s: Slice) {
            return extractFile(s.srcFile, s.dumpFile, s.offset.toLong(), s.length)
        }

        private fun transport(src: RandomAccessFile, sink: DataOutput, length: Int) {
            val ibs = 1024 * 1024
            val buffer = ByteArray(ibs)
            var bytesRemaining = length
            while (bytesRemaining > 0) {
                log.debug("Remain $bytesRemaining, reading ...")
                val bytesRead = src.read(buffer)
                if (bytesRemaining > ibs) {
                    check(bytesRead == ibs) { "bytesRemaining=$bytesRemaining, ibs=$ibs, bytesRead=$bytesRead" }
                    sink.write(buffer)
                } else {
                    check(bytesRead >= bytesRemaining)
                    sink.write(buffer, 0, bytesRemaining)
                }
                bytesRemaining -= bytesRead
                log.debug("Read $bytesRead, remain $bytesRemaining")
            }
        }

        fun extractFile(fileName: String, outImgName: String, offset: Long, length: Int) {
            if (0 == length) {
                return
            }
            RandomAccessFile(fileName, "r").use { inRaf ->
                RandomAccessFile(outImgName, "rw").use { outRaf ->
                    inRaf.seek(offset)
                    transport(inRaf, outRaf, length)
                }
            }
        }

        fun round_to_multiple(size: UInt, page: UInt): UInt {
            val remainder = size % page
            return if (remainder == 0U) {
                size
            } else {
                size + page - remainder
            }
        }

        fun round_to_multiple(size: Long, page: Long): Long {
            val remainder = size % page
            return if (remainder == 0L) {
                size
            } else {
                size + page - remainder
            }
        }

        fun round_to_multiple(size: Int, page: Int): Int {
            val remainder = size % page
            return if (remainder == 0) {
                size
            } else {
                size + page - remainder
            }
        }

        fun round_to_pow2(num: Long): Long {
            return 2.0.pow((num - 1).toBigInteger().bitLength().toDouble()).toLong()
        }

        fun dumpToFile(dumpFile: String, data: ByteArray) {
            log.info("Dumping data to $dumpFile ...")
            FileOutputStream(dumpFile, false).use { fos ->
                fos.write(data)
            }
            log.info("Dumping data to $dumpFile done")
        }

        fun String.deleteIfExists() {
            if (File(this).exists()) {
                log.info("deleting $this")
                File(this).delete()
            }
        }

        fun String.check_call(inWorkdir: String? = null): Boolean {
            val ret: Boolean
            try {
                val cmd = CommandLine.parse(this)
                log.run {
                    info("CMD: $cmd, workDir: $inWorkdir")
                }
                val exec = DefaultExecutor()
                inWorkdir?.let { exec.workingDirectory = File(it) }
                exec.execute(cmd)
                ret = true
            } catch (e: java.lang.IllegalArgumentException) {
                log.error("$e: can not parse command: [$this]")
                throw e
            } catch (e: ExecuteException) {
                log.error("$e: can not exec command")
                throw e
            } catch (e: IOException) {
                log.error("$e: can not exec command")
                throw e
            }
            return ret
        }

        fun String.check_output(): String {
            val outputStream = ByteArrayOutputStream()
            log.info(this)
            DefaultExecutor().let {
                it.streamHandler = PumpStreamHandler(outputStream)
                it.execute(CommandLine.parse(this))
            }
            log.debug(outputStream.toString().trim())
            return outputStream.toString().trim()
        }

        fun String.pumpRun(): Array<ByteArrayOutputStream> {
            val outStream = ByteArrayOutputStream()
            val errStream = ByteArrayOutputStream()
            log.info("CMD: $this")
            DefaultExecutor().let {
                it.streamHandler = PumpStreamHandler(outStream, errStream)
                it.execute(CommandLine.parse(this))
            }
            log.info("stdout [$outStream]")
            log.info("stderr [$errStream]")
            return arrayOf(outStream, errStream)
        }

        fun powerRun3(cmdline: CommandLine, inputStream: InputStream?): Array<Any> {
            var ret = true
            val outStream = ByteArrayOutputStream()
            val errStream = ByteArrayOutputStream()
            log.info("CMD: $cmdline")
            try {
                DefaultExecutor().let {
                    it.streamHandler = PumpStreamHandler(outStream, errStream, inputStream)
                    it.execute(cmdline)
                }
            } catch (e: ExecuteException) {
                log.error("fail to execute [${cmdline}]")
                ret = false
            }
            log.debug("stdout [$outStream]")
            log.debug("stderr [$errStream]")
            return arrayOf(ret, outStream.toByteArray(), errStream.toByteArray())
        }

        fun powerRun2(cmd: String, inputStream: InputStream?): Array<Any> {
            var ret = true
            val outStream = ByteArrayOutputStream()
            val errStream = ByteArrayOutputStream()
            log.info("CMD: $cmd")
            try {
                DefaultExecutor().let {
                    it.streamHandler = PumpStreamHandler(outStream, errStream, inputStream)
                    it.execute(CommandLine.parse(cmd))
                }
            } catch (e: ExecuteException) {
                log.error("fail to execute [$cmd]")
                ret = false
            }
            log.debug("stdout [$outStream]")
            log.debug("stderr [$errStream]")
            return arrayOf(ret, outStream.toByteArray(), errStream.toByteArray())
        }

        fun powerRun(cmd: String, inputStream: InputStream?): Array<ByteArray> {
            val outStream = ByteArrayOutputStream()
            val errStream = ByteArrayOutputStream()
            log.info("CMD: $cmd")
            try {
                DefaultExecutor().let {
                    it.streamHandler = PumpStreamHandler(outStream, errStream, inputStream)
                    it.execute(CommandLine.parse(cmd))
                }
            } catch (e: ExecuteException) {
                log.error("fail to execute [$cmd]")
            }
            log.debug("stdout [$outStream]")
            log.debug("stderr [$errStream]")
            return arrayOf(outStream.toByteArray(), errStream.toByteArray())
        }

        fun hashFileAndSize(vararg inFiles: String?): ByteArray {
            val md = MessageDigest.getInstance("SHA1")
            for (item in inFiles) {
                if (null == item) {
                    md.update(
                        ByteBuffer.allocate(4).order(ByteOrder.LITTLE_ENDIAN)
                            .putInt(0)
                            .array()
                    )
                    log.debug("update null $item: " + toHexString((md.clone() as MessageDigest).digest()))
                } else {
                    val currentFile = File(item)
                    FileInputStream(currentFile).use { iS ->
                        var byteRead: Int
                        val dataRead = ByteArray(1024)
                        while (true) {
                            byteRead = iS.read(dataRead)
                            if (-1 == byteRead) {
                                break
                            }
                            md.update(dataRead, 0, byteRead)
                        }
                        log.debug("update file $item: " + toHexString((md.clone() as MessageDigest).digest()))
                        md.update(
                            ByteBuffer.allocate(4).order(ByteOrder.LITTLE_ENDIAN)
                                .putInt(currentFile.length().toInt())
                                .array()
                        )
                        log.debug("update SIZE $item: " + toHexString((md.clone() as MessageDigest).digest()))
                    }
                }
            }

            return md.digest()
        }

        fun assertFileEquals(file1: String, file2: String) {
            val hash1 = hashFileAndSize(file1)
            val hash2 = hashFileAndSize(file2)
            log.info("$file1 hash ${toHexString(hash1)}, $file2 hash ${toHexString(hash2)}")
            if (hash1.contentEquals(hash2)) {
                log.info("Hash verification passed: ${toHexString(hash1)}")
            } else {
                log.error("Hash verification failed")
                throw UnknownError("Do not know why hash verification fails, maybe a bug")
            }
        }

        fun modeToPermissions(inMode: Int): Set<PosixFilePermission> {
            var mode = inMode
            mode = mode and Integer.valueOf("7777", 8) //trim to xxxx
            val maxSupportedMode = Integer.valueOf("777", 8) //setgid/setuid/sticky are not supported
            if (mode and maxSupportedMode != mode) {
                throw IOException("Invalid mode(oct): ${Integer.toOctalString(mode)}")
            }
            val allPermissions = PosixFilePermission.values()
            val result: MutableSet<PosixFilePermission> = EnumSet.noneOf(PosixFilePermission::class.java)
            for (i in allPermissions.indices) {
                if (mode and 1 == 1) {
                    result.add(allPermissions[allPermissions.size - i - 1])
                }
                mode = mode shr 1
            }
            return result
        }

        /*
          https://stackoverflow.com/questions/3758606/how-can-i-convert-byte-size-into-a-human-readable-format-in-java
         */
        fun humanReadableByteCountBin(bytes: Long): String {
            val absB = if (bytes == Long.MIN_VALUE) Long.MAX_VALUE else Math.abs(bytes)
            if (absB < 1024) {
                return "$bytes B"
            }
            var value = absB
            val ci: CharacterIterator = StringCharacterIterator("KMGTPE")
            var i = 40
            while (i >= 0 && absB > 0xfffccccccccccccL shr i) {
                value = value shr 10
                ci.next()
                i -= 10
            }
            value *= java.lang.Long.signum(bytes).toLong()
            return String.format("%.1f %ciB", value / 1024.0, ci.current())
        }

        fun readFully(fileName: String, offset: Long, byteCount: Int): ByteArray {
            val data = ByteArray(byteCount).apply {
                FileInputStream(fileName).use { fis ->
                    fis.skip(offset)
                    fis.read(this)
                }
            }
            return data
        }

        fun readFully(data: ByteArray, offset: Long, byteCount: Int): ByteArray {
            return data.sliceArray(offset.toInt()..(offset + byteCount).toInt())
        }

        fun readFully(fileName: String, coordinate: Pair<Long, Int>): ByteArray {
            return readFully(fileName, coordinate.first, coordinate.second)
        }

        fun readFully(data: ByteArray, coordinate: Pair<Long, Int>): ByteArray {
            return readFully(data, coordinate.first, coordinate.second)
        }

        private val log = LoggerFactory.getLogger("Helper")
    }
}

```

`helper/src/main/kotlin/cfig/helper/Launcher.kt`:

```kt
@file:Suppress("JAVA_MODULE_DOES_NOT_EXPORT_PACKAGE")

package cfig.helper

import org.bouncycastle.asn1.ASN1Primitive
import org.bouncycastle.asn1.pkcs.PrivateKeyInfo
import org.bouncycastle.util.io.pem.PemObject
import org.bouncycastle.util.io.pem.PemWriter
import org.slf4j.LoggerFactory
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.io.FileWriter
import java.math.BigInteger
import java.security.KeyFactory
import java.security.KeyPairGenerator
import java.security.spec.RSAPublicKeySpec
import java.util.*
import kotlin.system.exitProcess

class Launcher {
    companion object {
        val allSupportedCommands =
            listOf("genrsa", "toPublicKey", "decodePEM", "toPk8", "toPk1", "toJks", "toCsr", "toCrt").toString()

        private val log = LoggerFactory.getLogger(Launcher::class.java)

        fun getSize(size: Long): String? {
            val kilo = 1024L
            val mega = kilo * kilo
            val giga = mega * kilo
            val tera = giga * kilo
            var s = ""
            val kb: Double = size.toDouble() / kilo
            val mb: Double = kb / kilo
            val gb: Double = mb / kilo
            val tb: Double = gb / kilo
            if (size < kilo) {
                s = "$size Bytes"
            } else if (size in kilo until mega) {
                s = String.format("%.2f", kb) + " KB"
            } else if (size in mega until giga) {
                s = String.format("%.2f", mb) + " MB"
            } else if (size in giga until tera) {
                s = String.format("%.2f", gb) + " GB"
            } else if (size >= tera) {
                s = String.format("%.2f", tb) + " TB"
            }
            return s
        }
    }

    //https://stackoverflow.com/questions/7611383/generating-rsa-keys-in-pkcs1-format-in-java
    private fun dumpPem(pem: PemObject, outFile: String) {
        FileWriter(outFile).use { fw ->
            log.info("Writing ${pem.type}to $outFile")
            PemWriter(fw).use { pw ->
                pw.writeObject(pem)
            }
        }
    }

    private fun dumpPublicKey(n: BigInteger, e: BigInteger, outFile: String) {
        val pubK = KeyFactory.getInstance("RSA").generatePublic(RSAPublicKeySpec(n, e))
        FileWriter(outFile).use { fw ->
            log.info("Writing public key to $outFile")
            PemWriter(fw).use { pw ->
                pw.writeObject(PemObject("RSA PUBLIC KEY", pubK.encoded))
            }
        }
    }

    private fun pk8toPk1(pk8: java.security.PrivateKey): ASN1Primitive {
        return PrivateKeyInfo.getInstance(pk8.encoded).parsePrivateKey().toASN1Primitive()
    }

    fun processCommand(inFile: String, info2: Properties) {
        FileInputStream(inFile).use { fis ->
            info2.load(fis)
        }
        log.warn("CMD=" + info2.getProperty("cmd"))
        val kFile = info2.getProperty("file")

        when (val cmd = info2.getProperty("cmd")) {
            "genrsa" -> {
                val kLen = info2.getProperty("rsa.len").toInt()
                val keyPair = KeyPairGenerator.getInstance("RSA").let {
                    it.initialize(kLen)
                    it.generateKeyPair()
                }
                FileOutputStream(kFile, false).use {
                    it.write(keyPair.private.encoded)
                    log.info("RSA priv key(len=$kLen) written to $kFile.pk8")
                }

                dumpPem(PemObject("RSA PRIVATE KEY", pk8toPk1(keyPair.private).encoded), "$kFile.pem.pk1")

                FileOutputStream("$kFile.pub", false).use {
                    it.write(keyPair.public.encoded)
                    log.info("RSA pub  key(len=$kLen) written to $kFile.pub")
                }
                dumpPem(PemObject("RSA PUBLIC KEY", keyPair.public.encoded), "$kFile.pem.pub")
            }
            "toPub" -> {
                val k = CryptoHelper.KeyBox.parse4(File(kFile).readBytes())
                if (k.key is org.bouncycastle.asn1.pkcs.RSAPrivateKey) {
                    dumpPublicKey(k.key.modulus, k.key.publicExponent, "pub.k")
                } else if (k.key is sun.security.rsa.RSAPrivateCrtKeyImpl) {
                    dumpPublicKey(k.key.modulus, k.key.publicExponent, "pub.k")
                } else {
                    throw IllegalArgumentException("not supported")
                }
            }
            "parse" -> {
                val k = CryptoHelper.KeyBox.parse4(File(kFile).readBytes())
                log.info("fmt=" + k.fmt.toString())
                log.info("clazz=" + k.clazz)
                log.info("key=" + k.key)
            }
            else -> {
                //pass
            }
        } //end-of-cmd-mode
    }

    fun processFile(inFile: String, info2: Properties) {
        val preFile = info2.getProperty("file")
        info2["file"] = (if (preFile == null) "" else "$preFile,") + File(inFile).canonicalFile.path
        info2["propFile"] = File(info2.getProperty("file")).name + ".prop"
        val k = CryptoHelper.KeyBox.parse4(File(inFile).readBytes())
        info2["fileType"] = k.fmt
        info2["fileClazz"] = k.clazz
        log.info("Recognized ${k.fmt}: " + k.clazz)
        if (k.key is sun.security.x509.X509CertImpl) {
            val crt = k.key
            val crtSubj = (crt.get("x509.info") as sun.security.x509.X509CertInfo).get("subject").toString()
            val subj2 = crtSubj
                .replace(", ", "/")
                .replace("EMAILADDRESS", "emailAddress")
                .replace("\\s".toRegex(), "")
            info2.setProperty("csr.info", "/$subj2")
        }
        if (k.key is sun.security.rsa.RSAPrivateCrtKeyImpl) {
            val pk8 = k.key
            info2.setProperty("rsa.len", pk8.modulus.bitLength().toString())
            info2["rsa.modulus"] = Helper.toHexString(pk8.modulus.toByteArray())
            info2["rsa.privateExponent"] = Helper.toHexString(pk8.privateExponent.toByteArray())
            info2["rsa.publicExponent"] = Helper.toHexString(pk8.publicExponent.toByteArray())
            info2["rsa.primeP"] = Helper.toHexString(pk8.primeP.toByteArray())
            info2["rsa.primeQ"] = Helper.toHexString(pk8.primeQ.toByteArray())
        }
        if (k.key is org.bouncycastle.asn1.pkcs.RSAPrivateKey) {
            val rsa = k.key
            info2.setProperty("rsa.len", rsa.modulus.bitLength().toString())
            info2["rsa.modulus"] = Helper.toHexString(rsa.modulus.toByteArray())
            info2["rsa.privateExponent"] = Helper.toHexString(rsa.privateExponent.toByteArray())
            info2["rsa.publicExponent"] = Helper.toHexString(rsa.publicExponent.toByteArray())
            info2["rsa.primeP"] = Helper.toHexString(rsa.prime1.toByteArray())
            info2["rsa.primeQ"] = Helper.toHexString(rsa.prime2.toByteArray())
        }

    }
}

fun main(args: Array<String>) {
    val log = LoggerFactory.getLogger("main")
    val allSupportedCommands =
        listOf("genrsa", "toPublicKey", "decodePEM", "toPk8", "toPk1", "toJks", "toCsr", "toCrt").toString()

    val info2 = Properties().apply {
        this.setProperty("all_cmds", allSupportedCommands)
        this["available_cmds"] = this.getProperty("all_cmds")
        this["cmd"] = ""
        this.setProperty(
            "csr.info", "/C=CN/ST=Shanghai/L=Shanghai/O=XXX/OU=infra/CN=gerrit/emailAddress=webmaster@XX.com"
        )
        this.setProperty("pfx.alias", "androiddebugkey")
        this.setProperty("pfx.password", "somepassword")
    }

    if (args.isEmpty()) {
        info2.setProperty("rsa.len", 4096.toString())
        info2["file"] = "k"
        info2["propFile"] = "run.prop"
        FileOutputStream(info2.getProperty("propFile")).use { fos ->
            info2.store(fos, null)
            log.info("Writing to " + info2.getProperty("propFile"))
        }
        exitProcess(0)
    }

    if (args.size == 1 && File(args[0]).exists() && args[0].endsWith(".prop")) { //cmd mode
        Launcher().processCommand(args[0], info2)
    } else { // file mode
        args.forEachIndexed { index, s ->
            log.warn("[${index + 1}/${args.size}] Processing $s ...")
            Launcher().processFile(s, info2)
        }
        FileOutputStream(info2.getProperty("propFile")).use { fos ->
            info2.setProperty("all_cmds", allSupportedCommands)
            info2.store(fos, null)
            log.info("Writing to " + info2.getProperty("propFile"))
        }
    }
}

```

`helper/src/main/kotlin/cfig/helper/OpenSslHelper.kt`:

```kt
package cfig.helper

import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.slf4j.LoggerFactory
import java.io.File

//https://www.digicert.com/kb/ssl-support/openssl-quick-reference-guide.htm
class OpenSslHelper {
    companion object {
        private val log = LoggerFactory.getLogger(OpenSslHelper::class.java)

        //openssl req -new -newkey rsa:2048 -nodes -keyout server.key -out server.csr -subj "/C=US/ST=Utah/L=Lehi/O=Your Company, Inc./OU=IT/CN=yourdomain.com"\n
        //openssl req -text -in server.csr -noout -verify
        //\"/C=US/ST=Utah/L=Lehi/O=Your Company, Inc./OU=IT/CN=yourdomain.com\"
        fun createCsr(outKey: String, outCsr: String, subj: String, keyLen: Int = 2048) {
            DefaultExecutor().execute(
                CommandLine.parse("openssl req -new -newkey rsa:$keyLen -nodes").apply {
                    addArguments("-keyout $outKey")
                    addArguments("-out $outCsr")
                    addArgument("-subj").addArgument("$subj", false)
                })
            DefaultExecutor().execute(CommandLine.parse("openssl req -text -in $outCsr -noout -verify"))
        }

        fun toJks(
            pk8: String, x509Pem: String,
            outFile: String,
            paramSrcPass: String = "somepassword",
            paramDstPass: String = "somepassword",
            alias: String = "androiddebugkey"
        ) {
            File(outFile).let {
                if (it.exists()) it.delete()
            }
            val privKey = File.createTempFile("key.", ".tmp").let {
                it.deleteOnExit()
                val ret = Helper.powerRun2("openssl pkcs8 -in $pk8 -inform DER -outform PEM -nocrypt", null)
                if (ret[0] as Boolean) {
                    it.writeBytes(ret[1] as ByteArray)
                } else {
                    log.error("stdout: " + String(ret[1] as ByteArray))
                    log.error("stderr: " + String(ret[2] as ByteArray))
                    throw java.lang.RuntimeException()
                }
                it
            }

            val pk12 = File.createTempFile("key.", ".tmp").let {
                it.deleteOnExit()
                val ret = Helper.powerRun2(
                    "openssl pkcs12 -export -in $x509Pem -password pass:$paramSrcPass -inkey ${privKey.path} -name androiddebugkey",
                    null
                )
                if (ret[0] as Boolean) {
                    it.writeBytes(ret[1] as ByteArray)
                } else {
                    log.error("stdout: " + String(ret[1] as ByteArray))
                    log.error("stderr: " + String(ret[2] as ByteArray))
                    throw java.lang.RuntimeException()
                }
                it
            }

            val ret = Helper.powerRun2(
                "keytool -importkeystore " +
                        " -deststorepass $paramDstPass -destkeystore $outFile" +
                        " -srckeystore ${pk12.path} -srcstoretype PKCS12 -srcstorepass $paramSrcPass" +
                        " -alias $alias",
                null
            )
            if (ret[0] as Boolean) {
                log.info("$outFile is ready")
            } else {
                log.error("stdout: " + String(ret[1] as ByteArray))
                log.error("stderr: " + String(ret[2] as ByteArray))
                throw java.lang.RuntimeException()
            }
        }
    }
}
```

`helper/src/main/kotlin/cfig/helper/ZipHelper.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.helper

import cc.cfig.io.Struct
import cfig.helper.Helper.Companion.check_call
import cfig.helper.Helper.Companion.check_output
import org.apache.commons.compress.archivers.zip.ZipArchiveEntry
import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream
import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream
import org.apache.commons.compress.archivers.zip.ZipFile
import org.apache.commons.compress.archivers.zip.ZipMethod
import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream
import org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream
import org.apache.commons.compress.compressors.gzip.GzipCompressorOutputStream
import org.apache.commons.compress.compressors.gzip.GzipParameters
import org.apache.commons.compress.compressors.lzma.LZMACompressorInputStream
import org.apache.commons.compress.compressors.lzma.LZMACompressorOutputStream
import org.apache.commons.compress.compressors.xz.XZCompressorInputStream
import org.apache.commons.compress.compressors.xz.XZCompressorOutputStream
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.PumpStreamHandler
import org.slf4j.LoggerFactory
import org.tukaani.xz.XZFormatException
import java.io.*
import java.lang.RuntimeException
import java.net.URI
import java.nio.file.FileSystems
import java.nio.file.Files
import java.nio.file.StandardCopyOption
import java.util.zip.GZIPInputStream
import java.util.zip.GZIPOutputStream
import java.util.zip.ZipException
import kotlin.reflect.full.declaredFunctions
import kotlin.reflect.jvm.isAccessible

class ZipHelper {
    class ZipEntryRecipe(val data: ByteArray, val name: String, val method: ZipMethod)

    companion object {
        private val log = LoggerFactory.getLogger("ZipHelper")

        /*
            unzip(): unzip fileName to outDir
         */
        fun unzip(fileName: String, outDir: String) {
            log.info("unzip: $fileName --> $outDir")
            if (File(outDir).exists()) {
                if (!File(outDir).isDirectory) {
                    throw RuntimeException("$outDir exists but is not directory")
                }
            } else {
                log.info("Creating $outDir ...")
                File(outDir).mkdirs()
            }
            ZipArchiveInputStream(FileInputStream(fileName)).use { zis ->
                while (true) {
                    val entry = zis.nextZipEntry ?: break
                    when {
                        entry.isDirectory -> {
                            val entryOut = File(outDir + "/" + entry.name)
                            entryOut.mkdir()
                            log.debug("Unzipping[d]: ${entry.name}")
                        }
                        entry.isUnixSymlink -> {
                            throw IllegalArgumentException("this should not happen: Found dir ${entry.name}")
                        }
                        else -> {
                            val entryOut = File(outDir + "/" + entry.name)
                            log.debug("Unzipping[f]: ${entry.name}")
                            FileOutputStream(entryOut).use {
                                zis.copyTo(it)
                            }
                        }
                    }
                }
            }
            log.info("unzip: $fileName --> $outDir Done.")
        }

        fun zipDelete(zipFile: File, entryName: String) {
            val zipProperties = mutableMapOf("create" to "false")
            val zipURI = URI.create("jar:file:" + zipFile.canonicalPath)
            FileSystems.newFileSystem(zipURI, zipProperties).use { zipfs ->
                val entryPath = zipfs.getPath(entryName)
                log.info("deleting " + entryPath.toUri() + " from ZIP File ${zipFile.name}")
                Files.delete(entryPath)
            }
        }

        fun zipClone(inFile: String, outFile: String) {
            ZipFile(inFile).use { zf ->
                val zaos = ZipArchiveOutputStream(FileOutputStream(outFile))
                val e = zf.entries
                while (e.hasMoreElements()) {
                    val entry = e.nextElement()
                    zaos.putArchiveEntry(entry)
                    zf.getInputStream(entry).copyTo(zaos)
                    zaos.closeArchiveEntry()
                }
                zaos.finish()
                zaos.close()
            }
        }

        fun zipEdit(inFile: String, entryRecipe: ZipEntryRecipe) {
            val tmpFile = File.createTempFile("edit.", ".zip")
            log.info("transforming $inFile --> $tmpFile ...")
            ZipFile(inFile).use { zf ->
                val zaos = ZipArchiveOutputStream(tmpFile)
                val e = zf.entries
                if (zf.getEntry(entryRecipe.name) == null) {
                    log.info("adding new entry [${entryRecipe.name}(${entryRecipe.method})] into [${tmpFile.canonicalPath}]")
                    val entry = ZipArchiveEntry(entryRecipe.name)
                    entry.method = entryRecipe.method.ordinal
                    zaos.putArchiveEntry(entry)
                    ByteArrayInputStream(entryRecipe.data).copyTo(zaos)
                }

                while (e.hasMoreElements()) {
                    val entry = e.nextElement()
                    zaos.putArchiveEntry(entry)
                    if (entry.name == entryRecipe.name) {
                        log.info("modifying existent entry [${entryRecipe.name}(${entryRecipe.method})] into [${tmpFile.canonicalPath}]")
                        ByteArrayInputStream(entryRecipe.data).copyTo(zaos)
                    } else {
                        log.debug("cloning entry ${entry.name} ...")
                        zf.getInputStream(entry).copyTo(zaos)
                    }
                    zaos.closeArchiveEntry()
                }

                zaos.finish()
                zaos.close()
            }
            log.info("transforming $inFile --> ${tmpFile.name} done")
            Files.move(tmpFile.toPath(), File(inFile).toPath(), StandardCopyOption.REPLACE_EXISTING)
            log.info("renaming ${tmpFile.canonicalPath} --> $inFile done")
        }


        /*
            https://github.com/python/cpython/blob/3.8/Lib/zipfile.py
            The "local file header" structure, magic number, size, and indices
            (section V.A in the format document)
            structFileHeader = "<4s2B4HL2L2H"
            stringFileHeader = b"PK\003\004"
            sizeFileHeader = struct.calcsize(structFileHeader)
        */
        fun ZipArchiveEntry.getEntryOffset(): Long {
            val zipFileHeaderSize = Struct("<4s2B4HL2L2H").calcSize()
            val funGetLocalHeaderOffset = ZipArchiveEntry::class.declaredFunctions.filter { funcItem ->
                funcItem.name == "getLocalHeaderOffset"
            }[0]
            funGetLocalHeaderOffset.isAccessible = true
            val headerOffset = funGetLocalHeaderOffset.call(this) as Long
            val offset: Long = headerOffset + zipFileHeaderSize + this.localFileDataExtra.size + this.name.length
            log.debug("headerOffset = $headerOffset")
            log.debug("calcSize: $zipFileHeaderSize")
            return offset
        }

        fun ZipFile.dumpEntry(entryName: String, outFile: File, ignoreError: Boolean = false) {
            val entry = this.getEntry(entryName)
            if (entry != null) {
                log.info("dumping entry: $entryName -> $outFile")
                FileOutputStream(outFile).use { outStream ->
                    this.getInputStream(entry).copyTo(outStream)
                }
            } else {
                if (ignoreError) {
                    log.info("dumping entry: $entryName : entry not found, skip")
                } else {
                    throw IllegalArgumentException("$entryName doesn't exist")
                }
            }
        }

        fun ZipArchiveOutputStream.pack(
            inFile: File,
            entryName: String,
            zipMethod: ZipMethod = ZipMethod.DEFLATED
        ) {
            log.info("packing $entryName($zipMethod) from file $inFile (size=${inFile.length()} ...")
            val entry = ZipArchiveEntry(inFile, entryName)
            entry.method = zipMethod.ordinal
            this.putArchiveEntry(entry)
            Files.newInputStream(inFile.toPath()).copyTo(this)
            this.closeArchiveEntry()
        }

        fun ZipArchiveOutputStream.pack(
            inStream: InputStream,
            entryName: String,
            zipMethod: ZipMethod = ZipMethod.DEFLATED
        ) {
            log.info("packing $entryName($zipMethod) from input stream (size=unknown...")
            val entry = ZipArchiveEntry(entryName)
            entry.method = zipMethod.ordinal
            this.putArchiveEntry(entry)
            inStream.copyTo(this)
            this.closeArchiveEntry()
        }

        /*
        LZMACompressorInputStream() may raise OOM sometimes, like this:
            Caused by: java.lang.OutOfMemoryError: Java heap space
            at org.tukaani.xz.ArrayCache.getByteArray(Unknown Source)
            at org.tukaani.xz.lz.LZDecoder.<init>(Unknown Source)
            at org.tukaani.xz.LZMAInputStream.initialize(Unknown Source)
        So we catch it explicitly.
         */
        fun isLzma(compressedFile: String): Boolean {
            return try {
                FileInputStream(compressedFile).use { fis ->
                    LZMACompressorInputStream(fis).use {
                    }
                }
                true
            } catch (e: IOException) {
                false
            } catch (e: OutOfMemoryError) {
                false
            }
        }

        fun lzma(compressedFile: String, fis: InputStream) {
            log.info("Compress(lzma) ... ")
            FileOutputStream(compressedFile).use { fos ->
                LZMACompressorOutputStream(fos).use { gos ->
                    val buffer = ByteArray(1024)
                    while (true) {
                        val bytesRead = fis.read(buffer)
                        if (bytesRead <= 0) break
                        gos.write(buffer, 0, bytesRead)
                    }
                }
            }
            log.info("compress(lzma) done: $compressedFile")
        }

        /*
            @function: lzcat compressedFile > decompressedFile
         */
        fun lzcat(compressedFile: String, decompressedFile: String) {
            FileInputStream(compressedFile).use { fileIn ->
                LZMACompressorInputStream(fileIn).use { lzmaInputStream ->
                    FileOutputStream(decompressedFile).use { fileOutputStream ->
                        val buffer = ByteArray(1024)
                        while (true) {
                            val bytesRead = lzmaInputStream.read(buffer)
                            if (bytesRead <= 0) break
                            fileOutputStream.write(buffer, 0, bytesRead)
                        }
                    }
                }
            }
            log.info("decompress(lzma) done: $compressedFile -> $decompressedFile")
        }

        fun isXz(compressedFile: String): Boolean {
            return try {
                FileInputStream(compressedFile).use { fis ->
                    XZCompressorInputStream(fis).use {
                    }
                }
                true
            } catch (e: XZFormatException) {
                false
            }
        }

        fun xz(compressedFile: String, fis: InputStream) {
            log.info("Compress(xz) ... ")
            FileOutputStream(compressedFile).use { fos ->
                XZCompressorOutputStream(fos).use { gos ->
                    val buffer = ByteArray(1024)
                    while (true) {
                        val bytesRead = fis.read(buffer)
                        if (bytesRead <= 0) break
                        gos.write(buffer, 0, bytesRead)
                    }
                }
            }
            log.info("compress(xz) done: $compressedFile")
        }

        /*
            @function: xzcat compressedFile > decompressedFile
         */
        fun xzcat(compressedFile: String, decompressedFile: String) {
            FileInputStream(compressedFile).use { fileIn ->
                XZCompressorInputStream(fileIn).use { zis ->
                    FileOutputStream(decompressedFile).use { fileOutputStream ->
                        val buffer = ByteArray(1024)
                        while (true) {
                            val bytesRead = zis.read(buffer)
                            if (bytesRead <= 0) break
                            fileOutputStream.write(buffer, 0, bytesRead)
                        }
                    }
                }
            }
            log.info("decompress(xz) done: $compressedFile -> $decompressedFile")
        }

        fun isLz4(compressedFile: String): Boolean {
            return try {
                "lz4 -t $compressedFile".check_call()
                true
            } catch (e: Exception) {
                false
            }
        }

        fun lz4cat(lz4File: String, outFile: String) {
            "lz4 -d -fv $lz4File $outFile".check_call()
        }

        fun lz4(lz4File: String, inputStream: InputStream) {
            FileOutputStream(File(lz4File)).use { fos ->
                val baosE = ByteArrayOutputStream()
                DefaultExecutor().let { exec ->
                    exec.streamHandler = PumpStreamHandler(fos, baosE, inputStream)
                    val cmd = CommandLine.parse("lz4 -l -12")
                    if ("lz4 --version".check_output().contains("r\\d+,".toRegex())) {
                        log.warn("lz4 version obsolete, needs update")
                    } else {
                        cmd.addArgument("--favor-decSpeed")
                    }
                    log.info(cmd.toString())
                    exec.execute(cmd)
                }
                baosE.toByteArray().let {
                    if (it.isNotEmpty()) {
                        log.warn(String(it))
                    }
                }
            }
        }

        fun isAndroidCpio(compressedFile: String): Boolean {
            return Dumpling(compressedFile).readFully(0L..5)
                .contentEquals(byteArrayOf(0x30, 0x37, 0x30, 0x37, 0x30, 0x31))
        }

        fun isGZ(compressedFile: String): Boolean {
            return try {
                FileInputStream(compressedFile).use { fis ->
                    GZIPInputStream(fis).use {
                    }
                }
                true
            } catch (e: ZipException) {
                false
            }
        }

        /*
            @function: zcat compressedFile > decompressedFile
         */
        fun zcat(compressedFile: String, decompressedFile: String) {
            FileInputStream(compressedFile).use { fileIn ->
                GZIPInputStream(fileIn).use { gZIPInputStream ->
                    FileOutputStream(decompressedFile).use { fileOutputStream ->
                        val buffer = ByteArray(1024)
                        while (true) {
                            val bytesRead = gZIPInputStream.read(buffer)
                            if (bytesRead <= 0) break
                            fileOutputStream.write(buffer, 0, bytesRead)
                        }
                    }
                }
            }
            log.info("decompress(gz) done: $compressedFile -> $decompressedFile")
        }

        /*
            @function: gzip InputStream to file,
                       using java.util.zip.GZIPOutputStream

            caution: about gzip header - OS (Operating System)
            According to https://docs.oracle.com/javase/8/docs/api/java/util/zip/package-summary.html
            and GZIP spec RFC-1952(http://www.ietf.org/rfc/rfc1952.txt),
            gzip files created from java.util.zip.GZIPOutputStream will mark the OS field with
                0 - FAT filesystem (MS-DOS, OS/2, NT/Win32)
            But default image built from Android source code has the OS field:
                3 - Unix
         */
        fun gzip(compressedFile: String, fis: InputStream) {
            FileOutputStream(compressedFile).use { fos ->
                GZIPOutputStream(fos).use { gos ->
                    val buffer = ByteArray(1024)
                    while (true) {
                        val bytesRead = fis.read(buffer)
                        if (bytesRead <= 0) break
                        gos.write(buffer, 0, bytesRead)
                    }
                }
            }
            log.info("compress(gz) done: $compressedFile")
        }

        /*
            @function: gzip InputStream to file like Android minigzip,
                       using commons.compress GzipCompressorOutputStream,
            @dependency: commons.compress
         */
        fun minigzip(compressedFile: String, fis: InputStream) {
            val param = GzipParameters().apply {
                operatingSystem = 3 //3: Unix
            }
            FileOutputStream(compressedFile).use { fos ->
                GzipCompressorOutputStream(fos, param).use { gos ->
                    val buffer = ByteArray(1024)
                    while (true) {
                        val bytesRead = fis.read(buffer)
                        if (bytesRead <= 0) break
                        gos.write(buffer, 0, bytesRead)
                    }
                }
            }
            log.info("compress(gz) done: $compressedFile")
        }

        fun isBzip2(compressedFile: String): Boolean {
            return try {
                FileInputStream(compressedFile).use { fis ->
                    BZip2CompressorInputStream(fis).use { }
                }
                true
            } catch (e: IOException) {
                false
            }
        }

        fun bzip2(compressedFile: String, fis: InputStream) {
            log.info("Compress(bzip2) ... ")
            FileOutputStream(compressedFile).use { fos ->
                BZip2CompressorOutputStream(fos).use { zos ->
                    val buffer = ByteArray(1024)
                    while (true) {
                        val bytesRead = fis.read(buffer)
                        if (bytesRead <= 0) break
                        zos.write(buffer, 0, bytesRead)
                    }
                }
            }
            log.info("compress(bzip2) done: $compressedFile")
        }
    } // end-of-companion
}

```

`helper/src/test/kotlin/cfig/helper/CryptoHelperTest.kt`:

```kt
package cfig.helper

import org.junit.Assert.assertEquals
import java.io.File

class CryptoHelperTest {
    private fun checkRsaPair(privKey: String) {
        val pubKey = "$privKey.pub"
        val priv = CryptoHelperTest::class.java.classLoader.getResource(privKey).file
        val privK = CryptoHelper.KeyBox.parse4(File(priv).readBytes())
        assertEquals(org.bouncycastle.asn1.pkcs.RSAPrivateKey::class, privK.clazz)

        val pub = CryptoHelperTest::class.java.classLoader.getResource(pubKey).file
        val pubK = CryptoHelper.KeyBox.parse4(File(pub).readBytes())
        assertEquals(java.security.interfaces.RSAPublicKey::class, pubK.clazz)

        assertEquals(
            (privK.key as org.bouncycastle.asn1.pkcs.RSAPrivateKey).modulus,
            (pubK.key as java.security.interfaces.RSAPublicKey).modulus
        )

        assertEquals(
            (privK.key as org.bouncycastle.asn1.pkcs.RSAPrivateKey).publicExponent,
            (pubK.key as java.security.interfaces.RSAPublicKey).publicExponent
        )
    }

    //@Test
    fun parsePemRSA() {
        checkRsaPair("pem.rsa/rsa.2048")
        checkRsaPair("pem.rsa/rsa.4096")
        checkRsaPair("pem.rsa/rsa.8192")
    }

    fun geographicalHash() {
        val f = "/home/work/boot/payload.bin"
        val dg = CryptoHelper.Hasher.hash(Dumpling(f), listOf(Pair(0, 1862657060)), "sha-256")
        println(Helper.toHexString(dg))
    }
}

```

`helper/src/test/kotlin/cfig/helper/OpenSslHelperTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.helper

import org.bouncycastle.asn1.est.CsrAttrs
import org.bouncycastle.cert.X509CertificateHolder
import org.bouncycastle.cert.crmf.CertificateRequestMessageBuilder
import org.junit.Test
import org.slf4j.LoggerFactory
import java.io.File

class OpenSslHelperTest {
    private val log = LoggerFactory.getLogger(OpenSslHelperTest::class.java)

    @Test
    fun testCsr() {
        OpenSslHelper.createCsr(
            "test.key",
            "test.csr",
            "/C=US/ST=Utah/L=Lehi/O=Your Company, Inc./OU=IT/CN=yourdomain.com"
        )
    }

    @Test
    fun parsePk8() {
        val pk8 = CryptoHelperTest::class.java.classLoader.getResource("platform.pk8").file
        val x509 = CryptoHelperTest::class.java.classLoader.getResource("platform.x509.pem").file
        val kb = CryptoHelper.KeyBox.parse4(File(pk8).readBytes())
        println(kb.key::class)
        peekKeyBox(kb)
        OpenSslHelper.toJks(pk8, x509, "platform.jks")
    }

    private fun peekKeyBox(kb: CryptoHelper.KeyBox) {
        if (kb.fmt == CryptoHelper.KeyFormat.PEM) {
            println("fmt=[PEM] type=[" + kb.clazz.qualifiedName + "]")
        } else {
            println("type=[" + kb.clazz.qualifiedName + "]")
        }
    }

}

```

`helper/src/test/kotlin/cfig/helper/ZipHelperTest.kt`:

```kt
// Copyright 2021 yuyezhong@gmail.com
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cfig.helper

import cfig.helper.ZipHelper.Companion.dumpEntry
import org.apache.commons.compress.archivers.zip.ZipFile
import org.junit.After
import org.junit.Assert
import org.junit.Before
import org.junit.Test
import java.io.File

class ZipHelperTest {

    @Before
    fun setUp() {
        File("out").let {
            if (!it.exists()) it.mkdir()
        }
    }

    @After
    fun tearDown() {
        File("out").deleteRecursively()
    }

    @Test
    fun unzip() {
        val zf = ZipHelperTest::class.java.classLoader.getResource("appcompat.zip").file
        ZipHelper.unzip(File(zf).path, "out")
        File("out").deleteRecursively()
    }

    @Test
    fun dumpEntry() {
        val zf = ZipHelperTest::class.java.classLoader.getResource("appcompat.zip").file
        ZipFile(zf).use {
            it.dumpEntry("webview.log", File("out/webview.log"))
        }
    }

    @Test
    fun testDataSrc() {
        if (File("/proc/cpuinfo").exists()) {
            val ds1 = Dumpling("/proc/cpuinfo")
            Assert.assertTrue(ds1.readFully(0L..31).contentEquals(ds1.readFully(Pair(0, 32))))
            val d2 = Dumpling(ds1.readFully(0L..31))
            Assert.assertTrue(d2.readFully(0..15L).contentEquals(d2.readFully(Pair(0, 16))))
        }
    }
}
```

`helper/src/test/resources/platform.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIIEqDCCA5CgAwIBAgIJALOZgIbQVs/6MA0GCSqGSIb3DQEBBAUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g
VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE
AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0wODA0MTUyMjQwNTBaFw0zNTA5MDEyMjQwNTBaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G
A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI
hvcNAQEBBQADggENADCCAQgCggEBAJx4BZKsDV04HN6qZezIpgBuNkgMbXIHsSAR
vlCGOqvitV0Amt9xRtbyICKAx81Ne9smJDuKgGwms0sTdSOkkmgiSQTcAUk+fArP
GgXIdPabA3tgMJ2QdNJCgOFrrSqHNDYZUer3KkgtCbIEsYdeEqyYwap3PWgAuer9
5W1Yvtjo2hb5o2AJnDeoNKbf7be2tEoEngeiafzPLFSW8s821k35CjuNjzSjuqtM
9TNxqydxmzulh1StDFP8FOHbRdUeI0+76TybpO35zlQmE1DsU1YHv2mi/0qgfbX3
6iANCabBtJ4hQC+J7RGQiTqrWpGA8VLoL4WkV1PPX8GQccXuyCcCAQOjgfwwgfkw
HQYDVR0OBBYEFE/koLPdnLop9x1yh8Tnw48ghsKZMIHJBgNVHSMEgcEwgb6AFE/k
oLPdnLop9x1yh8Tnw48ghsKZoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH
QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG
CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJALOZgIbQVs/6MAwGA1Ud
EwQFMAMBAf8wDQYJKoZIhvcNAQEEBQADggEBAFclUbjZOh9z3g9tRp+G2tZwFAAp
PIigzXzXeLc9r8wZf6t25iEuVsHHYc/EL9cz3lLFCuCIFM78CjtaGkNGBU2Cnx2C
tCsgSL+ItdFJKe+F9g7dEtctVWV+IuPoXQTIMdYT0Zk4u4mCJH+jISVroS0dao+S
6h2xw3Mxe6DAN/DRr/ZFrvIkl5+6bnoUvAJccbmBOM7z3fwFlhfPJIRc97QNY4L3
J17XOElatuWTG5QhdlxJG3L7aOCA29tYwgKdNHyLMozkPvaosVUz7fvpib1qSN1L
IC7alMarjdW4OZID2q4u1EYjLk/pvZYTlMYwDlE448/Shebk5INTjLixs1c=
-----END CERTIFICATE-----

```

`helper/src/test/resources/testkey.pub`:

```pub
-----BEGIN PUBLIC KEY-----
MIIBIDANBgkqhkiG9w0BAQEFAAOCAQ0AMIIBCAKCAQEA1pMZBN7GCySx7cdi4NnY
JT4+zWzrHeL/Boyo6LyozWvTeG6nCqds5g67D5k1Wf/ZPnepQ+foPUtkuOT+otPm
VvHiZ6gbv7IwtXjCBEO+THIYuEb1IRWG8DihTonCvjh/jr7Pj8rD2h7jMMnqk9Cn
w9xK81AiDVAIBzLggJcX7moFM1nmppTsLLPyhKCkZsh6lNg7MQk6ZzcuL2QSwG5t
QvFYGN/+A4HMDNRE2mzdw7gkWBlIAbMlZBNPv96YySh3SNv1Z2pUDYFUyLvKB7ni
R1UzEcRrmvdv3uzMjmnnyKLQjngmIJQ/mXJ9PAT+cpkdmd+brjigshd/ox1bav7p
HwIBAw==
-----END PUBLIC KEY-----

```

`helper/src/test/resources/testkey.x509.pem`:

```pem
-----BEGIN CERTIFICATE-----
MIIEqDCCA5CgAwIBAgIJAJNurL4H8gHfMA0GCSqGSIb3DQEBBQUAMIGUMQswCQYD
VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g
VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE
AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe
Fw0wODAyMjkwMTMzNDZaFw0zNTA3MTcwMTMzNDZaMIGUMQswCQYDVQQGEwJVUzET
MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G
A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p
ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI
hvcNAQEBBQADggENADCCAQgCggEBANaTGQTexgskse3HYuDZ2CU+Ps1s6x3i/waM
qOi8qM1r03hupwqnbOYOuw+ZNVn/2T53qUPn6D1LZLjk/qLT5lbx4meoG7+yMLV4
wgRDvkxyGLhG9SEVhvA4oU6Jwr44f46+z4/Kw9oe4zDJ6pPQp8PcSvNQIg1QCAcy
4ICXF+5qBTNZ5qaU7Cyz8oSgpGbIepTYOzEJOmc3Li9kEsBubULxWBjf/gOBzAzU
RNps3cO4JFgZSAGzJWQTT7/emMkod0jb9WdqVA2BVMi7yge54kdVMxHEa5r3b97s
zI5p58ii0I54JiCUP5lyfTwE/nKZHZnfm644oLIXf6MdW2r+6R8CAQOjgfwwgfkw
HQYDVR0OBBYEFEhZAFY9JyxGrhGGBaR0GawJyowRMIHJBgNVHSMEgcEwgb6AFEhZ
AFY9JyxGrhGGBaR0GawJyowRoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE
CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH
QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG
CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJAJNurL4H8gHfMAwGA1Ud
EwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEBAHqvlozrUMRBBVEY0NqrrwFbinZa
J6cVosK0TyIUFf/azgMJWr+kLfcHCHJsIGnlw27drgQAvilFLAhLwn62oX6snb4Y
LCBOsVMR9FXYJLZW2+TcIkCRLXWG/oiVHQGo/rWuWkJgU134NDEFJCJGjDbiLCpe
+ZTWHdcwauTJ9pUbo8EvHRkU3cYfGmLaLfgn9gP+pWA7LFQNvXwBnDa6sppCccEX
31I828XzgXpJ4O+mDL1/dBd+ek8ZPUP0IgdyZm5MTYPhvVqGCHzzTy3sIeJFymwr
sBbmg2OAUNLEMO6nwmocSdN2ClirfxqCzJOLSDE4QyS9BAH6EhY6UFcOaE0=
-----END CERTIFICATE-----

```

`integrationTest.py`:

```py
#!/usr/bin/env python3

import shutil, os.path, json, subprocess, hashlib, glob
import unittest, logging, sys, lzma, time, platform

successLogo = """
      +----------------------------------+
      |    All test cases have PASSED    |
      +----------------------------------+
"""
resDir = "src/integrationTest/resources"
resDir2 = "src/integrationTest/resources_2"
log = logging.getLogger('TEST')
log.setLevel(logging.DEBUG)
consoleHandler = logging.StreamHandler(sys.stdout)
consoleHandler.setFormatter(logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(name)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'))
log.addHandler(consoleHandler)

def hashFile(fileName):
    hasher = hashlib.md5()
    with open(fileName, 'rb') as afile:
        buf = afile.read()
        hasher.update(buf)
    return hasher.hexdigest()

def deleteIfExists(inFile):
    if os.path.isfile(inFile):
        log.info("rm %s" % inFile)
        raise
    ## do not delete
    #for i in range(3):
    #    try:
    #        if os.path.isfile(inFile):
    #            log.info("rm %s" % inFile)
    #            os.remove(inFile)
    #        return
    #    except Exception as e:
    #        log.warning("Exception in cleaning up %s" % inFile)
    #        time.sleep(3)

def cleanUp():
    log.info("clean up ...")
    shutil.rmtree("build/unzip_boot", ignore_errors = True)
    [deleteIfExists(item) for item in [
        "boot.img", "boot.img.clear", "boot.img.google", "boot.img.signed", "boot.img.signed2",
        "recovery.img", "recovery.img.clear", "recovery.img.google", "recovery.img.signed", "recovery.img.signed2",
        "vbmeta.img", "vbmeta.img.signed",
        "dtbo.img", "dtbo.img.clear", "dtbo.img.signed", "dtbo.img.signed2",
        "misc.img", "misc.img.new",
        "payload.bin",
        "init_boot.img", "init_boot.img.signed",
        "vendor_boot.img", "vendor_boot.img.clear", "vendor_boot.img.google", "vendor_boot.img.signed", "vendor_boot.img.signed2",
        "boot-debug.img", "boot-debug.img.clear", "boot-debug.img.google",
        "vendor_boot-debug.img", "vendor_boot-debug.img.clear", "vendor_boot-debug.img.google" ]]

def verifySingleJson(jsonFile, func = None):
    log.info("executing %s ..." % jsonFile)
    imgDir = os.path.dirname(jsonFile)
    verifyItems = json.load(open(jsonFile))
    for k, v in verifyItems["copy"].items():
        it = os.path.join(imgDir, k)
        if (os.path.isfile(it)):
            log.info("copy file: %s -> %s" % (os.path.join(imgDir, k), v))
            shutil.copyfile(it, v)
        elif (os.path.isfile(it + ".xz")):
            log.info("extract file: %s -> %s" % (it + ".xz", v))
            decompressXZ(it + ".xz", v)
        else:
            raise
    if sys.platform == "win32":
        gradleWrapper = "gradlew.bat"
    else:
        gradleWrapper = "./gradlew"
    subprocess.check_call(gradleWrapper + " unpack", shell = True)
    if func:
        func()
    subprocess.check_call(gradleWrapper + " pack", shell = True)
    for k, v in verifyItems["hash"].items():
        log.info("%s : %s" % (k, v))
        unittest.TestCase().assertIn(hashFile(k), v.split())
    try:
        subprocess.check_call(gradleWrapper + " clear", shell = True)
    except Exception as e:
        pass

def verifySingleDir(inResourceDir, inImageDir):
    resDir = inResourceDir
    imgDir = inImageDir
    log.info("Enter %s ..." % os.path.join(resDir, imgDir))
    jsonFiles = glob.glob(os.path.join(resDir, imgDir) + "/*.json")
    for jsonFile in jsonFiles:
        cleanUp()
        verifySingleJson(jsonFile)
        cleanUp()
    pyFiles = glob.glob(os.path.join(resDir, imgDir) + "/*.py")
    for pyFile in pyFiles:
        cleanUp()
        log.warning("calling %s" % pyFile)
        if sys.platform == "win32":
            theCmd = "python " + pyFile
        else:
            theCmd = pyFile
        subprocess.check_call(theCmd, shell = True)
        cleanUp()
    log.info("Leave %s" % os.path.join(resDir, imgDir))

def decompressXZ(inFile, outFile):
    with lzma.open(inFile) as f:
        file_content = f.read()
        with open(outFile, "wb") as f2:
            f2.write(file_content)

def seekedCopy(inFile, outFile, offset):
    print(inFile + " -> " + outFile)
    with open(inFile, "rb") as reader:
        reader.seek(offset)
        content = reader.read()
        with open(outFile, "wb") as writer:
            writer.write(content)

def main():
    #########################################
    #   resource_1
    #########################################
    # from volunteers
    verifySingleDir(resDir, "recovery_image_from_s-trace")
    verifySingleDir(resDir, "boot_img_from_gesangtome") # android 9, no ramdisk
    verifySingleDir(resDir, "issue_47")
    verifySingleDir(resDir, "issue_52")
    verifySingleDir(resDir, "issue_54")
    # 5.0
    verifySingleDir(resDir, "5.0_fugu_lrx21m")
    # 6.0
    verifySingleDir(resDir, "6.0.0_bullhead_mda89e")
    # 7.0 special boot
    cleanUp()
    #subprocess.check_call("dd if=%s/7.1.1_volantis_n9f27m/boot.img of=boot.img bs=256 skip=1" % resDir, shell = True)
    seekedCopy(os.path.join(resDir, "7.1.1_volantis_n9f27m", "boot.img"), "boot.img", 256)
    verifySingleJson(resDir + "/7.1.1_volantis_n9f27m/boot.json")
    # 7.0 special recovery
    cleanUp()
    #subprocess.check_call("dd if=%s/7.1.1_volantis_n9f27m/recovery.img of=recovery.img bs=256 skip=1" % resDir, shell = True)
    seekedCopy(os.path.join(resDir, "7.1.1_volantis_n9f27m", "recovery.img"), "recovery.img", 256)
    verifySingleJson("%s/7.1.1_volantis_n9f27m/recovery.json" % resDir)
    # 8.0
    verifySingleDir(resDir, "8.0.0_fugu_opr2.170623.027")
    # 9.0 + avb
    verifySingleDir(resDir, "9.0.0_blueline_pq1a.181105.017.a1")
    # Q preview
    verifySingleDir(resDir, "Q_preview_blueline_qpp2.190228.023")
    # 10
    verifySingleDir(resDir, "10.0.0_coral-qq1d.200205.002")
    # 11
    verifySingleDir(resDir, "11.0.0_redfin.rd1a.200810.021.a1")

    #########################################
    #   resource_2
    #########################################
    cleanUp()
    verifySingleJson("%s/issue_59/recovery.json" % resDir2, func = lambda: shutil.rmtree("build/unzip_boot/root", ignore_errors = False))
    # Issue 71: dtbo
    if platform.system() != "Darwin":
        verifySingleDir(resDir2, "issue_71")
        verifySingleDir(resDir2, "issue_71/redfin")
    else:
        log.info("dtbo not fully supported on MacOS, skip testing")
    # Issue 83: init_boot
    verifySingleDir(resDir2, "issue_83")
    # Issue 86: vendor_boot with vrt and board name
    verifySingleDir(resDir2, "issue_86")
    # Issue 88: boot image V4 without boot signature,
    #  and Issue 75: allow duplicated entry in cpio
    verifySingleDir(resDir2, "issue_88")
    # Issue 92: unsigned vendor_boot
    verifySingleDir(resDir2, "issue_91_unsigned_vendor_boot")

    log.info(successLogo)

if __name__ == "__main__":
    # execute only if run as a script
    main()

```

`settings.gradle.kts`:

```kts
rootProject.name = "boot"
include("bbootimg")
include("aosp:boot_signer")
include("aosp:mkbootfs.10")
include("aosp:mkbootfs.11")
include("aosp:libsparse:base")
include("aosp:libsparse:sparse")
include("aosp:libsparse:img2simg")
include("aosp:libsparse:simg2img")
include("aosp:libsparse:simg2simg")
include("aosp:libsparse:append2simg")
include("aosp:libavb1.1")
include("aosp:libavb1.2")
include("avbImpl")
include("helper")

```

`src/resources/console.rc`:

```rc
service console /system/bin/sh
    console
    disabled
    user root
    group root shell log readproc
    seclabel u:r:shell:s0

on property:ro.debuggable=*
    # Give writes to anyone for the trace folder on debug builds.
    # The folder is used to store method traces.
    chmod 0773 /data/misc/trace
    start console

```

`src/resources/init.debug.rc`:

```rc
service console /system/bin/sh
    console
    user root
    group root shell log readproc
    seclabel u:r:shell:s0

on property:persist.logd.logpersistd=logcatd
    # all exec/services are called with umask(077), so no gain beyond 0700
    mkdir /data/misc/logd 0700 logd log
    # logd for write to /data/misc/logd, log group for read from pstore (-L)
    # exec - logd log -- /system/bin/logcat -L -b all -v threadtime -v usec -v printable -D -f /data/misc/logd/logcat -r 1024 -n 256
    start logcatd

service logcatd /system/bin/logcat -b all -v threadtime -v usec -v printable -D -f /data/misc/logd/logcat -r 1024 -n 256
    class late_start
    disabled
    # logd for write to /data/misc/logd, log group for read from log daemon
    user logd
    group log
    writepid /dev/cpuset/system-background/tasks
    seclabel u:r:recovery:s0

service logd /system/bin/logd
    socket logd stream 0666 logd logd
    socket logdr seqpacket 0666 logd logd
    socket logdw dgram 0222 logd logd
    group root system readproc
    writepid /dev/cpuset/system-background/tasks
    seclabel u:r:recovery:s0

service logd-reinit /system/bin/logd --reinit
    oneshot
    disabled
    writepid /dev/cpuset/system-background/tasks
    seclabel u:r:recovery:s0

```

`tools/1.kts`:

```kts
import java.io.*
import org.apache.commons.exec.CommandLine
import org.apache.commons.exec.DefaultExecutor
import org.apache.commons.exec.PumpStreamHandler
import com.fasterxml.jackson.databind.ObjectMapper

fun adbCmd(cmd: String): String {
    val outputStream = ByteArrayOutputStream()
    val exec = DefaultExecutor()
    exec.streamHandler = PumpStreamHandler(outputStream)
    val cmdline = "adb shell $cmd"
    //println(cmdline)
    exec.execute(CommandLine.parse(cmdline))
    //println(outputStream)
    return outputStream.toString().trim()
}

val cpufreqDir = "/sys/devices/system/cpu/cpufreq/policy0"
val interactGov = "/sys/devices/system/cpu/cpufreq/interactive"

val scaling_governor = adbCmd("cat $cpufreqDir/scaling_governor")
val avail_governer = adbCmd("cat $cpufreqDir/scaling_available_governors")
val avail_freq = adbCmd("cat $cpufreqDir/scaling_available_frequencies")
println("Available governers: " + avail_governer)
println("Available frequency: " + avail_freq)

val scaleMax = adbCmd("cat $cpufreqDir/scaling_max_freq")
val scaleMin = adbCmd("cat $cpufreqDir/scaling_min_freq")
println("scaling_X_freq: [$scaleMin, $scaleMax]")
println("Current governer: $scaling_governor")

fun getInteractValue(k: String): String {
    return adbCmd("cat $interactGov/$k")
}
fun getInteractInt(k: String): Int {
    return Integer.decode(adbCmd("cat $interactGov/$k"))
}

data class Boost(
    var boost: Int,
    var boostpulse_duration_ms: Int)
val boostInfo = Boost(getInteractInt("boost"), getInteractInt("boostpulse_duration") / 1000)

data class HiSpeed(
    var load: Int,
    var above_delay_Ms: Int,
    var freq_GHz: Double)
val hiSpeedInfo = HiSpeed(
    getInteractInt("go_hispeed_load"),
    getInteractInt("above_hispeed_delay") / 1000,
    getInteractInt("hispeed_freq") / 1000000.0)

data class InteractiveGov(
    var target_loads: Int,
    var boost: Boost,
    var hiSpeed: HiSpeed,
    var minSampleTimeMs: Int,
    var timerRateMs: Int,
    var timerSlackMs: Int,
    var io_is_busy: Int)

val info = InteractiveGov(
    getInteractInt("target_loads"), 
    boostInfo,
    hiSpeedInfo,
    getInteractInt("min_sample_time") / 1000,
    getInteractInt("timer_rate") / 1000,
    getInteractInt("timer_slack") / 1000,
    getInteractInt("io_is_busy"))

println(ObjectMapper().writerWithDefaultPrettyPrinter().writeValueAsString(info))

```

`tools/avb_print_property_desc.diff`:

```diff
diff --git a/aosp/libavb/src/avb/c/avb_slot_verify.c b/aosp/libavb/src/avb/c/avb_slot_verify.c
index 0d75210..4c44755 100644
--- a/aosp/libavb/src/avb/c/avb_slot_verify.c
+++ b/aosp/libavb/src/avb/c/avb_slot_verify.c
@@ -29,10 +29,12 @@
 #include "avb_hash_descriptor.h"
 #include "avb_hashtree_descriptor.h"
 #include "avb_kernel_cmdline_descriptor.h"
+#include "avb_property_descriptor.h"
 #include "avb_sha.h"
 #include "avb_util.h"
 #include "avb_vbmeta_image.h"
 #include "avb_version.h"
+#include <stdio.h>
 
 /* Maximum number of partitions that can be loaded with avb_slot_verify(). */
 #define MAX_NUMBER_OF_LOADED_PARTITIONS 32
@@ -1199,8 +1201,21 @@ static AvbSlotVerifyResult load_and_verify_vbmeta(
         }
       } break;
 
-      case AVB_DESCRIPTOR_TAG_PROPERTY:
+      case AVB_DESCRIPTOR_TAG_PROPERTY: {
         /* Do nothing. */
+        AvbPropertyDescriptor property_desc;
+        const uint8_t* prop_key = NULL;
+        const char* prop_value = NULL;
+        if (!avb_property_descriptor_validate_and_byteswap((AvbPropertyDescriptor *)descriptors[n], &property_desc)) {
+            avb_errorv(full_partition_name, ": Property descriptor is invalid.\n", NULL);
+            ret = AVB_SLOT_VERIFY_RESULT_ERROR_INVALID_METADATA;
+            goto out;
+        }
+        prop_key = (const uint8_t*)descriptors[n] + sizeof(AvbPropertyDescriptor);
+        prop_value = (const char*)descriptors[n] + sizeof(AvbPropertyDescriptor) + property_desc.key_num_bytes + 1;
+        fprintf(stderr, "PROPERTY DESCRIPTOR: k=[%s], v=[%s]\n", prop_key, prop_value);
+        /* Do nothing. */
+      }
         break;
     }
   }

```

`tools/debug.kts`:

```kts
import java.io.File
import java.nio.file.Files
import java.nio.file.Paths

if (null == System.getenv("ANDROID_PRODUCT_OUT")) {
    println("ANDROID_PRODUCT_OUT not set, did U envsetup/lunch product?")
    System.exit(1)
}

val xbins = listOf("su")
val bins = listOf("sh", "logcat", "logcatd", "logd", "linker", "toolbox", "toybox", "applypatch", "debuggerd",  "reboot")
val libs = listOf("libnetutils.so", "libdl.so", "libutils.so", "libc++.so", "libc.so", "libm.so", "libz.so", "libstdc++.so", "libcutils.so", "libselinux.so", "liblog.so", "libpcrecpp.so", "libpcre2.so", "libsysutils.so", "libnl.so", "libbase.so", "libbacktrace.so", "libunwind.so", "libcrypto.so", "libpackagelistparser.so", "libpcrecpp.so", "liblzma.so", "liblogcat.so")
val initrcFiles = listOf("logcatd.rc", "logd.rc")
val toolboxLinks = listOf("df", "getevent", "iftop", "ioctl", "ionice", "log", "lsof", "nandread", "newfs_msdos", "ps", "prlimit", "renice", "sendevent", "start", "stop", "top", "uptime", "watchprops", "dd", "du")
val toyboxLinks = listOf("ps", "ls", "acpi", "basename", "blockdev", "bzcat", "cal", "cat", "chcon", "chgrp", "chmod", "chown", "chroot", "cksum", "clear", "comm", "cmp", "cp", "cpio", "cut", "date", "dirname", "dmesg", "dos2unix", "echo", "env", "expand", "expr", "fallocate", "false", "find", "free", "getenforce", "getprop", "groups", "head", "hostname", "hwclock", "id", "ifconfig", "inotifyd", "insmod", "kill", "load_policy", "ln", "logname", "losetup", "lsmod", "lsusb", "md5sum", "mkdir", "mknod", "mkswap", "mktemp", "modinfo", "more", "mount", "mountpoint", "mv", "netstat", "nice", "nl", "nohup", "od", "paste", "patch", "grep", "pidof", "pkill", "pmap", "printenv", "printf", "pwd", "readlink", "realpath", "restorecon", "rm", "rmdir", "rmmod", "route", "runcon", "sed", "seq", "setenforce", "setprop", "setsid", "sha1sum", "sleep", "sort", "split", "stat", "strings", "swapoff", "swapon", "sync", "sysctl", "tac", "tail", "tar", "taskset", "tee", "time", "timeout", "touch", "tr", "true", "truncate", "umount", "uname", "uniq", "unix2dos", "usleep", "vmstat", "wc", "which", "whoami", "xargs", "yes")

val workdir: String = "build/unzip_boot"
File("$workdir/root/system/bin").mkdirs()
File("$workdir/root/system/xbin").mkdirs()
File("$workdir/root/system/lib").mkdirs()

xbins.forEach { it ->
    val bin = System.getenv("ANDROID_PRODUCT_OUT") + "/system/xbin/" + it
    val binTgt = workdir + "/root/system/xbin/" + it
    println("$bin -> $binTgt")
    File(bin).copyTo(File(binTgt), true)
}

bins.forEach { it ->
    val bin = System.getenv("ANDROID_PRODUCT_OUT") + "/system/bin/" + it
    val binTgt = workdir + "/root/system/bin/" + it
    println("$bin -> $binTgt")
    File(bin).copyTo(File(binTgt), true)
}

libs.forEach { it ->
    val lib = System.getenv("ANDROID_PRODUCT_OUT") + "/system/lib/" + it
    val libTgt = workdir + "/root/system/lib/" + it
    println("$lib -> $libTgt")
    File(lib).copyTo(File(libTgt), true)
}

toolboxLinks.forEach { it ->
    val bin = workdir + "/root/system/bin/" + it
    Files.deleteIfExists(File(bin).toPath())
    Files.createSymbolicLink(Paths.get(bin), Paths.get("toolbox"));
}

toyboxLinks.forEach { it ->
    val bin = workdir + "/root/system/bin/" + it
    Files.deleteIfExists(File(bin).toPath())
    Files.createSymbolicLink(Paths.get(bin), Paths.get("toybox"));
}

File(workdir + "/root/system/etc/init").mkdirs()
initrcFiles.forEach { it ->
    val bin = System.getenv("ANDROID_PRODUCT_OUT") + "/system/etc/init/" + it
    val binTgt = workdir + "/root/system/etc/init/" + it
    Files.deleteIfExists(File(binTgt).toPath())
    File(bin).copyTo(File(binTgt), true)
}

fun enableShell() {
    val bin = "src/resources/console.rc"
    val binTgt = workdir + "/root/system/etc/init/" + "console.rc"
    Files.deleteIfExists(File(binTgt).toPath())
    File(bin).copyTo(File(binTgt), true)
}
enableShell()

```

`tools/extract_kernel.py.diff`:

```diff
1c1
< #!/usr/bin/env python
---
> #!/usr/bin/env python2.7
181c181
<           "Cannot extract kernel configs in {}".format(args.input.name))
---
>           "Cannot extract kernel configs in {}\n".format(args.input.name))
189c189
<           "Cannot extract kernel versions in {}".format(args.input.name))
---
>           "Cannot extract kernel versions in {}\n".format(args.input.name))

```

`tools/free.py`:

```py
#! /usr/bin/env python3
# -*- coding: utf-8 -*-
# vim:fenc=utf-8
#
import subprocess

def run(cmd):
    print(cmd)
    subprocess.check_call(cmd, shell = True)

run("touch vbmeta.img")
run("gradle pull")
run("gradle unpack")
run('vim -u NONE -N build/unzip_boot/vbmeta.avb.json  -c ":19s/0/2/g" -c ":wq"')
run("gradle pack")
run("gradle flash")


```

`tools/mkdtboimg.diff`:

```diff
diff --git a/external/mkdtboimg.py b/external/mkdtboimg.py
index 03f0fd1..4b2de3d 100755
--- a/external/mkdtboimg.py
+++ b/external/mkdtboimg.py
@@ -1,4 +1,4 @@
-#! /usr/bin/env python
+#! /usr/bin/env python2
 # Copyright 2017, The Android Open Source Project
 #
 # Licensed under the Apache License, Version 2.0 (the "License");

```

`tools/port.mk`:

```mk
ROOTDIR := staging
LOG_H := $(ROOTDIR)/src/mkbootfs/headers/log/log.h

define build_gradle_content
YXBwbHkgcGx1Z2luOiAnY3BwJyAKYXBwbHkgcGx1Z2luOiAnYycgCgptb2RlbCB7CiAgICBidWls
ZFR5cGVzIHsKICAgICAgICByZWxlYXNlCiAgICB9ICAgCgogICAgY29tcG9uZW50cyB7CiAgICAg
ICAgbWtib290ZnMoTmF0aXZlRXhlY3V0YWJsZVNwZWMpIHsKICAgICAgICAgICAgYmluYXJpZXMu
YWxsIHsKICAgICAgICAgICAgICAgIGNwcENvbXBpbGVyLmRlZmluZSAiX19BTkRST0lEX1ZOREtf
XyIKICAgICAgICAgICAgICAgIC8vY3BwQ29tcGlsZXIuZGVmaW5lICdDRklHX05PX0ZJWF9TVEFU
JwogICAgICAgICAgICAgICAgY3BwQ29tcGlsZXIuYXJncyA8PCAnLXN0ZD1nbnUrKzExJyA8PCAi
LVduby13cml0ZS1zdHJpbmdzIgogICAgICAgICAgICB9ICAgCiAgICAgICAgfSAgIAogICAgfSAg
IAp9Cg==
endef

define log_h_content
I2lmbmRlZiBfQ0ZJR19MT0dfSAojZGVmaW5lIF9DRklHX0xPR19ICgojZGVmaW5lIEFMT0dFIHBy
aW50ZgoKI2VuZGlmCg==
endef

define mkbootfs_patch_content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endef			

export build_gradle_content
export log_h_content
export mkbootfs_patch_content
t:
	rm -fr $(ROOTDIR)
	mkdir $(ROOTDIR)
	mkdir -p $(ROOTDIR)/src/mkbootfs/cpp
	mkdir -p $(ROOTDIR)/src/mkbootfs/headers/private
	mkdir -p $(ROOTDIR)/src/mkbootfs/headers/utils
	mkdir -p $(ROOTDIR)/src/mkbootfs/headers/log
	cp -v system/core/cpio/mkbootfs.c $(ROOTDIR)/src/mkbootfs/cpp/
	cp -v system/core/libcutils/fs_config.cpp $(ROOTDIR)/src/mkbootfs/cpp/
	cp -v system/core/libcutils/include/private/android_filesystem_config.h $(ROOTDIR)/src/mkbootfs/headers/private/
	cp -v system/core/libcutils/include/private/android_filesystem_capability.h $(ROOTDIR)/src/mkbootfs/headers/private/
	cp -v system/core/libcutils/include/private/fs_config.h $(ROOTDIR)/src/mkbootfs/headers/private/
	cp -v system/core/libutils/include/utils/Compat.h $(ROOTDIR)/src/mkbootfs/headers/utils/
	echo "$$log_h_content" | base64 --decode > $(LOG_H)
	echo "$$build_gradle_content" | base64 --decode  > $(ROOTDIR)/build.gradle
	echo "$$mkbootfs_patch_content" | base64 --decode > $(ROOTDIR)/1.diff

tt:
	echo "$$mkbootfs_patch_content" | base64 --decode > 1.diff

```

`tools/pull.py`:

```py
#! /usr/bin/env python3
# -*- coding: utf-8 -*-
# vim:fenc=utf-8
#
import subprocess

def run(cmd):
    print(cmd)
    subprocess.check_call(cmd, shell = True)

run("touch vbmeta.img")
run("gradle pull")
run("touch boot.img")
run("gradle pull")
run("gradle unpack")


```

`tools/release.mk`:

```mk
#
# release.mk
# yu, 2020-12-20 00:19
#
define gw
#!/usr/bin/env sh\n
if [ "x$$1" = "xassemble" ]; then\n
    echo "already assembled"\n
    exit\n
fi\n
if [ "x$$1" = "xcheck" ]; then\n
echo "no check is needed"\n
exit 0\n
fi\n
if [ "x$$1" = "xclean" ]; then\n
echo "no cleaning is needed"\n
exit 0\n
fi\n
java -jar bbootimg/bbootimg.jar $$*

endef

define gw_win
@IF EXIST tools\\bin SET PATH=%PATH%;tools\\bin\n
@if "%1" == "check" exit 0\n
@if "%1" == "clean" exit 0\n
@java -jar bbootimg/bbootimg.jar %*
endef
export gw gw_win
all:
	cd ../bbootimg && gradle build
	cp ../bbootimg/build/libs/bbootimg.jar .
	cd ../aosp/boot_signer && gradle build
	cp ../aosp/boot_signer/build/libs/boot_signer.jar .
	cd .. && rm -fr avbImpl  bbootimg build build.gradle.kts gradle gradlew gradlew.bat settings.gradle.kts
	cd ../aosp && rm -r libavb1.1 libavb1.2 mkbootfs.10 mkbootfs.11
	rm -r ../aosp/boot_signer
	mkdir -p ../aosp/boot_signer/build/libs/ && mv boot_signer.jar ../aosp/boot_signer/build/libs/
	mkdir ../bbootimg && mv bbootimg.jar ../bbootimg/
	echo $$gw > gradlew
	chmod 755 gradlew
	echo $$gw_win > gradlew.bat
	mv gradlew ../
	mv gradlew.bat ../

# vim:ft=make
#

```

`tools/remove_projects.diff`:

```diff
diff --git a/build.gradle.kts b/build.gradle.kts
index fae7552..a871a89 100644
--- a/build.gradle.kts
+++ b/build.gradle.kts
@@ -59,15 +59,15 @@ tasks {
     flashTask.dependsOn("bbootimg:jar")
 
     //sparse image dependencies
-    packTask.dependsOn("aosp:mkbootfs:mkbootfsExecutable")
-    unpackTask.dependsOn("aosp:mkbootfs:mkbootfsExecutable")
-    if (System.getProperty("os.name").contains("Mac")) {
-        unpackTask.dependsOn("aosp:libsparse:simg2img:installReleaseMacos")
-        packTask.dependsOn("aosp:libsparse:img2simg:installReleaseMacos")
-    } else {
-        unpackTask.dependsOn("aosp:libsparse:simg2img:installReleaseLinux")
-        packTask.dependsOn("aosp:libsparse:img2simg:installReleaseLinux")
-    }
+    //packTask.dependsOn("aosp:mkbootfs:mkbootfsExecutable")
+    //unpackTask.dependsOn("aosp:mkbootfs:mkbootfsExecutable")
+    //if (System.getProperty("os.name").contains("Mac")) {
+    //    unpackTask.dependsOn("aosp:libsparse:simg2img:installReleaseMacos")
+    //    packTask.dependsOn("aosp:libsparse:img2simg:installReleaseMacos")
+    //} else {
+    //    unpackTask.dependsOn("aosp:libsparse:simg2img:installReleaseLinux")
+    //    packTask.dependsOn("aosp:libsparse:img2simg:installReleaseLinux")
+    //}
 }
 
 fun parseGradleVersion(version: String): Int {
diff --git a/settings.gradle.kts b/settings.gradle.kts
index 1485b37..fd953dc 100644
--- a/settings.gradle.kts
+++ b/settings.gradle.kts
@@ -1,11 +1,11 @@
 include("bbootimg")
 include("aosp:boot_signer")
-include("aosp:mkbootfs")
-include("aosp:libsparse:base")
-include("aosp:libsparse:sparse")
-include("aosp:libsparse:img2simg")
-include("aosp:libsparse:simg2img")
-include("aosp:libsparse:simg2simg")
-include("aosp:libsparse:append2simg")
-include("aosp:libavb")
-include("avbImpl")
+//include("aosp:mkbootfs")
+//include("aosp:libsparse:base")
+//include("aosp:libsparse:sparse")
+//include("aosp:libsparse:img2simg")
+//include("aosp:libsparse:simg2img")
+//include("aosp:libsparse:simg2simg")
+//include("aosp:libsparse:append2simg")
+//include("aosp:libavb")
+//include("avbImpl")

```

`tools/syncCode.sh`:

```sh
#!/bin/bash
set -x

git submodule init
git submodule update

```

`tools/temp.txt`:

```txt
Enable developer debugging for AVB-enabled devices

### modify build/unzip_boot/vbmeta.img.avb.json

* disable dm-verity hashtree verification
header -> flags: set to 1(AVB_VBMETA_IMAGE_FLAGS_HASHTREE_DISABLED = 1) to disable dm-verity hashtree(system/vendor etc.)

```diff
    "descriptors_size" : 1384,
    "rollback_index" : 0,
-   "flags" : 0,
+   "flags" : 1,
    "release_string" : "avbtool 1.0.0"
  },
  "authBlob" : {
```

* disable all AVB verification
header -> flags: set to 2(AVB_VBMETA_IMAGE_FLAGS_VERIFICATION_DISABLED = 2) to disable all verification, including AVB hash_footer(boot/recovery etc.) and dm-verity hashtree(system/vendor etc.)

```diff
    "descriptors_size" : 1384,
    "rollback_index" : 0,
-   "flags" : 0,
+   "flags" : 2,
    "release_string" : "avbtool 1.0.0"
  },
  "authBlob" : {
```

### unlock bootloader
'unlock' state will pass flag AVB_SLOT_VERIFY_FLAGS_ALLOW_VERIFICATION_ERROR when verifying images, then you can disable 



```

`tools/work_from_China.diff`:

```diff
diff --git a/aosp/boot_signer/build.gradle.kts b/aosp/boot_signer/build.gradle.kts
index be7419c..a8826c9 100644
--- a/aosp/boot_signer/build.gradle.kts
+++ b/aosp/boot_signer/build.gradle.kts
@@ -5,7 +5,7 @@ plugins {
 }
 
 repositories {
-    mavenCentral()
+    maven { setUrl("https://maven.aliyun.com/repository/public/") }
 }
 
 dependencies {
diff --git a/bbootimg/build.gradle.kts b/bbootimg/build.gradle.kts
index 499fb5b..f46cbcf 100644
--- a/bbootimg/build.gradle.kts
+++ b/bbootimg/build.gradle.kts
@@ -20,7 +20,7 @@ plugins {
 }
 
 repositories {
-    mavenCentral()
+    maven { setUrl("https://maven.aliyun.com/repository/public/") }
 }
 
 dependencies {
diff --git a/build.gradle.kts b/build.gradle.kts
index e133f36..7537313 100644
--- a/build.gradle.kts
+++ b/build.gradle.kts
@@ -15,7 +15,7 @@ if (parseGradleVersion(gradle.gradleVersion) < 6) {
 
 buildscript {
     repositories {
-        mavenCentral()
+        maven { setUrl("https://maven.aliyun.com/repository/public/") }
     }
     dependencies {
         classpath("org.apache.commons:commons-exec:1.3")
diff --git a/gradle/wrapper/gradle-wrapper.properties b/gradle/wrapper/gradle-wrapper.properties
index 8049c68..2e33ce8 100644
--- a/gradle/wrapper/gradle-wrapper.properties
+++ b/gradle/wrapper/gradle-wrapper.properties
@@ -1,5 +1,5 @@
 distributionBase=GRADLE_USER_HOME
 distributionPath=wrapper/dists
-distributionUrl=https\://services.gradle.org/distributions/gradle-7.6-bin.zip
+distributionUrl=https\://mirrors.cloud.tencent.com/gradle/gradle-7.6-bin.zip
 zipStoreBase=GRADLE_USER_HOME
 zipStorePath=wrapper/dists
diff --git a/helper/build.gradle.kts b/helper/build.gradle.kts
index 8618fd9..efd102e 100644
--- a/helper/build.gradle.kts
+++ b/helper/build.gradle.kts
@@ -21,7 +21,7 @@ plugins {
 }
 
 repositories {
-    mavenCentral()
+    maven { setUrl("https://maven.aliyun.com/repository/public/") }
 }
 
 dependencies {

```