Project Path: arc_gmh5225_camera-triggerbot_syid3c05

Source Tree:

```txt
arc_gmh5225_camera-triggerbot_syid3c05
├── LICENSE
├── README.md
├── media
│   ├── mode_color.png
│   ├── mode_difference.png
│   ├── observer_components.png
│   ├── observer_mouse_circuit.jpg
│   └── observer_overview.jpg
├── observer
│   ├── calibration.py
│   ├── config.cfg
│   ├── config.py
│   ├── hardware.py
│   ├── input.py
│   ├── observer.py
│   └── utility.py
└── remote-keyboard
    └── key.py

```

`LICENSE`:

```
MIT License

Copyright (c) 2022 Leander Lehmenkuehler

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`README.md`:

```md
# A Raspberry Pi 4 Based Camera Triggerbot 

## Introduction

The bot reacts to either movement or color around the crosshair. All components operate within a system that is separate from the computer that runs the video game. The camera is directed at the middle of the monitor, small adjustments to focus the exact center can be made using a calibration feature. To control the bot a key is connected to the Pi's GPIO. The relay is connected to the left clicking circuit of the mouse. Opening the relay, which is what happens if the bot finds a target while the key is held down, shorts the mouse circuit and triggers a click. The clicking is - just like using a finger - performed mechanically (inside the relay) and is hence indistinguishable from a real mouse click for the computer that uses the mouse. The intrusion is performed at the analog level, before the mouse digitally processes and passes information to the computer, making this type of input undetectable if used with temporal variation.

Recent non-memory bots that use machine learning to identify targets make use of capture cards to obtain input. I found the delay when using capture cards to be detrimental for a bot that requires speed most of all, so I just made this instead.

![observer_overview](./media/observer_overview.jpg)

__The program uses two different modes:__

### Difference Between Two Consecutive Frames

Consecutive frames are compared and if a config-defined threshold is exceeded the relay is opened. In this example a possible target appears from behind a wall. The white area in the lower frame series is the
difference between $f_n$ and $f_{n-1}$ of the upper series.

![mode_difference](./media/mode_difference.png)

### Color Detection

The relay is opened if a config-defined amount of a color is in the focus area. In this example the color purple of a specific brightness and saturation triggers a positive.

![mode_color](./media/mode_color.png)

## Comparison to Memory Cheats

### Advantages

- Doesn't require reverse engineering
- Doesn't require bypassing an anti-cheat / is undetectable
- Doesn't require updates
- Works for any game (in theory)
- Almost no delay (< 17ms)
- Looks cool

### Disadvantages

- Very limited functionality compared to a memory cheat
- Moving the mouse in 'difference' mode triggers false positives
- Expensive components / hardware based
- Loss of information by recording a monitor
- Requires additional mouse cables
- Requires space on the desk

## Components

Some of these components are optional or exchangeable. Instead of a key, the main computer's keyboard can be used over the network (which exposes the setup to the main computer though). LEDs are optional but useful as status indicators. Depending on the camera-monitor-constellation a different focal length than the suggested 50mm may be suitable.

- Raspberry Pi 4 & peripherals (RP Zero is too slow, RP3 has not been tested so far)
- Raspberry Pi High Quality Camera
- Manual focus lens (e.g. a Canon FD 50mm 1:1.8 with a C-mount adapter and macro extension)
- Tripod (or a different mount like solid steel with a tripod head)
- Relay module (single-channel, 5V)
- Cables, resistors, LEDs and GPIO connectors (crimping, stacking header, ...)
- Key (e.g. a mechanical keyboard switch)
- Mouse (with enough space to run two cables beneath the circuit board)
- A (second) keyboard, most practical is a wireless numpad
- Basic tools to assemble electrical components (soldering iron etc.)

![observer_components](./media/observer_components.png)

![observer_mouse_circuit](./media/observer_mouse_circuit.jpg)

## Setup

Clone the repository:

```sh
git clone https://github.com/lehmenkuehler/camera-triggerbot
```
Install some prerequisites:

```sh
pip install opencv-python
pip install numpy
pip install keyboard

apt-get install libcblas-dev
apt-get install libhdf5-dev
apt-get install libhdf5-serial-dev
apt-get install libatlas-base-dev
apt-get install libjasper-dev
apt-get install libqtgui4
apt-get install libqt4-test
```

## Running

Running requires root permissions because of the keyboard library. The configuration file can be changed using _nano_. Once the program is running the camera output stream can be opened using a browser with the Raspberry Pi's address at port 1337.

```sh
sudo su
cd camera-triggerbot/observer/
nano config.cfg
python observer.py
```

## References

A part of the streaming handler is taken from the [Raspberry Pi Camera Documentation](https://picamera.readthedocs.io/en/latest/recipes2.html#web-streaming).
```

`observer/calibration.py`:

```py
import logging
import socketserver
import threading
from http import server
import cv2
import time
import socket
import keyboard

PAGE = """\
<html>
    <body>
        <div>
            <div style="position: relative; width: 640px; height: 480px">
                <img style="float: left; position: relative; left: 0px; top: 0px;" src="stream.mjpg" width="640" height="480"></img>
                <p style="font-family:consolas; font-size: 10pt; padding: 5px;">switch between high and low quality using 'backspace' (depending on network capacity)
                \nuse 'enter' + numpad arrow keys to calibrate</p>
            </div>
        </div>
    </body>
</html>
"""

stream_img = None


class StreamingHandler(server.BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path == '/':
            self.send_response(301)
            self.send_header('Location', '/index.html')
            self.end_headers()
        elif self.path == '/index.html':
            content = PAGE.encode('utf-8')
            self.send_response(200)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Content-Length', len(content))
            self.end_headers()
            self.wfile.write(content)
        elif self.path == '/stream.mjpg':
            self.send_response(200)
            self.send_header('Age', 0)
            self.send_header('Cache-Control', 'no-cache, private')
            self.send_header('Pragma', 'no-cache')
            self.send_header(
                'Content-Type', 'multipart/x-mixed-replace; boundary=FRAME')
            self.end_headers()
            try:
                global stream_img
                high_quality = False
                fps, qual = 10, 50
                while True:

                    if keyboard.is_pressed('backspace'):
                        high_quality = not high_quality
                        if high_quality:
                            fps, qual = 60, 95
                            print('switching to high quality streaming')
                        else:
                            fps, qual = 10, 50
                            print('switching to low quality streaming')
                        time.sleep(1.0)

                    img = stream_img[0]
                    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), qual]
                    encimg = cv2.imencode('.jpg', img, encode_param)[1]
                    frame = encimg

                    time.sleep(float(1.0 / fps))

                    self.wfile.write(b'--FRAME\r\n')
                    self.send_header('Content-Type', 'image/jpeg')
                    self.send_header('Content-Length', len(frame))
                    self.end_headers()
                    self.wfile.write(frame)
                    self.wfile.write(b'\r\n')
            except Exception as e:
                logging.warning(
                    'Removed streaming client %s: %s',
                    self.client_address, str(e))
        else:
            self.send_error(404)
            self.end_headers()

    def log_message(self, format, *args):
        pass


class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):
    allow_reuse_address = True
    daemon_threads = True

    def log_message(self, format, *args):
        return


class Stream:

    thread_stream = None
    server = None

    def __init__(self, img):
        global stream_img
        stream_img = img
        pass

    def stream(self):
        address = ('', 1337)
        self.server = StreamingServer(address, StreamingHandler)
        self.server.serve_forever()

    def run_stream(self):
        print("initiating stream for calibration")
        self.thread_stream = threading.Thread(
            target=self.stream, name=self.stream, args=(), daemon=True)
        self.thread_stream.start()
        print("stream established at " + get_ip() + ":1337")


def get_ip():
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.settimeout(0)
    try:
        s.connect(('10.255.255.255', 1))
        ip = s.getsockname()[0]
    except Exception:
        ip = '127.0.0.1'
    finally:
        s.close()
    return str(ip)

```

`observer/config.cfg`:

```cfg
[CAMERA]

# camera sensor sensitivity, set to 100, 200, 320, 400, 500, 640 or 800
iso: 400

# further camera adjustments if needed
brightness: 52
contrast: 15

# settings for Canon FD 50mm 1:1.8
# ISO 400 - brightness 52 - contrast 15

[DEBUG]

# print benchmark for every 1000 iterations
benchmark: 0

# enable saving frames for analysis
image_logger: 1

[PROCESSING]

# observation area in the middle of the frame
# preview in the calibration stream
obs_x: 60
obs_y: 60

# trigger sensitivity in percent
# required area of the observation area to be positive
sens_color: 0.1
sens_diff: 10.0

# red high contrast
#col_hue_low: 340
#col_hue_high: 360
#col_sat_low: 0.70
#col_sat_high: 1.0
#col_bri_low: 0.70
#col_bri_high: 1.0

# red normal
#col_hue_low: 345
#col_hue_high: 360
#col_sat_low: 0.60
#col_sat_high: 1.0
#col_bri_low: 0.60
#col_bri_high: 1.0

# purple high contrast
col_hue_low: 290
col_hue_high: 305
col_sat_low: 0.70
col_sat_high: 1.0
col_bri_low: 0.70
col_bri_high: 1.0

# purple normal
#col_hue_low: 290
#col_hue_high: 305
#col_sat_low: 0.60
#col_sat_high: 1.0
#col_bri_low: 0.60
#col_bri_high: 1.0

# marker in the middle of the crosshair used as second trigger condition (e.g. a green dot)
col_marker_hue_low: 90
col_marker_hue_high: 130
col_marker_sat_low: 0.70
col_marker_sat_high: 1.0
col_marker_bri_low: 0.70
col_marker_bri_high: 1.0

[CONTROL]

# use socket based input instead of a GPIO button
remote_keyboard: 0

[GAMEPLAY]

# 'color', 'difference'
mode: color

# delay between positive and relay opening (delay to fire)
delay: 0

# Enables observer only when middle marker is visible
marker_check: 0

# When enabled requires positives over multiple consecutive frames to trigger
consecutive: 0

# Delay in milliseconds after key press before observer is active.
# Does not work with 'enable_tap' enabled.
activation_delay: 0

# tapping the key toggles activity
tap: 0
# tap mode:
# set to 'charge' for a single shot and automatic deactivation
# set to 'toggle' for manual deactivation
tap_mode: toggle
# while tapping is enabled and active make the LED blink (set time_off to 0 to disable)
tap_led_time_on: 500
tap_led_time_off: 0

# duration of the relay being opened (the value is randomly modified in the program to seem human)
duration_active: 60
# break between openings of the relay (this value is also modified)
duration_break: 500

# some values allow multiple configs that can be set here
# set as: 'CONFIG-NAME,NAME-1,VALUE-1,NAME-2,VALUE-2,...'
[KEYS]

NUM_0: DEFAULT
NUM_1: SCOPE,tap,1,marker_check,1,duration_active,60,duration_break,200
NUM_2:
NUM_3:
NUM_4:
NUM_5:
NUM_6:
NUM_7: DIFF_10.0,mode,difference,obs_x,40,obs_y,40,sens_diff,10.0,tap,0,tap_mode,charge,activation_delay,100,duration_active,50,duration_break,1500
NUM_8: DIFF_1.0,mode,difference,obs_x,40,obs_y,40,sens_diff,1.0,tap,0,tap_mode,charge,activation_delay,100,duration_active,50,duration_break,1500
NUM_9:

```

`observer/config.py`:

```py
import configparser
import time
import random

cp = configparser.ConfigParser(
    converters={'list': lambda x: [i.strip() for i in x.split(',')]})
cp.read(['config.cfg'])


class Config:

    def __init__(self):
        pass

    name = "DEFAULT"

    iso = cp.getint("CAMERA", "iso")
    brightness = cp.getint("CAMERA", "brightness")
    contrast = cp.getint("CAMERA", "contrast")

    # focus area around the crosshair
    obs_x = cp.getint("PROCESSING", "obs_x")
    obs_y = cp.getint("PROCESSING", "obs_y")

    # performance and analysis
    benchmark = cp.getboolean("DEBUG", "benchmark")
    image_logger = cp.getboolean("DEBUG", "image_logger")

    # sensitivity in percent
    sens_diff = cp.getfloat("PROCESSING", "sens_diff")
    sens_color = cp.getfloat("PROCESSING", "sens_color")

    # color tracking for color mode
    col_hue_low = cp.getint("PROCESSING", "col_hue_low") / 2
    col_hue_high = cp.getint("PROCESSING", "col_hue_high") / 2
    col_sat_low = int(cp.getfloat("PROCESSING", "col_sat_low") * 255.0)
    col_sat_high = int(cp.getfloat("PROCESSING", "col_sat_high") * 255.0)
    col_bri_low = int(cp.getfloat("PROCESSING", "col_bri_low") * 255.0)
    col_bri_high = int(cp.getfloat("PROCESSING", "col_bri_high") * 255.0)

    # marker color (scoped-in marker color)
    col_marker_hue_low = cp.getint("PROCESSING", "col_marker_hue_low") / 2
    col_marker_hue_high = cp.getint("PROCESSING", "col_marker_hue_high") / 2
    col_marker_sat_low = int(cp.getfloat(
        "PROCESSING", "col_marker_sat_low") * 255.0)
    col_marker_sat_high = int(cp.getfloat(
        "PROCESSING", "col_marker_sat_high") * 255.0)
    col_marker_bri_low = int(cp.getfloat(
        "PROCESSING", "col_marker_bri_low") * 255.0)
    col_marker_bri_high = int(cp.getfloat(
        "PROCESSING", "col_marker_bri_high") * 255.0)

    remote_keyboard = cp.getboolean("CONTROL", "remote_keyboard")

    mode = cp.get("GAMEPLAY", "mode")
    delay = cp.getint("GAMEPLAY", "delay")
    tap_mode = cp.get("GAMEPLAY", "tap_mode")
    marker_check = cp.getboolean("GAMEPLAY", "marker_check")
    consecutive = cp.getboolean("GAMEPLAY", "consecutive")

    duration_active = cp.getint("GAMEPLAY", "duration_active") / 1000.0
    duration_break = cp.getint("GAMEPLAY", "duration_break") / 1000.0
    duration_active_tmp = 0
    duration_breake_tmp = 0

    tap = cp.getboolean("GAMEPLAY", "tap")
    activation_delay = cp.getint("GAMEPLAY", "activation_delay")
    tap_led_time_on = cp.getint("GAMEPLAY", "tap_led_time_on")
    tap_led_time_off = cp.getint("GAMEPLAY", "tap_led_time_off")

    # randomize mouse click and pause time
    # mean values can be set in config
    # using uniform distribution
    def randomizer(self):
        if time.time() * 1000 % 1000 < 25:
            self.duration_active_tmp = self.duration_active + \
                random.randint(-20, 20) / 1000
            self.duration_break_tmp = self.duration_break + \
                random.randint(-50, 50) / 1000


def process_configs(configs):

    NUM = [cp.getlist("KEYS", "NUM_0"), cp.getlist("KEYS", "NUM_1"), cp.getlist("KEYS", "NUM_2"),
           cp.getlist("KEYS", "NUM_3"), cp.getlist(
               "KEYS", "NUM_4"), cp.getlist("KEYS", "NUM_5"),
           cp.getlist("KEYS", "NUM_6"), cp.getlist(
               "KEYS", "NUM_7"), cp.getlist("KEYS", "NUM_8"),
           cp.getlist("KEYS", "NUM_9")]

    for idx, N in enumerate(NUM):
        configs[idx].name = N[0]
        i = 1
        while i < len(N):
            if N[i] == 'mode':
                configs[idx].mode = N[i + 1]
            elif N[i] == 'obs_x':
                configs[idx].obs_x = int(N[i + 1])
            elif N[i] == 'obs_y':
                configs[idx].obs_y = int(N[i + 1])
            elif N[i] == 'sens_diff':
                configs[idx].sens_diff = float(N[i + 1])
            elif N[i] == 'sens_color':
                configs[idx].sens_diff = float(N[i + 1])
            elif N[i] == 'duration_active':
                configs[idx].duration_active = int(N[i + 1]) / 1000.0
            elif N[i] == 'duration_break':
                configs[idx].duration_break = int(N[i + 1]) / 1000.0
            elif N[i] == 'activation_delay':
                configs[idx].activation_delay = int(N[i + 1])
            elif N[i] == 'tap':
                configs[idx].tap = bool(int(N[i + 1]))
            elif N[i] == 'tap_mode':
                configs[idx].tap_mode = N[i + 1]
            elif N[i] == 'marker_check':
                configs[idx].marker_check = bool(int(N[i + 1]))
            i += 2

```

`observer/hardware.py`:

```py
import RPi.GPIO as GPIO

# ----------------------------------------------------------------------------------------------------
# GPIO SETUP AND FUNCTIONS
# ----------------------------------------------------------------------------------------------------

ID_LED_GREEN = 36
ID_LED_RED = 32
ID_RELAY = 18
ID_KEY = 10

GPIO.setmode(GPIO.BOARD)
GPIO.setwarnings(False)
GPIO.setup(ID_LED_GREEN, GPIO.OUT)
GPIO.setup(ID_LED_RED, GPIO.OUT)
GPIO.setup(ID_KEY, GPIO.IN, pull_up_down = GPIO.PUD_DOWN)
GPIO.setup(ID_RELAY, GPIO.OUT)


class gpio:
    @staticmethod
    def led_green(state):
        if (state == False):
            GPIO.output(ID_LED_GREEN, GPIO.LOW)
        else:
            GPIO.output(ID_LED_GREEN, GPIO.HIGH)

    @staticmethod
    def led_red(state):
        if (state == False):
            GPIO.output(ID_LED_RED, GPIO.LOW)
        else:
            GPIO.output(ID_LED_RED, GPIO.HIGH)

    @staticmethod
    def relay(state):
        if (state == False):
            GPIO.output(ID_RELAY, GPIO.LOW)
        else:
            GPIO.output(ID_RELAY, GPIO.HIGH)

    @staticmethod
    def sync_key():
        return GPIO.input(ID_KEY) == GPIO.HIGH

```

`observer/input.py`:

```py
import time
import keyboard

from socket import socket, gethostbyname, AF_INET, SOCK_DGRAM
import queue
import sys
import threading

import hardware


class Synchro:

    def __init__(self):
        pass

    t_open = 0
    t_on = time.time()
    obs_on = False

    active = False

    charged_backup = False
    charged = False

    def sync_observer(self, cfg):

        if cfg.remote_keyboard:
            key_pressed = self.sync_remote_key()
        else:
            key_pressed = hardware.gpio.sync_key()

        if cfg.tap == False:
            if key_pressed:
                if self.obs_on == False:
                    self.t_on = time.time()
                    self.obs_on = True
                    self.charged_backup = False
                elif self.active == False and time.time() - self.t_on > cfg.activation_delay / 1000.0:
                    self.active = True
            else:
                self.obs_on = False
                self.active = False
            hardware.gpio.led_green(self.active)
            return

        if key_pressed:
            if self.obs_on == False:
                self.t_on = time.time()
                self.obs_on = True
                self.active = True
                self.charged_backup = False
            elif self.active == False:
                self.active = True
            if self.charged:
                self.charged = False
                self.charged_backup = True
        else:
            if self.charged == False and time.time() - self.t_on < 0.30:
                if self.charged_backup == False:
                    self.charged = True
            self.obs_on = False
            if self.charged == False:
                self.active = False
            elif self.active == False:
                self.charged = False

        if self.active and self.charged == False:
            hardware.gpio.led_green(True)
        elif self.active:
            if time.time() * 1000.0 % cfg.tap_led_time_on + cfg.tap_led_time_off < cfg.tap_led_time_on:
                hardware.gpio.led_green(True)
            else:
                hardware.gpio.led_green(False)
        else:
            hardware.gpio.led_green(False)

    q = queue.Queue()

    def sync_remote_key(self):
        key_pressed = False
        if not self.q.empty():
            key_pressed = self.q.queue[-1]
            if not key_pressed:
                self.q.queue.clear()
        return key_pressed

    def start_remote_keyboard(self):
        thread_remote_keyboard = threading.Thread(
            target=listen_for_remote_keyboard, name=listen_for_remote_keyboard, args=(self.q,), daemon=True)
        thread_remote_keyboard.start()

# remote keyboard functions
# receives key input from the main computer
# requires client to send packages and is hence exposing the system to the anti-cheat


def listen_for_remote_keyboard(q):

    sock = socket(AF_INET, SOCK_DGRAM)
    sock.bind((gethostbyname('0.0.0.0'), 5000))
    sock.settimeout(5)
    print("connecting to remote keyboard...")

    t_pressed = time.time()
    while True:
        try:
            data = sock.recvfrom(16)[0]
        except socket.timeout:
            print('no remote keyboard client detected')
            break
        if keyboard.is_pressed('+'):
            break
        b = False
        if str(data)[2] != '0':
            b = True
        if b:
            t_pressed = time.time()
        if time.time() - t_pressed < 0.1:
            q.put(True)
        else:
            q.put(False)
    sys.exit(0)

```

`observer/observer.py`:

```py
import hardware
import utility
import input
import calibration
from picamera.array import PiRGBArray
from picamera import PiCamera
import time
import cv2
import numpy
import random
import keyboard
import os
import sys

import config

configs = [config.Config() for x in range(10)]
config.process_configs(configs)
cfg = configs[0]

res = (320, 240)
calib = [0, 0]
focus = [0, 320, 0, 240]

stream = None
stream_img = None

synchro = None


# camera settings (don't use auto mode...)
# iso, brightness and contrast have to be adjusted for lens - monitor - environment conditions

camera = PiCamera()
camera.resolution = res
camera.framerate = 60
camera.awb_mode = 'off'
camera.awb_gains = (3.625, 1.40)
camera.iso = cfg.iso
camera.brightness = cfg.brightness
camera.contrast = cfg.contrast
camera.analog_gain
camera.shutter_speed = 16667  # 1 / (t / s * 10^6)
raw_capture = PiRGBArray(camera, size=(res))

# calculate cut boundaries based on the active config


def focus_area():
    global focus
    focus = (int(res[0] / 2 - cfg.obs_x / 2) + calib[0],
             int(res[0] / 2 + cfg.obs_x / 2) + calib[0],
             int(res[1] / 2 - cfg.obs_y / 2) + calib[1],
             int(res[1] / 2 + cfg.obs_y / 2) + calib[1])

# check if flashed
# only required for absolute difference of frames + (this method is not reliable)


def flashed(img):
    col = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    sat = col[:, :, 1].mean()
    bri = col[:, :, 2].mean() / 2.55
    if sat < 20 and bri > 99.0:
        return True
    else:
        return False

# check if in scope, based on color detection at the crosshair middle
# checks for config-defined color in the vertical and horizontal second third of the focus area
# uses secondary LED as an indicator for its state


def crosshair_indicator(img):
    if cfg.marker_check == False:
        return True
    x_1 = int(cfg.obs_x / 3)
    x_2 = int(cfg.obs_x * 2 / 3)
    y_1 = int(cfg.obs_y / 3)
    y_2 = int(cfg.obs_y * 2 / 3)
    img = img[x_1:x_2, y_1:y_2]
    col = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    low = numpy.array(
        [cfg.col_marker_hue_low, cfg.col_marker_sat_low, cfg.col_marker_bri_low])
    high = numpy.array(
        [cfg.col_marker_hue_high, cfg.col_marker_sat_high, cfg.col_marker_bri_high])
    mask = cv2.inRange(col, low, high)
    pxsum_marker = int(sum(cv2.sumElems(mask / 2.550))) / \
        ((x_2 - x_1) * (y_2 - y_1))
    if pxsum_marker > 1:
        hardware.gpio.led_red(False)
        return True
    else:
        hardware.gpio.led_red(True)
        return False

# keyboard input / control


def keypress(data):

    global cfg
    global calib
    global log_dir

    # calibration, 'enter' + numbers on numpad arrow keys
    # (num lock doesn't work for me and I'm only using a numpad for the Raspberry Pi)
    # shifting the focus area can be viewed in the stream
    # 'enter' + '5' resets the calibration
    if keyboard.is_pressed('enter'):
        time.sleep(0.02)
        if keyboard.is_pressed('4'):
            calib[0] -= 1
        elif keyboard.is_pressed('6'):
            calib[0] += 1
        elif keyboard.is_pressed('8'):
            calib[1] -= 1
        elif keyboard.is_pressed('2'):
            calib[1] += 1
        elif keyboard.is_pressed('5'):
            calib = (0, 0)
        return True

    # config selection
    for key in range(0, 9):
        if keyboard.is_pressed(str(key)):
            cfg = configs[key]
            print('active config changed: [' + str(key) + '] ' + cfg.name)
            time.sleep(2.0)
            return True

    # shut down the program
    if keyboard.is_pressed('+'):
        print("observer shutting down")
        for x in range(0, 10):
            hardware.gpio.led_green(x % 2 == 0)
            hardware.gpio.led_red(x % 2 == 0)
            time.sleep(0.05)
        sys.exit(0)

    # save last positive for inspection
    if keyboard.is_pressed('-'):
        if os.path.isdir("./data/" + str(data.log_dir)):
            os.rename("./data/" + str(data.log_dir), "data/" +
                      str(data.log_dir) + "_inspection")
            print("last positive marked for inspection")
            time.sleep(1.0)

    # print(keyboard.read_key())
    return False


def observe_difference():

    global stream_img

    # has to be initialized for the first run
    crop_focus_prev = numpy.zeros([cfg.obs_x, cfg.obs_y, 3], dtype=numpy.uint8)
    active = False
    t_open = time.time()

    # data object to save frames for analysis + labeling of the streamed frames
    # clears the frames from the last session except the ones marked for inspection
    data = utility.Data()
    data.clear_data()

    # to count iterations
    run = 0

    # calculate focus area based on the active config
    focus_area()

    for frame in camera.capture_continuous(raw_capture, format="bgr", use_video_port=True):

        # randomize relay opening and break duration
        cfg.randomizer()
        utility.run_benchmark(cfg)
        run += 1

        img = frame.array
        crop_focus = img[focus[2]:focus[3], focus[0]:focus[1]]

        raw_capture.truncate(0)

        # sync keyboard input, break if active config is changed
        if keypress(data):
            break

        # the absolute difference enables positives for changes in brightness from dark to bright
        # - most games tested have bright backgrounds and dark targets though
        # using just the subtraction gives a little fewer false positives
        # diff_crop = cv2.absdiff(img_crop, prev_img_crop) # for all changes

        # only for changes from bright to dark
        diff_crop = cv2.subtract(crop_focus_prev, crop_focus)
        thresh_crop = cv2.threshold(diff_crop, 30, 255, cv2.THRESH_BINARY)[1]
        pxsum_crop = int(sum(cv2.sumElems(thresh_crop / 2.55))) / \
            (3.0 * (focus[1] - focus[0]) * (focus[3] - focus[2]))

        # check if key is pressed
        synchro.sync_observer(cfg)

        # draw focus area
        utility.label_frame(img, pxsum_crop, focus, calib, synchro.active)

        # pass the current frame into a global variable (by reference) that is used in the streaming thread
        stream_img[0] = img

        # append frame to temporary stack
        data.update_frames(img)
        data.update_diffs(thresh_crop)
        if run == 0:
            data.save_data()

        # close the relay
        if active and time.time() - t_open > cfg.duration_active:
            time.sleep(random.randint(1, 17) / 1000)
            hardware.gpio.relay(False)
            print("relay closed after " +
                  str(round((time.time() - t_open) * 1000, 1)) + " ms")
            active = False

        # open the relay
        if pxsum_crop >= cfg.sens_diff and active == False and synchro.active and time.time() - t_open > cfg.duration_break and not flashed(crop_focus):
            hardware.gpio.relay(True)
            print("relay opened")
            if cfg.tap_mode == 'charge':
                synchro.active = False
            t_open = time.time()
            active = True
            run = -5

        if active:
            hardware.gpio.led_green(False)

        crop_focus_prev = crop_focus


def observe_color():

    global stream_img
    active = False
    t_open = time.time()

    # data required for consecutive mode
    cons_data = [False] * 3

    # data object to save frames for analysis + labeling of the streamed frames
    # clears the frames from the last session except the ones marked for inspection
    data = utility.Data()
    data.clear_data()

    # to count iterations
    run = 0

    # calculate focus area based on the active config
    focus_area()

    for frame in camera.capture_continuous(raw_capture, format="bgr", use_video_port=True):

        # randomize relay opening and break duration
        cfg.randomizer()
        utility.run_benchmark(cfg)
        run += 1

        img = frame.array
        crop_focus = img[focus[2]:focus[3], focus[0]:focus[1]]

        raw_capture.truncate(0)

        # sync keyboard input, break if active config is changed
        if keypress(data):
            break

        col = cv2.cvtColor(crop_focus, cv2.COLOR_BGR2HSV)
        low = numpy.array([cfg.col_hue_low, cfg.col_sat_low, cfg.col_bri_low])
        high = numpy.array(
            [cfg.col_hue_high, cfg.col_sat_high, cfg.col_bri_high])
        mask = cv2.inRange(col, low, high)
        pxsum_col = int(sum(cv2.sumElems(mask / 2.550))) / \
            ((focus[1] - focus[0]) * (focus[3] - focus[2]))

        # check if key is pressed
        synchro.sync_observer(cfg)

        # draw focus area
        utility.label_frame(img, pxsum_col, focus, calib, synchro.active)

        # pass the current frame into a global variable (by reference) that is used in the streaming thread
        stream_img[0] = img

        # append frame to temporary stack
        data.update_frames(img)
        if run == 0:
            data.save_data()

        # close the relay
        if active and time.time() - t_open > cfg.duration_active:
            time.sleep(random.randint(1, 17) / 1000)
            hardware.gpio.relay(False)
            print("relay closed after " +
                  str(round((time.time() - t_open) * 1000, 1)) + " ms")
            active = False

        # save last results in a buffer
        consecutive_positive = True
        if cfg.consecutive:
            cons_data.append(pxsum_col >= cfg.sens_color)
            cons_data.pop(0)
            consecutive_positive = not False in cons_data

        # check secondary activation condition
        still = crosshair_indicator(crop_focus)

        # open the relay
        if (synchro.active and pxsum_col >= cfg.sens_color and
                active == False and time.time() - t_open > cfg.duration_break and
                still and consecutive_positive):
            time.sleep(cfg.delay / 1000)
            hardware.gpio.relay(True)
            print("relay opened")
            if cfg.tap_mode == 'charge':
                synchro.active = False
            t_open = time.time()
            active = True
            run = -5

        if active:
            hardware.gpio.led_green(False)


def main():

    # keyboard library requires root permissions
    if os.geteuid() != 0:
        print("try again with root privileges")
        time.sleep(2)
        print("observer shutting down")
        sys.exit(0)

    # blinking LEDs as startup sign
    for x in range(0, 2):
        hardware.gpio.led_green(x % 2 == 0)
        hardware.gpio.led_red(x % 2 == 0)
        time.sleep(0.4)

    print("observer running")

    # set up the stream to calibrate
    global stream_img, stream
    stream_img = [numpy.zeros((*res, 4), numpy.uint16) + [0, 0, 0, 128]]
    stream = calibration.Stream(stream_img)
    stream.run_stream()

    # input manager
    global synchro
    synchro = input.Synchro()

    # use socket based input instead of a GPIO button
    if cfg.remote_keyboard:
        synchro.start_remote_keyboard()

    while True:
        if cfg.mode == "color":
            observe_color()
        elif cfg.mode == "difference":
            observe_difference()


if __name__ == "__main__":
    main()

```

`observer/utility.py`:

```py
import time
import numpy as np
import os
import cv2
import shutil

global cfg, ACT_CFG, focus, calib

first_run = True
benchmarks = []
time_last_loop = 0

# print benchmarks every 1000 frames
# for 60 fps the minimum value is 16.667 ms


def run_benchmark(cfg):
    if not cfg.benchmark:
        return
    global first_run
    global benchmarks
    global time_last_loop
    t = time.time() * 1000.0
    d_t = round(t - time_last_loop, 0)
    if first_run != True:
        benchmarks.append(d_t)
    if len(benchmarks) == 1000:
        print("1000f benchmark:", np.average(benchmarks), "ms")
        benchmarks = []
    time_last_loop = t
    first_run = False

# allows to log what the camera sees shortly before and after the relay is opened (10 frames)
# to analyze false positives or adjust sensitivity etc.


class Data:
    frames = []
    diffs = []
    log_dir = None

    def __init__(self):
        self.frames = []
        self.diffs = []
        if not os.path.exists('./data'):
            os.makedirs('./data')

    def update_diffs(self, img):
        self.diffs.append(img)
        if len(self.diffs) > 10:
            self.diffs.pop(0)

    def update_frames(self, img):
        self.frames.append(img)
        if len(self.frames) > 10:
            self.frames.pop(0)

    # save frame buffer for analysis
    # called upon key press
    def save_data(self):
        t = str(int(time.time() * 1000))
        self.log_dir = t
        os.makedirs('./data/' + t)
        n = 0
        for frame in self.frames:
            if len(self.diffs) > 0:
                diff = cv2.resize(self.diffs[n], (320, 240))
                concat = cv2.hconcat([frame, diff])
                cv2.imwrite('./data/' + t + '/concat_' +
                            t + '_' + str(n) + '.jpg', concat)
            else:
                cv2.imwrite('./data/' + t + '/img_' + t +
                            '_' + str(n) + '.jpg', frame)
            n += 1

    # delete frame log from previous session unless directory is marked for analysis
    def clear_data(self):
        for root, dirs, files in os.walk("./data/"):
            for name in dirs:
                if not name.endswith(("_inspection")):
                    shutil.rmtree(os.path.join(root, name), ignore_errors=True)

# draw focus area and center (including calibration)
# draw pxsum


def label_frame(img, pxsum, focus, calib, active):
    cv2.putText(img, "px/% : " + str(round(pxsum, 1)), (20, 220),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
    cv2.line(img, (focus[0], focus[2]),
             (focus[0], focus[3]), (0, 255, 0), thickness=1)
    cv2.line(img, (focus[1], focus[2]),
             (focus[1], focus[3]), (0, 255, 0), thickness=1)
    cv2.line(img, (focus[0], focus[2]),
             (focus[1], focus[2]), (0, 255, 0), thickness=1)
    cv2.line(img, (focus[0], focus[3]),
             (focus[1], focus[3]), (0, 255, 0), thickness=1)
    cv2.rectangle(img, pt1=(158 + calib[0], 118 + calib[1]), pt2=(
        162 + calib[0], 122 + calib[1]), color=(0, 0, 255), thickness=-1)
    if active:
        col = (0, 255, 0)
    else:
        col = (128, 128, 128)
    cv2.rectangle(img, pt1=(4, 4), pt2=(24, 24), color=col, thickness=-1)

```

`remote-keyboard/key.py`:

```py
import keyboard
from socket import socket, AF_INET, SOCK_DGRAM
import time

IP = '192.168.178.41'
PORT = 5000
SIZE = 16
socket = socket( AF_INET, SOCK_DGRAM )

while True:
    msg = '0'
    if keyboard.is_pressed('umschalt'):
        msg = '1'
    socket.sendto(msg.encode('utf-8'), (IP, PORT))
    time.sleep(0.005)
```