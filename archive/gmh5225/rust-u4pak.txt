Project Path: arc_gmh5225_rust-u4pak_w_3fr54q

Source Tree:

```txt
arc_gmh5225_rust-u4pak_w_3fr54q
├── .github
│   └── workflows
│       └── rust.yml
├── .gitignore
├── .gitmodules
├── Cargo.lock
├── Cargo.toml
├── LICENSE.txt
├── README.adoc
├── pak-examples
├── release.sh
├── src
│   ├── bin
│   │   └── u4pak
│   │       ├── args.rs
│   │       ├── io.rs
│   │       ├── list.rs
│   │       ├── main.rs
│   │       └── sort.rs
│   ├── check.rs
│   ├── decode.rs
│   ├── decrypt.rs
│   ├── encode.rs
│   ├── filter.rs
│   ├── index.rs
│   ├── info.rs
│   ├── lib.rs
│   ├── mount.rs
│   ├── pack.rs
│   ├── pak.rs
│   ├── record.rs
│   ├── reopen.rs
│   ├── result.rs
│   ├── unpack.rs
│   ├── util.rs
│   └── walkdir.rs
└── tests
    ├── unpack_v11_it.rs
    ├── unpack_v2_it.rs
    ├── unpack_v3_it.rs
    ├── unpack_v4_it.rs
    ├── unpack_v5_it.rs
    ├── unpack_v7_it.rs
    ├── unpack_v8_it.rs
    ├── unpack_v9_it.rs
    └── util
        └── mod.rs

```

`.github/workflows/rust.yml`:

```yml
name: Rust

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    - name: Fetch example pak files from submodule
      run: git submodule update --init

    - name: Fuse dependency
      run: sudo apt-get install -y libfuse-dev pkg-config

    - name: Cache pak files
      id: cache-pak
      uses: actions/cache@v2
      with:
        path: |
          pak-examples/pak
        key: ${{ runner.os }}-pak-${{ hashFiles('pak-examples/build/download/*') }}
        restore-keys: |
          ${{ runner.os }}-pak-

    - name: Download pak files
      if: steps.cache-pak.outputs.cache-hit != 'true'
      run: |
        cd pak-examples
        chmod u+x download.sh
        ./download.sh

    - uses: Swatinem/rust-cache@v1

    - name: Build
      run: cargo build --verbose

    - name: Run tests
      run: cargo test --verbose

```

`.gitignore`:

```
/target
/tmp
*.zip
*.exe
*.pak
.*
/perf.data
/perf.data.old
/dump
/release
!.keep
!.gitignore
!.github
!.gitmodules
!.gitattributes
```

`.gitmodules`:

```
[submodule "pak-examples"]
	path = pak-examples
	url = https://github.com/Xenira/ue4-pak-examples.git

```

`Cargo.lock`:

```lock
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 3

[[package]]
name = "adler"
version = "1.0.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f26201604c87b1e01bd3d98f8d5d9a8fcbb815e8cedb41ffccbeb4bf593a35fe"

[[package]]
name = "aes"
version = "0.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9e8b47f52ea9bae42228d07ec09eb676433d7c4ed1ebdf0f1d1c29ed446f1ab8"
dependencies = [
 "cfg-if",
 "cipher",
 "cpufeatures",
 "opaque-debug",
]

[[package]]
name = "aho-corasick"
version = "0.7.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e37cfd5e7657ada45f742d6e99ca5788580b5c529dc78faf11ece6dc702656f"
dependencies = [
 "memchr",
]

[[package]]
name = "ansi_term"
version = "0.12.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d52a9bb7ec0cf484c551830a7ce27bd20d67eac647e1befb56b0be4ee39a55d2"
dependencies = [
 "winapi",
]

[[package]]
name = "atty"
version = "0.2.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d9b39be18770d11421cdb1b9947a45dd3f37e93092cbf377614828a319d5fee8"
dependencies = [
 "hermit-abi",
 "libc",
 "winapi",
]

[[package]]
name = "autocfg"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cdb031dd78e28731d87d56cc8ffef4a8f36ca26c38fe2de700543e627f8a464a"

[[package]]
name = "base64"
version = "0.13.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "904dfeac50f3cdaba28fc6f57fdcddb75f49ed61346676a78c4ffe55877802fd"

[[package]]
name = "bitflags"
version = "1.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cf1de2fe8c75bc145a2f577add951f8134889b4795d47466a54a5c846d691693"

[[package]]
name = "boxfnonce"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5988cb1d626264ac94100be357308f29ff7cbdd3b36bda27f450a4ee3f713426"

[[package]]
name = "cc"
version = "1.0.67"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e3c69b077ad434294d3ce9f1f6143a2a4b89a8a2d54ef813d85003a4fd1137fd"

[[package]]
name = "cfg-if"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"

[[package]]
name = "chrono"
version = "0.4.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "670ad68c9088c2a963aaa298cb369688cf3f9465ce5e2d4ca10e6e0098a1ce73"
dependencies = [
 "libc",
 "num-integer",
 "num-traits",
 "time",
 "winapi",
]

[[package]]
name = "cipher"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7ee52072ec15386f770805afd189a01c8841be8696bed250fa2f13c4c0d6dfb7"
dependencies = [
 "generic-array",
]

[[package]]
name = "clap"
version = "2.34.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a0610544180c38b88101fecf2dd634b174a62eef6946f84dfc6a7127512b381c"
dependencies = [
 "ansi_term",
 "atty",
 "bitflags",
 "strsim",
 "textwrap",
 "unicode-width",
 "vec_map",
]

[[package]]
name = "cntr-fuse"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6086675ec972930e5db2402db5456691f1023253c3e18c9a13440fc4c16a39d"
dependencies = [
 "cntr-fuse-abi",
 "cntr-fuse-sys",
 "libc",
 "log",
]

[[package]]
name = "cntr-fuse-abi"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9ea6ecd4a8a57b0262d82c7521f498ecc01f60888091b1eb3b3c70ccafd2a25d"

[[package]]
name = "cntr-fuse-sys"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bfb0da5a62f5c9c384041af4d81ab52c19b0064663d0b5b6626393af20c224f9"
dependencies = [
 "pkg-config",
]

[[package]]
name = "cpufeatures"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "95059428f66df56b63431fdb4e1947ed2190586af5c5a8a8b71122bdf5a7f469"
dependencies = [
 "libc",
]

[[package]]
name = "crc32fast"
version = "1.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "81156fece84ab6a9f2afdb109ce3ae577e42b1228441eded99bd77f627953b1a"
dependencies = [
 "cfg-if",
]

[[package]]
name = "crossbeam-channel"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "06ed27e177f16d65f0f0c22a213e17c696ace5dd64b14258b52f9417ccb52db4"
dependencies = [
 "cfg-if",
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-utils"
version = "0.8.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4feb231f0d4d6af81aed15928e58ecf5816aa62a2393e2c82f46973e92a9a278"
dependencies = [
 "autocfg",
 "cfg-if",
 "lazy_static",
]

[[package]]
name = "daemonize"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "70c24513e34f53b640819f0ac9f705b673fcf4006d7aab8778bee72ebfc89815"
dependencies = [
 "boxfnonce",
 "libc",
]

[[package]]
name = "env_logger"
version = "0.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b2cf0344971ee6c64c31be0d530793fba457d322dfec2810c453d0ef228f9c3"
dependencies = [
 "atty",
 "humantime",
 "log",
 "regex",
 "termcolor",
]

[[package]]
name = "flate2"
version = "1.0.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e6988e897c1c9c485f43b47a529cef42fde0547f9d8d41a7062518f1d8fc53f"
dependencies = [
 "cfg-if",
 "crc32fast",
 "libc",
 "miniz_oxide",
]

[[package]]
name = "foreign-types"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6f339eb8adc052cd2ca78910fda869aefa38d22d5cb648e6485e4d3fc06f3b1"
dependencies = [
 "foreign-types-shared",
]

[[package]]
name = "foreign-types-shared"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "00b0228411908ca8685dba7fc2cdd70ec9990a6e753e89b6ac91a84c40fbaf4b"

[[package]]
name = "generic-array"
version = "0.14.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "501466ecc8a30d1d3b7fc9229b122b2ce8ed6e9d9223f1138d4babb253e51817"
dependencies = [
 "typenum",
 "version_check",
]

[[package]]
name = "hermit-abi"
version = "0.1.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "322f4de77956e22ed0e5032c359a0f1273f1f7f0d79bfa3b8ffbc730d7fbcc5c"
dependencies = [
 "libc",
]

[[package]]
name = "humantime"
version = "2.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a3a5bfb195931eeb336b2a7b4d761daec841b97f947d34394601737a7bba5e4"

[[package]]
name = "lazy_static"
version = "1.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e2abad23fbc42b3700f2f279844dc832adb2b2eb069b2df918f455c4e18cc646"

[[package]]
name = "libc"
version = "0.2.113"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "eef78b64d87775463c549fbd80e19249ef436ea3bf1de2a1eb7e717ec7fab1e9"

[[package]]
name = "log"
version = "0.4.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "51b9bbe6c47d51fc3e1a9b945965946b4c44142ab8792c50835a980d362c2710"
dependencies = [
 "cfg-if",
]

[[package]]
name = "memchr"
version = "2.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "308cc39be01b73d0d18f82a0e7b2a3df85245f84af96fdddc5d202d27e47b86a"

[[package]]
name = "miniz_oxide"
version = "0.4.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a92518e98c078586bc6c934028adcca4c92a53d6a958196de835170a01d84e4b"
dependencies = [
 "adler",
 "autocfg",
]

[[package]]
name = "num-integer"
version = "0.1.44"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d2cc698a63b549a70bc047073d2949cce27cd1c7b0a4a862d08a8031bc2801db"
dependencies = [
 "autocfg",
 "num-traits",
]

[[package]]
name = "num-traits"
version = "0.2.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a64b1ec5cda2586e284722486d802acf1f7dbdc623e2bfc57e65ca1cd099290"
dependencies = [
 "autocfg",
]

[[package]]
name = "num_cpus"
version = "1.13.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "19e64526ebdee182341572e50e9ad03965aa510cd94427a4549448f285e957a1"
dependencies = [
 "hermit-abi",
 "libc",
]

[[package]]
name = "once_cell"
version = "1.7.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "af8b08b04175473088b46763e51ee54da5f9a164bc162f615b91bc179dbf15a3"

[[package]]
name = "opaque-debug"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "624a8340c38c1b80fd549087862da4ba43e08858af025b236e509b6649fc13d5"

[[package]]
name = "openssl"
version = "0.10.34"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6d7830286ad6a3973c0f1d9b73738f69c76b739301d0229c4b96501695cbe4c8"
dependencies = [
 "bitflags",
 "cfg-if",
 "foreign-types",
 "libc",
 "once_cell",
 "openssl-sys",
]

[[package]]
name = "openssl-src"
version = "111.17.0+1.1.1m"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "05d6a336abd10814198f66e2a91ccd7336611f30334119ca8ce300536666fcf4"
dependencies = [
 "cc",
]

[[package]]
name = "openssl-sys"
version = "0.9.63"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6b0d6fb7d80f877617dfcb014e605e2b5ab2fb0afdf27935219bb6bd984cb98"
dependencies = [
 "autocfg",
 "cc",
 "libc",
 "openssl-src",
 "pkg-config",
 "vcpkg",
]

[[package]]
name = "pkg-config"
version = "0.3.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3831453b3449ceb48b6d9c7ad7c96d5ea673e9b470a1dc578c2ce6521230884c"

[[package]]
name = "regex"
version = "1.5.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d07a8629359eb56f1e2fb1652bb04212c072a87ba68546a04065d525673ac461"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-syntax",
]

[[package]]
name = "regex-syntax"
version = "0.6.25"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f497285884f3fcff424ffc933e56d7cbca511def0c9831a7f9b5f6153e3cc89b"

[[package]]
name = "strsim"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8ea5119cdb4c55b55d432abb513a0429384878c15dde60cc77b1c99de1a95a6a"

[[package]]
name = "termcolor"
version = "1.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2dfed899f0eb03f32ee8c6a0aabdb8a7949659e3466561fc0adf54e26d88c5f4"
dependencies = [
 "winapi-util",
]

[[package]]
name = "terminal_size"
version = "0.1.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "633c1a546cee861a1a6d0dc69ebeca693bf4296661ba7852b9d21d159e0506df"
dependencies = [
 "libc",
 "winapi",
]

[[package]]
name = "textwrap"
version = "0.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d326610f408c7a4eb6f51c37c330e496b08506c9457c9d34287ecc38809fb060"
dependencies = [
 "unicode-width",
]

[[package]]
name = "time"
version = "0.1.44"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6db9e6914ab8b1ae1c260a4ae7a49b6c5611b40328a735b21862567685e73255"
dependencies = [
 "libc",
 "wasi",
 "winapi",
]

[[package]]
name = "typenum"
version = "1.13.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "879f6906492a7cd215bfa4cf595b600146ccfac0c79bcbd1f3000162af5e8b06"

[[package]]
name = "u4pak"
version = "1.4.0"
dependencies = [
 "aes",
 "base64",
 "chrono",
 "clap",
 "cntr-fuse",
 "crossbeam-channel",
 "crossbeam-utils",
 "daemonize",
 "env_logger",
 "flate2",
 "libc",
 "log",
 "num_cpus",
 "openssl",
 "terminal_size",
]

[[package]]
name = "unicode-width"
version = "0.1.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9337591893a19b88d8d87f2cec1e73fad5cdfd10e5a6f349f498ad6ea2ffb1e3"

[[package]]
name = "vcpkg"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cbdbff6266a24120518560b5dc983096efb98462e51d0d68169895b237be3e5d"

[[package]]
name = "vec_map"
version = "0.8.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f1bddf1187be692e79c5ffeab891132dfb0f236ed36a43c7ed39f1165ee20191"

[[package]]
name = "version_check"
version = "0.9.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5fecdca9a5291cc2b8dcf7dc02453fee791a280f3743cb0905f8822ae463b3fe"

[[package]]
name = "wasi"
version = "0.10.0+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1a143597ca7c7793eff794def352d41792a93c481eb1042423ff7ff72ba2c31f"

[[package]]
name = "winapi"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5c839a674fcd7a98952e593242ea400abe93992746761e38641405d28b00f419"
dependencies = [
 "winapi-i686-pc-windows-gnu",
 "winapi-x86_64-pc-windows-gnu",
]

[[package]]
name = "winapi-i686-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ac3b87c63620426dd9b991e5ce0329eff545bccbbb34f3be09ff6fb6ab51b7b6"

[[package]]
name = "winapi-util"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "70ec6ce85bb158151cae5e5c87f95a8e97d2c0c4b001223f33a334e3ce5de178"
dependencies = [
 "winapi",
]

[[package]]
name = "winapi-x86_64-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"

```

`Cargo.toml`:

```toml
[package]
name = "u4pak"
version = "1.4.0"
authors = ["Mathias Panzenböck <grosser.meister.morti@gmx.net>", "L. Sprengel <l.sprengel@pm.me>"]
edition = "2018"
license-file = "LICENSE.txt"

[[bin]]
name="u4pak"
path="src/bin/u4pak/main.rs"

[lib]
name="u4pak"
path="src/lib.rs"

[dependencies]
clap = "2.34"
chrono = "0.4"
flate2 = "1.0.22"
#flate2 = { version = "1.0.20", features = ["zlib"], default-features = false }
crossbeam-channel = "0.5"
crossbeam-utils = "0.8"
num_cpus = "1.13.1"
# OpenSSL's SHA-1 implementation is much faster than the one in rust-crypto
openssl = { version = "0.10", features = ["vendored"] }
terminal_size = "0.1.17"
aes = "0.7.5"
base64 = "0.13.0"
log = "0.4"
env_logger = "0.9.0"

[target.'cfg(target_os = "linux")'.dependencies]
# for sendfile() and fuse support
libc = "0.2.113"

# FUSE might work on other OSes too (like macOS and BSD), but I don't use
# anything other than Linux (testing Windows binaries through wine).
# Also I use "cntr-fuse" because it seems to be more actively maintained than
# "fuse". Is that a wise choice?
cntr-fuse = { version = "0.4" }

daemonize = { version = "0.4.1" }

```

`LICENSE.txt`:

```txt
Mozilla Public License Version 2.0
==================================

1. Definitions
--------------

1.1. "Contributor"
    means each individual or legal entity that creates, contributes to
    the creation of, or owns Covered Software.

1.2. "Contributor Version"
    means the combination of the Contributions of others (if any) used
    by a Contributor and that particular Contributor's Contribution.

1.3. "Contribution"
    means Covered Software of a particular Contributor.

1.4. "Covered Software"
    means Source Code Form to which the initial Contributor has attached
    the notice in Exhibit A, the Executable Form of such Source Code
    Form, and Modifications of such Source Code Form, in each case
    including portions thereof.

1.5. "Incompatible With Secondary Licenses"
    means

    (a) that the initial Contributor has attached the notice described
        in Exhibit B to the Covered Software; or

    (b) that the Covered Software was made available under the terms of
        version 1.1 or earlier of the License, but not also under the
        terms of a Secondary License.

1.6. "Executable Form"
    means any form of the work other than Source Code Form.

1.7. "Larger Work"
    means a work that combines Covered Software with other material, in 
    a separate file or files, that is not Covered Software.

1.8. "License"
    means this document.

1.9. "Licensable"
    means having the right to grant, to the maximum extent possible,
    whether at the time of the initial grant or subsequently, any and
    all of the rights conveyed by this License.

1.10. "Modifications"
    means any of the following:

    (a) any file in Source Code Form that results from an addition to,
        deletion from, or modification of the contents of Covered
        Software; or

    (b) any new file in Source Code Form that contains any Covered
        Software.

1.11. "Patent Claims" of a Contributor
    means any patent claim(s), including without limitation, method,
    process, and apparatus claims, in any patent Licensable by such
    Contributor that would be infringed, but for the grant of the
    License, by the making, using, selling, offering for sale, having
    made, import, or transfer of either its Contributions or its
    Contributor Version.

1.12. "Secondary License"
    means either the GNU General Public License, Version 2.0, the GNU
    Lesser General Public License, Version 2.1, the GNU Affero General
    Public License, Version 3.0, or any later versions of those
    licenses.

1.13. "Source Code Form"
    means the form of the work preferred for making modifications.

1.14. "You" (or "Your")
    means an individual or a legal entity exercising rights under this
    License. For legal entities, "You" includes any entity that
    controls, is controlled by, or is under common control with You. For
    purposes of this definition, "control" means (a) the power, direct
    or indirect, to cause the direction or management of such entity,
    whether by contract or otherwise, or (b) ownership of more than
    fifty percent (50%) of the outstanding shares or beneficial
    ownership of such entity.

2. License Grants and Conditions
--------------------------------

2.1. Grants

Each Contributor hereby grants You a world-wide, royalty-free,
non-exclusive license:

(a) under intellectual property rights (other than patent or trademark)
    Licensable by such Contributor to use, reproduce, make available,
    modify, display, perform, distribute, and otherwise exploit its
    Contributions, either on an unmodified basis, with Modifications, or
    as part of a Larger Work; and

(b) under Patent Claims of such Contributor to make, use, sell, offer
    for sale, have made, import, and otherwise transfer either its
    Contributions or its Contributor Version.

2.2. Effective Date

The licenses granted in Section 2.1 with respect to any Contribution
become effective for each Contribution on the date the Contributor first
distributes such Contribution.

2.3. Limitations on Grant Scope

The licenses granted in this Section 2 are the only rights granted under
this License. No additional rights or licenses will be implied from the
distribution or licensing of Covered Software under this License.
Notwithstanding Section 2.1(b) above, no patent license is granted by a
Contributor:

(a) for any code that a Contributor has removed from Covered Software;
    or

(b) for infringements caused by: (i) Your and any other third party's
    modifications of Covered Software, or (ii) the combination of its
    Contributions with other software (except as part of its Contributor
    Version); or

(c) under Patent Claims infringed by Covered Software in the absence of
    its Contributions.

This License does not grant any rights in the trademarks, service marks,
or logos of any Contributor (except as may be necessary to comply with
the notice requirements in Section 3.4).

2.4. Subsequent Licenses

No Contributor makes additional grants as a result of Your choice to
distribute the Covered Software under a subsequent version of this
License (see Section 10.2) or under the terms of a Secondary License (if
permitted under the terms of Section 3.3).

2.5. Representation

Each Contributor represents that the Contributor believes its
Contributions are its original creation(s) or it has sufficient rights
to grant the rights to its Contributions conveyed by this License.

2.6. Fair Use

This License is not intended to limit any rights You have under
applicable copyright doctrines of fair use, fair dealing, or other
equivalents.

2.7. Conditions

Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted
in Section 2.1.

3. Responsibilities
-------------------

3.1. Distribution of Source Form

All distribution of Covered Software in Source Code Form, including any
Modifications that You create or to which You contribute, must be under
the terms of this License. You must inform recipients that the Source
Code Form of the Covered Software is governed by the terms of this
License, and how they can obtain a copy of this License. You may not
attempt to alter or restrict the recipients' rights in the Source Code
Form.

3.2. Distribution of Executable Form

If You distribute Covered Software in Executable Form then:

(a) such Covered Software must also be made available in Source Code
    Form, as described in Section 3.1, and You must inform recipients of
    the Executable Form how they can obtain a copy of such Source Code
    Form by reasonable means in a timely manner, at a charge no more
    than the cost of distribution to the recipient; and

(b) You may distribute such Executable Form under the terms of this
    License, or sublicense it under different terms, provided that the
    license for the Executable Form does not attempt to limit or alter
    the recipients' rights in the Source Code Form under this License.

3.3. Distribution of a Larger Work

You may create and distribute a Larger Work under terms of Your choice,
provided that You also comply with the requirements of this License for
the Covered Software. If the Larger Work is a combination of Covered
Software with a work governed by one or more Secondary Licenses, and the
Covered Software is not Incompatible With Secondary Licenses, this
License permits You to additionally distribute such Covered Software
under the terms of such Secondary License(s), so that the recipient of
the Larger Work may, at their option, further distribute the Covered
Software under the terms of either this License or such Secondary
License(s).

3.4. Notices

You may not remove or alter the substance of any license notices
(including copyright notices, patent notices, disclaimers of warranty,
or limitations of liability) contained within the Source Code Form of
the Covered Software, except that You may alter any license notices to
the extent required to remedy known factual inaccuracies.

3.5. Application of Additional Terms

You may choose to offer, and to charge a fee for, warranty, support,
indemnity or liability obligations to one or more recipients of Covered
Software. However, You may do so only on Your own behalf, and not on
behalf of any Contributor. You must make it absolutely clear that any
such warranty, support, indemnity, or liability obligation is offered by
You alone, and You hereby agree to indemnify every Contributor for any
liability incurred by such Contributor as a result of warranty, support,
indemnity or liability terms You offer. You may include additional
disclaimers of warranty and limitations of liability specific to any
jurisdiction.

4. Inability to Comply Due to Statute or Regulation
---------------------------------------------------

If it is impossible for You to comply with any of the terms of this
License with respect to some or all of the Covered Software due to
statute, judicial order, or regulation then You must: (a) comply with
the terms of this License to the maximum extent possible; and (b)
describe the limitations and the code they affect. Such description must
be placed in a text file included with all distributions of the Covered
Software under this License. Except to the extent prohibited by statute
or regulation, such description must be sufficiently detailed for a
recipient of ordinary skill to be able to understand it.

5. Termination
--------------

5.1. The rights granted under this License will terminate automatically
if You fail to comply with any of its terms. However, if You become
compliant, then the rights granted under this License from a particular
Contributor are reinstated (a) provisionally, unless and until such
Contributor explicitly and finally terminates Your grants, and (b) on an
ongoing basis, if such Contributor fails to notify You of the
non-compliance by some reasonable means prior to 60 days after You have
come back into compliance. Moreover, Your grants from a particular
Contributor are reinstated on an ongoing basis if such Contributor
notifies You of the non-compliance by some reasonable means, this is the
first time You have received notice of non-compliance with this License
from such Contributor, and You become compliant prior to 30 days after
Your receipt of the notice.

5.2. If You initiate litigation against any entity by asserting a patent
infringement claim (excluding declaratory judgment actions,
counter-claims, and cross-claims) alleging that a Contributor Version
directly or indirectly infringes any patent, then the rights granted to
You by any and all Contributors for the Covered Software under Section
2.1 of this License shall terminate.

5.3. In the event of termination under Sections 5.1 or 5.2 above, all
end user license agreements (excluding distributors and resellers) which
have been validly granted by You or Your distributors under this License
prior to termination shall survive termination.

************************************************************************
*                                                                      *
*  6. Disclaimer of Warranty                                           *
*  -------------------------                                           *
*                                                                      *
*  Covered Software is provided under this License on an "as is"       *
*  basis, without warranty of any kind, either expressed, implied, or  *
*  statutory, including, without limitation, warranties that the       *
*  Covered Software is free of defects, merchantable, fit for a        *
*  particular purpose or non-infringing. The entire risk as to the     *
*  quality and performance of the Covered Software is with You.        *
*  Should any Covered Software prove defective in any respect, You     *
*  (not any Contributor) assume the cost of any necessary servicing,   *
*  repair, or correction. This disclaimer of warranty constitutes an   *
*  essential part of this License. No use of any Covered Software is   *
*  authorized under this License except under this disclaimer.         *
*                                                                      *
************************************************************************

************************************************************************
*                                                                      *
*  7. Limitation of Liability                                          *
*  --------------------------                                          *
*                                                                      *
*  Under no circumstances and under no legal theory, whether tort      *
*  (including negligence), contract, or otherwise, shall any           *
*  Contributor, or anyone who distributes Covered Software as          *
*  permitted above, be liable to You for any direct, indirect,         *
*  special, incidental, or consequential damages of any character      *
*  including, without limitation, damages for lost profits, loss of    *
*  goodwill, work stoppage, computer failure or malfunction, or any    *
*  and all other commercial damages or losses, even if such party      *
*  shall have been informed of the possibility of such damages. This   *
*  limitation of liability shall not apply to liability for death or   *
*  personal injury resulting from such party's negligence to the       *
*  extent applicable law prohibits such limitation. Some               *
*  jurisdictions do not allow the exclusion or limitation of           *
*  incidental or consequential damages, so this exclusion and          *
*  limitation may not apply to You.                                    *
*                                                                      *
************************************************************************

8. Litigation
-------------

Any litigation relating to this License may be brought only in the
courts of a jurisdiction where the defendant maintains its principal
place of business and such litigation shall be governed by laws of that
jurisdiction, without reference to its conflict-of-law provisions.
Nothing in this Section shall prevent a party's ability to bring
cross-claims or counter-claims.

9. Miscellaneous
----------------

This License represents the complete agreement concerning the subject
matter hereof. If any provision of this License is held to be
unenforceable, such provision shall be reformed only to the extent
necessary to make it enforceable. Any law or regulation which provides
that the language of a contract shall be construed against the drafter
shall not be used to construe this License against a Contributor.

10. Versions of the License
---------------------------

10.1. New Versions

Mozilla Foundation is the license steward. Except as provided in Section
10.3, no one other than the license steward has the right to modify or
publish new versions of this License. Each version will be given a
distinguishing version number.

10.2. Effect of New Versions

You may distribute the Covered Software under the terms of the version
of the License under which You originally received the Covered Software,
or under the terms of any subsequent version published by the license
steward.

10.3. Modified Versions

If you create software not governed by this License, and you want to
create a new license for such software, you may create and use a
modified version of this License if you rename the license and remove
any references to the name of the license steward (except to note that
such modified license differs from this License).

10.4. Distributing Source Code Form that is Incompatible With Secondary
Licenses

If You choose to distribute Source Code Form that is Incompatible With
Secondary Licenses under the terms of this version of the License, the
notice described in Exhibit B of this License must be attached.

Exhibit A - Source Code Form License Notice
-------------------------------------------

  This Source Code Form is subject to the terms of the Mozilla Public
  License, v. 2.0. If a copy of the MPL was not distributed with this
  file, You can obtain one at https://mozilla.org/MPL/2.0/.

If it is not possible or desirable to put the notice in a particular
file, then You may include the notice in a location (such as a LICENSE
file in a relevant directory) where a recipient would be likely to look
for such a notice.

You may add additional accurate notices of copyright ownership.

Exhibit B - "Incompatible With Secondary Licenses" Notice
---------------------------------------------------------

  This Source Code Form is "Incompatible With Secondary Licenses", as
  defined by the Mozilla Public License, v. 2.0.

```

`README.adoc`:

```adoc
= Rust U4Pak
Mathias Panzenböck <grosser.meister.morti@gmx.net>; L. Sprengel <l.sprengel@pm.me>
v1.4.0
:icons: font
:sectnums:
:toc: left
:toclevels: 3

image:https://img.shields.io/github/workflow/status/panzi/rust-u4pak/Rust["Build status", link=https://github.com/panzi/rust-u4pak/actions/workflows/rust.yml]
image:https://img.shields.io/github/v/release/panzi/rust-u4pak["Release",link="https://github.com/panzi/rust-u4pak/releases"]
image:https://img.shields.io/github/license/panzi/rust-u4pak?cachebust=1["License",link="https://github.com/panzi/rust-u4pak/blob/main/LICENSE.txt"]

More or less re-implementation of https://github.com/panzi/u4pak[Python U4Pak]
for fun, ease of use (standalone binary), and speed (multi-threading).

This is a tool to pack, unpack, check, and list the contents of Unreal Engine 4
packages. Under Linux it can also be used to read-only FUSE-mount archives. Note
that only a limited number of pak versions are supported.

.Supported Versions
|====
|Pak Version |Unreal Engine Version |Reading |Writing
|1  |< 4.0 |✔️ |✔️
|2  |4.0 - 4.2 |✔️ |✔️
|3  |4.3 - 4.15 |✔️ |✔️
|4  |4.16 - 4.19 |✔️ |❌
|5  |4.20 |✔️ |❌
|6  |- |✔️ |❌
|7  |4.21 |✔️ |❌
|8  |4.22 - 4.24 |✔️ |❌
|9  |4.25 |✔️ |❌
|10 |-    |✔️ |❌
|11 |4.26 - 4.27 |✔️ |❌
|====

.Supported Compression
|====
|Name |Supported
|None |✔️
|https://zlib.net[Zlib] |✔️
|https://www.gnu.org/software/gzip/[Gzip] |❌
|https://lz4.github.io/lz4/[LZ4] |❌
|====

Instead of passing arguments you can also put the arguments in a file with the
extension .u4pak and pass the path to that instead. This is useful for Windows
users that aren't used to a terminal. You can even associate the extension with
u4pak.exe so that it will be automatically opened with it when you double click
it. File paths in a .u4pak file are relative to the directory containing the
file. The syntax of these files is not shell syntax. If you don't have any white
space, double quotes (`"`), or hash marks (`#`) in your file names you don't have
to worry about anything. `#` is used to start a comment line (only if it doesn't
touch any non-white space on it's left) and `"` is used to quote arguments
containing white space, `#`, or `"`. In order to write a `"` in a quoted argument
you simply need to double it, meaning an argument that contains nothing but a
single `"` is written as `""""`. Newlines are ignored like any other white space.
An example .u4pak file whould be:

```sh
# This is packing my project:
pack
--version=4
--mount-point=../../..

"C:\Users\Alice\My Documents\U4Project\NewArchive.pak"

":rename=/:C:\Users\Alice\My Documents\U4Project\Some Files"
":zlib,rename=/:Some Other Files"
```

If u4pak.exe is run by double clicking or by dropping a .u4pak file on it it
won't immediately close the terminal window, but will instead ask you to press
ENTER. It does this so you have a chance to read the output. Since I don't use
Windows (I cross compile on Linux and test with Wine) I could not test this
particular feature. If it doesn't work please report a bug. In order to force
the "Press ENTER to continue..." message you can pass the argument
`--pause-on-exit=always` (Windows-only).

== Usage

```
u4pak [--pause-on-exit=<always|never|auto>] [SUBCOMMAND]
```

Or:

```
u4pak "C:\Path\to\arguments.u4pak"
```

== Sub-Commands

|====
| Sub-Command |Description
| check       | Check consistency of a package
| help        | Prints general help message or the help of the given subcommand(s)
| info        | Show summarized information of a package
| list        | List content of a package
| mount       | Mount package as read-only filesystem (Linux-only)
| pack        | Create a new package
| unpack      | Unpack content of a package
|====

For help to the various sub-commands run `u4pak help SUBCOMMAND`.

== File Format

Byte order is little endian and the character encoding of file names seems to be
ASCII (or ISO-8859-1/UTF-8 that coincidentally only uses ASCII compatiple
characters).

Offsets and sizes seem to be 64bit or at least unsigned 32bit integers. If
interpreted as 32bit integers all sizes (except the size of file names) and offsets
are followed by another 32bit integer of the value 0, which makes me guess these
are 64bit values. Also some values exceed the range of signed 32bit integers, so
they have to be at least unsigned 32bit integers.

This information was reverse engineered from the Elemental
https://wiki.unrealengine.com/Linux_Demos[Demo] for Linux (which contains a 2.5
GB .pak file), the https://www.techpowerup.com/download/unreal-engine-4-five-tech-demos/[Unreal Engine 4 - Five Tech Demos],
version 7 was reverse engineered from the https://store.steampowered.com/app/813630/Supraland/[Supraland Demo],
and the Conan Exiles variant was reverse egineered from the
https://steamcommunity.com/sharedfiles/filedetails/?id=1765361591[SandstormFix_EXP workshop item].
Reverse engineering was done by poking around the pak files with a hex editor,
no kind of decompilation was done by me.

Versions >= 8 where reversed from an empty unreal engine project.

.Basic layout
* Data Records
* Index
** Index Header
** Index Records
* Footer

In order to parse a file you need to read the footer first. The footer contains
an offset pointer to the start of the index records. The index records then
contain offset pointers to the data records.

[[encoded-record]]
=== Encoded Record

[subs="quotes"]
----
*Offset  Size  Type         Description*
     0     4  uint32_t     bitfield containing record information
                              0-5  : Compression block size
                              6-21 : Compression blocks count
                              22   : Encrypted
                              23-28: Compression method
                              29   : Size 32-bit safe?
                              30   : Uncompressed size 32-bit safe?
                              31   : Offset 32-bit safe?
_if offset 32 bit_
     4     4  uint32_t     offset
_else_
     4     8  uint64_t     offset
_end_
_if uncompressed size 32 bit_
     ?     4  uint32_t     uncompressed size
_else_
     ?     8  uint64_t     uncompressed size
_end_
_if compression method != 0x00_
  _if size 32 bit_
     ?     4  uint32_t     size
  _else_
     ?     4  uint32_t     size
  _end_
_end_
_if compression block count > 0 && (encrypted || compression block count != 1)_
  _for _ in 0..compression block count_
     ?     4  uint32_t     block size
  _end_
_end_
----

=== Record
NOTE: This structure, while still present in version >= 10 is not used anymore by default. See xref:encoded-record[Encoded Record] for the current record information.

[subs="quotes"]
----
*Offset  Size  Type         Description*
     0     8  uint64_t     offset
     8     8  uint64_t     size (N)
    16     8  uint64_t     uncompressed size
    24     4  uint32_t     compression method:
                              0x00 ... none
                              0x01 ... zlib
                              0x10 ... bias memory
                              0x20 ... bias speed
_if version <= 1_
    28     8  uint64_t     timestamp
_end_
     ?    20  uint8_t[20]  data sha1 hash
_if version >= 3_
 _if compression_method != 0x00_
  ?+20     4  uint32_t     block count (M)
  ?+24  M*16  CB[M]        compression blocks
 _end_
     ?     1  uint8_t      is encrypted
   ?+1     4  uint32_t     The uncompressed size of each compression block.
_end_                        The last block can be smaller, of course.
_if variant == "Conan Exiles"_
     ?     4  uint32_t     Unknown field. For Conan Exiles index record only
                           seen it to have the value 0.
_end_
----

=== Compression Block (CB)
[horizontal]
Size:: 16 bytes

[subs="quotes"]
----
*Offset  Size  Type         Description*
     0     8  uint64_t     compressed data block start offset.
                           version <= 4: offset is absolute to the file
                           version 7: offset is relative to the offset
                                      field in the corresponding Record
     8     8  uint64_t     compressed data block end offset.
                           There may or may not be a gap between blocks.
                           version <= 4: offset is absolute to the file
                           version 7: offset is relative to the offset
                                      field in the corresponding Record
----

=== Data Record
[subs="quotes"]
----
*Offset  Size  Type            Description*
     0     ?  Record          file metadata (offset field is 0, N = compressed_size)
_if variant == "Conan Exiles"_
     ?    20  ?               Unknown. Maybe another SHA-1 sum of something?
                              The first 4 bytes have values other than the extra
                              4 bytes in the index record, which is why I didn't
                              put those into the general record structure.
_else if version >= 4 and compression_method != 0x00_
     ?     4  uint32_t        Unknown.
_end_
     ?     N  uint8_t[N]      file data
----

[NOTE]
====
Starting with version 4 there is an additional 4 bytes in the repeated
*data* record copy (the record that precedes the actual file date, not the
record in the index). I don't know what that is. It is not always the same value.
E.g. it is the same for some files, but different for others. The first 2 bytes
seem to be always the same (`0x78 0x9c` in a v4 and a v7 pak that I saw), so maybe
its 2 16 bit fields?

This is why I've deactivated packing for versions > 3.
====

[[fdi]]
=== Full Directory Index
The data structure is a map<DirectoryName, map<FileName, offset>>.

[subs="normal"]
----
*Offset  Size  Type            Description*
     0     4  uint32_t        directory count (D)
_for i in 0..D_
     ?     4  int32_t         directory name size (DS)
                              For some games a negative value means it's a UTF-16
                              string in 2 * -S bytes.
   ?+4    DS  char[DS]        directory name (includes terminating null byte)
?+4+DS     4  uint32_t        file count (F)
  _for j in 0..F_
     ?     4  int32_t         file name size (FS)
                              For some games a negative value means it's a UTF-16
                              string in 2 * -S bytes.
   ?+4    FS  char[FS]        file name (includes terminating null byte)
?+4+FS     4  uint32_t        offset in xref:directory-info[encoded entry info]
  _end_
_end_
----


=== Index Record
NOTE: This structure, while still present in version >= 10 is not used anymore by default. See xref:fdi[Full Directory Index] for record information.

[subs="quotes"]
----
*Offset  Size  Type            Description*
     0     4  int32_t         file name size (S)
                              For some games a negative value means it's a UTF-16
                              string in 2 * -S bytes.
     4     S  char[S]         file name (includes terminating null byte)
   4+S     ?  Record          file metadata
_if variant == "Conan Exiles"_
     ?     4  ?               Unknown. Only saw all 0 so far.
_end_
----

=== Index
[subs="normal,callouts"]
.Version >= 10
----
*Offset  Size  Type            Description*
     0     4  int32_t         mount point size (S)
                              For some games a negative value means it's a UTF-16
                              string in 2 * -S bytes.
     4     S  char[S]         mount point (includes terminating null byte)
   S+4     4  int32_t         entry count
   S+8     8  uint64_t        path hash seed <1>
  S+16     4  uint32_t        has path hash index
_if has path index != 0_
  S+20     8  int64_t         path hash index offset
  S+28     8  int64_t         path hash index size
  S+36    20  uint8_t[20]     path hash index hash
_end_
     ?     4  uint32_t        has full directory index
_if has full directory index != 0_
   ?+4     8  int64_t         full directory index offset
  ?+12     8                  full directory index size
  ?+20    20  uint8_t[20]     full directory index hash
_end_
     ?     4  int32_t         encoded entry info size (P)
   ?+4     P  uint8_t[P]      encoded entry info [[directory-info]]
   ?+P     4  uint32_t        file count, probably unused / 0 (N)
 ?+P+4     ?  IndexRecord[N]  records
----
<1> Needs clarification

[subs="quotes"]
.Legacy (Version < 10)
----
*Offset  Size  Type            Description*
     0     4  int32_t         mount point size (S)
                              For some games a negative value means it's a UTF-16
                              string in 2 * -S bytes.
     4     S  char[S]         mount point (includes terminating null byte)
   S+4     4  uint32_t        record count (N)
   S+8     ?  IndexRecord[N]  records
----

=== Footer
[horizontal]
.Size and index features
|====
|Versions |Size |Index Encryption |Encryption Key Guid |Compression method name |Frozen Index
|v1 - v3 |44 bytes |❌ |❌ |❌ |❌
|v4 - v6 | 45 bytes |✔️ |❌ |❌ |❌
|v7 | 65 bytes |✔️ |✔️ |❌ |❌
|v8 | 193 bytes |✔️ |✔️ |✔️(Max. 4) |❌
|v9 | 226 bytes |✔️ |✔️ |✔️(Max. 5) |✔️
|v10 - v11 | 225 bytes |✔️ |✔️ |✔️(Max. 5) |❌
|====

[subs="quotes"]
----
*Offset  Size  Type         Description*
_if version >= 7_
     0    20  uint8_t[20]  encryption key Guid
_end_
_if version >= 4_
     ?     1  uint8_t      encrypted index
_end_
     ?     4  uint32_t     magic: 0x5A6F12E1
   ?+4     4  uint32_t     version: 1 - 11
   ?+8     8  uint64_t     index offset
  ?+16     8  uint64_t     index size
  ?+24    20  uint8_t[20]  index sha1 hash
_if version == 9_
  ?+44     1  uint8_t      frozen index
_end_
_if version == 8_
  ?+44   128  uint8_t[128] compression methods (4 * 32 chars)
_else if version > 8_
     ?   160  uint8_t[160] compression methods (5 * 32 chars)
_end_
----

== Related Projects

* https://github.com/panzi/fezpak[fezpak]: pack, unpack, list and mount FEZ .pak archives
* https://github.com/panzi/psypkg[psypkg]: pack, unpack, list and mount Psychonauts .pkg archives
* https://github.com/panzi/bgebf[bgebf]: unpack, list and mount Beyond Good and Evil .bf archives
* https://github.com/panzi/unvpk[unvpk]: extract, list, check and mount Valve .vpk archives (C++)
* https://github.com/panzi/rust-vpk[rust-vpk]: Rust rewrite of the above (Rust)
* https://github.com/panzi/t2fbq[t2fbq]: unpack, list and mount Trine 2 .fbq archives
* https://github.com/panzi/u4pak[u4pak]: old Python version of this program

== MPLv2 License

Rust U4Pak - pack, unpack, check, list and mount Unreal Engine 4 packages

Copyright (C) {localyear} Mathias Panzenböck, L. Sprengel

This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this
file, You can obtain one at https://mozilla.org/MPL/2.0/.

```

`release.sh`:

```sh
#!/usr/bin/bash

set -e

SELF=$(readlink -f "$0")
DIR=$(dirname "$SELF")

cd "$DIR"

release_id=$(git describe --tags || git rev-parse HEAD)
release_dir="$DIR/release"

if [[ -e "$release_dir" ]]; then
    rm -r "$release_dir"
fi

if [[ -e "$DIR/release-$release_id.zip" ]]; then
    rm "$DIR/release-$release_id.zip"
fi

mkdir -p "$release_dir"

cargo build

{
    "./target/debug/u4pak" help

    for cmd in help check info list unpack pack mount; do
        printf '=%.0s' {1..120}; echo
        "./target/debug/u4pak" help $cmd
    done
} > "$release_dir/Help.txt"

asciidoctor -o "$release_dir/README.html" README.adoc
cp LICENSE.txt "$release_dir"

for target in x86_64-unknown-linux-gnu x86_64-pc-windows-gnu; do
    cargo clean --release --target="$target"
    cargo build --release --target="$target"
    mkdir "$release_dir/$target"
    if [[ "$target" =~ .*windows.* ]]; then
        cp "./target/$target/release/u4pak.exe" "$release_dir/$target"
    else
        cp "./target/$target/release/u4pak" "$release_dir/$target"
    fi
done

pushd "$release_dir"
zip -9r "$DIR/release-$release_id.zip" .
popd

```

`src/bin/u4pak/args.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{fmt::Display, fs::File, io::Read, path::PathBuf};

use crate::{Error, Result};

#[derive(Debug, PartialEq, Eq, Clone, Copy, Hash)]
enum ParseState {
    Space,
    Comment,
    PlainString,
    QuotedString,
    Quote,
}

fn parser_error(source: &[u8], index: usize, message: impl Display) -> Error {
    let prefix = &source[0..index];
    let lineno = prefix.iter().copied().filter(|&byte| byte == b'\n').count() + 1;
    let line_start = if let Some(line_start) = prefix.iter().copied()
            .rposition(|byte| byte == b'\n') {
        line_start + 1
    } else {
        0
    };
    let column = String::from_utf8_lossy(&prefix[line_start..]).len() + 1;

    let line_end = index + if let Some(line_end) = (&source[index..]).iter().copied()
            .position(|byte| byte == b'\n') {
        line_end
    } else {
        source.len()
    };

    let line = String::from_utf8_lossy(&source[line_start..line_end]);
    let lineno_str = format!("{}: ", lineno);
    let mut message = format!("{}:{}: {}\n{}{}\n", lineno, column, message, lineno_str, line);

    for _ in 0..lineno_str.len() {
        message.push(' ');
    }

    if column > 1 {
        for _ in 0..(column - 1) {
            message.push('-');
        }
    }
    message.push('^');

    Error::new(message)
}

pub fn parse_arg_file(bin_name: String, source: &[u8]) -> Result<Vec<String>> {
    let mut args = vec![bin_name];

    let mut state = ParseState::Space;
    let mut start_index = 0usize;
    let mut buffer = String::new();

    for (index, &byte) in source.iter().enumerate() {
        match state {
            ParseState::Space => {
                match byte {
                    b'"' => {
                        start_index = index + 1;
                        state = ParseState::QuotedString;
                    }
                    b'#' => {
                        state = ParseState::Comment;
                    }
                    _ if byte.is_ascii_whitespace() => {}
                    _ => {
                        start_index = index;
                        state = ParseState::PlainString;
                    }
                }
            }
            ParseState::Comment => {
                if byte == b'\n' {
                    state = ParseState::Space;
                }
            }
            ParseState::PlainString => {
                if byte.is_ascii_whitespace() {
                    let value = match std::str::from_utf8(&source[start_index..index]) {
                        Ok(value) => value,
                        Err(error) => {
                            return Err(parser_error(source, start_index + error.valid_up_to(), &error));
                        }
                    };
                    buffer.push_str(value);
                    args.push(buffer.to_owned());
                    buffer.clear();
                    state = ParseState::Space;
                } else if byte == b'"' {
                    let value = match std::str::from_utf8(&source[start_index..index]) {
                        Ok(value) => value,
                        Err(error) => {
                            return Err(parser_error(source, start_index + error.valid_up_to(), &error));
                        }
                    };
                    buffer.push_str(value);
                    start_index = index + 1;
                    state = ParseState::QuotedString;
                }
            }
            ParseState::QuotedString => {
                if byte == b'"' {
                    state = ParseState::Quote;
                }
            }
            ParseState::Quote => {
                if byte == b'"' {
                    buffer.push('"');
                    start_index = index + 1;
                    state = ParseState::QuotedString;
                } else if byte.is_ascii_whitespace() {
                    let value = match std::str::from_utf8(&source[start_index..index - 1]) {
                        Ok(value) => value,
                        Err(error) => {
                            return Err(parser_error(source, start_index + error.valid_up_to(), &error));
                        }
                    };
                    buffer.push_str(value);
                    args.push(buffer.to_owned());
                    buffer.clear();
                    state = ParseState::Space;
                } else {
                    let value = match std::str::from_utf8(&source[start_index..index - 1]) {
                        Ok(value) => value,
                        Err(error) => {
                            return Err(parser_error(source, start_index + error.valid_up_to(), &error));
                        }
                    };
                    buffer.push_str(value);
                    start_index = index;
                    state = ParseState::PlainString;
                }
            }
        }
    }

    match state {
        ParseState::Comment | ParseState::Space => {}
        ParseState::PlainString => {
            let value = match std::str::from_utf8(&source[start_index..]) {
                Ok(value) => value,
                Err(error) => {
                    return Err(parser_error(source, start_index + error.valid_up_to(), error));
                }
            };
            buffer.push_str(value);
            args.push(buffer);
        }
        ParseState::QuotedString => {
            let index = if let Some(&b'\n') = source.last() {
                source.len() - 1
            } else {
                source.len()
            };
            return Err(parser_error(source, index, "unexpected end of file"));
        }
        ParseState::Quote => {
            let value = match std::str::from_utf8(&source[start_index..source.len() - 1]) {
                Ok(value) => value,
                Err(error) => {
                    return Err(parser_error(source, start_index + error.valid_up_to(), &error));
                }
            };
            buffer.push_str(value);
            args.push(buffer);
        }
    }

    Ok(args)
}

pub fn get_args_from_file() -> Result<Option<Vec<String>>> {
    let mut args = std::env::args();
    if args.len() != 2 {
        return Ok(None);
    }

    let bin_name = if let Some(arg) = args.next() {
        arg
    } else {
        return Ok(None);
    };

    let path = if let Some(arg) = args.next() {
        if let Some(index) = arg.rfind('.') {
            let ext = &arg[index + 1..];
            if ext.eq_ignore_ascii_case("u4pak") {
                arg
            } else if ext.eq_ignore_ascii_case("pak") {
                return Ok(Some(vec![bin_name, "info".to_string(), "-h".to_string(), arg]));
            } else {
                return Ok(None);
            }
        } else {
            return Ok(None);
        }
    } else {
        return Ok(None);
    };

    let path = PathBuf::from(path);
    let mut file = match File::open(&path) {
        Ok(file) => file,
        Err(error) => return Err(Error::io_with_path(error, path))
    };
    let mut source = Vec::new();
    match file.read_to_end(&mut source) {
        Ok(_) => {}
        Err(error) => return Err(Error::io_with_path(error, path))
    }

    match parse_arg_file(bin_name, &source) {
        Ok(args) => {
            if let Some(path) = path.parent() {
                // no components means the file path was relative to the current directory
                // and passing an empty path to set_current_dir() gives an error
                if path.components().count() > 0 {
                    // so that relative paths inside of the .u4pak file work
                    std::env::set_current_dir(path)?;
                }
            }
            Ok(Some(args))
        },
        Err(error) => Err(error.with_path(path))
    }
}

```

`src/bin/u4pak/io.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

#[cfg(target_os = "linux")]
pub fn transfer(in_file: &mut std::fs::File, out_file: &mut std::fs::File, size: usize) -> std::io::Result<()> {
    use std::os::unix::io::AsRawFd;

    let in_fd  = in_file.as_raw_fd();
    let out_fd = out_file.as_raw_fd();

    let mut remaining = size;
    while remaining > 0 {
        unsafe {
            let result = libc::sendfile(out_fd, in_fd, std::ptr::null_mut(), remaining as libc::size_t);

            if result < 0 {
                return Err(std::io::Error::last_os_error());
            }

            remaining -= result as usize;
        }
    }

    Ok(())
}

#[cfg(not(target_os = "linux"))]
pub fn transfer(in_file: &mut std::fs::File, out_file: &mut std::fs::File, size: usize) -> std::io::Result<()> {
    use std::io::{Read, Write};
    use u4pak::pak::BUFFER_SIZE;

    // needs to be heap allocated since Windows has small stack sizes
    let mut buf = vec![0u8; std::cmp::min(BUFFER_SIZE, size)];

    let mut remaining = size;
    while remaining >= BUFFER_SIZE {
        in_file.read_exact(&mut buf)?;
        out_file.write_all(&buf)?;
        remaining -= BUFFER_SIZE;
    }

    if remaining > 0 {
        let buf = &mut buf[..remaining];
        in_file.read_exact(buf)?;
        out_file.write_all(buf)?;
    }

    Ok(())
}

```

`src/bin/u4pak/list.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::io::Write;

use chrono::NaiveDateTime;

use u4pak::{Filter, util::print_headless_table};
use u4pak::util::{format_size, print_table, Align::*};
use u4pak::result::Result;
use u4pak::record::Record;
use u4pak::pak::{Pak, compression_method_name, HexDisplay};
use u4pak::check::NULL_SHA1;
use crate::sort::{sort, Order};

#[derive(Debug, PartialEq)]
pub enum ListStyle {
    Table { human_readable: bool, no_header: bool },
    OnlyNames { null_separated: bool },
}

pub struct ListOptions<'a> {
    pub order: Option<&'a Order>,
    pub style: ListStyle,
    pub paths: Option<&'a [&'a str]>,
}

impl ListOptions<'_> {
    #[inline]
    pub fn new() -> Self {
        ListOptions::default()
    }
}

impl Default for ListStyle {
    #[inline]
    fn default() -> Self {
        ListStyle::Table { human_readable: false, no_header: false }
    }
}

impl Default for ListOptions<'_> {
    #[inline]
    fn default() -> Self {
        Self {
            order: None,
            style: ListStyle::default(),
            paths: None,
        }
    }
}

pub fn list(pak: Pak, options: ListOptions) -> Result<()> {
    let version = pak.version();
    match (options.order, options.paths) {
        (Some(order), Some(paths)) => {
            let mut filter = Filter::from_paths(paths.iter().cloned());
            let mut records = pak.index().records()
                .iter()
                .filter(|record| filter.visit(record.filename()))
                .collect();

            sort(&mut records, order);
            list_records(version, &records, options)?;
            filter.assert_all_visited()?;
        }
        (Some(order), None) => {
            let mut records = pak.index().records().iter().collect();

            sort(&mut records, order);
            list_records(version, &records, options)?;
        }
        (None, Some(paths)) => {
            let mut filter = Filter::from_paths(paths.iter().cloned());
            let records = pak.index().records()
                .iter()
                .filter(|record| filter.visit(record.filename()))
                .collect::<Vec<_>>();

            list_records(version, &records, options)?;
            filter.assert_all_visited()?;
        }
        (None, None) => {
            list_records(version, pak.index().records(), options)?;
        }
    }

    Ok(())
}

fn list_records(version: u32, records: &[impl AsRef<Record>], options: ListOptions) -> Result<()> {
    match options.style {
        ListStyle::Table { human_readable, no_header } => {
            let mut body: Vec<Vec<String>> = Vec::new();

            let fmt_size = if human_readable {
                |size: u64| format_size(size)
            } else {
                |size: u64| format!("{}", size)
            };

            for record in records {
                let record = record.as_ref();
                let mut row = vec![
                    format!("{}", record.offset()),
                    fmt_size(record.uncompressed_size()),
                    fmt_size(record.size()),
                    compression_method_name(record.compression_method()).to_owned(),
                    fmt_size(record.compression_block_size() as u64),
                ];
                if version == 1 {
                    if let Some(timestamp) = record.timestamp() {
                        if let Some(timestamp) = NaiveDateTime::from_timestamp_opt(timestamp as i64, 0) {
                            row.push(timestamp.format("%Y-%m-%d %H:%M:%S").to_string());
                        } else {
                            row.push("-".to_string());
                        }
                    } else {
                        row.push("-".to_string());
                    }
                } else if version >= 3 {
                    row.push(if record.encrypted() { "Encrypted" } else { "-" }.to_string());
                }
                row.push(HexDisplay::new(record.sha1().as_ref().unwrap_or(&NULL_SHA1)).to_string());
                row.push(record.filename().to_owned());
                body.push(row);
            }

            if version == 1 {
                let align = [Right, Right, Right, Left, Right, Left, Left, Left];
                if no_header {
                    print_headless_table(&body, &align);
                } else {
                    print_table(
                        &["Offset", "Size", "Compr.", "Method", "Block-Size", "Timestamp", "SHA-1", "Filename"],
                        &align,
                        &body,
                    );
                }
            } else if version >= 3 {
                let align = [Right, Right, Right, Left, Right, Left, Left, Left];
                if no_header {
                    print_headless_table(&body, &align);
                } else {
                    print_table(
                        &["Offset", "Size", "Compr.", "Method", "Block-Size", "Encrypted", "SHA-1", "Filename"],
                        &align,
                        &body,
                    );
                }
            } else {
                let align = [Right, Right, Right, Left, Right, Left, Left];
                if no_header {
                    print_headless_table(&body, &align);
                } else {
                    print_table(
                        &["Offset", "Size", "Compr.", "Method", "Block-Size", "SHA-1", "Filename"],
                        &align,
                        &body,
                    );
                }
            }
        }
        ListStyle::OnlyNames { null_separated } => {
            let sep = [if null_separated { 0 } else { b'\n' }];
            let mut stdout = std::io::stdout();
            for record in records {
                stdout.write_all(record.as_ref().filename().as_bytes())?;
                stdout.write_all(&sep)?;
            }
        }
    }

    Ok(())
}

```

`src/bin/u4pak/main.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use clap::{App, AppSettings, Arg, ArgMatches, SubCommand, crate_version, crate_authors};
use terminal_size::{terminal_size, Width};

use env_logger::Env;
use std::fs::File;
use std::io::BufReader;
use std::{
    convert::TryInto,
    io::stderr,
    num::{NonZeroU32, NonZeroU64, NonZeroUsize},
};

#[cfg(target_family = "windows")]
use std::convert::TryFrom;

use u4pak::check::{check, CheckOptions};
use u4pak::info::info;
use u4pak::pack::{pack, PackOptions, PackPath};
use u4pak::pak::{Options, COMPR_NONE, COMPR_ZLIB};
use u4pak::unpack::{unpack, UnpackOptions};
use u4pak::util::{parse_compression_level, parse_size};
use u4pak::{Error, Pak, Result, Variant};

pub mod sort;
use sort::parse_order;

mod list;
use list::{list, ListOptions, ListStyle};

pub mod args;
pub mod io;

#[cfg(target_os = "linux")]
pub use u4pak::mount::{mount, MountOptions};

fn get_paths<'a>(args: &'a clap::ArgMatches) -> Result<Option<Vec<&'a str>>> {
    if let Some(arg_paths) = args.values_of("paths") {
        let count = arg_paths.len();
        if count == 0 {
            Ok(None)
        } else {
            let mut paths: Vec<&str> = Vec::with_capacity(count);
            for path in arg_paths {
                if path.is_empty() {
                    return Err(Error::new(
                        "Path may not be empty. Use \"/\" to reference the root directory of a pak archive."
                        .to_string()));
                }
                paths.push(path);
            }
            Ok(Some(paths))
        }
    } else {
        Ok(None)
    }
}

fn get_threads(args: &clap::ArgMatches) -> Result<NonZeroUsize> {
    let threads = if let Some(threads) = args.value_of("threads") {
        if threads.eq_ignore_ascii_case("auto") {
            NonZeroUsize::new(num_cpus::get())
        } else {
            let threads = threads.parse()?;
            if threads == 0 {
                return Err(Error::new("thread count may not be 0".to_string()));
            }
            NonZeroUsize::new(threads)
        }
    } else {
        NonZeroUsize::new(num_cpus::get())
    };

    Ok(threads.unwrap_or_else(|| NonZeroUsize::new(1).unwrap()))
}

pub fn parse_compression_method(value: &str) -> Result<u32> {
    if value.eq_ignore_ascii_case("none") {
        Ok(COMPR_NONE)
    } else if value.eq_ignore_ascii_case("zlib") {
        Ok(COMPR_ZLIB)
    } else {
        Err(Error::new(format!(
            "compression method not supported: {:?}",
            value
        )))
    }
}

fn arg_human_readable<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("human-readable")
        .long("human-readable")
        .short("h")
        .takes_value(false)
        .help("Print sizes like 1.0 K, 2.2 M, 4.1 G etc.")
}

fn arg_package<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("package")
        .index(1)
        .required(true)
        .value_name("PACKAGE")
        .help("An Unreal Engine 4 pak file")
}

fn arg_paths<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("paths")
        .index(2)
        .multiple(true)
        .value_name("PATH")
        .help("If given, only consider these files from the package.")
}

fn arg_verbose<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("verbose")
        .long("verbose")
        .short("v")
        .takes_value(false)
        .help("Verbose output.")
}

fn arg_variant<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("variant")
        .long("variant")
        .short("a")
        .takes_value(true)
        .default_value("standard")
        .help("Pak variant: 'standard' or 'conan_exiles'.")
}

fn arg_ignore_magic<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("ignore-magic")
        .long("ignore-magic")
        .takes_value(false)
        .help("Ignore file magic.")
}

fn arg_encoding<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("encoding")
        .long("encoding")
        .short("e")
        .takes_value(true)
        .default_value("UTF-8")
        .value_name("ENCODING")
        .help("Use ENCODING to decode strings. Supported encodings: UTF-8, Latin1, ASCII")
}

fn arg_threads<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("threads")
        .long("threads")
        .short("t")
        .takes_value(true)
        .default_value("auto")
        .value_name("COUNT")
        .help(
            "Number of threads to use for the operation. \
            'auto' means use the number of logical cores on your computer.",
        )
}

fn arg_force_version<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("force-version")
        .long("force-version")
        .takes_value(true)
        .value_name("VERSION")
        .help("Assume package to be of given version.")
}

fn arg_ignore_null_checksums<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("ignore-null-checksums")
        .long("ignore-null-checksums")
        .takes_value(false)
        .help("Ignore checksums that are all zeros.")
}

fn arg_print0<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("print0")
        .long("print0")
        .short("0")
        .takes_value(false)
        .help(
            "Separate file names with NULL bytes. \
            This is useful for use with xargs --null, to be sure that \
            possible new lines in file names aren't interpreted as \
            file name separators.",
        )
}

fn arg_encryption_key<'a, 'b>() -> Arg<'a, 'b> {
    Arg::with_name("encryption-key")
        .long("encryption-key")
        .short("k")
        .takes_value(true)
        .value_name("ENCRYPTION_KEY")
        .help("Base64 encoded 16 byte AES encryption key")
}

#[cfg(target_family = "windows")]
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Pause {
    Always,
    Never,
    Auto,
}

#[cfg(target_family = "windows")]
impl Default for Pause {
    fn default() -> Self {
        Self::Auto
    }
}

#[cfg(target_family = "windows")]
impl TryFrom<&str> for Pause {
    type Error = crate::Error;

    fn try_from(value: &str) -> std::result::Result<Self, Self::Error> {
        let trim_value = value.trim();

        if trim_value.eq_ignore_ascii_case("auto") {
            Ok(Pause::Auto)
        } else if trim_value.eq_ignore_ascii_case("never") {
            Ok(Pause::Never)
        } else if trim_value.eq_ignore_ascii_case("always") {
            Ok(Pause::Always)
        } else {
            Err(Error::new(format!(
                "illegal value for --pause: {:?}",
                value
            )))
        }
    }
}

const DEFAULT_BLOCK_SIZE_STR: &str = "65536";
const DEFAULT_MIN_COMPRESSION_SIZE_STR: &str = "100";

fn make_app<'a, 'b>() -> App<'a, 'b> {
    let width = if let Some((Width(width), _)) = terminal_size() {
        width as usize
    } else {
        120
    };

    let app = App::new("Rust U4Pak")
        .set_term_width(width)
        .about("\n\
                This is a tool to pack, unpack, check, and list the contents of Unreal Engine 4 packages. \
                Note that only a limited number of pak versions are supported, depending on the kinds of \
                paks I have seen.For reading that is version 1-11, for writing it is 1, 2, 3.\n\
                \n\
                Instead of passing arguments you can also put the arguments in a file with the extension \
                .u4pak and pass the path to that instead. This is useful for Windows users that aren't \
                used to a terminal. You can even associate the extension with u4pak.exe so that it will \
                be automatically opened with it when you double click it. File paths in a .u4pak file are \
                relative to the directory containing the file. The syntax of these files is not shell \
                syntax. If you don't have any white space, double quotes (\"), or hash marks (#) in your \
                file names you don't have to worry about anything. # is used to start a comment line (only \
                if it doesn't touch any non-white space on it's left) and \" is used to quote arguments \
                containing white space, #, or \". In order to write a \" in an quoted argument you simply \
                need to double it, meaning an argument that contains nothing but a single \" is written \
                as \"\"\"\". Newlines are ignored like any other white space. An example .u4pak file \
                whould be:\n\
                \n\
                \t# This is packing my project:\n\
                \tpack\n\
                \t--version=4\n\
                \t--mount-point=../../..\n\
                \t\n\
                \t\":rename=/:C:\\Users\\Alice\\My Documents\\U4Project\\Some Files\"\n\
                \t\":zlib,rename=/:Some Other Files\"\n\
                \n\
                If u4pak.exe is run by double clicking or by dropping a .u4pak file on it it won't \
                immediately close the terminal window, but will instead ask you to press ENTER. It does \
                this so you have a chance to read the output. Since I don't use Windows (I cross compile \
                on Linux and test with Wine) I could not test this particular feature. If it doesn't work \
                please report a bug. In order to force the \"Press ENTER to continue...\" message you can \
                pass the argument --pause-on-exit=always (Windows-only).\n\
                \n\
                Homepage: https://github.com/panzi/rust-u4pak\n\
                Report issues to: https://github.com/panzi/rust-u4pak/issues")
        .version(crate_version!())
        .global_setting(AppSettings::VersionlessSubcommands)
        .author(crate_authors!());

    #[cfg(target_family = "windows")]
    let app = app.arg(
        Arg::with_name("pause-on-exit")
            .long("pause-on-exit")
            .default_value("auto")
            .takes_value(true)
            .help("Wait for user to press ENTER on exit. Possible values: always, never, auto."),
    );

    let app = app
        .subcommand(SubCommand::with_name("info")
            .alias("i")
            .about("Show summarized information of a package")
            .arg(arg_variant())
            .arg(arg_human_readable())
            .arg(arg_ignore_magic())
            .arg(arg_encoding())
            .arg(arg_force_version())
            .arg(arg_package())
            .arg(arg_encryption_key()))
        .subcommand(SubCommand::with_name("list")
            .alias("l")
            .about("List content of a package")
            .arg(arg_variant())
            .arg(Arg::with_name("only-names")
                .long("only-names")
                .short("n")
                .takes_value(false)
                .help(
                    "Only print file names. \
                    This is useful for use with xargs and the like."))
            .arg(Arg::with_name("no-header")
                .long("no-header")
                .short("H")
                .takes_value(false)
                .conflicts_with("only-names")
                .help("Don't print table header"))
            .arg(Arg::with_name("sort")
                .long("sort")
                .short("s")
                .takes_value(true)
                .value_name("ORDER")
                .help(
                    "Sort order of list as comma separated keys:\n\
                    \n\
                    * p, path                   - path of the file inside the package\n\
                    * o, offset                 - offset inside of the package\n\
                    * s, size                   - size of the data embedded in the package\n\
                    * u, uncompressed-size      - size of the data when uncompressed\n\
                    * c, compression-method     - the compression method (zlib or none)\n\
                    * b, compression-block-size - size of blocks a compressed file is split into\n\
                    * t, timestamp              - timestamp of a file (only in pak version 1)\n\
                    * e, encrypted              - whether the file is encrypted\n\
                    \n\
                    You can invert the sort order by prepending - to the key. E.g.:\n\
                    \n\
                    u4pak list --sort=-size,-timestamp,name")
            )
            .arg(arg_print0().requires("only-names"))
            .arg(arg_ignore_magic())
            .arg(arg_encoding())
            .arg(arg_force_version())
            .arg(arg_human_readable())
            .arg(arg_threads())
            .arg(arg_package())
            .arg(arg_paths())
            .arg(arg_encryption_key()))
        .subcommand(SubCommand::with_name("check")
            .alias("c")
            .about("Check consistency of a package")
            .arg(Arg::with_name("abort-on-error")
                .long("abort-on-error")
                .takes_value(false)
                .help("Stop on the first found error."))
            .arg(arg_variant())
            .arg(arg_print0())
            .arg(arg_ignore_magic())
            .arg(arg_encoding())
            .arg(arg_force_version())
            .arg(arg_ignore_null_checksums())
            .arg(arg_threads())
            .arg(arg_verbose())
            .arg(arg_package())
            .arg(arg_paths())
            .arg(arg_encryption_key()))
        .subcommand(SubCommand::with_name("unpack")
            .alias("u")
            .about("Unpack content of a package")
            .arg(arg_variant())
            .arg(arg_print0())
            .arg(arg_ignore_magic())
            .arg(arg_encoding())
            .arg(arg_force_version())
            .arg(arg_threads())
            .arg(arg_verbose())
            .arg(Arg::with_name("dirname-from-compression")
                .long("dirname-from-compression")
                .short("d")
                .takes_value(false)
                .help(
                    "Put files that where compressed into separate folders. \
                     The folder names will be 'none' and 'zlib'."))
            .arg(Arg::with_name("outdir")
                .long("outdir")
                .short("o")
                .takes_value(true)
                .value_name("DIR")
                .default_value(".")
                .help("Write unpacked files to DIR."))
            .arg(arg_package())
            .arg(arg_paths())
            .arg(arg_encryption_key()))
        .subcommand(SubCommand::with_name("pack")
            .alias("p")
            .about("Create a new package")
            .arg(arg_variant())
            .arg(Arg::with_name("version")
                .long("version")
                .short("V")
                .takes_value(true)
                .help(
                    "Create package of given VERSION. Supported versions are: 1, 2, and 3 \
                    [default: 3 when --variant=standard, 4 when --variant=conan_exiles]"))
            .arg(Arg::with_name("mount-point")
                .long("mount-point")
                .short("m")
                .takes_value(true)
                .help("Mount-point field of the package."))
            .arg(Arg::with_name("compression-method")
                .long("compression-method")
                .short("c")
                .takes_value(true)
                .default_value("none")
                .help("Default compression method. See also: --compression-min-size"))
            .arg(Arg::with_name("compression-block-size")
                .long("compression-block-size")
                .short("b")
                .takes_value(true)
                .default_value(DEFAULT_BLOCK_SIZE_STR)
                .help("Default compresison block size."))
            .arg(Arg::with_name("compression-level")
                .long("compression-level")
                .short("l")
                .takes_value(true)
                .default_value("default")
                .help(
                    "Default compression level. Allowed values are the integers from 1 to 9, \
                    or the strings 'fast' (=1), 'best' (=9), and 'default' (=6)."))
            .arg(Arg::with_name("compression-min-size")
                .long("compression-min-size")
                .short("s")
                .takes_value(true)
                .default_value(DEFAULT_MIN_COMPRESSION_SIZE_STR)
                .help(
                    "Minimum size of files to be compressed. Note that it makes no sense to \
                    try to compress files smaller than 100 bytes or so, because of the \
                    compression overhead."))
            .arg(arg_encoding())
            .arg(arg_print0())
            .arg(arg_threads())
            .arg(arg_verbose())
            .arg(arg_package())
            .arg(Arg::with_name("paths")
                .index(2)
                .multiple(true)
                .value_name("PATH")
                .help(
                    "Pack these files or directories. You can overload certain settings for a path using a special syntax, e.g.:\n\
                    \n\
                    Linux/Unix:\n\
                    \tu4pak pack Archive.pak :zlib,level=7,block_size=65536,rename=/Foo/Bar:/Some/Folder\n\
                    \n\
                    Windows:\n\
                    \tu4pak pack Archive.pak :zlib,level=7,block_size=65536,rename=/Foo/Bar:C:\\Some\\Folder\n\
                    \n\
                    This means add the fiels from the folder '/Some/Folder' ('C:\\Some\\Folder') \
                    from your hard disk, use zlib compression at compression level 7 with a \
                    compression block size of 65536 bytes, and rename the folder to be 'Foo/Bar' \
                    inside of the pak archive file.\n\
                    \n\
                    Instead of 'zlib' you can also write 'none' to not compress the files from the \
                    given path. If you don't say any of either the default value provided by \
                    --compression-method is used. Same goes for all the other parameters. \
                    If you don't specify 'rename' then the same path is used for the folder inside \
                    of the pak archive as the files on your hard disk have.\n\
                    \n\
                    This is handy if you want to compress some files, but not all:\n\
                    \tu4pak pack Archive.pak :zlib,rename=/:ZlibFiles :none,rename=/:UncompressedFiles
                    \n\
                    If the default parameters are all you need (and you provide relative paths \
                    that don't need renaming) you can simply say e.g.:\n\
                    \n\
                    Linux/Unix:\n\
                    \tu4pak pack Archive.pak Some/Folder\n\
                    \n\
                    Windows:\n\
                    \tu4pak pack Archive.pak Some\\Folder\n\
                    ")));

    #[cfg(target_os = "linux")]
    let app = app.subcommand(
        SubCommand::with_name("mount")
            .alias("m")
            .about("Mount package as read-only filesystem")
            .arg(arg_variant())
            .arg(arg_ignore_magic())
            .arg(arg_encoding())
            .arg(arg_force_version())
            .arg(arg_encryption_key())
            .arg(
                Arg::with_name("foregound")
                    .long("foreground")
                    .short("f")
                    .takes_value(false)
                    .help("Keep process in foreground."),
            )
            .arg(
                Arg::with_name("debug")
                    .long("debug")
                    .short("g")
                    .takes_value(false)
                    .help("Debug mode. Implies --foreground."),
            )
            .arg(arg_package())
            .arg(
                Arg::with_name("mountpt")
                    .index(2)
                    .required(true)
                    .value_name("MOUNTPT"),
            ),
    );

    app
}

fn main() {
    env_logger::Builder::from_env(Env::default().default_filter_or("warn")).init();
    let args_from_file = match args::get_args_from_file() {
        Ok(args_from_file) => args_from_file,
        Err(error) => {
            let _ = error.write_to(&mut stderr(), false);
            #[cfg(target_family = "windows")]
            {
                windows::pause_if_owns_terminal();
            }
            return;
        }
    };

    let matches = if let Some(args) = args_from_file {
        make_app().get_matches_from_safe_borrow(args.iter())
    } else {
        make_app().get_matches_safe()
    };

    let matches = match matches {
        Ok(matches) => matches,
        Err(error) => {
            if error.use_stderr() {
                eprintln!("{}", error);
                #[cfg(target_family = "windows")]
                {
                    windows::pause_if_owns_terminal();
                }
                std::process::exit(1);
            } else {
                println!("{}", error);
                #[cfg(target_family = "windows")]
                {
                    windows::pause_if_owns_terminal();
                }
                return;
            }
        }
    };

    #[cfg(target_family = "windows")]
    let pause: Pause = match matches.value_of("pause-on-exit").unwrap().try_into() {
        Ok(pause) => pause,
        Err(error) => {
            eprintln!("{}", error);
            windows::pause_if_owns_terminal();
            std::process::exit(1);
        }
    };

    if let Err(error) = run(&matches) {
        let _ = error.write_to(&mut stderr(), false);
    }

    #[cfg(target_family = "windows")]
    match pause {
        Pause::Always => windows::pause(),
        Pause::Never => {}
        Pause::Auto => windows::pause_if_owns_terminal(),
    }
}

fn run(matches: &ArgMatches) -> Result<()> {
    match matches.subcommand() {
        ("info", Some(args)) => {
            let variant = args.value_of("variant").unwrap().try_into()?;
            let human_readable = args.is_present("human-readable");
            let ignore_magic = args.is_present("ignore-magic");
            let encoding = args.value_of("encoding").unwrap().try_into()?;
            let path = args.value_of("package").unwrap();

            let force_version = if let Some(version) = args.value_of("force-version") {
                Some(version.parse()?)
            } else {
                None
            };

            let encryption_key = if let Some(key) = args.value_of("encryption-key") {
                Some(
                    base64::decode(
                        key.parse::<String>()
                            .expect("Failed to read encryption key."),
                    )
                    .expect("Failed to parse encryption key."),
                )
            } else {
                None
            };

            let pak = Pak::from_path(
                &path,
                Options {
                    variant,
                    ignore_magic,
                    encoding,
                    force_version,
                    encryption_key,
                },
            )?;

            info(&pak, human_readable)?;
        }
        ("list", Some(args)) => {
            let order = if let Some(order) = args.value_of("sort") {
                Some(parse_order(order)?)
            } else {
                None
            };
            let order = order.as_ref().map(|order| &order[..]);

            let variant = args.value_of("variant").unwrap().try_into()?;
            let human_readable = args.is_present("human-readable");
            let null_separated = args.is_present("print0");
            let only_names = args.is_present("only-names");
            let ignore_magic = args.is_present("ignore-magic");
            let no_header = args.is_present("no-header");
            let encoding = args.value_of("encoding").unwrap().try_into()?;
            let path = args.value_of("package").unwrap();
            let paths = get_paths(args)?;
            let paths: Option<&[&str]> = if let Some(paths) = &paths {
                Some(paths)
            } else {
                None
            };

            let force_version = if let Some(version) = args.value_of("force-version") {
                Some(version.parse()?)
            } else {
                None
            };

            let encryption_key = if let Some(key) = args.value_of("encryption-key") {
                Some(
                    base64::decode(
                        key.parse::<String>()
                            .expect("Failed to read encryption key."),
                    )
                    .expect("Failed to parse encryption key."),
                )
            } else {
                None
            };

            let mut file = match File::open(path) {
                Ok(file) => file,
                Err(error) => return Err(Error::io_with_path(error, path)),
            };
            let mut reader = BufReader::new(&mut file);

            let pak = Pak::from_reader(
                &mut reader,
                Options {
                    variant,
                    ignore_magic,
                    encoding,
                    force_version,
                    encryption_key,
                },
            )?;

            drop(reader);

            list(
                pak,
                ListOptions {
                    order,
                    style: if only_names {
                        ListStyle::OnlyNames { null_separated }
                    } else {
                        ListStyle::Table {
                            human_readable,
                            no_header,
                        }
                    },
                    paths,
                },
            )?;
        }
        ("check", Some(args)) => {
            let null_separated = args.is_present("print0");
            let ignore_magic = args.is_present("ignore-magic");
            let ignore_null_checksums = args.is_present("ignore-null-checksums");
            let abort_on_error = args.is_present("abort-on-error");
            let verbose = args.is_present("verbose");
            let variant = args.value_of("variant").unwrap().try_into()?;
            let encoding = args.value_of("encoding").unwrap().try_into()?;
            let path = args.value_of("package").unwrap();
            let paths = get_paths(args)?;
            let paths: Option<&[&str]> = if let Some(paths) = &paths {
                Some(paths)
            } else {
                None
            };

            let force_version = if let Some(version) = args.value_of("force-version") {
                Some(version.parse()?)
            } else {
                None
            };

            let encryption_key = if let Some(key) = args.value_of("encryption-key") {
                Some(
                    base64::decode(
                        key.parse::<String>()
                            .expect("Failed to read encryption key."),
                    )
                    .expect("Failed to parse encryption key."),
                )
            } else {
                None
            };

            let mut file = match File::open(path) {
                Ok(file) => file,
                Err(error) => return Err(Error::io_with_path(error, path)),
            };
            let mut reader = BufReader::new(&mut file);

            let pak = Pak::from_reader(
                &mut reader,
                Options {
                    variant,
                    ignore_magic,
                    encoding,
                    force_version,
                    encryption_key,
                },
            )?;

            let options = CheckOptions {
                variant,
                abort_on_error,
                ignore_null_checksums,
                null_separated,
                verbose,
                thread_count: get_threads(args)?,
                paths,
            };

            let error_count = check(&pak, &mut file, options)?;

            let sep = if null_separated { '\0' } else { '\n' };
            if error_count == 0 {
                print!("All ok{}", sep);
            } else {
                print!("Found {} error(s){}", error_count, sep);
                std::process::exit(1);
            }
        }
        ("unpack", Some(args)) => {
            let variant = args.value_of("variant").unwrap().try_into()?;
            let outdir = args.value_of("outdir").unwrap();
            let null_separated = args.is_present("print0");
            let verbose = args.is_present("verbose");
            let ignore_magic = args.is_present("ignore-magic");
            let dirname_from_compression = args.is_present("dirname-from-compression");
            let encoding = args.value_of("encoding").unwrap().try_into()?;
            let thread_count = get_threads(args)?;
            let path = args.value_of("package").unwrap();
            let paths = get_paths(args)?;
            let paths: Option<&[&str]> = if let Some(paths) = &paths {
                Some(paths)
            } else {
                None
            };

            let force_version = if let Some(version) = args.value_of("force-version") {
                Some(version.parse()?)
            } else {
                None
            };

            let encryption_key = if let Some(key) = args.value_of("encryption-key") {
                Some(
                    base64::decode(
                        key.parse::<String>()
                            .expect("Failed to read encryption key."),
                    )
                    .expect("Failed to parse encryption key."),
                )
            } else {
                None
            };

            let mut file = match File::open(path) {
                Ok(file) => file,
                Err(error) => return Err(Error::io_with_path(error, path)),
            };
            let mut reader = BufReader::new(&mut file);

            let pak = Pak::from_reader(
                &mut reader,
                Options {
                    variant,
                    ignore_magic,
                    encoding,
                    force_version,
                    encryption_key: encryption_key.clone(),
                },
            )?;

            drop(reader);

            unpack(
                &pak,
                &mut file,
                outdir,
                UnpackOptions {
                    dirname_from_compression,
                    verbose,
                    null_separated,
                    paths,
                    thread_count,
                    encryption_key,
                },
            )?;
        }
        ("pack", Some(args)) => {
            let variant = args.value_of("variant").unwrap().try_into()?;
            let thread_count = get_threads(args)?;
            let null_separated = args.is_present("print0");
            let verbose = args.is_present("verbose");
            let mount_point = args.value_of("mount-point");
            let encoding = args.value_of("encoding").unwrap().try_into()?;
            let version = if let Some(version) = args.value_of("version") {
                version.parse()?
            } else {
                match variant {
                    Variant::Standard => 3,
                    Variant::ConanExiles => 4,
                }
            };
            let compression_block_size =
                parse_size(args.value_of("compression-block-size").unwrap())?;
            if compression_block_size > u32::MAX as usize {
                return Err(Error::new(format!(
                    "--compression-block-size too big: {}",
                    compression_block_size
                )));
            }
            let compression_block_size =
                if let Some(value) = NonZeroU32::new(compression_block_size as u32) {
                    value
                } else {
                    return Err(Error::new(
                        "--compression-block-size cannot be 0".to_string(),
                    ));
                };
            let compression_min_size =
                parse_size(args.value_of("compression-min-size").unwrap())?;
            if compression_min_size > u64::MAX as usize {
                return Err(Error::new(format!(
                    "--compression-min-size too big: {}",
                    compression_block_size
                )));
            }
            let compression_min_size =
                if let Some(value) = NonZeroU64::new(compression_min_size as u64) {
                    value
                } else {
                    return Err(Error::new(format!(
                        "--compression-min-size cannot be 0: {}",
                        compression_min_size
                    )));
                };
            let compression_method =
                parse_compression_method(args.value_of("compression-method").unwrap())?;
            let compression_level =
                parse_compression_level(args.value_of("compression-level").unwrap())?;
            let path = args.value_of("package").unwrap();
            let paths = if let Some(path_strs) = args.values_of("paths") {
                let mut paths = Vec::<PackPath>::new();

                for path in path_strs {
                    paths.push(path.try_into()?);
                }

                paths
            } else {
                return Err(Error::new("missing argument: PATH".to_string()));
            };

            pack(
                path,
                &paths,
                PackOptions {
                    variant,
                    version,
                    mount_point,
                    compression_method,
                    compression_block_size,
                    compression_min_size,
                    compression_level,
                    encoding,
                    verbose,
                    null_separated,
                    thread_count,
                },
            )?;
        }
        #[cfg(target_os = "linux")]
        ("mount", Some(args)) => {
            let foreground = args.is_present("foreground");
            let debug = args.is_present("debug");
            let ignore_magic = args.is_present("ignore-magic");
            let variant = args.value_of("variant").unwrap().try_into()?;
            let encoding = args.value_of("encoding").unwrap().try_into()?;
            let path = args.value_of("package").unwrap();
            let mountpt = args.value_of("mountpt").unwrap();

            let force_version = if let Some(version) = args.value_of("force-version") {
                Some(version.parse()?)
            } else {
                None
            };

            let encryption_key = if let Some(key) = args.value_of("encryption-key") {
                Some(
                    base64::decode(
                        key.parse::<String>()
                            .expect("Failed to read encryption key."),
                    )
                    .expect("Failed to parse encryption key."),
                )
            } else {
                None
            };

            let mut file = match File::open(path) {
                Ok(file) => file,
                Err(error) => return Err(Error::io_with_path(error, path)),
            };
            let mut reader = BufReader::new(&mut file);

            let pak = Pak::from_reader(
                &mut reader,
                Options {
                    variant,
                    ignore_magic,
                    encoding,
                    force_version,
                    encryption_key,
                },
            )?;

            drop(reader);

            mount(pak, file, mountpt, MountOptions { foreground, debug })
                .map_err(|error| error.with_path_if_none(path))?;
        }
        ("", _) => {
            let mut buf = Vec::new();
            make_app().write_long_help(&mut buf)?;
            let message = std::str::from_utf8(&buf)?;

            return Err(Error::new(format!(
                "Error: Missing sub-command!\n\
                 \n\
                 {}",
                message
            )));
        }
        (cmd, _) => {
            let mut buf = Vec::new();
            make_app().write_long_help(&mut buf)?;
            let message = std::str::from_utf8(&buf)?;

            return Err(Error::new(format!(
                "Error: Unknown subcommand: {}\n\
                 \n\
                 {}",
                cmd, message
            )));
        }
    }

    Ok(())
}

#[allow(unused)]
#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[cfg(target_family = "windows")]
mod windows {
    use std::io::Read;

    pub(crate) type DWORD = u32;

    #[link(name = "user32")]
    extern "stdcall" {
        pub(crate) fn GetConsoleProcessList(
            lpdwProcessList: *mut DWORD,
            dwProcessCount: DWORD,
        ) -> DWORD;
    }

    pub fn pause() {
        println!("Press ENTER to continue...");
        let mut buf = [0];
        let _ = std::io::stdin().read(&mut buf);
    }

    pub fn pause_if_owns_terminal() {
        let mut process_list = [0, 0];
        let count = unsafe {
            GetConsoleProcessList(
                process_list.as_mut_ptr() as *mut DWORD,
                process_list.len() as DWORD,
            )
        };

        if count == 1 {
            pause();
        }
    }
}

```

`src/bin/u4pak/sort.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::cmp::Ordering;
use std::convert::TryFrom;

use u4pak::result::{Result, Error};
use u4pak::record::Record;

#[derive(Debug)]
pub enum SortKey {
    Name,
    Offset,
    Size,
    ComprMethod,
    UncomprSize,
    ComprBlockSize,
    Timestamp,
    Encrypted,

    RevName,
    RevOffset,
    RevSize,
    RevComprMethod,
    RevUncomprSize,
    RevComprBlockSize,
    RevTimestamp,
    RevEncrypted,
}

pub type Order = [SortKey];

pub const DEFAULT_ORDER:  [SortKey; 1] = [SortKey::Name];
pub const PHYSICAL_ORDER: [SortKey; 1] = [SortKey::Offset];

impl TryFrom<&str> for SortKey {
    type Error = Error;

    fn try_from(value: &str) -> Result<SortKey> {
        if value.eq_ignore_ascii_case("p") || value.eq_ignore_ascii_case("name") || value.eq_ignore_ascii_case("path") || value.eq_ignore_ascii_case("filename") {
            Ok(SortKey::Name)
        } else if value.eq_ignore_ascii_case("s") || value.eq_ignore_ascii_case("size") || value.eq_ignore_ascii_case("compressed-size") {
            Ok(SortKey::Size)
        } else if value.eq_ignore_ascii_case("o") || value.eq_ignore_ascii_case("offset") {
            Ok(SortKey::Offset)
        } else if value.eq_ignore_ascii_case("c") || value.eq_ignore_ascii_case("compr-method") || value.eq_ignore_ascii_case("compression-method") {
            Ok(SortKey::ComprMethod)
        } else if value.eq_ignore_ascii_case("u") || value.eq_ignore_ascii_case("uncompressed-size") {
            Ok(SortKey::UncomprSize)
        } else if value.eq_ignore_ascii_case("b") || value.eq_ignore_ascii_case("compression-block-size") {
            Ok(SortKey::ComprBlockSize)
        } else if value.eq_ignore_ascii_case("t") || value.eq_ignore_ascii_case("timestamp") {
            Ok(SortKey::Timestamp)
        } else if value.eq_ignore_ascii_case("e") || value.eq_ignore_ascii_case("encrypted") {
            Ok(SortKey::Encrypted)
        } else if value.eq_ignore_ascii_case("-p") || value.eq_ignore_ascii_case("-name") || value.eq_ignore_ascii_case("-path") || value.eq_ignore_ascii_case("-filename") {
            Ok(SortKey::RevName)
        } else if value.eq_ignore_ascii_case("-s") || value.eq_ignore_ascii_case("-size") || value.eq_ignore_ascii_case("-compressed-size") {
            Ok(SortKey::RevSize)
        } else if value.eq_ignore_ascii_case("-o") || value.eq_ignore_ascii_case("-offset") {
            Ok(SortKey::RevOffset)
        } else if value.eq_ignore_ascii_case("-c") || value.eq_ignore_ascii_case("-compr-method") || value.eq_ignore_ascii_case("-compression-method") {
            Ok(SortKey::RevComprMethod)
        } else if value.eq_ignore_ascii_case("-u") || value.eq_ignore_ascii_case("-uncompressed-size") {
            Ok(SortKey::RevUncomprSize)
        } else if value.eq_ignore_ascii_case("-b") ||value.eq_ignore_ascii_case("-compression-block-size") {
            Ok(SortKey::RevComprBlockSize)
        } else if value.eq_ignore_ascii_case("-t") ||value.eq_ignore_ascii_case("-timestamp") {
            Ok(SortKey::RevTimestamp)
        } else if value.eq_ignore_ascii_case("-e") || value.eq_ignore_ascii_case("-encrypted") {
            Ok(SortKey::RevEncrypted)
        } else {
            Err(Error::new(format!("illegal argument --sort={:?}", value)))
        }
    }
}

impl SortKey {
    #[inline]
    pub fn to_cmp(&self) -> impl Fn(&Record, &Record) -> Ordering {
        match self {
            SortKey::Name              => |a: &Record, b: &Record| a.filename().cmp(&b.filename()),
            SortKey::Size              => |a: &Record, b: &Record| a.size().cmp(&b.size()),
            SortKey::Offset            => |a: &Record, b: &Record| a.offset().cmp(&b.offset()),
            SortKey::ComprMethod       => |a: &Record, b: &Record| a.compression_method().cmp(&b.compression_method()),
            SortKey::UncomprSize       => |a: &Record, b: &Record| a.uncompressed_size().cmp(&b.uncompressed_size()),
            SortKey::ComprBlockSize    => |a: &Record, b: &Record| a.compression_block_size().cmp(&b.compression_block_size()),
            SortKey::Timestamp         => |a: &Record, b: &Record| a.timestamp().cmp(&b.timestamp()),
            SortKey::Encrypted         => |a: &Record, b: &Record| a.encrypted().cmp(&b.encrypted()),

            SortKey::RevName           => |a: &Record, b: &Record| b.filename().cmp(&a.filename()),
            SortKey::RevSize           => |a: &Record, b: &Record| b.size().cmp(&a.size()),
            SortKey::RevOffset         => |a: &Record, b: &Record| b.offset().cmp(&a.offset()),
            SortKey::RevComprMethod    => |a: &Record, b: &Record| b.compression_method().cmp(&a.compression_method()),
            SortKey::RevUncomprSize    => |a: &Record, b: &Record| b.uncompressed_size().cmp(&a.uncompressed_size()),
            SortKey::RevComprBlockSize => |a: &Record, b: &Record| b.compression_block_size().cmp(&a.compression_block_size()),
            SortKey::RevTimestamp      => |a: &Record, b: &Record| b.timestamp().cmp(&a.timestamp()),
            SortKey::RevEncrypted      => |a: &Record, b: &Record| b.encrypted().cmp(&a.encrypted()),
        }
    }
}

fn chain(cmp1: Box<dyn Fn(&Record, &Record) -> Ordering>, cmp2: Box<dyn Fn(&Record, &Record) -> Ordering>) -> Box<dyn Fn(&Record, &Record) -> Ordering> {
    Box::new(move |a: &Record, b: &Record|
        match cmp1(a, b) {
            Ordering::Equal => cmp2(a, b),
            ord => ord,
        }
    )
}

fn make_chain(cmp1: Box<dyn Fn(&Record, &Record) -> Ordering>, mut iter: std::slice::Iter<SortKey>) -> Box<dyn Fn(&Record, &Record) -> Ordering> {
    if let Some(key) = iter.next() {
        make_chain(chain(cmp1, Box::new(key.to_cmp())), iter)
    } else {
        cmp1
    }
}

pub fn sort(list: &mut Vec<impl AsRef<Record>>, order: &Order) {
    let mut iter = order.iter();

    if let Some(first_key) = iter.next() {
        let cmp = make_chain(Box::new(first_key.to_cmp()), iter);
        list.sort_by(|a, b| cmp(a.as_ref(), b.as_ref()));
    }
}

pub fn parse_order(value: &str) -> Result<Vec<SortKey>> {
    let mut order = Vec::new();
    for key in value.split(',') {
        order.push(SortKey::try_from(key)?);
    }
    Ok(order)
}

```

`src/check.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{collections::HashSet, fs::File, io::{BufReader, Read, Seek, SeekFrom, stderr}, num::NonZeroUsize};

use crossbeam_channel::{Sender, unbounded};
use crossbeam_utils::thread;
use openssl::sha::Sha1 as OpenSSLSha1;

use crate::{Error, Filter, Pak, pak::{BUFFER_SIZE, COMPR_METHODS, COMPR_NONE, HexDisplay, Sha1, Variant}};
use crate::reopen::Reopen;
use crate::{Record, Result};

pub const NULL_SHA1: Sha1 = [0u8; 20];

#[derive(Debug)]
pub struct CheckOptions<'a> {
    pub variant: Variant,
    pub abort_on_error: bool,
    pub ignore_null_checksums: bool,
    pub null_separated: bool,
    pub verbose: bool,
    pub paths: Option<&'a [&'a str]>,
    pub thread_count: NonZeroUsize,
}

impl Default for CheckOptions<'_> {
    fn default() -> Self {
        Self {
            variant: Variant::default(),
            abort_on_error: false,
            ignore_null_checksums: false,
            null_separated: false,
            verbose: false,
            paths: None,
            thread_count: NonZeroUsize::new(num_cpus::get()).unwrap_or(NonZeroUsize::new(1).unwrap()),
        }
    }
}

macro_rules! check_error {
    ($ok:expr, $result_sender:expr, $abort_on_error:expr, $error:expr) => {
        {
            if let Err(_) = $result_sender.send(Err($error)) {
                return;
            }

            if $abort_on_error {
                return;
            }

            $ok = false;
        }
    };
}

macro_rules! io {
    () => { Ok(()) };
    ($expr:expr $(,)?) => { $expr };
    ($expr:expr, $($tail:expr),* $(,)?) => {
        if let Err(_error) = ($expr) {
            Err(_error)
        } else {
            io!($($tail),*)
        }
    };
}

fn check_data<R>(reader: &mut R, filename: &str, offset: u64, size: u64, checksum: &Sha1, ignore_null_checksums: bool, buffer: &mut Vec<u8>) -> Result<()>
where R: Read, R: Seek {
    if ignore_null_checksums && checksum == &NULL_SHA1 {
        return Ok(());
    }
    reader.seek(SeekFrom::Start(offset))?;
    let mut hasher = OpenSSLSha1::new();
    let mut remaining = size;
    buffer.resize(BUFFER_SIZE, 0);
    loop {
        if remaining >= BUFFER_SIZE as u64 {
            reader.read_exact(buffer)?;
            hasher.update(&buffer);
            remaining -= BUFFER_SIZE as u64;
        } else {
            let buffer = &mut buffer[..remaining as usize];
            reader.read_exact(buffer)?;
            hasher.update(&buffer);
            break;
        }
    }
    let actual_digest = hasher.finish();
    if &actual_digest != checksum {
        return Err(Error::new(format!(
            "checksum missmatch:\n\
             \texpected: {}\n\
             \tactual:   {}",
             HexDisplay::new(checksum),
             HexDisplay::new(&actual_digest)
        )).with_path(filename));
    }
    Ok(())
}


pub fn check<'a>(pak: &'a Pak, in_file: &mut File, options: CheckOptions) -> Result<usize> {
    let CheckOptions {
        variant,
        abort_on_error,
        ignore_null_checksums,
        null_separated,
        verbose,
        thread_count,
        paths,
    } = options;
    let mut error_count = 0usize;
    let pak_path = in_file.path()?;
    let index_offset = pak.index_offset();
    let version = pak.version();
    let mut filter: Option<Filter> = paths.map(|paths| paths.into());
    let mut stderr = stderr();

    if let Err(error) = check_data(&mut BufReader::new(in_file), "<archive index>", index_offset, pak.index_size(), pak.index_sha1(), ignore_null_checksums, &mut vec![0u8; BUFFER_SIZE]) {
        error_count += 1;
        if abort_on_error {
            return Err(error);
        } else {
            let _ = error.write_to(&mut stderr, null_separated);
        }
    }

    let read_record = match variant {
        Variant::ConanExiles => {
            if version != 4 {
                return Err(Error::new(format!("Only know how to handle Conan Exile paks of version 4, but version was {}.", version)));
            }
            Record::read_conan_exiles
        }
        Variant::Standard => match version {
            1 => Record::read_v1,
            2 => Record::read_v2,
            _ if version <= 5 || version == 7 => Record::read_v3,
            _ => {
                return Err(Error::new(format!("unsupported version: {}", version)));
            }
        }
    };

    let thread_result = thread::scope::<_, Result<usize>>(|scope| {
        let (work_sender, work_receiver) = unbounded::<&Record>();
        let (result_sender, result_receiver) = unbounded::<Result<&Record>>();

        for _ in 0..thread_count.get() {
            let work_receiver = work_receiver.clone();
            let result_sender = result_sender.clone();
            let in_file = File::open(&pak_path)?;

            scope.spawn(move |_| {
                let mut reader = BufReader::new(in_file);
                let mut buffer = vec![0u8; BUFFER_SIZE];

                while let Ok(record) = work_receiver.recv() {
                    let mut ok = true;

                    if !COMPR_METHODS.contains(&record.compression_method()) {
                        check_error!(ok, result_sender, abort_on_error, Error::new(format!(
                            "unknown compression method: 0x{:02x}",
                            record.compression_method(),
                        )).with_path(record.filename()));
                    }

                    if record.compression_method() == COMPR_NONE && record.size() != record.uncompressed_size() {
                        check_error!(ok, result_sender, abort_on_error, Error::new(format!(
                            "file is not compressed but compressed size ({}) differes from uncompressed size ({})",
                            record.size(),
                            record.uncompressed_size(),
                        )).with_path(record.filename()));
                    }

                    let offset = record.offset() + Pak::header_size(version, variant, record);
                    if offset + record.size() > index_offset {
                        check_error!(ok, result_sender, abort_on_error, Error::new(
                            "data bleeds into index".to_string()
                        ).with_path(record.filename()));
                    }

                    if let Err(error) = reader.seek(SeekFrom::Start(record.offset())) {
                        check_error!(ok, result_sender, abort_on_error,
                            Error::io_with_path(error, record.filename()));
                    } else {
                        match read_record(&mut reader, record.filename().to_string()) {
                            Ok(other_record) => {
                                if other_record.offset() != 0 {
                                    check_error!(ok, result_sender, abort_on_error,
                                        Error::new(format!("data record offset field is not 0 but {}",
                                                other_record.offset()))
                                            .with_path(other_record.filename()));
                                }

                                if !record.same_metadata(&other_record) {
                                    check_error!(ok, result_sender, abort_on_error,
                                        Error::new(format!("metadata missmatch:\n{}",
                                                record.metadata_diff(&other_record)))
                                            .with_path(other_record.filename()));
                                }
                            }
                            Err(error) => {
                                check_error!(ok, result_sender, abort_on_error, error);
                            }
                        };
                        //if version >= 4 {
                        //    let mut f = || -> Result<()> {
                        //        decode!(&mut reader, unknown: u32);
                        //        println!(">>> {:20} {:15x} {}", unknown, unknown, record.filename());
                        //        Ok(())
                        //    };
                        //    let _ = f();
                        //}
                    }

                    if let Some(blocks) = record.compression_blocks() {
                        if !ignore_null_checksums || record.sha1().map_or(true, |sha1| sha1 != NULL_SHA1) {
                            let header_size = Pak::header_size(version, variant, record);
                            let mut hasher = OpenSSLSha1::new();

                            let base_offset;
                            let mut next_start_offset;

                            if variant == Variant::ConanExiles {
                                // only version 4 is correctly supported
                                base_offset = 0;
                                next_start_offset = record.offset() + header_size + 20;
                            } else if version >= 7 {
                                // + 4 for unknown extra field in inline record
                                base_offset = record.offset();
                                next_start_offset = header_size + 4;
                            } else if version >= 4 {
                                base_offset = 0;
                                next_start_offset = record.offset() + header_size + 4;
                            } else {
                                base_offset = 0;
                                next_start_offset = record.offset() + header_size;
                            }

                            let end_offset = next_start_offset + record.size();

                            for (index, block) in blocks.iter().enumerate() {
                                if block.start_offset > block.end_offset {
                                    check_error!(ok, result_sender, abort_on_error,
                                        Error::new(format!(
                                            "compression block start offset is bigger than end offset: {} > {}",
                                            block.start_offset, block.end_offset,
                                        )).with_path(record.filename()));
                                } else {
                                    if next_start_offset != block.start_offset {
                                        check_error!(ok, result_sender, abort_on_error,
                                            Error::new(format!(
                                                "compression block with index {} start offset differes from expected value: {} != {} ({})",
                                                index, block.start_offset, next_start_offset, block.start_offset as i64 - next_start_offset as i64,
                                            )).with_path(record.filename()));
                                    }

                                    let block_size = block.end_offset - block.start_offset;

                                    buffer.resize(block_size as usize, 0);
                                    if let Err(error) = io!{
                                        reader.seek(SeekFrom::Start(base_offset + block.start_offset)),
                                        reader.read_exact(&mut buffer)
                                    } {
                                        let _ = result_sender.send(Err(Error::io_with_path(error, record.filename())));
                                        return;
                                    }
                                    hasher.update(&buffer);

                                    next_start_offset += block_size;
                                }
                            }

                            if next_start_offset != end_offset {
                                check_error!(ok, result_sender, abort_on_error,
                                    Error::new(format!(
                                        "actual record end offset differes from expected value: {} != {} ({})",
                                        next_start_offset, end_offset, next_start_offset as i64 - end_offset as i64,
                                    )).with_path(record.filename()));
                            }

                            let actual_digest = hasher.finish();
                            if &actual_digest != record.sha1().as_ref().unwrap_or(&NULL_SHA1) {
                                check_error!(ok, result_sender, abort_on_error, Error::new(format!(
                                    "checksum missmatch:\n\
                                    \texpected: {}\n\
                                    \tactual:   {}",
                                    HexDisplay::new(record.sha1().as_ref().unwrap_or(&NULL_SHA1)),
                                    HexDisplay::new(&actual_digest)
                                )).with_path(record.filename()));
                            }
                        }
                    } else if let Err(error) = check_data(&mut reader, record.filename(), offset,
                            record.size(), record.sha1().as_ref().unwrap_or(&NULL_SHA1), ignore_null_checksums, &mut buffer) {
                        check_error!(ok, result_sender, abort_on_error, error);
                    }

                    if ok {
                        let _ = result_sender.send(Ok(record));
                    }
                }
            });
        }

        drop(work_receiver);
        drop(result_sender);

        if let Some(filter) = &mut filter {
            let records = pak.index().records()
                .iter()
                .filter(|&record| filter.visit(record.filename()));

            error_count += enqueue(records, work_sender, abort_on_error, null_separated)?;
        } else {
            error_count += enqueue(pak.index().records().iter(), work_sender, abort_on_error, null_separated)?;
        }

        let linesep = if options.null_separated { '\0' } else { '\n' };

        while let Ok(result) = result_receiver.recv() {
            match result {
                Ok(record) => {
                    if verbose {
                        print!("{}: OK{}", record.filename(), linesep);
                    }
                }
                Err(error) => {
                    error_count += 1;
                    if abort_on_error {
                        return Err(error);
                    }
                    let _ = error.write_to(&mut stderr, null_separated);
                }
            }
        }

        if let Some(filter) = &filter {
            let mut iter = filter.non_visited_paths();
            if let Some(filename) = iter.next() {
                let mut message = format!("Paths not found in pak:\n* {}", filename);
                error_count += 1;
                for filename in iter {
                    message.push_str("\n* ");
                    message.push_str(&filename);
                    error_count += 1;
                }
                let error = Error::new(message);
                if abort_on_error {
                    return Err(error);
                }
                let _ = error.write_to(&mut stderr, null_separated);
            }
        }

        Ok(error_count)
    });

    match thread_result {
        Err(error) => {
            return Err(Error::new(format!("threading error: {:?}", error)));
        }
        Ok(result) => result
    }
}

fn enqueue<'a>(records: impl std::iter::Iterator<Item=&'a Record>, work_sender: Sender<&'a Record>, abort_on_error: bool, null_separated: bool) -> Result<usize> {
    let mut filenames: HashSet<&str> = HashSet::new();
    let mut error_count = 0usize;
    for record in records {
        if !filenames.insert(record.filename()) {
            let error = Error::new(
                "filename not unique in archive".to_string()
            ).with_path(record.filename());

            error_count += 1;
            if abort_on_error {
                return Err(error);
            } else {
                let _ = error.write_to(&mut stderr(), null_separated);
            }
        }

        let _ = work_sender.send(record);
    }
    Ok(error_count)
}

```

`src/decode.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::io::Read;
use crate::Result;
use crate::record::CompressionBlock;

pub trait Decode: Sized {
    fn decode(reader: &mut impl Read) -> Result<Self>;
}

impl Decode for bool {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 1];
        reader.read_exact(&mut buffer)?;
        Ok(buffer[0] != 0u8)
    }
}

impl Decode for u8 {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 1];
        reader.read_exact(&mut buffer)?;
        Ok(buffer[0])
    }
}
impl Decode for u32 {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 4];
        reader.read_exact(&mut buffer)?;
        Ok(Self::from_le_bytes(buffer))
    }
}

impl Decode for i32 {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 4];
        reader.read_exact(&mut buffer)?;
        Ok(Self::from_le_bytes(buffer))
    }
}

impl Decode for u64 {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 8];
        reader.read_exact(&mut buffer)?;
        Ok(Self::from_le_bytes(buffer))
    }
}

impl Decode for i64 {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 8];
        reader.read_exact(&mut buffer)?;
        Ok(Self::from_le_bytes(buffer))
    }
}

impl Decode for u128 {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut buffer = [0u8; 16];
        reader.read_exact(&mut buffer)?;
        Ok(Self::from_le_bytes(buffer))
    }
}

impl<const N: usize> Decode for [u8; N] {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let mut items = [0u8; N];
        reader.read_exact(&mut items)?;
        Ok(items)
    }
}

impl Decode for CompressionBlock {
    #[inline]
    fn decode(reader: &mut impl Read) -> Result<Self> {
        let start_offset = u64::decode(reader)?;
        let end_offset   = u64::decode(reader)?;

        Ok(Self {
            start_offset,
            end_offset,
        })
    }
}

#[macro_export]
macro_rules! decode {
    ($reader:expr, $($rest:tt)*) => {
        decode!(@decl $($rest)*);
        decode!(@decode () ($reader) $($rest)*);
    };

    (@decode ($($wrap:tt)*) ($reader:expr) $(,)?) => {};

    (@decode ($($wrap:tt)*) ($reader:expr) if $($rest:tt)*) => {
        decode!(@if ($($wrap)*) ($reader) () $($rest)*);
    };

    (@if ($($wrap:tt)*) ($reader:expr) ($($cond:tt)*) { $($body:tt)* } $($rest:tt)*) => {
        if $($cond)* {
            decode!(@decode (Some) ($reader) $($body)*);
        } else {
            decode!(@none $($body)*);
        }
        decode!(@decode ($($wrap)*) ($reader) $($rest)*);
    };

    (@if ($($wrap:tt)*) ($reader:expr) ($($cond:tt)*) $tok:tt $($rest:tt)*) => {
        decode!(@if ($($wrap)*) ($reader) ($($cond)* $tok) $($rest)*);
    };

    (@decl $(,)?) => {};

    (@decl if $($rest:tt)*) => {
        decode!(@decl_if () $($rest)*);
    };

    (@decl $name:ident : $type:ty $([$($count:tt)*])? $(,)?) => {
        let $name;
    };

    (@decl $name:ident : $type:ty $([$($count:tt)*])?, $($rest:tt)*) => {
        let $name;
        decode!(@decl $($rest)*);
    };

    (@decl_if ($($cond:tt)*) { $($body:tt)* } $($rest:tt)*) => {
        decode!(@decl $($body)*);
        decode!(@decl $($rest)*);
    };

    (@decl_if ($($cond:tt)*) $tok:tt $($rest:tt)*) => {
        decode!(@decl_if ($($cond)* $tok) $($rest)*);
    };

    (@none $(,)?) => {};

    (@none if $($rest:tt)*) => {
        decode!(@none_if () $($rest)*);
    };

    (@none $name:ident : $type:ty $([$($count:tt)*])? $(,)?) => {
        $name = None;
    };

    (@none $name:ident : $type:ty $([$($count:tt)*])?, $($rest:tt)*) => {
        $name = None;
        decode!(@none $($rest)*);
    };

    (@none_if ($cond:expr) { $($body:tt)* } $($rest:tt)*) => {
        decode!(@none $($body)*);
        decode!(@none $($rest)*);
    };

    (@none_if ($($cond:tt)*) $tok:tt $($rest:tt)*) => {
        decode!(@none_if ($($cond)* $tok) $($rest)*);
    };

    (@decode ($($wrap:tt)*) ($reader:expr) $name:ident : $type:ty $([$($count:tt)*])? $(,)?) => {
        decode!(@read ($($wrap)*) ($reader) $name $type $([$($count)*])?);
    };

    (@decode ($($wrap:tt)*) ($reader:expr) $name:ident : $type:ty $([$($count:tt)*])?, $($rest:tt)*) => {
        decode!(@read ($($wrap)*) ($reader) $name $type $([$($count)*])?);
        decode!(@decode ($($wrap)*) ($reader) $($rest)*);
    };

    (@read ($($wrap:tt)*) ($reader:expr) $name:ident $type:ty) => {
        $name = $($wrap)*(<$type>::decode($reader)?);
    };

    (@read ($($wrap:tt)*) ($reader:expr) $name:ident $type:ty [$count:ty]) => {
        $name = {
            let _count = <$count>::decode($reader)? as usize;
            let mut _items = Vec::with_capacity(_count);
            for _ in 0.._count {
                _items.push(<$type>::decode($reader)?);
            }
            $($wrap)*(_items)
        };
    };

    (@read ($($wrap:tt)*) ($reader:expr) $name:ident $type:ty [$count:expr]) => {
        $name = {
            let _count = $count;
            let mut _items = Vec::with_capacity(_count);
            for _ in 0..(_count) {
                _items.push(<$type>::decode($reader)?);
            }
            $($wrap)*(_items)
        };
    };
}

```

`src/decrypt.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use aes::cipher::{BlockDecrypt, NewBlockCipher};
use aes::{Aes256, Block, BLOCK_SIZE};
use log::trace;

pub fn decrypt(data: &mut Vec<u8>, key: &Vec<u8>) {
    trace!("Decrypting data using aes256 with key {:?}", key);
    let cipher = Aes256::new_from_slice(&key).expect("Unable to convert key to Aes256 cipher");
    assert_eq!(data.len() % BLOCK_SIZE, 0, "Data length must be a multiple of 16");

    for block in data.chunks_mut(BLOCK_SIZE) {
        cipher.decrypt_block(Block::from_mut_slice(block));
    }
}

```

`src/encode.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::io::Write;
use crate::Result;
use crate::record::CompressionBlock;

pub trait Encode: Sized {
    fn encode(&self, writer: &mut impl Write) -> Result<()>;
}

impl Encode for u8 {
    #[inline]
    fn encode(&self, writer: &mut impl Write) -> Result<()> {
        writer.write_all(&[*self])?;
        Ok(())
    }
}
impl Encode for u32 {
    #[inline]
    fn encode(&self, writer: &mut impl Write) -> Result<()> {
        writer.write_all(&self.to_le_bytes())?;
        Ok(())
    }
}


impl Encode for u64 {
    #[inline]
    fn encode(&self, writer: &mut impl Write) -> Result<()> {
        writer.write_all(&self.to_le_bytes())?;
        Ok(())
    }
}

impl<const N: usize> Encode for [u8; N] {
    #[inline]
    fn encode(&self, writer: &mut impl Write) -> Result<()> {
        writer.write_all(self)?;
        Ok(())
    }
}

impl Encode for CompressionBlock {
    #[inline]
    fn encode(&self, writer: &mut impl Write) -> Result<()> {
        self.start_offset.encode(writer)?;
        self.end_offset.encode(writer)
    }
}

#[macro_export]
macro_rules! encode {
    ($writer:expr, $($rest:tt)*) => {
        encode!(@encode ($writer) $($rest)*);
    };

    (@encode ($writer:expr) $(,)?) => {};

    (@encode ($writer:expr) if $($rest:tt)*) => {
        encode!(@if ($writer) () $($rest)*);
    };

    (@if ($writer:expr) ($($cond:tt)*) { $($body:tt)* } $($rest:tt)*) => {
        if $($cond)* {
            encode!(@encode ($writer) $($body)*);
        }
        encode!(@encode ($writer) $($rest)*);
    };

    (@if ($writer:expr) ($($cond:tt)*) $tok:tt $($rest:tt)*) => {
        encode!(@if ($writer) ($($cond)* $tok) $($rest)*);
    };

    (@encode ($writer:expr) $($rest:tt)*) => {
        encode!(@value ($writer) () $($rest)*);
    };

    (@value ($writer:expr) ($($expr:tt)*) [$($count:tt)*], $($rest:tt)*) => {
        encode!(@write ($writer) ($($expr)*) [$($count)*]);
        encode!(@encode ($writer) $($rest)*);
    };

    (@value ($writer:expr) ($($expr:tt)*) [$($count:tt)*]) => {
        encode!(@write ($writer) ($($expr)*) [$($count)*]);
    };

    (@value ($writer:expr) ($($expr:tt)*) , $($rest:tt)*) => {
        encode!(@write ($writer) ($($expr)*));
        encode!(@encode ($writer) $($rest)*);
    };

    (@value ($writer:expr) ($($expr:tt)*)) => {
        encode!(@write ($writer) ($($expr)*));
    };

    (@value ($writer:expr) ($($expr:tt)*) $tok:tt $($rest:tt)*) => {
        encode!(@value ($writer) ($($expr)* $tok) $($rest)*);
    };

    (@write ($writer:expr) ($value:expr)) => {
        ($value).encode($writer)?;
    };

    (@write ($writer:expr) ($value:expr) [$count:ty]) => {
        (($value).len() as $count).encode($writer)?;
        for _item in ($value).iter() {
            _item.encode($writer)?;
        }
    };
}

```

`src/filter.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::iter::Map;

use crate::Error;
use crate::Result;

#[derive(Debug)]
pub struct Filter<'a> {
    nodes: std::collections::HashMap<&'a str, Filter<'a>>,
    included: bool,
    visited: bool,
}

impl<'a> Default for Filter<'a> {
    fn default() -> Self {
        Self {
            nodes: std::collections::HashMap::<&'a str, Filter<'a>>::new(),
            included: false,
            visited: false,
        }
    }
}

impl<'a> Filter<'a> {
    pub fn new() -> Self {
        Self {
            nodes: std::collections::HashMap::<&'a str, Filter<'a>>::new(),
            included: false,
            visited: false,
        }
    }

    pub fn from_paths<I>(paths: I) -> Self
    where I: std::iter::Iterator<Item=&'a str> {
        let mut filter = Self {
            nodes: std::collections::HashMap::<&'a str, Filter<'a>>::new(),
            included: false,
            visited: false,
        };

        for path in paths {
            filter.insert(path);
        }

        filter
    }

    #[inline]
    pub fn insert(&mut self, path: &'a str) {
        self.insert_iter(path.trim_matches('/').split('/'))
    }

    pub fn insert_iter<I>(&mut self, mut path: I)
    where I: std::iter::Iterator<Item=&'a str> {
        if let Some(name) = path.next() {
            if name.is_empty() {
                self.insert_iter(path);
            } else if let Some(child) = self.nodes.get_mut(name) {
                child.insert_iter(path);
            } else {
                let mut child = Self::new();
                child.insert_iter(path);
                self.nodes.insert(name, child);
            }
        } else {
            self.included = true;
        }
    }

    #[inline]
    pub fn contains(&self, path: impl AsRef<str>) -> bool {
        self.contains_iter(path.as_ref().trim_matches('/').split('/').filter(|comp| !comp.is_empty()))
    }

    pub fn contains_iter<'b, I>(&self, mut path: I) -> bool
    where I: std::iter::Iterator<Item=&'b str> {
        if self.included {
            true
        } else if let Some(name) = path.next() {
            if let Some(child) = self.nodes.get(name) {
                child.contains_iter(path)
            } else {
                false
            }
        } else {
            false
        }
    }

    #[inline]
    pub fn visit(&mut self, path: impl AsRef<str>) -> bool {
        self.visit_iter(path.as_ref().trim_matches('/').split('/').filter(|comp| !comp.is_empty()))
    }

    pub fn visit_iter<'b, I>(&mut self, mut path: I) -> bool
    where I: std::iter::Iterator<Item=&'b str> {
        if self.included {
            self.visited = true;
            if let Some(name) = path.next() {
                if let Some(child) = self.nodes.get_mut(name) {
                    child.visit_iter(path);
                }
            }

            true
        } else if let Some(name) = path.next() {
            if let Some(child) = self.nodes.get_mut(name) {
                child.visit_iter(path)
            } else {
                false
            }
        } else {
            false
        }
    }

    #[inline]
    pub fn iter(&'a self) -> FilterIter<'a> {
        FilterIter {
            stack: vec![(self, self.nodes.iter(), 0)],
            buffer: String::new(),
        }
    }

    #[inline]
    pub fn paths(&'a self) -> Map<FilterIter<'_>, impl FnMut((&'a Filter<'a>, String)) -> String> {
        self.iter().map(|(_, path)| path)
    }

    #[inline]
    pub fn visited_paths(&'a self) -> Map<std::iter::Filter<FilterIter<'_>, impl FnMut(&(&'a Filter<'a>, String)) -> bool>, impl FnMut((&'a Filter<'a>, String)) -> String> {
        self.iter().filter(|&(filter, _)| filter.visited).map(|(_, path)| path)
    }

    #[inline]
    pub fn non_visited_paths(&'a self) -> Map<std::iter::Filter<FilterIter<'_>, impl FnMut(&(&'a Filter<'a>, String)) -> bool>, impl FnMut((&'a Filter<'a>, String)) -> String> {
        self.iter().filter(|&(filter, _)| !filter.visited).map(|(_, path)| path)
    }

    pub fn assert_all_visited(&self) -> Result<()> {
        let mut iter = self.non_visited_paths();
        if let Some(filename) = iter.next() {
            let mut message = format!("Paths not found in pak:\n* {}", filename);
            for filename in iter {
                message.push_str("\n* ");
                message.push_str(&filename);
            }
            return Err(Error::new(message));
        }
        Ok(())
    }

    //#[inline]
    //pub fn filter<'b, I>(&'a mut self, records: I) -> std::iter::Filter<I, impl FnMut(&&'b Record) -> bool>
    //where I: Iterator<Item=&'b Record> {
    //    records.filter(move |&record| self.visit(record.filename()))
    //}
}

#[derive(Debug)]
pub struct FilterIter<'a> {
    stack: Vec<(&'a Filter<'a>, std::collections::hash_map::Iter<'a, &'a str, Filter<'a>>, usize)>,
    buffer: String,
}

impl<'a> std::iter::Iterator for FilterIter<'a> {
    type Item = (&'a Filter<'a>, String);

    fn next(&mut self) -> Option<Self::Item> {
        while let Some(&mut (_, ref mut iter, buffer_index)) = self.stack.last_mut() {
            if let Some((&name, child)) = iter.next() {
                let prev_index = self.buffer.len();
                self.buffer.push('/');
                self.buffer.push_str(name);
                self.stack.push((child, child.nodes.iter(), prev_index));
            } else {
                let (child, _, _) = self.stack.pop().unwrap();

                if child.included {
                    let filename = self.buffer.clone();
                    self.buffer.truncate(buffer_index);
                    return Some((child, filename));
                } else {
                    self.buffer.truncate(buffer_index);
                }
            }
        }
        None
    }
}

impl<'a> From<&[&'a str]> for Filter<'a> {
    #[inline]
    fn from(paths: &[&'a str]) -> Self {
        Filter::from_paths(paths.iter().cloned())
    }
}

```

`src/index.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use crate::decode;
use crate::decode::Decode;
use crate::decrypt::decrypt;
use crate::Variant;
use crate::{Error, Record, Result};

use std::convert::TryFrom;
use std::io::{Cursor, Read, Seek, SeekFrom};
use log::{debug, error, trace, warn};

#[derive(Copy, Clone, Debug, PartialEq)]
pub enum Encoding {
    ASCII,
    Latin1,
    UTF8,
}

impl Default for Encoding {
    fn default() -> Self {
        Encoding::UTF8
    }
}

impl Encoding {
    pub fn parse_vec(self, buffer: Vec<u8>) -> Result<String> {
        match self {
            Encoding::UTF8 => Ok(String::from_utf8(buffer)?),
            Encoding::ASCII => {
                for byte in &buffer {
                    if *byte > 0x7F {
                        return Err(Error::new(format!(
                            "ASCII conversion error: byte outside of ASCII range: {}",
                            *byte
                        )));
                    }
                }
                Ok(buffer.into_iter().map(|byte| byte as char).collect())
            }
            Encoding::Latin1 => Ok(buffer.into_iter().map(|byte| byte as char).collect()),
        }
    }
}

impl TryFrom<&str> for Encoding {
    type Error = crate::result::Error;

    fn try_from(encoding: &str) -> std::result::Result<Self, Error> {
        if encoding.eq_ignore_ascii_case("utf-8") || encoding.eq_ignore_ascii_case("utf8") {
            Ok(Encoding::UTF8)
        } else if encoding.eq_ignore_ascii_case("ascii") {
            Ok(Encoding::ASCII)
        } else if encoding.eq_ignore_ascii_case("latin1")
            || encoding.eq_ignore_ascii_case("iso-8859-1")
        {
            Ok(Encoding::Latin1)
        } else {
            Err(Error::new(format!("unsupported encoding: {:?}", encoding)))
        }
    }
}

#[derive(Debug)]
pub struct IndexLoadParams {
    keep_full_directory: bool,
    validate_pruning: bool,
    delay_pruning: bool,
    write_path_hash: bool,
    write_full_directory_index: bool,
}

#[derive(Debug, Default)]
pub struct SecondaryIndexInfo {
    has_path_hash_index: bool,
    path_hash_index_offset: i64,
    path_hash_index_size: i64,
    has_full_directory_index: bool,
    full_directory_index_offset: i64,
    full_directory_index_size: i64,
    encoded_record_info: Vec<u8>,
}

#[derive(Debug)]
pub struct Index {
    mount_point: Option<String>,
    records: Vec<Record>,
}

impl Index {
    pub(crate) fn new(mount_point: Option<String>, records: Vec<Record>) -> Self {
        Self {
            mount_point,
            records,
        }
    }
    pub fn read<R>(
        reader: &mut R,
        index_size: usize,
        version: u32,
        variant: Variant,
        encoding: Encoding,
        encryption_key: Option<Vec<u8>>,
    ) -> Result<Self> 
    where
        R: Read,
        R: Seek,
    {
        let mut index_buff = vec![0; index_size as usize];
        reader.read_exact(&mut index_buff)?;
        if let Some(encryption_key) = &encryption_key {
            decrypt(&mut index_buff, &encryption_key);
        }

        let decrypted_index = &mut Cursor::new(index_buff);

        let mount_point = read_path(decrypted_index, encoding)?;
        let records;
        if version < 10 {
            records = read_records_legacy(decrypted_index, version, variant, encoding)
                .expect("Failed to read index records");
        } else {
            if let Ok((index_info, mut r)) = read_records(decrypted_index, encoding) {
                if let Ok(mut sec_records) = read_secondary_index_records(reader, &index_info, encryption_key, encoding) {
                    r.append(&mut sec_records);
                }

                records = r;
            } else {
                return Err(Error::new(format!(
                    "Only know how to handle Conan Exile paks of version 4, but version was {}.",
                    version
                )));
            }
        };

        Ok(Self {
            mount_point: if mount_point.is_empty() { None } else { Some(mount_point) },
            records,
        })
    }

    #[inline]
    pub fn mount_point(&self) -> Option<&str> {
        match &self.mount_point {
            Some(mount_point) => Some(mount_point),
            None => None
        }
    }

    #[inline]
    pub fn records(&self) -> &[Record] {
        &self.records
    }

    #[inline]
    pub fn into_records<'a>(self) -> Vec<Record> {
        self.records
    }
}

pub fn read_path(reader: &mut impl Read, encoding: Encoding) -> Result<String> {
    let mut buf = [0; 4];
    reader.read_exact(&mut buf)?;
    let size = i32::from_le_bytes(buf);

    if size < 0 {
        let utf16_size = -(size as isize) as usize;
        let mut buf = vec![0u8; 2 * utf16_size];
        reader.read_exact(&mut buf)?;

        let mut utf16 = Vec::with_capacity(utf16_size);
        let mut index = 0usize;
        while index < buf.len() {
            let bytes = [buf[index], buf[index + 1]];
            utf16.push(u16::from_le_bytes(bytes));
            index += 2;
        }

        if let Some(index) = utf16.iter().position(|&ch| ch == 0) {
            utf16.truncate(index);
        }

        return Ok(String::from_utf16(&utf16)?);
    }

    let mut buf = vec![0u8; size as usize];
    reader.read_exact(&mut buf)?;
    if let Some(index) = buf.iter().position(|&byte| byte == 0) {
        buf.truncate(index);
    }

    encoding.parse_vec(buf)
}

pub fn read_records_legacy(
    reader: &mut impl Read,
    version: u32,
    variant: Variant,
    encoding: Encoding,
) -> Result<Vec<Record>> {
    let read_record = match variant {
        Variant::ConanExiles => {
            if version != 4 {
                return Err(Error::new(format!(
                    "Only know how to handle Conan Exile paks of version 4, but version was {}.",
                    version
                )));
            }
            Record::read_conan_exiles
        }
        Variant::Standard => match version {
            1 => Record::read_v1,
            2 => Record::read_v2,
            _ if version <= 5 || version <= 9 => Record::read_v3,
            _ => {
                return Err(Error::new(format!("unsupported version: {}", version)));
            }
        },
    };

    decode!(reader, entry_count: u32);

    let mut records = Vec::with_capacity(entry_count as usize);

    for _ in 0..entry_count {
        let filename = read_path(reader, encoding)?;
        let record = read_record(reader, filename)?;
        records.push(record);
    }

    Ok(records)
}

pub fn read_records(
    reader: &mut impl Read,
    encoding: Encoding,
) -> Result<(SecondaryIndexInfo, Vec<Record>)> {
    decode!(
        reader,
        entry_count: i32,
        path_hash_seed: u64,
        has_path_hash_index: u32
    );

    let mut secondary_index_info = SecondaryIndexInfo::default();
    secondary_index_info.has_path_hash_index = has_path_hash_index != 0;

    if secondary_index_info.has_path_hash_index {
        decode!(
            reader,
            path_hash_index_offset: i64,
            path_hash_index_size: i64,
            path_hash_index_hash: [u8; 20]
        );

        secondary_index_info.has_path_hash_index = path_hash_index_size != -1;
        secondary_index_info.path_hash_index_offset = path_hash_index_offset;
        secondary_index_info.path_hash_index_size = path_hash_index_size;
    }
    decode!(reader, has_full_directory_index: u32);
    secondary_index_info.has_full_directory_index = has_full_directory_index != 0;

    if secondary_index_info.has_full_directory_index {
        decode!(
            reader,
            full_directory_index_offset: i64,
            full_directory_index_size: i64,
            full_directory_index_hash: [u8; 20]
        );
        secondary_index_info.has_full_directory_index = full_directory_index_size != -1;
        secondary_index_info.full_directory_index_offset = full_directory_index_offset;
        secondary_index_info.full_directory_index_size = full_directory_index_size;
    }
    decode!(reader, pak_entries_size: i32);
    let mut pak_entries = vec![0u8; pak_entries_size as usize];
    reader.read_exact(&mut pak_entries)?;
    secondary_index_info.encoded_record_info = pak_entries;

    decode!(reader, file_count: u32);
    let mut records = Vec::with_capacity(file_count as usize);
    for _ in 0..file_count {
        let filename = read_path(reader, encoding)?;
        let record = Record::read_v3(reader, filename)?;
        records.push(record);
    }

    Ok((secondary_index_info, records))
}

fn read_secondary_index_records<R>(
    reader: &mut R,
    index_info: &SecondaryIndexInfo,
    encryption_key: Option<Vec<u8>>,
    encoding: Encoding
) -> Result<Vec<Record>> where
    R: Read,
    R: Seek,
{
    debug!("Reading secondary index");

    let mut records = vec![];
    let mut encoded_record_info = Cursor::new(&index_info.encoded_record_info[..]);
    if index_info.has_full_directory_index {
        debug!("Reading full directory index");
        let mut full_directory_index_data =
            vec![0u8; index_info.full_directory_index_size as usize];
        if let Err(err) = reader.seek(SeekFrom::Start(
            index_info.full_directory_index_offset as u64,
        )) {
            error!("Failed to load fill directory index: {}", err);
            return Err(Error::from(err));
        }
        if let Err(err) = reader.read_exact(&mut full_directory_index_data) {
            error!("Failed to read full directory index: {}", err);
            return Err(Error::from(err));
        }

        if let Some(key) = encryption_key {
            decrypt(&mut full_directory_index_data, &key);
        }

        let mut index_buff = &full_directory_index_data[..];
        decode!(&mut index_buff, dir_count: u32);
        for i in 0..dir_count {
            let path = read_path(&mut index_buff, encoding);
            decode!(&mut index_buff, file_count: u32);
            let mut file_path = String::new();
            if let Ok(p) = path {
                trace!("Reading {} files from directory {}", file_count, p);
                if p != "/" {
                    file_path.push_str(&p);
                }
            } else {
                warn!("Failed to resolve path for file {}. Skipping.", i);
                continue;
            }

            for _ in 0..file_count {
                let file_name = read_path(&mut index_buff, encoding);
                decode!(&mut index_buff, entry: u32);

                if let Ok(name) = file_name {
                    let mut p = file_path.clone();
                    p.push_str(&name);

                    encoded_record_info.seek(SeekFrom::Start(entry as u64))?;
                    trace!("Decoding file {} from location {}", p, entry);
                    if let Ok(record) = Record::decode_entry(&mut encoded_record_info, p.clone()) {
                        records.push(record);
                    } else {
                        warn!("Failed to read record for file {}. Skipping.", p);
                    }
                } else {
                    warn!("Failed to resolve name for file {} in folder {}. Skipping.", i, file_path);
                    continue;
                }
            }
        }
    } else if index_info.has_path_hash_index {
        warn!("Hash index is used as no full directory index was found. Filenames and paths can not be restored using this index!");
        debug!("Reading path hash index from {} with size {}", index_info.path_hash_index_offset, index_info.path_hash_index_size);
        let mut path_hash_index_data =
            vec![0u8; index_info.path_hash_index_size as usize];
        if let Err(err) = reader.seek(SeekFrom::Start(
            index_info.path_hash_index_offset as u64,
        )) {
            error!("Failed to load fill directory index: {}", err);
            return Err(Error::from(err));
        }
        if let Err(err) = reader.read_exact(&mut path_hash_index_data) {
            error!("Failed to read full directory index: {}", err);
            return Err(Error::from(err));
        }

        if let Some(key) = encryption_key {
            decrypt(&mut path_hash_index_data, &key);
        }

        let mut index_buff = &path_hash_index_data[..];
        decode!(&mut index_buff, file_count: u32);
        debug!("Found {} files in hash index", file_count);
        for _ in 0..file_count {
            decode!(&mut index_buff, hash: u64, entry: u32);

            encoded_record_info.seek(SeekFrom::Start(entry as u64))?;
            trace!("Decoding file {:x} from location {}", hash, entry);
            if let Ok(record) = Record::decode_entry(&mut encoded_record_info, format!("{:x}", hash)) {
                records.push(record);
            } else {
                warn!("Failed to read record for file {:x}. Skipping.", hash);
            }
        }
    } else {
        warn!("Neither full direcotry nor hash index found! Files are probably missing!");
    }

    debug!("Read {} records from secondary index", records.len());

    Ok(records)
}

```

`src/info.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use crate::{pak::{Pak, COMPR_NONE, COMPR_ZLIB, COMPR_BIAS_MEMORY, COMPR_BIAS_SPEED}, util::print_table};
use crate::result::Result;
use crate::util::{format_size, Align};

pub fn info(pak: &Pak, human_readable: bool) -> Result<()> {
    let fmt_size = if human_readable {
        |size: u64| format_size(size)
    } else {
        |size: u64| format!("{}", size)
    };

    let mut sum_size              = 0;
    let mut sum_uncompressed_size = 0;
    let mut uncompr_count     = 0usize;
    let mut zlib_count        = 0usize;
    let mut bias_speed_count  = 0usize;
    let mut bias_memory_count = 0usize;
    let mut other_count       = 0usize;
    let mut encrypted_count   = 0usize;
    let mut sum_uncompr_size     = 0;
    let mut sum_zlib_size        = 0;
    let mut sum_bias_speed_size  = 0;
    let mut sum_bias_memory_size = 0;
    let mut sum_unknown_size     = 0;
    let mut sum_encrypted_size   = 0;

    let mut sum_uncompr_zlib_size        = 0;
    let mut sum_uncompr_bias_speed_size  = 0;
    let mut sum_uncompr_bias_memory_size = 0;
    let mut sum_uncompr_unknown_size     = 0;
    let mut sum_uncompr_encrypted_size   = 0;

    for record in pak.index().records() {
        sum_size += record.size();
        sum_uncompressed_size += record.uncompressed_size();
        if record.encrypted() {
            encrypted_count += 1;
            sum_encrypted_size += record.size();
            sum_uncompr_encrypted_size += record.uncompressed_size();
        }
        match record.compression_method() {
            self::COMPR_NONE => {
                uncompr_count += 1;
                sum_uncompr_size += record.size();
            }
            self::COMPR_ZLIB => {
                zlib_count += 1;
                sum_zlib_size += record.size();
                sum_uncompr_zlib_size += record.uncompressed_size();
            }
            self::COMPR_BIAS_SPEED => {
                bias_speed_count += 1;
                sum_bias_speed_size += record.size();
                sum_uncompr_bias_speed_size += record.uncompressed_size();
            }
            self::COMPR_BIAS_MEMORY => {
                bias_memory_count += 1;
                sum_bias_memory_size += record.size();
                sum_uncompr_bias_memory_size += record.uncompressed_size();
            }
            _ => {
                other_count += 1;
                sum_unknown_size += record.size();
                sum_uncompr_unknown_size += record.uncompressed_size();
            }
        }
    }

    println!("Pak Version: {}", pak.version());
    println!("Mount Point: {}", pak.index().mount_point().unwrap_or(""));
    println!();

    print_table(
        &["", "Count", "Size", "Uncompr."],
        &[Align::Left, Align::Right, Align::Right, Align::Right],
        &[
            vec!["Files:",              &format!("{}", pak.index().records().len()), &fmt_size(sum_size),             &fmt_size(sum_uncompressed_size)],
            vec!["Uncompr.:",           &format!("{}", uncompr_count),       &fmt_size(sum_uncompr_size),     ""],
            vec!["ZLIB Compr.:",        &format!("{}", zlib_count),          &fmt_size(sum_zlib_size),        &fmt_size(sum_uncompr_zlib_size)],
            vec!["Bias Speed Compr.:",  &format!("{}", bias_speed_count),    &fmt_size(sum_bias_speed_size),  &fmt_size(sum_uncompr_bias_speed_size)],
            vec!["Bias Memory Compr.:", &format!("{}", bias_memory_count),   &fmt_size(sum_bias_memory_size), &fmt_size(sum_uncompr_bias_memory_size)],
            vec!["Unknown Compr.:",     &format!("{}", other_count),         &fmt_size(sum_unknown_size),     &fmt_size(sum_uncompr_unknown_size)],
            vec!["Encrypted:",          &format!("{}", encrypted_count),     &fmt_size(sum_encrypted_size),   &fmt_size(sum_uncompr_encrypted_size)],
        ],
    );

    Ok(())
}

```

`src/lib.rs`:

```rs
pub mod pak;
pub use pak::{Pak, Variant};

pub mod decrypt;
pub mod index;
pub mod result;
pub use result::{Error, Result};

pub mod record;
pub use record::Record;

pub mod info;
pub mod util;
pub mod decode;
pub mod encode;
pub mod filter;
pub use filter::Filter;

pub mod unpack;
pub mod pack;
pub mod check;

pub mod reopen;
pub mod walkdir;

#[cfg(target_os = "linux")]
pub mod mount;

```

`src/mount.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{collections::HashMap, ffi::OsStr, fs::File, io::Read, path::Path, time::{Duration, SystemTime, UNIX_EPOCH}};
use std::os::unix::fs::FileExt;
use std::os::linux::fs::MetadataExt;

use cntr_fuse as fuse;
use flate2::bufread::ZlibDecoder;
use fuse::{Filesystem, FileType, Request, ReplyEntry, FileAttr, ReplyAttr, ReplyEmpty, ReplyOpen, ReplyDirectory, ReplyStatfs, ReplyRead, FUSE_ROOT_ID};
use daemonize::{Daemonize, DaemonizeError};
use libc::{ENOENT, EISDIR, EACCES, ENOTDIR, EINVAL, EIO, ENOSYS, O_RDONLY};

use crate::{Error, Pak, Record, Result, pak::{self, Variant}, record::CompressionBlock, util::{make_pak_path, parse_pak_path}};

#[derive(Debug)]
enum INodeData {
    File {
        offset: u64,
        size: u64,
        uncompressed_size: u64,
        compression_method: u32,
        compression_blocks: Option<Vec<CompressionBlock>>,
        encrypted: bool,
        compression_block_size: u32,
    },
    Dir(HashMap<String, u64>)
}

#[derive(Debug)]
struct INode {
    parent: u64,
    inode: u64,
    data: INodeData,
    stat: FileAttr,
}

impl INode {
    #[inline]
    fn is_dir(&self) -> bool {
        matches!(self.data, INodeData::Dir(_))
    }

    #[allow(unused)]
    #[inline]
    fn is_file(&self) -> bool {
        matches!(self.data, INodeData::File { .. })
    }
}

#[derive(Debug)]
pub struct U4PakFS {
    file: File,
    inodes: Vec<INode>,

    atime:  SystemTime,
    mtime:  SystemTime,
    ctime:  SystemTime,
    crtime: SystemTime,

    uid: u32,
    gid: u32,

    blksize: u64,
    blocks:  u64,
}

impl U4PakFS {
    pub fn new(pak: &Pak, file: File) -> Result<Self> {
        let meta = file.metadata()?;

        let mut u4pakfs = U4PakFS {
            file,
            inodes: Vec::new(),

            atime:  make_time(meta.st_atime(), meta.st_atime_nsec()),
            mtime:  make_time(meta.st_mtime(), meta.st_mtime_nsec()),
            ctime:  make_time(meta.st_ctime(), meta.st_ctime_nsec()),
            crtime: meta.created().unwrap_or(UNIX_EPOCH),

            uid:    meta.st_uid(),
            gid:    meta.st_gid(),

            blksize: meta.st_blksize(),
            blocks:  0,
        };

        u4pakfs.inodes.push(INode {
            parent: FUSE_ROOT_ID,
            inode:  FUSE_ROOT_ID,
            data: INodeData::Dir(HashMap::new()),
            stat: FileAttr {
                ino:    FUSE_ROOT_ID,
                size:   5,
                blocks: 1 + ((5 - 1) / u4pakfs.blksize),
                atime:  u4pakfs.atime,
                mtime:  u4pakfs.mtime,
                ctime:  u4pakfs.ctime,
                crtime: u4pakfs.crtime,
                kind:   FileType::Directory,
                perm:   0o555,
                nlink:  1,
                uid:    u4pakfs.uid,
                gid:    u4pakfs.gid,
                rdev:   0,
                flags:  0,
            },
        });

        let version = pak.version();
        let variant = pak.variant();
        for record in pak.index().records() {
            u4pakfs.insert(variant, version, record)?;
        }

        Ok(u4pakfs)
    }

    #[inline]
    fn get(&self, inode: u64) -> Option<&INode> {
        self.inodes.get((inode - FUSE_ROOT_ID) as usize)
    }

    fn insert(&mut self, variant: Variant, version: u32, record: &Record) -> Result<u64> {
        let mut parent = FUSE_ROOT_ID;
        let path: Vec<_> = parse_pak_path(record.filename()).collect();

        if path.len() > 1 {
            for (index, &name) in path[0..path.len() - 1].iter().enumerate() {
                let new_inode = self.inodes.len() as u64 + FUSE_ROOT_ID;
                let parent_inode = &mut self.inodes[(parent - FUSE_ROOT_ID) as usize];

                if let INodeData::Dir(children) = &mut parent_inode.data {
                    if let Some(&child_inode) = children.get(name) {
                        parent = child_inode;
                    } else {
                        parent_inode.stat.nlink += 1;
                        parent_inode.stat.size += name.len() as u64 + 1;
                        parent_inode.stat.blocks = 1 + ((parent_inode.stat.size - 1) / self.blksize);

                        children.insert(name.to_string(), new_inode);
                        self.inodes.push(INode {
                            parent,
                            inode:  new_inode,
                            data: INodeData::Dir(HashMap::new()),
                            stat: FileAttr {
                                ino:    new_inode,
                                size:   5,
                                blocks: 1 + ((5 - 1) / self.blksize),
                                atime:  self.atime,
                                mtime:  self.mtime,
                                ctime:  self.ctime,
                                crtime: self.crtime,
                                kind:   FileType::Directory,
                                perm:   0o555,
                                nlink:  1,
                                uid:    self.uid,
                                gid:    self.gid,
                                rdev:   0,
                                flags:  0,
                            },
                        });

                        parent = new_inode;
                    }
                } else {
                    return Err(Error::new(format!("{}: not a directory", make_pak_path(path[0..index].iter()))));
                }
            }
        }

        if let Some(&name) = path.last() {
            let new_inode = self.inodes.len() as u64 + FUSE_ROOT_ID;
            let parent_inode = &mut self.inodes[(parent - FUSE_ROOT_ID) as usize];

            if let INodeData::Dir(children) = &mut parent_inode.data {
                if children.contains_key(name) {
                    return Err(Error::new(format!("{}: file already exists", record.filename())));
                }

                parent_inode.stat.nlink += 1;
                parent_inode.stat.size += name.len() as u64 + 1;
                parent_inode.stat.blocks = 1 + ((parent_inode.stat.size - 1) / self.blksize);

                children.insert(name.to_string(), new_inode);

                let atime:  SystemTime;
                let mtime:  SystemTime;
                let ctime:  SystemTime;
                let crtime: SystemTime;
                if let Some(timestamp) = record.timestamp() {
                    atime  = UNIX_EPOCH + Duration::from_secs(timestamp);
                    mtime  = atime;
                    ctime  = atime;
                    crtime = atime;
                } else {
                    atime  = self.atime;
                    mtime  = self.mtime;
                    ctime  = self.ctime;
                    crtime = self.crtime;
                }

                let offset = record.offset();
                let compression_blocks;
                if version < 7 {
                    compression_blocks = (*record.compression_blocks()).clone();
                } else if let Some(blocks) = record.compression_blocks() {
                    compression_blocks = Some(blocks.iter().map(|block| CompressionBlock {
                        start_offset: offset + block.start_offset,
                        end_offset:   offset + block.end_offset,
                    }).collect());
                } else {
                    compression_blocks = None;
                }

                let uncompressed_size = record.uncompressed_size();

                self.inodes.push(INode {
                    parent,
                    inode: new_inode,
                    data: INodeData::File {
                        offset: offset + pak::Pak::header_size(version, variant, record),
                        size: record.size(),
                        uncompressed_size,
                        compression_method: record.compression_method(),
                        compression_blocks,
                        encrypted: record.encrypted(),
                        compression_block_size: record.compression_block_size(),
                    },
                    stat: FileAttr {
                        ino:    new_inode,
                        size:   uncompressed_size,
                        blocks: if uncompressed_size != 0 { 1 + ((uncompressed_size - 1) / self.blksize) } else { 0 },
                        atime,
                        mtime,
                        ctime,
                        crtime,
                        kind:   FileType::RegularFile,
                        perm:   0o444,
                        nlink:  1,
                        uid:    self.uid,
                        gid:    self.gid,
                        rdev:   0,
                        flags:  0,
                    },
                });

            } else {
                return Err(Error::new(format!("{}: not a directory", make_pak_path(path[0..path.len() - 1].iter()))));
            }
        } else {
            return Err(Error::new("empty path".to_string()));
        }

        Ok(0)
    }
}

const TTL: Duration = Duration::from_secs(std::u64::MAX);

impl Filesystem for U4PakFS {
    fn lookup(&mut self, _req: &Request, parent: u64, name: &OsStr, reply: ReplyEntry) {
        if let Some(mut inode_data) = self.get(parent) {
            if "." == name {
                // done
            } else if ".." == name {
                inode_data = if let Some(inode_data) = self.get(inode_data.parent) {
                    inode_data
                } else {
                    return reply.error(ENOENT);
                };
            } else if let INodeData::Dir(children) = &inode_data.data {
                if let Some(name) = name.to_str() {
                    if let Some(&inode) = children.get(name) {
                        inode_data = if let Some(inode_data) = self.get(inode) {
                            inode_data
                        } else {
                            return reply.error(ENOENT);
                        };
                    } else {
                        return reply.error(ENOENT);
                    }
                } else {
                    return reply.error(ENOENT);
                }
            } else {
                return reply.error(ENOTDIR);
            }

            return reply.entry(&TTL, &inode_data.stat, 0);
        } else {
            return reply.error(ENOENT);
        }
    }

    fn getattr(&mut self, _req: &Request, ino: u64, reply: ReplyAttr) {
        if let Some(inode_data) = self.get(ino) {
            return reply.attr(&TTL, &inode_data.stat);
        } else {
            return reply.error(ENOENT);
        }
    }

    fn access(&mut self, _req: &Request, ino: u64, mask: u32, reply: ReplyEmpty) {
        if let Some(inode_data) = self.get(ino) {
            if mask & inode_data.stat.perm as u32 != mask {
                return reply.error(EACCES);
            }
            return reply.ok();
        } else {
            return reply.error(ENOENT);
        }
    }


    fn opendir(&mut self, _req: &Request, ino: u64, _flags: u32, reply: ReplyOpen) {
        if let Some(inode_data) = self.get(ino) {
            if !inode_data.is_dir() {
                return reply.error(ENOTDIR);
            }
            return reply.opened(ino, 0);
        } else {
            return reply.error(ENOENT);
        }
    }

    fn readdir(&mut self, _req: &Request, ino: u64, _fh: u64, offset: i64, mut reply: ReplyDirectory) {
        if let Some(inode_data) = self.get(ino) {
            if let INodeData::Dir(children) = &inode_data.data {
                // Offset will be the last offset FUSE already got, or 0 at the start.
                // Therefore I give the entries offsets starting with 1, so that the
                // start is no special case. The offset 0 is just the last offset FUSE
                // already got, which is not a real entry.
                let mut entry_offset = 1;
                if offset < entry_offset {
                    reply.add(ino, entry_offset, FileType::Directory, ".");
                }
                entry_offset += 1;
                if offset < entry_offset {
                    reply.add(inode_data.parent, entry_offset, FileType::Directory, "..");
                }
                entry_offset += 1;
                for (name, &child_inode) in children {
                    if offset < entry_offset {
                        let child = self.get(child_inode).unwrap();
                        if reply.add(child.inode, entry_offset, if child.is_dir() {
                            FileType::Directory
                        } else {
                            FileType::RegularFile
                        }, name) {
                            break;
                        }
                    }
                    entry_offset += 1;
                }
                return reply.ok();
            } else {
                return reply.error(ENOTDIR);
            }
        } else {
            return reply.error(ENOENT);
        }
    }

    fn statfs(&mut self, _req: &Request, _ino: u64, reply: ReplyStatfs) {
        reply.statfs(
            /* blocks  */ self.blocks,
            /* bfree   */ 0,
            /* bavail  */ 0,
            /* files   */ self.inodes.len() as u64,
            /* ffree   */ 0,
            /* bsize   */ self.blksize as u32,
            /* namelen */ std::u32::MAX,
            /* frsize  */ 0);
    }

    fn open(&mut self, _req: &Request, ino: u64, flags: u32, reply: ReplyOpen) {
        if let Some(inode_data) = self.get(ino) {
            if inode_data.is_dir() {
                return reply.error(EISDIR);
            } else if flags & 3 != O_RDONLY as u32 {
                return reply.error(EACCES);
            }
            return reply.opened(ino, 0);
        } else {
            return reply.error(ENOENT);
        }
    }

    fn read(&mut self, _req: &Request, ino: u64, _fh: u64, read_offset: i64, read_size: u32, reply: ReplyRead) {
        if let Some(inode_data) = self.get(ino) {
            if let INodeData::File {
                    compression_method,
                    compression_block_size,
                    compression_blocks,
                    encrypted,
                    offset,
                    size,
                    uncompressed_size,
            } = &inode_data.data {
                if *encrypted {
                    return reply.error(ENOSYS);
                }

                if read_offset < 0 {
                    return reply.error(EINVAL);
                }

                let uncompressed_size = *uncompressed_size;
                if read_offset as u64 >= uncompressed_size {
                    return reply.data(&[]);
                }

                let offset = *offset;
                match *compression_method {
                    pak::COMPR_NONE => {
                        let read_offset = offset + read_offset as u64;
                        let end_offset = std::cmp::min(offset + uncompressed_size, read_offset + read_size as u64);
                        let read_size = end_offset - read_offset;

                        let mut buffer = vec![0; read_size as usize];
                        if let Err(error) = self.file.read_exact_at(&mut buffer, read_offset) {
                            return reply.error(error.raw_os_error().unwrap_or(EIO));
                        }

                        return reply.data(&buffer);
                    }
                    pak::COMPR_ZLIB => {
                        if let Some(blocks) = compression_blocks {
                            let compression_block_size = *compression_block_size as u64;
                            let end_offset = std::cmp::min(read_offset as u64 + read_size as u64, uncompressed_size);
                            let start_block_index   = (read_offset as u64 / compression_block_size) as usize;
                            let mut end_block_index = (end_offset         / compression_block_size) as usize;

                            if end_offset % compression_block_size != 0 {
                                end_block_index += 1;
                            }

                            let mut current_offset = compression_block_size * start_block_index as u64;
                            let mut in_buffer = Vec::new();
                            let mut out_buffer = Vec::new();
                            for block in &blocks[start_block_index..end_block_index] {
                                let block_size = block.end_offset - block.start_offset;
                                in_buffer.resize(block_size as usize, 0);
                                if let Err(error) = self.file.read_exact_at(&mut in_buffer, block.start_offset) {
                                    return reply.error(error.raw_os_error().unwrap_or(EIO));
                                }

                                let mut zlib = ZlibDecoder::new(&in_buffer[..]);

                                if current_offset < read_offset as u64 {
                                    out_buffer.resize(std::cmp::min(compression_block_size, end_offset) as usize, 0);
                                    if let Err(error) = zlib.read_exact(&mut out_buffer) {
                                        return reply.error(error.raw_os_error().unwrap_or(EIO));
                                    }
                                    out_buffer.drain(0..read_offset as usize);
                                } else if end_offset < current_offset + compression_block_size {
                                    let remaining = end_offset - current_offset;
                                    let index = out_buffer.len();
                                    out_buffer.resize(index + remaining as usize, 0);
                                    if let Err(error) = zlib.read_exact(&mut out_buffer[index..]) {
                                        return reply.error(error.raw_os_error().unwrap_or(EIO));
                                    }
                                } else if let Err(error) = zlib.read_to_end(&mut out_buffer) {
                                    return reply.error(error.raw_os_error().unwrap_or(EIO));
                                }
                                current_offset += compression_block_size;
                            }

                            return reply.data(&out_buffer);
                        } else {
                            // version 2 has compression support, but not compression blocks
                            let size = *size;
                            let mut in_buffer = vec![0u8; size as usize];
                            let mut out_buffer = Vec::with_capacity(uncompressed_size as usize);
                            if let Err(error) = self.file.read_exact_at(&mut in_buffer, offset) {
                                return reply.error(error.raw_os_error().unwrap_or(EIO));
                            }

                            let mut zlib = ZlibDecoder::new(&in_buffer[..]);
                            if let Err(error) = zlib.read_to_end(&mut out_buffer) {
                                return reply.error(error.raw_os_error().unwrap_or(EIO));
                            }

                            if (read_size as usize) < out_buffer.len() {
                                return reply.data(&out_buffer[0..read_size as usize]);
                            }
                            return reply.data(&out_buffer);
                        }
                    }
                    _ => return reply.error(ENOSYS)
                }
            } else {
                return reply.error(EISDIR);
            }
        } else {
            return reply.error(ENOENT);
        }
    }
}

#[derive(Debug, PartialEq)]
pub struct MountOptions {
    pub foreground: bool,
    pub debug: bool,
}

impl Default for MountOptions {
    fn default() -> Self {
        Self {
            foreground: false,
            debug: false,
        }
    }
}

impl From<DaemonizeError> for Error {
    fn from(error: DaemonizeError) -> Self {
        Error::new(error.to_string())
    }
}

pub fn mount(pak: Pak, file: File, mountpt: impl AsRef<Path>, options: MountOptions) -> Result<()> {
    let mountpt = match mountpt.as_ref().canonicalize() {
        Ok(mountpt) => mountpt,
        Err(error) => return Err(Error::io_with_path(error, mountpt))
    };

    let mut fuse_options = vec![
        OsStr::new("fsname=u4pakfs"),
        OsStr::new("subtype=u4pakfs"),
        OsStr::new("ro")
    ];

    let foreground;
    if options.debug {
        foreground = true;
        fuse_options.push(OsStr::new("debug"));
    } else {
        foreground = options.foreground;
    }

    let fs = U4PakFS::new(&pak, file)?;

    drop(pak);

    if !foreground {
        let daemonize = Daemonize::new()
            .working_directory("/")
            .umask(0);

        daemonize.start()?;
    }

    fuse::mount(fs, mountpt, &fuse_options)?;

    Ok(())
}

fn make_time(mut time: i64, mut nsec: i64) -> SystemTime {
    if time <= 0 {
        time = -time;
        if nsec < 0 {
            nsec = -nsec;
        } else {
            time += 1;
            nsec = 1_000_000_000 - nsec;
        }

        return UNIX_EPOCH - Duration::new(time as u64, nsec as u32);
    } else {
        if nsec < 0 {
            time -= 1;
            nsec += 1_000_000_000;
        }
        return UNIX_EPOCH + Duration::new(time as u64, nsec as u32);
    }
}

```

`src/pack.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{collections::HashMap, convert::TryFrom, io::{BufWriter, Read, Seek, SeekFrom, Write}, num::{NonZeroU32, NonZeroUsize, NonZeroU64}, path::{Path, PathBuf}, time::UNIX_EPOCH};
use std::fs::{OpenOptions, File};

use crossbeam_channel::{Receiver, Sender, unbounded};
use crossbeam_utils::thread;
use openssl::sha::Sha1 as OpenSSLSha1;
use flate2::{Compression, write::ZlibEncoder};

use crate::{Result, pak::{BUFFER_SIZE, COMPRESSION_BLOCK_HEADER_SIZE, CONAN_EXILE_RECORD_HEADER_SIZE, DEFAULT_COMPRESSION_LEVEL, V1_RECORD_HEADER_SIZE, V2_RECORD_HEADER_SIZE, V3_RECORD_HEADER_SIZE, Variant}, record::CompressionBlock, walkdir::walkdir};
use crate::Pak;
use crate::result::Error;
use crate::pak::{PAK_MAGIC, Sha1, COMPR_NONE, COMPR_ZLIB, DEFAULT_BLOCK_SIZE, DEFAULT_MIN_COMPRESSION_SIZE, compression_method_name};
use crate::record::Record;
use crate::util::{make_pak_path, parse_compression_level, parse_pak_path, parse_size};
use crate::encode;
use crate::encode::Encode;
use crate::index::Encoding;
use crate::index::Index;

pub const COMPR_DEFAULT: u32 = u32::MAX;

#[derive(Debug, Clone)]
pub struct PackPath {
    pub compression_method: u32,
    pub compression_block_size: Option<NonZeroU32>,
    pub compression_level: Option<NonZeroU32>,
    pub filename: String,
    pub rename: Option<String>,
}

impl PackPath {
    pub fn new(filename: String) -> Self {
        Self {
            compression_method: COMPR_DEFAULT,
            compression_block_size: None,
            compression_level: None,
            filename,
            rename: None,
        }
    }
}

impl TryFrom<&str> for PackPath {
    type Error = crate::result::Error;

    fn try_from(path_spec: &str) -> std::result::Result<Self, Self::Error> {
        // :zlib,level=5,block_size=512,rename=egg/spam.txt:/foo/bar/baz.txt
        if let Some(suffix) = path_spec.strip_prefix(':') {
            if let Some(index) = suffix.find(':') {
                let (param_str, filename) = suffix.split_at(index + 1);
                let param_str = &param_str[..param_str.len() - 1];

                let mut compression_method = COMPR_DEFAULT;
                let mut compression_block_size = None;
                let mut compression_level = None;
                let mut rename = None;

                for param in param_str.split(',') {
                    if param.eq_ignore_ascii_case("zlib") {
                        compression_method = COMPR_ZLIB;
                    } else if param.eq_ignore_ascii_case("none") {
                        compression_method = COMPR_NONE;
                    } else if let Some(index) = param.find('=') {
                        let (key, value) = param.split_at(index + 1);
                        let key = &key[..key.len() - 1];

                        if key.eq_ignore_ascii_case("level") {
                            compression_level = Some(parse_compression_level(value)?);
                        } else if key.eq_ignore_ascii_case("block_size") {
                            if value.eq_ignore_ascii_case("default") {
                                compression_block_size = Some(DEFAULT_BLOCK_SIZE);
                            } else {
                                match parse_size(value) {
                                    Ok(block_size) if block_size > 0 && block_size <= u32::MAX as usize => {
                                        compression_block_size = NonZeroU32::new(block_size as u32);
                                    }
                                    _ => {
                                        return Err(Error::new(format!(
                                            "illegal path specification, illegal parameter value {:?} in: {:?}",
                                            param, path_spec)));
                                    }
                                }
                            }
                        } else if key.eq_ignore_ascii_case("rename") {
                            rename = Some(value.to_string());
                        } else {
                            return Err(Error::new(format!(
                                "illegal path specification, unhandeled parameter {:?} in: {:?}",
                                param, path_spec)));
                        }
                    } else {
                        return Err(Error::new(format!(
                            "illegal path specification, unhandeled parameter {:?} in: {:?}",
                            param, path_spec)));
                    }
                }

                return Ok(Self {
                    compression_block_size,
                    compression_level,
                    compression_method,
                    filename: filename.to_string(),
                    rename,
                });
            } else {
                return Err(Error::new(format!(
                    "illegal path specification, expected a second ':' in: {:?}",
                    path_spec)));
            }
        } else {
            return Ok(Self::new(path_spec.to_string()));
        }
    }
}

#[derive(Debug)]
pub struct PackOptions<'a> {
    pub variant: Variant,
    pub version: u32,
    pub mount_point: Option<&'a str>,
    pub compression_method: u32,
    pub compression_block_size: NonZeroU32,
    pub compression_min_size: NonZeroU64,
    pub compression_level: NonZeroU32,
    pub encoding: Encoding,
    pub verbose: bool,
    pub null_separated: bool,
    pub thread_count: NonZeroUsize,
}

impl Default for PackOptions<'_> {
    fn default() -> Self {
        Self {
            variant: Variant::default(),
            version: 3,
            mount_point: None,
            compression_method: COMPR_NONE,
            compression_block_size: DEFAULT_BLOCK_SIZE,
            compression_min_size: DEFAULT_MIN_COMPRESSION_SIZE,
            compression_level: DEFAULT_COMPRESSION_LEVEL,
            encoding: Encoding::default(),
            verbose: false,
            null_separated: false,
            thread_count: NonZeroUsize::new(num_cpus::get()).unwrap_or(NonZeroUsize::new(1).unwrap()),
        }
    }
}

pub fn pack(pak_path: impl AsRef<Path>, paths: &[PackPath], options: PackOptions) -> Result<Pak> {
    let write_record_inline = match options.variant {
        Variant::ConanExiles => {
            return Err(Error::new("Writing of Conan Exile paks is not supported.".to_string()).
                with_path(pak_path));
            // XXX: There a are 20 unknown bytes after the inline record information if compressed.
            //      That is 16 extra to the already 4 extra bytes in standard version >= 4.
            //      In the index record there are only 4 extra bytes that are always 0.
            //if options.version != 4 {
            //    return Err(Error::new(format!(
            //        "Only know how to handle Conan Exile paks of version 4, but version was {}.",
            //        options.version)).
            //        with_path(pak_path));
            //}
            //Record::write_conan_exiles_inline
        }
        Variant::Standard => match options.version {
            1 => Record::write_v1_inline,
            2 => Record::write_v2_inline,
            3 => Record::write_v3_inline,
            // XXX: There is an unknown 32bit field after the inline(!) record information if compressed.
            // 4 => Record::write_v3_inline, // maybe?
            // 5 => Record::write_v3_inline, // maybe?
            // 7 => Record::write_v3_inline, // maybe?
            _ => {
                return Err(Error::new(
                    format!("unsupported version: {}", options.version)).
                    with_path(pak_path));
            }
        }
    };

    match options.compression_method {
        self::COMPR_NONE | self::COMPR_ZLIB => {}
        _ => return Err(Error::new(
            format!("unsupported compression method: {} ({})",
                compression_method_name(options.compression_method), options.compression_method)).
            with_path(pak_path))
    }

    let pak_path = pak_path.as_ref();
    let mut out_file = match OpenOptions::new()
        .create(true)
        .write(true)
        .truncate(true)
        .open(pak_path) {
            Ok(file) => file,
            Err(error) => return Err(Error::io_with_path(error, pak_path))
        };

    let mut records = Vec::new();
    let mut buffer = Vec::with_capacity(BUFFER_SIZE);
    let mut writer = BufWriter::new(&mut out_file);

    let mut data_size = 0u64;

    let thread_result = thread::scope::<_, Result<()>>(|scope| {
        let mut filenames = HashMap::new();
        let (work_sender, work_receiver) = unbounded();
        let (result_sender, result_receiver) = unbounded();

        for _ in 0..options.thread_count.get() {
            let work_receiver = work_receiver.clone();
            let result_sender = result_sender.clone();

            scope.spawn(|_| {
                if let Err(error) = worker_proc(&options, work_receiver, result_sender) {
                    if !error.error_type().is_channel_disconnected() {
                        eprintln!("error in worker thread: {}", error);
                    }
                }
            });
        }

        drop(work_receiver);
        drop(result_sender);

        for path in paths {
            let compression_method = if path.compression_method == COMPR_DEFAULT {
                options.compression_method
            } else {
                path.compression_method
            };

            if options.version < 2 && compression_method != COMPR_NONE {
                return Err(Error::new("Compression is only supported startig with version 2".to_string())
                    .with_path(&path.filename));
            }

            let source_path: PathBuf;
            let filename = if let Some(filename) = &path.rename {
                source_path = (&path.filename).into();
                parse_pak_path(&filename).collect::<Vec<_>>()
            } else {
                #[cfg(target_os = "windows")]
                let filename = path.filename
                    .trim_end_matches(|ch| ch == '/' || ch == '\\')
                    .split(|ch| ch == '/' || ch == '\\')
                    .filter(|comp| !comp.is_empty())
                    .collect::<Vec<_>>();

                #[cfg(not(target_os = "windows"))]
                let filename = path.filename
                    .trim_end_matches('/')
                    .split('/')
                    .filter(|comp| !comp.is_empty())
                    .collect::<Vec<_>>();

                source_path = filename.iter().collect();
                filename
            };

            let component_count = source_path.components().count();

            let metadata = match source_path.metadata() {
                Ok(metadata) => metadata,
                Err(error) => return Err(Error::io_with_path(error, source_path))
            };

            let mut make_filename = |file_path: &Path| -> Result<String> {
                let mut pak_filename: Vec<String> = filename.iter().map(|comp| comp.to_string()).collect();

                pak_filename.extend(file_path
                    .components()
                    .skip(component_count)
                    .map(|comp| comp.as_os_str().to_string_lossy().into_owned()));

                let filename = make_pak_path(pak_filename.iter());

                if let Some(other_path) = filenames.insert(filename.clone(), file_path.to_owned()) {
                    return Err(Error::new(
                        format!("{}: filename not unique in archive, other path: {:?}", filename, other_path)
                    ).with_path(file_path));
                }

                Ok(filename)
            };

            if metadata.is_dir() {
                let iter = match walkdir(&source_path) {
                    Ok(iter) => iter,
                    Err(error) => return Err(Error::io_with_path(error, source_path))
                };
                for entry in iter {
                    let entry = match entry {
                        Ok(entry) => entry,
                        Err(error) => return Err(Error::io_with_path(error, source_path))
                    };
                    let file_path = entry.path();
                    let filename = make_filename(&file_path)?;
                    match work_sender.send(Work {
                        filename,
                        file_path,
                        path,
                        compression_method,
                    }) {
                        Ok(()) => {}
                        Err(error) =>
                            return Err(Error::new(error.to_string()).with_path(entry.path()))
                    }
                }
            } else {
                let file_path = source_path.clone();
                let filename = make_filename(&file_path)?;
                match work_sender.send(Work {
                    filename,
                    file_path,
                    path,
                    compression_method,
                }) {
                    Ok(()) => {}
                    Err(error) =>
                        return Err(Error::new(error.to_string()).with_path(source_path))
                }
            }
        }

        drop(work_sender);

        let seperator = if options.null_separated { '\0' } else { '\n' };

        while let Ok(result) = result_receiver.recv() {
            let (mut record, mut data) = result?;

            record.move_to(options.version, data_size);

            buffer.clear();
            write_record_inline(&record, &mut buffer)?;

            data.splice(0..buffer.len(), buffer.iter().cloned());

            writer.write_all(&data)?;
            data_size += data.len() as u64;

            if options.verbose {
                print!("{}{}", record.filename(), seperator);
            }

            records.push(record);
        }

        drop(result_receiver);

        Ok(())
    });

    match thread_result {
        Err(error) => {
            return Err(Error::new(format!("threading error: {:?}", error)).with_path(pak_path));
        }
        Ok(result) => result?
    }

    let index_offset = data_size;

    writer.seek(SeekFrom::Start(index_offset))?;

    let mut index_size = 0u64;

    let mount_pount = options.mount_point.unwrap_or("");

    let mut hasher = OpenSSLSha1::new();

    buffer.clear();

    write_path(&mut buffer, mount_pount, options.encoding)?;
    encode!(&mut buffer, records.len() as u32);
    writer.write_all(&buffer)?;
    hasher.update(&buffer);

    index_size += buffer.len() as u64;

    let write_record = match options.variant {
        Variant::ConanExiles => {
            if options.version != 4 {
                return Err(Error::new(format!(
                    "Only know how to handle Conan Exile paks of version 4, but version was {}.",
                    options.version)).
                    with_path(pak_path));
            }
            Record::write_conan_exiles
        }
        Variant::Standard => match options.version {
            1 => Record::write_v1,
            2 => Record::write_v2,
            3 => Record::write_v3,
            // XXX: There is an unknown 32bit field after the inline(!) record information if compressed.
            // 4 => Record::write_v3, // maybe?
            // 5 => Record::write_v3, // maybe?
            // 7 => Record::write_v3, // maybe?
            _ => {
                return Err(Error::new(
                    format!("unsupported version: {}", options.version)).
                    with_path(pak_path));
            }
        }
    };

    for record in &records {
        buffer.clear();
        write_path(&mut buffer, record.filename(), options.encoding)?;
        write_record(record, &mut buffer)?;

        writer.write_all(&buffer)?;
        hasher.update(&buffer);
        index_size += buffer.len() as u64;
    }

    let index_sha1: Sha1 = hasher.finish();

    encode!(&mut writer,
        PAK_MAGIC,
        options.version,
        index_offset,
        index_size,
        index_sha1,
    );
    writer.flush()?;

    let index = Index::new(
        options
            .mount_point
            .map(str::to_string),
        records,
    );

    Ok(Pak::new(
        options.variant,
        options.version,
        index_offset,
        index_size,
        index_sha1,
        index,
    ))
}

pub fn write_path(writer: &mut impl Write, path: &str, encoding: Encoding) -> Result<()> {
    match encoding {
        Encoding::UTF8 => {
            let bytes = path.as_bytes();
            if bytes.len() > (u32::MAX - 1) as usize {
                return Err(Error::new(format!("path is too long: {:?}", path)));
            }
            let size = (bytes.len() + 1) as u32;
            writer.write_all(&size.to_le_bytes())?;
            writer.write_all(bytes)?;
            writer.write_all(&[0])?;
        }
        Encoding::ASCII => {
            for ch in path.chars() {
                if ch > 127 as char {
                    return Err(Error::new(format!(
                        "Illegal char {:?} (0x{:x}) for ASCII codec in string: {:?}",
                        ch, ch as u32, path,
                    )));
                }
            }

            let bytes = path.as_bytes();
            if bytes.len() > (u32::MAX - 1) as usize {
                return Err(Error::new(format!("path is too long: {:?}", path)));
            }
            let size = (bytes.len() + 1) as u32;
            writer.write_all(&size.to_le_bytes())?;
            writer.write_all(bytes)?;
            writer.write_all(&[0])?;
        }
        Encoding::Latin1 => {
            for ch in path.chars() {
                if ch > 255 as char {
                    return Err(Error::new(format!(
                        "Illegal char {:?} (0x{:x}) for Latin1 codec in string: {:?}",
                        ch, ch as u32, path,
                    )));
                }
            }

            let mut bytes: Vec<_> = path.chars().map(|ch| ch as u8).collect();
            bytes.push(0);
            if bytes.len() > u32::MAX as usize {
                return Err(Error::new(format!("path is too long: {:?}", path)));
            }
            let size = bytes.len() as u32;
            writer.write_all(&size.to_le_bytes())?;
            writer.write_all(&bytes)?;
        }
    }
    Ok(())
}

#[derive(Debug)]
struct Work<'a> {
    filename: String,
    file_path: PathBuf,
    path: &'a PackPath,
    compression_method: u32,
}

#[inline]
fn write_uncompressed(data: &mut Vec<u8>, header_buffer: &mut Vec<u8>, base_header_size: u64, in_file: &mut File, uncompressed_size: u64, buffer: &mut Vec<u8>) -> Result<Sha1> {
    let mut hasher = OpenSSLSha1::new();

    data.write_all(&header_buffer[..base_header_size as usize])?;

    let mut remaining = uncompressed_size as usize;
    {
        // buffer might be bigger than BUFFER_SIZE if any previous
        // compression_block_size is bigger than BUFFER_SIZE
        if buffer.len() < BUFFER_SIZE {
            buffer.resize(BUFFER_SIZE, 0);
        }
        let buffer = &mut buffer[..BUFFER_SIZE];
        while remaining >= BUFFER_SIZE {
            in_file.read_exact(buffer)?;
            data.write_all(buffer)?;
            hasher.update(buffer);
            remaining -= BUFFER_SIZE;
        }
    }

    if remaining > 0 {
        let buffer = &mut buffer[..remaining];
        in_file.read_exact(buffer)?;
        data.write_all(buffer)?;
        hasher.update(buffer);
    }

    Ok(hasher.finish())
}

fn worker_proc(options: &PackOptions, work_channel: Receiver<Work>, result_channel: Sender<Result<(Record, Vec<u8>)>>) -> Result<()> {
    let mut buffer = vec![0u8; BUFFER_SIZE];
    let mut out_buffer = Vec::new();

    let compression_level = Compression::new(options.compression_level.get());
    let compression_min_size = options.compression_min_size.get();

    let base_header_size = match options.variant {
        Variant::ConanExiles => {
            if options.version != 4 {
                return Err(Error::new(format!(
                    "Only know how to handle Conan Exile paks of version 4, but version was {}.",
                    options.version)));
            }
            CONAN_EXILE_RECORD_HEADER_SIZE
        }
        Variant::Standard => match options.version {
            1 => V1_RECORD_HEADER_SIZE,
            2 => V2_RECORD_HEADER_SIZE,
            3 => V3_RECORD_HEADER_SIZE,
            4 => V3_RECORD_HEADER_SIZE, // maybe?
            5 => V3_RECORD_HEADER_SIZE, // maybe?
            7 => V3_RECORD_HEADER_SIZE, // maybe?
            _ => {
                panic!("unsupported version: {}", options.version)
            }
        }
    };
    let mut header_buffer = vec![0u8; base_header_size as usize];

    while let Ok(Work { filename, file_path, path, mut compression_method }) = work_channel.recv() {
        let mut data = Vec::new();
        let offset = 0;
        let compression_blocks;
        let mut compression_block_size = 0u32;
        let mut size;

        let mut in_file = match File::open(&file_path) {
            Ok(file) => file,
            Err(error) => {
                result_channel.send(Err(Error::io_with_path(error, file_path)))?;
                break;
            }
        };

        let metadata = match in_file.metadata() {
            Ok(metadata) => metadata,
            Err(error) => {
                result_channel.send(Err(Error::io_with_path(error, file_path)))?;
                break;
            }
        };

        let uncompressed_size = metadata.len();

        let timestamp = if options.version == 1 {
            let created = match metadata.created() {
                Ok(created) => created,
                Err(error) => {
                    result_channel.send(Err(Error::io_with_path(error, file_path)))?;
                    break;
                }
            };
            let timestamp = match created.duration_since(UNIX_EPOCH) {
                Ok(timestamp) => timestamp,
                Err(error) => {
                    result_channel.send(Err(Error::new(error.to_string()).with_path(file_path)))?;
                    break;
                }
            };
            Some(timestamp.as_secs())
        } else {
            None
        };

        let sha1: Sha1;

        if uncompressed_size < compression_min_size {
            compression_method = COMPR_NONE;
        }

        match compression_method {
            self::COMPR_NONE => {
                size = uncompressed_size;
                compression_blocks = None;
                sha1 = write_uncompressed(&mut data, &mut header_buffer, base_header_size, &mut in_file, uncompressed_size, &mut buffer)?;
            }
            self::COMPR_ZLIB => {
                let mut hasher = OpenSSLSha1::new();

                let compression_level = if let Some(compression_level) = path.compression_level {
                    Compression::new(compression_level.get())
                } else {
                    compression_level
                };
                if options.version <= 2 {
                    data.write_all(&header_buffer[..base_header_size as usize])?;

                    if buffer.len() < uncompressed_size as usize {
                        buffer.resize(uncompressed_size as usize, 0);
                    }

                    {
                        let buffer = &mut buffer[..uncompressed_size as usize];
                        in_file.read_exact(buffer)?;

                        out_buffer.clear();
                        let mut zlib = ZlibEncoder::new(&mut out_buffer, compression_level);
                        zlib.write_all(&buffer)?;
                        zlib.finish()?;
                    }

                    size = out_buffer.len() as u64;
                    compression_blocks = None;

                    if size >= uncompressed_size {
                        // compressed actually bigger (or same size),
                        // so revert what we did and use uncompressed instead

                        compression_method = COMPR_NONE;
                        data.clear();
                        in_file.seek(SeekFrom::Start(0))?;
                        size = uncompressed_size;
                        sha1 = write_uncompressed(&mut data, &mut header_buffer, base_header_size, &mut in_file, uncompressed_size, &mut buffer)?;
                    } else {
                        data.write_all(&out_buffer)?;
                        hasher.update(&out_buffer);
                        sha1 = hasher.finish();
                    }
                } else {
                    size = 0u64;
                    compression_block_size = path.compression_block_size
                        .unwrap_or(options.compression_block_size)
                        .get();

                    if compression_block_size as u64 > uncompressed_size {
                        compression_block_size = uncompressed_size as u32;
                    }

                    let mut header_size = base_header_size + 4;
                    if uncompressed_size > 0 {
                        header_size += (1 + ((uncompressed_size - 1) / compression_block_size as u64)) * COMPRESSION_BLOCK_HEADER_SIZE;
                    }
                    if header_buffer.len() < header_size as usize {
                        header_buffer.resize(header_size as usize, 0);
                    }
                    data.write_all(&header_buffer[..header_size as usize])?;

                    if buffer.len() < compression_block_size as usize {
                        buffer.resize(compression_block_size as usize, 0);
                    }

                    let mut blocks = Vec::<CompressionBlock>::new();
                    {
                        let buffer = &mut buffer[..compression_block_size as usize];
                        let mut remaining = uncompressed_size as usize;
                        let mut start_offset = header_size;

                        while remaining >= compression_block_size as usize {
                            in_file.read_exact(buffer)?;

                            out_buffer.clear();
                            let mut zlib = ZlibEncoder::new(&mut out_buffer, compression_level);
                            zlib.write_all(&buffer)?;
                            zlib.finish()?;
                            data.write_all(&out_buffer)?;
                            hasher.update(&out_buffer);

                            let compressed_block_size = out_buffer.len() as u64;
                            size += compressed_block_size;

                            remaining -= compression_block_size as usize;
                            let end_offset = start_offset + compressed_block_size;
                            blocks.push(CompressionBlock {
                                start_offset,
                                end_offset,
                            });
                            start_offset = end_offset;
                        }

                        if remaining > 0 {
                            let buffer = &mut buffer[..remaining];
                            in_file.read_exact(buffer)?;

                            out_buffer.clear();
                            let mut zlib = ZlibEncoder::new(&mut out_buffer, compression_level);
                            zlib.write_all(buffer)?;
                            zlib.finish()?;
                            data.write_all(&out_buffer)?;
                            hasher.update(&out_buffer);

                            let compressed_block_size = out_buffer.len() as u64;
                            size += compressed_block_size;

                            let end_offset = start_offset + compressed_block_size;
                            blocks.push(CompressionBlock {
                                start_offset,
                                end_offset,
                            });
                        }
                    }

                    if size + blocks.len() as u64 * COMPRESSION_BLOCK_HEADER_SIZE as u64 >= uncompressed_size {
                        // compressed actually bigger (or same size),
                        // so revert what we did and use uncompressed instead

                        compression_method = COMPR_NONE;
                        data.clear();
                        in_file.seek(SeekFrom::Start(0))?;
                        size = uncompressed_size;
                        compression_blocks = None;
                        sha1 = write_uncompressed(&mut data, &mut header_buffer, base_header_size, &mut in_file, uncompressed_size, &mut buffer)?;
                    } else {
                        compression_blocks = Some(blocks);
                        sha1 = hasher.finish();
                    }
                }
            }
            _ => {
                result_channel.send(Err(Error::new(
                    format!("{}: unsupported compression method: {} ({})",
                        path.filename, compression_method_name(compression_method), compression_method))))?;
                break;
            }
        }

        let record = Record::new(
            filename,
            offset,
            size,
            uncompressed_size,
            compression_method,
            timestamp,
            Some(sha1),
            compression_blocks,
            false,
            compression_block_size,
        );

        result_channel.send(Ok((record, data)))?;
    }

    Ok(())
}

```

`src/pak.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{convert::TryFrom, fmt::Display, num::{NonZeroU32, NonZeroU64}, path::Path, usize};
use std::fs::File;
use std::io::{Read, Seek, SeekFrom, BufReader};
use log::{debug};

use crate::{Error, Record, Result};
use crate::decode;
use crate::decode::Decode;
use crate::index::{Encoding, Index};

pub const BUFFER_SIZE: usize = 2 * 1024 * 1024;

pub const PAK_MAGIC: u32 = 0x5A6F12E1;
pub const PAK_RELATIVE_COMPRESSION_OFFSET_VERSION: u32 = 5;
pub const PAK_MAX_SUPPORTED_VERSION: u32 = 11;

pub const DEFAULT_BLOCK_SIZE: NonZeroU32 = unsafe { NonZeroU32::new_unchecked(64 * 1024) };
pub const DEFAULT_COMPRESSION_LEVEL: NonZeroU32 = unsafe { NonZeroU32::new_unchecked(6) };
pub const DEFAULT_MIN_COMPRESSION_SIZE: NonZeroU64 = unsafe { NonZeroU64::new_unchecked(100) };

pub const COMPR_NONE       : u32 = 0x00;
pub const COMPR_ZLIB       : u32 = 0x01;
pub const COMPR_BIAS_MEMORY: u32 = 0x10; // I'm not sure, maybe these are just flags for zlib?
pub const COMPR_BIAS_SPEED : u32 = 0x20;

pub const V1_RECORD_HEADER_SIZE: u64 = 56;
pub const V2_RECORD_HEADER_SIZE: u64 = 48;
pub const V3_RECORD_HEADER_SIZE: u64 = 53;
pub const CONAN_EXILE_RECORD_HEADER_SIZE: u64 = 57;
pub const COMPRESSION_BLOCK_HEADER_SIZE: u64 = 16;

pub const PAK_BOOL_SIZE: usize = 1;
// TODO: Version 8 can have a max of 4 (version 4.22) or 5 (version 4.23-4.24)
pub const V8_PAK_COMPRESSION_METHOD_COUNT: usize = 5;
pub const PAK_COMPRESSION_METHOD_COUNT: usize = 5;
pub const PAK_COMPRESSION_METHOD_SIZE: usize = 32;
pub const PAK_ENCRYPTION_GUID_SIZE: usize = std::mem::size_of::<u128>();

pub const COMPR_METHODS: [u32; 4] = [COMPR_NONE, COMPR_ZLIB, COMPR_BIAS_MEMORY, COMPR_BIAS_SPEED];

pub type Sha1 = [u8; 20];

pub fn compression_method_name(compression_method: u32) -> &'static str {
    match compression_method {
        COMPR_NONE => "-",
        COMPR_ZLIB => "zlib",
        COMPR_BIAS_MEMORY => "bias memory",
        COMPR_BIAS_SPEED  => "bias speed",
        _ => "unknown",
    }
}

#[derive(Debug)]
pub struct HexDisplay<'a> {
    data: &'a [u8]
}

impl<'a> HexDisplay<'a> {
    #[inline]
    pub fn new(data: &'a [u8]) -> Self {
        Self { data }
    }
}

impl<'a> Display for HexDisplay<'a> {
    #[inline]
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        for byte in self.data {
            write!(f, "{:02x}", byte)?;
        }
        Ok(())
    }
}

#[derive(Copy, Clone, Debug, PartialEq)]
pub enum Variant {
    Standard,
    ConanExiles,
}

impl Default for Variant {
    fn default() -> Self {
        Variant::Standard
    }
}

impl TryFrom<&str> for Variant {
    type Error = crate::result::Error;

    fn try_from(variant: &str) -> std::result::Result<Self, Error> {
        let trimmed_variant = variant.trim();
        if trimmed_variant.eq_ignore_ascii_case("standard") {
            Ok(Variant::Standard)
        } else if trimmed_variant.eq_ignore_ascii_case("conan_exiles") || trimmed_variant.eq_ignore_ascii_case("conanexiles") || trimmed_variant.eq_ignore_ascii_case("conan exiles") {
            Ok(Variant::ConanExiles)
        } else {
            Err(Error::new(format!("illegal variant: {:?}", variant)))
        }
    }
}

#[derive(Debug)]
pub struct Options {
    pub variant: Variant,
    pub ignore_magic: bool,
    pub encoding: Encoding,
    pub force_version: Option<u32>,
    pub encryption_key: Option<Vec<u8>>,
}

impl Default for Options {
    fn default() -> Self {
        Self {
            variant: Variant::default(),
            ignore_magic: false,
            encoding: Encoding::UTF8,
            force_version: None,
            encryption_key: None,
        }
    }
}

pub struct Footer {
    footer_offset: u64,
    encryption_uuid: u128,
    encrypted: bool,
    magic: u32,
    version: u32,
    index_offset: u64,
    index_size: u64,
    index_sha1: Sha1,
    frozen: bool,
    compression: Vec<u8>,
}

#[derive(Debug)]
pub struct Pak {
    variant: Variant,
    version: u32,
    index_offset: u64,
    index_size: u64,
    index_sha1: Sha1,
    index: Index,
}

impl Pak {
    #[inline]
    pub(crate) fn new(
        variant: Variant,
        version: u32,
        index_offset: u64,
        index_size: u64,
        index_sha1: Sha1,
        index: Index,
    ) -> Self {
        Self {
            variant,
            version,
            index_offset,
            index_size,
            index_sha1,
            index,
        }
    }

    pub fn from_path(path: impl AsRef<Path>, options: Options) -> Result<Pak> {
        match File::open(&path) {
            Ok(mut file) => match Self::from_file(&mut file, options) {
                Ok(package) => Ok(package),
                Err(error) => if error.path.is_none() {
                    Err(error.with_path(path))
                } else {
                    Err(error)
                },
            }
            Err(error) => Err(Error::io_with_path(error, path.as_ref().to_path_buf())),
        }
    }

    #[inline]
    pub fn from_file(file: &mut File, options: Options) -> Result<Pak> {
        Self::from_reader(&mut BufReader::new(file), options)
    }

    pub fn from_reader<R>(reader: &mut R, options: Options) -> Result<Pak>
    where R: Read, R: Seek {
        let footer: Footer;
        
        if let Some(force_version) = options.force_version {
            footer = Self::decode_footer(reader, force_version)?;
            if !options.ignore_magic && footer.magic != 0x5A6F12E1 {
                return Err(Error::new(format!(
                    "illegal file magic: 0x{:X}",
                    footer.magic
                )));
            }
        } else {
            if let Ok(version) = Self::get_version(reader) {
                debug!("Determined pak version {}", version);
                footer = Self::decode_footer(reader, version)?;
            } else if options.ignore_magic {
                footer = Self::decode_footer(reader, PAK_MAX_SUPPORTED_VERSION)?;
            } else {
                return Err(Error::new(format!("Failed to determine pak file version.")))
            }
        }

        let variant = options.variant;

        if footer.index_offset + footer.index_size > footer.footer_offset {
            return Err(Error::new(format!(
                "illegal index offset/size: index_offset ({}) + index_size ({}) > footer_offset ({})",
                footer.index_offset, footer.index_size, footer.footer_offset)));
        }

        reader.seek(SeekFrom::Start(footer.index_offset))?;

        let index = Index::read(
            reader,
            footer.index_size as usize,
            footer.version,
            variant,
            options.encoding,
            match footer.encrypted {
                true => options.encryption_key,
                false => None,
            },
        )?;

        let pos = reader.seek(SeekFrom::Current(0))?;
        if pos > footer.footer_offset {
            return Err(Error::new("index bleeds into footer".to_owned()));
        }

        Ok(Self {
            variant,
            version: footer.version,
            index_offset: footer.index_offset,
            index_size: footer.index_size,
            index_sha1: footer.index_sha1,
            index,
        })
    }

    #[inline]
    pub fn variant(&self) -> Variant {
        self.variant
    }

    #[inline]
    pub fn version(&self) -> u32 {
        self.version
    }

    #[inline]
    pub fn index_offset(&self) -> u64 {
        self.index_offset
    }

    #[inline]
    pub fn index_size(&self) -> u64 {
        self.index_size
    }

    #[inline]
    pub fn index_sha1(&self) -> &Sha1 {
        &self.index_sha1
    }

    #[inline]
    pub fn index(&self) -> &Index {
        &self.index
    }

    //#[inline]
    //pub fn filter_records<'a>(&'a self, filter: &'a mut Filter<'a>) -> std::iter::Filter<impl Iterator<Item=&'a Record>, impl FnMut(&&'a Record) -> bool> {
    //    filter.filter(self.records.iter())
    //}

    // FIXME: inline header has different size in some versions/variants!
    pub fn header_size(version: u32, variant: Variant, record: &Record) -> u64 {
        match variant {
            Variant::ConanExiles => {
                if version != 4 {
                    panic!("unsupported Conan Exile pak version: {}", version)
                }
                CONAN_EXILE_RECORD_HEADER_SIZE
            }
            Variant::Standard => match version {
                1 => V1_RECORD_HEADER_SIZE,
                2 => V2_RECORD_HEADER_SIZE,
                _ => {
                    let mut size: u64 = V3_RECORD_HEADER_SIZE;

                    if let Some(blocks) = &record.compression_blocks() {
                        size += blocks.len() as u64 * COMPRESSION_BLOCK_HEADER_SIZE;
                        if version >= 3 {
                            size += 4;
                        }
                    }
                    size
                }
                _ => {
                    panic!("unsupported version: {}", version)
                }
            },
        }
    }

    pub fn footer_size(version: u32) -> i64 {
        // Same in every version
        let magic = std::mem::size_of::<u32>();
        let version_size = std::mem::size_of::<u32>();
        let index_offset = std::mem::size_of::<u64>();
        let index_size = std::mem::size_of::<u64>();
        let index_sha1 = std::mem::size_of::<Sha1>();
        let mut size: usize = magic + version_size + index_offset + index_size + index_sha1;

        // Version >= 4 has encrypted index flag
        if version >= 4 {
            size += PAK_BOOL_SIZE;
        }

        // Version 7 has encryption key guid
        if version >= 7 {
            size += PAK_ENCRYPTION_GUID_SIZE;
        }

        // Version 8 has Compression method
        if version == 8 {
            size += V8_PAK_COMPRESSION_METHOD_COUNT * PAK_COMPRESSION_METHOD_SIZE;
        } else if version > 8 {
            size += PAK_COMPRESSION_METHOD_COUNT * PAK_COMPRESSION_METHOD_SIZE;
        }

        // Version 9 has frozen index flag and version 10 upwards does not
        if version == 9 {
            size += PAK_BOOL_SIZE;
        }

        return i64::try_from(size).unwrap();
    }

    pub fn get_version<R>(reader: &mut R) -> Result<u32>
    where
        R: Read,
        R: Seek,
    {
        // Check if version >= 10 footer is found
        if reader.seek(SeekFrom::End(-Self::footer_size(10) +
                (PAK_ENCRYPTION_GUID_SIZE + PAK_BOOL_SIZE) as i64)).is_ok() {
            decode!(reader, magic: u32, version: u32);
            if magic == PAK_MAGIC {
                return Ok(version);
            }
        }

        // Check if version 9 footer is found
        if reader.seek(SeekFrom::End(-Self::footer_size(9) +
                (PAK_ENCRYPTION_GUID_SIZE + PAK_BOOL_SIZE) as i64)).is_ok() {
            decode!(reader, magic: u32, version: u32);
            if magic == PAK_MAGIC {
                return Ok(version);
            }
        }

        // Check if version 8 footer is found
        if reader.seek(SeekFrom::End(-Self::footer_size(8) +
                (PAK_ENCRYPTION_GUID_SIZE + PAK_BOOL_SIZE) as i64)).is_ok() {
            decode!(reader, magic: u32, version: u32);
            if magic == PAK_MAGIC {
                return Ok(version);
            }
        }

        // Check if version <= 7 footer is found
        if reader.seek(SeekFrom::End(-Self::footer_size(7) + (PAK_BOOL_SIZE) as i64)).is_ok() {
            decode!(reader, magic: u32, version: u32);
            if magic == PAK_MAGIC {
                return Ok(version);
            }
        }

        // Check if version <= 3 footer is found
        if reader.seek(SeekFrom::End(-Self::footer_size(3) as i64)).is_ok() {
            decode!(reader, magic: u32, version: u32);
            if magic == PAK_MAGIC {
                return Ok(version);
            }
        }

        Err(Error::new(String::from("No valid version detected")))
    }

    pub fn decode_footer<R>(reader: &mut R, target_version: u32) -> Result<Footer>
    where
        R: Read,
        R: Seek,
    {
        let footer_offset = reader
            .seek(SeekFrom::End(-Self::footer_size(target_version)));
        
        if let Ok(offset) = footer_offset {
            
            let encryption_uuid: u128 = 0;
            let frozen: bool = false;
            
            match target_version {
                _ if target_version >= 10 => {
                    decode!(
                        reader,
                        encryption_uuid: u128,
                        encrypted: bool,
                        magic: u32,
                        version: u32,
                        index_offset: u64,
                        index_size: u64,
                        index_sha1: Sha1,
                        compression: [u8; PAK_COMPRESSION_METHOD_COUNT * PAK_COMPRESSION_METHOD_SIZE]
                    );
                    return Ok(Footer {
                        footer_offset: offset,
                        encryption_uuid,
                        encrypted,
                        magic,
                        version,
                        index_offset,
                        index_size,
                        index_sha1,
                        frozen,
                        compression: compression.to_vec(),
                    });
                }
                9 => {
                    decode!(
                        reader,
                        encryption_uuid: u128,
                        encrypted: bool,
                        magic: u32,
                        version: u32,
                        index_offset: u64,
                        index_size: u64,
                        index_sha1: Sha1,
                        frozen: bool,
                        compression: [u8; PAK_COMPRESSION_METHOD_COUNT * PAK_COMPRESSION_METHOD_SIZE]
                    );
                    return Ok(Footer {
                        footer_offset: offset,
                        encryption_uuid,
                        encrypted,
                        magic,
                        version,
                        index_offset,
                        index_size,
                        index_sha1,
                        frozen,
                        compression: compression.to_vec(),
                    });
                }
                8 => {
                    decode!(
                        reader,
                        encryption_uuid: u128,
                        encrypted: bool,
                        magic: u32,
                        version: u32,
                        index_offset: u64,
                        index_size: u64,
                        index_sha1: Sha1,
                        compression: [u8; V8_PAK_COMPRESSION_METHOD_COUNT * PAK_COMPRESSION_METHOD_SIZE]
                    );
                    return Ok(Footer {
                        footer_offset: offset,
                        encryption_uuid,
                        encrypted,
                        magic,
                        version,
                        index_offset,
                        index_size,
                        index_sha1,
                        frozen,
                        compression: compression.to_vec(),
                    });
                }
                7 => {
                    decode!(
                        reader,
                        encryption_uuid: u128,
                        encrypted: bool,
                        magic: u32,
                        version: u32,
                        index_offset: u64,
                        index_size: u64,
                        index_sha1: Sha1
                    );
                    return Ok(Footer {
                        footer_offset: offset,
                        encryption_uuid,
                        encrypted,
                        magic,
                        version,
                        index_offset,
                        index_size,
                        index_sha1,
                        frozen,
                        compression: vec![],
                    });
                }
                _ if target_version >= 4 => {
                    decode!(
                        reader,
                        encrypted: bool,
                        magic: u32,
                        version: u32,
                        index_offset: u64,
                        index_size: u64,
                        index_sha1: Sha1,
                    );
                    return Ok(Footer {
                        footer_offset: offset,
                        encryption_uuid,
                        encrypted,
                        magic,
                        version,
                        index_offset,
                        index_size,
                        index_sha1,
                        frozen,
                        compression: vec![],
                    });
                }
                _ => {
                    decode!(
                        reader,
                        magic: u32,
                        version: u32,
                        index_offset: u64,
                        index_size: u64,
                        index_sha1: Sha1,
                    );
                    return Ok(Footer {
                        footer_offset: offset,
                        encryption_uuid,
                        encrypted: false,
                        magic,
                        version,
                        index_offset,
                        index_size,
                        index_sha1,
                        frozen,
                        compression: vec![],
                    });
                }
            }
        } else if let Err(error) = footer_offset {
            return Err(Error::from(error));
        } else {
            return Err(Error::new(format!("Failed to read footer.")))
        }
    }
}

```

`src/record.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::io::{Read, Write};
use std::fmt::Write as FmtWrite;
use aes::BLOCK_SIZE;

use crate::{Error, Result, check::NULL_SHA1, pak::{COMPR_NONE, HexDisplay, Sha1}};
use crate::decode;
use crate::decode::Decode;
use crate::encode;
use crate::encode::Encode;
use crate::pak::V3_RECORD_HEADER_SIZE;
use crate::util::align;

macro_rules! cmp_record_field {
    ($buf:expr, $field:ident, $r1:expr, $r2:expr) => {
        if $r1.$field != $r2.$field {
            let _ = write!($buf, "\t{}: {:?} != {:?}\n", stringify!($field), $r1.$field, $r2.$field);
        }
    };
}

#[derive(Debug, PartialEq)]
pub struct Record {
    filename: String,
    offset: u64,
    size: u64,
    uncompressed_size: u64,
    compression_method: u32,
    timestamp: Option<u64>,
    sha1: Option<Sha1>,
    compression_blocks: Option<Vec<CompressionBlock>>,
    encrypted: bool,
    compression_block_size: u32,
}

#[derive(Debug, PartialEq, Eq, Hash, Clone)]
pub struct CompressionBlock {
    pub start_offset: u64,
    pub end_offset: u64,
}

impl Record {
    #[inline]
    pub(crate) fn new(
        filename: String,
        offset: u64,
        size: u64,
        uncompressed_size: u64,
        compression_method: u32,
        timestamp: Option<u64>,
        sha1: Option<Sha1>,
        compression_blocks: Option<Vec<CompressionBlock>>,
        encrypted: bool,
        compression_block_size: u32,
    ) -> Self {
        Self {
            filename,
            offset,
            size,
            uncompressed_size,
            compression_method,
            timestamp,
            sha1,
            compression_blocks,
            encrypted,
            compression_block_size,
        }
    }

    pub fn v1(filename: String, offset: u64, size: u64, uncompressed_size: u64, compression_method: u32, timestamp: u64, sha1: Option<Sha1>) -> Self {
        Self {
            filename,
            offset,
            size,
            uncompressed_size,
            compression_method,
            timestamp: Some(timestamp),
            sha1,
            compression_blocks: None,
            encrypted: false,
            compression_block_size: 0,
        }
    }

    pub fn v2(filename: String, offset: u64, size: u64, uncompressed_size: u64, compression_method: u32, sha1: Option<Sha1>) -> Self {
        Self {
            filename,
            offset,
            size,
            uncompressed_size,
            compression_method,
            timestamp: None,
            sha1,
            compression_blocks: None,
            encrypted: false,
            compression_block_size: 0,
        }
    }

    pub fn v3(filename: String, offset: u64, size: u64, uncompressed_size: u64, compression_method: u32, sha1: Option<Sha1>,
              compression_blocks: Option<Vec<CompressionBlock>>, encrypted: bool, compression_block_size: u32) -> Self {
        Self {
            filename,
            offset,
            size,
            uncompressed_size,
            compression_method,
            timestamp: None,
            sha1,
            compression_blocks,
            encrypted,
            compression_block_size,
        }
    }

    #[inline]
    pub fn filename(&self) -> &str {
        &self.filename
    }

    #[inline]
    pub fn offset(&self) -> u64 {
        self.offset
    }

    #[inline]
    pub fn size(&self) -> u64 {
        self.size
    }

    #[inline]
    pub fn uncompressed_size(&self) -> u64 {
        self.uncompressed_size
    }

    #[inline]
    pub fn compression_method(&self) -> u32 {
        self.compression_method
    }

    #[inline]
    pub fn timestamp(&self) -> Option<u64> {
        self.timestamp
    }

    #[inline]
    pub fn sha1(&self) -> &Option<Sha1> {
        &self.sha1
    }

    #[inline]
    pub fn compression_blocks(&self) -> &Option<Vec<CompressionBlock>> {
        &self.compression_blocks
    }

    #[inline]
    pub fn encrypted(&self) -> bool {
        self.encrypted
    }

    #[inline]
    pub fn compression_block_size(&self) -> u32 {
        self.compression_block_size
    }

    pub fn read_v1(reader: &mut impl Read, filename: String) -> Result<Record> {
        decode!(reader,
            offset: u64,
            size: u64,
            uncompressed_size: u64,
            compression_method: u32,
            timestamp: u64,
            sha1: Sha1,
        );

        Ok(Record::v1(filename, offset, size, uncompressed_size, compression_method, timestamp, Some(sha1)))
    }

    pub fn read_v2(reader: &mut impl Read, filename: String) -> Result<Record> {
        decode!(reader,
            offset: u64,
            size: u64,
            uncompressed_size: u64,
            compression_method: u32, // i32?
            sha1: Sha1,
        );

        Ok(Record::v2(filename, offset, size, uncompressed_size, compression_method, Some(sha1)))
    }

    pub fn read_v3(reader: &mut impl Read, filename: String) -> Result<Record> {
        decode!(reader,
            offset: u64,
            size: u64,
            uncompressed_size: u64,
            compression_method: u32,
            sha1: Sha1,
            if compression_method != COMPR_NONE {
                compression_blocks: CompressionBlock [u32],
            }
            encrypted: u8,
            compression_block_size: u32,
        );

        Ok(Record::v3(filename, offset, size, uncompressed_size, compression_method, Some(sha1), compression_blocks, encrypted != 0, compression_block_size))
    }

    pub fn decode_entry(reader: &mut impl Read, filename: String) -> Result<Record> {
        // Bitfield contains information about entry data:
        // 0-5  : Compression block size
        // 6-21 : Compression blocks count
        // 22   : Encrypted
        // 23-28: Compression method
        // 29   : Size 32-bit
        // 30   : Uncompressed size 32-bit
        // 31   : Offset 32-bit
        decode!(reader, bitfield: u32);
        let compression_method = (bitfield >> 23) & 0x3f;
        let offset: u64;
        let uncompressed_size: u64;
        let size: u64;
        let encrypted: bool = (bitfield & (1 << 22)) != 0;
        let compression_block_count: u32 = (bitfield >> 6) & 0xffff;
        let mut compression_block_size: u32 = (bitfield & 0x3f) << 11;
        let mut compression_blocks: Option<Vec<CompressionBlock>> = None;

        // Check if offset is 32 bit safe
        if (bitfield & (1 << 31)) != 0 {
            decode!(reader, x32_offset: u32);
            offset = x32_offset as u64;
        } else {
            decode!(reader, x64_offset: u64);
            offset = x64_offset;
        }

        if (bitfield & (1 << 30)) != 0 {
            decode!(reader, x32_uncompressed_size: u32);
            uncompressed_size = x32_uncompressed_size as u64;
        } else {
            decode!(reader, x64_uncompressed_size: u64);
            uncompressed_size = x64_uncompressed_size;
        }

        if compression_method != COMPR_NONE {
            if (bitfield & (1 << 29)) != 0 {
                decode!(reader, x32_size: u32);
                size = x32_size as u64;
            } else {
                decode!(reader, x64_size: u64);
                size = x64_size;
            }
        } else {
            size = uncompressed_size;
        }

        if compression_block_count > 0 {
            if uncompressed_size <= 0xffff {
                compression_block_size = uncompressed_size as u32;
            };

            if compression_block_count == 1 && !encrypted {
                let start = Record::get_serialized_size(compression_method, compression_block_count);
                compression_blocks = Some(vec![CompressionBlock {
                    start_offset: start,
                    end_offset: start + size
                }]);
            } else if compression_block_count > 0 {
                let mut blocks = vec![];
                let block_alignment = if encrypted {
                    BLOCK_SIZE as u64
                } else {
                    1
                };

                let mut start_offset = Record::get_serialized_size(compression_method, compression_block_count);
                for _ in 0..compression_block_count {
                    decode!(reader, block_size: u32);
                    let end_offset = start_offset + block_size as u64;

                    blocks.push(CompressionBlock {
                        start_offset,
                        end_offset
                    });
                    start_offset += align(block_size as u64, block_alignment)
                }

                compression_blocks = Some(blocks);
            }
        }

        Ok(Self::new(filename, offset, size, uncompressed_size, compression_method, None, None, compression_blocks, encrypted, compression_block_size))
    }

    pub fn read_conan_exiles(reader: &mut impl Read, filename: String) -> Result<Record> {
        decode!(reader,
            offset: u64,
            size: u64,
            uncompressed_size: u64,
            compression_method: u32,
            sha1: Sha1,
            if compression_method != COMPR_NONE {
                compression_blocks: CompressionBlock [u32],
            }
            encrypted: u8,
            compression_block_size: u32,
            unknown: u32,
        );

        if unknown != 0 {
            eprintln!("{}: WARNING: unknown field has other value than 0: {}", filename, unknown);
        }

        Ok(Record::v3(filename, offset, size, uncompressed_size, compression_method, Some(sha1), compression_blocks, encrypted != 0, compression_block_size))
    }

    fn get_serialized_size(compression_method: u32, compression_block_count: u32) -> u64 {
        let mut serialized_size = V3_RECORD_HEADER_SIZE;
        if compression_method != COMPR_NONE {
            // Block info * block count
            serialized_size += 16 * compression_block_count as u64 + 4;
        }
        serialized_size
    }

    pub fn write_v1(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            self.offset,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.timestamp.unwrap_or(0),
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
        );
        Ok(())
    }

    pub fn write_v1_inline(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            0u64,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.timestamp.unwrap_or(0),
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
        );
        Ok(())
    }

    pub fn write_v2(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            self.offset,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
        );
        Ok(())
    }

    pub fn write_v2_inline(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            0u64,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
        );
        Ok(())
    }

    pub fn write_v3(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            self.offset,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
            if let Some(blocks) = &self.compression_blocks {
                blocks [u32],
            }
            self.encrypted as u8,
            self.compression_block_size,
        );
        Ok(())
    }

    pub fn write_v3_inline(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            0u64,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
            if let Some(blocks) = &self.compression_blocks {
                blocks [u32],
            }
            self.encrypted as u8,
            self.compression_block_size,
        );
        Ok(())
    }

    pub fn write_conan_exiles(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            self.offset,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
            if let Some(blocks) = &self.compression_blocks {
                blocks [u32],
            }
            self.encrypted as u8,
            self.compression_block_size,
            0u32,
        );
        Ok(())
    }

    pub fn write_conan_exiles_inline(&self, writer: &mut impl Write) -> Result<()> {
        encode!(writer,
            0u64,
            self.size,
            self.uncompressed_size,
            self.compression_method,
            self.sha1.as_ref().unwrap_or(&NULL_SHA1),
            if let Some(blocks) = &self.compression_blocks {
                blocks [u32],
            }
            self.encrypted as u8,
            self.compression_block_size,
            // there are suppodes to be 20 more bytes of something that I don't know:
            NULL_SHA1,
        );
        Ok(())
    }

    pub fn same_metadata(&self, other: &Record) -> bool {
        // compare all metadata except for the filename
        // data records always have offset == 0 it seems, so skip that
        self.size                   == other.size               &&
        self.uncompressed_size      == other.uncompressed_size  &&
        self.compression_method     == other.compression_method &&
        self.timestamp              == other.timestamp          &&
        self.sha1                   == other.sha1               &&
        self.compression_blocks     == other.compression_blocks &&
        self.encrypted              == other.encrypted          &&
        self.compression_block_size == other.compression_block_size
    }

    pub fn metadata_diff(&self, other: &Record) -> String {
        let mut buf = String::new();

        cmp_record_field!(buf, size,                   self, other);
        cmp_record_field!(buf, uncompressed_size,      self, other);
        cmp_record_field!(buf, timestamp,              self, other);
        cmp_record_field!(buf, encrypted,              self, other);
        cmp_record_field!(buf, compression_block_size, self, other);

        if self.sha1 != other.sha1 {
            let _ = write!(buf, "\tsha1: {} != {}",
                HexDisplay::new(self.sha1.as_ref().unwrap_or(&NULL_SHA1)),
                HexDisplay::new(other.sha1.as_ref().unwrap_or(&NULL_SHA1)));
        }

        if self.compression_blocks != other.compression_blocks {
            let _ = write!(buf, "\tcompression_blocks:\n\t\t{:?}\n\t\t\t!=\n\t\t{:?}",
                self.compression_blocks,
                other.compression_blocks);
        }

        buf
    }

    pub(crate) fn move_to(&mut self, version: u32, new_offset: u64) {
        if version < 7 {
            if let Some(blocks) = &mut self.compression_blocks {
                for block in blocks {
                    block.start_offset = (block.start_offset - self.offset) + new_offset;
                    block.end_offset   = (block.end_offset   - self.offset) + new_offset
                }
            }
        }
        self.offset = new_offset;
    }
}

impl AsRef<Record> for Record {
    fn as_ref(&self) -> &Record {
        &self
    }
}

```

`src/reopen.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{fs::{File, OpenOptions}, path::PathBuf};

#[allow(unused)]
#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[cfg(target_family="windows")]
mod windows {
    use std::os::windows::io::RawHandle;

    pub(crate) type WCHAR = u16;
    pub(crate) type DWORD = u32;

    pub(crate) const FILE_NAME_NORMALIZED: DWORD = 0x0;
    pub(crate) const FILE_NAME_OPENED: DWORD = 0x8;
    pub(crate) const MAX_PATH: DWORD = 260;

    pub(crate) const ERROR_NOT_ENOUGH_MEMORY: i32 = 8;

    #[link(name = "user32")]
    extern "stdcall" {
        pub(crate) fn GetFinalPathNameByHandleW(hFile: RawHandle, lpszFilePath: *mut WCHAR, cchFilePath: DWORD, dwFlags: DWORD) -> DWORD;
    }
}

pub trait Reopen: Sized {
    fn reopen(&self) -> std::io::Result<Self>;
    fn path(&self) -> std::io::Result<PathBuf>;
}

pub trait ReopenOptions {
    type File;

    fn reopen(&self, file: &Self::File) -> std::io::Result<Self::File>;
}

impl Reopen for File {
    #[inline]
    fn reopen(&self) -> std::io::Result<Self> {
        let path = get_file_path(self)?;
        File::open(path)
    }

    #[inline]
    fn path(&self) -> std::io::Result<PathBuf> {
        get_file_path(self)
    }
}

impl ReopenOptions for OpenOptions {
    type File = std::fs::File;

    #[inline]
    fn reopen(&self, file: &Self::File) -> std::io::Result<Self::File> {
        let path = get_file_path(file)?;
        self.open(path)
    }
}

#[cfg(target_family="unix")]
pub fn get_file_path(file: &File) -> std::io::Result<PathBuf> {
    use std::os::unix::io::AsRawFd;

    let fd = file.as_raw_fd();

    #[cfg(target_os="linux")]
    let path = PathBuf::from(format!("/proc/self/fd/{}", fd));

    #[cfg(not(target_os="linux"))]
    let path = PathBuf::from(format!("/dev/fd/{}", fd));

    Ok(path)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[cfg(target_family="windows")]
pub fn get_file_path(file: &File) -> std::io::Result<PathBuf> {
    use std::os::windows::io::AsRawHandle;
    use std::os::windows::ffi::OsStringExt;
    use std::ffi::OsString;

    let hFile = file.as_raw_handle();
    let mut buf = vec![0u16; windows::MAX_PATH as usize];
    let size = unsafe { windows::GetFinalPathNameByHandleW(hFile, buf.as_mut_ptr(), buf.len() as windows::DWORD, windows::FILE_NAME_NORMALIZED) };

    if size == 0 {
        return Err(std::io::Error::last_os_error());
    } else if size as usize >= buf.len() {
        buf.resize(size as usize + 1, 0);
        let size = unsafe { windows::GetFinalPathNameByHandleW(hFile, buf.as_mut_ptr(), buf.len() as windows::DWORD, windows::FILE_NAME_NORMALIZED) };

        if size == 0 {
            return Err(std::io::Error::last_os_error());
        } else if size as usize >= buf.len() {
            return Err(std::io::Error::from_raw_os_error(windows::ERROR_NOT_ENOUGH_MEMORY));
        } else {
            buf.truncate(size as usize);
        }
    } else {
        buf.truncate(size as usize);
    }

    let path = OsString::from_wide(&buf[..]);
    let path = PathBuf::from(path);

    Ok(path)
}

```

`src/result.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{io::Write, path::{PathBuf, Path}};

use crossbeam_channel::SendError;

#[derive(Debug)]
pub enum ErrorType {
    IO(std::io::Error),
    Message(String),
    ChannelDisconnected,
}

impl ErrorType {
    #[inline]
    pub fn is_io(&self) -> bool {
        matches!(self, Self::IO(_))
    }

    #[inline]
    pub fn is_message(&self) -> bool {
        matches!(self, Self::Message(_))
    }

    #[inline]
    pub fn is_channel_disconnected(&self) -> bool {
        matches!(self, Self::ChannelDisconnected)
    }
}

#[derive(Debug)]
pub struct Error {
    pub(crate) path: Option<PathBuf>,
    pub(crate) error_type: ErrorType,
}

impl Error {
    #[inline]
    pub fn new(message: String) -> Self {
        Self {
            path: None,
            error_type: ErrorType::Message(message),
        }
    }

    #[inline]
    pub fn io(error: std::io::Error) -> Self {
        Self {
            path:       None,
            error_type: ErrorType::IO(error),
        }
    }

    #[inline]
    pub fn io_with_path(error: std::io::Error, path: impl AsRef<Path>) -> Self {
        Self {
            path:       Some(path.as_ref().to_path_buf()),
            error_type: ErrorType::IO(error),
        }
    }

    #[inline]
    pub fn channel_disconnected() -> Self {
        Self {
            path: None,
            error_type: ErrorType::ChannelDisconnected,
        }
    }

    #[inline]
    pub fn error_type(&self) -> &ErrorType {
        &self.error_type
    }

    #[inline]
    pub fn path(&self) -> &Option<PathBuf> {
        &self.path
    }

    #[inline]
    pub fn with_path(self, path: impl AsRef<Path>) -> Self {
        Self {
            path: Some(path.as_ref().to_path_buf()),
            error_type: self.error_type,
        }
    }

    #[inline]
    pub fn with_path_if_none(self, path: impl AsRef<Path>) -> Self {
        if self.path.is_some() {
            return self;
        }
        Self {
            path: Some(path.as_ref().to_path_buf()),
            error_type: self.error_type,
        }
    }

    pub fn write_to(&self, writer: &mut impl Write, null_separated: bool) -> std::io::Result<()> {
        if let Some(path) = &self.path {
            #[cfg(target_family="unix")]
            {
                use std::os::unix::ffi::OsStrExt;
                writer.write_all(path.as_os_str().as_bytes())?;
                writer.write_all(b": ")?;
            }

            #[cfg(not(target_family="unix"))]
            {
                write!(writer, "{}: ", path.to_string_lossy())?
            }
        }

        write!(writer, "{}{}", self.error_type, if null_separated { '\0' } else { '\n' })
    }
}

impl std::fmt::Display for ErrorType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ErrorType::IO(err)       => err.fmt(f),
            ErrorType::Message(msg) => msg.fmt(f),
            ErrorType::ChannelDisconnected => write!(f, "sending on a disconnected channel"),
        }
    }
}

impl std::fmt::Display for Error {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        if let Some(path) = &self.path {
            write!(f, "{:?}: {}", path, self.error_type)
        } else {
            self.error_type.fmt(f)
        }
    }
}

impl From<std::io::Error> for Error {
    fn from(error: std::io::Error) -> Self {
        Error {
            path: None,
            error_type: ErrorType::IO(error),
        }
    }
}

impl From<std::string::FromUtf8Error> for Error {
    fn from(error: std::string::FromUtf8Error) -> Self {
        Error::new(format!("UTF-8 conversion error: {}", error))
    }
}

impl From<std::str::Utf8Error> for Error {
    fn from(error: std::str::Utf8Error) -> Self {
        Error::new(format!("UTF-8 conversion error: {}", error))
    }
}

impl From<std::string::FromUtf16Error> for Error {
    fn from(error: std::string::FromUtf16Error) -> Self {
        Error::new(format!("UTF-16 conversion error: {}", error))
    }
}

impl From<clap::Error> for Error {
    fn from(error: clap::Error) -> Self {
        Error::new(error.message)
    }
}

impl From<std::array::TryFromSliceError> for Error {
    fn from(error: std::array::TryFromSliceError) -> Self {
        Error::new(error.to_string())
    }
}

impl From<std::num::ParseIntError> for Error {
    fn from(error: std::num::ParseIntError) -> Self {
        Error::new(error.to_string())
    }
}

impl From<std::time::SystemTimeError> for Error {
    fn from(error: std::time::SystemTimeError) -> Self {
        Error::new(error.to_string())
    }
}

impl From<flate2::DecompressError> for Error {
    fn from(error: flate2::DecompressError) -> Self {
        Error::new(error.to_string())
    }
}

impl<T: Sized> From<SendError<Result<T>>> for Error {
    fn from(_error: SendError<Result<T>>) -> Self {
        Error::channel_disconnected()
    }
}

pub type Result<T> = core::result::Result<T, Error>;

```

`src/unpack.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{fs::OpenOptions, io::{BufWriter, Read, Seek, SeekFrom, Write}, num::NonZeroUsize, path::{Path, PathBuf}};
use std::fs::File;

use crossbeam_channel::{Receiver, Sender, unbounded};
use crossbeam_utils::thread;
use flate2::bufread::ZlibDecoder;
use aes::BLOCK_SIZE;

use crate::util::align;
use crate::decrypt::decrypt;

use crate::{Error, Result, Pak, pak::{self, COMPR_NONE, PAK_RELATIVE_COMPRESSION_OFFSET_VERSION, Variant, compression_method_name}, util::parse_pak_path};
use crate::Record;
use crate::Filter;
use crate::reopen::Reopen;
use log::{debug};

#[derive(Debug)]
pub struct UnpackOptions<'a> {
    pub dirname_from_compression: bool,
    pub verbose: bool,
    pub null_separated: bool,
    pub paths: Option<&'a [&'a str]>,
    pub thread_count: NonZeroUsize,
    pub encryption_key: Option<Vec<u8>>,
}

impl Default for UnpackOptions<'_> {
    fn default() -> Self {
        Self {
            dirname_from_compression: false,
            verbose: false,
            null_separated: false,
            paths: None,
            thread_count: NonZeroUsize::new(num_cpus::get()).unwrap_or(NonZeroUsize::new(1).unwrap()),
            encryption_key: None,
        }
    }
}

#[inline]
fn unpack_iter<'a>(pak: &Pak, in_file: &mut File, outdir: &Path, options: &'a UnpackOptions<'a>, records_iter: impl Iterator<Item=&'a Record>) -> Result<()> {
    let version = pak.version();
    let variant = pak.variant();

    let dirnames = if options.dirname_from_compression {
        let mut zlib_outdir = outdir.to_path_buf();
        let mut none_outdir = outdir.to_path_buf();

        zlib_outdir.push("zlib");
        none_outdir.push("none");

        Some((zlib_outdir, none_outdir))
    } else {
        None
    };

    let pak_path = in_file.path()?;

    let thread_result = thread::scope::<_, Result<()>>(|scope| {
        let (work_sender, work_receiver) = unbounded();
        let (result_sender, result_receiver) = unbounded();

        for _ in 0..options.thread_count.get() {
            let work_receiver = work_receiver.clone();
            let result_sender = result_sender.clone();
            let mut in_file = File::open(&pak_path)?;

            scope.spawn(move |_| {
                let in_file = &mut in_file;
                if let Err(error) = worker_proc(in_file, version, variant, options.encryption_key.clone(), work_receiver, result_sender) {
                    if !error.error_type().is_channel_disconnected() {
                        eprintln!("error in worker thread: {}", error);
                    }
                }
            });
        }

        drop(work_receiver);
        drop(result_sender);

        if let Some((zlib_outdir, none_outdir)) = &dirnames {
            for record in records_iter {
                let method = record.compression_method();
                let outdir = if method == COMPR_NONE { &none_outdir } else { &zlib_outdir };

                match work_sender.send(Work { record, outdir }) {
                    Ok(()) => {}
                    Err(error) =>
                        return Err(Error::new(error.to_string()).with_path(record.filename()))
                }
            }
        } else {
            for record in records_iter {
                match work_sender.send(Work { record, outdir }) {
                    Ok(()) => {}
                    Err(error) =>
                        return Err(Error::new(error.to_string()).with_path(record.filename()))
                }
            }
        }

        drop(work_sender);

        #[cfg(target_family="unix")]
        let mut stdout = std::io::stdout();

        let linesep = if options.null_separated { '\0' } else { '\n' };

        while let Ok(result) = result_receiver.recv() {
            let path = result?;
            if options.verbose {
                #[cfg(target_family="unix")]
                {
                    use std::os::unix::ffi::OsStrExt;
                    let _ = stdout.write_all(path.as_os_str().as_bytes());
                    let _ = stdout.write_all(&[linesep as u8]);
                }

                #[cfg(not(target_family="unix"))]
                {
                    print!("{}{}", path.to_string_lossy(), linesep);
                }
            }
        }

        drop(result_receiver);

        Ok(())
    });

    match thread_result {
        Err(error) => {
            return Err(Error::new(format!("threading error: {:?}", error)));
        }
        Ok(result) => result
    }
}

pub fn unpack<'a>(pak: &Pak, in_file: &mut File, outdir: impl AsRef<Path>, options: UnpackOptions<'a>) -> Result<()> {
    let outdir = outdir.as_ref();

    if let Some(paths) = options.paths {
        let mut filter: Filter = paths.into();
        let records = pak.index().records().iter()
            .filter(|record| filter.visit(record.filename()));

        unpack_iter(pak, in_file, outdir, &options, records)?;
        filter.assert_all_visited()?;
    } else {
        unpack_iter(pak, in_file, outdir, &options, pak.index().records().iter())?;
    }
    Ok(())
}

pub fn unpack_record(record: &Record, version: u32, variant: Variant, in_file: &mut File, outdir: impl AsRef<Path>, encryption_key: Option<Vec<u8>>) -> Result<PathBuf> {
    let header_size = pak::Pak::header_size(version, variant, record);
    
    let mut path = outdir.as_ref().to_path_buf();
    for component in parse_pak_path(record.filename()) {
        path.push(component);
    }
    
    let mut out_file = match OpenOptions::new()
            .write(true)
            .create(true)
            .truncate(true)
            .open(&path) {
        Ok(file) => file,
        Err(error) => {
            if error.kind() == std::io::ErrorKind::NotFound {
                if let Some(parent) = path.parent() {
                    std::fs::create_dir_all(parent)?;
                    OpenOptions::new().write(true).create(true).open(&path)?
                } else {
                    return Err(Error::io_with_path(error, path));
                }
            } else {
                return Err(Error::io_with_path(error, path));
            }
        }
    };

    let start_offset = record.offset() + header_size;
    in_file.seek(SeekFrom::Start(start_offset))?;

    // Encrypted files need to be read in 16 byte blocks
    let buffer_length = if record.encrypted() {
        align(record.size(), BLOCK_SIZE as u64)
    } else {
        record.size()
    } as usize;

    let mut in_buffer = vec![0u8; buffer_length];
    in_file.read_exact(&mut in_buffer)?;
    
    decrypt_entry(&mut in_buffer, record, encryption_key, record.size() as usize)?;
    debug!("unpacking {:?}", record);

    match record.compression_method() {
        pak::COMPR_NONE => {
            out_file.write_all(&in_buffer)?;
            out_file.flush()?;
        }
        pak::COMPR_ZLIB => {
            if let Some(blocks) = record.compression_blocks() {
                let mut out_file = BufWriter::new(out_file);

                let mut out_buffer = Vec::with_capacity(record.compression_block_size() as usize);

                for block in blocks {
                    let mut block_start = (block.start_offset - header_size) as usize;
                    let mut block_end = (block.end_offset - header_size) as usize;

                    if version < PAK_RELATIVE_COMPRESSION_OFFSET_VERSION {
                        block_start -= (start_offset - header_size) as usize;
                        block_end -= (start_offset - header_size) as usize;
                    }

                    let mut zlib = ZlibDecoder::new(&in_buffer[block_start..block_end]);
                    out_buffer.clear();
                    zlib.read_to_end(&mut out_buffer)?;
                    out_file.write_all(&out_buffer)?;
                }
                out_file.flush()?;
            } else {
                // version 2 has compression support, but not compression blocks
                let mut out_buffer = Vec::new();

                let mut zlib = ZlibDecoder::new(&in_buffer[..]);
                zlib.read_to_end(&mut out_buffer)?;
                out_file.write_all(&out_buffer)?;
                out_file.flush()?;
            }
        }
        _ => {
            return Err(Error::new(format!(
                    "unsupported compression method: {}",
                    compression_method_name(record.compression_method())))
                .with_path(record.filename()));
        }
    }

    Ok(path)
}

#[derive(Debug)]
struct Work<'a> {
    record: &'a Record,
    outdir: &'a Path,
}

fn worker_proc(in_file: &mut File, version: u32, variant: Variant, encryption_key: Option<Vec<u8>>, work_channel: Receiver<Work>, result_channel: Sender<Result<PathBuf>>) -> Result<()> {
    while let Ok(Work { record, outdir }) = work_channel.recv() {
        let result = unpack_record(record, version, variant, in_file, outdir, encryption_key.clone())
            .map_err(|error| error
                .with_path_if_none(record.filename()));

        result_channel.send(result)?;
    }

    Ok(())
}

fn decrypt_entry(buffer: &mut Vec<u8>, record: &Record, encryption_key: Option<Vec<u8>>, size: usize) -> Result<()> {
    if record.encrypted() {
        if let Some(key) = encryption_key {
            decrypt(buffer, &key);
            // Trim padded bytes from undersized encryption blocks
            buffer.truncate(size);
        } else {
            return Err(Error::new(
                "File is encrypted, but no encryption key was provided".to_string(),
            ).with_path(record.filename()));
        }
    }
    Ok(())
}
```

`src/util.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::io::Read;
use std::str::FromStr;
use core::num::NonZeroU32;
use openssl::sha::Sha1 as OpenSSLSha1;

use crate::{Result, Error};

pub fn format_size(size: u64) -> String {
    if size >= 1024 * 1024 * 1024 * 1024 * 1024 * 1024 {
        format!("{:.1} E", (size / (1024 * 1024 * 1024 * 1024 * 1024)) as f64 / 1024.0)
    } else if size >= 1024 * 1024 * 1024 * 1024 * 1024 {
        format!("{:.1} P", (size / (1024 * 1024 * 1024 * 1024)) as f64 / 1024.0)
    } else if size >= 1024 * 1024 * 1024 * 1024 {
        format!("{:.1} T", (size / (1024 * 1024 * 1024)) as f64 / 1024.0)
    } else if size >= 1024 * 1024 * 1024 {
        format!("{:.1} G", (size / (1024 * 1024)) as f64 / 1024.0)
    } else if size >= 1024 * 1024 {
        format!("{:.1} M", (size / 1024) as f64 / 1024.0)
    } else if size >= 1024 {
        format!("{:.1} K", size as f64 / 1024.0)
    } else {
        format!("{} B", size)
    }
}

pub enum Align {
    Left,
    Right
}

impl Align {
    #[allow(unused)]
    pub fn is_left(&self) -> bool {
        match self {
            Align::Left  => true,
            Align::Right => false,
        }
    }

    pub fn is_right(&self) -> bool {
        match self {
            Align::Left  => false,
            Align::Right => true,
        }
    }
}

pub fn print_row(row: &[impl AsRef<str>], lens: &[usize], align: &[Align]) {
    let cell_count = row.len();
    if cell_count > 0 {
        let mut first = true;
        let last_index = cell_count - 1;
        for (index, ((cell, len), align)) in row.iter().zip(lens.iter()).zip(align.iter()).enumerate() {
            if first {
                first = false;
            } else {
                print!("  "); // cell spacing
            }

            if align.is_right() {
                print!("{:>1$}", cell.as_ref(), *len);
            } else if index == last_index {
                print!("{}", cell.as_ref());
            } else {
                print!("{:<1$}", cell.as_ref(), *len);
            }
        }
    }

    println!();
}

pub fn print_table(header: &[impl AsRef<str>], align: &[Align], body: &[Vec<impl AsRef<str>>]) {
    // TODO: maybe count graphemes? needs extra lib. haven't seen non-ASCII filenames anyway
    let mut lens: Vec<usize> = vec![0; align.len()];

    for (cell, max_len) in header.iter().zip(lens.iter_mut()) {
        let len = cell.as_ref().chars().count();
        if len > *max_len {
            *max_len = len;
        }
    }

    for row in body {
        for (cell, max_len) in row.iter().zip(lens.iter_mut()) {
            let len = cell.as_ref().chars().count();
            if len > *max_len {
                *max_len = len;
            }
        }
    }

    print_row(header, &lens, align);
    let line_len = if lens.is_empty() { 0 } else {
        lens.iter().sum::<usize>() + 2 * (lens.len() - 1)
    };
    for _ in 0..line_len {
        print!("-");
    }
    println!();

    for row in body {
        print_row(row, &lens, align);
    }
}

pub fn print_headless_table(body: &[Vec<impl AsRef<str>>], align: &[Align]) {
    let mut lens = Vec::new();

    for row in body {
        while lens.len() < row.len() {
            lens.push(0);
        }
        for (cell, max_len) in row.iter().zip(lens.iter_mut()) {
            let len = cell.as_ref().chars().count();
            if len > *max_len {
                *max_len = len;
            }
        }
    }

    for row in body {
        print_row(row, &lens, align);
    }
}

pub fn parse_size(value: &str) -> std::result::Result<usize, <usize as FromStr>::Err> {
    let mut value = value.trim();

    if value.ends_with('B') {
        value = &value[..value.len() - 1];
    }

    if value.ends_with('K') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024)
    } else if value.ends_with('M') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024)
    } else if value.ends_with('G') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024 * 1024)
    } else if value.ends_with('T') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024 * 1024 * 1024)
    } else if value.ends_with('P') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024 * 1024 * 1024 * 1024)
    } else if value.ends_with('E') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024 * 1024 * 1024 * 1024 * 1024)
    } else if value.ends_with('Z') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024)
    } else if value.ends_with('Y') {
        value = &value[..value.len() - 1].trim_end();
        Ok(value.parse::<usize>()? * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024)
    } else {
        value.parse()
    }
}

pub fn parse_pak_path(path: &str) -> impl std::iter::Iterator<Item=&str> {
    path.trim_matches('/')
        .split('/')
        .filter(|comp| !comp.is_empty())
}

pub fn make_pak_path(mut components: impl std::iter::Iterator<Item=impl AsRef<str>>) -> String {
    let mut path = String::new();
    if let Some(first) = components.next() {
        path.push_str(first.as_ref());
        for component in components {
            path.push('/');
            path.push_str(component.as_ref());
        }
    } else {
        path.push('/');
    }
    path
}

// Align to power of 2 alignment
pub fn align(val: u64, alignment: u64) -> u64 {
    assert_eq!(alignment & (alignment - 1), 0, "Alignment must be a power of 2");
    // Add alignment        Zero out alignment bits
    (val + alignment - 1) & !(alignment - 1)
}

pub const COMPR_LEVEL_FAST:    NonZeroU32 = unsafe { NonZeroU32::new_unchecked(1) };
pub const COMPR_LEVEL_DEFAULT: NonZeroU32 = unsafe { NonZeroU32::new_unchecked(6) };
pub const COMPR_LEVEL_BEST:    NonZeroU32 = unsafe { NonZeroU32::new_unchecked(9) };

pub fn parse_compression_level(value: &str) -> Result<NonZeroU32> {
    if value.eq_ignore_ascii_case("best") {
        Ok(COMPR_LEVEL_BEST)
    } else if value.eq_ignore_ascii_case("fast") {
        Ok(COMPR_LEVEL_FAST)
    } else if value.eq_ignore_ascii_case("default") {
        Ok(COMPR_LEVEL_DEFAULT)
    } else {
        match value.parse() {
            Ok(level) if level > 0 && level < 10 => {
                Ok(NonZeroU32::new(level).unwrap())
            }
            _ => {
                return Err(Error::new(format!(
                    "illegal compression level: {:?}",
                    value)));
            }
        }
    }
}

pub fn sha1_digest<R: Read>(mut reader: R) -> Result<[u8; 20]> {
    let mut hasher = OpenSSLSha1::new();
    let mut buffer = [0; 1024];

    loop {
        let count = reader.read(&mut buffer)?;
        if count == 0 {
            break;
        }
        hasher.update(&buffer[..count]);
    }

    Ok(hasher.finish())
}

```

`src/walkdir.rs`:

```rs
// This file is part of rust-u4pak.
//
// This Source Code Form is subject to the terms of the Mozilla Public
// License, v. 2.0. If a copy of the MPL was not distributed with this
// file, You can obtain one at https://mozilla.org/MPL/2.0/.

use std::{fs::DirEntry, path::Path};

#[derive(Debug)]
pub struct WalkDir {
    stack: Vec<std::fs::ReadDir>,
    follow_links: bool,
    only_files: bool,
}

impl WalkDir {
    #[inline]
    pub fn new(path: impl AsRef<Path>, follow_links: bool, only_files: bool) -> std::io::Result<Self> {
        Ok(Self {
            stack: vec![std::fs::read_dir(path)?],
            follow_links,
            only_files,
        })
    }

    #[inline]
    pub fn follow_links(&self) -> bool {
        self.follow_links
    }

    #[inline]
    pub fn only_files(&self) -> bool {
        self.only_files
    }
}

impl Iterator for WalkDir {
    type Item = std::io::Result<DirEntry>;

    fn next(&mut self) -> Option<std::io::Result<DirEntry>> {
        while let Some(iter) = self.stack.last_mut() {
            if let Some(entry) = iter.next() {
                match entry {
                    Ok(entry) => {
                        match entry.metadata() {
                            Ok(metadata) => {
                                if (!self.follow_links && metadata.file_type().is_symlink()) || !metadata.is_dir() {
                                    return Some(Ok(entry));
                                } else {
                                    // is dir
                                    match std::fs::read_dir(entry.path()) {
                                        Ok(iter) => {
                                            self.stack.push(iter);
                                            if !self.only_files {
                                                return Some(Ok(entry));
                                            }
                                        }
                                        Err(error) => {
                                            return Some(Err(error));
                                        }
                                    }
                                }
                            }
                            Err(error) => {
                                return Some(Err(error));
                            }
                        }
                    }
                    Err(error) => {
                        return Some(Err(error));
                    }
                }
            } else {
                self.stack.pop();
            }
        }
        None
    }
}

#[inline]
pub fn walkdir(path: impl AsRef<Path>) -> std::io::Result<WalkDir> {
    WalkDir::new(path, true, true)
}

```

`tests/unpack_v11_it.rs`:

```rs
mod util;

use util::remove_dir_all_if_exists;
use u4pak::Result;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v11() -> Result<()> {
    let out_dir = "./v11-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_v11.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_encrypted() -> Result<()> {
    let out_dir = "./v11_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_encrypted_v11.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_encrypted_encindex() -> Result<()> {
    let out_dir = "./v11_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_encrypted_encindex_v11.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_encindex() -> Result<()> {
    let out_dir = "./v11_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_encindex_v11.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_compressed() -> Result<()> {
    let out_dir = "./v11_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_compressed_v11.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_compressed_encrypted() -> Result<()> {
    let out_dir = "./v11_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_compressed_encrypted_v11.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_compressed_encrypted_encindex() -> Result<()> {
    let out_dir = "./v11_compressed_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_compressed_encrypted_encindex_v11.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v11_compressed_encindex() -> Result<()> {
    let out_dir = "./v11_compressed_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v11/test_compressed_encindex_v11.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v2_it.rs`:

```rs
mod util;

use u4pak::Result;
use util::remove_dir_all_if_exists;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v3() -> Result<()> {
    let out_dir = "./v3-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_v3.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v3_encrypted() -> Result<()> {
    let out_dir = "./v3_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_encrypted_v3.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v3_compressed() -> Result<()> {
    let out_dir = "./v3_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_compressed_v3.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v3_compressed_encrypted() -> Result<()> {
    let out_dir = "./v3_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_compressed_encrypted_v3.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v3_it.rs`:

```rs
mod util;

use u4pak::Result;
use util::remove_dir_all_if_exists;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v3() -> Result<()> {
    let out_dir = "./v3-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_v3.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v3_encrypted() -> Result<()> {
    let out_dir = "./v3_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_encrypted_v3.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v3_compressed() -> Result<()> {
    let out_dir = "./v3_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_compressed_v3.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v3_compressed_encrypted() -> Result<()> {
    let out_dir = "./v3_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v3/test_compressed_encrypted_v3.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v4_it.rs`:

```rs
mod util;

use u4pak::Result;
use util::remove_dir_all_if_exists;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v4() -> Result<()> {
    let out_dir = "./v4-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_v4.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_encrypted() -> Result<()> {
    let out_dir = "./v4_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_encrypted_v4.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_encrypted_encindex() -> Result<()> {
    let out_dir = "./v4_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_encrypted_encindex_v4.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_encindex() -> Result<()> {
    let out_dir = "./v4_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_encindex_v4.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_compressed() -> Result<()> {
    let out_dir = "./v4_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_compressed_v4.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_compressed_encrypted() -> Result<()> {
    let out_dir = "./v4_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_compressed_encrypted_v4.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_compressed_encrypted_encindex() -> Result<()> {
    let out_dir = "./v4_compressed_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_compressed_encrypted_encindex_v4.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v4_compressed_encindex() -> Result<()> {
    let out_dir = "./v4_compressed_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v4/test_compressed_encindex_v4.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v5_it.rs`:

```rs
mod util;

use u4pak::Result;
use util::remove_dir_all_if_exists;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v5() -> Result<()> {
    let out_dir = "./v5-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_v5.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_encrypted() -> Result<()> {
    let out_dir = "./v5_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_encrypted_v5.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_encrypted_encindex() -> Result<()> {
    let out_dir = "./v5_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_encrypted_encindex_v5.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_encindex() -> Result<()> {
    let out_dir = "./v5_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_encindex_v5.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_compressed() -> Result<()> {
    let out_dir = "./v5_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_compressed_v5.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_compressed_encrypted() -> Result<()> {
    let out_dir = "./v5_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_compressed_encrypted_v5.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_compressed_encrypted_encindex() -> Result<()> {
    let out_dir = "./v5_compressed_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_compressed_encrypted_encindex_v5.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v5_compressed_encindex() -> Result<()> {
    let out_dir = "./v5_compressed_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v5/test_compressed_encindex_v5.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v7_it.rs`:

```rs
mod util;

use util::remove_dir_all_if_exists;
use u4pak::Result;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v7() -> Result<()> {
    let out_dir = "./v7-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_v7.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_encrypted() -> Result<()> {
    let out_dir = "./v7_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_encrypted_v7.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_encrypted_encindex() -> Result<()> {
    let out_dir = "./v7_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_encrypted_encindex_v7.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_encindex() -> Result<()> {
    let out_dir = "./v7_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_encindex_v7.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_compressed() -> Result<()> {
    let out_dir = "./v7_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_compressed_v7.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_compressed_encrypted() -> Result<()> {
    let out_dir = "./v7_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_compressed_encrypted_v7.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_compressed_encrypted_encindex() -> Result<()> {
    let out_dir = "./v7_compressed_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_compressed_encrypted_encindex_v7.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v7_compressed_encindex() -> Result<()> {
    let out_dir = "./v7_compressed_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v7/test_compressed_encindex_v7.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v8_it.rs`:

```rs
mod util;

use util::remove_dir_all_if_exists;
use u4pak::Result;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v8() -> Result<()> {
    let out_dir = "./v8-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_v8.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_encrypted() -> Result<()> {
    let out_dir = "./v8_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_encrypted_v8.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_encrypted_encindex() -> Result<()> {
    let out_dir = "./v8_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_encrypted_encindex_v8.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_encindex() -> Result<()> {
    let out_dir = "./v8_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_encindex_v8.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_compressed() -> Result<()> {
    let out_dir = "./v8_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_compressed_v8.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_compressed_encrypted() -> Result<()> {
    let out_dir = "./v8_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_compressed_encrypted_v8.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_compressed_encrypted_encindex() -> Result<()> {
    let out_dir = "./v8_compressed_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_compressed_encrypted_encindex_v8.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v8_compressed_encindex() -> Result<()> {
    let out_dir = "./v8_compressed_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v8/test_compressed_encindex_v8.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/unpack_v9_it.rs`:

```rs
mod util;

use util::remove_dir_all_if_exists;
use u4pak::Result;

const ENCRYPTION_KEY: &str = "aWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWk=";

#[test]
fn test_v9() -> Result<()> {
    let out_dir = "./v9-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_v9.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_encrypted() -> Result<()> {
    let out_dir = "./v9_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_encrypted_v9.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_encrypted_encindex() -> Result<()> {
    let out_dir = "./v9_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_encrypted_encindex_v9.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_encindex() -> Result<()> {
    let out_dir = "./v9_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_encindex_v9.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_compressed() -> Result<()> {
    let out_dir = "./v9_compressed-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_compressed_v9.pak", out_dir, None)?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_compressed_encrypted() -> Result<()> {
    let out_dir = "./v9_compressed_encrypted-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_compressed_encrypted_v9.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_compressed_encrypted_encindex() -> Result<()> {
    let out_dir = "./v9_compressed_encrypted_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_compressed_encrypted_encindex_v9.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

#[test]
fn test_v9_compressed_encindex() -> Result<()> {
    let out_dir = "./v9_compressed_encindex-it";
    remove_dir_all_if_exists(out_dir)?;

    util::unpack("./pak-examples/pak/v9/test_compressed_encindex_v9.pak", out_dir, Some(ENCRYPTION_KEY.to_string()))?;
    util::validate("./pak-examples/original-files", out_dir)?;

    remove_dir_all_if_exists(out_dir)?;
    Ok(())
}

```

`tests/util/mod.rs`:

```rs
use std::fs::File;
use std::io::BufReader;
use std::num::NonZeroUsize;
use std::path::Path;

use u4pak::index::Encoding;
use u4pak::pak::Options;
use u4pak::unpack::UnpackOptions;
use u4pak::util::{sha1_digest};
use u4pak::walkdir::{walkdir};
use u4pak::{Error, Pak, Result, Variant};

pub fn remove_dir_all_if_exists(path: impl AsRef<std::path::Path>) -> std::io::Result<()> {
    if let Err(error) = std::fs::remove_dir_all(path) {
        if let std::io::ErrorKind::NotFound = error.kind() {
            return Ok(());
        }
        return Err(error);
    }

    Ok(())
}

pub fn unpack(path: &str, outdir: &str, encryption: Option<String>) -> Result<()> {
    let encryption_key = if let Some(key) = encryption {
        Some(
            base64::decode(
                key.parse::<String>()
                    .expect("Failed to read encryption key."),
            )
            .expect("Failed to parse encryption key."),
        )
    } else {
        None
    };

    let mut file = match File::open(path) {
        Ok(file) => file,
        Err(error) => return Err(Error::io_with_path(error, path)),
    };
    let mut reader = BufReader::new(&mut file);

    let pak = Pak::from_reader(
        &mut reader,
        Options {
            variant: Variant::default(),
            ignore_magic: false,
            encoding: Encoding::default(),
            force_version: None,
            encryption_key: encryption_key.clone(),
        },
    )?;

    drop(reader);

    u4pak::unpack::unpack(
        &pak,
        &mut file,
        outdir,
        UnpackOptions {
            dirname_from_compression: false,
            verbose: false,
            null_separated: false,
            paths: None,
            thread_count: NonZeroUsize::new(num_cpus::get())
                .unwrap_or(NonZeroUsize::new(1).unwrap()),
            encryption_key,
        },
    )
}

pub fn validate(source_dir: &str, out_dir: &str) -> Result<()> {
    let out_path = Path::new(out_dir);

    let iter = match walkdir(source_dir) {
        Ok(iter) => iter,
        Err(err) => return Err(Error::io_with_path(err, source_dir)),
    };

    for entry in iter {
        let entry = match entry {
            Ok(entry) => entry,
            Err(error) => return Err(Error::io_with_path(error, source_dir)),
        };
        let file_path = entry.path();
        let file = match file_path.strip_prefix(source_dir) {
            Ok(file) => file,
            Err(err) => return Err(Error::new(format!("Failed to strip prefix from {:?}: {:?}", file_path, err).to_string()))
        };

        let out_path_buff = out_path.join(file);
        let out_path = out_path_buff.as_path();
        
        if out_path.exists() {
            let source_digest = sha1_digest(File::open(&file_path)?)?;
            let out_digest = sha1_digest(File::open(out_path)?)?;
            if source_digest != out_digest {
                return Err(Error::new(format!("Source digest {:?} does not match out digest {:?} for file {:?}", source_digest, out_digest, file).to_string()));
            }
        } else {
            return Err(Error::new(format!("File {:?} does not exist in output", file).to_string()));
        }
    }

    Ok(())
}

```