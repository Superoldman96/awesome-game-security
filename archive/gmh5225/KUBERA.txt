Project Path: arc_gmh5225_KUBERA_9p_085ju

Source Tree:

```txt
arc_gmh5225_KUBERA_9p_085ju
├── CONTRIBUTING.md
├── LICENSE
├── README.md
├── dll_minimal
│   ├── dll_minimal.cpp
│   ├── dll_minimal.vcxproj
│   ├── dll_minimal.vcxproj.filters
│   └── sig.hpp
├── emulator
│   ├── emulator.vcxproj
│   ├── emulator.vcxproj.filters
│   └── src
│       ├── change.cpp
│       ├── emulator.cpp
│       ├── exception.cpp
│       ├── pch.cpp
│       ├── pch.hpp
│       ├── sig_scanner.hpp
│       └── utilities.cpp
├── exception_tests
│   ├── exception_tests.cpp
│   ├── exception_tests.vcxproj
│   ├── exception_tests.vcxproj.filters
│   └── header.hpp
├── kubera.sln
├── kubera.vcxproj
├── kubera.vcxproj.filters
├── kubera_tests
│   ├── kubera_tests.cpp
│   ├── kubera_tests.vcxproj
│   ├── kubera_tests.vcxproj.filters
│   └── utils.hpp
├── module_loader
│   ├── module_loader.cpp
│   ├── module_loader.vcxproj
│   └── module_loader.vcxproj.filters
├── semantics
│   ├── semantics.vcxproj
│   ├── semantics.vcxproj.filters
│   └── src
│       ├── arithmetic.cpp
│       ├── avx.cpp
│       ├── bit.cpp
│       ├── control_flow.cpp
│       ├── cpu.cpp
│       ├── data.cpp
│       ├── flags.cpp
│       ├── fpu.cpp
│       ├── frame.cpp
│       ├── jcc.cpp
│       ├── logical.cpp
│       ├── pch.cpp
│       ├── pch.hpp
│       ├── syscall.asm
│       ├── syscalls.cpp
│       └── winapi.cpp
├── shared
│   ├── capstone++.hpp
│   ├── context.hpp
│   ├── module_loader.hpp
│   ├── portable_executable.hpp
│   ├── shared.vcxproj
│   ├── shared.vcxproj.filters
│   ├── src
│   │   └── portable_executable.cpp
│   └── types.hpp
├── vcpkg-configuration.json
└── vcpkg.json

```

`CONTRIBUTING.md`:

```md
# Contributing to KUBERA

Thank you for your interest in contributing to KUBERA! We welcome contributions to improve this x86 software emulator. Please follow the guidelines below to ensure a smooth collaboration.

## How to Contribute

1. **Fork the Repository**: Create a fork of the [KUBERA repository](https://github.com/[your-repo]/kubera) on GitHub.
2. **Clone Your Fork**: Clone your fork to your local machine.
3. **Create a Branch**: Use a descriptive branch name (e.g., `feature/add-avx512-support` or `fix/memory-leak`).
4. **Make Changes**: Implement your feature, bug fix, or improvement.
5. **Test Your Changes**: Ensure your changes work as intended and do not introduce new issues. Test within an isolated VM environment.
6. **Commit Changes**: Write clear, concise commit messages following the [Conventional Commits](https://www.conventionalcommits.org/) format (e.g., `feat: add AVX512 emulation support`).
7. **Push to Your Fork**: Push your branch to your forked repository.
8. **Submit a Pull Request**: Open a pull request (PR) against the main repository’s `main` branch. Include a detailed description of your changes and reference any related issues.

## Code Style and Formatting

- Follow the formatting rules specified in the [`.editorconfig`](.editorconfig) file. Use an editor that supports EditorConfig to enforce these settings.
- Write clean, readable code with meaningful variable names and comments where necessary.
- Ensure consistency with the existing codebase (e.g., use spaces, not tabs, and follow naming conventions).

## Contribution Guidelines

- **Scope**: Contributions should align with KUBERA’s goals (x86 emulation, detailed analysis, isolation). Major feature proposals should be discussed in an issue first.
- **Testing**: Test your changes thoroughly, especially for edge cases involving different x86 architectures or operating systems. Include test cases if applicable.
- **Documentation**: Update relevant documentation (e.g., README, code comments) for new features or changes.
- **Licensing**: By contributing, you agree that your contributions are licensed under the [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/), as specified in the [LICENSE](LICENSE) file.

## Reporting Issues

- Use the GitHub Issues tab to report bugs or suggest features.
- Provide a clear title, detailed description, steps to reproduce (for bugs), and any relevant logs or screenshots.
- Check for existing issues to avoid duplicates.

## Code of Conduct

- Be respectful and inclusive in all interactions.
- Follow GitHub’s [Community Guidelines](https://docs.github.com/en/site-policy/github-terms/github-community-guidelines).
- Avoid submitting code that violates third-party intellectual property rights or introduces security risks.

## Contact

For questions or clarification, contact REAPS, s.r.o. at reapsgg@proton.me. For significant changes, open an issue to discuss before starting work.

Thank you for helping make KUBERA better!
```

`LICENSE`:

```
MIT License

Copyright (c) 2025 binsnake

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`README.md`:

```md
# KUBERA
KUBERA is a concrete x86 software emulator focused on detailed analysis and control, primarily for Windows binaries, with planned support for Linux and other operating systems. It is aiming to be platform-independent, designed for research, and not intended for full system emulation.

Disclaimer: This project is heavily work-in-progress. Development has been ongoing for several months.

## Purpose
KUBERA provides deterministic, reversible, and verbose emulation, offering maximum insight into execution flow, including stack, memory, and register changes. It includes a user-friendly SDK to intercept operations and aims to prevent emulation detection by software. Key use cases:

Analyze software interactions with operating systems.
Inspect functionality at the instruction level.
Emulate x86 software natively, including extensions (AVX2, AVX512, APX) on legacy hardware.
Examine edge cases across x86 CPU architectures (contribution-dependent).

## Features

Detailed execution tracing (stack, memory, registers).
Platform-independent emulation of Windows and Linux binaries.
Support for x86 extensions on unsupported hardware.
SDK for operation interception and analysis.
Focus on isolation (ongoing development).

## Usage Warnings
KUBERA is not a secure sandbox for malicious software. It may allow host data access or VM escapes, potentially enabling malicious code execution. Always run KUBERA and emulated applications in an isolated environment (e.g., VMWare, VirtualBox, QEMU). KUBERA is a research tool in early development, not sponsored, and not guaranteed to be safe or complete.
Third-Party Software
KUBERA references third-party software names for binary initialization. These names and binaries are the property of their respective legal entities or developers, and REAPS, s.r.o. claims no ownership. No binaries are distributed with this project.
A lot of the code is very experimental and prone to failure. KUBERA is mostly an ongoing learning project towards CPU & OS internals.

## Dependencies
KUBERA includes the following open-source libraries:

ImGui - Licensed under the MIT License.
Capstone - Licensed under the BSD 3-Clause License.
Boost libraries - Licensed under the BSL-1.0 License.

See the LICENSE file for full license texts and copyright notices.

## License
This project is licensed under the MIT license, effective from the commit including the LICENSE file. See the LICENSE file for details.

## Tests
It is recommended that new instructions are tested vs hardware, we use https://github.com/ZehMatt/x86Tester/ to generate instruction combinations that we test our framework against.

## Contributing
Contributions are welcome! Please follow the naming conventions and formatting specified in the .editorconfig file. For detailed guidelines, see CONTRIBUTING.md (if available) or contact REAPS, s.r.o.

## Contact
For commercial inquiries, licensing questions, or issues, contact REAPS, s.r.o. at reapsgg@proton.me.

Disclaimer
KUBERA is provided "as is" for research purposes only. REAPS, s.r.o. is not liable for any damages, data loss, or security breaches resulting from its use. Users are responsible for ensuring compliance with all applicable laws and third-party intellectual property rights when using KUBERA or emulating third-party software.

## Community

We're currently on discord: https://discord.gg/6HyQYzPpyN

## Similar projects

https://github.com/icicle-emu/icicle-emu - Icicle is an emulator written in Rust
https://github.com/unicorn-engine/unicorn

```

`dll_minimal/dll_minimal.cpp`:

```cpp
/*
 * Minimal KUBERA implementation for emulating a Windows DLL.
 * Configures emulator, executes at AddressOfEntryPoint, handles CRT, exceptions,
 * and logs execution time with optional verbose logging.
 */

#include <semantics/src/pch.hpp>
#include <shared/types.hpp>
#include <shared/context.hpp>
#include <shared/capstone++.hpp>
#include <Windows.h>
#include <algorithm>
#include <chrono>
#include <cstdint>
#include <iostream>
#include <mutex>
#include <print>
#include <thread>
#include <unordered_map>

#include "sig.hpp"
#include <Psapi.h>
DWORD get_dll_size ( HMODULE module ) {
	MODULEINFO info;
	if ( GetModuleInformation ( GetCurrentProcess ( ), module, &info, sizeof ( info ) ) ) {
		return info.SizeOfImage;
	}
	return 0;
}

/* Load module (DLL or EXE) */
static bool load_module ( const std::string& file_path, HMODULE& module, uint64_t& loaded_base, uint64_t& module_size ) {
	HANDLE hFile = CreateFileA ( file_path.c_str ( ), GENERIC_READ, FILE_SHARE_READ, nullptr, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, nullptr );
	if ( hFile == INVALID_HANDLE_VALUE ) {
		std::print ( "Failed to open file: {}\n", GetLastError ( ) );
		return false;
	}

	HANDLE hMap = CreateFileMappingA ( hFile, nullptr, PAGE_READONLY, 0, 0x1000, nullptr );
	if ( !hMap ) {
		CloseHandle ( hFile );
		std::print ( "Failed to create mapping: {}\n", GetLastError ( ) );
		return false;
	}

	auto base = MapViewOfFile ( hMap, FILE_MAP_READ, 0, 0, 0x1000 );
	CloseHandle ( hMap );
	CloseHandle ( hFile );
	if ( !base ) {
		std::print ( "Failed to view headers: {}\n", GetLastError ( ) );
		return false;
	}

	auto dos = reinterpret_cast< IMAGE_DOS_HEADER* >( base );
	auto nt = reinterpret_cast< IMAGE_NT_HEADERS64* >( ( uint8_t* ) base + dos->e_lfanew );
	bool isDll = ( nt->FileHeader.Characteristics & IMAGE_FILE_DLL ) != 0;
	UnmapViewOfFile ( base );

	if ( isDll ) {
		module = LoadLibraryExA ( file_path.c_str ( ), nullptr, DONT_RESOLVE_DLL_REFERENCES );
		if ( !module ) {
			std::print ( "DLL LoadLibraryExA failed: {}\n", GetLastError ( ) );
			return false;
		}
		loaded_base = reinterpret_cast< uint64_t >( module );
		module_size = parser ? parser->pe_info_.optional_header.size_of_image : 0x100000;
	}
	else {
		HANDLE f = CreateFileA ( file_path.c_str ( ), GENERIC_READ, FILE_SHARE_READ, nullptr, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, nullptr );
		if ( f == INVALID_HANDLE_VALUE ) return false;
		HANDLE m = CreateFileMappingA ( f, nullptr, PAGE_READONLY | SEC_IMAGE, 0, 0, nullptr );
		CloseHandle ( f );
		if ( !m ) return false;
		auto fullBase = MapViewOfFile ( m, FILE_MAP_READ, 0, 0, 0 );
		CloseHandle ( m );
		if ( !fullBase ) return false;
		auto dos2 = reinterpret_cast< IMAGE_DOS_HEADER* >( fullBase );
		auto nt2 = reinterpret_cast< IMAGE_NT_HEADERS64* >( ( uint8_t* ) fullBase + dos2->e_lfanew );

		module = reinterpret_cast< HMODULE >( fullBase );
		loaded_base = reinterpret_cast< uint64_t >( fullBase );
		module_size = nt2->OptionalHeader.SizeOfImage;
	}

	auto new_parser = std::make_unique<PE::Parser> ( loaded_base );
	if ( parser ) parser.swap ( new_parser );
	else parser = std::move ( new_parser );

	std::print ( "Module loaded at {:016x}h, size: {:x}h\n", loaded_base, module_size );
	return true;
}

/* Initialize emulator state */
static void initialize_state ( EmulationContext& state, HMODULE module, uint64_t loaded_base, uint64_t module_size ) {
	state.decoder.emplace_back ( new capstone::Decoder ( ( uint8_t* ) module, module_size, loaded_base ) );
	state.decoder.back ( )->set_ip ( loaded_base + parser->pe_info_.optional_header.address_of_entry_point );
	//InstructionEffect effect { };
	//CONTEXT ctx { 0 };
	//state.save_context ( &ctx );
	//
	//ctx.Rip = state.windows->ldr_initialize_thunk;
	//ctx.Rcx = parser->get_entry_point ( );
	//ctx.Rdx = 0; // arg
	//PE::Parser ntdll_parser ( state.windows->ntdll_base );
	//
	//state.decoder.emplace_back ( new capstone::Decoder ( ( uint8_t* ) state.windows->ntdll_base, ntdll_parser.pe_info_.optional_header.size_of_image, state.windows->ntdll_base ) );
	//state.decoder.back ( )->set_ip ( state.windows->ldr_initialize_thunk );
	//
	//state.allocate_stack ( sizeof ( CONTEXT ), effect );
	//auto base = state.get_reg<uint64_t> ( X86_REG_RSP );
	//for ( auto i = sizeof(CONTEXT); i != 0; i -= 8 ) {
	//	state.set_stack ( base + i, *reinterpret_cast< uint64_t* > ( reinterpret_cast< uint8_t* > ( &ctx ) + i ), effect, 8 );
	//}

	state.windows->loaded_module = module;
	state.windows->loaded_base_address = loaded_base;
	state.windows->loaded_module_size = module_size;
}

#define SET_KERNEL_MODULE(x) multihook(#x, handlers::winapi::x)
void init_hooks ( EmulationContext& state ) {
	auto kernel32 = GetModuleHandleA ( "kernel32.dll" );
	auto kernelbase = GetModuleHandleA ( "kernelbase.dll" );

	if ( !kernel32 || !kernelbase ) {
		return;
	}

	const auto multihook = [ & ] ( const std::string& name, APIHandler handler )
	{
		auto [first, last] = state.windows->import_multi_map.equal_range ( name );
		size_t set = 0u;
		for ( auto it = first; it != last; ++it ) {
			state.windows->api_hooks.insert ( { it->second, handler } );
			std::print ( "{:x} ", it->second );
			++set;
		}

		auto ntdll_stub = ( uint64_t ) GetProcAddress ( reinterpret_cast< HMODULE >( state.windows->ntdll_base ), name.c_str ( ) );
		if ( ntdll_stub ) {
			state.windows->api_hooks.insert ( { ntdll_stub, handler } );
			std::print ( "{:x} ", ntdll_stub );
			++set;
		}

		auto kb_stub = ( uint64_t ) GetProcAddress ( kernelbase, name.c_str ( ) );
		if ( kb_stub ) {
			state.windows->api_hooks.insert ( { kb_stub, handler } );
			std::print ( "{:x} ", kb_stub );
			++set;
		}

		std::println ( "[{}] Hooked {} times across API", name, set );
	};

	//SET_KERNEL_MODULE ( GetProcAddress );
	//SET_KERNEL_MODULE ( LoadLibraryA );
	//SET_KERNEL_MODULE ( LoadLibraryW );
	//SET_KERNEL_MODULE ( LoadLibraryExA );
	//SET_KERNEL_MODULE ( LoadLibraryExW );
	////SET_KERNEL_MODULE ( InitializeCriticalSectionAndSpinCount );
	////SET_KERNEL_MODULE ( InitializeCriticalSectionEx );
	//SET_KERNEL_MODULE ( RtlInitializeCriticalSectionEx );
	//SET_KERNEL_MODULE ( RtlInitializeCriticalSectionAndSpinCount );
	//SET_KERNEL_MODULE ( RtlEnterCriticalSection );
	//SET_KERNEL_MODULE ( RtlLeaveCriticalSection );
	//SET_KERNEL_MODULE ( RtlDeleteCriticalSection );
	////SET_KERNEL_MODULE ( InitializeSListHead );
	//SET_KERNEL_MODULE ( FlsAlloc );
	//SET_KERNEL_MODULE ( FlsGetValue );
	//SET_KERNEL_MODULE ( FlsSetValue );
	//SET_KERNEL_MODULE ( FlsFree );
	//SET_KERNEL_MODULE ( TlsAlloc );
	//SET_KERNEL_MODULE ( TlsGetValue );
	//SET_KERNEL_MODULE ( TlsSetValue );
	//SET_KERNEL_MODULE ( TlsFree );
	//
	//SET_KERNEL_MODULE ( VirtualProtect );
	////SET_KERNEL_MODULE ( IsProcessorFeaturePresent );
	//SET_KERNEL_MODULE ( GetLastError );

	std::println ( "Applied {} API hooks!", state.windows->api_hooks.size ( ) );
}

std::string format_rva ( EmulationContext& state, uint64_t ip ) {
	for ( const auto& [base, module] : state.windows->loaded_modules ) {
		if ( ip >= base && ip < base + module.size ) {
			return std::format ( "{:#x}", ip - base + 0x180000000 );
		}
	}
	return std::format ( "{:#x}", ip );
}

/* Main emulation loop */
void run ( ) {
	std::string file_path = "maddi.dll";
	HMODULE module;
	uint64_t loaded_base, module_size;
	if ( !load_module ( file_path, module, loaded_base, module_size ) ) return;

	EmulationContext state;
	init_hooks ( state );
	initialize_state ( state, module, loaded_base, module_size );
	state.windows->add_module ( module, loaded_base, module_size, ( uint8_t* ) module );

	//state.decoder.emplace_back ( new capstone::Decoder ( ( uint8_t* ) module, module_size, loaded_base ) );
	state.options.enable_logging = true;

	auto execute_to_return = [ & ] ( InstructionEffect& effect )
	{
		while ( state.decoder.back ( )->can_decode ( ) ) {
			capstone::Instruction instr = state.decoder.back ( )->decode ( );
			state.set_reg ( X86_REG_RIP, instr.ip ( ) + instr.length ( ), 8, effect );

			GuestExceptionInfo current_exception;
			bool run_handler = true;
			bool handler_executed_cleanly = false;

			if ( !instr.is_valid ( ) ) {
				current_exception.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
				run_handler = false;
			}
			else {
				const InstructionExceptionInfo& baseInfo = g_instruction_exception_table [ instr.mnemonic ( ) ];
				PreCheckInfo check_info;
				populate_pre_check_info ( check_info, state, instr, baseInfo );
				current_exception = check_instruction_exceptions ( state, instr, check_info );
				if ( current_exception.exception_occurred ) run_handler = false;
			}

			if ( run_handler ) {
				effect = state.log_effect ( instr );
				effect.instr_str = instr.to_string ( );
				try {
					auto it = instruction_handlers.find ( static_cast< x86_insn >( instr.mnemonic ( ) ) );
					if ( it != instruction_handlers.end ( ) && *it->second ) {
						( *it->second )( instr, state, effect );
						handler_executed_cleanly = true;
					}
					else {
						current_exception.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
						run_handler = false;
					}
				}
				catch ( const GuestExceptionInfo& handler_ex ) {
					current_exception = handler_ex;
					run_handler = false;
					return false;
				}
				catch ( const std::exception& handler_host_ex ) {
					UNREFERENCED_PARAMETER ( handler_host_ex );
					current_exception.set_access_violation ( instr.ip ( ), 0, false );
					run_handler = false;
					return false;
				}
			}

			if ( run_handler && handler_executed_cleanly && !current_exception.exception_occurred ) {
				const InstructionExceptionInfo& baseInfo = g_instruction_exception_table [ instr.mnemonic ( ) ];
				uint8_t op_size = instr.operand_count ( ) > 0 ? instr.operands ( ) [ 0 ].size : 8;
				if ( baseInfo.categories.ARITHMETIC ) {
					std::println ( "Checking post-execution arithmetic for {}", instr.to_string ( ) );
					GuestExceptionInfo arith_ex = check_post_execution_arithmetic ( state, baseInfo, instr.ip ( ), op_size );
					if ( arith_ex.exception_occurred ) {
						std::println ( "Arithmetic exception: Code=0x{:X}, VA=0x{:016x}", arith_ex.ExceptionCode, arith_ex.FaultingVa );
						current_exception = arith_ex;
					}
				}
				if ( !current_exception.exception_occurred && baseInfo.categories.FPU_SIMD ) {
					std::println ( "Checking post-execution FPU/SIMD for {}", instr.to_string ( ) );
					GuestExceptionInfo fp_simd_ex = check_post_execution_fpu_simd ( state, baseInfo, instr.ip ( ) );
					if ( fp_simd_ex.exception_occurred ) {
						std::println ( "FPU/SIMD exception: Code=0x{:X}, VA=0x{:016x}", fp_simd_ex.ExceptionCode, fp_simd_ex.FaultingVa );
						current_exception = fp_simd_ex;
					}
				}
			}

			if ( current_exception.exception_occurred ) {
				std::println ( "Dispatching exception: Code=0x{:X}, IP=0x{:016x}, VA=0x{:016x}",
										 current_exception.ExceptionCode, current_exception.ExceptionAddress, current_exception.FaultingVa );
				setup_guest_exception_dispatch ( state, current_exception );
				std::println ( "Exception dispatch completed for IP=0x{:016x}", current_exception.ExceptionAddress );
				if ( state.exit_due_to_critical_error ) break;
				continue;
			}

			if ( run_handler && handler_executed_cleanly ) {
				state.increment_tsc ( );
				effect.normalize_registers ( &state );
				if ( instr.is_return ( ) && state.call_stack.empty ( ) ) break;
			}

			if ( state.exit_due_to_critical_error ) break;
		}
		return true;
	};

	InstructionEffect effect;

	// Handle TLS callbacks
	auto dos = reinterpret_cast< IMAGE_DOS_HEADER* >( loaded_base );
	auto nt = reinterpret_cast< IMAGE_NT_HEADERS64* >( loaded_base + dos->e_lfanew );
	auto& opt = nt->OptionalHeader;
	if ( opt.DataDirectory [ IMAGE_DIRECTORY_ENTRY_TLS ].VirtualAddress ) {
		auto tls = reinterpret_cast< IMAGE_TLS_DIRECTORY64* >( loaded_base + opt.DataDirectory [ IMAGE_DIRECTORY_ENTRY_TLS ].VirtualAddress );
		auto cbArray = reinterpret_cast< PIMAGE_TLS_CALLBACK* >( tls->AddressOfCallBacks );
		for ( size_t i = 0; cbArray [ i ]; ++i ) {
			state.set_reg ( X86_REG_RCX, loaded_base, 8, effect );
			state.set_reg ( X86_REG_RDX, DLL_PROCESS_ATTACH, 8, effect );
			state.set_reg ( X86_REG_R8, 0ULL, 8, effect );
			state.decoder.back ( )->set_ip ( reinterpret_cast< uint64_t >( cbArray [ i ] ) );
			execute_to_return ( effect );
		}
	}

	// Handle static TLS data
	{
		auto ntdll = reinterpret_cast< std::uint8_t* >( GetModuleHandleA ( "ntdll.dll" ) );
		size_t ntdll_size = get_dll_size ( ( HMODULE ) ntdll );
		auto ntdll_end = ntdll + ntdll_size;
		std::uint8_t* ldrp_handle_tls_data = byte_scanner<"4C 8B DC 49 89 5B ? 49 89 73 ? 57 41 54 41 55 41 56 41 57 48 81 EC ? ? ? ? 48 8B 05 ? ? ? ? 48 33 C4 48 89 84 24 ? ? ? ? 48 8B F9">.search ( ntdll, ntdll_end );
		if ( !ldrp_handle_tls_data ) {
			ldrp_handle_tls_data = byte_scanner<"48 89 5C 24 ? 48 89 74 24 ? 48 89 7C 24 ? 41 54 41 56 41 57 48 81 EC ? ? ? ? 48 8B 05 ? ? ? ? 48 33 C4 48 89 84 24 ? ? ? ? 48 8B C1">.search ( ntdll, ntdll_end );
		}
		char fake_ldr [ 0x130 ] { 0 };
		*( uint64_t* ) ( fake_ldr + 0x30 ) = loaded_base;
		//reinterpret_cast< void( * )( void* ) >( ldrp_handle_tls_data )( fake_ldr );
		state.set_reg ( X86_REG_RCX, reinterpret_cast< uint64_t >( fake_ldr ), 8, effect );
		state.set_reg ( X86_REG_RDX, 0ULL, 8, effect );
		state.decoder.emplace_back ( new capstone::Decoder ( ntdll, ntdll_size, ( uint64_t ) ntdll ) );

		state.push_call_frame ( 0xDEADBEEFDEADBEEF, effect );
		state.decoder.back ( )->set_ip ( ( uint64_t ) ldrp_handle_tls_data );
		if ( !execute_to_return ( effect ) ) {
			__debugbreak ( );
		}

		state.decoder.pop_back ( );
		state.decoder.pop_back ( );
	}
	// Resume at CRT entrypoint
	state.decoder.back ( )->set_ip ( loaded_base + 0x1E000 );
	state.options.enable_logging = true;

	state.set_reg ( X86_REG_R8, 0ULL, 8, effect );
	state.set_reg ( X86_REG_RDX, 1ULL, 8, effect );
	state.set_reg ( X86_REG_RCX, loaded_base, 8, effect );
	state.set_reg ( X86_REG_RSI, state.decoder.back ( )->ip ( ), 8, effect );
	state.set_reg ( X86_REG_RBX, state.get_reg<uint64_t> ( X86_REG_RSP ), 8, effect );

	auto rsp = state.get_reg<uint64_t> ( X86_REG_RSP );
	state.set_reg ( X86_REG_RSP, ( rsp & ~0xFFFFULL ) | ( ( rsp & 0xFFFF ) & 0xFF00 ), 8, effect );


	std::unordered_map<uint64_t, int> visit_count;
	const int max_loop_iterations = 1000;
	bool dllmain_phase = false;
	constexpr uint64_t dllMainRVA = 0x1000;
	constexpr uint64_t fake_ret_addr_value = 0xDEADBEEFBAADF00DULL;
	int instruction_count = 0;

	std::println ( "Starting execution at 0x{:016x}", state.decoder.back ( )->ip ( ) );
	auto start = std::chrono::high_resolution_clock::now ( );
	size_t control_ins = 0;
	bool run_handler = true;

	while ( state.decoder.back ( )->can_decode ( ) ) {
		uint64_t ip_before_decode = state.decoder.back ( )->ip ( );
		capstone::Instruction instr = state.decoder.back ( )->decode ( );
		state.set_reg ( X86_REG_RIP, instr.ip ( ) + instr.length ( ), 8, effect );

		GuestExceptionInfo current_exception;
		bool handler_executed_cleanly = false;
		std::println ( "[{}]{} ({}) {}", state.call_stack.size ( ), std::format ( "{:>{}}", "", state.call_stack.size ( ) ),
						 format_rva ( state, instr.ip ( ) ), instr.to_string ( ) );

		if ( !instr.is_valid ( ) ) {
			std::println ( "0x{:016x}: Invalid instruction, stopping.", ip_before_decode );
			current_exception.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, ip_before_decode );
			run_handler = false;
		}
		else {
			instruction_count++;
			visit_count [ instr.ip ( ) ]++;
			const InstructionExceptionInfo& baseInfo = g_instruction_exception_table [ instr.mnemonic ( ) ];
			PreCheckInfo check_info;
			populate_pre_check_info ( check_info, state, instr, baseInfo );
			current_exception = check_instruction_exceptions ( state, instr, check_info );
			if ( current_exception.exception_occurred ) {
				std::println ( "Pre-execution Exception: Code=0x{:X} @ IP=0x{:016x}, VA=0x{:016x}",
										 current_exception.ExceptionCode, current_exception.ExceptionAddress, current_exception.FaultingVa );
				run_handler = false;
			}
		}

		if ( run_handler ) {
			effect = state.log_effect ( instr );
			effect.instr_str = instr.to_string ( );
			try {
				auto it = instruction_handlers.find ( static_cast< x86_insn >( instr.mnemonic ( ) ) );
				if ( it != instruction_handlers.end ( ) && *it->second ) {
					( *it->second )( instr, state, effect );
					handler_executed_cleanly = true;
				}
				else {
					std::println ( "Emulator Error: Unhandled mnemonic: {}", instr.to_string ( ) );
					current_exception.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
					run_handler = false;
				}
			}
			catch ( const GuestExceptionInfo& handler_ex ) {
				std::println ( "Handler Guest Exception: Code=0x{:X} @ IP=0x{:016x}, VA=0x{:016x}",
										 handler_ex.ExceptionCode, handler_ex.ExceptionAddress, handler_ex.FaultingVa );
				state.dump_state ( );
				current_exception = handler_ex;
				run_handler = false;
				break;
			}
			catch ( const std::exception& handler_host_ex ) {
				std::println ( "Host Exception: {}", handler_host_ex.what ( ) );
				current_exception.set_access_violation ( instr.ip ( ), 0, false );
				run_handler = false;
				break;
			}
		}

		if ( run_handler && handler_executed_cleanly && !current_exception.exception_occurred ) {
			const InstructionExceptionInfo& baseInfo = g_instruction_exception_table [ instr.mnemonic ( ) ];
			uint8_t op_size = instr.operand_count ( ) > 0 ? instr.operands ( ) [ 0 ].size : 8;
			if ( baseInfo.categories.ARITHMETIC ) {
				std::println ( "Checking post-execution arithmetic for {}", instr.to_string ( ) );
				GuestExceptionInfo arith_ex = check_post_execution_arithmetic ( state, baseInfo, instr.ip ( ), op_size );
				if ( arith_ex.exception_occurred ) {
					std::println ( "Arithmetic exception: Code=0x{:X}, VA=0x{:016x}", arith_ex.ExceptionCode, arith_ex.FaultingVa );
					current_exception = arith_ex;
				}
			}
			if ( !current_exception.exception_occurred && baseInfo.categories.FPU_SIMD ) {
				std::println ( "Checking post-execution FPU/SIMD for {}", instr.to_string ( ) );
				GuestExceptionInfo fp_simd_ex = check_post_execution_fpu_simd ( state, baseInfo, instr.ip ( ) );
				if ( fp_simd_ex.exception_occurred ) {
					std::println ( "FPU/SIMD exception: Code=0x{:X}, VA=0x{:016x}", fp_simd_ex.ExceptionCode, fp_simd_ex.FaultingVa );
					current_exception = fp_simd_ex;
				}
			}
			if ( current_exception.exception_occurred ) {
				std::println ( "Post-execution Exception: Code=0x{:X} @ IP=0x{:016x}, VA=0x{:016x}",
										 current_exception.ExceptionCode, current_exception.ExceptionAddress, current_exception.FaultingVa );
			}
		}

		if ( current_exception.exception_occurred ) {
			std::println ( "Dispatching exception: Code=0x{:X}, IP=0x{:016x}, VA=0x{:016x}",
									 current_exception.ExceptionCode, current_exception.ExceptionAddress, current_exception.FaultingVa );
			setup_guest_exception_dispatch ( state, current_exception );
			std::println ( "Exception dispatch completed for IP=0x{:016x}", current_exception.ExceptionAddress );
			if ( state.exit_due_to_critical_error ) {
				std::println ( "Stopping due to critical error." );
				break;
			}
			continue;
		}

		if ( run_handler && handler_executed_cleanly ) {
			state.increment_tsc ( );
			if ( state.options.enable_logging ) {

				if ( !effect.changes.empty ( ) ) {
					for ( const auto& change : effect.changes ) {
						std::print ( "{} ", change );
					}
					std::print ( "\n" );
				}

			}
			effect.normalize_registers ( &state );

			if ( instr.is_return ( ) && state.call_stack.empty ( ) ) {
				state.set_reg ( X86_REG_RSP, state.get_reg<uint64_t> ( X86_REG_RBX ), 8, effect );

				std::println ( "DllMain finished; stopping trace at 0x{:016x}", instr.ip ( ) );
				break;
			}
			if ( state.options.exit_on_infinite_loop ) {
				if ( visit_count [ instr.ip ( ) ] >= max_loop_iterations &&
						instr.is_jump ( ) &&
						instr.branch_target ( ) <= instr.ip ( ) ) {
					std::println ( "Max loop iterations ({}) reached for backwards jump at 0x{:016x}, stopping.", max_loop_iterations, instr.ip ( ) );
					break;
				}
			}
		}

		if ( state.exit_due_to_critical_error ) {
			std::println ( "Emulation stopping due to critical error flag." );
			break;
		}
		++control_ins;
	}

	auto end = std::chrono::high_resolution_clock::now ( );
	auto end_us = std::chrono::duration_cast< std::chrono::nanoseconds >( end - start ).count ( );
	auto end_ms = std::chrono::duration_cast< std::chrono::milliseconds >( end - start ).count ( );

	std::println ( "Trace completed with {} instructions executed.", instruction_count );
	std::println ( "[+] Ran {} instructions in {} ns ({}ms)", control_ins, end_us, end_ms );
	std::println ( "[+] Throughput: {} instructions / second", control_ins / ( static_cast< float >( end_ms ) / 1000.f ) );
}


int main ( ) {
	run ( );
	std::cin.get ( );
}
```

`dll_minimal/dll_minimal.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{4c9a92ca-125c-48b0-9e44-830fbb978258}</ProjectGuid>
    <RootNamespace>dllminimal</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Release;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <RuntimeLibrary>MultiThreadedDebug</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <AdditionalDependencies>semantics.lib;emulator.lib;shared.lib;$(CoreLibraryDependencies);%(AdditionalDependencies)</AdditionalDependencies>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <RuntimeLibrary>MultiThreaded</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <AdditionalDependencies>semantics.lib;emulator.lib;shared.lib;$(CoreLibraryDependencies);%(AdditionalDependencies)</AdditionalDependencies>
    </Link>
  </ItemDefinitionGroup>
  <ItemGroup>
    <ClCompile Include="dll_minimal.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="sig.hpp" />
  </ItemGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
```

`dll_minimal/dll_minimal.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="dll_minimal.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="sig.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
  </ItemGroup>
</Project>
```

`dll_minimal/sig.hpp`:

```hpp
#pragma once 
#include <algorithm>
#include <type_traits>
#include <array>
#include <cstdint>
#include <utility>
#include <immintrin.h>
#if defined(__clang__)
#define CLANG 1
#else
#define CLANG 0
#endif
#if defined(__GNUC__)&&!defined(__clang__)
#define GCC 1
#else
#define GCC 0
#endif
#if defined(_MSC_VER)&&!defined(__clang__)
#define MSVC 1
#else
#define MSVC 0
#endif
#if defined(_MSC_VER)&&defined(__clang__)
#define CLANG_CL 1
#else
#define CLANG_CL 0
#endif
static_assert( CLANG + GCC + MSVC == 1 );
#if MSVC || CLANG_CL
#if _WIN32 || _WIN64
#if _WIN64
#define BITNESS 64
#else
#define BITNESS 32
#endif
#endif
#else
#if __x86_64__ || __ppc64__
#define BITNESS 64
#else
#define BITNESS 32
#endif
#endif
static_assert( sizeof ( void* ) * 8 == BITNESS );
#if CLANG || GCC
#define UNREACHABLE __builtin_unreachable()
#define Inline __attribute__((always_inline)) inline
#define LambdaInline __attribute__((always_inline))
#else
#define UNREACHABLE __assume(false)
#define Inline __forceinline
#define LambdaInline [[msvc::forceinline]]
#endif
#define FWD(...) static_cast<decltype(__VA_ARGS__)&&>(__VA_ARGS__)
#define MOV(...) static_cast<typename std::remove_reference<decltype(__VA_ARGS__)>::type &&>(__VA_ARGS__)
#if CLANG || GCC
template<class T, class T0>concept $Same = __is_same ( T, T0 );
template<class T, class...Ts>constexpr bool all_same { ( __is_same ( T, Ts )&&... ) };
#else
template<class T, class T0>concept $Same = std::is_same_v<T, T0>;
template<class T, class...Ts>constexpr bool all_same { ( std::is_same_v<T, Ts>&&... ) };
#endif
namespace Algorithm
{
	template<class Arg0, class...Args>
		requires( all_same<Arg0, Args...>&& std::is_trivially_copyable_v<Arg0> && sizeof ( Arg0 ) <= 2 * sizeof ( void* ) )
	Inline constexpr Arg0 max ( Arg0 arg0, const Args...args )noexcept {
		( ( arg0 = ( args > arg0 ) ? args : arg0 ), ... );
		return arg0;
	}
}
namespace details
{
	template<std::uint64_t MaxValue>struct compact_impl;
	template<std::uint64_t MaxValue>requires( ( MaxValue >= 0 ) && MaxValue <= std::uint8_t ( -1 ) ) struct compact_impl<MaxValue> { using type = std::uint8_t; };
	template<std::uint64_t MaxValue>requires( ( MaxValue > std::uint8_t ( -1 ) ) && MaxValue <= std::uint16_t ( -1 ) )	struct compact_impl<MaxValue> { using type = std::uint16_t; };
	template<std::uint64_t MaxValue>requires( ( MaxValue > std::uint16_t ( -1 ) ) && MaxValue <= std::uint32_t ( -1 ) )	struct compact_impl<MaxValue> { using type = std::uint32_t; };
	template<std::uint64_t MaxValue>requires( ( MaxValue > std::uint32_t ( -1 ) ) && MaxValue <= std::uint64_t ( -1 ) )	struct compact_impl<MaxValue> { using type = std::uint64_t; };
}
template<std::uint64_t...MaxValue>using Compact = typename details::compact_impl<Algorithm::max ( MaxValue... )>::type;
template<std::uint64_t Value>static constexpr Compact<Value> compact { static_cast< Compact<Value> >( Value ) };
template<class...>struct LikeImpl;
template<class From, class To>struct LikeImpl<From&, To> { using type = To&; };
template<class From, class To>struct LikeImpl<const From&, To> { using type = const To&; };
template<class From, class To>struct LikeImpl<volatile From&, To> { using type = volatile To&; };
template<class From, class To>struct LikeImpl<const volatile From&, To> { using type = const volatile To&; };
template<class From, class To>struct LikeImpl<From&&, To> { using type = To&&; };
template<class From, class To>struct LikeImpl<const From&&, To> { using type = const To&&; };
template<class From, class To>struct LikeImpl<volatile From&&, To> { using type = volatile To&&; };
template<class From, class To>struct LikeImpl<const volatile From&&, To> { using type = const volatile To&&; };
template<class From, class To>struct LikeImpl<From, To> { using type = To&&; };
template<class From, class To>struct LikeImpl<const From, To> { using type = const To&&; };
template<class From, class To>struct LikeImpl<volatile From, To> { using type = volatile To&&; };
template<class From, class To>struct LikeImpl<const volatile From, To> { using type = const volatile To&&; };
template<class From, class To>using Like = typename LikeImpl<From, std::remove_cvref_t<To>>::type;
template<class From, class To>using LikePtr = std::remove_reference_t<Like<From, To>>*;
template<class, std::size_t>struct ConstVector;
template<class T, std::size_t N>
	requires( N > 0 )
struct ConstVector<T, N> {
	using index_t = Compact<N>;
	T m_data [ N ];
	index_t m_size;
	constexpr ConstVector ( auto&& ...args )noexcept requires( sizeof...( args ) <= N ) : m_data { FWD ( args )... }, m_size { sizeof...( args ) } { }
	constexpr index_t size ( )const noexcept { return m_size; }
	static constexpr index_t capacity ( ) noexcept { return N; }
	template<class Self>constexpr Like<Self, T> front ( this Self&& self ) noexcept { return FWD ( self ).m_data [ 0 ]; }
	template<class Self>constexpr Like<Self, T> back ( this Self&& self ) noexcept { return FWD ( self ).m_data [ self.m_size - 1 ]; }
	template<class Self>constexpr Like<Self, T> operator[]( this Self&& self, index_t index ) noexcept { return static_cast< Like<Self, T> >( FWD ( self ).m_data [ index ] ); }//msvc bug
	template<class Self>constexpr LikePtr<Self, T> data ( this Self&& self ) noexcept { return self.m_data; }
	template<class Self>constexpr LikePtr<Self, T> begin ( this Self&& self ) noexcept { return self.m_data; }
	template<class Self>constexpr LikePtr<Self, T> end ( this Self&& self ) noexcept { return self.begin ( ) + self.m_size; }
	constexpr void clear ( )noexcept { m_size = {}; }
	constexpr void push_back ( T entry )noexcept { m_data [ m_size++ ] = entry; }
};
template<class T>
struct ConstVector<T, 0> {
	constexpr ConstVector ( )noexcept { }
	static constexpr std::uint8_t size ( ) noexcept { return 0; }
	static constexpr std::uint8_t capacity ( ) noexcept { return 0; }
	constexpr const T* data ( )const noexcept { return nullptr; }
	constexpr const T* begin ( )const noexcept { return nullptr; }
	constexpr const T* end ( )const noexcept { return nullptr; }
};
template<class, class Sig>struct CallableImpl;
template<class T, class Ret, class...Args>struct CallableImpl<T, Ret ( Args... )> { static constexpr bool value { requires( T f, Args...args ) { { FWD ( f )( FWD ( args )... ) }->$Same<Ret>; } }; };
template<class T, class Sig>concept Callable = CallableImpl<T, Sig>::value;
template<class T, std::size_t N>
struct FixedString {
private:
	template<std::size_t...I>
	Inline constexpr FixedString ( const T ( &str ) [ N + 1 ], std::index_sequence<I...> )noexcept :m_data { str [ I ]... } { }
public:
	Inline constexpr FixedString ( const T ( &str ) [ N + 1 ] )noexcept : FixedString { str, std::make_index_sequence<N>{} } { }
	Inline constexpr FixedString ( auto...chars )noexcept : m_data { chars... } { }
	Inline static constexpr Compact<N> size ( )noexcept { return N; }
	template<class Self>Inline constexpr Like<Self, T> operator[]( this Self&& self, std::size_t index ) noexcept { return static_cast< Like<Self, T> >( FWD ( self ).m_data [ index ] ); }//msvc bug
	Inline constexpr const T* begin ( )const noexcept { return m_data; }
	Inline constexpr const T* end ( )const noexcept { return m_data + size ( ); }
	Inline constexpr const T* data ( )const noexcept { return begin ( ); }
	Inline constexpr bool operator==( const FixedString<T, N>& )const noexcept = default;
	Inline constexpr bool operator!=( const FixedString<T, N>& )const noexcept = default;
	using char_type = T;
	T m_data [ N ];
};
template<class T>
struct FixedString<T, 0> {
	Inline constexpr FixedString ( const T ( & ) [ 1 ] )noexcept { }
	Inline constexpr FixedString ( )noexcept { }
	Inline static constexpr std::uint8_t size ( )noexcept { return 0; }
	template<class Self>Inline constexpr Like<Self, T> operator[]( this Self&&, std::size_t ) noexcept;
	Inline constexpr const T* begin ( )const noexcept { return nullptr; }
	Inline constexpr const T* end ( )const noexcept { return nullptr; }
	Inline constexpr const T* data ( )const noexcept { return nullptr; }
	Inline constexpr bool operator==( const FixedString<T, 0>& )const noexcept { return true; }
	Inline constexpr bool operator!=( const FixedString<T, 0>& )const noexcept { return false; }
	using char_type = T;
};
template<class Char, std::size_t N>FixedString ( const Char ( & ) [ N ] ) -> FixedString<Char, N - 1>;
template<class Char, $Same<Char>...Chars>FixedString ( Char, Chars... ) -> FixedString<Char, sizeof...( Chars ) + 1>;
template<class T, std::size_t Size>
concept $Size = sizeof ( T ) == Size;
template<class T>concept $HasBeginEnd = requires( const T container ) { container.begin ( ) != container.end ( ); };
template<class T>concept $HasDataSize = requires( const T container ) { container.data ( ) + container.size ( ); };
template<class T>concept $CArray = std::is_array<typename std::remove_cvref<T>::type>::value;
namespace details
{
	template<class Container>struct ElementOfImpl { using type = std::remove_cvref_t<decltype( *std::declval<const std::remove_cvref_t<Container>> ( ).data ( ) )>; };
	template<$CArray Container>struct ElementOfImpl<Container> { using type = std::remove_cvref_t<decltype( *std::declval<Container> ( ) )>; };
}
template<class Container>using ElementOf = typename details::ElementOfImpl<Container>::type;
namespace Algorithm
{
	template<$HasDataSize Container>
	Inline constexpr void bubble_sort ( Container&& container, Callable<bool ( const ElementOf<Container>, const ElementOf<Container> )> auto&& compare )noexcept {
		using Index = std::remove_cvref_t<decltype( container.size ( ) )>;
		const Index n { container.size ( ) };
		if ( n )
			for ( Index i {}; i != n - 1; ++i )
				for ( Index j {}; j < n - i - 1; ++j )
					if ( !FWD ( compare )( container [ j ], container [ j + 1 ] ) )
						std::swap ( container [ j ], container [ j + 1 ] );
	}
	template<$HasBeginEnd Container>
	Inline constexpr void stable_sort ( Container&& container, Callable<bool ( const ElementOf<Container>, const ElementOf<Container> )> auto&& compare )noexcept {
		if ( std::is_constant_evaluated ( ) )
			bubble_sort ( FWD ( container ), FWD ( compare ) );
		else
			std::stable_sort ( container.begin ( ), container.end ( ), FWD ( compare ) );
	}
}
template<auto Value>constexpr auto constant { Value };
template<std::uint8_t Bits>struct UnsignedBitsImpl { };
template<std::uint8_t Bits> using UnsignedBits = typename UnsignedBitsImpl<Bits>::type;
template<> struct UnsignedBitsImpl<8> { using type = std::uint8_t; };
template<> struct UnsignedBitsImpl<16> { using type = std::uint16_t; };
template<> struct UnsignedBitsImpl<32> { using type = std::uint32_t; };
template<> struct UnsignedBitsImpl<64> { using type = std::uint64_t; };
template<class T>concept $Dtor = !std::is_trivially_destructible_v<T>;
template<class T>concept $NotCvref = $Same<T, std::remove_cvref_t<T>>;
template<$NotCvref T>
struct Opt {
#if GCC//gcc bug
	T m_value {};
#else
	union { T m_value; };
#endif
	bool m_hasValue;
	Inline constexpr Opt ( )noexcept :m_hasValue {} { }
	Inline constexpr Opt ( auto&&...args )noexcept requires( requires{T { FWD ( args )... }; } ) : m_value { FWD ( args )... }, m_hasValue { true } { }
	Inline constexpr Opt& operator=( const Opt& rhs )noexcept {
		( *this ).~Opt ( );
		std::construct_at ( this, rhs );
		return *this;
	}
	Inline constexpr Opt& operator=( Opt&& rhs )noexcept {
		( *this ).~Opt ( );
		std::construct_at ( this, MOV ( rhs ) );
		return *this;
	}
	Inline constexpr Opt& operator=( auto&& args )noexcept
		requires( requires{T { FWD ( args ) }; } ) {
		( *this ).~Opt ( );
		std::construct_at ( this, FWD ( args ) );
		return *this;
	}
	Inline constexpr void emplace ( auto&&...args )noexcept
		requires( requires{T { FWD ( args )... }; } ) {
		std::construct_at ( this, FWD ( args )... );
		m_hasValue = true;
	}
	Inline constexpr void reset ( )noexcept {
		if ( m_hasValue ) {
			if constexpr ( $Dtor<T> )
				m_value.~T ( );
			m_hasValue = false;
		}
	}
	Inline constexpr ~Opt ( )noexcept {
		if constexpr ( $Dtor<T> )
			if ( m_hasValue )
				m_value.~T ( );
	}
	Inline constexpr Opt ( const Opt& rhs )noexcept :m_hasValue { rhs.m_hasValue } {
		if ( m_hasValue )
			std::construct_at ( __builtin_addressof( m_value ), rhs.m_value );
	}
	Inline constexpr Opt ( Opt&& rhs )noexcept :m_hasValue { rhs.m_hasValue } {
		if ( m_hasValue ) {
			std::construct_at ( __builtin_addressof( m_value ), MOV ( rhs.m_value ) );
			rhs.m_hasValue = false;
		}
	}
	Inline constexpr explicit operator bool ( )const noexcept { return m_hasValue; }
	Inline constexpr bool has_value ( )const noexcept { return m_hasValue; }
	template<class Self>Inline constexpr Like<Self, T> value ( this Self&& self ) noexcept { return FWD ( self ).m_value; }
	template<class Self>Inline constexpr Like<Self, T> operator*( this Self&& self ) noexcept { return FWD ( self ).m_value; }
	template<class Self>Inline constexpr LikePtr<Self, T> operator->( this Self&& self ) noexcept { return __builtin_addressof( self.m_value ); }
};
template<class T>Inline constexpr bool operator==( const Opt<T>& l, const Opt<T>& r )noexcept {
	if ( l.has_value ( ) )
		return r.has_value ( ) && *l == *r;
	else
		return !r.has_value ( );
}
template<class T>Inline constexpr bool operator!=( const Opt<T>& l, const Opt<T>& r )noexcept { return !( l == r ); }
template<class T>Inline constexpr bool operator==( const Opt<T>& l, const T& r )noexcept { return l && ( *l == r ); }
template<class T>Inline constexpr bool operator==( const T& l, const Opt<T>& r )noexcept { return r && ( l == *r ); }
template<class T>Inline constexpr bool operator!=( const Opt<T>& l, const T& r )noexcept { return !l || ( *l != r ); }
template<class T>Inline constexpr bool operator!=( const T& l, const Opt<T>& r )noexcept { return !r || ( l != *r ); }
#if CLANG || GCC
template<class T, class...Ts>concept $AnyOf = ( __is_same ( T, Ts ) || ... );
#else
template<class T, class...Ts>concept $AnyOf = ( std::is_same_v<T, Ts> || ... );
#endif
template<class T, class U>concept $Assignable = requires( U & u, const T x ) { u = x; };
namespace Bytes
{
	template<$Same<std::uint16_t> T>Inline constexpr T concat ( std::uint8_t v0, std::uint8_t v1 ) noexcept { return v0 | ( v1 << 8 ); }
	template<$Same<std::uint32_t> T>Inline constexpr T concat ( std::uint8_t v0, std::uint8_t v1, std::uint8_t v2, std::uint8_t v3 ) noexcept { return v0 | ( v1 << 8 ) | ( v2 << 16 ) | ( v3 << 24 ); }
	template<$Same<std::uint64_t> T>Inline constexpr T concat ( std::uint8_t v0, std::uint8_t v1, std::uint8_t v2, std::uint8_t v3, std::uint8_t v4, std::uint8_t v5, std::uint8_t v6, std::uint8_t v7 ) noexcept { return std::uint64_t ( v0 ) | ( std::uint64_t ( v1 ) << 8 ) | ( ( std::uint64_t ) ( v2 ) << 16 ) | ( std::uint64_t ( v3 ) << 24 ) | ( std::uint64_t ( v4 ) << 32 ) | ( std::uint64_t ( v5 ) << 40 ) | ( std::uint64_t ( v6 ) << 48 ) | ( std::uint64_t ( v7 ) << 56 ); }
}
namespace BytePattern
{
	struct Nibbles {
		std::uint8_t low : 4;
		std::uint8_t high : 4;
	};
	struct ComparisonEntryNibble {
		std::size_t offset;
		Opt<std::uint8_t> low;
		Opt<std::uint8_t> high;
	};
	struct ComparisonEntryBytes {
		std::size_t offset {};
		std::uint8_t size {};
	};
	struct Element {
		Opt<std::uint8_t> low, high, byte;
		constexpr Element ( Opt<std::uint8_t> low, Opt<std::uint8_t> high )noexcept :low { low }, high { high }, byte { ( low && high ) ? static_cast< std::uint8_t >( *low | ( *high << 4 ) ) : Opt<std::uint8_t>{} } { }
		constexpr Element ( std::uint8_t byte )noexcept :low { static_cast< std::uint8_t >( byte & 0x0f ) }, high { static_cast< std::uint8_t >( static_cast< std::uint8_t >( byte & 0xf0 ) >> 4 ) }, byte { ( low && high ) ? static_cast< std::uint8_t >( *low | ( *high << 4 ) ) : Opt<std::uint8_t>{} } { }
		constexpr Element ( )noexcept { }
		constexpr bool operator==( const Element& r )noexcept { return low == r.low && high == r.high; }
	};

	namespace details
	{
		template<auto OriginalElements, std::size_t... IndexesToClear>
		consteval auto create_modified_array_for_sequence ( ) noexcept {
			auto new_array = OriginalElements; // OriginalElements is std::array<BytePattern::Element, N>
			// Element is BytePattern::Element, visible due to nested namespace.
			( ( std::get<IndexesToClear> ( new_array ) = Element {} ), ... );
			return new_array;
		}
	}

	template<auto Elements>
	struct Sequence {
		static constexpr std::size_t numElements { Elements.size ( ) };
		static constexpr std::array<Element, numElements> elements { Elements };
		static constexpr ConstVector<ComparisonEntryBytes, numElements> bytesEntries { [ ]
		{
			ConstVector<ComparisonEntryBytes, numElements> result;
			std::size_t start{};
			for ( ;;) {
				while ( start < numElements && !elements [ start ].byte )++start;//skip wildcards/nibbles
				if ( start >= numElements )break;
				std::size_t iNextNonByte{ start + 1 };
				while ( iNextNonByte < numElements&& elements [ iNextNonByte ].byte )++iNextNonByte;
				const std::size_t dist{ iNextNonByte - start };
				const std::uint8_t compareLength{ ( dist >= 8 && sizeof ( void* ) >= 8 ) ? std::uint8_t ( 8 ) : ( dist >= 4 ? std::uint8_t ( 4 ) : ( dist >= 2 ? std::uint8_t ( 2 ) : std::uint8_t ( 1 ) ) )};
				result.push_back ( { start, compareLength } );
				start += compareLength;
			}
			Algorithm::stable_sort ( result,[ ] ( const ComparisonEntryBytes& l, const ComparisonEntryBytes& r ) { return l.size > r.size; } );
			return result;
		}( ) };
		static constexpr ConstVector<ComparisonEntryNibble, numElements> nibbleEntries { [ ]
		{
			ConstVector<ComparisonEntryNibble, numElements> result;
			std::size_t offset{};
			for ( Element e : elements ) {
				if ( e.low.has_value ( ) ^ e.high.has_value ( ) )
					result.push_back ( { offset, e.low, e.high } );
				++offset;
			}
			return result;
		}( ) };
		template<auto I, $Size<1> Uint8>
		Inline static constexpr bool cmpBytesEntries ( Uint8* ptr )noexcept {
			static constexpr ComparisonEntryBytes entry { bytesEntries [ I ] };
			static constexpr std::size_t offset { entry.offset };
			static constexpr std::uint8_t size { entry.size };
			static constexpr auto bytes { [ ] ( )->UnsignedBits<size * 8>
			{
				/* */if constexpr ( size == 1 )return *elements [ offset ].byte;
				else if constexpr ( size == 2 )return Bytes::concat<std::uint16_t> ( *elements [ offset ].byte, *elements [ offset + 1 ].byte );
				else if constexpr ( size == 4 )return Bytes::concat<std::uint32_t> ( *elements [ offset ].byte, *elements [ offset + 1 ].byte, *elements [ offset + 2 ].byte, *elements [ offset + 3 ].byte );
				else if constexpr ( size == 8 )return Bytes::concat<std::uint64_t> ( *elements [ offset ].byte, *elements [ offset + 1 ].byte, *elements [ offset + 2 ].byte, *elements [ offset + 3 ].byte, *elements [ offset + 4 ].byte, *elements [ offset + 5 ].byte, *elements [ offset + 6 ].byte, *elements [ offset + 7 ].byte );
			}( ) };
			return *reinterpret_cast< const decltype( bytes )* >( ptr + offset ) == bytes;
		}
		template<auto I, $Size<1> Uint8>
		Inline static constexpr bool cmpNibbleEntry ( Uint8* ptr )noexcept {
			static constexpr ComparisonEntryNibble entry { nibbleEntries [ I ] };
			static constexpr std::size_t offset { entry.offset };
			static constexpr Opt<std::uint8_t> low { entry.low };
			static constexpr Opt<std::uint8_t> high { entry.high };
			if constexpr ( low )
				return reinterpret_cast< const Nibbles* >( ptr + offset )->low == constant<*low>;
			else if constexpr ( high )
				return reinterpret_cast< const Nibbles* >( ptr + offset )->high == constant<*high>;
		}
		template<$Size<1> Uint8, auto...I, auto...J>
		Inline static constexpr bool isMatchImpl ( Uint8* ptr, std::index_sequence<I...>, std::index_sequence<J...> )noexcept {
			return ( cmpBytesEntries<I> ( ptr )&&... ) && ( cmpNibbleEntry<J> ( ptr )&&... );
		}
		template<$Size<1> Uint8>
		Inline static constexpr bool isMatch ( Uint8* ptr )noexcept {
			return isMatchImpl ( ptr, std::make_index_sequence<bytesEntries.size ( )>{}, std::make_index_sequence<nibbleEntries.size ( )>{} );
		}
		template<std::size_t...Indexes>
		static consteval auto deleteElement ( )noexcept {
			return Sequence<details::create_modified_array_for_sequence<Elements, Indexes...> ( )>{};
		}
	};
	template<FixedString str>
	constexpr ConstVector<Element, str.size ( )> parsePatternString ( )noexcept {
		constexpr auto isHexDigit { [ ] ( char c ) { return ( c >= '0' && c <= '9' ) || ( c >= 'a' && c <= 'f' ) || ( c >= 'A' && c <= 'F' ); } };
		constexpr auto char2hexDigit { [ ] ( char c )-> std::uint8_t
		{
			if ( c >= '0' && c <= '9' ) return c - '0';
			if ( c >= 'a' && c <= 'f' ) return c - 'a' + 10;
			if ( c >= 'A' && c <= 'F' ) return c - 'A' + 10;
			UNREACHABLE;
		} };
		constexpr std::size_t size { str.size ( ) };
		const char* pBegin { str.data ( ) };
		const char* pEnd { pBegin + size };
		ConstVector<Element, size> result;
		if constexpr ( size ) {
			bool expectSpace {};
			for ( const char* pChar { pBegin }; pChar != pEnd;) {
				const char c { *pChar };
				if ( c == ' ' ) {
					if ( !expectSpace )
						UNREACHABLE;
					++pChar;
					expectSpace = false;
				}
				else {
					if ( expectSpace )UNREACHABLE;
					if ( c == '?' ) {
						if ( pChar + 1 == pEnd ) {
							pChar += 1;
							result.push_back ( {} );
						}
						else {
							const char c1 { pChar [ 1 ] };
							if ( c1 == ' ' ) {
								pChar += 1;
								result.push_back ( {} );
							}
							else if ( c1 == '?' ) {
								pChar += 2;
								result.push_back ( {} );
							}
							else if ( isHexDigit ( c1 ) ) {
								result.push_back ( Element { char2hexDigit ( c1 ), {} } );
								pChar += 2;
							}
							else
								UNREACHABLE;
						}
					}
					else {
						if ( !isHexDigit ( c ) )UNREACHABLE;
						if ( pChar + 1 == pEnd ) {
							result.push_back ( char2hexDigit ( c ) );
							pChar += 1;
						}
						else {
							const char c1 { pChar [ 1 ] };
							if ( c1 == ' ' ) {
								result.push_back ( char2hexDigit ( c ) );
								pChar += 1;
							}
							else if ( c1 == '?' ) {
								result.push_back ( Element { {}, char2hexDigit ( c ) } );
								pChar += 2;
							}
							else if ( isHexDigit ( c1 ) ) {
								result.push_back ( static_cast< std::uint8_t >( char2hexDigit ( c ) * 0x10 + char2hexDigit ( c1 ) ) );
								pChar += 2;
							}
							else
								UNREACHABLE;
						}
					}
					expectSpace = true;
				}
			}
		}
		return result;
	}
	template<FixedString str>
	constexpr auto makeBytePattern ( )noexcept {
		constexpr ConstVector<Element, str.size ( )> arr { parsePatternString<str> ( ) };
		return [ = ]<auto...I>( std::index_sequence<I...> ) {
			return Sequence < std::array<Element, arr.size ( )>{arr [ I ]...} > {};
		}( std::make_index_sequence<arr.size ( )>{} );
	}
}
template<class Container, class T>concept LinearContainerOf = requires{ *( std::declval<Container> ( ).data ( ) + std::declval<Container> ( ).size ( ) ); }&& $Same<std::remove_cvref_t<decltype( *( std::declval<Container> ( ).data ( ) + std::declval<Container> ( ).size ( ) ) )>, std::remove_cvref_t<T>>;
template<class Container, class...Ts>concept LinearContainerAnyOf = ( LinearContainerOf<Container, Ts> || ... );
template<class T>concept $UInt = std::is_integral_v<std::remove_cvref_t<T>> && std::is_unsigned_v<std::remove_cvref_t<T>>;
namespace Bits
{
	template <$UInt T>Inline constexpr T clearLowestBit ( T value ) noexcept { return value & ( value - 1 ); }
	//Returns the number of trailing 0-bits in x, starting at the least significant bit position. If x is 0, the result is undefined
	Inline constexpr std::uint32_t trailingZeroCount ( std::uint32_t x )noexcept {
	#if MSVC
		if ( std::is_constant_evaluated ( ) ) {
			if ( x == 0 ) return 32; // Defined behavior for 0 for ctz in C++20 is width.
			std::uint32_t count { 0 };
			while ( ( x & 1 ) == 0 && count < 32 ) {
				x >>= 1;
				++count;
			}
			return count;
		}
		else {
			unsigned long result;
			if ( _BitScanForward ( &result, x ) ) // _BitScanForward returns non-zero on success
				return static_cast< std::uint32_t > ( result );
			return 32; // If x is 0, result is undefined, _BitScanForward returns 0. Match C++20 __builtin_ctz.
		}
	#else
		return static_cast< std::uint32_t >( __builtin_ctz ( x ) );
	#endif
	}
}
#if MSVC
#define DEFINE_AVX_BYTES(name,x) static constexpr __m256i name{ .m256i_u8{x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x} }
#else
#define DEFINE_AVX_BYTES(name,x) static constexpr __m256i name{ __builtin_bit_cast(__m256i,std::array<std::uint8_t,32>{x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x}) }
#endif
namespace BytePattern
{
	template<auto pattern, std::intptr_t Offset>
	struct Scanner {
		using Pattern = decltype( pattern );
		static constexpr std::intptr_t offset { Offset };
		static constexpr std::size_t numElements { Pattern::numElements };
		static constexpr Opt<std::size_t> iFirstByte { [ ] ( )->Opt<std::size_t>
		{
			for ( std::size_t i{}; i < Pattern::elements.size ( ); ++i )
				if ( Pattern::elements [ i ].byte )
					return i;
			return {};
		}( ) };
		static constexpr Opt<std::size_t> iLastByte { [ ] ( )->Opt<std::size_t>
		{
			std::size_t result{Pattern::elements.size ( )};
			for ( std::size_t i{}; i < Pattern::elements.size ( ); ++i )
				if ( Pattern::elements [ i ].byte )
					result = i;
			if ( result == Pattern::elements.size ( ) )return {};
			else return result;
		}( ) };
		//bytes == 0, nibbles >= 1
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( !iFirstByte.has_value ( ) )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search_unbounded ( Uint8* pBegin, Action&&...action )noexcept//todo:optimize
		{
			for ( ;;) {
				if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
				{
					( action ( pBegin + offset ), ... );
					if constexpr ( sizeof...( action ) == 0 )
						return pBegin + offset;
				}
				++pBegin;
			}
		}
		//bytes == 1, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte == *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search_unbounded ( Uint8* pBegin, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			for ( ;; pBegin += sizeof ( __m256i ) ) {
				const __m256i block { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
				const __m256i eq { _mm256_cmpeq_epi8 ( first, block ) };
				for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( eq ) ) }; mask; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
				{
					const auto bitPos { Bits::trailingZeroCount ( mask ) };
					if ( decltype( Pattern::template deleteElement<iFirst> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
					{
						( action ( pBegin + bitPos + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + bitPos + offset;
					}
				}
			}
		}
		//bytes >= 2, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte != *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search_unbounded ( Uint8* pBegin, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			static constexpr auto iLast { compact<*iLastByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			DEFINE_AVX_BYTES ( last, *Pattern::elements [ iLast ].byte );
			for ( ;; pBegin += sizeof ( __m256i ) ) {
				const __m256i block_first { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
				const __m256i block_last { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iLast ) ) };
				const __m256i eq_first { _mm256_cmpeq_epi8 ( first, block_first ) };
				const __m256i eq_last { _mm256_cmpeq_epi8 ( last, block_last ) };
				for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( _mm256_and_si256 ( eq_first, eq_last ) ) ) }; mask != 0; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
				{
					const auto bitPos { Bits::trailingZeroCount ( mask ) };
					if ( decltype( Pattern::template deleteElement<iFirst, iLast> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
					{
						( action ( pBegin + bitPos + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + bitPos + offset;
					}
				}
			}
		}
		//bytes == 0, nibbles >= 1
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( !iFirstByte.has_value ( ) )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, std::size_t size, Action&&...action )noexcept//todo:optimize
		{
			if ( size >= numElements ) [[likely]]//prevent pEnd underflow
			{
				Uint8* const pEnd { pBegin + size - numElements };
				while ( pBegin <= pEnd ) [[likely]]
				{
					if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
					{
						( action ( pBegin + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + offset;
					}
					++pBegin;
				}
			}
			if constexpr ( sizeof...( action ) == 0 )
				return nullptr;
		}
		//bytes == 1, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte == *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, std::size_t size, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			if ( size >= numElements ) [[likely]]//prevent pEnd underflow
			{
				Uint8* const pEnd { pBegin + size - numElements };
				if ( numElements > 0 && size >= numElements + sizeof ( __m256i ) - 1 ) // Ensure pBegin + iFirst + (sizeof(__m256i) -1) is valid. More general: size >= iFirst + sizeof(__m256i) && size >= numElements
					// Simpler check: size >= iFirst + sizeof(__m256i)
					// Corrected check for loop: (pBegin + iFirst) should be readable up to (pBegin + iFirst + sizeof(__m256i) -1)
					// The loop runs as long as (pBegin + iFirst + sizeof(__m256i) -1) < (pBegin_orig + size).
					// And also pBegin <= pEnd.
					// A common way to write this is: pEndSimd = pBegin_orig + size - (iFirst + sizeof(__m256i)). Loop while pBegin <= pEndSimd.
					// But pBegin is also used for Pattern::isMatch, which reads up to pBegin + numElements -1.
					// So, pBegin + numElements -1 < pBegin_orig + size.
					// Let's use a conservative bound that satisfies both SIMD reads and scalar pattern matching.
					// For SIMD: pBegin + iFirst + sizeof(__m256i) <= pBegin_orig + size
					// For scalar: pBegin + numElements <= pBegin_orig + size
					// So pBegin must be <= pBegin_orig + size - max(iFirst + sizeof(__m256i), numElements)
					// The original condition was: size >= numElements + sizeof(__m256i). This implies pBegin <= pEndSimd where pEndSimd = pBegin_orig + size - numElements - sizeof(__m256i)
					// This is safe for pBegin in Pattern::isMatch. But is it safe for _mm256_loadu_si256(ptr + iFirst)?
					// pBegin + iFirst for _mm256_loadu_si256 should be fine if pBegin increments by sizeof(__m256i) and max pBegin in loop is pEndSimd.
					// Max address read by SIMD: pEndSimd + iFirst + sizeof(__m256i) - 1
					// = pBegin_orig + size - numElements - sizeof(__m256i) + iFirst + sizeof(__m256i) - 1
					// = pBegin_orig + size - numElements + iFirst - 1
					// This must be < pBegin_orig + size. So, size - numElements + iFirst - 1 < size --> iFirst < numElements + 1. (This is true if iFirst is a valid index)
					// The original condition `size >= numElements + sizeof(__m256i)` seems fine and conservative.
				{
					Uint8* const pEndSimd { pBegin + size - ( numElements > 0 ? numElements - 1 : 0 ) - sizeof ( __m256i ) }; // ensure pBegin + (numElements-1) is valid and pBegin + iFirst + sizeof(__m256i) -1 is valid
					for ( ; pBegin <= pEndSimd; pBegin += sizeof ( __m256i ) ) { // Check if pBegin + iFirst is safe for load
						const __m256i block { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
						const __m256i eq { _mm256_cmpeq_epi8 ( first, block ) };
						for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( eq ) ) }; mask; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
						{
							const auto bitPos { Bits::trailingZeroCount ( mask ) };
							if ( pBegin + bitPos <= pEnd ) { // Check candidate is not past pEnd
								if ( decltype( Pattern::template deleteElement<iFirst> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
								{
									( action ( pBegin + bitPos + offset ), ... );
									if constexpr ( sizeof...( action ) == 0 )
										return pBegin + bitPos + offset;
								}
							}
							else { // if bitPos would go past pEnd, subsequent bits also will.
								break;
							}
						}
					}
				}
				[[unlikely]]; // Fallthrough for remaining part or small sizes
				for ( ; pBegin <= pEnd; ++pBegin )
					if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
					{
						( action ( pBegin + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + offset;
					}
			}
			if constexpr ( sizeof...( action ) == 0 )
				return nullptr;
		}
		//bytes >= 2, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte != *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, std::size_t size, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			static constexpr auto iLast { compact<*iLastByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			DEFINE_AVX_BYTES ( last, *Pattern::elements [ iLast ].byte );
			if ( size >= numElements ) [[likely]]//prevent pEnd underflow
			{
				Uint8* const pEnd { pBegin + size - numElements };
				// Ensure reads for block_first and block_last are valid.
				// Max index read is iLast. So, pBegin + iLast + sizeof(__m256i) -1 must be < pBegin_orig + size
				// pBegin loop max: pBegin_orig + size - (iLast + sizeof(__m256i))
				// The loop needs pBegin <= pEndSimd.
				// pEndSimd should be pBegin_orig + size - std::max(numElements, iLast + (std::uint8_t)sizeof(__m256i)); (rough idea)
				// The original condition: size >= sizeof ( __m256i ) + iLast
				// This means pBegin_orig + size >= pBegin_orig + sizeof(__m256i) + iLast
				// So pEndSimd = pBegin_orig + size - (sizeof(__m256i) + iLast) is well-defined.
				// Max address read for block_last: (pEndSimd) + iLast + sizeof(__m256i) -1
				// = pBegin_orig + size - sizeof(__m256i) - iLast + iLast + sizeof(__m256i) -1 = pBegin_orig + size -1. This is safe.
				// Also need to ensure pBegin + bitPos <= pEnd for the scalar check.
				if ( size >= ( iLast + sizeof ( __m256i ) ) && size >= numElements ) [[likely]]
				{
					// Ensure pBegin for Pattern::isMatch never exceeds pEnd.
					// pBegin for SIMD can go up to a point where pBegin + iLast + sizeof(__m256i) -1 is the last byte of the buffer.
					// Max offset for SIMD read is iLast.
					Uint8* const pEndSimd { pBegin + size - ( iLast + sizeof ( __m256i ) ) };
					for ( ; pBegin <= pEndSimd; pBegin += sizeof ( __m256i ) ) [[likely]]
					{
						const __m256i block_first { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
						const __m256i block_last { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iLast ) ) };
						const __m256i eq_first { _mm256_cmpeq_epi8 ( first, block_first ) };
						const __m256i eq_last { _mm256_cmpeq_epi8 ( last, block_last ) };
						for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( _mm256_and_si256 ( eq_first, eq_last ) ) ) }; mask != 0; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
						{
							const auto bitPos { Bits::trailingZeroCount ( mask ) };
							if ( pBegin + bitPos <= pEnd ) { // Check candidate is not past pEnd
								if ( decltype( Pattern::template deleteElement<iFirst, iLast> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
								{
									( action ( pBegin + bitPos + offset ), ... );
									if constexpr ( sizeof...( action ) == 0 )
										return pBegin + bitPos + offset;
								}
							}
							else { // if bitPos would go past pEnd
								break;
							}
						}
					}
				}
				[[unlikely]]; // Fallthrough for remaining part or small sizes
				for ( ; pBegin <= pEnd; ++pBegin )
					if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
					{
						( action ( pBegin + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + offset;
					}
			}
			if constexpr ( sizeof...( action ) == 0 )
				return nullptr;
		}
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, Uint8* pEnd, Action&&...action )noexcept { return search ( pBegin, static_cast< std::size_t >( pEnd - pBegin ), FWD ( action )... ); } // Added FWD
		template<LinearContainerAnyOf<char, std::uint8_t> Container, Callable<void ( ElementOf<Container>* )>...Action>Inline static auto search ( Container&& bytes, Action&&...action )noexcept { return search ( bytes.data ( ), bytes.size ( ), FWD ( action )... ); } // Added FWD
	};
}
template<FixedString str, std::intptr_t offset = 0>constexpr BytePattern::Scanner<BytePattern::makeBytePattern<str> ( ), offset> byte_scanner {};
```

`emulator/emulator.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="src\change.cpp" />
    <ClCompile Include="src\emulator.cpp" />
    <ClCompile Include="src\exception.cpp" />
    <ClCompile Include="src\pch.cpp">
      <PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Create</PrecompiledHeader>
      <PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Create</PrecompiledHeader>
    </ClCompile>
    <ClCompile Include="src\utilities.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="src\sig_scanner.hpp" />
    <ClInclude Include="src\pch.hpp" />
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{377929f2-7380-4359-889e-d7c223d040e4}</ProjectGuid>
    <RootNamespace>emulator</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Release;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>BUILD_WINDOWS;_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.hpp</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <MultiProcessorCompilation>true</MultiProcessorCompilation>
      <RuntimeLibrary>MultiThreadedDebug</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>BUILD_WINDOWS;NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.hpp</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <MultiProcessorCompilation>true</MultiProcessorCompilation>
      <RuntimeLibrary>MultiThreaded</RuntimeLibrary>
      <EnableEnhancedInstructionSet>NotSet</EnableEnhancedInstructionSet>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
```

`emulator/emulator.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="src\emulator.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\utilities.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\change.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\pch.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\exception.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="src\pch.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
    <ClInclude Include="src\sig_scanner.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
  </ItemGroup>
</Project>
```

`emulator/src/change.cpp`:

```cpp
#include "pch.hpp"

InstructionEffect EmulationContext::log_effect ( capstone::Instruction& instr ) {
	return InstructionEffect { instr.to_string ( ), {} };
}

void EmulationContext::log_reg_change ( InstructionEffect& effect, x86_reg reg, uint64_t old_val, uint64_t new_val, const char* op ) {
	if ( !options.enable_logging ) {
		return;
	}
	effect.push_to_changes ( std::format ( "{} {} {:#x} (pv: {:#x})",
													 cs_reg_name ( decoder.back()->get_handle ( ), reg ), op, new_val, old_val ) );
}

void EmulationContext::log_reg_change ( InstructionEffect& effect, x86_reg reg, int128_t old_val, int128_t new_val, const char* op ) {
	if ( !options.enable_logging ) {
		return;
	}
	effect.push_to_changes ( std::format ( "{} {} {} (pv: {})",
													 cs_reg_name ( decoder.back()->get_handle ( ), reg ), op, new_val.convert_to<double> ( ), old_val.convert_to<double> ( ) ) );
}

void EmulationContext::log_flag_change ( InstructionEffect& effect, const char* flag, uint64_t old_val, uint64_t new_val ) {
	if ( !options.enable_logging ) {
		return;
	}
	effect.push_to_changes ( std::format ( "flags.{}={} (pv: {})", flag, new_val, old_val ) );
}

void EmulationContext::log_stack_change ( InstructionEffect& effect, int64_t addr, uint64_t old_val, uint64_t new_val, uint8_t size ) {
	if ( !options.enable_logging ) {
		return;
	}
	// Format the log message including the size of the write
	effect.push_to_changes ( std::format ( "[0x{:x}] ({}-byte) = {:#x} (was {:#x})", addr, size, new_val, old_val ) );
}

void InstructionEffect::push_to_changes ( const EmulationContext& ctx, const std::string& data ) {
	if constexpr ( STATE_TRACKING ) { // for better optimization
		if ( ctx.options.enable_logging ) {
			changes.emplace_back ( data );
		}
	}
}
void InstructionEffect::push_to_changes ( const EmulationContext* ctx, const std::string& data ) {
	if constexpr ( STATE_TRACKING ) { // for better optimization
		if ( ctx->options.enable_logging ) {
			changes.emplace_back ( data );
		}
	}
}

void InstructionEffect::push_to_changes ( const std::string& data ) {
	if constexpr ( STATE_TRACKING ) { // for better optimization
		changes.emplace_back ( data );
	}
}
```

`emulator/src/emulator.cpp`:

```cpp
#include <shared/context.hpp>
#include "sig_scanner.hpp"
#include "pch.hpp"

std::array<KGPR, X86_REG_ENDING> reg_map;
std::array<int, X86_REG_ENDING> avx_map {};

InstructionExceptionInfo g_instruction_exception_table [ X86_INS_ENDING ];

std::unique_ptr<PE::Parser> parser = nullptr;

constexpr int64_t KUSER_SHARED_DATA_BASE = 0x7FFE0000;
constexpr size_t KUSER_SHARED_DATA_SIZE = 2688; // 0xA80
constexpr int64_t KUSER_SHARED_DATA_END = KUSER_SHARED_DATA_BASE + KUSER_SHARED_DATA_SIZE;

bool EmulationContext::is_within_stack_bounds ( uint64_t address, uint8_t size ) const noexcept {
	const auto stack_base_addr = reinterpret_cast< uint64_t >( rsp_base.get ( ) );
	const auto stack_limit = stack_base_addr;
	const auto stack_top = stack_base_addr + stack_allocated;
	return ( address >= stack_limit && ( address + size ) <= stack_top );
}

uint64_t EmulationContext::get_access_mask ( x86_reg reg, uint8_t size ) const noexcept {
	switch ( size ) {
		case 8: return 0xFFFFFFFFFFFFFFFFULL;
		case 4: return 0x00000000FFFFFFFFULL;
		case 2:
			return 0x000000000000FFFFULL;
		case 1:
			if ( reg == X86_REG_CH || reg == X86_REG_DH || reg == X86_REG_BH || reg == X86_REG_AH )
				return 0x000000000000FF00ULL;
			return 0x00000000000000FFULL;
		default: return 0;
	}
}

uint8_t EmulationContext::get_access_shift ( x86_reg reg, uint8_t size ) const noexcept {
	if ( size == 1 ) {
		if ( reg == X86_REG_AH || reg == X86_REG_BH || reg == X86_REG_CH || reg == X86_REG_DH ) {
			return 8;
		}
	}
	return 0;
}

uint64_t EmulationContext::get_reg ( x86_reg reg, uint8_t size ) const {
	if ( reg == X86_REG_RIP ) {
		const auto current_instr_ip = decoder.back ( )->last_successful_ip ( );
		const auto current_instr_len = decoder.back ( )->last_successful_length ( );
		return current_instr_ip + current_instr_len;
	}

	const auto full_reg = reg_map [ reg ];
	const auto concrete_full = cpu->registers [ full_reg ];
	const auto access_mask = get_access_mask ( reg, size );
	const auto shift = get_access_shift ( reg, size );
	const auto extracted_value = ( concrete_full & access_mask ) >> shift;

	return extracted_value;
}

void EmulationContext::set_reg ( x86_reg reg, uint64_t val, uint8_t size, InstructionEffect& effect ) {
	const auto full_reg = reg_map [ reg ];
	uint64_t old_full_val_emu = cpu->registers [ full_reg ];

	const auto old_full_concrete = static_cast< uint64_t >( old_full_val_emu );
	const auto value_to_set = static_cast< uint64_t >( val );
	const auto access_mask = get_access_mask ( reg, size );
	const auto shift = get_access_shift ( reg, size );
	GET_OPERAND_MASK ( size_mask, size );

	uint64_t new_full_concrete;

	if ( size == 4 && ( full_reg >= KRAX && full_reg <= KR15 ) ) {
		new_full_concrete = static_cast< uint32_t >( value_to_set ); // Zero upper 32 bits
	}
	else {
		uint64_t shifted_value = ( value_to_set & size_mask ) << shift;
		new_full_concrete = ( old_full_concrete & ~access_mask ) | ( shifted_value & access_mask );
	}

	cpu->registers [ full_reg ] = new_full_concrete;

	if ( reg == X86_REG_RSP ) {
		cpu->rsp_offset = new_full_concrete - reinterpret_cast< uint64_t >( rsp_base.get ( ) );
	}
	if ( !effect.no_log ) {
		log_reg_change ( effect, reg, old_full_val_emu, new_full_concrete, "set" );
	}
}

uint64_t EmulationContext::get_stack ( uint64_t address, uint8_t size ) const {
	if ( !is_within_stack_bounds ( address, size ) ) {
		uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( );
		GuestExceptionInfo ex;
		ex.set_access_violation ( faulting_rip, address, false ); // Read violation outside stack
		throw ex;
	}

	return *( uint64_t* ) ( address );
}

uint128_t EmulationContext::get_stack_128 ( uint64_t address ) const {
	if ( !is_within_stack_bounds ( address, 16 ) ) {
		uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( );
		GuestExceptionInfo ex;
		ex.set_access_violation ( faulting_rip, address, false ); // Read violation outside stack
		throw ex;
	}

	return *( uint128_t* ) ( address );
}

void EmulationContext::set_stack ( uint64_t address, uint64_t val, InstructionEffect& effect, uint8_t size ) {
	if ( !is_within_stack_bounds ( address, size ) ) {
		uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( ); // RIP of instruction *causing* access
		GuestExceptionInfo ex;
		// Writing outside allocated stack region typically triggers Stack Overflow semantically
		ex.set_exception ( EXCEPTION_STACK_OVERFLOW, faulting_rip, address );
		throw ex;
	}

	void* ptr = reinterpret_cast< void* >( address );
	uint64_t old_val_preview = 0; // For logging
	if ( options.enable_logging ) { // Read old value only if logging
		memcpy ( &old_val_preview, ptr, size > 8 ? 8 : size ); // Preview up to 8 bytes
	}

	switch ( size ) {
		case 1: *static_cast< uint8_t* >( ptr ) = static_cast< uint8_t >( val ); break;
		case 2: *static_cast< uint16_t* >( ptr ) = static_cast< uint16_t >( val ); break;
		case 4: *static_cast< uint32_t* >( ptr ) = static_cast< uint32_t >( val ); break;
		case 8: *static_cast< uint64_t* >( ptr ) = val; break;
		default:
		{
			uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( );
			std::println ( "INTERNAL ERROR: Unsupported write size ({}) to stack @ 0x{:X}", size, address );
			GuestExceptionInfo ex;
			ex.set_exception ( 0xDEADBABE, faulting_rip );
			throw ex;
		}
	}

	// Log stack change uses a different function signature in context.hpp
		// log_stack_change(effect, address, old_val_preview, val, size); // Adapt if logging needed
	if ( options.enable_logging ) {
		effect.push_to_changes ( this, std::format ( "[STACK:0x{:016x}] = 0x{:x} (size={})", address, val, size ) );
	}
	effect.modified_mem.insert ( address );
}
void EmulationContext::set_stack_128 ( uint64_t address, uint128_t val, InstructionEffect& effect ) {
	if ( !is_within_stack_bounds ( address, 16 ) ) {
		uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( ); // RIP of instruction *causing* access
		GuestExceptionInfo ex;
		// Writing outside allocated stack region typically triggers Stack Overflow semantically
		ex.set_exception ( EXCEPTION_STACK_OVERFLOW, faulting_rip, address );
		throw ex;
	}

	void* ptr = reinterpret_cast< void* >( address );
	*( uint128_t* ) ptr = val;

	if ( options.enable_logging ) {
		effect.push_to_changes ( this, std::format ( "[STACK:0x{:016x}] = 0x{} (size=16)", address, val.str ( ) ) );
	}
	effect.modified_mem.insert ( address );
}

uint64_t dereference_by_size ( const uint8_t* ptr, size_t size ) noexcept {
	switch ( size ) {
		case 1: return static_cast< uint64_t >( *ptr );
		case 2: return static_cast< uint64_t >( *reinterpret_cast< const uint16_t* >( ptr ) );
		case 4: return static_cast< uint64_t >( *reinterpret_cast< const uint32_t* >( ptr ) );
		case 8: return *reinterpret_cast< const uint64_t* >( ptr );
		default:
			std::print ( "Unsupported read size {:#x} at KUSER_SHARED_DATA {:#x}h\n", size, reinterpret_cast< uint64_t >( ptr ) );
			return 0ULL;
	}
}
void EmulationContext::allocate_kuser_shared_data ( InstructionEffect& effect ) {
	if ( options.enable_logging ) {
		effect.push_to_changes ( this, std::format ( "KUSER_SHARED_DATA allocated at 0x{:016x}, ProcessorFeatures set at 0x{:016x}", KUSER_SHARED_DATA_BASE, KUSER_SHARED_DATA_BASE + 0x3C0 ) );
	}
}

void EmulationContext::set_rcx_to_ioport ( uint16_t port, InstructionEffect& effect ) {
	uint64_t port_value = windows->io_ports.count ( port ) ? windows->io_ports [ port ] : 0;
	set_reg ( X86_REG_RCX, port_value, 8, effect );
	if ( options.enable_logging ) {
		effect.push_to_changes ( this, std::format ( "RCX set to I/O port 0x{:04x} value: 0x{:x}", port, port_value ) );
	}
}
uint64_t EmulationContext::get_memory ( uint64_t addr, uint8_t size ) const {
	uint64_t faulting_rip = 0;
	if ( decoder.back ( )->last_successful_ip ( ) != 0 && decoder.back ( )->last_successful_ip ( ) < 0x7FFFFFFFFFFF ) {
		faulting_rip = decoder.back ( )->last_successful_ip ( );
	}

	if ( addr < 0x1000 ) {
		GuestExceptionInfo ex;
		ex.set_access_violation ( faulting_rip, addr, false );
		throw ex;
	}

	if ( addr >= KUSER_SHARED_DATA_BASE && addr < KUSER_SHARED_DATA_END ) {
		return *( uint64_t* ) addr;
	}

	if ( is_within_stack_bounds ( addr, size ) ) {
		return get_stack ( addr, size );
	}

	// Loaded Modules Check
	for ( const auto& [base, mod] : windows->loaded_modules ) {
		if ( addr >= mod.base_address && addr < mod.base_address + mod.size ) {
			if ( addr + size > mod.base_address + mod.size ) {
				GuestExceptionInfo ex;
				ex.set_access_violation ( faulting_rip, addr, false );
				throw ex;
			}
			try {
				const uint8_t* ptr = reinterpret_cast< const uint8_t* >( addr );
				return dereference_by_size ( ptr, size );
			}
			catch ( ... ) {
				GuestExceptionInfo ex;
				ex.set_access_violation ( faulting_rip, addr, false );
				throw ex;
			}
		}
	}
	if ( !IsBadReadPtr ( reinterpret_cast< const void* >( addr ), 8 ) ) {
		auto value = *( uint64_t* ) addr;
		return value;
	}

	GuestExceptionInfo ex;
	ex.set_access_violation ( faulting_rip, addr, false );
	throw ex;
}

void EmulationContext::set_memory ( uint64_t addr, uint64_t val, uint8_t size, InstructionEffect& effect ) {
	uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( );

	if ( addr < 0x1000 ) {
		GuestExceptionInfo ex;
		ex.set_access_violation ( faulting_rip, addr, true );
		throw ex;
	}

	if ( is_within_stack_bounds ( addr, size ) ) {
		return set_stack ( addr, val, effect, size );
	}

	if ( IsBadWritePtr ( ( void* ) addr, size ) ) {
		GuestExceptionInfo ex;
		ex.set_access_violation ( faulting_rip, addr, true );
		throw ex;
	}

	try {
		void* ptr = reinterpret_cast< void* >( addr );
		uint64_t old_val_preview = 0;
		if ( options.enable_logging ) memcpy ( &old_val_preview, ptr, size > 8 ? 8 : size );

		switch ( size ) {
			case 1: *static_cast< uint8_t* >( ptr ) = static_cast< uint8_t >( val ); break;
			case 2: *static_cast< uint16_t* >( ptr ) = static_cast< uint16_t >( val ); break;
			case 4: *static_cast< uint32_t* >( ptr ) = static_cast< uint32_t >( val ); break;
			case 8: *static_cast< uint64_t* >( ptr ) = val; break;
			default:
			{
				std::println ( "INTERNAL ERROR: Unsupported write size ({}) to module memory @ 0x{:X}", size, addr );
				GuestExceptionInfo ex;
				ex.set_exception ( 0xDEADBABE, faulting_rip );
				throw ex;
			}
		}

		if ( options.enable_logging ) {
			effect.push_to_changes ( this, std::format ( "[MODULE:0x{:016x}] = 0x{:x} (size={})", addr, val, size ) );
		}
		windows->memory_writes [ addr ].push_back ( val );
		return;

	}
	catch ( ... ) {
		GuestExceptionInfo ex;
		ex.set_access_violation ( faulting_rip, addr, true );
		throw ex;
	}
	GuestExceptionInfo ex;
	ex.set_access_violation ( faulting_rip, addr, true );
	throw ex;
}

void EmulationContext::allocate_stack ( int64_t size, InstructionEffect& effect ) noexcept {
	uint64_t old_rsp = get_reg ( X86_REG_RSP );
	uint64_t new_rsp = old_rsp - static_cast< uint64_t >( size );
	set_reg ( X86_REG_RSP, new_rsp, 8, effect );

	stack_allocated += size;
	if ( options.enable_logging ) {
		effect.changes.push_back (
				std::format ( "allocate_stack: reserved {} bytes, newstate.rsp_offset= {}", size, cpu->rsp_offset )
		);
	}
}


void EmulationContext::increment_tsc ( ) {
	cpu->tsc += 3;
}

void EmulationContext::push_call_frame ( uint64_t ret_addr, InstructionEffect& effect ) {
	CallFrame frame {};
	frame.rsp_before_call = get_reg ( X86_REG_RSP ); // RSP *after* CALL pushed ret addr
	frame.return_addr = ret_addr;

	call_stack.push_back ( frame );
	if ( options.enable_logging ) {
		effect.push_to_changes ( this, std::format ( "Pushed call frame: return addr=0x{:016x}, RSP_after_push=0x{:016x}", ret_addr, frame.rsp_before_call ) );
	}
}

void EmulationContext::pop_call_frame ( InstructionEffect& effect ) {
	if ( call_stack.empty ( ) ) {
		std::println ( "Pop call frame with empty call stack (allowed)" );
		if ( options.enable_logging ) {
			effect.push_to_changes ( this, "Pop call frame with empty call stack" );
		}
		return;
	}

	CallFrame frame = call_stack.back ( );
	call_stack.pop_back ( );

	if ( options.enable_logging ) {
		effect.push_to_changes ( this, std::format ( "Popped call frame: return addr=0x{:016x}", frame.return_addr ) );
	}
}

uint32_t EmulationContext::get_eflags ( ) const noexcept {
	uint32_t eflags = 0;
	const auto& flags = cpu->cpu_flags.flags;

	eflags |= ( flags.CF & 1 );
	eflags |= ( options.allow_reserved_write ? flags.reserved1 : 1 ) << 1;
	eflags |= flags.PF << 2;
	eflags |= ( options.allow_reserved_write ? flags.reserved2 : 0 ) << 3;
	eflags |= flags.AF << 4;
	eflags |= ( options.allow_reserved_write ? flags.reserved3 : 1 ) << 5;
	eflags |= flags.ZF << 6;
	eflags |= flags.SF << 7;
	eflags |= flags.TF << 8;
	eflags |= flags.IF << 9;
	eflags |= flags.DF << 10;
	eflags |= flags.OF << 11;
	eflags |= flags.IOPL << 12;
	eflags |= flags.NT << 14;
	eflags |= ( options.allow_reserved_write ? flags.reserved4 : 0 ) << 15;
	eflags |= flags.RF << 16;
	eflags |= flags.VM << 17;
	eflags |= flags.AC << 18;
	eflags |= flags.VIF << 19;
	eflags |= flags.VIP << 20;
	eflags |= flags.ID << 21;
	eflags |= flags.reserved5 << 22;
	return eflags;
}

uint64_t EmulationContext::get_rflags ( ) const noexcept {
	const auto& flags = cpu->cpu_flags.flags;
	return ( uint64_t ( flags.CF & 1 ) ) |
		( uint64_t ( options.allow_reserved_write ? flags.reserved1 : 1 ) << 1 ) |  // Reserved1 always 1
		( uint64_t ( flags.PF ) << 2 ) |
		( uint64_t ( options.allow_reserved_write ? flags.reserved2 : 0 ) << 3 ) |  // Reserved2 always 0
		( uint64_t ( flags.AF ) << 4 ) |
		( uint64_t ( options.allow_reserved_write ? flags.reserved3 : 0 ) << 5 ) |  // Reserved3 always 0
		( uint64_t ( flags.ZF ) << 6 ) |
		( uint64_t ( flags.SF ) << 7 ) |
		( uint64_t ( flags.TF ) << 8 ) |
		( uint64_t ( flags.IF ) << 9 ) |
		( uint64_t ( flags.DF ) << 10 ) |
		( uint64_t ( flags.OF ) << 11 ) |
		( uint64_t ( flags.IOPL ) << 12 ) |
		( uint64_t ( flags.NT ) << 14 ) |
		( uint64_t ( options.allow_reserved_write ? flags.reserved4 : 0 ) << 15 ) |  // Reserved4 always 0
		( uint64_t ( flags.RF ) << 16 ) |
		( uint64_t ( flags.VM ) << 17 ) |
		( uint64_t ( flags.AC ) << 18 ) |
		( uint64_t ( flags.VIF ) << 19 ) |
		( uint64_t ( flags.VIP ) << 20 ) |
		( uint64_t ( flags.ID ) << 21 ) |
		( uint64_t ( flags.reserved5 ) << 22 ) |
		( uint64_t ( flags.reserved6 ) << 32 );
}

void EmulationContext::set_rflags ( uint64_t rflags, InstructionEffect& effect ) noexcept {
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF;
	uint64_t old_PF = flags.PF;
	uint64_t old_AF = flags.AF;
	uint64_t old_ZF = flags.ZF;
	uint64_t old_SF = flags.SF;
	uint64_t old_TF = flags.TF;
	uint64_t old_IF = flags.IF;
	uint64_t old_DF = flags.DF;
	uint64_t old_OF = flags.OF;
	uint64_t old_AC = flags.AC;

	flags.CF = ( rflags >> 0 ) & 1;  
	flags.PF = ( rflags >> 2 ) & 1;  
	flags.AF = ( rflags >> 4 ) & 1;  
	flags.ZF = ( rflags >> 6 ) & 1;  
	flags.SF = ( rflags >> 7 ) & 1;  
	flags.TF = ( rflags >> 8 ) & 1;  
	flags.DF = ( rflags >> 10 ) & 1; 
	flags.OF = ( rflags >> 11 ) & 1; 
	flags.AC = ( rflags >> 18 ) & 1; 
	if ( options.allow_reserved_write ) {
		flags.reserved1 = ( rflags >> 1 ) & 1;
		flags.reserved2 = ( rflags >> 3 ) & 1;
		flags.reserved3 = ( rflags >> 5 ) & 1;
		flags.reserved4 = ( rflags >> 15 ) & 1;
		flags.reserved5 = ( rflags >> 22 ) & 0x3FF;
		flags.reserved6 = ( rflags >> 32 ) & 0xFFFFFFFF;
	}

	if ( cpu->current_privilege_level == 0 ) {
		if ( cpu->current_privilege_level <= flags.IOPL ) {
			uint64_t old_IF = flags.IF;
			flags.IF = ( rflags >> 9 ) & 1;
			if ( old_IF != flags.IF ) log_flag_change ( effect, "IF", old_IF, flags.IF );
		}

		flags.IOPL = ( rflags >> 12 ) & 3;  
		flags.NT = ( rflags >> 14 ) & 1;    
		flags.RF = ( rflags >> 16 ) & 1;    
		flags.VM = ( rflags >> 17 ) & 1;    
		flags.VIF = ( rflags >> 19 ) & 1;   
		flags.VIP = ( rflags >> 20 ) & 1;   
		if ( options.allow_reserved_write ) {
			flags.ID = ( rflags >> 21 ) & 1;
		}
	}

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_AF != flags.AF ) log_flag_change ( effect, "AF", old_AF, flags.AF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_TF != flags.TF ) log_flag_change ( effect, "TF", old_TF, flags.TF );
	if ( old_DF != flags.DF ) log_flag_change ( effect, "DF", old_DF, flags.DF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AC != flags.AC ) log_flag_change ( effect, "AC", old_AC, flags.AC );
}

void EmulationContext::set_eflags ( uint32_t eflags, InstructionEffect& effect ) noexcept {
	set_rflags ( eflags, effect );
}
#include <Windows.h>
#include <semantics/src/pch.hpp>

#define CONTEXT_X86_MAIN           0x00010000
#define CONTEXT_AMD64_MAIN         0x100000
#define CONTEXT_CONTROL_32         (CONTEXT_X86_MAIN | 0x1L)
#define CONTEXT_CONTROL_64         (CONTEXT_AMD64_MAIN | 0x1L)
#define CONTEXT_INTEGER_32         (CONTEXT_X86_MAIN | 0x2L)
#define CONTEXT_INTEGER_64         (CONTEXT_AMD64_MAIN | 0x2L)
#define CONTEXT_SEGMENTS_32        (CONTEXT_X86_MAIN | 0x4L)
#define CONTEXT_SEGMENTS_64        (CONTEXT_AMD64_MAIN | 0x4L)
#define CONTEXT_FLOATING_POINT_32  (CONTEXT_X86_MAIN | 0x8L)
#define CONTEXT_FLOATING_POINT_64  (CONTEXT_AMD64_MAIN | 0x8L)
#define CONTEXT_DEBUG_REGISTERS_32 (CONTEXT_X86_MAIN | 0x10L)
#define CONTEXT_DEBUG_REGISTERS_64 (CONTEXT_AMD64_MAIN | 0x10L)
#define CONTEXT_XSTATE_32          (CONTEXT_X86_MAIN | 0x20L)
#define CONTEXT_XSTATE_64          (CONTEXT_AMD64_MAIN | 0x20L)

#define CONTEXT64_ALL                                                                            \
    (CONTEXT_CONTROL_64 | CONTEXT_INTEGER_64 | CONTEXT_SEGMENTS_64 | CONTEXT_FLOATING_POINT_64 | \
     CONTEXT_DEBUG_REGISTERS_64)
// thank you sogen!
void EmulationContext::save_context ( CONTEXT* context ) {
	if ( ( context->ContextFlags & CONTEXT_DEBUG_REGISTERS_64 ) == CONTEXT_DEBUG_REGISTERS_64 ) {
		context->Dr0 = get_reg<uint64_t> ( x86_reg::X86_REG_DR0 );
		context->Dr1 = get_reg<uint64_t> ( x86_reg::X86_REG_DR1 );
		context->Dr2 = get_reg<uint64_t> ( x86_reg::X86_REG_DR2 );
		context->Dr3 = get_reg<uint64_t> ( x86_reg::X86_REG_DR3 );
		context->Dr6 = get_reg<uint64_t> ( x86_reg::X86_REG_DR6 );
		context->Dr7 = get_reg<uint64_t> ( x86_reg::X86_REG_DR7 );
	}

	if ( ( context->ContextFlags & CONTEXT_CONTROL_64 ) == CONTEXT_CONTROL_64 ) {
		context->SegSs = get_reg<uint16_t> ( x86_reg::X86_REG_SS );
		context->SegCs = get_reg<uint16_t> ( x86_reg::X86_REG_CS );
		context->Rip = get_reg<uint64_t> ( x86_reg::X86_REG_RIP );
		context->Rsp = get_reg<uint64_t> ( x86_reg::X86_REG_RSP );
		context->EFlags = get_eflags ( );
	}

	if ( ( context->ContextFlags & CONTEXT_INTEGER_64 ) == CONTEXT_INTEGER_64 ) {
		context->Rax = get_reg<uint64_t> ( x86_reg::X86_REG_RAX );
		context->Rbx = get_reg<uint64_t> ( x86_reg::X86_REG_RBX );
		context->Rcx = get_reg<uint64_t> ( x86_reg::X86_REG_RCX );
		context->Rdx = get_reg<uint64_t> ( x86_reg::X86_REG_RDX );
		context->Rbp = get_reg<uint64_t> ( x86_reg::X86_REG_RBP );
		context->Rsi = get_reg<uint64_t> ( x86_reg::X86_REG_RSI );
		context->Rdi = get_reg<uint64_t> ( x86_reg::X86_REG_RDI );
		context->R8 = get_reg<uint64_t> ( x86_reg::X86_REG_R8 );
		context->R9 = get_reg<uint64_t> ( x86_reg::X86_REG_R9 );
		context->R10 = get_reg<uint64_t> ( x86_reg::X86_REG_R10 );
		context->R11 = get_reg<uint64_t> ( x86_reg::X86_REG_R11 );
		context->R12 = get_reg<uint64_t> ( x86_reg::X86_REG_R12 );
		context->R13 = get_reg<uint64_t> ( x86_reg::X86_REG_R13 );
		context->R14 = get_reg<uint64_t> ( x86_reg::X86_REG_R14 );
		context->R15 = get_reg<uint64_t> ( x86_reg::X86_REG_R15 );
	}

	if ( ( context->ContextFlags & CONTEXT_SEGMENTS_64 ) == CONTEXT_SEGMENTS_64 ) {
		context->SegDs = get_reg<uint16_t> ( x86_reg::X86_REG_DS );
		context->SegEs = get_reg<uint16_t> ( x86_reg::X86_REG_ES );
		context->SegFs = get_reg<uint16_t> ( x86_reg::X86_REG_FS );
		context->SegGs = get_reg<uint16_t> ( x86_reg::X86_REG_GS );
	}

	if ( ( context->ContextFlags & CONTEXT_FLOATING_POINT_64 ) == CONTEXT_FLOATING_POINT_64 ) {
		context->FltSave.ControlWord = cpu->fpu.fpu_control_word;
		context->FltSave.StatusWord = cpu->fpu.fpu_status_word;
		context->FltSave.TagWord = static_cast<BYTE>(cpu->fpu.fpu_tag_word);
		// windows float register types are incompatible with float80_t
		//for ( int i = 0; i < 8; i++ ) {
		//	const auto reg = static_cast< x86_register > ( static_cast< int > ( x86_reg::X86_REG_st0 ) + i );
		//	context.FltSave.FloatRegisters [ i ] = emu.reg<M128A> ( reg );
		//}
	}

	if ( ( context->ContextFlags & CONTEXT_INTEGER_64 ) == CONTEXT_INTEGER_64 ) {
		context->MxCsr = *reinterpret_cast<DWORD*>(&cpu->cpu_flags.mxcsr);
		for ( int i = 0; i < 16; i++ ) {
			const auto reg = static_cast< x86_reg > ( static_cast< int > ( x86_reg::X86_REG_XMM0 ) + i );
			const auto value = get_xmm_raw ( reg );
			M128A xmm {};
			xmm.Low = ( value & 0xFFFFFFFFFFFFFFFFULL ).convert_to<ULONGLONG> ( );
			xmm.High = ( value >> 64 ).convert_to<LONGLONG> ( );
			( &context->Xmm0 ) [ i ] = xmm;
		}
	}
}


template <typename T>
T& get_subword ( uint64_t& reg ) noexcept {
	static_assert( sizeof ( T ) <= sizeof ( uint64_t ), "Type too large for register" );
	return reinterpret_cast< T& >( reg );
}

template <typename T>
const T& EmulationContext::get_reg ( x86_reg reg ) const {
	static_assert( sizeof ( T ) <= sizeof ( uint64_t ), "this type does not fit in general purpose registers" );
	return reinterpret_cast< const T& >( this->cpu->registers [ reg_map [ reg ] ] );
}

template <typename T>
T& EmulationContext::get_reg_mut ( x86_reg reg ) {
	static_assert( sizeof ( T ) <= sizeof ( uint64_t ), "this type does not fit in general purpose registers" );
	return get_subword<T> ( this->cpu->registers [ reg_map [ reg ] ] );
}


uint128_t EmulationContext::get_xmm_raw ( x86_reg _reg ) const {
	auto reg = avx_map [ _reg ];
	uint512_t value = ( *cpu->avx_registers ) [ reg ];
	return value.convert_to<uint128_t> ( );
}

void EmulationContext::set_xmm_raw ( x86_reg _reg, const uint128_t& value, InstructionEffect& effect ) {
	auto reg = avx_map [ _reg ];
	( *cpu->avx_registers ) [ reg ] = value;
}

uint256_t EmulationContext::get_ymm_raw ( x86_reg _reg ) const {
	auto reg = avx_map [ _reg ];
	uint512_t value = ( *cpu->avx_registers ) [ reg ];
	return value.convert_to<uint256_t> ( );
}

void EmulationContext::set_ymm_raw ( x86_reg _reg, const uint256_t& value, InstructionEffect& effect ) {
	auto reg = avx_map [ _reg ];
	( *cpu->avx_registers ) [ reg ] = value;
}

uint512_t EmulationContext::get_zmm_raw ( x86_reg _reg ) const {
	auto reg = avx_map [ _reg ];
	uint512_t value = ( *cpu->avx_registers ) [ reg ];
	return value;
}

void EmulationContext::set_zmm_raw ( x86_reg _reg, const uint512_t& value, InstructionEffect& effect ) {
	auto reg = avx_map [ _reg ];
	( *cpu->avx_registers ) [ reg ] = value;
}

float EmulationContext::get_xmm_float ( x86_reg reg ) const {
	uint128_t raw = get_xmm_raw ( reg );
	uint32_t low_bits = static_cast< uint32_t >( raw & 0xFFFFFFFF );
	return std::bit_cast< float >( low_bits );
}

void EmulationContext::set_xmm_float ( x86_reg reg, float value, InstructionEffect& effect ) {
	uint128_t current_raw = get_xmm_raw ( reg );
	uint32_t new_low_bits = std::bit_cast< uint32_t >( value );
	current_raw = ( current_raw & ~uint128_t ( 0xFFFFFFFF ) ) | uint128_t ( new_low_bits );
	set_xmm_raw ( reg, current_raw, effect );
	effect.modified_regs.insert ( reg );
}

double EmulationContext::get_xmm_double ( x86_reg reg ) const {
	uint128_t raw = get_xmm_raw ( reg );
	uint64_t low_bits = static_cast< uint64_t >( raw & 0xFFFFFFFFFFFFFFFF );
	return std::bit_cast< double >( low_bits );
}

void EmulationContext::set_xmm_double ( x86_reg reg, double value, InstructionEffect& effect ) {
	uint128_t current_raw = get_xmm_raw ( reg );
	uint64_t new_low_bits = std::bit_cast< uint64_t >( value );
	current_raw = ( current_raw & ~uint128_t ( 0xFFFFFFFFFFFFFFFF ) ) | uint128_t ( new_low_bits );
	set_xmm_raw ( reg, current_raw, effect );
	effect.modified_regs.insert ( reg );
}

uint128_t EmulationContext::get_memory_128 ( uint64_t addr ) const {
	// Read low 64 bits, then high 64 bits
	uint64_t low = get_memory ( addr, 8 );
	uint64_t high = get_memory ( addr + 8, 8 );
	return ( uint128_t ( high ) << 64 ) | low;
}

void EmulationContext::set_memory_128 ( uint64_t addr, const uint128_t& val, InstructionEffect& effect ) {
	// Write low 64 bits, then high 64 bits
	uint64_t low = static_cast< uint64_t >( val & 0xFFFFFFFFFFFFFFFF );
	uint64_t high = static_cast< uint64_t >( val >> 64 );
	set_memory ( addr, low, 8, effect );
	set_memory ( addr + 8, high, 8, effect );
}

uint256_t EmulationContext::get_memory_256 ( uint64_t addr ) const {
	// Read four 64-bit chunks
	uint64_t p0 = get_memory ( addr + 0, 8 );
	uint64_t p1 = get_memory ( addr + 8, 8 );
	uint64_t p2 = get_memory ( addr + 16, 8 );
	uint64_t p3 = get_memory ( addr + 24, 8 );
	return ( uint256_t ( p3 ) << 192 ) | ( uint256_t ( p2 ) << 128 ) | ( uint256_t ( p1 ) << 64 ) | uint256_t ( p0 );
}

void EmulationContext::set_memory_256 ( uint64_t addr, const uint256_t& val, InstructionEffect& effect ) {
	// Write four 64-bit chunks
	uint64_t p0 = static_cast< uint64_t >( val & 0xFFFFFFFFFFFFFFFFULL );
	uint64_t p1 = static_cast< uint64_t >( ( val >> 64 ) & 0xFFFFFFFFFFFFFFFFULL );
	uint64_t p2 = static_cast< uint64_t >( ( val >> 128 ) & 0xFFFFFFFFFFFFFFFFULL );
	uint64_t p3 = static_cast< uint64_t >( ( val >> 192 ) & 0xFFFFFFFFFFFFFFFFULL );
	set_memory ( addr + 0, p0, 8, effect );
	set_memory ( addr + 8, p1, 8, effect );
	set_memory ( addr + 16, p2, 8, effect );
	set_memory ( addr + 24, p3, 8, effect );
}

uint512_t EmulationContext::get_memory_512 ( uint64_t addr ) const {
	// Read eight 64-bit chunks
	uint64_t p0 = get_memory ( addr + 0, 8 );
	uint64_t p1 = get_memory ( addr + 8, 8 );
	uint64_t p2 = get_memory ( addr + 16, 8 );
	uint64_t p3 = get_memory ( addr + 24, 8 );
	uint64_t p4 = get_memory ( addr + 32, 8 );
	uint64_t p5 = get_memory ( addr + 40, 8 );
	uint64_t p6 = get_memory ( addr + 48, 8 );
	uint64_t p7 = get_memory ( addr + 56, 8 );
	return ( uint512_t ( p7 ) << 448 ) | ( uint512_t ( p6 ) << 384 ) | ( uint512_t ( p5 ) << 320 ) | ( uint512_t ( p4 ) << 256 ) |
		( uint512_t ( p3 ) << 192 ) | ( uint512_t ( p2 ) << 128 ) | ( uint512_t ( p1 ) << 64 ) | uint512_t ( p0 );
}

void EmulationContext::set_memory_512 ( uint64_t addr, const uint512_t& val, InstructionEffect& effect ) {
	for ( int i = 0; i < 8; ++i ) {
		set_memory ( addr + ( i * 8 ), static_cast< uint64_t > ( ( val >> ( i * 64 ) ) & 0xFFFFFFFFFFFFFFFFULL ), 8, effect );
	}
}

static constexpr uint64_t CR0_AM_BIT = 1ULL << 18;
bool EmulationContext::is_alignment_check_enabled ( ) const noexcept {
	auto cr0_val = get_reg ( X86_REG_CR0, 8 );
	bool cr0_am = ( cr0_val & CR0_AM_BIT ) != 0;
	return cr0_am && cpu->cpu_flags.flags.AC && cpu->current_privilege_level == 3;
}

float80_t EmulationContext::read_float80_from_memory ( uint64_t addr, InstructionEffect& effect ) {
	uint64_t significand_bits = get_memory ( addr, 8 );
	uint16_t exponent_sign_bits = static_cast< uint16_t >( get_memory ( addr + 8, 2 ) );

	bool sign = ( exponent_sign_bits >> 15 ) & 1;
	int16_t exponent_raw = exponent_sign_bits & 0x7FFF;

	if ( exponent_raw == 0x7FFF ) {
		bool is_quiet_nan = ( significand_bits >> 62 ) & 1;
		if ( ( ( significand_bits >> 63 ) & 1 ) == 0 && significand_bits << 1 == 0 ) {
			// Intel Manual Vol 1, Section 8.3.7 differentiates Inf from NaN this way.
			return sign ? -std::numeric_limits<float80_t>::infinity ( ) : std::numeric_limits<float80_t>::infinity ( );
		}
		else {
			return std::numeric_limits<float80_t>::quiet_NaN ( );
		}
	}
	else if ( exponent_raw == 0 ) {
		if ( significand_bits == 0 ) {
			return float80_t ( 0.0 ); // Loses sign info potentially
		}
		else {
			int exponent_unbiased = 1 - 16383;
			float80_t significand_val = significand_bits;
			significand_val /= boost::multiprecision::pow ( float80_t ( 2 ), 64 );
			float80_t result = boost::multiprecision::ldexp ( significand_val, exponent_unbiased );
			return sign ? -result : result;
		}
	}
	else {
		if ( !( ( significand_bits >> 63 ) & 1 ) ) {
			effect.push_to_changes ( *this, "Warning: Reading potentially invalid 80-bit normalized number (integer bit is 0)" );
		}
		int exponent_unbiased = exponent_raw - 16383; // Unbias exponent
		float80_t significand_val = significand_bits;
		significand_val /= boost::multiprecision::pow ( float80_t ( 2 ), 63 );
		float80_t result = boost::multiprecision::ldexp ( significand_val, exponent_unbiased );
		return sign ? -result : result;
	}
}

void EmulationContext::write_float80_to_memory ( uint64_t addr, const float80_t& val, InstructionEffect& effect ) {
	using namespace boost::multiprecision;

	uint64_t significand_bits = 0;
	uint16_t exponent_sign_bits = 0;
	bool sign = val < 0;

	int classification = fpclassify ( val );

	if ( classification == FP_INFINITE ) {
		exponent_sign_bits = 0x7FFF;
		significand_bits = 0x8000000000000000ULL;
	}
	else if ( classification == FP_NAN ) {
		exponent_sign_bits = 0x7FFF;
		significand_bits = 0xC000000000000000ULL;
	}
	else if ( classification == FP_ZERO ) {
		exponent_sign_bits = 0;
		significand_bits = 0;
	}
	else {
		int exponent_unbiased;
		float80_t significand_normalized = frexp ( val, &exponent_unbiased );

		int exponent_biased = exponent_unbiased + 16383 - 1; // Adjust exponent and bias. -1 because frexp gives [0.5, 1)

		if ( exponent_biased <= 0 ) { // Denormal or underflowed to zero (Zero already handled)
			// Denormal case: Adjust exponent and shift significand
			exponent_biased = 0; // Exponent field is 0
			// Significand = M * 2^(exponent_unbiased) * 2^(64 - (1-16383))
			// This requires careful scaling to get the raw bits with implicit integer bit 0
			float80_t scaled_sig = ldexp ( val, 64 - ( 1 - 16383 ) ); // Scale denormal value appropriately
			significand_bits = scaled_sig.convert_to<uint64_t> ( ); // Approximate conversion

			effect.push_to_changes ( *this, "Warning: Writing denormal 80-bit float - precision may be lost." );

		}
		else if ( exponent_biased >= 0x7FFF ) { // Overflow (Infinity already handled)
			// Should not happen if Infinity case was correct
			exponent_sign_bits = 0x7FFF;
			significand_bits = 0x8000000000000000ULL;
			effect.push_to_changes ( *this, "Warning: Overflow during 80-bit float write conversion." );
		}
		else { // Normalized Case
			// Scale significand M (in [0.5, 1.0)) to have explicit integer bit 1 at position 63
			// M * 2^64 should yield the significand bits directly if M is in [0.5, 1.0)
			float80_t scaled_significand = ldexp ( significand_normalized, 64 );
			significand_bits = scaled_significand.convert_to<uint64_t> ( );
			// Ensure explicit integer bit is set (it should be by frexp/ldexp)
			significand_bits |= ( 1ULL << 63 );
			exponent_sign_bits = static_cast< uint16_t >( exponent_biased );
		}
	}

	// Set the sign bit
	if ( sign ) {
		exponent_sign_bits |= ( 1 << 15 );
	}

	// Write the 10 bytes
	set_memory ( addr, significand_bits, 8, effect );
	set_memory ( addr + 8, exponent_sign_bits, 2, effect );
}

void EmulationContext::initialize_exception_table ( ) noexcept {
	// --- Data Movement Instructions ---
	// MOV (mem read/write, alignment checks, FS/GS possible)
	g_instruction_exception_table [ X86_INS_MOV ] = {
			.categories = {.MEMORY = true, .ALIGNMENT = true }
			// Note: MOV to/from CRn/DRn/Segment Regs is privileged
	};
	g_instruction_exception_table [ X86_INS_MOVABS ] = { // MOVABS reg, imm (no mem)
			.categories = {}
	};
	g_instruction_exception_table [ X86_INS_MOVAPS ] = { // SSE aligned move (mem read/write, intrinsic align, SSE state)
			.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
			.is_sse_avx_related = true, .requires_intrinsic_alignment = true, .intrinsic_alignment_bytes = 16
	};
	g_instruction_exception_table [ X86_INS_MOVUPS ] = { // SSE unaligned move (mem read/write, AC align possible, SSE state)
			.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
			.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_MOVQ ] = { // MMX/SSE64 move (mem read/write, AC align possible, MMX/SSE state)
		 .categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
		 .is_mmx_related = true, .is_sse_avx_related = true // Can target GP or XMM/MMX
	};
	g_instruction_exception_table [ X86_INS_MOVZX ] = { // Zero-extend move (mem read possible, alignment)
			.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_MOVSX ] = { // Sign-extend move (mem read possible, alignment)
		 .categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_MOVSXD ] = { // Sign-extend doubleword to quadword (mem read possible, alignment)
			.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_PUSH ] = { // Stack write, maybe mem read, stack align/bounds
			.categories = {.MEMORY = true, .STACK = true, .ALIGNMENT = true },
			.is_explicit_push = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_PUSHFQ ] = { // Stack write, stack align/bounds
			.categories = {.STACK = true, .ALIGNMENT = true },
			.is_explicit_push = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_POP ] = { // Stack read, maybe mem write, stack align/bounds
			.categories = {.MEMORY = true, .STACK = true, .ALIGNMENT = true },
			.is_explicit_pop = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_POPFQ ] = { // Stack read, stack align/bounds, potentially privileged flag changes
			.categories = {.STACK = true, .ALIGNMENT = true }, // Add INVALID_USAGE if simulating privilege checks for flags like IF/IOPL
			.is_explicit_pop = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_LEA ] = { // Address calculation, no memory access itself, but uses mem operand syntax
			.categories = {.MEMORY = true } // Category needed to trigger FS/GS NULL check if used in address
	};
	g_instruction_exception_table [ X86_INS_SAHF ] = { // Loads AH into flags
			.categories = {}
	};
	g_instruction_exception_table [ X86_INS_LAHF ] = { // Stores flags into AH
			.categories = {}
	};
	g_instruction_exception_table [ X86_INS_XCHG ] = { // Mem read/write, alignment, lock possible
			.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true },
			.lock_prefix_allowed = true
	};
	// STOS variants (mem write, use RDI/ES, REP prefix interaction)
	g_instruction_exception_table [ X86_INS_STOSB ] =
		g_instruction_exception_table [ X86_INS_STOSW ] =
		g_instruction_exception_table [ X86_INS_STOSD ] =
		g_instruction_exception_table [ X86_INS_STOSQ ] = {
				.categories = {.MEMORY = true, .ALIGNMENT = true }, // Uses ES:RDI implicitly, host OS handles segment violation
				.uses_string_registers = true
				// REP prefix handling is usually dynamic
	};
	// MOVS variants (mem read/write, use RSI/DS, RDI/ES, REP prefix interaction)
	g_instruction_exception_table [ X86_INS_MOVSB ] =
		g_instruction_exception_table [ X86_INS_MOVSW ] =
		g_instruction_exception_table [ X86_INS_MOVSD ] = // Note: MOVSD is also SSE double scalar move
		g_instruction_exception_table [ X86_INS_MOVSQ ] = {
				.categories = {.MEMORY = true, .ALIGNMENT = true }, // Uses DS:RSI, ES:RDI
				.uses_string_registers = true
	};
	// SSE MOVSD (Scalar Double)
	g_instruction_exception_table [ X86_INS_MOVSD ] = { // Overwrite string op entry if capstone ID conflicts
			.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
			.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_MOVSS ] = { // SSE scalar single
			.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
			.is_sse_avx_related = true
	};


	// --- Arithmetic Instructions ---

	g_instruction_exception_table [ X86_INS_ADD ] =
		g_instruction_exception_table [ X86_INS_ADC ] =
		g_instruction_exception_table [ X86_INS_SUB ] =
		g_instruction_exception_table [ X86_INS_SBB ] =
		g_instruction_exception_table [ X86_INS_XADD ] = { // Mem read/write possible, alignment, lock possible
				.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true },
				.lock_prefix_allowed = true
	};
	g_instruction_exception_table [ X86_INS_INC ] =
		g_instruction_exception_table [ X86_INS_DEC ] =
		g_instruction_exception_table [ X86_INS_NEG ] = { // Mem read/write possible, alignment, lock possible
				.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true},
				.lock_prefix_allowed = true
	};
	g_instruction_exception_table [ X86_INS_MUL ] = { // Mem read possible, alignment
			.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_IMUL ] = { // Mem read possible, alignment
			.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_DIV ] =
		g_instruction_exception_table [ X86_INS_IDIV ] = { // Mem read possible, alignment, divide error
				.categories = {.MEMORY = true, .ARITHMETIC = true, .ALIGNMENT = true },
				.is_divide = true
	};
	g_instruction_exception_table [ X86_INS_CDQ ] =
		g_instruction_exception_table [ X86_INS_CWD ] = // AX -> DX:AX
		g_instruction_exception_table [ X86_INS_CBW ] = // AL -> AX
		g_instruction_exception_table [ X86_INS_CWDE ] = // AX -> EAX
		g_instruction_exception_table [ X86_INS_CDQE ] = // EAX -> RAX
		g_instruction_exception_table [ X86_INS_CQO ] = { // RAX -> RDX:RAX
				.categories = {}
	};

	// --- SSE Arithmetic ---
	g_instruction_exception_table [ X86_INS_ADDSS ] =
		g_instruction_exception_table [ X86_INS_SUBSS ] =
		g_instruction_exception_table [ X86_INS_MULSS ] =
		g_instruction_exception_table [ X86_INS_DIVSS ] =
		g_instruction_exception_table [ X86_INS_MINSS ] =
		g_instruction_exception_table [ X86_INS_MAXSS ] =
		g_instruction_exception_table [ X86_INS_SQRTSS ] =
		g_instruction_exception_table [ X86_INS_RCPSS ] =
		g_instruction_exception_table [ X86_INS_RSQRTSS ] = { // Mem read possible, align, SIMD FP state/exceptions
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_ADDSD ] = // Add scalar double (if ID different from MOVS)
		g_instruction_exception_table [ X86_INS_SUBSD ] =
		g_instruction_exception_table [ X86_INS_MULSD ] =
		g_instruction_exception_table [ X86_INS_DIVSD ] =
		g_instruction_exception_table [ X86_INS_MINSD ] =
		g_instruction_exception_table [ X86_INS_MAXSD ] =
		g_instruction_exception_table [ X86_INS_SQRTSD ] = {
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};

	// --- SSE Comparisons ---
	g_instruction_exception_table [ X86_INS_CMPSS ] =
		g_instruction_exception_table [ X86_INS_COMISS ] =
		g_instruction_exception_table [ X86_INS_UCOMISS ] = { // Mem read possible, align, SIMD FP state/exceptions
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_CMPSD ] = // Add if ID different
		g_instruction_exception_table [ X86_INS_COMISD ] =
		g_instruction_exception_table [ X86_INS_UCOMISD ] = {
			 .categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
			 .is_sse_avx_related = true
	};

	// --- SSE Conversions ---
	g_instruction_exception_table [ X86_INS_CVTSI2SS ] = // Mem read possible (int source), align, SIMD FP state
		g_instruction_exception_table [ X86_INS_CVTSI2SD ] = {
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_CVTSS2SI ] = // Mem read possible (float source), align, SIMD FP state
		g_instruction_exception_table [ X86_INS_CVTSD2SI ] =
		g_instruction_exception_table [ X86_INS_CVTTSS2SI ] = // Truncating versions
		g_instruction_exception_table [ X86_INS_CVTTSD2SI ] = {
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_CVTSS2SD ] =
		g_instruction_exception_table [ X86_INS_CVTSD2SS ] = { // Mem read possible, align, SIMD FP state
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};

	// --- SSE Logical/Util ---
	g_instruction_exception_table [ X86_INS_ANDPS ] =
		g_instruction_exception_table [ X86_INS_ANDNPS ] = // Add if needed
		g_instruction_exception_table [ X86_INS_ORPS ] =
		g_instruction_exception_table [ X86_INS_XORPS ] = { // Mem read possible, align, SSE state (#NM)
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true }, // FPU_SIMD for #NM check
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_ANDPD ] = // Add if needed
		g_instruction_exception_table [ X86_INS_ANDNPD ] = // Add if needed
		g_instruction_exception_table [ X86_INS_ORPD ] = // Add if needed
		g_instruction_exception_table [ X86_INS_XORPD ] = { // Add if needed
			 .categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
			 .is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_MOVHLPS ] = // Register only
		g_instruction_exception_table [ X86_INS_MOVLHPS ] = { // Register only
				.categories = {.FPU_SIMD = true },
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_UNPCKLPS ] =
		g_instruction_exception_table [ X86_INS_UNPCKHPS ] = // Add if needed
		g_instruction_exception_table [ X86_INS_UNPCKLPD ] = // Add if needed
		g_instruction_exception_table [ X86_INS_UNPCKHPD ] = { // Add if needed
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};
	g_instruction_exception_table [ X86_INS_ROUNDSS ] =
		g_instruction_exception_table [ X86_INS_ROUNDSD ] = { // Add if needed
				.categories = {.MEMORY = true, .ALIGNMENT = true, .FPU_SIMD = true },
				.is_sse_avx_related = true
	};


	// --- Logical Instructions ---

	g_instruction_exception_table [ X86_INS_AND ] =
		g_instruction_exception_table [ X86_INS_OR ] =
		g_instruction_exception_table [ X86_INS_XOR ] = {
				.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true },
				.lock_prefix_allowed = true
	};
	g_instruction_exception_table [ X86_INS_TEST ] = {
		 .categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_NOT ] = { // Mem read/write possible, alignment, lock possible
			.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true },
			.lock_prefix_allowed = true
	};

	g_instruction_exception_table [ X86_INS_SHL ] =
		g_instruction_exception_table [ X86_INS_SHR ] =
		g_instruction_exception_table [ X86_INS_SAL ] =
		g_instruction_exception_table [ X86_INS_SAR ] =
		g_instruction_exception_table [ X86_INS_ROL ] =
		g_instruction_exception_table [ X86_INS_ROR ] =
		g_instruction_exception_table [ X86_INS_RCL ] =
		g_instruction_exception_table [ X86_INS_RCR ] = { // Mem read/write possible, alignment
				.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_SHLD ] =
		g_instruction_exception_table [ X86_INS_SHRD ] = { // Mem read/write possible, alignment
				.categories = {.MEMORY = true, .ALIGNMENT = true }
	};

	// --- Conditional Moves --- (No exceptions typically triggered by the move itself)
	g_instruction_exception_table [ X86_INS_CMOVO ] =
		g_instruction_exception_table [ X86_INS_CMOVNO ] =
		g_instruction_exception_table [ X86_INS_CMOVB ] = // NAE, C
		g_instruction_exception_table [ X86_INS_CMOVAE ] = // NB, NC
		g_instruction_exception_table [ X86_INS_CMOVE ] = // Z
		g_instruction_exception_table [ X86_INS_CMOVNE ] = // NZ
		g_instruction_exception_table [ X86_INS_CMOVBE ] = // NA
		g_instruction_exception_table [ X86_INS_CMOVA ] = // NBE
		g_instruction_exception_table [ X86_INS_CMOVS ] =
		g_instruction_exception_table [ X86_INS_CMOVNS ] =
		g_instruction_exception_table [ X86_INS_CMOVP ] = // PE
		g_instruction_exception_table [ X86_INS_CMOVNP ] = // PO
		g_instruction_exception_table [ X86_INS_CMOVL ] = // NGE
		g_instruction_exception_table [ X86_INS_CMOVGE ] = // NL
		g_instruction_exception_table [ X86_INS_CMOVLE ] = // NG
		g_instruction_exception_table [ X86_INS_CMOVG ] = { // NLE
				.categories = {.MEMORY = true, .ALIGNMENT = true } // Only if source is memory
	};

	// --- Control Flow Instructions ---
	g_instruction_exception_table [ X86_INS_CMP ] = { // Mem read possible, alignment
			.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_CMPXCHG ] = { // Mem read/write, alignment, lock allowed
			.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true},
			.lock_prefix_allowed = true
	};
	g_instruction_exception_table [ X86_INS_CALL ] = { // Mem read possible (indirect), stack write, stack align/bounds, control flow
			.categories = {.MEMORY = true, .STACK = true, .ALIGNMENT = true, .CONTROL_FLOW = true },
			.is_explicit_push = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_RET ] = { // Stack read, stack align/bounds, control flow
			.categories = {.STACK = true, .ALIGNMENT = true, .CONTROL_FLOW = true },
			.is_explicit_pop = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_JMP ] = { // Mem read possible (indirect), control flow
			.categories = {.MEMORY = true, .CONTROL_FLOW = true }
	};
	// Conditional Jumps (No memory access by default, control flow category)
	g_instruction_exception_table [ X86_INS_JE ] =
		g_instruction_exception_table [ X86_INS_JNE ] =
		g_instruction_exception_table [ X86_INS_JB ] =
		g_instruction_exception_table [ X86_INS_JBE ] =
		g_instruction_exception_table [ X86_INS_JA ] =
		g_instruction_exception_table [ X86_INS_JAE ] =
		g_instruction_exception_table [ X86_INS_JL ] =
		g_instruction_exception_table [ X86_INS_JLE ] =
		g_instruction_exception_table [ X86_INS_JG ] =
		g_instruction_exception_table [ X86_INS_JGE ] =
		g_instruction_exception_table [ X86_INS_JS ] =
		g_instruction_exception_table [ X86_INS_JNS ] =
		g_instruction_exception_table [ X86_INS_JO ] =
		g_instruction_exception_table [ X86_INS_JNO ] =
		g_instruction_exception_table [ X86_INS_JP ] =
		g_instruction_exception_table [ X86_INS_JNP ] =
		g_instruction_exception_table [ X86_INS_JCXZ ] =
		g_instruction_exception_table [ X86_INS_JECXZ ] =
		g_instruction_exception_table [ X86_INS_JRCXZ ] = {
				.categories = {.CONTROL_FLOW = true }
	};

	// --- Stack Frame Instructions ---
	g_instruction_exception_table [ X86_INS_ENTER ] = { // Stack write/read, stack align/bounds
			.categories = {.STACK = true, .ALIGNMENT = true },
			.is_explicit_push = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_LEAVE ] = { // Stack read, modifies RSP/RBP
			.categories = {.STACK = true, .ALIGNMENT = true },
			.is_explicit_pop = true, .modifies_rsp_implicitly = true
	};
	g_instruction_exception_table [ X86_INS_NOP ] = {
			.categories = {}
	};

	// --- Bit Manipulation Instructions --- (BMI1/BMI2)
	g_instruction_exception_table [ X86_INS_BZHI ] =
		g_instruction_exception_table [ X86_INS_ANDN ] =
		g_instruction_exception_table [ X86_INS_BEXTR ] = { // Mem read possible, alignment
				.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_POPCNT ] = { // Mem read possible, alignment
			.categories = {.MEMORY = true, .ALIGNMENT = true }
	};
	g_instruction_exception_table [ X86_INS_BSWAP ] = { // Register only
			.categories = {}
	};
	g_instruction_exception_table [ X86_INS_BT ] =
		g_instruction_exception_table [ X86_INS_BTS ] =
		g_instruction_exception_table [ X86_INS_BTR ] =
		g_instruction_exception_table [ X86_INS_BTC ] = { // Mem read/write possible, alignment, lock allowed for BTS/BTR/BTC
				.categories = {.MEMORY = true, .INVALID_USAGE = true, .ALIGNMENT = true },
				.lock_prefix_allowed = true
	};
	// Override BT (no lock, no write)
	g_instruction_exception_table [ X86_INS_BT ] = {
		 .categories = {.MEMORY = true, .ALIGNMENT = true },
		 .lock_prefix_allowed = false
	};
	// SETcc instructions (Register only, no exceptions)
	g_instruction_exception_table [ X86_INS_SETB ] =
		g_instruction_exception_table [ X86_INS_SETAE ] =
		g_instruction_exception_table [ X86_INS_SETBE ] =
		g_instruction_exception_table [ X86_INS_SETA ] =
		g_instruction_exception_table [ X86_INS_SETE ] =
		g_instruction_exception_table [ X86_INS_SETNE ] =
		g_instruction_exception_table [ X86_INS_SETL ] =
		g_instruction_exception_table [ X86_INS_SETLE ] =
		g_instruction_exception_table [ X86_INS_SETG ] =
		g_instruction_exception_table [ X86_INS_SETGE ] =
		g_instruction_exception_table [ X86_INS_SETS ] =
		g_instruction_exception_table [ X86_INS_SETNS ] =
		g_instruction_exception_table [ X86_INS_SETO ] =
		g_instruction_exception_table [ X86_INS_SETNO ] =
		g_instruction_exception_table [ X86_INS_SETP ] =
		g_instruction_exception_table [ X86_INS_SETNP ] = {
				.categories = {.MEMORY = true, .ALIGNMENT = true } // Only if destination is memory
	};

	// --- Flags & Misc Instructions ---
	g_instruction_exception_table [ X86_INS_CLI ] = { // Privileged check needed if CPL > IOPL (complex)
				.categories = {.INVALID_USAGE = true }, // Treat as privileged for simplicity in user-mode emu
				.is_privileged = true // Simplification for user-mode
	};
	g_instruction_exception_table [ X86_INS_CLD ] =
		g_instruction_exception_table [ X86_INS_CLC ] =
		g_instruction_exception_table [ X86_INS_CMC ] =
		g_instruction_exception_table [ X86_INS_STC ] = {
				.categories = {}
	};
	g_instruction_exception_table [ X86_INS_RDTSC ] = { // Can be privileged based on CR4.TSD
			.categories = {.INVALID_USAGE = true } // Needs runtime check of CR4/CPL
	};
	g_instruction_exception_table [ X86_INS_CPUID ] = {
			.categories = {}
	};
	g_instruction_exception_table [ X86_INS_XGETBV ] = { // Can cause #UD if XSETBV/XGETBV not enabled, or #GP(0) with invalid ECX
			.categories = {.INVALID_USAGE = true }
	};
	g_instruction_exception_table [ X86_INS_SYSCALL ] = {
			.categories = {} // Handled by OS
	};

	g_instruction_exception_table [ X86_INS_BOUND ] = {
		 .categories = {.MEMORY = true, .ARITHMETIC = true, .ALIGNMENT = true },
		 .is_bound = true
	};

	g_instruction_exception_table [ X86_INS_INTO ] = {
			.categories = {.ARITHMETIC = true },
			.is_into = true
	};

	g_instruction_exception_table [ X86_INS_INT3 ] = {
	.categories = {.INVALID_USAGE = true }, // Belongs to usage category
	.is_int3 = true,
	// All other flags default to false/0
	};

	g_instruction_exception_table [ X86_INS_HLT ] = {
	.categories = {.INVALID_USAGE = true }, // Belongs to usage category
	.is_privileged = true,
	// All other flags default to false/0
	};
}

template const uint8_t& EmulationContext::get_reg<uint8_t> ( x86_reg ) const;
template const uint16_t& EmulationContext::get_reg<uint16_t> ( x86_reg ) const;
template const uint32_t& EmulationContext::get_reg<uint32_t> ( x86_reg ) const;
template const uint64_t& EmulationContext::get_reg<uint64_t> ( x86_reg ) const;
template uint8_t& EmulationContext::get_reg_mut<uint8_t> ( x86_reg );
template uint16_t& EmulationContext::get_reg_mut<uint16_t> ( x86_reg );
template uint32_t& EmulationContext::get_reg_mut<uint32_t> ( x86_reg );
template uint64_t& EmulationContext::get_reg_mut<uint64_t> ( x86_reg );

void init_reg_map ( ) {
	std::array<KGPR, X86_REG_ENDING> ( ).fill ( static_cast< KGPR >( -1 ) );

	reg_map [ X86_REG_RAX ] = KRAX;
	reg_map [ X86_REG_EAX ] = KRAX;
	reg_map [ X86_REG_AX ] = KRAX;
	reg_map [ X86_REG_AH ] = KRAX;
	reg_map [ X86_REG_AL ] = KRAX;
	reg_map [ X86_REG_RBX ] = KRBX;
	reg_map [ X86_REG_EBX ] = KRBX;
	reg_map [ X86_REG_BX ] = KRBX;
	reg_map [ X86_REG_BH ] = KRBX;
	reg_map [ X86_REG_BL ] = KRBX;
	reg_map [ X86_REG_RCX ] = KRCX;
	reg_map [ X86_REG_ECX ] = KRCX;
	reg_map [ X86_REG_CX ] = KRCX;
	reg_map [ X86_REG_CH ] = KRCX;
	reg_map [ X86_REG_CL ] = KRCX;
	reg_map [ X86_REG_RDX ] = KRDX;
	reg_map [ X86_REG_EDX ] = KRDX;
	reg_map [ X86_REG_DX ] = KRDX;
	reg_map [ X86_REG_DH ] = KRDX;
	reg_map [ X86_REG_DL ] = KRDX;
	reg_map [ X86_REG_RSI ] = KRSI;
	reg_map [ X86_REG_ESI ] = KRSI;
	reg_map [ X86_REG_SI ] = KRSI;
	reg_map [ X86_REG_SIL ] = KRSI;
	reg_map [ X86_REG_RDI ] = KRDI;
	reg_map [ X86_REG_EDI ] = KRDI;
	reg_map [ X86_REG_DI ] = KRDI;
	reg_map [ X86_REG_DIL ] = KRDI;
	reg_map [ X86_REG_RBP ] = KRBP;
	reg_map [ X86_REG_EBP ] = KRBP;
	reg_map [ X86_REG_BP ] = KRBP;
	reg_map [ X86_REG_BPL ] = KRBP;
	reg_map [ X86_REG_RSP ] = KRSP;
	reg_map [ X86_REG_ESP ] = KRSP;
	reg_map [ X86_REG_SP ] = KRSP;
	reg_map [ X86_REG_SPL ] = KRSP;
	reg_map [ X86_REG_R8 ] = KR8;
	reg_map [ X86_REG_R8D ] = KR8;
	reg_map [ X86_REG_R8W ] = KR8;
	reg_map [ X86_REG_R8B ] = KR8;
	reg_map [ X86_REG_R9 ] = KR9;
	reg_map [ X86_REG_R9D ] = KR9;
	reg_map [ X86_REG_R9W ] = KR9;
	reg_map [ X86_REG_R9B ] = KR9;
	reg_map [ X86_REG_R10 ] = KR10;
	reg_map [ X86_REG_R10D ] = KR10;
	reg_map [ X86_REG_R10W ] = KR10;
	reg_map [ X86_REG_R10B ] = KR10;
	reg_map [ X86_REG_R11 ] = KR11;
	reg_map [ X86_REG_R11D ] = KR11;
	reg_map [ X86_REG_R11W ] = KR11;
	reg_map [ X86_REG_R11B ] = KR11;
	reg_map [ X86_REG_R12 ] = KR12;
	reg_map [ X86_REG_R12D ] = KR12;
	reg_map [ X86_REG_R12W ] = KR12;
	reg_map [ X86_REG_R12B ] = KR12;
	reg_map [ X86_REG_R13 ] = KR13;
	reg_map [ X86_REG_R13D ] = KR13;
	reg_map [ X86_REG_R13W ] = KR13;
	reg_map [ X86_REG_R13B ] = KR13;
	reg_map [ X86_REG_R14 ] = KR14;
	reg_map [ X86_REG_R14D ] = KR14;
	reg_map [ X86_REG_R14W ] = KR14;
	reg_map [ X86_REG_R14B ] = KR14;
	reg_map [ X86_REG_R15 ] = KR15;
	reg_map [ X86_REG_R15D ] = KR15;
	reg_map [ X86_REG_R15W ] = KR15;
	reg_map [ X86_REG_R15B ] = KR15;
	reg_map [ X86_REG_RIP ] = KRIP;
	reg_map [ X86_REG_EIP ] = KRIP;
	reg_map [ X86_REG_IP ] = KRIP;
	reg_map [ X86_REG_DR0 ] = KDR0;
	reg_map [ X86_REG_DR1 ] = KDR1;
	reg_map [ X86_REG_DR2 ] = KDR2;
	reg_map [ X86_REG_DR3 ] = KDR3;
	reg_map [ X86_REG_DR4 ] = KDR4;
	reg_map [ X86_REG_DR5 ] = KDR5;
	reg_map [ X86_REG_DR6 ] = KDR6;
	reg_map [ X86_REG_DR7 ] = KDR7;
	reg_map [ X86_REG_CR0 ] = KCR0;
	reg_map [ X86_REG_CR2 ] = KCR2;
	reg_map [ X86_REG_CR3 ] = KCR3;
	reg_map [ X86_REG_CR4 ] = KCR4;
	reg_map [ X86_REG_CR8 ] = KCR8;
	reg_map [ X86_REG_CS ] = KCS;
	reg_map [ X86_REG_DS ] = KDS;
	reg_map [ X86_REG_ES ] = KES;
	reg_map [ X86_REG_FS ] = KFS;
	reg_map [ X86_REG_GS ] = KGS;
	reg_map [ X86_REG_SS ] = KSS;
}

void init_avx_map ( ) {
	avx_map [ X86_REG_XMM0 ] = 0;
	avx_map [ X86_REG_XMM1 ] = 1;
	avx_map [ X86_REG_XMM2 ] = 2;
	avx_map [ X86_REG_XMM3 ] = 3;
	avx_map [ X86_REG_XMM4 ] = 4;
	avx_map [ X86_REG_XMM5 ] = 5;
	avx_map [ X86_REG_XMM6 ] = 6;
	avx_map [ X86_REG_XMM7 ] = 7;
	avx_map [ X86_REG_XMM8 ] = 8;
	avx_map [ X86_REG_XMM9 ] = 9;
	avx_map [ X86_REG_XMM10 ] = 10;
	avx_map [ X86_REG_XMM11 ] = 11;
	avx_map [ X86_REG_XMM12 ] = 12;
	avx_map [ X86_REG_XMM13 ] = 13;
	avx_map [ X86_REG_XMM14 ] = 14;
	avx_map [ X86_REG_XMM15 ] = 15;
	avx_map [ X86_REG_YMM0 ] = 0;
	avx_map [ X86_REG_YMM1 ] = 1;
	avx_map [ X86_REG_YMM2 ] = 2;
	avx_map [ X86_REG_YMM3 ] = 3;
	avx_map [ X86_REG_YMM4 ] = 4;
	avx_map [ X86_REG_YMM5 ] = 5;
	avx_map [ X86_REG_YMM6 ] = 6;
	avx_map [ X86_REG_YMM7 ] = 7;
	avx_map [ X86_REG_YMM8 ] = 8;
	avx_map [ X86_REG_YMM9 ] = 9;
	avx_map [ X86_REG_YMM10 ] = 10;
	avx_map [ X86_REG_YMM11 ] = 11;
	avx_map [ X86_REG_YMM12 ] = 12;
	avx_map [ X86_REG_YMM13 ] = 13;
	avx_map [ X86_REG_YMM14 ] = 14;
	avx_map [ X86_REG_YMM15 ] = 15;
	avx_map [ X86_REG_ZMM0 ] = 0;
	avx_map [ X86_REG_ZMM1 ] = 1;
	avx_map [ X86_REG_ZMM2 ] = 2;
	avx_map [ X86_REG_ZMM3 ] = 3;
	avx_map [ X86_REG_ZMM4 ] = 4;
	avx_map [ X86_REG_ZMM5 ] = 5;
	avx_map [ X86_REG_ZMM6 ] = 6;
	avx_map [ X86_REG_ZMM7 ] = 7;
	avx_map [ X86_REG_ZMM8 ] = 8;
	avx_map [ X86_REG_ZMM9 ] = 9;
	avx_map [ X86_REG_ZMM10 ] = 10;
	avx_map [ X86_REG_ZMM11 ] = 11;
	avx_map [ X86_REG_ZMM12 ] = 12;
	avx_map [ X86_REG_ZMM13 ] = 13;
	avx_map [ X86_REG_ZMM14 ] = 14;
	avx_map [ X86_REG_ZMM15 ] = 15;
};

uint64_t calc_initial_rsp ( uintptr_t stack_base,
																 size_t    stack_size,
																 size_t    shadow_space = 32,   // Win64
																 size_t    fake_ret_space = 8 ) {
	uintptr_t top = stack_base + stack_size;
	uintptr_t rsp = ( top - fake_ret_space ) & ~uintptr_t ( 0xF );

	rsp -= shadow_space;

	return static_cast< uint64_t >( rsp );
}

bool is_24h2 ( ) {
	OSVERSIONINFOEXW osInfo = { sizeof ( osInfo ) };
	if ( GetVersionExW ( ( LPOSVERSIONINFOW ) &osInfo ) ) {
		return osInfo.dwMajorVersion >= 10 && osInfo.dwBuildNumber >= 26100;
	}
	return false;
}

EmulationContext::EmulationContext ( ) {
	EmulationContext::initialize_exception_table ( );
	helpers::bind_arithmetic ( );
	helpers::bind_bit ( );
	helpers::bind_cf ( );
	helpers::bind_jx ( );
	helpers::bind_cpu ( );
	helpers::bind_fpu ( );
	helpers::bind_data ( );
	helpers::bind_logical ( );
	helpers::bind_frame ( );
	helpers::bind_avx ( );
	helpers::bind_winapi ( );
	init_reg_map ( );
	init_avx_map ( );
	cpu = std::make_unique<KCPU> ( );
	windows = std::make_unique<WindowsCompat> ( );
	cpu->avx_registers = std::make_unique<std::array<uint512_t, 16>> ( );
	cpu->registers.fill ( 0 );

	constexpr size_t stack_total_size = 0x200000; // 2MB stack
	constexpr size_t stack_alignment = 16;
	constexpr int64_t shadow_space_size = 32;
	constexpr int64_t fake_ret_addr_space = 8;
	constexpr uint64_t fake_ret_addr_value = 0xDEADBEEFBAADF00DULL;

	// Allocate stack
	rsp_base = std::unique_ptr<uint8_t [ ], void ( * )( uint8_t* )> (
			static_cast< uint8_t* >( _aligned_malloc ( stack_total_size, stack_alignment ) ),
			[ ] ( uint8_t* ptr ) { _aligned_free ( ptr ); } );
	if ( !rsp_base ) {
		throw std::runtime_error ( "Failed to allocate aligned stack" );
	}

	uintptr_t stack_base_addr = reinterpret_cast< uintptr_t >( rsp_base.get ( ) );
	if ( stack_base_addr % stack_alignment != 0 ) {
		_aligned_free ( rsp_base.release ( ) );
		throw std::runtime_error ( "Stack allocation is not aligned" );
	}

	stack_allocated = stack_total_size;

	// Setup TEB
	auto real_teb = reinterpret_cast< _TEB64* >( __readgsqword ( 0x30 ) );
	windows->teb = std::make_unique<_TEB64> ( );
	if ( is_24h2 ( ) ) {
		memcpy ( windows->teb.get ( ), real_teb, sizeof ( _TEB64 ) );
	}
	windows->teb->ProcessEnvironmentBlock = __readgsqword ( 0x60 );
	windows->teb->NtTib.StackBase = stack_base_addr + stack_total_size;
	windows->teb->NtTib.StackLimit = stack_base_addr;
	windows->teb->NtTib.Self = reinterpret_cast< DWORD64 >( windows->teb.get ( ) );
	windows->teb->ClientId.UniqueProcess = GetCurrentProcessId ( );
	windows->teb->ClientId.UniqueThread = GetCurrentThreadId ( );

	windows->ntdll_base = reinterpret_cast< uint64_t >( GetModuleHandleA ( "ntdll.dll" ) );
	windows->kernel32_base = reinterpret_cast< uint64_t >( GetModuleHandleA ( "kernel32.dll" ) );

	windows->ldr_initialize_thunk = reinterpret_cast< uint64_t >( GetProcAddress ( reinterpret_cast< HMODULE >( windows->ntdll_base ), "LdrInitializeThunk" ) );
	windows->rtl_user_thread_start = reinterpret_cast< uint64_t >( GetProcAddress ( reinterpret_cast< HMODULE >( windows->ntdll_base ), "RtlUserThreadStart" ) );
	windows->ki_user_exception_dispatcher = reinterpret_cast< uint64_t >( GetProcAddress ( reinterpret_cast< HMODULE >( windows->ntdll_base ), "KiUserExceptionDispatcher" ) );
	windows->ki_user_apc_dispatcher = reinterpret_cast< uint64_t >( GetProcAddress ( reinterpret_cast< HMODULE >( windows->ntdll_base ), "KiUserApcDispatcher" ) );

	InstructionEffect effect { .no_log = true };
	set_reg ( X86_REG_GS, ( uint64_t ) windows->teb.get ( ), 8, effect );

	uint64_t initial_rsp = calc_initial_rsp ( stack_base_addr, stack_total_size );
	set_reg ( X86_REG_RSP, initial_rsp, 8, effect );
	set_stack ( initial_rsp, fake_ret_addr_value, effect, 8 );
	push_call_frame ( fake_ret_addr_value, effect );

	set_rcx_to_ioport ( 0x0000, effect );

	initialize_imports ( parser );
	if ( options.enable_logging ) {
		std::print ( "Initialized State: Stack Base=0x{:016x}, Size=0x{:x}\n", stack_base_addr, stack_total_size );
		std::print ( "Initial Registers: RSP=0x{:016x}, RBP=0x{:016x}, rsp_offset=0x{:x}\n",
							 initial_rsp, get_reg ( X86_REG_RBP ), cpu->rsp_offset );
		std::print ( "Stack Top=0x{:016x}\n", windows->teb->NtTib.StackBase );
		std::print ( "Stack Bottom=0x{:016x}\n", windows->teb->NtTib.StackLimit );
		std::print ( "Fake return address 0x{:016x} at RSP 0x{:016x}\n", fake_ret_addr_value, initial_rsp );
	}
}
```

`emulator/src/exception.cpp`:

```cpp

#include "pch.hpp"
#include <semantics/src/pch.hpp>

inline bool is_canonical ( uint64_t addr ) {
  return ( ( addr <= 0x00007FFFFFFFFFFFULL ) || ( addr >= 0xFFFF800000000000ULL ) );
}

bool check_x87_fault_condition ( const EmulationContext& state ) {
  uint16_t fsw = state.cpu->fpu.fpu_status_word;
  uint16_t fcw = state.cpu->fpu.fpu_control_word;
  uint16_t exception_status = fsw & 0x3F;
  uint16_t exception_mask = fcw & 0x3F;
  return ( exception_status & ~exception_mask ) != 0;
}

DWORD map_x87_exception ( const EmulationContext& state ) {
  uint16_t fsw = state.cpu->fpu.fpu_status_word;
  uint16_t fcw = state.cpu->fpu.fpu_control_word;
  uint16_t exception_status = fsw & 0x3F;
  uint16_t exception_mask = fcw & 0x3F;
  uint16_t unmasked = exception_status & ~exception_mask;
  if ( unmasked == 0 ) return 0;
  if ( unmasked & 0x01 ) return EXCEPTION_FLT_INVALID_OPERATION;
  if ( unmasked & 0x02 ) return EXCEPTION_FLT_DENORMAL_OPERAND;
  if ( unmasked & 0x04 ) return EXCEPTION_FLT_DIVIDE_BY_ZERO;
  if ( unmasked & 0x08 ) return EXCEPTION_FLT_OVERFLOW;
  if ( unmasked & 0x10 ) return EXCEPTION_FLT_UNDERFLOW;
  if ( unmasked & 0x20 ) return EXCEPTION_FLT_INEXACT_RESULT;
  return 0;
}

bool check_simd_fault_condition ( const EmulationContext& state ) {
  uint32_t mxcsr = state.cpu->fpu.mxcsr_control;
  uint32_t status = mxcsr & 0x3F;
  uint32_t mask = ( mxcsr >> 7 ) & 0x3F;
  return ( status & ~mask ) != 0;
}

DWORD map_sse_exception ( const EmulationContext& state ) {
  uint32_t mxcsr = state.cpu->fpu.mxcsr_control;
  uint32_t status = mxcsr & 0x3F;
  uint32_t mask = ( mxcsr >> 7 ) & 0x3F;
  return ( ( status & ~mask ) != 0 ) ? EXCEPTION_FLT_INVALID_OPERATION : 0;
}

GuestExceptionInfo check_instruction_exceptions (
    EmulationContext& state,
    capstone::Instruction& instr,
    const PreCheckInfo& check_info
) {
  GuestExceptionInfo result = {};
  uint64_t ip = instr.ip ( );
  const auto& baseInfo = g_instruction_exception_table [ instr.mnemonic ( ) ];
  const auto& cats = baseInfo.categories;

  // INVALID_USAGE
  if ( cats.INVALID_USAGE ) {
    if ( baseInfo.is_privileged && state.cpu->current_privilege_level != 0 ) {
      result.set_exception ( EXCEPTION_PRIV_INSTRUCTION, ip );
      return result;
    }
    if ( baseInfo.is_io ) {
      result.set_exception ( EXCEPTION_PRIV_INSTRUCTION, ip );
      return result;
    }
    if ( check_info.has_lock_prefix ) {
      bool need_mem = !( instr.mnemonic ( ) == X86_INS_XCHG && instr.operands ( ) [ 0 ].type == X86_OP_REG );
      if ( !baseInfo.lock_prefix_allowed || baseInfo.lock_prefix_always_invalid ||
         ( baseInfo.lock_prefix_allowed && need_mem && !check_info.has_mem_operand ) ) {
        result.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, ip );
        return result;
      }
    }
    if ( baseInfo.is_invalid_by_default ) {
      result.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, ip );
      return result;
    }
    if ( baseInfo.is_int3 ) {
      result.set_exception ( EXCEPTION_BREAKPOINT, ip );
      return result;
    }
  }

  // MEMORY
  if ( cats.MEMORY && check_info.has_mem_operand ) {
    uint64_t addr = check_info.mem_effective_addr;
    if ( !is_canonical ( addr ) ) {
      result.set_access_violation ( ip, addr, check_info.mem_is_write );
      return result;
    }
    if ( check_info.uses_fs && state.get_reg ( X86_REG_FS, 2 ) == 0 ) {
      result.set_access_violation ( ip, addr, check_info.mem_is_write );
      return result;
    }
    if ( check_info.uses_gs && state.get_reg ( X86_REG_GS, 2 ) == 0 ) {
      result.set_access_violation ( ip, addr, check_info.mem_is_write );
      return result;
    }
  }

  // STACK
  if ( cats.STACK ) {
    uint64_t addr = state.get_reg ( X86_REG_RSP );
    if ( check_info.is_stack_push ) addr = check_info.stack_access_addr;
    if ( check_info.is_stack_pop )  addr = check_info.stack_access_addr;
    if ( !state.is_within_stack_bounds ( addr, check_info.stack_access_size ) ) {
      if ( check_info.is_stack_push )
        result.set_exception ( EXCEPTION_STACK_OVERFLOW, ip, addr );
      else
        result.set_access_violation ( ip, addr, false );
      return result;
    }
    uint64_t future = state.get_reg ( X86_REG_RSP );
    if ( baseInfo.modifies_rsp_implicitly ) {
      if ( check_info.is_stack_push ) future -= check_info.stack_access_size;
      if ( check_info.is_stack_pop )  future += check_info.stack_access_size;
    }
    if ( !is_canonical ( future ) ) {
      result.set_access_violation ( ip, future, false );
      return result;
    }
  }

  // ALIGNMENT
  if ( cats.ALIGNMENT ) {
    uint64_t addr = 0; uint8_t size = 0; bool do_check = false;
    if ( check_info.has_mem_operand ) {
      addr = check_info.mem_effective_addr; size = check_info.mem_op_size; do_check = true;
    }
    else if ( check_info.is_stack_push || check_info.is_stack_pop ) {
      addr = check_info.stack_access_addr; size = check_info.stack_access_size; do_check = true;
    }
    if ( do_check && size > 0 ) {
      if ( check_info.alignment_required_intrinsic ) {
        if ( addr % check_info.required_alignment_bytes ) {
          result.set_exception ( EXCEPTION_DATATYPE_MISALIGNMENT, ip, addr );
          return result;
        }
      }
      else {
        if ( state.is_alignment_check_enabled ( ) && size > 1 && size <= 8 && ( addr % size ) ) {
          result.set_exception ( EXCEPTION_DATATYPE_MISALIGNMENT, ip, addr );
          return result;
        }
      }
    }
  }

  // CONTROL_FLOW
  if ( cats.CONTROL_FLOW ) {
    InstructionEffect eff;
    uint64_t target = helpers::get_target2 ( instr, state, eff );
    if ( target && !is_canonical ( target ) ) {
      result.set_access_violation ( ip, target, true );
      return result;
    }
  }

  return result;
}

GuestExceptionInfo check_post_execution_arithmetic (
    EmulationContext& state,
    const InstructionExceptionInfo& baseInfo,
    uint64_t ip,
    uint8_t op_size
) {
  GuestExceptionInfo result = {};
  if ( baseInfo.is_into && state.cpu->cpu_flags.flags.OF ) {
    result.set_exception ( EXCEPTION_INT_OVERFLOW, ip );
    return result;
  }
  return result;
}

GuestExceptionInfo check_post_execution_fpu_simd (
    EmulationContext& state,
    const InstructionExceptionInfo& baseInfo,
    uint64_t ip
) {
  GuestExceptionInfo result = {};
  if ( baseInfo.is_fpu_related && check_x87_fault_condition ( state ) ) {
    DWORD code = map_x87_exception ( state );
    if ( code ) { result.set_exception ( code, ip ); return result; }
  }
  if ( baseInfo.is_sse_avx_related && check_simd_fault_condition ( state ) ) {
    DWORD code = map_sse_exception ( state );
    if ( code ) { result.set_exception ( code, ip ); return result; }
  }
  return result;
}

void setup_guest_exception_dispatch ( EmulationContext& state, const GuestExceptionInfo& ex_info ) {
  if ( !ex_info.exception_occurred ) {
    std::println ( "INTERNAL ERROR: setup_guest_exception_dispatch called with no exception occurred." );
    state.exit_due_to_critical_error = true; return;
  }
  std::println ( "Dispatching exception 0x{:X} @ IP=0x{:016x}, VA=0x{:016x}...",
               ex_info.ExceptionCode, ex_info.ExceptionAddress, ex_info.FaultingVa );
  uint64_t disp = state.windows->ki_user_exception_dispatcher;
  if ( !disp ) { state.exit_due_to_critical_error = true; return; }
  alignas( 16 ) CONTEXT ctx = {}; ctx.ContextFlags = CONTEXT_ALL;
  state.save_context ( &ctx ); ctx.Rip = ex_info.ExceptionAddress;
  EXCEPTION_RECORD er = {};
  er.ExceptionCode = ex_info.ExceptionCode;
  er.ExceptionFlags = ex_info.ExceptionFlags;
  er.ExceptionAddress = reinterpret_cast< PVOID >( ex_info.ExceptionAddress );
  er.NumberParameters = ex_info.NumberParameters;
  memcpy ( er.ExceptionInformation, ex_info.ExceptionInformation.data ( ), ex_info.NumberParameters * sizeof ( ULONG_PTR ) );
  uint64_t rsp = state.get_reg ( X86_REG_RSP );
  size_t rsz = ( sizeof ( EXCEPTION_RECORD ) + 15 ) & ~15ULL;
  size_t csz = ( sizeof ( CONTEXT ) + 15 ) & ~15ULL;
  uint64_t ra = rsp - rsz;
  uint64_t ca = ra - csz;
  uint64_t fr = ( ca - 32 ) & ~15ULL;
  *( EXCEPTION_RECORD* ) ra = er;
  *( CONTEXT* ) ca = ctx;
  InstructionEffect de = {};
  state.set_reg ( X86_REG_RCX, ra, 8, de );
  state.set_reg ( X86_REG_RDX, ca, 8, de );
  state.set_reg ( X86_REG_RSP, fr, 8, de );
  if ( state.cpu->cpu_flags.flags.TF ) { state.cpu->cpu_flags.flags.TF = 0; }
  state.decoder.back ( )->set_ip ( disp );
}

void populate_pre_check_info (
    PreCheckInfo& ci,
    EmulationContext& state,
    capstone::Instruction& instr,
    const InstructionExceptionInfo& bi
) {
  ci = {};
  for ( int i = 0; i < 4 && instr.prefix ( ) [ i ]; ++i )
    if ( instr.prefix ( ) [ i ] == X86_PREFIX_LOCK ) ci.has_lock_prefix = true;
  auto ops = instr.operands ( ); size_t cnt = instr.operand_count ( );
  if ( cnt > 0 && ops [ 0 ].type == X86_OP_MEM ) ci.mem_is_write = true;
  for ( size_t i = 0; i < cnt; ++i ) if ( ops [ i ].type == X86_OP_MEM ) {
    ci.has_mem_operand = true;
    ci.mem_op_size = ops [ i ].size;
    ci.mem_segment_reg = static_cast< x86_reg > ( ops [ i ].mem.segment );
    ci.uses_fs = ( ci.mem_segment_reg == X86_REG_FS );
    ci.uses_gs = ( ci.mem_segment_reg == X86_REG_GS );
    ci.mem_effective_addr = helpers::calculate_mem_addr ( ops [ i ], instr, state );
    if ( i > 0 ) ci.mem_is_write = false;
    if ( ( instr.mnemonic ( ) == X86_INS_CMPXCHG || instr.mnemonic ( ) == X86_INS_XADD ) && i == 0 )
      ci.mem_is_write = true;
    if ( instr.mnemonic ( ) == X86_INS_TEST || instr.mnemonic ( ) == X86_INS_CMP )
      ci.mem_is_write = false;
    break;
  }
  ci.is_stack_push = bi.is_explicit_push;
  ci.is_stack_pop = bi.is_explicit_pop;
  if ( ci.is_stack_push || ci.is_stack_pop ) {
    ci.stack_access_size = 8;
    uint64_t r = state.get_reg ( X86_REG_RSP );
    ci.stack_access_addr = ci.is_stack_push ? ( r - 8 ) : r;
  }
  else if ( bi.modifies_rsp_implicitly ) {
    if ( instr.is_call ( ) ) { ci.is_stack_push = true; ci.stack_access_size = 8; ci.stack_access_addr = state.get_reg ( X86_REG_RSP ) - 8; }
    else if ( instr.is_return ( ) ) { ci.is_stack_pop = true; ci.stack_access_size = 8; ci.stack_access_addr = state.get_reg ( X86_REG_RSP ); }
  }
  ci.alignment_required_intrinsic = bi.requires_intrinsic_alignment;
  ci.required_alignment_bytes = bi.intrinsic_alignment_bytes > 0 ? bi.intrinsic_alignment_bytes : 1;
  ci.alignment_required_by_ac = bi.categories.ALIGNMENT;
}


```

`emulator/src/pch.cpp`:

```cpp
#include "pch.hpp"
```

`emulator/src/pch.hpp`:

```hpp
#pragma once

#include <shared/context.hpp>
#include <shared/portable_executable.hpp>
```

`emulator/src/sig_scanner.hpp`:

```hpp
#pragma once 
#include <algorithm>
#include <type_traits>
#include <array>
#include <cstdint>
#include <utility>
#include <immintrin.h>
#if defined(__clang__)
#define CLANG 1
#else
#define CLANG 0
#endif
#if defined(__GNUC__)&&!defined(__clang__)
#define GCC 1
#else
#define GCC 0
#endif
#if defined(_MSC_VER)&&!defined(__clang__)
#define MSVC 1
#else
#define MSVC 0
#endif
#if defined(_MSC_VER)&&defined(__clang__)
#define CLANG_CL 1
#else
#define CLANG_CL 0
#endif
static_assert( CLANG + GCC + MSVC == 1 );
#if MSVC || CLANG_CL
#if _WIN32 || _WIN64
#if _WIN64
#define BITNESS 64
#else
#define BITNESS 32
#endif
#endif
#else
#if __x86_64__ || __ppc64__
#define BITNESS 64
#else
#define BITNESS 32
#endif
#endif
static_assert( sizeof ( void* ) * 8 == BITNESS );
#if CLANG || GCC
#define UNREACHABLE __builtin_unreachable()
#define Inline __attribute__((always_inline)) inline
#define LambdaInline __attribute__((always_inline))
#else
#define UNREACHABLE __assume(false)
#define Inline __forceinline
#define LambdaInline [[msvc::forceinline]]
#endif
#define FWD(...) static_cast<decltype(__VA_ARGS__)&&>(__VA_ARGS__)
#define MOV(...) static_cast<typename std::remove_reference<decltype(__VA_ARGS__)>::type &&>(__VA_ARGS__)
#if CLANG || GCC
template<class T, class T0>concept $Same = __is_same ( T, T0 );
template<class T, class...Ts>constexpr bool all_same { ( __is_same ( T, Ts )&&... ) };
#else
template<class T, class T0>concept $Same = std::is_same_v<T, T0>;
template<class T, class...Ts>constexpr bool all_same { ( std::is_same_v<T, Ts>&&... ) };
#endif
namespace Algorithm
{
	template<class Arg0, class...Args>
		requires( all_same<Arg0, Args...>&& std::is_trivially_copyable_v<Arg0> && sizeof ( Arg0 ) <= 2 * sizeof ( void* ) )
	Inline constexpr Arg0 max ( Arg0 arg0, const Args...args )noexcept {
		( ( arg0 = ( args > arg0 ) ? args : arg0 ), ... );
		return arg0;
	}
}
namespace details
{
	template<std::uint64_t MaxValue>struct compact_impl;
	template<std::uint64_t MaxValue>requires( ( MaxValue >= 0 ) && MaxValue <= std::uint8_t ( -1 ) ) struct compact_impl<MaxValue> { using type = std::uint8_t; };
	template<std::uint64_t MaxValue>requires( ( MaxValue > std::uint8_t ( -1 ) ) && MaxValue <= std::uint16_t ( -1 ) )	struct compact_impl<MaxValue> { using type = std::uint16_t; };
	template<std::uint64_t MaxValue>requires( ( MaxValue > std::uint16_t ( -1 ) ) && MaxValue <= std::uint32_t ( -1 ) )	struct compact_impl<MaxValue> { using type = std::uint32_t; };
	template<std::uint64_t MaxValue>requires( ( MaxValue > std::uint32_t ( -1 ) ) && MaxValue <= std::uint64_t ( -1 ) )	struct compact_impl<MaxValue> { using type = std::uint64_t; };
}
template<std::uint64_t...MaxValue>using Compact = typename details::compact_impl<Algorithm::max ( MaxValue... )>::type;
template<std::uint64_t Value>static constexpr Compact<Value> compact { static_cast< Compact<Value> >( Value ) };
template<class...>struct LikeImpl;
template<class From, class To>struct LikeImpl<From&, To> { using type = To&; };
template<class From, class To>struct LikeImpl<const From&, To> { using type = const To&; };
template<class From, class To>struct LikeImpl<volatile From&, To> { using type = volatile To&; };
template<class From, class To>struct LikeImpl<const volatile From&, To> { using type = const volatile To&; };
template<class From, class To>struct LikeImpl<From&&, To> { using type = To&&; };
template<class From, class To>struct LikeImpl<const From&&, To> { using type = const To&&; };
template<class From, class To>struct LikeImpl<volatile From&&, To> { using type = volatile To&&; };
template<class From, class To>struct LikeImpl<const volatile From&&, To> { using type = const volatile To&&; };
template<class From, class To>struct LikeImpl<From, To> { using type = To&&; };
template<class From, class To>struct LikeImpl<const From, To> { using type = const To&&; };
template<class From, class To>struct LikeImpl<volatile From, To> { using type = volatile To&&; };
template<class From, class To>struct LikeImpl<const volatile From, To> { using type = const volatile To&&; };
template<class From, class To>using Like = typename LikeImpl<From, std::remove_cvref_t<To>>::type;
template<class From, class To>using LikePtr = std::remove_reference_t<Like<From, To>>*;
template<class, std::size_t>struct ConstVector;
template<class T, std::size_t N>
	requires( N > 0 )
struct ConstVector<T, N> {
	using index_t = Compact<N>;
	T m_data [ N ];
	index_t m_size;
	constexpr ConstVector ( auto&& ...args )noexcept requires( sizeof...( args ) <= N ) : m_data { FWD ( args )... }, m_size { sizeof...( args ) } { }
	constexpr index_t size ( )const noexcept { return m_size; }
	static constexpr index_t capacity ( ) noexcept { return N; }
	template<class Self>constexpr Like<Self, T> front ( this Self&& self ) noexcept { return FWD ( self ).m_data [ 0 ]; }
	template<class Self>constexpr Like<Self, T> back ( this Self&& self ) noexcept { return FWD ( self ).m_data [ self.m_size - 1 ]; }
	template<class Self>constexpr Like<Self, T> operator[]( this Self&& self, index_t index ) noexcept { return static_cast< Like<Self, T> >( FWD ( self ).m_data [ index ] ); }//msvc bug
	template<class Self>constexpr LikePtr<Self, T> data ( this Self&& self ) noexcept { return self.m_data; }
	template<class Self>constexpr LikePtr<Self, T> begin ( this Self&& self ) noexcept { return self.m_data; }
	template<class Self>constexpr LikePtr<Self, T> end ( this Self&& self ) noexcept { return self.begin ( ) + self.m_size; }
	constexpr void clear ( )noexcept { m_size = {}; }
	constexpr void push_back ( T entry )noexcept { m_data [ m_size++ ] = entry; }
};
template<class T>
struct ConstVector<T, 0> {
	constexpr ConstVector ( )noexcept { }
	static constexpr std::uint8_t size ( ) noexcept { return 0; }
	static constexpr std::uint8_t capacity ( ) noexcept { return 0; }
	constexpr const T* data ( )const noexcept { return nullptr; }
	constexpr const T* begin ( )const noexcept { return nullptr; }
	constexpr const T* end ( )const noexcept { return nullptr; }
};
template<class, class Sig>struct CallableImpl;
template<class T, class Ret, class...Args>struct CallableImpl<T, Ret ( Args... )> { static constexpr bool value { requires( T f, Args...args ) { { FWD ( f )( FWD ( args )... ) }->$Same<Ret>; } }; };
template<class T, class Sig>concept Callable = CallableImpl<T, Sig>::value;
template<class T, std::size_t N>
struct FixedString {
private:
	template<std::size_t...I>
	Inline constexpr FixedString ( const T ( &str ) [ N + 1 ], std::index_sequence<I...> )noexcept :m_data { str [ I ]... } { }
public:
	Inline constexpr FixedString ( const T ( &str ) [ N + 1 ] )noexcept : FixedString { str, std::make_index_sequence<N>{} } { }
	Inline constexpr FixedString ( auto...chars )noexcept : m_data { chars... } { }
	Inline static constexpr Compact<N> size ( )noexcept { return N; }
	template<class Self>Inline constexpr Like<Self, T> operator[]( this Self&& self, std::size_t index ) noexcept { return static_cast< Like<Self, T> >( FWD ( self ).m_data [ index ] ); }//msvc bug
	Inline constexpr const T* begin ( )const noexcept { return m_data; }
	Inline constexpr const T* end ( )const noexcept { return m_data + size ( ); }
	Inline constexpr const T* data ( )const noexcept { return begin ( ); }
	Inline constexpr bool operator==( const FixedString<T, N>& )const noexcept = default;
	Inline constexpr bool operator!=( const FixedString<T, N>& )const noexcept = default;
	using char_type = T;
	T m_data [ N ];
};
template<class T>
struct FixedString<T, 0> {
	Inline constexpr FixedString ( const T ( & ) [ 1 ] )noexcept { }
	Inline constexpr FixedString ( )noexcept { }
	Inline static constexpr std::uint8_t size ( )noexcept { return 0; }
	template<class Self>Inline constexpr Like<Self, T> operator[]( this Self&&, std::size_t ) noexcept;
	Inline constexpr const T* begin ( )const noexcept { return nullptr; }
	Inline constexpr const T* end ( )const noexcept { return nullptr; }
	Inline constexpr const T* data ( )const noexcept { return nullptr; }
	Inline constexpr bool operator==( const FixedString<T, 0>& )const noexcept { return true; }
	Inline constexpr bool operator!=( const FixedString<T, 0>& )const noexcept { return false; }
	using char_type = T;
};
template<class Char, std::size_t N>FixedString ( const Char ( & ) [ N ] ) -> FixedString<Char, N - 1>;
template<class Char, $Same<Char>...Chars>FixedString ( Char, Chars... ) -> FixedString<Char, sizeof...( Chars ) + 1>;
template<class T, std::size_t Size>
concept $Size = sizeof ( T ) == Size;
template<class T>concept $HasBeginEnd = requires( const T container ) { container.begin ( ) != container.end ( ); };
template<class T>concept $HasDataSize = requires( const T container ) { container.data ( ) + container.size ( ); };
template<class T>concept $CArray = std::is_array<typename std::remove_cvref<T>::type>::value;
namespace details
{
	template<class Container>struct ElementOfImpl { using type = std::remove_cvref_t<decltype( *std::declval<const std::remove_cvref_t<Container>> ( ).data ( ) )>; };
	template<$CArray Container>struct ElementOfImpl<Container> { using type = std::remove_cvref_t<decltype( *std::declval<Container> ( ) )>; };
}
template<class Container>using ElementOf = typename details::ElementOfImpl<Container>::type;
namespace Algorithm
{
	template<$HasDataSize Container>
	Inline constexpr void bubble_sort ( Container&& container, Callable<bool ( const ElementOf<Container>, const ElementOf<Container> )> auto&& compare )noexcept {
		using Index = std::remove_cvref_t<decltype( container.size ( ) )>;
		const Index n { container.size ( ) };
		if ( n )
			for ( Index i {}; i != n - 1; ++i )
				for ( Index j {}; j < n - i - 1; ++j )
					if ( !FWD ( compare )( container [ j ], container [ j + 1 ] ) )
						std::swap ( container [ j ], container [ j + 1 ] );
	}
	template<$HasBeginEnd Container>
	Inline constexpr void stable_sort ( Container&& container, Callable<bool ( const ElementOf<Container>, const ElementOf<Container> )> auto&& compare )noexcept {
		if ( std::is_constant_evaluated ( ) )
			bubble_sort ( FWD ( container ), FWD ( compare ) );
		else
			std::stable_sort ( container.begin ( ), container.end ( ), FWD ( compare ) );
	}
}
template<auto Value>constexpr auto constant { Value };
template<std::uint8_t Bits>struct UnsignedBitsImpl { };
template<std::uint8_t Bits> using UnsignedBits = typename UnsignedBitsImpl<Bits>::type;
template<> struct UnsignedBitsImpl<8> { using type = std::uint8_t; };
template<> struct UnsignedBitsImpl<16> { using type = std::uint16_t; };
template<> struct UnsignedBitsImpl<32> { using type = std::uint32_t; };
template<> struct UnsignedBitsImpl<64> { using type = std::uint64_t; };
template<class T>concept $Dtor = !std::is_trivially_destructible_v<T>;
template<class T>concept $NotCvref = $Same<T, std::remove_cvref_t<T>>;
template<$NotCvref T>
struct Opt {
#if GCC//gcc bug
	T m_value {};
#else
	union { T m_value; };
#endif
	bool m_hasValue;
	Inline constexpr Opt ( )noexcept :m_hasValue {} { }
	Inline constexpr Opt ( auto&&...args )noexcept requires( requires{T { FWD ( args )... }; } ) : m_value { FWD ( args )... }, m_hasValue { true } { }
	Inline constexpr Opt& operator=( const Opt& rhs )noexcept {
		( *this ).~Opt ( );
		std::construct_at ( this, rhs );
		return *this;
	}
	Inline constexpr Opt& operator=( Opt&& rhs )noexcept {
		( *this ).~Opt ( );
		std::construct_at ( this, MOV ( rhs ) );
		return *this;
	}
	Inline constexpr Opt& operator=( auto&& args )noexcept
		requires( requires{T { FWD ( args ) }; } ) {
		( *this ).~Opt ( );
		std::construct_at ( this, FWD ( args ) );
		return *this;
	}
	Inline constexpr void emplace ( auto&&...args )noexcept
		requires( requires{T { FWD ( args )... }; } ) {
		std::construct_at ( this, FWD ( args )... );
		m_hasValue = true;
	}
	Inline constexpr void reset ( )noexcept {
		if ( m_hasValue ) {
			if constexpr ( $Dtor<T> )
				m_value.~T ( );
			m_hasValue = false;
		}
	}
	Inline constexpr ~Opt ( )noexcept {
		if constexpr ( $Dtor<T> )
			if ( m_hasValue )
				m_value.~T ( );
	}
	Inline constexpr Opt ( const Opt& rhs )noexcept :m_hasValue { rhs.m_hasValue } {
		if ( m_hasValue )
			std::construct_at ( __builtin_addressof( m_value ), rhs.m_value );
	}
	Inline constexpr Opt ( Opt&& rhs )noexcept :m_hasValue { rhs.m_hasValue } {
		if ( m_hasValue ) {
			std::construct_at ( __builtin_addressof( m_value ), MOV ( rhs.m_value ) );
			rhs.m_hasValue = false;
		}
	}
	Inline constexpr explicit operator bool ( )const noexcept { return m_hasValue; }
	Inline constexpr bool has_value ( )const noexcept { return m_hasValue; }
	template<class Self>Inline constexpr Like<Self, T> value ( this Self&& self ) noexcept { return FWD ( self ).m_value; }
	template<class Self>Inline constexpr Like<Self, T> operator*( this Self&& self ) noexcept { return FWD ( self ).m_value; }
	template<class Self>Inline constexpr LikePtr<Self, T> operator->( this Self&& self ) noexcept { return __builtin_addressof( self.m_value ); }
};
template<class T>Inline constexpr bool operator==( const Opt<T>& l, const Opt<T>& r )noexcept {
	if ( l.has_value ( ) )
		return r.has_value ( ) && *l == *r;
	else
		return !r.has_value ( );
}
template<class T>Inline constexpr bool operator!=( const Opt<T>& l, const Opt<T>& r )noexcept { return !( l == r ); }
template<class T>Inline constexpr bool operator==( const Opt<T>& l, const T& r )noexcept { return l && ( *l == r ); }
template<class T>Inline constexpr bool operator==( const T& l, const Opt<T>& r )noexcept { return r && ( l == *r ); }
template<class T>Inline constexpr bool operator!=( const Opt<T>& l, const T& r )noexcept { return !l || ( *l != r ); }
template<class T>Inline constexpr bool operator!=( const T& l, const Opt<T>& r )noexcept { return !r || ( l != *r ); }
#if CLANG || GCC
template<class T, class...Ts>concept $AnyOf = ( __is_same ( T, Ts ) || ... );
#else
template<class T, class...Ts>concept $AnyOf = ( std::is_same_v<T, Ts> || ... );
#endif
template<class T, class U>concept $Assignable = requires( U & u, const T x ) { u = x; };
namespace Bytes
{
	template<$Same<std::uint16_t> T>Inline constexpr T concat ( std::uint8_t v0, std::uint8_t v1 ) noexcept { return v0 | ( v1 << 8 ); }
	template<$Same<std::uint32_t> T>Inline constexpr T concat ( std::uint8_t v0, std::uint8_t v1, std::uint8_t v2, std::uint8_t v3 ) noexcept { return v0 | ( v1 << 8 ) | ( v2 << 16 ) | ( v3 << 24 ); }
	template<$Same<std::uint64_t> T>Inline constexpr T concat ( std::uint8_t v0, std::uint8_t v1, std::uint8_t v2, std::uint8_t v3, std::uint8_t v4, std::uint8_t v5, std::uint8_t v6, std::uint8_t v7 ) noexcept { return std::uint64_t ( v0 ) | ( std::uint64_t ( v1 ) << 8 ) | ( ( std::uint64_t ) ( v2 ) << 16 ) | ( std::uint64_t ( v3 ) << 24 ) | ( std::uint64_t ( v4 ) << 32 ) | ( std::uint64_t ( v5 ) << 40 ) | ( std::uint64_t ( v6 ) << 48 ) | ( std::uint64_t ( v7 ) << 56 ); }
}
namespace BytePattern
{
	struct Nibbles {
		std::uint8_t low : 4;
		std::uint8_t high : 4;
	};
	struct ComparisonEntryNibble {
		std::size_t offset;
		Opt<std::uint8_t> low;
		Opt<std::uint8_t> high;
	};
	struct ComparisonEntryBytes {
		std::size_t offset {};
		std::uint8_t size {};
	};
	struct Element {
		Opt<std::uint8_t> low, high, byte;
		constexpr Element ( Opt<std::uint8_t> low, Opt<std::uint8_t> high )noexcept :low { low }, high { high }, byte { ( low && high ) ? static_cast< std::uint8_t >( *low | ( *high << 4 ) ) : Opt<std::uint8_t>{} } { }
		constexpr Element ( std::uint8_t byte )noexcept :low { static_cast< std::uint8_t >( byte & 0x0f ) }, high { static_cast< std::uint8_t >( static_cast< std::uint8_t >( byte & 0xf0 ) >> 4 ) }, byte { ( low && high ) ? static_cast< std::uint8_t >( *low | ( *high << 4 ) ) : Opt<std::uint8_t>{} } { }
		constexpr Element ( )noexcept { }
		constexpr bool operator==( const Element& r )noexcept { return low == r.low && high == r.high; }
	};

	namespace details
	{
		template<auto OriginalElements, std::size_t... IndexesToClear>
		consteval auto create_modified_array_for_sequence ( ) noexcept {
			auto new_array = OriginalElements; // OriginalElements is std::array<BytePattern::Element, N>
			// Element is BytePattern::Element, visible due to nested namespace.
			( ( std::get<IndexesToClear> ( new_array ) = Element {} ), ... );
			return new_array;
		}
	}

	template<auto Elements>
	struct Sequence {
		static constexpr std::size_t numElements { Elements.size ( ) };
		static constexpr std::array<Element, numElements> elements { Elements };
		static constexpr ConstVector<ComparisonEntryBytes, numElements> bytesEntries { [ ]
		{
			ConstVector<ComparisonEntryBytes, numElements> result;
			std::size_t start{};
			for ( ;;) {
				while ( start < numElements && !elements [ start ].byte )++start;//skip wildcards/nibbles
				if ( start >= numElements )break;
				std::size_t iNextNonByte{ start + 1 };
				while ( iNextNonByte < numElements&& elements [ iNextNonByte ].byte )++iNextNonByte;
				const std::size_t dist{ iNextNonByte - start };
				const std::uint8_t compareLength{ ( dist >= 8 && sizeof ( void* ) >= 8 ) ? std::uint8_t ( 8 ) : ( dist >= 4 ? std::uint8_t ( 4 ) : ( dist >= 2 ? std::uint8_t ( 2 ) : std::uint8_t ( 1 ) ) )};
				result.push_back ( { start, compareLength } );
				start += compareLength;
			}
			Algorithm::stable_sort ( result,[ ] ( const ComparisonEntryBytes& l, const ComparisonEntryBytes& r ) { return l.size > r.size; } );
			return result;
		}( ) };
		static constexpr ConstVector<ComparisonEntryNibble, numElements> nibbleEntries { [ ]
		{
			ConstVector<ComparisonEntryNibble, numElements> result;
			std::size_t offset{};
			for ( Element e : elements ) {
				if ( e.low.has_value ( ) ^ e.high.has_value ( ) )
					result.push_back ( { offset, e.low, e.high } );
				++offset;
			}
			return result;
		}( ) };
		template<auto I, $Size<1> Uint8>
		Inline static constexpr bool cmpBytesEntries ( Uint8* ptr )noexcept {
			static constexpr ComparisonEntryBytes entry { bytesEntries [ I ] };
			static constexpr std::size_t offset { entry.offset };
			static constexpr std::uint8_t size { entry.size };
			static constexpr auto bytes { [ ] ( )->UnsignedBits<size * 8>
			{
				/* */if constexpr ( size == 1 )return *elements [ offset ].byte;
				else if constexpr ( size == 2 )return Bytes::concat<std::uint16_t> ( *elements [ offset ].byte, *elements [ offset + 1 ].byte );
				else if constexpr ( size == 4 )return Bytes::concat<std::uint32_t> ( *elements [ offset ].byte, *elements [ offset + 1 ].byte, *elements [ offset + 2 ].byte, *elements [ offset + 3 ].byte );
				else if constexpr ( size == 8 )return Bytes::concat<std::uint64_t> ( *elements [ offset ].byte, *elements [ offset + 1 ].byte, *elements [ offset + 2 ].byte, *elements [ offset + 3 ].byte, *elements [ offset + 4 ].byte, *elements [ offset + 5 ].byte, *elements [ offset + 6 ].byte, *elements [ offset + 7 ].byte );
			}( ) };
			return *reinterpret_cast< const decltype( bytes )* >( ptr + offset ) == bytes;
		}
		template<auto I, $Size<1> Uint8>
		Inline static constexpr bool cmpNibbleEntry ( Uint8* ptr )noexcept {
			static constexpr ComparisonEntryNibble entry { nibbleEntries [ I ] };
			static constexpr std::size_t offset { entry.offset };
			static constexpr Opt<std::uint8_t> low { entry.low };
			static constexpr Opt<std::uint8_t> high { entry.high };
			if constexpr ( low )
				return reinterpret_cast< const Nibbles* >( ptr + offset )->low == constant<*low>;
			else if constexpr ( high )
				return reinterpret_cast< const Nibbles* >( ptr + offset )->high == constant<*high>;
		}
		template<$Size<1> Uint8, auto...I, auto...J>
		Inline static constexpr bool isMatchImpl ( Uint8* ptr, std::index_sequence<I...>, std::index_sequence<J...> )noexcept {
			return ( cmpBytesEntries<I> ( ptr )&&... ) && ( cmpNibbleEntry<J> ( ptr )&&... );
		}
		template<$Size<1> Uint8>
		Inline static constexpr bool isMatch ( Uint8* ptr )noexcept {
			return isMatchImpl ( ptr, std::make_index_sequence<bytesEntries.size ( )>{}, std::make_index_sequence<nibbleEntries.size ( )>{} );
		}
		template<std::size_t...Indexes>
		static consteval auto deleteElement ( )noexcept {
			return Sequence<details::create_modified_array_for_sequence<Elements, Indexes...> ( )>{};
		}
	};
	template<FixedString str>
	constexpr ConstVector<Element, str.size ( )> parsePatternString ( )noexcept {
		constexpr auto isHexDigit { [ ] ( char c ) { return ( c >= '0' && c <= '9' ) || ( c >= 'a' && c <= 'f' ) || ( c >= 'A' && c <= 'F' ); } };
		constexpr auto char2hexDigit { [ ] ( char c )-> std::uint8_t
		{
			if ( c >= '0' && c <= '9' ) return c - '0';
			if ( c >= 'a' && c <= 'f' ) return c - 'a' + 10;
			if ( c >= 'A' && c <= 'F' ) return c - 'A' + 10;
			UNREACHABLE;
		} };
		constexpr std::size_t size { str.size ( ) };
		const char* pBegin { str.data ( ) };
		const char* pEnd { pBegin + size };
		ConstVector<Element, size> result;
		if constexpr ( size ) {
			bool expectSpace {};
			for ( const char* pChar { pBegin }; pChar != pEnd;) {
				const char c { *pChar };
				if ( c == ' ' ) {
					if ( !expectSpace )
						UNREACHABLE;
					++pChar;
					expectSpace = false;
				}
				else {
					if ( expectSpace )UNREACHABLE;
					if ( c == '?' ) {
						if ( pChar + 1 == pEnd ) {
							pChar += 1;
							result.push_back ( {} );
						}
						else {
							const char c1 { pChar [ 1 ] };
							if ( c1 == ' ' ) {
								pChar += 1;
								result.push_back ( {} );
							}
							else if ( c1 == '?' ) {
								pChar += 2;
								result.push_back ( {} );
							}
							else if ( isHexDigit ( c1 ) ) {
								result.push_back ( Element { char2hexDigit ( c1 ), {} } );
								pChar += 2;
							}
							else
								UNREACHABLE;
						}
					}
					else {
						if ( !isHexDigit ( c ) )UNREACHABLE;
						if ( pChar + 1 == pEnd ) {
							result.push_back ( char2hexDigit ( c ) );
							pChar += 1;
						}
						else {
							const char c1 { pChar [ 1 ] };
							if ( c1 == ' ' ) {
								result.push_back ( char2hexDigit ( c ) );
								pChar += 1;
							}
							else if ( c1 == '?' ) {
								result.push_back ( Element { {}, char2hexDigit ( c ) } );
								pChar += 2;
							}
							else if ( isHexDigit ( c1 ) ) {
								result.push_back ( static_cast< std::uint8_t >( char2hexDigit ( c ) * 0x10 + char2hexDigit ( c1 ) ) );
								pChar += 2;
							}
							else
								UNREACHABLE;
						}
					}
					expectSpace = true;
				}
			}
		}
		return result;
	}
	template<FixedString str>
	constexpr auto makeBytePattern ( )noexcept {
		constexpr ConstVector<Element, str.size ( )> arr { parsePatternString<str> ( ) };
		return [ = ]<auto...I>( std::index_sequence<I...> ) {
			return Sequence < std::array<Element, arr.size ( )>{arr [ I ]...} > {};
		}( std::make_index_sequence<arr.size ( )>{} );
	}
}
template<class Container, class T>concept LinearContainerOf = requires{ *( std::declval<Container> ( ).data ( ) + std::declval<Container> ( ).size ( ) ); }&& $Same<std::remove_cvref_t<decltype( *( std::declval<Container> ( ).data ( ) + std::declval<Container> ( ).size ( ) ) )>, std::remove_cvref_t<T>>;
template<class Container, class...Ts>concept LinearContainerAnyOf = ( LinearContainerOf<Container, Ts> || ... );
template<class T>concept $UInt = std::is_integral_v<std::remove_cvref_t<T>> && std::is_unsigned_v<std::remove_cvref_t<T>>;
namespace Bits
{
	template <$UInt T>Inline constexpr T clearLowestBit ( T value ) noexcept { return value & ( value - 1 ); }
	//Returns the number of trailing 0-bits in x, starting at the least significant bit position. If x is 0, the result is undefined
	Inline constexpr std::uint32_t trailingZeroCount ( std::uint32_t x )noexcept {
	#if MSVC
		if ( std::is_constant_evaluated ( ) ) {
			if ( x == 0 ) return 32; // Defined behavior for 0 for ctz in C++20 is width.
			std::uint32_t count { 0 };
			while ( ( x & 1 ) == 0 && count < 32 ) {
				x >>= 1;
				++count;
			}
			return count;
		}
		else {
			unsigned long result;
			if ( _BitScanForward ( &result, x ) ) // _BitScanForward returns non-zero on success
				return static_cast< std::uint32_t > ( result );
			return 32; // If x is 0, result is undefined, _BitScanForward returns 0. Match C++20 __builtin_ctz.
		}
	#else
		return static_cast< std::uint32_t >( __builtin_ctz ( x ) );
	#endif
	}
}
#if MSVC
#define DEFINE_AVX_BYTES(name,x) static constexpr __m256i name{ .m256i_u8{x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x} }
#else
#define DEFINE_AVX_BYTES(name,x) static constexpr __m256i name{ __builtin_bit_cast(__m256i,std::array<std::uint8_t,32>{x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x,x}) }
#endif
namespace BytePattern
{
	template<auto pattern, std::intptr_t Offset>
	struct Scanner {
		using Pattern = decltype( pattern );
		static constexpr std::intptr_t offset { Offset };
		static constexpr std::size_t numElements { Pattern::numElements };
		static constexpr Opt<std::size_t> iFirstByte { [ ] ( )->Opt<std::size_t>
		{
			for ( std::size_t i{}; i < Pattern::elements.size ( ); ++i )
				if ( Pattern::elements [ i ].byte )
					return i;
			return {};
		}( ) };
		static constexpr Opt<std::size_t> iLastByte { [ ] ( )->Opt<std::size_t>
		{
			std::size_t result{Pattern::elements.size ( )};
			for ( std::size_t i{}; i < Pattern::elements.size ( ); ++i )
				if ( Pattern::elements [ i ].byte )
					result = i;
			if ( result == Pattern::elements.size ( ) )return {};
			else return result;
		}( ) };
		//bytes == 0, nibbles >= 1
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( !iFirstByte.has_value ( ) )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search_unbounded ( Uint8* pBegin, Action&&...action )noexcept//todo:optimize
		{
			for ( ;;) {
				if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
				{
					( action ( pBegin + offset ), ... );
					if constexpr ( sizeof...( action ) == 0 )
						return pBegin + offset;
				}
				++pBegin;
			}
		}
		//bytes == 1, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte == *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search_unbounded ( Uint8* pBegin, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			for ( ;; pBegin += sizeof ( __m256i ) ) {
				const __m256i block { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
				const __m256i eq { _mm256_cmpeq_epi8 ( first, block ) };
				for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( eq ) ) }; mask; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
				{
					const auto bitPos { Bits::trailingZeroCount ( mask ) };
					if ( decltype( Pattern::template deleteElement<iFirst> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
					{
						( action ( pBegin + bitPos + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + bitPos + offset;
					}
				}
			}
		}
		//bytes >= 2, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte != *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search_unbounded ( Uint8* pBegin, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			static constexpr auto iLast { compact<*iLastByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			DEFINE_AVX_BYTES ( last, *Pattern::elements [ iLast ].byte );
			for ( ;; pBegin += sizeof ( __m256i ) ) {
				const __m256i block_first { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
				const __m256i block_last { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iLast ) ) };
				const __m256i eq_first { _mm256_cmpeq_epi8 ( first, block_first ) };
				const __m256i eq_last { _mm256_cmpeq_epi8 ( last, block_last ) };
				for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( _mm256_and_si256 ( eq_first, eq_last ) ) ) }; mask != 0; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
				{
					const auto bitPos { Bits::trailingZeroCount ( mask ) };
					if ( decltype( Pattern::template deleteElement<iFirst, iLast> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
					{
						( action ( pBegin + bitPos + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + bitPos + offset;
					}
				}
			}
		}
		//bytes == 0, nibbles >= 1
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( !iFirstByte.has_value ( ) )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, std::size_t size, Action&&...action )noexcept//todo:optimize
		{
			if ( size >= numElements ) [[likely]]//prevent pEnd underflow
			{
				Uint8* const pEnd { pBegin + size - numElements };
				while ( pBegin <= pEnd ) [[likely]]
				{
					if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
					{
						( action ( pBegin + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + offset;
					}
					++pBegin;
				}
			}
			if constexpr ( sizeof...( action ) == 0 )
				return nullptr;
		}
		//bytes == 1, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte == *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, std::size_t size, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			if ( size >= numElements ) [[likely]]//prevent pEnd underflow
			{
				Uint8* const pEnd { pBegin + size - numElements };
				if ( numElements > 0 && size >= numElements + sizeof ( __m256i ) - 1 ) // Ensure pBegin + iFirst + (sizeof(__m256i) -1) is valid. More general: size >= iFirst + sizeof(__m256i) && size >= numElements
					// Simpler check: size >= iFirst + sizeof(__m256i)
					// Corrected check for loop: (pBegin + iFirst) should be readable up to (pBegin + iFirst + sizeof(__m256i) -1)
					// The loop runs as long as (pBegin + iFirst + sizeof(__m256i) -1) < (pBegin_orig + size).
					// And also pBegin <= pEnd.
					// A common way to write this is: pEndSimd = pBegin_orig + size - (iFirst + sizeof(__m256i)). Loop while pBegin <= pEndSimd.
					// But pBegin is also used for Pattern::isMatch, which reads up to pBegin + numElements -1.
					// So, pBegin + numElements -1 < pBegin_orig + size.
					// Let's use a conservative bound that satisfies both SIMD reads and scalar pattern matching.
					// For SIMD: pBegin + iFirst + sizeof(__m256i) <= pBegin_orig + size
					// For scalar: pBegin + numElements <= pBegin_orig + size
					// So pBegin must be <= pBegin_orig + size - max(iFirst + sizeof(__m256i), numElements)
					// The original condition was: size >= numElements + sizeof(__m256i). This implies pBegin <= pEndSimd where pEndSimd = pBegin_orig + size - numElements - sizeof(__m256i)
					// This is safe for pBegin in Pattern::isMatch. But is it safe for _mm256_loadu_si256(ptr + iFirst)?
					// pBegin + iFirst for _mm256_loadu_si256 should be fine if pBegin increments by sizeof(__m256i) and max pBegin in loop is pEndSimd.
					// Max address read by SIMD: pEndSimd + iFirst + sizeof(__m256i) - 1
					// = pBegin_orig + size - numElements - sizeof(__m256i) + iFirst + sizeof(__m256i) - 1
					// = pBegin_orig + size - numElements + iFirst - 1
					// This must be < pBegin_orig + size. So, size - numElements + iFirst - 1 < size --> iFirst < numElements + 1. (This is true if iFirst is a valid index)
					// The original condition `size >= numElements + sizeof(__m256i)` seems fine and conservative.
				{
					Uint8* const pEndSimd { pBegin + size - ( numElements > 0 ? numElements - 1 : 0 ) - sizeof ( __m256i ) }; // ensure pBegin + (numElements-1) is valid and pBegin + iFirst + sizeof(__m256i) -1 is valid
					for ( ; pBegin <= pEndSimd; pBegin += sizeof ( __m256i ) ) { // Check if pBegin + iFirst is safe for load
						const __m256i block { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
						const __m256i eq { _mm256_cmpeq_epi8 ( first, block ) };
						for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( eq ) ) }; mask; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
						{
							const auto bitPos { Bits::trailingZeroCount ( mask ) };
							if ( pBegin + bitPos <= pEnd ) { // Check candidate is not past pEnd
								if ( decltype( Pattern::template deleteElement<iFirst> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
								{
									( action ( pBegin + bitPos + offset ), ... );
									if constexpr ( sizeof...( action ) == 0 )
										return pBegin + bitPos + offset;
								}
							}
							else { // if bitPos would go past pEnd, subsequent bits also will.
								break;
							}
						}
					}
				}
				[[unlikely]]; // Fallthrough for remaining part or small sizes
				for ( ; pBegin <= pEnd; ++pBegin )
					if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
					{
						( action ( pBegin + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + offset;
					}
			}
			if constexpr ( sizeof...( action ) == 0 )
				return nullptr;
		}
		//bytes >= 2, nibbles >= 0
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>
			requires( iFirstByte.has_value ( ) && iLastByte.has_value ( ) && *iFirstByte != *iLastByte )
		Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, std::size_t size, Action&&...action )noexcept {
			static constexpr auto iFirst { compact<*iFirstByte> };
			static constexpr auto iLast { compact<*iLastByte> };
			DEFINE_AVX_BYTES ( first, *Pattern::elements [ iFirst ].byte );
			DEFINE_AVX_BYTES ( last, *Pattern::elements [ iLast ].byte );
			if ( size >= numElements ) [[likely]]//prevent pEnd underflow
			{
				Uint8* const pEnd { pBegin + size - numElements };
				// Ensure reads for block_first and block_last are valid.
				// Max index read is iLast. So, pBegin + iLast + sizeof(__m256i) -1 must be < pBegin_orig + size
				// pBegin loop max: pBegin_orig + size - (iLast + sizeof(__m256i))
				// The loop needs pBegin <= pEndSimd.
				// pEndSimd should be pBegin_orig + size - std::max(numElements, iLast + (std::uint8_t)sizeof(__m256i)); (rough idea)
				// The original condition: size >= sizeof ( __m256i ) + iLast
				// This means pBegin_orig + size >= pBegin_orig + sizeof(__m256i) + iLast
				// So pEndSimd = pBegin_orig + size - (sizeof(__m256i) + iLast) is well-defined.
				// Max address read for block_last: (pEndSimd) + iLast + sizeof(__m256i) -1
				// = pBegin_orig + size - sizeof(__m256i) - iLast + iLast + sizeof(__m256i) -1 = pBegin_orig + size -1. This is safe.
				// Also need to ensure pBegin + bitPos <= pEnd for the scalar check.
				if ( size >= ( iLast + sizeof ( __m256i ) ) && size >= numElements ) [[likely]]
				{
					// Ensure pBegin for Pattern::isMatch never exceeds pEnd.
					// pBegin for SIMD can go up to a point where pBegin + iLast + sizeof(__m256i) -1 is the last byte of the buffer.
					// Max offset for SIMD read is iLast.
					Uint8* const pEndSimd { pBegin + size - ( iLast + sizeof ( __m256i ) ) };
					for ( ; pBegin <= pEndSimd; pBegin += sizeof ( __m256i ) ) [[likely]]
					{
						const __m256i block_first { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iFirst ) ) };
						const __m256i block_last { _mm256_loadu_si256 ( reinterpret_cast< const __m256i* >( pBegin + iLast ) ) };
						const __m256i eq_first { _mm256_cmpeq_epi8 ( first, block_first ) };
						const __m256i eq_last { _mm256_cmpeq_epi8 ( last, block_last ) };
						for ( std::uint32_t mask { static_cast< std::uint32_t >( _mm256_movemask_epi8 ( _mm256_and_si256 ( eq_first, eq_last ) ) ) }; mask != 0; mask = Bits::clearLowestBit ( mask ) ) [[unlikely]]
						{
							const auto bitPos { Bits::trailingZeroCount ( mask ) };
							if ( pBegin + bitPos <= pEnd ) { // Check candidate is not past pEnd
								if ( decltype( Pattern::template deleteElement<iFirst, iLast> ( ) )::isMatch ( pBegin + bitPos ) ) [[unlikely]]
								{
									( action ( pBegin + bitPos + offset ), ... );
									if constexpr ( sizeof...( action ) == 0 )
										return pBegin + bitPos + offset;
								}
							}
							else { // if bitPos would go past pEnd
								break;
							}
						}
					}
				}
				[[unlikely]]; // Fallthrough for remaining part or small sizes
				for ( ; pBegin <= pEnd; ++pBegin )
					if ( Pattern::isMatch ( pBegin ) ) [[unlikely]]
					{
						( action ( pBegin + offset ), ... );
						if constexpr ( sizeof...( action ) == 0 )
							return pBegin + offset;
					}
			}
			if constexpr ( sizeof...( action ) == 0 )
				return nullptr;
		}
		template<$Size<1> Uint8, Callable<void ( Uint8* const )>...Action>Inline static std::conditional_t<sizeof...( Action ) == 0, Uint8*, void> search ( Uint8* pBegin, Uint8* pEnd, Action&&...action )noexcept { return search ( pBegin, static_cast< std::size_t >( pEnd - pBegin ), FWD ( action )... ); } // Added FWD
		template<LinearContainerAnyOf<char, std::uint8_t> Container, Callable<void ( ElementOf<Container>* )>...Action>Inline static auto search ( Container&& bytes, Action&&...action )noexcept { return search ( bytes.data ( ), bytes.size ( ), FWD ( action )... ); } // Added FWD
	};
}
template<FixedString str, std::intptr_t offset = 0>constexpr BytePattern::Scanner<BytePattern::makeBytePattern<str> ( ), offset> byte_scanner {};
```

`emulator/src/utilities.cpp`:

```cpp
#include "pch.hpp"

uint64_t EmulationContext::translate_reg ( x86_reg reg, uint64_t value, uint8_t op_size ) const noexcept {
	// Map sub-registers to their 64-bit parent and extract the right bits
	switch ( reg ) {
		// RAX family
		case X86_REG_RAX: return value;
		case X86_REG_EAX: return value & 0xFFFFFFFF;
		case X86_REG_AX:  return value & 0xFFFF;
		case X86_REG_AH:  return ( value >> 8 ) & 0xFF;
		case X86_REG_AL:  return value & 0xFF;

			// RBX family
		case X86_REG_RBX: return value;
		case X86_REG_EBX: return value & 0xFFFFFFFF;
		case X86_REG_BX:  return value & 0xFFFF;
		case X86_REG_BH:  return ( value >> 8 ) & 0xFF;
		case X86_REG_BL:  return value & 0xFF;

			// RCX family
		case X86_REG_RCX: return value;
		case X86_REG_ECX: return value & 0xFFFFFFFF;
		case X86_REG_CX:  return value & 0xFFFF;
		case X86_REG_CH:  return ( value >> 8 ) & 0xFF;
		case X86_REG_CL:  return value & 0xFF;

			// RDX family
		case X86_REG_RDX: return value;
		case X86_REG_EDX: return value & 0xFFFFFFFF;
		case X86_REG_DX:  return value & 0xFFFF;
		case X86_REG_DH:  return ( value >> 8 ) & 0xFF;
		case X86_REG_DL:  return value & 0xFF;

			// RSI family
		case X86_REG_RSI: return value;
		case X86_REG_ESI: return value & 0xFFFFFFFF;
		case X86_REG_SI:  return value & 0xFFFF;
		case X86_REG_SIL: return value & 0xFF;

			// RDI family
		case X86_REG_RDI: return value;
		case X86_REG_EDI: return value & 0xFFFFFFFF;
		case X86_REG_DI:  return value & 0xFFFF;
		case X86_REG_DIL: return value & 0xFF;

			// RBP family
		case X86_REG_RBP: return value;
		case X86_REG_EBP: return value & 0xFFFFFFFF;
		case X86_REG_BP:  return value & 0xFFFF;
		case X86_REG_BPL: return value & 0xFF;

			// RSP family
		case X86_REG_RSP: return value;
		case X86_REG_ESP: return value & 0xFFFFFFFF;
		case X86_REG_SP:  return value & 0xFFFF;
		case X86_REG_SPL: return value & 0xFF;

			// R8-R15 (64-bit and their sub-registers)
		case X86_REG_R8:  return value;
		case X86_REG_R8D: return value & 0xFFFFFFFF;
		case X86_REG_R8W: return value & 0xFFFF;
		case X86_REG_R8B: return value & 0xFF;

		case X86_REG_R9:  return value;
		case X86_REG_R9D: return value & 0xFFFFFFFF;
		case X86_REG_R9W: return value & 0xFFFF;
		case X86_REG_R9B: return value & 0xFF;

		case X86_REG_R10:  return value;
		case X86_REG_R10D: return value & 0xFFFFFFFF;
		case X86_REG_R10W: return value & 0xFFFF;
		case X86_REG_R10B: return value & 0xFF;

		case X86_REG_R11:  return value;
		case X86_REG_R11D: return value & 0xFFFFFFFF;
		case X86_REG_R11W: return value & 0xFFFF;
		case X86_REG_R11B: return value & 0xFF;

		case X86_REG_R12:  return value;
		case X86_REG_R12D: return value & 0xFFFFFFFF;
		case X86_REG_R12W: return value & 0xFFFF;
		case X86_REG_R12B: return value & 0xFF;

		case X86_REG_R13:  return value;
		case X86_REG_R13D: return value & 0xFFFFFFFF;
		case X86_REG_R13W: return value & 0xFFFF;
		case X86_REG_R13B: return value & 0xFF;

		case X86_REG_R14:  return value;
		case X86_REG_R14D: return value & 0xFFFFFFFF;
		case X86_REG_R14W: return value & 0xFFFF;
		case X86_REG_R14B: return value & 0xFF;

		case X86_REG_R15:  return value;
		case X86_REG_R15D: return value & 0xFFFFFFFF;
		case X86_REG_R15W: return value & 0xFFFF;
		case X86_REG_R15B: return value & 0xFF;

		default: return value; // Fallback, shouldnt hit this often
	}
}

// Helper to map sub-registers to their 64-bit parent for storage
x86_reg EmulationContext::to_64bit_reg ( x86_reg reg ) const noexcept {
	switch ( reg ) {
		case X86_REG_EAX: case X86_REG_AX: case X86_REG_AH: case X86_REG_AL:
			return X86_REG_RAX;
		case X86_REG_EBX: case X86_REG_BX: case X86_REG_BH: case X86_REG_BL:
			return X86_REG_RBX;
		case X86_REG_ECX: case X86_REG_CX: case X86_REG_CH: case X86_REG_CL:
			return X86_REG_RCX;
		case X86_REG_EDX: case X86_REG_DX: case X86_REG_DH: case X86_REG_DL:
			return X86_REG_RDX;
		case X86_REG_ESI: case X86_REG_SI: case X86_REG_SIL:
			return X86_REG_RSI;
		case X86_REG_EDI: case X86_REG_DI: case X86_REG_DIL:
			return X86_REG_RDI;
		case X86_REG_EBP: case X86_REG_BP: case X86_REG_BPL:
			return X86_REG_RBP;
		case X86_REG_ESP: case X86_REG_SP: case X86_REG_SPL:
			return X86_REG_RSP;
		case X86_REG_R8D: case X86_REG_R8W: case X86_REG_R8B:
			return X86_REG_R8;
		case X86_REG_R9D: case X86_REG_R9W: case X86_REG_R9B:
			return X86_REG_R9;
		case X86_REG_R10D: case X86_REG_R10W: case X86_REG_R10B:
			return X86_REG_R10;
		case X86_REG_R11D: case X86_REG_R11W: case X86_REG_R11B:
			return X86_REG_R11;
		case X86_REG_R12D: case X86_REG_R12W: case X86_REG_R12B:
			return X86_REG_R12;
		case X86_REG_R13D: case X86_REG_R13W: case X86_REG_R13B:
			return X86_REG_R13;
		case X86_REG_R14D: case X86_REG_R14W: case X86_REG_R14B:
			return X86_REG_R14;
		case X86_REG_R15D: case X86_REG_R15W: case X86_REG_R15B:
			return X86_REG_R15;
		default: return reg; // Already 64-bit or unhandled
	}
}

void EmulationContext::dump_state ( ) const {
	std::println ( "Registers:" );
	auto print_reg = [ & ] ( KGPR reg )
	{
		return cpu->registers [ reg ];
	};
	std::println ( "\tRAX: {:016x}  RBX: {:016x}  RCX: {:016x}  RDX: {:016x}  RSI: {:016x}  RDI: {:016x}",
							 print_reg ( KRAX ), print_reg ( KRBX ),
							 print_reg ( KRCX ), print_reg ( KRDX ),
							 print_reg ( KRSI ), print_reg ( KRDI ) );
	std::println ( "\tRSP: {:016x}  RBP: {:016x}  R8:  {:016x}  R9:  {:016x}  R10: {:016x}  R11: {:016x}",
							 print_reg ( KRSP ), print_reg ( KRBP ),
							 print_reg ( KR8 ), print_reg (  KR9 ),
							 print_reg ( KR10 ), print_reg ( KR11 ) );
	std::println ( "\tR12: {:016x}  R13: {:016x}  R14: {:016x}  R15: {:016x}",
							 print_reg ( KR12 ), print_reg ( KR13 ),
							 print_reg ( KR14 ), print_reg ( KR15 ) );
	std::println ( "Flags: CF={} PF={} ZF={} SF={} OF={}",
							 ( char ) cpu->cpu_flags.flags.CF, ( char ) cpu->cpu_flags.flags.PF, ( char ) cpu->cpu_flags.flags.ZF,
							 ( char ) cpu->cpu_flags.flags.SF, ( char ) cpu->cpu_flags.flags.OF );
	for ( auto start = ( int ) X86_REG_XMM0; start < ( int ) X86_REG_XMM15; ++start ) {
		std::print ( "XMM{}: {} ", start - X86_REG_XMM0, ( *cpu->avx_registers ) [ start - X86_REG_XMM0 ].convert_to<double> ( ) );
		if ( start % 5 == 0 ) {
			std::print ( "\n" );
		}
	}
	std::println ( "MXCSR Flags: IE={} DE={}, ZE={}, OE={}, UE={}, PE={}",
								 ( char ) cpu->cpu_flags.mxcsr.IE,
								 ( char ) cpu->cpu_flags.mxcsr.DE,
								 ( char ) cpu->cpu_flags.mxcsr.ZE,
								 ( char ) cpu->cpu_flags.mxcsr.OE,
								 ( char ) cpu->cpu_flags.mxcsr.UE,
								 ( char ) cpu->cpu_flags.mxcsr.PE );

	for ( int i = 0; i < 8; ++i ) {
		int phys_idx = get_fpu_phys_idx ( i );
		if ( get_fpu_tag ( phys_idx ) != FPU_TAG_EMPTY ) {
			double log_val = cpu->fpu.fpu_stack [ phys_idx ].convert_to<double> ( );
			std::println ( "[ST{}] - {}", i, log_val );
		}
		else {
			std::println ( "[ST{}] - <empty>", i );
		}
	}
	std::println ( "Stack (size={:x}):", stack_allocated );

	std::println ( "" );
}

void InstructionEffect::normalize_registers ( EmulationContext* ctx ) {
	std::unordered_set<x86_reg> normalized {};
	for ( auto reg : modified_regs ) {
		normalized.insert ( ctx->to_64bit_reg ( reg ) );
	}
	modified_regs = normalized;
}
static void map_all_sections ( EmulationContext& state, HMODULE mod ) {
	uint64_t base = ( uint64_t ) mod;
	PE::Parser secparser ( base );
	for ( auto& sec : secparser.pe_info_.section_headers ) {
		uint64_t rva = sec.virtual_address;
		uint64_t size = std::max<uint32_t> ( sec.virtual_size, sec.size_of_raw_data );
		uint8_t* data = reinterpret_cast< uint8_t* >( mod ) + rva;
		state.windows->add_module (
			/*handle=*/mod,
			/*va=*/base + rva,
			/*size=*/size,
			/*backing_ptr=*/data
		);
	}
}


// we need to resolve dependancies recursively, since on newer windows versions
// kernel32 calls into kernelbase, which we may not catch.
void EmulationContext::initialize_imports ( std::unique_ptr<PE::Parser>& parser ) {
	if ( !parser ) return;

	auto imports_data = parser->get_imports ( );
	std::unordered_set<std::string> modules_parsed {};
	for ( const auto& [dllName, funcs] : imports_data ) {
		HMODULE mod = GetModuleHandleA ( dllName.c_str ( ) );
		if ( !mod ) {
			mod = LoadLibraryExA (
				dllName.c_str ( ),
				nullptr,
				DONT_RESOLVE_DLL_REFERENCES
			);
		}
		modules_parsed.emplace ( dllName );
		if ( !mod ) {
			std::println ( "[!] Failed to map {}: {}", dllName, GetLastError ( ) );
			continue;
		}

		map_all_sections ( *this, mod );
		for ( const auto& entry : funcs ) {
			windows->import_multi_map.insert ( { entry.first, entry.second } );
		}

		PE::Parser modParser ( ( uint64_t ) mod );
		auto import_map = modParser.get_imports ( );
		for ( const auto& kv : import_map ) {
			const auto& key_name = kv.first;
			if ( modules_parsed.contains ( key_name ) ) {
				continue;
			}
			HMODULE sub_mod = GetModuleHandleA ( key_name.c_str ( ) );
			if ( !sub_mod ) {
				sub_mod = LoadLibraryExA (
				key_name.c_str ( ),
				nullptr,
				DONT_RESOLVE_DLL_REFERENCES
				);
			}
			if ( !sub_mod ) {
				continue;
			}

			map_all_sections ( *this, sub_mod );
			modules_parsed.emplace ( key_name );
			for ( const auto& entry : kv.second ) {
				windows->import_multi_map.insert ( { entry.first, entry.second } );
			}
		}

		auto [expDir, expEntries] = modParser.get_export_directory ( );

		for ( auto& [funcName, iatAddr] : funcs ) {
			uint32_t rva = 0;
			for ( auto const& entry : expEntries ) {
				if ( std::get<0> ( entry ) == funcName ) {
					rva = uint32_t ( std::get<3> ( entry ) - reinterpret_cast< uint64_t >( mod ) );
					break;
				}
			}
			if ( !rva ) {
				std::println ( "[!] {} does not export {}", dllName, funcName );
				continue;
			}

			//uint64_t emuVA = ( uint64_t ) mod + rva;
			//DWORD old;
			//VirtualProtect ( ( void* ) iatAddr, sizeof ( uint64_t ), PAGE_READWRITE, &old );
			//*reinterpret_cast< uint64_t* >( iatAddr ) = emuVA;
			//windows->import_multi_map.insert ( { funcName, emuVA } );
			//windows->import_multi_map.insert ( { funcName, iatAddr } );
			//
			//VirtualProtect ( ( void* ) iatAddr, sizeof ( uint64_t ), old, &old );
		}
	}
}



bool EmulationContext::is_string_at ( int64_t base, int64_t max_len ) const {
	__debugbreak ( );
	return false;
}
```

`exception_tests/exception_tests.cpp`:

```cpp
#include "header.hpp"
#include <semantics/src/pch.hpp>
#include <shared/context.hpp>
#include <shared/capstone++.hpp>
#include <print>
#include <format>

std::vector<ExceptionTestShellcode> g_exception_tests;

TestResult run_test_shellcode ( const ExceptionTestShellcode& test_case ) {
	TestResult result;
	result.message = "[" + test_case.name + "] ";

	constexpr size_t STACK_SIZE = 0x10000;
	constexpr size_t STACK_ALIGNMENT = 16;
	constexpr int MAX_STEPS = 500;

	EmulationContext state;
	int64_t rsp_offset_dummy = 0;
	InstructionEffect effectd {};

	state.rsp_base = std::unique_ptr<uint8_t [ ], void( * )( uint8_t* )> (
		static_cast< uint8_t* >( _aligned_malloc ( STACK_SIZE, STACK_ALIGNMENT ) ),
		[ ] ( uint8_t* ptr ) { _aligned_free ( ptr ); }
	);
	if ( !state.rsp_base ) {
		result.message += "Failed to allocate stack.";
		return result;
	}
	state.stack_allocated = STACK_SIZE;
	uint64_t stack_base_addr = reinterpret_cast< uint64_t >( state.rsp_base.get ( ) );
	uint64_t initial_rsp = ( stack_base_addr + STACK_SIZE - 0x28 ) & ~15ULL;
	state.set_reg ( X86_REG_RSP, initial_rsp, 8, effectd );
	state.cpu->current_privilege_level = 3; // Assume user mode for tests

	// --- Set required RFLAGS.AC if needed by test ---
	if ( test_case.requires_ac_flag ) {
		state.cpu->cpu_flags.flags.AC = 1;
		// state.cr0.AM = 1; // Assuming CR0.AM is effectively 1 in 64-bit mode if emulated
		std::println ( "DEBUG: Set RFLAGS.AC=1 for test '{}'", test_case.name );
	}
	else {
		state.cpu->cpu_flags.flags.AC = 0; // Ensure AC is off otherwise
	}
	// ---

	LPVOID shellcode_mem = VirtualAlloc (
		nullptr,
		test_case.bytes.size ( ),
		MEM_COMMIT | MEM_RESERVE,
		PAGE_EXECUTE_READWRITE // Use RWX for simplicity in testing writes to code
	);
	if ( !shellcode_mem ) {
		result.message += "Failed to VirtualAlloc executable memory.";
		return result;
	}
	uint64_t shellcode_base_addr = reinterpret_cast< uint64_t >( shellcode_mem );
	memcpy ( shellcode_mem, test_case.bytes.data ( ), test_case.bytes.size ( ) );

	capstone::Decoder* decoder = new capstone::Decoder ( static_cast< uint8_t* >( shellcode_mem ), test_case.bytes.size ( ) - 1, shellcode_base_addr );
	if ( !decoder->can_decode ( ) ) {
		result.message += "Failed to initialize Capstone decoder.";
		VirtualFree ( shellcode_mem, 0, MEM_RELEASE );
		return result;
	}
	state.decoder.emplace_back ( decoder );

	decoder->set_ip ( shellcode_base_addr );

	int steps = 0;
	capstone::Instruction current_instr; // Store current instruction being processed

	while ( steps < MAX_STEPS && decoder->can_decode ( ) ) {
		uint64_t ip_before_decode = decoder->ip ( );
		result.stop_rip = ip_before_decode; // Tentative stop RIP

		current_instr = decoder->decode ( );

		GuestExceptionInfo exception_info = {}; // Holds exception detected in this cycle
		bool run_handler = true;
		bool handler_executed_cleanly = false;


		if ( !current_instr.is_valid ( ) ) {
			exception_info.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, ip_before_decode );
			run_handler = false;
		}
		else {
			const InstructionExceptionInfo& baseInfo = g_instruction_exception_table [ current_instr.mnemonic ( ) ];
			PreCheckInfo check_info = {};
			populate_pre_check_info ( check_info, state, current_instr, baseInfo );

			// Run pre-checks
			exception_info = check_instruction_exceptions ( state, current_instr, check_info );
			if ( exception_info.exception_occurred ) {
				run_handler = false; // Don't run handler if pre-check failed
			}
		}

		// Check for expected INT3 marker *after* pre-checks but *before* handler
		if ( run_handler && current_instr.mnemonic ( ) == X86_INS_INT3 && test_case.expected_exception_code == 0 ) {
			result.message += "Reached expected INT3 marker.";
			result.success = true;
			result.stop_rip = current_instr.ip ( ); // Stop at the INT3
			break;
		}

		// Run the handler if no pre-check exception occurred
		if ( run_handler ) {
			InstructionEffect effect; // Dummy effect
			try {
				auto it = instruction_handlers.find ( static_cast< x86_insn >( current_instr.mnemonic ( ) ) );
				if ( it != instruction_handlers.end ( ) && *it->second ) {
					std::println ( "[{}]{}", state.call_stack.size ( ), std::format ( "{:>{}} ({:#x}) {}", "", state.call_stack.size ( ), current_instr.ip ( ), current_instr.to_string_no_address ( ) ) );
					( *it->second )( current_instr, state, effect );
					handler_executed_cleanly = true;
				}
				else {
					// Handler not found for a valid instruction? Treat as illegal.
					exception_info.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, current_instr.ip ( ) );
					handler_executed_cleanly = false; // Handler didn't run
				}
			}
			catch ( const GuestExceptionInfo& handler_ex ) {
				// Handler itself detected and threw an exception (e.g., DIV/IDIV/BOUND)
				exception_info = handler_ex;
				handler_executed_cleanly = true; // Handler ran partially or fully before throwing
			}
			catch ( const std::exception& handler_host_ex ) {
				// Host exception during handler execution (e.g., null pointer in handler logic)
				result.message += " Host Exception in Handler: " + std::string ( handler_host_ex.what ( ) );
				// Map unexpected host errors to a generic guest fault like AV
				exception_info.set_access_violation ( current_instr.ip ( ), 0, false );
				handler_executed_cleanly = false;
			}
		}


		// Run post-checks ONLY if handler executed cleanly AND no exception so far
		if ( handler_executed_cleanly && !exception_info.exception_occurred ) {
			const InstructionExceptionInfo& baseInfo = g_instruction_exception_table [ current_instr.mnemonic ( ) ];
			uint8_t op_size = get_primary_operand_size ( current_instr ); // Simplified helper

			// Post-execution arithmetic check (mainly for INTO)
			GuestExceptionInfo post_ex = check_post_execution_arithmetic ( state, baseInfo, current_instr.ip ( ), op_size );
			if ( post_ex.exception_occurred ) {
				exception_info = post_ex;
			}
			else {
				// Post-execution FPU/SIMD check
				// NOTE: Requires handlers to have updated FSW/MXCSR correctly
				post_ex = check_post_execution_fpu_simd ( state, baseInfo, current_instr.ip ( ) );
				if ( post_ex.exception_occurred ) {
					exception_info = post_ex;
				}
			}
		}

		// Check if any exception was detected in this cycle
		if ( exception_info.exception_occurred ) {
			result.exception_occurred = true;
			result.captured_exception = exception_info;
			result.stop_rip = exception_info.ExceptionAddress; // Use the RIP from the exception record
			result.message += std::format ( " Detected Exception 0x{:X}.", exception_info.ExceptionCode );
			break; // Stop emulation
		}

		// Check for unexpected INT3 marker (if handler ran and instruction was INT3)
		if ( handler_executed_cleanly && current_instr.mnemonic ( ) == X86_INS_INT3 && test_case.expected_exception_code != 0 ) {
			result.message += " Reached INT3 marker unexpectedly (an exception was expected).";
			result.success = false;
			result.stop_rip = current_instr.ip ( ); // Stop at the unexpected INT3
			break;
		}


		steps++;
	} // End while loop

	bool stopped_at_marker_int3 = false;
	if ( !result.exception_occurred && // No *other* exception occurred
			!test_case.bytes.empty ( ) && // Shellcode not empty
			result.stop_rip == shellcode_base_addr + test_case.bytes.size ( ) - 1 && // Stopped at last byte
			test_case.bytes.back ( ) == 0xCC ) // Last byte is INT3
	{
		// This implies the loop finished because decode reached the final INT3 marker
		// We need to check if this *was* the expected behavior
		stopped_at_marker_int3 = true;
	}


	// --- Verification ---
	if ( stopped_at_marker_int3 && test_case.expected_exception_code == 0 ) {
		// Correctly stopped at the marker INT3 for a test expecting normal termination via marker
		result.success = true;
		result.message += " Success (Reached expected INT3 marker).";

	}
	else if ( result.exception_occurred ) {
		// An exception was captured.
		if ( result.captured_exception.ExceptionCode == test_case.expected_exception_code ) {
			// The captured exception matches the one we expected.
			result.success = true;
			result.message += " Success (Correct exception code captured).";
		}
		else {
			// An exception occurred, but it wasn't the one expected.
			result.success = false;
			result.message += std::format ( " Failure (Expected Exception 0x{:X}, Got 0x{:X}).",
																		test_case.expected_exception_code, result.captured_exception.ExceptionCode );
			// If we expected 0 but got something else (and it wasn't the marker INT3 handled above)
			if ( test_case.expected_exception_code == 0 ) {
				result.message += " An unexpected exception occurred.";
			}
		}
	}
	else { // No exception occurred, and didn't stop at marker INT3 (or marker wasn't expected termination)
		if ( test_case.expected_exception_code == 0 ) {
			// Expected normal termination (no exception, possibly no marker or finished early)
			if ( steps >= MAX_STEPS ) {
				result.message += " Failure (Exceeded max steps, expected normal finish).";
				result.success = false;
			}
			else {
				// Finished before max steps without exception and without marker hit being the goal
				result.message += " Success (Finished normally, no exception expected)."; // Assume finishing early is ok if no marker specified/hit
				result.success = true;
			}
		}
		else {
			// Expected an exception, but none occurred and loop finished.
			result.success = false;
			result.message += std::format ( " Failure (Expected Exception 0x{:X}, but none occurred).", test_case.expected_exception_code );
			if ( steps >= MAX_STEPS ) {
				result.message += " Stopped at max steps.";
			}
			else {
				result.message += std::format ( " Stopped at RIP 0x{:X} without error.", result.stop_rip );
			}
		}
	}

	// --- Cleanup ---
	VirtualFree ( shellcode_mem, 0, MEM_RELEASE );

	return result;
}

void initialize_exception_tests ( ) {
	auto add_nop_int3 = [ ] ( std::vector<uint8_t>& vec )
	{
		vec.push_back ( 0x90 ); // NOP
		vec.push_back ( 0xCC ); // INT3 marker
	};

	// --- #DE Divide By Zero ---
	{
		ExceptionTestShellcode test;
		test.name = "Divide By Zero (#DE)";
		test.expected_exception_code = EXCEPTION_INT_DIVIDE_BY_ZERO; // 0xC0000094
		test.notes = "Triggers #DE via DIV instruction with zero divisor. Handler MUST detect.";
		test.bytes = {
			0x48, 0xC7, 0xC0, 0x0A, 0x00, 0x00, 0x00, // mov rax, 10
			0x48, 0x31, 0xD2,                         // xor rdx, rdx
			0x48, 0x31, 0xC9,                         // xor rcx, rcx
			0x48, 0xF7, 0xF1,                         // div rcx <- Exception expected here
		};
		add_nop_int3 ( test.bytes ); // Marker should not be reached
		g_exception_tests.push_back ( test );
	}

	// --- #UD Illegal Instruction (UD2 Opcode) ---
	{
		ExceptionTestShellcode test;
		test.name = "Illegal Instruction UD2 (#UD)";
		test.expected_exception_code = EXCEPTION_ILLEGAL_INSTRUCTION; // 0xC000001D
		test.notes = "Executes the UD2 instruction.";
		test.bytes = {
			0x0F, 0x0B, // ud2 <- Exception expected here
			0xCC        // int3 marker
		};
		g_exception_tests.push_back ( test );
	}

	// --- #UD Illegal Instruction (LOCK Misuse) ---
	{
		ExceptionTestShellcode test;
		test.name = "Illegal Instruction LOCK Misuse (#UD)";
		test.expected_exception_code = EXCEPTION_ILLEGAL_INSTRUCTION; // 0xC000001D
		test.notes = "Uses LOCK prefix on INC REG, which is invalid.";
		test.bytes = {
			0xF0, 0x48, 0xFF, 0xC0, // lock inc rax <- Exception expected here
			0xCC                   // int3 marker
		};
		g_exception_tests.push_back ( test );
	}

	// --- #BP Breakpoint (INT3) ---
	{
		ExceptionTestShellcode test;
		test.name = "Breakpoint (#BP)";
		test.expected_exception_code = EXCEPTION_BREAKPOINT; // 0x80000003
		test.notes = "Executes INT3 instruction.";
		test.bytes = {
			0xCC, // int3 <- Exception expected here
			0x90, // nop (potentially skipped by exception handling)
			0xCC  // int3 marker
		};
		g_exception_tests.push_back ( test );
	}

	// --- Access Violation (NULL Pointer Read) ---
	{
		ExceptionTestShellcode test;
		test.name = "Access Violation (NULL Read)";
		test.expected_exception_code = EXCEPTION_ACCESS_VIOLATION; // 0xC0000005
		test.notes = "Attempts to read from address 0.";
		test.bytes = {
			0x48, 0x31, 0xDB,             // xor rbx, rbx
			0x48, 0x8B, 0x03,             // mov rax, [rbx] <- Exception expected here
		};
		add_nop_int3 ( test.bytes );
		g_exception_tests.push_back ( test );
	}

	// --- Access Violation (NULL Pointer Write) ---
	{
		ExceptionTestShellcode test;
		test.name = "Access Violation (NULL Write)";
		test.expected_exception_code = EXCEPTION_ACCESS_VIOLATION; // 0xC0000005
		test.notes = "Attempts to write to address 0.";
		test.bytes = {
			0x48, 0x31, 0xDB,                         // xor rbx, rbx
			0x48, 0xC7, 0xC0, 0x7B, 0x00, 0x00, 0x00, // mov rax, 123
			0x48, 0x89, 0x03,                         // mov [rbx], rax <- Exception expected here
		};
		add_nop_int3 ( test.bytes );
		g_exception_tests.push_back ( test );
	}

	// --- Access Violation (Write Code) ---
	{
		ExceptionTestShellcode test;
		test.name = "Access Violation (Write Code)";
		test.expected_exception_code = EXCEPTION_ACCESS_VIOLATION; // 0xC0000005
		test.notes = "Attempts to write to the current instruction pointer (read-only code).";
		test.bytes = {
			// mov byte ptr [rip+0], 0 -> Writes to the byte after the immediate 0
			// Encoding: C6 /0 ib -> C6 05 disp32 ib
			0xC6, 0x05, 0x01, 0x00, 0x00, 0x00, 0x00, // mov byte ptr [rip+1], 0 <- Exception expected here
			0x90, // Target of the write (will cause AV)
			0xCC // INT3 marker (should not be reached)
		};
		// The instruction is 7 bytes. [rip+1] points to the NOP (offset 7).
		g_exception_tests.push_back ( test );
	}


	// --- Datatype Misalignment (#AC) ---
	{
		ExceptionTestShellcode test;
		test.name = "Datatype Misalignment (#AC)";
		test.expected_exception_code = EXCEPTION_DATATYPE_MISALIGNMENT; // 0x80000002
		test.notes = "Requires RFLAGS.AC=1 set by test framework. Uses MOVAPS on unaligned stack address.";
		test.requires_ac_flag = true; // <<< Mark test as needing AC flag set
		test.bytes = {
			0x48, 0x83, 0xEC, 0x20,             // sub rsp, 0x20
			0x48, 0x8D, 0x5C, 0x24, 0x01,       // lea rbx, [rsp+1] (RBX is now rsp+1, unaligned)
			0x0F, 0x28, 0x03,                   // movaps xmm0, [rbx] <- Exception expected here
			0x48, 0x83, 0xC4, 0x20,             // add rsp, 0x20 (cleanup, likely skipped)
		};
		add_nop_int3 ( test.bytes );
		g_exception_tests.push_back ( test );
	}

	// --- Privileged Instruction (#GP) ---
	{
		ExceptionTestShellcode test;
		test.name = "Privileged Instruction (#GP)";
		test.expected_exception_code = EXCEPTION_PRIV_INSTRUCTION; // 0xC0000096
		test.notes = "Executes HLT in user mode (CPL=3).";
		test.bytes = {
			0xF4, // hlt <- Exception expected here
			0xCC  // int3 marker
		};
		g_exception_tests.push_back ( test );
	}

	// --- Stack Overflow (Manual Write Below RSP) ---
	{
		ExceptionTestShellcode test;
		test.name = "Stack Overflow (Manual Write)";
		// Use AV as the expected code, as guard page hit -> AV is more common than specific SO code from OS
		test.expected_exception_code = EXCEPTION_ACCESS_VIOLATION; // 0xC0000005 (likely result)
		// test.expected_exception_code = EXCEPTION_STACK_OVERFLOW; // 0xC00000FD (less likely from hardware/OS directly)
		test.notes = "Writes significantly below RSP. Emulator stack bounds check or host AV should trigger.";
		test.bytes = {
			// mov qword ptr [rsp - 0x10000], rax
			// Encoding: 48 89 84 24 lo_dword -> 48 89 84 24 00 00 FF FF
			0x48, 0x89, 0x84, 0x24, 0x00, 0x00, 0xFF, 0xFF, // mov [rsp-0x10000], rax <- Exception expected here
		};
		add_nop_int3 ( test.bytes );
		g_exception_tests.push_back ( test );
	}

	// --- Array Bounds Exceeded (#BR) ---
	{
		ExceptionTestShellcode test;
		test.name = "Array Bounds Exceeded (#BR)";
		test.expected_exception_code = EXCEPTION_ARRAY_BOUNDS_EXCEEDED; // 0xC000008C
		test.notes = "Uses BOUND instruction with an out-of-bounds index. Handler MUST detect. 32-bit only";
		test.bytes = {
			0x48, 0x83, 0xEC, 0x10,                         // sub rsp, 16
			0xC7, 0x04, 0x24, 0x0A, 0x00, 0x00, 0x00,       // mov dword ptr [rsp], 10 (lower)
			0xC7, 0x44, 0x24, 0x04, 0x14, 0x00, 0x00, 0x00, // mov dword ptr [rsp+4], 20 (upper)
			0xB8, 0x05, 0x00, 0x00, 0x00,                   // mov eax, 5 (index)
			0x62, 0x04, 0x24,                               // bound eax, [rsp] <- Exception expected here
			0x48, 0x83, 0xC4, 0x10,                         // add rsp, 16 (cleanup, likely skipped)
		};
		add_nop_int3 ( test.bytes );
		g_exception_tests.push_back ( test );
	}

	// --- SSE Invalid Operation (#XF -> Invalid Op) ---
	{
		ExceptionTestShellcode test;
		test.name = "SSE Invalid Operation (#XF)";
		test.expected_exception_code = EXCEPTION_FLT_INVALID_OPERATION; // 0xC0000090
		test.notes = "Calculates sqrt(-1.0) after unmasking invalid operation in MXCSR. SQRTSS handler MUST update MXCSR status.";
		test.bytes = {
			0x48, 0x83, 0xEC, 0x10,                         // sub rsp, 16
			// Setup MXCSR with IM=0 (unmasked invalid operation)
			0x0F, 0xAE, 0x5C, 0x24, 0x08,                   // stmxcsr [rsp+8] (Save default)
			0x8B, 0x44, 0x24, 0x08,                         // mov eax, [rsp+8]
			0x83, 0xE0, 0x7F,                               // and al, 0x7F <- Clears bit 7 (IM)
			0x89, 0x44, 0x24, 0x04,                         // mov [rsp+4], eax (Store modified)
			0x0F, 0xAE, 0x54, 0x24, 0x04,                   // ldmxcsr [rsp+4] (Load modified)
			// Prepare -1.0f
			0xB8, 0x00, 0x00, 0x80, 0xBF,                   // mov eax, 0xBF800000 (-1.0f)
			0x89, 0x04, 0x24,                               // mov [rsp], eax
			0xF3, 0x0F, 0x10, 0x04, 0x24,                   // movss xmm0, [rsp]
			// Trigger exception
			0xF3, 0x0F, 0x51, 0xC0,                         // sqrtss xmm0, xmm0 <- Exception expected (post-check)
			// Cleanup (likely skipped)
			0x0F, 0xAE, 0x5C, 0x24, 0x08,                   // ldmxcsr [rsp+8] (restore)
			0x48, 0x83, 0xC4, 0x10,                         // add rsp, 16
		};
		add_nop_int3 ( test.bytes );
		g_exception_tests.push_back ( test );
	}

	// --- No Exception Expected (Simple Arithmetic) ---
	{
		ExceptionTestShellcode test;
		test.name = "No Exception Expected";
		test.expected_exception_code = 0; // 0 means no exception expected before INT3 marker
		test.notes = "Simple arithmetic, should finish at the INT3 marker.";
		test.bytes = {
			0x48, 0xC7, 0xC0, 0x0A, 0x00, 0x00, 0x00, // mov rax, 10
			0x48, 0xC7, 0xC3, 0x05, 0x00, 0x00, 0x00, // mov rbx, 5
			0x48, 0x01, 0xD8,                         // add rax, rbx
			0x48, 0x29, 0xD8,                         // sub rax, rbx
		};
		add_nop_int3 ( test.bytes ); // Expect execution to reach here
		g_exception_tests.push_back ( test );
	}

} // End of initialize_exception_tests
int main ( ) {
	initialize_exception_tests ( );

	std::println ( "Running {} exception tests...", g_exception_tests.size ( ) );
	int passed = 0;
	int failed = 0;

	for ( const auto& test : g_exception_tests ) {
		std::println ( "------------------------------------------" );
		std::println ( "Executing Test: {}", test.name );
		std::println ( "Notes: {}", test.notes );

		TestResult result = run_test_shellcode ( test );

		std::println ( "Result: {}", result.message );
		std::println ( "Stopped at RIP: 0x{:016x}", result.stop_rip );
		if ( result.exception_occurred ) {
			std::println ( "Captured Exception: Code=0x{:X}, Addr=0x{:016x}, VA=0x{:016x}",
				result.captured_exception.ExceptionCode,
				result.captured_exception.ExceptionAddress,
				result.captured_exception.FaultingVa );
		}

		if ( result.success ) {
			std::println ( "Status: PASSED" );
			passed++;
		}
		else {
			std::println ( "Status: FAILED" );
			failed++;
		}
	}

	std::println ( "==========================================" );
	std::println ( "Test Summary: Passed={}, Failed={}", passed, failed );
	std::println ( "==========================================" );

	return ( failed == 0 ) ? 0 : 1;
}
```

`exception_tests/exception_tests.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{df34a047-d142-4d77-bbdc-eb7d4349c4ee}</ProjectGuid>
    <RootNamespace>exceptiontests</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <LibraryPath>$(SolutionDir)\x64\Release;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <RuntimeLibrary>MultiThreadedDebug</RuntimeLibrary>
      <LanguageStandard>stdcpplatest</LanguageStandard>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <AdditionalDependencies>semantics.lib;emulator.lib;shared.lib;$(CoreLibraryDependencies);%(AdditionalDependencies)</AdditionalDependencies>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <RuntimeLibrary>MultiThreaded</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <AdditionalDependencies>semantics.lib;emulator.lib;shared.lib;$(CoreLibraryDependencies);%(AdditionalDependencies)</AdditionalDependencies>
    </Link>
  </ItemDefinitionGroup>
  <ItemGroup>
    <ClCompile Include="exception_tests.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="header.hpp" />
  </ItemGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
```

`exception_tests/exception_tests.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="exception_tests.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="header.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
  </ItemGroup>
</Project>
```

`exception_tests/header.hpp`:

```hpp
#include <shared/context.hpp>        // Defines EmulationContext, GuestExceptionInfo, etc.
#include <shared/capstone++.hpp>     // Defines capstone::Instruction
#include <vector>
#include <string>
#include <stdexcept>
#include <memory>             // For unique_ptr
#include <malloc.h>           // For _aligned_malloc/_aligned_free (Windows specific)
// Or use std::aligned_alloc if available and preferred on your platform
#include <Windows.h>          // For EXCEPTION_CODES, VirtualAlloc/Free

// --- Forward Declarations of necessary functions ---
// (Ensure these are linked or defined in this file/project)

// Exception checking framework
extern InstructionExceptionInfo g_instruction_exception_table[X86_INS_ENDING];

void populate_pre_check_info(PreCheckInfo& check_info, EmulationContext& state, const capstone::Instruction& instr, const InstructionExceptionInfo& baseInfo);
GuestExceptionInfo check_instruction_exceptions(EmulationContext& state, const capstone::Instruction& instr, const PreCheckInfo& check_info);
GuestExceptionInfo check_post_execution_arithmetic(EmulationContext& state, const InstructionExceptionInfo& baseInfo, uint64_t ip, uint8_t op_size);
GuestExceptionInfo check_post_execution_fpu_simd(EmulationContext& state, const InstructionExceptionInfo& baseInfo, uint64_t ip);
// (You might not need the actual dispatch function for testing, just the checkers)
// void setup_guest_exception_dispatch(EmulationContext& state, const GuestExceptionInfo& ex_info);

// Shellcode test structure (assumed defined elsewhere)
struct ExceptionTestShellcode {
    std::string name;
    DWORD expected_exception_code; // 0 if no exception expected before marker INT3
    std::vector<uint8_t> bytes;
    std::string notes;
    bool requires_ac_flag = false; // Flag to indicate if RFLAGS.AC=1 needs setting
};

// Test result structure
struct TestResult {
    bool success = false;
    bool exception_occurred = false; // Did the emulator *detect* a guest exception?
    GuestExceptionInfo captured_exception = {}; // Details if exception occurred
    uint64_t stop_rip = 0;          // RIP where execution stopped
    std::string message = "";       // Status or error message
};

// Helper to get operand size (simplified)
uint8_t get_primary_operand_size(const capstone::Instruction& instr) {
    if (instr.operand_count() > 0) {
        return instr.operands()[0].size;
    }
    // Guess based on common instructions if needed, but size is usually in op[0]
    switch (instr.mnemonic()) {
    case X86_INS_PUSHFQ:
    case X86_INS_POPFQ: return 8;
        // ... other implicit size cases ...
    default: return 8; // Default guess
    }
}
```

`kubera.sln`:

```sln

Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 17
VisualStudioVersion = 17.13.35919.96
MinimumVisualStudioVersion = 10.0.40219.1
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "semantics", "semantics\semantics.vcxproj", "{DA58FDCB-CC3E-4B97-920D-49131472F275}"
	ProjectSection(ProjectDependencies) = postProject
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68} = {F882B8D0-1A48-4BD7-8559-8C63E540BD68}
	EndProjectSection
EndProject
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "emulator", "emulator\emulator.vcxproj", "{377929F2-7380-4359-889E-D7C223D040E4}"
	ProjectSection(ProjectDependencies) = postProject
		{DA58FDCB-CC3E-4B97-920D-49131472F275} = {DA58FDCB-CC3E-4B97-920D-49131472F275}
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68} = {F882B8D0-1A48-4BD7-8559-8C63E540BD68}
	EndProjectSection
EndProject
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "shared", "shared\shared.vcxproj", "{F882B8D0-1A48-4BD7-8559-8C63E540BD68}"
EndProject
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "kubera_tests", "kubera_tests\kubera_tests.vcxproj", "{FC21FB0C-1048-4F3A-B762-59C785EAB761}"
	ProjectSection(ProjectDependencies) = postProject
		{377929F2-7380-4359-889E-D7C223D040E4} = {377929F2-7380-4359-889E-D7C223D040E4}
		{DA58FDCB-CC3E-4B97-920D-49131472F275} = {DA58FDCB-CC3E-4B97-920D-49131472F275}
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68} = {F882B8D0-1A48-4BD7-8559-8C63E540BD68}
	EndProjectSection
EndProject
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "exception_tests", "exception_tests\exception_tests.vcxproj", "{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}"
	ProjectSection(ProjectDependencies) = postProject
		{377929F2-7380-4359-889E-D7C223D040E4} = {377929F2-7380-4359-889E-D7C223D040E4}
		{DA58FDCB-CC3E-4B97-920D-49131472F275} = {DA58FDCB-CC3E-4B97-920D-49131472F275}
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68} = {F882B8D0-1A48-4BD7-8559-8C63E540BD68}
	EndProjectSection
EndProject
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "dll_minimal", "dll_minimal\dll_minimal.vcxproj", "{4C9A92CA-125C-48B0-9E44-830FBB978258}"
	ProjectSection(ProjectDependencies) = postProject
		{377929F2-7380-4359-889E-D7C223D040E4} = {377929F2-7380-4359-889E-D7C223D040E4}
		{DA58FDCB-CC3E-4B97-920D-49131472F275} = {DA58FDCB-CC3E-4B97-920D-49131472F275}
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68} = {F882B8D0-1A48-4BD7-8559-8C63E540BD68}
	EndProjectSection
EndProject
Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "module_loader", "module_loader\module_loader.vcxproj", "{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|x64 = Debug|x64
		Debug|x86 = Debug|x86
		Release|x64 = Release|x64
		Release|x86 = Release|x86
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Debug|x64.ActiveCfg = Debug|x64
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Debug|x64.Build.0 = Debug|x64
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Debug|x86.ActiveCfg = Debug|Win32
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Debug|x86.Build.0 = Debug|Win32
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Release|x64.ActiveCfg = Release|x64
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Release|x64.Build.0 = Release|x64
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Release|x86.ActiveCfg = Release|Win32
		{DA58FDCB-CC3E-4B97-920D-49131472F275}.Release|x86.Build.0 = Release|Win32
		{377929F2-7380-4359-889E-D7C223D040E4}.Debug|x64.ActiveCfg = Debug|x64
		{377929F2-7380-4359-889E-D7C223D040E4}.Debug|x64.Build.0 = Debug|x64
		{377929F2-7380-4359-889E-D7C223D040E4}.Debug|x86.ActiveCfg = Debug|Win32
		{377929F2-7380-4359-889E-D7C223D040E4}.Debug|x86.Build.0 = Debug|Win32
		{377929F2-7380-4359-889E-D7C223D040E4}.Release|x64.ActiveCfg = Release|x64
		{377929F2-7380-4359-889E-D7C223D040E4}.Release|x64.Build.0 = Release|x64
		{377929F2-7380-4359-889E-D7C223D040E4}.Release|x86.ActiveCfg = Release|Win32
		{377929F2-7380-4359-889E-D7C223D040E4}.Release|x86.Build.0 = Release|Win32
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Debug|x64.ActiveCfg = Debug|x64
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Debug|x64.Build.0 = Debug|x64
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Debug|x86.ActiveCfg = Debug|Win32
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Debug|x86.Build.0 = Debug|Win32
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Release|x64.ActiveCfg = Release|x64
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Release|x64.Build.0 = Release|x64
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Release|x86.ActiveCfg = Release|Win32
		{F882B8D0-1A48-4BD7-8559-8C63E540BD68}.Release|x86.Build.0 = Release|Win32
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Debug|x64.ActiveCfg = Debug|x64
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Debug|x64.Build.0 = Debug|x64
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Debug|x86.ActiveCfg = Debug|Win32
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Debug|x86.Build.0 = Debug|Win32
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Release|x64.ActiveCfg = Release|x64
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Release|x64.Build.0 = Release|x64
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Release|x86.ActiveCfg = Release|Win32
		{FC21FB0C-1048-4F3A-B762-59C785EAB761}.Release|x86.Build.0 = Release|Win32
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Debug|x64.ActiveCfg = Debug|x64
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Debug|x64.Build.0 = Debug|x64
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Debug|x86.ActiveCfg = Debug|Win32
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Debug|x86.Build.0 = Debug|Win32
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Release|x64.ActiveCfg = Release|x64
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Release|x64.Build.0 = Release|x64
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Release|x86.ActiveCfg = Release|Win32
		{DF34A047-D142-4D77-BBDC-EB7D4349C4EE}.Release|x86.Build.0 = Release|Win32
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Debug|x64.ActiveCfg = Debug|x64
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Debug|x64.Build.0 = Debug|x64
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Debug|x86.ActiveCfg = Debug|Win32
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Debug|x86.Build.0 = Debug|Win32
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Release|x64.ActiveCfg = Release|x64
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Release|x64.Build.0 = Release|x64
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Release|x86.ActiveCfg = Release|Win32
		{4C9A92CA-125C-48B0-9E44-830FBB978258}.Release|x86.Build.0 = Release|Win32
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Debug|x64.ActiveCfg = Debug|x64
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Debug|x64.Build.0 = Debug|x64
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Debug|x86.ActiveCfg = Debug|Win32
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Debug|x86.Build.0 = Debug|Win32
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Release|x64.ActiveCfg = Release|x64
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Release|x64.Build.0 = Release|x64
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Release|x86.ActiveCfg = Release|Win32
		{5AF09D5D-2A22-4EC9-B7E7-27A33B83D9E7}.Release|x86.Build.0 = Release|Win32
	EndGlobalSection
	GlobalSection(SolutionProperties) = preSolution
		HideSolutionNode = FALSE
	EndGlobalSection
	GlobalSection(ExtensibilityGlobals) = postSolution
		SolutionGuid = {B44430A7-181C-4956-A636-16A4D5BA1B6D}
	EndGlobalSection
EndGlobal

```

`kubera.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>

  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{4c8b4599-82ce-466c-9a61-d9c4b8f42b74}</ProjectGuid>
    <RootNamespace>kubera</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>

  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared" >
  </ImportGroup>
    <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
      <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
    </ImportGroup>
    <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
      <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
    </ImportGroup>
    <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
      <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
    </ImportGroup>
    <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
      <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
    </ImportGroup>

  <PropertyGroup Label="UserMacros" />

  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>

  <ItemGroup></ItemGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>

```

`kubera.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
</Project>
```

`kubera_tests/kubera_tests.cpp`:

```cpp
#include "utils.hpp"
#include <chrono>

std::unique_ptr< capstone::Decoder > capstone_decoder;

uint8_t get_gpr_size_from_id ( x86_reg reg_id ) {
	switch ( reg_id ) {
		// 8-bit
		case X86_REG_AL: case X86_REG_CL: case X86_REG_DL: case X86_REG_BL:
		case X86_REG_AH: case X86_REG_CH: case X86_REG_DH: case X86_REG_BH:
		case X86_REG_SPL: case X86_REG_BPL: case X86_REG_SIL: case X86_REG_DIL:
		case X86_REG_R8B: case X86_REG_R9B: case X86_REG_R10B: case X86_REG_R11B:
		case X86_REG_R12B: case X86_REG_R13B: case X86_REG_R14B: case X86_REG_R15B:
			return 1;
			// 16-bit
		case X86_REG_AX: case X86_REG_CX: case X86_REG_DX: case X86_REG_BX:
		case X86_REG_SP: case X86_REG_BP: case X86_REG_SI: case X86_REG_DI:
		case X86_REG_R8W: case X86_REG_R9W: case X86_REG_R10W: case X86_REG_R11W:
		case X86_REG_R12W: case X86_REG_R13W: case X86_REG_R14W: case X86_REG_R15W:
		case X86_REG_IP:
			return 2;
			// 32-bit
		case X86_REG_EAX: case X86_REG_ECX: case X86_REG_EDX: case X86_REG_EBX:
		case X86_REG_ESP: case X86_REG_EBP: case X86_REG_ESI: case X86_REG_EDI:
		case X86_REG_R8D: case X86_REG_R9D: case X86_REG_R10D: case X86_REG_R11D:
		case X86_REG_R12D: case X86_REG_R13D: case X86_REG_R14D: case X86_REG_R15D:
		case X86_REG_EIP:
			return 4;
			// 64-bit
		case X86_REG_RAX: case X86_REG_RCX: case X86_REG_RDX: case X86_REG_RBX:
		case X86_REG_RSP: case X86_REG_RBP: case X86_REG_RSI: case X86_REG_RDI:
		case X86_REG_R8: case X86_REG_R9: case X86_REG_R10: case X86_REG_R11:
		case X86_REG_R12: case X86_REG_R13: case X86_REG_R14: case X86_REG_R15:
		case X86_REG_RIP:
			return 8;
			// Segment registers (selectors)
		case X86_REG_CS: case X86_REG_DS: case X86_REG_ES:
		case X86_REG_FS: case X86_REG_GS: case X86_REG_SS:
			return 2;

		default:
			std::println ( "Warning: get_gpr_size_from_id called with unexpected reg_id: {}", cs_reg_name ( capstone_decoder->get_handle ( ), reg_id ) );
			return 8;
	}
}


void print_deserialized ( const std::vector<DeserializedTestCase>& cases ) {
	for ( size_t i = 0; i < cases.size ( ); ++i ) {
		const auto& tc = cases [ i ];
		std::print ( "Test Case {}:\n", i + 1 );
		std::print ( "  Instr ID: {:#x}, Mnemonic: {}\n", tc.instr_id, tc.mnemonic );
		std::print ( "  Opcode:" );
		for ( uint8_t byte : tc.opcode ) {
			std::print ( " {:#04x}", byte );
		}
		std::print ( "\n" );
		for ( size_t j = 0; j < tc.inputs.size ( ); ++j ) {
			std::print ( "  Input {}: X86_REG_{} ({}) = {:#x}\n",
								 j + 1, static_cast< int > ( tc.inputs [ j ].first ), cs_reg_name ( capstone_decoder->get_handle ( ), tc.inputs [ j ].first ), tc.inputs [ j ].second );
		}
		for ( size_t j = 0; j < tc.outputs.size ( ); ++j ) {
			std::print ( "  Output {}: X86_REG_{} ({}) = {:#x}\n",
								 j + 1, static_cast< int > ( tc.outputs [ j ].first ), cs_reg_name ( capstone_decoder->get_handle ( ), tc.outputs [ j ].first ), tc.outputs [ j ].second );
		}
		std::print ( "  Flags: {:#x}\n", tc.flags_out );
	}
}

std::string read_file ( const std::string& filename ) {
	std::ifstream file ( filename );
	if ( !file.is_open ( ) ) {
		std::print ( "Error: Could not open file {}\n", filename );
		return "";
	}

	std::stringstream buffer;
	buffer << file.rdbuf ( );
	return buffer.str ( );
}

unsigned char shellcode [ ] = {
		0x48, 0x31, 0xC0,        // xor rax, rax
		0x48, 0xC7, 0xC0, 0x0A, 0x00, 0x00, 0x00, // mov rax, 10
		0x48, 0x31, 0xD2,        // xor rdx, rdx
		0x48, 0x31, 0xDB,        // xor rbx, rbx
		0x48, 0xF7, 0xFB,        // idiv rbx
		0xC3                     // ret
};

#define CT_CHECK(x, y) if constexpr (x) {y;}

void test ( EmulationContext& state, const std::string& _file ) {
	std::println ( "[+] Loading tests from {}", _file );
	auto file = read_file ( _file );
	if ( file.empty ( ) ) {
		std::println ( "[!] Failed to load tests" );
		return;
	}
	auto instructions = parse_input ( file );
	auto deserialized = deserialize_test_cases ( instructions );
	std::println ( "[+] Loaded {} instructions with a total of {} tests", instructions.size ( ), deserialized.size ( ) );
	std::println ( "[+] Running tests" );


	auto start_time_clock = std::chrono::high_resolution_clock::now ( );
	[[maybe_unused]] auto control = 0; // Marked unused as it's not used in the loop now
	auto control_ins = 0;

	InstructionEffect effect {};
	constexpr bool print_fails = true;
	size_t cases = 0;
	size_t fails = 0;
	size_t passed = 0;

	capstone_decoder = std::make_unique<capstone::Decoder> ( deserialized [ 0 ].opcode.data ( ), deserialized [ 0 ].opcode.size ( ), 0ull );
	std::unordered_map<x86_insn, Handler*> handler_cache;


	const size_t BATCH_SIZE = 64;
	for ( size_t i = 0; i < deserialized.size ( ); i += BATCH_SIZE ) {
		size_t end = std::min ( i + BATCH_SIZE, deserialized.size ( ) );

		for ( size_t j = i; j < end; ++j ) {
			const auto& test_case = deserialized [ j ];

			capstone_decoder->reconfigure ( const_cast< uint8_t* > ( test_case.opcode.data ( ) ), test_case.opcode.size ( ), 0 );

			state.set_eflags ( test_case.flags_in, effect );
			for ( const auto& input : test_case.inputs ) {
				x86_reg reg_id = input.first;
				uint64_t val64 = input.second;

				if ( reg_id >= X86_REG_XMM0 && reg_id <= X86_REG_XMM15 ) {
					state.set_xmm_raw ( reg_id, uint128_t ( val64 ), effect );
				}
				else if ( reg_id >= X86_REG_YMM0 && reg_id <= X86_REG_YMM15 ) {
					state.set_ymm_raw ( reg_id, uint256_t ( val64 ), effect );
				}
				else if ( reg_id >= X86_REG_ZMM0 && reg_id <= X86_REG_ZMM15 ) {
					state.set_zmm_raw ( reg_id, uint512_t ( val64 ), effect );
				}
				else {
					uint8_t reg_size = get_gpr_size_from_id ( reg_id );
					state.set_reg ( reg_id, val64, reg_size, effect );
				}
			}
			auto last_flags = state.get_eflags ( );

			auto instr = capstone_decoder->decode ( );
			x86_insn mnemonic = static_cast< x86_insn >( instr.mnemonic ( ) );

			Handler* current_handler = nullptr; // Renamed from handler to avoid conflict
			if ( handler_cache.contains ( mnemonic ) ) [[likely]] {
				current_handler = handler_cache [ mnemonic ];
			}
			else {
				auto it = instruction_handlers.find ( mnemonic );
				if ( it != instruction_handlers.end ( ) ) {
					current_handler = it->second;
					handler_cache [ mnemonic ] = current_handler;
				}
			}

			if ( current_handler ) {
				( *current_handler )( instr, state, effect );
			}
			else {
				std::println ( "Unhandled mnemonic: {}", instr.to_string ( ) );
				__debugbreak ( );
			}

			bool success = true;
			for ( const auto& output : test_case.outputs ) {
				x86_reg reg_id_out = output.first;
				uint64_t expected_val64 = output.second;
				uint64_t actual_val64 = 0;
				bool reg_checked = false;

				if ( reg_id_out >= X86_REG_XMM0 && reg_id_out <= X86_REG_XMM15 ) {
					actual_val64 = static_cast< uint64_t >( state.get_xmm_raw ( reg_id_out ) );
					reg_checked = true;
				}
				else if ( reg_id_out >= X86_REG_YMM0 && reg_id_out <= X86_REG_YMM15 ) {
					actual_val64 = static_cast< uint64_t >( state.get_ymm_raw ( reg_id_out ) );
					reg_checked = true;
				}
				else if ( reg_id_out >= X86_REG_ZMM0 && reg_id_out <= X86_REG_ZMM15 ) {
					actual_val64 = static_cast< uint64_t >( state.get_zmm_raw ( reg_id_out ) );
					reg_checked = true;
				}
				else {
					uint8_t reg_size_out = get_gpr_size_from_id ( reg_id_out );
					actual_val64 = state.get_reg ( reg_id_out, reg_size_out );
					reg_checked = true;
				}

				if ( reg_checked && actual_val64 != expected_val64 ) {
					success = false;
				}
			}
			auto changed_flags = last_flags ^ state.get_eflags ( );
			if ( test_case.flags_out != changed_flags ) {
				 //success = false; // Still keeping strict flag check disabled for now
			}

			if ( !success ) {
				CT_CHECK ( print_fails, std::println ( "[!] Test case: {} failed", instr.to_string_no_address ( ) ) )
					++fails;

				CT_CHECK ( print_fails,
											for ( const auto& input : test_case.inputs ) {
												std::println ( "[?] INPUT: {}: {:#x}", cs_reg_name ( capstone_decoder->get_handle ( ), input.first ), static_cast< uint64_t >( input.second ) );
											}
												)

					CT_CHECK ( print_fails,
												for ( const auto& output_expected : test_case.outputs ) {
													uint64_t actual_value_debug = 0;
													x86_reg reg_id_debug = output_expected.first;
													if ( reg_id_debug >= X86_REG_XMM0 && reg_id_debug <= X86_REG_XMM15 ) actual_value_debug = static_cast< uint64_t >( state.get_xmm_raw ( reg_id_debug ) );
													else if ( reg_id_debug >= X86_REG_YMM0 && reg_id_debug <= X86_REG_YMM15 ) actual_value_debug = static_cast< uint64_t >( state.get_ymm_raw ( reg_id_debug ) );
													else if ( reg_id_debug >= X86_REG_ZMM0 && reg_id_debug <= X86_REG_ZMM15 ) actual_value_debug = static_cast< uint64_t >( state.get_zmm_raw ( reg_id_debug ) );
													else {
														uint8_t reg_size_out_dbg = get_gpr_size_from_id ( reg_id_debug );
														actual_value_debug = state.get_reg ( reg_id_debug, reg_size_out_dbg );
													}
													std::println ( "[?] OUTPUT: {}: expected {:#x} == emu: {:#x}", cs_reg_name ( capstone_decoder->get_handle ( ), output_expected.first ), static_cast< uint64_t >( output_expected.second ), actual_value_debug );
												}
													)
					CT_CHECK ( print_fails, std::println ( "[?] FLAGS_IN: {:#x}, FLAGS_AFTER_EMU: {:#x}, EXPECTED_FLAGS_DIFF: {:#x}, ACTUAL_FLAGS_DIFF: {:#x}", test_case.flags_in, state.get_eflags ( ), test_case.flags_out, changed_flags ) );
			}
			else {
				++passed;
			}

			++cases;
			++control_ins;
		}
	}
	auto end_time = std::chrono::high_resolution_clock::now ( );
	auto duration_ns = std::chrono::duration_cast< std::chrono::nanoseconds >( end_time - start_time_clock ).count ( );
	auto duration_ms = std::chrono::duration_cast< std::chrono::milliseconds >( end_time - start_time_clock ).count ( );
	std::println ( "[+] Success: {}\n[+] Fails: {}", passed, fails );
	std::println ( "[+] Ran {} test cases (instructions executed) in {} ns ({}ms)", control_ins, duration_ns, duration_ms );
	if ( duration_ms > 0 ) {
		std::println ( "[+] Throughput: {} instructions / second", static_cast< double >( control_ins ) / ( static_cast< double >( duration_ms ) / 1000.0 ) );
	}
	else if ( duration_ns > 0 ) {
		std::println ( "[+] Throughput: {} instructions / second", static_cast< double >( control_ins ) / ( static_cast< double >( duration_ns ) / 1000000000.0 ) );
	}
	else {
		std::println ( "[+] Throughput: N/A (duration too short)" );
	}
}

int main ( int argc, char* argv [ ] ) {
	//Sleep ( 10000 );
	if ( argc != 1 ) {
		std::println ( "usage: kubera_tests.exe add.txt" );
	}
	EmulationContext state {};

	std::string arg1 = argv [ 1 ];
	test ( state, "tests\\" + arg1 );

}
```

`kubera_tests/kubera_tests.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{fc21fb0c-1048-4f3a-b762-59c785eab761}</ProjectGuid>
    <RootNamespace>kuberatests</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Release;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <RuntimeLibrary>MultiThreadedDebug</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <AdditionalDependencies>semantics.lib;emulator.lib;shared.lib;$(CoreLibraryDependencies);%(AdditionalDependencies)</AdditionalDependencies>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <RuntimeLibrary>MultiThreaded</RuntimeLibrary>
      <EnableEnhancedInstructionSet>NoExtensions</EnableEnhancedInstructionSet>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
      <AdditionalDependencies>semantics.lib;emulator.lib;shared.lib;$(CoreLibraryDependencies);%(AdditionalDependencies)</AdditionalDependencies>
    </Link>
  </ItemDefinitionGroup>
  <ItemGroup>
    <ClCompile Include="kubera_tests.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="utils.hpp" />
  </ItemGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
```

`kubera_tests/kubera_tests.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="kubera_tests.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="utils.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
  </ItemGroup>
</Project>
```

`kubera_tests/utils.hpp`:

```hpp
#pragma once

#include <semantics/src/pch.hpp>
#include <shared/context.hpp>
#include <shared/capstone++.hpp>
#include <unordered_map>
#include <print>
#include <iostream>
#include <format>
#include <sstream>

x86_reg to_64bit_reg ( x86_reg reg ) {
	switch ( reg ) {
		case X86_REG_EAX: case X86_REG_AX: case X86_REG_AH: case X86_REG_AL:
			return X86_REG_RAX;
		case X86_REG_EBX: case X86_REG_BX: case X86_REG_BH: case X86_REG_BL:
			return X86_REG_RBX;
		case X86_REG_ECX: case X86_REG_CX: case X86_REG_CH: case X86_REG_CL:
			return X86_REG_RCX;
		case X86_REG_EDX: case X86_REG_DX: case X86_REG_DH: case X86_REG_DL:
			return X86_REG_RDX;
		case X86_REG_ESI: case X86_REG_SI: case X86_REG_SIL:
			return X86_REG_RSI;
		case X86_REG_EDI: case X86_REG_DI: case X86_REG_DIL:
			return X86_REG_RDI;
		case X86_REG_EBP: case X86_REG_BP: case X86_REG_BPL:
			return X86_REG_RBP;
		case X86_REG_ESP: case X86_REG_SP: case X86_REG_SPL:
			return X86_REG_RSP;
		case X86_REG_R8D: case X86_REG_R8W: case X86_REG_R8B:
			return X86_REG_R8;
		case X86_REG_R9D: case X86_REG_R9W: case X86_REG_R9B:
			return X86_REG_R9;
		case X86_REG_R10D: case X86_REG_R10W: case X86_REG_R10B:
			return X86_REG_R10;
		case X86_REG_R11D: case X86_REG_R11W: case X86_REG_R11B:
			return X86_REG_R11;
		case X86_REG_R12D: case X86_REG_R12W: case X86_REG_R12B:
			return X86_REG_R12;
		case X86_REG_R13D: case X86_REG_R13W: case X86_REG_R13B:
			return X86_REG_R13;
		case X86_REG_R14D: case X86_REG_R14W: case X86_REG_R14B:
			return X86_REG_R14;
		case X86_REG_R15D: case X86_REG_R15W: case X86_REG_R15B:
			return X86_REG_R15;
		default: return reg; // Already 64-bit or unhandled
	}
}

x86_reg resolve_register ( const std::string& reg_name ) {
	static const std::unordered_map<std::string, x86_reg> reg_map = {
		// RAX and its subregisters
		{"rax", X86_REG_RAX}, {"eax", X86_REG_EAX}, {"ax", X86_REG_AX}, {"ah", X86_REG_AH}, {"al", X86_REG_AL},
		// RBX and its subregisters
		{"rbx", X86_REG_RBX}, {"ebx", X86_REG_EBX}, {"bx", X86_REG_BX}, {"bh", X86_REG_BH}, {"bl", X86_REG_BL},
		// RCX and its subregisters
		{"rcx", X86_REG_RCX}, {"ecx", X86_REG_ECX}, {"cx", X86_REG_CX}, {"ch", X86_REG_CH}, {"cl", X86_REG_CL},
		// RDX and its subregisters
		{"rdx", X86_REG_RDX}, {"edx", X86_REG_EDX}, {"dx", X86_REG_DX}, {"dh", X86_REG_DH}, {"dl", X86_REG_DL},
		// RSI and its subregisters
		{"rsi", X86_REG_RSI}, {"esi", X86_REG_ESI}, {"si", X86_REG_SI}, {"sil", X86_REG_SIL},
		// RDI and its subregisters
		{"rdi", X86_REG_RDI}, {"edi", X86_REG_EDI}, {"di", X86_REG_DI}, {"dil", X86_REG_DIL},
		// RBP and its subregisters
		{"rbp", X86_REG_RBP}, {"ebp", X86_REG_EBP}, {"bp", X86_REG_BP}, {"bpl", X86_REG_BPL},
		// RSP and its subregisters
		{"rsp", X86_REG_RSP}, {"esp", X86_REG_ESP}, {"sp", X86_REG_SP}, {"spl", X86_REG_SPL},
		// R8 and its subregisters
		{"r8", X86_REG_R8}, {"r8d", X86_REG_R8D}, {"r8w", X86_REG_R8W}, {"r8b", X86_REG_R8B},
		// R9 and its subregisters
		{"r9", X86_REG_R9}, {"r9d", X86_REG_R9D}, {"r9w", X86_REG_R9W}, {"r9b", X86_REG_R9B},
		// R10 and its subregisters
		{"r10", X86_REG_R10}, {"r10d", X86_REG_R10D}, {"r10w", X86_REG_R10W}, {"r10b", X86_REG_R10B},
		// R11 and its subregisters
		{"r11", X86_REG_R11}, {"r11d", X86_REG_R11D}, {"r11w", X86_REG_R11W}, {"r11b", X86_REG_R11B},
		// R12 and its subregisters
		{"r12", X86_REG_R12}, {"r12d", X86_REG_R12D}, {"r12w", X86_REG_R12W}, {"r12b", X86_REG_R12B},
		// R13 and its subregisters
		{"r13", X86_REG_R13}, {"r13d", X86_REG_R13D}, {"r13w", X86_REG_R13W}, {"r13b", X86_REG_R13B},
		// R14 and its subregisters
		{"r14", X86_REG_R14}, {"r14d", X86_REG_R14D}, {"r14w", X86_REG_R14W}, {"r14b", X86_REG_R14B},
		// R15 and its subregisters
		{"r15", X86_REG_R15}, {"r15d", X86_REG_R15D}, {"r15w", X86_REG_R15W}, {"r15b", X86_REG_R15B},
		// XMM registers
		{"xmm0", X86_REG_XMM0}, {"xmm1", X86_REG_XMM1}, {"xmm2", X86_REG_XMM2}, {"xmm3", X86_REG_XMM3},
		{"xmm4", X86_REG_XMM4}, {"xmm5", X86_REG_XMM5}, {"xmm6", X86_REG_XMM6}, {"xmm7", X86_REG_XMM7},
		{"xmm8", X86_REG_XMM8}, {"xmm9", X86_REG_XMM9}, {"xmm10", X86_REG_XMM10}, {"xmm11", X86_REG_XMM11},
		{"xmm12", X86_REG_XMM12}, {"xmm13", X86_REG_XMM13}, {"xmm14", X86_REG_XMM14}, {"xmm15", X86_REG_XMM15},
		// YMM registers
		{"ymm0", X86_REG_YMM0}, {"ymm1", X86_REG_YMM1}, {"ymm2", X86_REG_YMM2}, {"ymm3", X86_REG_YMM3},
		{"ymm4", X86_REG_YMM4}, {"ymm5", X86_REG_YMM5}, {"ymm6", X86_REG_YMM6}, {"ymm7", X86_REG_YMM7},
		{"ymm8", X86_REG_YMM8}, {"ymm9", X86_REG_YMM9}, {"ymm10", X86_REG_YMM10}, {"ymm11", X86_REG_YMM11},
		{"ymm12", X86_REG_YMM12}, {"ymm13", X86_REG_YMM13}, {"ymm14", X86_REG_YMM14}, {"ymm15", X86_REG_YMM15},
		// ZMM registers
		{"zmm0", X86_REG_ZMM0}, {"zmm1", X86_REG_ZMM1}, {"zmm2", X86_REG_ZMM2}, {"zmm3", X86_REG_ZMM3},
		{"zmm4", X86_REG_ZMM4}, {"zmm5", X86_REG_ZMM5}, {"zmm6", X86_REG_ZMM6}, {"zmm7", X86_REG_ZMM7},
		{"zmm8", X86_REG_ZMM8}, {"zmm9", X86_REG_ZMM9}, {"zmm10", X86_REG_ZMM10}, {"zmm11", X86_REG_ZMM11},
		{"zmm12", X86_REG_ZMM12}, {"zmm13", X86_REG_ZMM13}, {"zmm14", X86_REG_ZMM14}, {"zmm15", X86_REG_ZMM15}
	};

	if ( reg_name.empty ( ) ) {
		std::print ( "Empty register name\n" );
		return X86_REG_INVALID;
	}

	if ( reg_name == "flags" ) {
		return X86_REG_INVALID;
	}

	auto it = reg_map.find ( reg_name );
	if ( it != reg_map.end ( ) ) {
		return it->second;
	}

	std::print ( "Unrecognized register: {}\n", reg_name );
	return X86_REG_INVALID;
}

uint64_t parse_register_value ( const std::string& value_str ) {
	if ( value_str.empty ( ) || value_str [ 0 ] != '#' ) {
		std::print ( "Invalid register value format: {}\n", value_str.empty ( ) ? "<empty>" : value_str );
		return 0;
	}

	// Remove trailing comma if present
	std::string clean_str = value_str;
	if ( !clean_str.empty ( ) && clean_str.back ( ) == ',' ) {
		clean_str.pop_back ( );
	}

	std::string hex_str = clean_str.substr ( 1 );
	if ( hex_str.length ( ) % 2 != 0 ) {
		//std::print ( "Padding odd-length register value: {} with 0 at front\n", hex_str );
		hex_str = "0" + hex_str;
	}

	std::vector<uint8_t> bytes;
	for ( size_t i = 0; i < hex_str.length ( ); i += 2 ) {
		try {
			std::string byte_str = hex_str.substr ( i, 2 );
			bytes.push_back ( static_cast< uint8_t > ( std::stoul ( byte_str, nullptr, 16 ) ) );
		}
		catch ( const std::exception& e ) {
			( e );
			std::print ( "Error parsing register value byte: {}\n", hex_str.substr ( i, 2 ) );
			return 0;
		}
	}


	uint64_t result = 0;
	for ( size_t i = 0; i < bytes.size ( ) && i < 8; ++i ) { // Limit to 8 bytes for uint64_t
		result |= static_cast< uint64_t > ( bytes [ i ] ) << ( i * 8 );
	}

	return result;
}

// Helper function to parse hex opcode into bytes
std::vector<uint8_t> parse_opcode ( const std::string& opcode_str ) {
	std::vector<uint8_t> opcode;
	if ( opcode_str.empty ( ) || opcode_str [ 0 ] != '#' ) {
		std::print ( "Invalid opcode format: {}\n", opcode_str );
		return opcode;
	}

	std::string hex_str = opcode_str.substr ( 1 ); // Skip '#'
	if ( hex_str.length ( ) % 2 != 0 ) {
		std::print ( "Invalid opcode length: {}\n", hex_str );
		return opcode;
	}

	for ( size_t i = 0; i < hex_str.length ( ); i += 2 ) {
		try {
			std::string byte_str = hex_str.substr ( i, 2 );
			uint8_t byte = static_cast< uint8_t > ( std::stoul ( byte_str, nullptr, 16 ) );
			opcode.push_back ( byte );
		}
		catch ( const std::exception& e ) {
			( e );
			std::print ( "Error parsing opcode byte: {}\n", hex_str.substr ( i, 2 ) );
			return {};
		}
	}
	return opcode;
}

struct DeserializedTestCase {
	uint64_t instr_id;
	std::vector<uint8_t> opcode;
	std::string mnemonic;
	std::vector<std::pair<x86_reg, uint64_t>> inputs; 
	std::vector<std::pair<x86_reg, uint64_t>> outputs;
	uint32_t flags_in;  
	uint32_t flags_out; 
};

struct TestCase {
	struct Register {
		std::string name;
		uint64_t value;
	};
	std::vector<Register> inputs;
	Register output;		
	uint32_t flags_in;  
	uint32_t flags_out; 
};

struct Instruction {
	uint64_t id;
	std::vector<uint8_t> opcode;
	std::string mnemonic;
	uint32_t case_count;
	std::vector<TestCase> cases;
};

std::vector<Instruction> parse_input ( const std::string& input ) {
	std::vector<Instruction> instructions;
	std::istringstream stream ( input );
	std::string line;

	while ( std::getline ( stream, line ) ) {
		if ( line.empty ( ) ) continue;

		// Parse instruction line
		if ( line.starts_with ( "instr:" ) ) {
			Instruction instr;
			std::string id_str, opcode_str, mnemonic, case_count_str;

			// Split instruction line
			size_t pos = line.find ( ':' );
			size_t semicolon1 = line.find ( ';', pos );
			size_t semicolon2 = line.find ( ';', semicolon1 + 1 );
			size_t semicolon3 = line.find ( ';', semicolon2 + 1 );

			id_str = line.substr ( pos + 1, semicolon1 - pos - 1 );
			opcode_str = line.substr ( semicolon1 + 1, semicolon2 - semicolon1 - 1 );
			mnemonic = line.substr ( semicolon2 + 1, semicolon3 - semicolon2 - 1 );
			case_count_str = line.substr ( semicolon3 + 1 );

			// Convert fields
			try {
				instr.id = std::stoull ( id_str, nullptr, 16 );
				instr.opcode = parse_opcode ( opcode_str );
				if ( instr.opcode.empty ( ) ) {
					std::print ( "Skipping instruction due to invalid opcode: {}\n", line );
					continue;
				}
				instr.mnemonic = mnemonic;
				instr.case_count = std::stoul ( case_count_str );
			}
			catch ( const std::exception& e ) {
				( e );
				std::print ( "Error parsing instruction: {}\n", line );
				continue;
			}

			// Parse test cases
			for ( uint32_t i = 0; i < instr.case_count; ++i ) {
				if ( !std::getline ( stream, line ) || line.empty ( ) ) {
					std::print ( "Missing test case for instruction ID {:#x}\n", instr.id );
					break;
				}

				if ( !line.starts_with ( " in:" ) ) {
					std::print ( "Invalid test case format: {}\n", line );
					continue;
				}

				TestCase test_case {};
				size_t pipe_pos = line.find ( '|' );
				if ( pipe_pos == std::string::npos ) {
					std::print ( "Invalid test case, missing '|': {}\n", line );
					continue;
				}

				// Parse inputs
				std::string inputs_str = line.substr ( 4, pipe_pos - 4 );
				std::string outputs_str = line.substr ( pipe_pos + 1 );

				// Parse input registers and flags
				size_t input_pos = 0;
				while ( input_pos < inputs_str.size ( ) ) {
					size_t colon = inputs_str.find ( ':', input_pos );
					size_t comma = inputs_str.find ( ',', colon );
					if ( colon == std::string::npos ) break; // No more inputs
					// Handle case where it's the last input, so no trailing comma
					if ( comma == std::string::npos || comma < colon ) comma = inputs_str.size ( );


					std::string reg_name_str = inputs_str.substr ( input_pos, colon - input_pos );
					std::string reg_value_str = inputs_str.substr ( colon + 1, comma - ( colon + 1 ) );


					try {
						if ( reg_name_str == "flags" ) {
							test_case.flags_in = static_cast< uint32_t > ( parse_register_value ( reg_value_str ) );
						}
						else {
							uint64_t value = parse_register_value ( reg_value_str );
							test_case.inputs.push_back ( { reg_name_str, value } );
						}
					}
					catch ( const std::exception& e ) {
						( e );
						std::print ( "Error parsing input register value: {} for reg {}\n", reg_value_str, reg_name_str );
					}
					if ( comma == inputs_str.size ( ) ) break;
					input_pos = comma + 1;
				}

				// Parse output and flags
				size_t out_prefix_pos = outputs_str.find ( "out:" );
				if ( out_prefix_pos == std::string::npos ) {
					std::print ( "Missing 'out:' in output: {}\n", outputs_str );
					continue;
				}

				std::string out_content_str = outputs_str.substr ( out_prefix_pos + 4 );
				try {
					if ( out_content_str.empty ( ) ) {
						std::print ( "Empty output string after 'out:'\n" );
						continue;
					}
					if ( out_content_str.starts_with ( "flags:" ) ) {
						std::string flags_value_str = out_content_str.substr ( 6 );
						if ( flags_value_str.empty ( ) ) {
							std::print ( "Empty flags value in output\n" );
							continue;
						}
						test_case.output = { "", 0 };
						test_case.flags_out = static_cast< uint32_t >( parse_register_value ( flags_value_str ) );
					}
					else {
						size_t comma_pos = out_content_str.find ( ',' );
						std::string reg_part_str = out_content_str;
						std::string flags_part_str = "";

						if ( comma_pos != std::string::npos ) {
							reg_part_str = out_content_str.substr ( 0, comma_pos );
							flags_part_str = out_content_str.substr ( comma_pos + 1 );
							if ( flags_part_str.starts_with ( "flags:" ) ) {
								flags_part_str = flags_part_str.substr ( 6 );
							}
							else {
								if ( !flags_part_str.empty ( ) ) {
									std::print ( "Warning: Unexpected content after comma in output: {}\n", flags_part_str );
									flags_part_str = "";
								}
							}
						}

						size_t out_colon = reg_part_str.find ( ':' );
						if ( out_colon == std::string::npos || out_colon == 0 || out_colon >= reg_part_str.size ( ) - 1 ) {
							std::print ( "Invalid output register format: {}\n", reg_part_str.empty ( ) ? "<empty>" : reg_part_str );
							continue;
						}

						std::string out_reg_name_str = reg_part_str.substr ( 0, out_colon );
						std::string out_reg_value_str = reg_part_str.substr ( out_colon + 1 );

						if ( out_reg_name_str.empty ( ) ) {
							std::print ( "Empty output register name\n" );
							continue;
						}
						if ( out_reg_value_str.empty ( ) ) {
							std::print ( "Empty output register value\n" );
							continue;
						}
						test_case.output = { out_reg_name_str, parse_register_value ( out_reg_value_str ) };
						test_case.flags_out = flags_part_str.empty ( ) ? 0 : static_cast< uint32_t >( parse_register_value ( flags_part_str ) );
					}
				}
				catch ( const std::exception& e ) {
					( e );
					std::print ( "Error parsing output/flags: {}\n", out_content_str );
					continue;
				}

				instr.cases.push_back ( test_case );
			}

			instructions.push_back ( instr );
		}
	}

	return instructions;
}

// Convert parsed instructions to deserialized test cases
std::vector<DeserializedTestCase> deserialize_test_cases ( const std::vector<Instruction>& instructions ) {
	std::vector<DeserializedTestCase> deserialized;
	deserialized.reserve ( instructions.size ( ) * 26 ); // Rough estimate for capacity

	for ( const auto& instr : instructions ) {
		for ( const auto& tc : instr.cases ) {
			DeserializedTestCase dtc;
			dtc.instr_id = instr.id;
			dtc.opcode = instr.opcode;
			dtc.mnemonic = instr.mnemonic;

			for ( const auto& input : tc.inputs ) {
				x86_reg reg_id = resolve_register ( input.name );
				if ( reg_id != X86_REG_INVALID ) {
					dtc.inputs.emplace_back ( reg_id, input.value );
				}
			}

			if ( !tc.output.name.empty ( ) ) {
				x86_reg out_reg_id = resolve_register ( tc.output.name );
				if ( out_reg_id != X86_REG_INVALID ) {
					dtc.outputs.emplace_back ( out_reg_id, tc.output.value );
				}
			}


			dtc.flags_in = tc.flags_in;
			dtc.flags_out = tc.flags_out;

			deserialized.push_back ( dtc );
		}
	}

	return deserialized;
}
```

`module_loader/module_loader.cpp`:

```cpp
#include <shared/module_loader.hpp>

//KModule::KModule ( std::filesystem::path path ) {
//	parser = PE::Parser ( path.string ( ) );
//
//	mapping = std::make_unique<uint8_t [ ]> ( parser.pe_info_.optional_header.size_of_image );
//	parser.
//}
```

`module_loader/module_loader.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="module_loader.cpp" />
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{5af09d5d-2a22-4ec9-b7e7-27a33b83d9e7}</ProjectGuid>
    <RootNamespace>moduleloader</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Release;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
```

`module_loader/module_loader.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="module_loader.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
  </ItemGroup>
</Project>
```

`semantics/semantics.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="src\avx.cpp" />
    <ClCompile Include="src\pch.cpp">
      <PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">Create</PrecompiledHeader>
      <PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Release|x64'">Create</PrecompiledHeader>
    </ClCompile>
    <ClCompile Include="src\arithmetic.cpp" />
    <ClCompile Include="src\bit.cpp" />
    <ClCompile Include="src\control_flow.cpp" />
    <ClCompile Include="src\cpu.cpp" />
    <ClCompile Include="src\data.cpp" />
    <ClCompile Include="src\flags.cpp" />
    <ClCompile Include="src\fpu.cpp" />
    <ClCompile Include="src\jcc.cpp" />
    <ClCompile Include="src\logical.cpp" />
    <ClCompile Include="src\frame.cpp" />
    <ClCompile Include="src\winapi.cpp" />
    <ClCompile Include="src\syscalls.cpp" />
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="src\pch.hpp" />
  </ItemGroup>
  <ItemGroup>
    <MASM Include="src\syscall.asm" />
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{da58fdcb-cc3e-4b97-920d-49131472f275}</ProjectGuid>
    <RootNamespace>semantics</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
    <Import Project="$(VCTargetsPath)\BuildCustomizations\masm.props" />
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.hpp</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <MultiProcessorCompilation>true</MultiProcessorCompilation>
      <RuntimeLibrary>MultiThreadedDebug</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.hpp</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <MultiProcessorCompilation>true</MultiProcessorCompilation>
      <RuntimeLibrary>MultiThreaded</RuntimeLibrary>
      <EnableEnhancedInstructionSet>NotSet</EnableEnhancedInstructionSet>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
    <Import Project="$(VCTargetsPath)\BuildCustomizations\masm.targets" />
  </ImportGroup>
</Project>
```

`semantics/semantics.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="src\flags.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\arithmetic.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\bit.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\control_flow.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\data.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\fpu.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\logical.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\frame.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\winapi.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\cpu.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\jcc.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\pch.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\avx.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
    <ClCompile Include="src\syscalls.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="src\pch.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
  </ItemGroup>
  <ItemGroup>
    <MASM Include="src\syscall.asm">
      <Filter>Source Files</Filter>
    </MASM>
  </ItemGroup>
</Project>
```

`semantics/src/arithmetic.cpp`:

```cpp
#include "pch.hpp"

namespace mp = boost::multiprecision;
using int128_t = mp::int128_t;
using uint128_t = mp::uint128_t;

void add ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	uint64_t dst_val = helpers::get_operand_value<uint64_t> ( instr, 0, state, effect );
	uint64_t src_val = helpers::get_operand_value<uint64_t> ( instr, 1, state, effect );
	uint64_t result = dst_val + src_val;
	helpers::set_dst_value<uint64_t> ( instr, 0, result, state, effect );
	GET_OPERAND_MASK ( operand_mask, op_size );
	state.update_flags_add ( dst_val & operand_mask, src_val & operand_mask, op_size, effect );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg full_dst_reg = state.to_64bit_reg ( ops [ 0 ].reg );
		if ( full_dst_reg == X86_REG_RSP ) {
			state.stack_allocated -= ( src_val & operand_mask );
		}
	}
}

void sub ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	if ( op_size == 0 ) op_size = 8;

	uint64_t dst_val = helpers::get_operand_value<uint64_t> ( instr, 0, state, effect );
	uint64_t src_val = helpers::get_operand_value<uint64_t> ( instr, 1, state, effect );
	uint64_t result = dst_val - src_val;

	helpers::set_dst_value<uint64_t> ( instr, 0, result, state, effect );

	GET_OPERAND_MASK ( operand_mask, op_size );
	state.update_flags_sub ( dst_val & operand_mask, src_val & operand_mask, op_size, effect );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg full_dst_reg = state.to_64bit_reg ( ops [ 0 ].reg );
		if ( full_dst_reg == X86_REG_RSP ) {
			state.stack_allocated += ( src_val & operand_mask );
		}
	}
}
void inc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		auto cur = state.get_reg ( dst, op_size );
		uint64_t result = cur + 1;
		state.set_reg ( dst, result, op_size, effect );
		state.update_flags_inc ( cur, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( addr == 0 ) {
			return;
		}
		auto cur = state.get_memory ( addr, op_size );
		uint64_t result = cur + 1;
		if ( state.is_within_stack_bounds ( addr, op_size ) ) {
			state.set_stack ( addr, result, effect, op_size );
		}
		else {
			state.set_memory ( addr, result, op_size, effect );
		}
		state.update_flags_inc ( cur, op_size, effect );
		effect.modified_mem.insert ( addr );
	}
}

void dec ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		auto cur = state.get_reg ( dst, op_size );
		uint64_t result = cur - 1;
		state.set_reg ( dst, result, op_size, effect );
		state.update_flags_dec ( cur, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( addr == 0 ) {
			return;
		}
		auto cur = state.get_memory ( addr, op_size );
		uint64_t result = cur - 1;
		if ( state.is_within_stack_bounds ( addr, op_size ) ) {
			state.set_stack ( addr, result, effect, op_size );
		}
		else {
			state.set_memory ( addr, result, op_size, effect );
		}
		state.update_flags_dec ( cur, op_size, effect );
		effect.modified_mem.insert ( addr );
	}
}

void mul ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	auto src_val = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );

	x86_reg low_reg, high_reg;
	uint64_t mask = ( 1ULL << ( op_size * 8 ) ) - 1;
	if ( op_size == 8 ) mask = 0xFFFFFFFFFFFFFFFFULL;

	switch ( op_size ) {
		case 1: low_reg = X86_REG_AL; high_reg = X86_REG_AH; break;
		case 2: low_reg = X86_REG_AX; high_reg = X86_REG_DX; break;
		case 4: low_reg = X86_REG_EAX; high_reg = X86_REG_EDX; break;
		case 8: low_reg = X86_REG_RAX; high_reg = X86_REG_RDX; break;
		default: return;
	}

	uint64_t acc_val = state.get_reg ( low_reg, op_size );

	uint128_t full_res = uint128_t ( acc_val ) * uint128_t ( src_val );

	uint64_t low_res = static_cast< uint64_t >( full_res & mask );
	uint64_t high_res = 0;
	if ( op_size < 8 ) {
		high_res = static_cast< uint64_t > ( ( full_res >> ( op_size * 8 ) ) & mask );
	}
	else {
		high_res = static_cast< uint64_t > ( full_res >> 64 );
	}

	state.set_reg ( low_reg, low_res, op_size, effect );
	state.set_reg ( high_reg, high_res, op_size, effect );

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF, old_OF = state.cpu->cpu_flags.flags.OF;
	state.cpu->cpu_flags.flags.CF = state.cpu->cpu_flags.flags.OF = ( high_res != 0 );
	state.cpu->cpu_flags.flags.SF = 0;
	state.cpu->cpu_flags.flags.ZF = 0;
	state.cpu->cpu_flags.flags.PF = 0;
	state.cpu->cpu_flags.flags.AF = 0;
	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );

}

void imul ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	const auto op_count = instr.operand_count ( );

	if ( op_count == 1 ) {
		uint8_t op_size = ops [ 0 ].size ? ops [ 0 ].size : 8;
		auto src_val_raw = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );

		x86_reg low_reg, high_reg;
		int bits = op_size * 8;

		switch ( op_size ) {
			case 1: low_reg = X86_REG_AL; high_reg = X86_REG_AH; break;
			case 2: low_reg = X86_REG_AX; high_reg = X86_REG_DX; break;
			case 4: low_reg = X86_REG_EAX; high_reg = X86_REG_EDX; break;
			case 8: low_reg = X86_REG_RAX; high_reg = X86_REG_RDX; break;
			default: return;
		}

		int64_t acc_signed = static_cast< int64_t >( state.get_reg ( low_reg, op_size ) );
		int64_t src_signed = static_cast< int64_t >( src_val_raw );
		if ( op_size < 8 ) {
			acc_signed = helpers::sign_extend ( static_cast< uint64_t > ( acc_signed ), op_size );
			src_signed = helpers::sign_extend ( static_cast< uint64_t > ( src_signed ), op_size );
		}

		int128_t full_res = int128_t ( acc_signed ) * int128_t ( src_signed );

		uint64_t low_res = static_cast< uint64_t > ( full_res & 0xFFFFFFFFFFFFFFFF );
		uint64_t high_res = static_cast< uint64_t > ( full_res >> 64 );

		state.set_reg ( low_reg, low_res, op_size, effect );
		state.set_reg ( high_reg, high_res, op_size, effect );

		bool overflow = false;
		int128_t stored_val_sign_extended = helpers::sign_extend ( static_cast< uint128_t >( low_res ), op_size );
		if ( stored_val_sign_extended != full_res ) {
			overflow = true;
		}

		uint64_t old_CF = state.cpu->cpu_flags.flags.CF, old_OF = state.cpu->cpu_flags.flags.OF;
		state.cpu->cpu_flags.flags.CF = state.cpu->cpu_flags.flags.OF = overflow;
		if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );

	}
	else if ( op_count == 2 && ops [ 0 ].type == X86_OP_REG ) {
		uint8_t op_size = ops [ 0 ].size ? ops [ 0 ].size : ( ops [ 1 ].size ? ops [ 1 ].size : 8 );
		x86_reg dst = ops [ 0 ].reg;
		int bits = op_size * 8;

		uint64_t cur_raw = state.get_reg ( dst, op_size );
		uint64_t src_raw = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );

		int64_t cur_signed = static_cast< int64_t >( cur_raw );
		int64_t src_signed = static_cast< int64_t >( src_raw );
		if ( op_size < 8 ) {
			cur_signed = helpers::sign_extend ( static_cast< uint64_t > ( cur_signed ), op_size );
			src_signed = helpers::sign_extend ( static_cast< uint64_t > ( src_signed ), op_size );
		}

		int128_t full_res = int128_t ( cur_signed ) * int128_t ( src_signed );
		uint64_t low_res = static_cast< uint64_t > ( full_res & 0xFFFFFFFFFFFFFFFF );

		bool overflow = false;
		int128_t stored_val_sign_extended = helpers::sign_extend ( static_cast< uint128_t > ( low_res ), op_size );
		if ( stored_val_sign_extended != full_res ) {
			overflow = true;
		}

		state.set_reg ( dst, low_res, op_size, effect );

		uint64_t old_CF = state.cpu->cpu_flags.flags.CF, old_OF = state.cpu->cpu_flags.flags.OF;
		state.cpu->cpu_flags.flags.CF = state.cpu->cpu_flags.flags.OF = overflow;
		if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
	}
	else if ( op_count == 3 && ops [ 0 ].type == X86_OP_REG && ops [ 2 ].type == X86_OP_IMM ) {
		uint8_t op_size = ops [ 0 ].size ? ops [ 0 ].size : ( ops [ 1 ].size ? ops [ 1 ].size : 8 );
		x86_reg dst = ops [ 0 ].reg;
		int bits = op_size * 8;

		uint64_t src1_raw = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
		uint64_t imm_raw = helpers::get_src<uint64_t> ( &instr, 2, state, op_size );

		int64_t src1_signed = static_cast< int64_t >( src1_raw );
		int64_t imm_signed = static_cast< int64_t >( imm_raw );
		if ( op_size < 8 ) {
			src1_signed = helpers::sign_extend ( static_cast< uint64_t > ( src1_signed ), op_size );
			imm_signed = helpers::sign_extend ( static_cast< uint64_t > ( imm_signed ), op_size );
		}

		int128_t full_res = int128_t ( src1_signed ) * int128_t ( imm_signed );
		uint64_t low_res = static_cast< uint64_t > ( full_res & 0xFFFFFFFFFFFFFFFF );

		bool overflow = false;
		int128_t stored_val_sign_extended = helpers::sign_extend ( static_cast< uint128_t > ( low_res ), op_size );
		if ( stored_val_sign_extended != full_res ) {
			overflow = true;
		}

		state.set_reg ( dst, low_res, op_size, effect );

		uint64_t old_CF = state.cpu->cpu_flags.flags.CF, old_OF = state.cpu->cpu_flags.flags.OF;
		state.cpu->cpu_flags.flags.CF = state.cpu->cpu_flags.flags.OF = overflow;
		if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
	}
	else {
		state.exit_due_to_critical_error = true;
	}
}

namespace
{
	bool divide_unsigned_boost ( uint128_t dividend, uint64_t divisor, uint8_t op_size, uint64_t& quotient, uint64_t& remainder ) {
		if ( divisor == 0 ) return true;

		uint128_t q = dividend / divisor;
		uint128_t r = dividend % divisor;

		uint128_t max_quotient_val = 0;
		if ( op_size == 8 ) max_quotient_val = uint128_t ( 0xFFFFFFFFFFFFFFFFULL );
		else max_quotient_val = ( uint128_t ( 1 ) << ( op_size * 8 ) ) - 1;

		if ( q > max_quotient_val ) return true;

		quotient = static_cast< uint64_t >( q );
		remainder = static_cast< uint64_t >( r );
		return false;
	}

	bool divide_signed_boost ( int128_t dividend, int64_t divisor_raw, uint8_t op_size, int64_t& quotient, int64_t& remainder ) {
		int bits = op_size * 8;
		int64_t divisor = helpers::sign_extend ( static_cast< uint64_t >( divisor_raw ), op_size );

		if ( divisor == 0 ) return true;

		int bits_dividend = bits * 2;
		if ( bits_dividend > 128 ) bits_dividend = 128;

		int128_t min_dividend = -( int128_t ( 1 ) << ( bits_dividend - 1 ) );
		if ( dividend == min_dividend && divisor == -1 ) return true;

		int128_t q = dividend / divisor;
		int128_t r = dividend % divisor;

		int128_t min_quotient = -( int128_t ( 1 ) << ( bits - 1 ) );
		int128_t max_quotient = ( int128_t ( 1 ) << ( bits - 1 ) ) - 1;
		if ( q < min_quotient || q > max_quotient ) return true;

		quotient = static_cast< int64_t >( q );
		remainder = static_cast< int64_t >( r );
		return false;
	}
}


void _div ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) < 1 ) {
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t op_size = ops [ 0 ].size;
	if ( op_size != 1 && op_size != 2 && op_size != 4 && op_size != 8 ) {
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}

	uint64_t divisor_val = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );

	uint128_t dividend = 0;
	x86_reg quotient_reg = X86_REG_INVALID;
	x86_reg remainder_reg = X86_REG_INVALID;

	switch ( op_size ) {
		case 1:
			quotient_reg = X86_REG_AL; remainder_reg = X86_REG_AH;
			dividend = state.get_reg ( X86_REG_AX, 2 );
			break;
		case 2:
			quotient_reg = X86_REG_AX; remainder_reg = X86_REG_DX;
			dividend = ( uint128_t ( state.get_reg ( X86_REG_DX, 2 ) ) << 16 ) | state.get_reg ( X86_REG_AX, 2 );
			break;
		case 4:
			quotient_reg = X86_REG_EAX; remainder_reg = X86_REG_EDX;
			dividend = ( uint128_t ( state.get_reg ( X86_REG_EDX, 4 ) ) << 32 ) | state.get_reg ( X86_REG_EAX, 4 );
			break;
		case 8:
			quotient_reg = X86_REG_RAX; remainder_reg = X86_REG_RDX;
			dividend = ( uint128_t ( state.get_reg ( X86_REG_RDX, 8 ) ) << 64 ) | state.get_reg ( X86_REG_RAX, 8 );
			break;
	}

	uint64_t quotient_res = 0, remainder_res = 0;
	bool overflow = divide_unsigned_boost ( dividend, divisor_val, op_size, quotient_res, remainder_res );

	if ( overflow ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_INT_DIVIDE_BY_ZERO, instr.ip ( ) );
		throw ex;
	}

	state.set_reg ( quotient_reg, quotient_res, op_size, effect );
	state.set_reg ( remainder_reg, remainder_res, op_size, effect );
}

void idiv ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) < 1 ) {
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t op_size = ops [ 0 ].size;
	if ( op_size != 1 && op_size != 2 && op_size != 4 && op_size != 8 ) {
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}

	int64_t divisor_val_raw = helpers::get_src<int64_t> ( &instr, 0, state, op_size );

	int128_t dividend = 0;
	x86_reg quotient_reg = X86_REG_INVALID;
	x86_reg remainder_reg = X86_REG_INVALID;

	switch ( op_size ) {
		case 1:
		{
			quotient_reg = X86_REG_AL; remainder_reg = X86_REG_AH;
			int16_t ax_val = static_cast< int16_t >( state.get_reg ( X86_REG_AX, 2 ) );
			dividend = ax_val;
			break;
		}
		case 2:
		{
			quotient_reg = X86_REG_AX; remainder_reg = X86_REG_DX;
			uint16_t dx_val = static_cast< uint16_t >( state.get_reg ( X86_REG_DX, 2 ) );
			uint16_t ax_val = static_cast< uint16_t >( state.get_reg ( X86_REG_AX, 2 ) );
			int32_t dxax_val = ( static_cast< int32_t >( dx_val ) << 16 ) | ax_val;
			dividend = dxax_val;
			break;
		}
		case 4:
		{
			quotient_reg = X86_REG_EAX; remainder_reg = X86_REG_EDX;
			uint32_t edx_val = static_cast< uint32_t >( state.get_reg ( X86_REG_EDX, 4 ) );
			uint32_t eax_val = static_cast< uint32_t >( state.get_reg ( X86_REG_EAX, 4 ) );
			int64_t edxeax_val = ( static_cast< int64_t >( edx_val ) << 32 ) | eax_val;
			dividend = edxeax_val;
			break;
		}
		case 8:
		{
			quotient_reg = X86_REG_RAX; remainder_reg = X86_REG_RDX;
			uint64_t rdx_val = state.get_reg ( X86_REG_RDX, 8 );
			uint64_t rax_val = state.get_reg ( X86_REG_RAX, 8 );
			dividend = ( int128_t ( rdx_val ) << 64 ) | rax_val;
			break;
		}
	}

	int64_t quotient_res = 0, remainder_res = 0;
	bool overflow = divide_signed_boost ( dividend, divisor_val_raw, op_size, quotient_res, remainder_res );

	if ( overflow ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_INT_DIVIDE_BY_ZERO, instr.ip ( ) );
		throw ex;
	}

	state.set_reg ( quotient_reg, static_cast< uint64_t >( quotient_res ), op_size, effect );
	state.set_reg ( remainder_reg, static_cast< uint64_t >( remainder_res ), op_size, effect );
}

void cdq ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto eax = state.get_reg ( X86_REG_EAX, 4 );
	int32_t eax_val = static_cast< int32_t >( eax );
	uint32_t edx_val = ( eax_val < 0 ) ? 0xFFFFFFFF : 0;
	state.set_reg ( X86_REG_EDX, edx_val, 4, effect );
}

void cdqe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto eax = state.get_reg ( X86_REG_EAX, 4 );
	int32_t eax_val = static_cast< int32_t > ( eax );
	int64_t sign_extended = static_cast< int64_t > ( eax_val );
	state.set_reg ( X86_REG_RAX, sign_extended, 8, effect );
}

void adc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	uint64_t src = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	uint64_t carry = state.cpu->cpu_flags.flags.CF;
	GET_OPERAND_MASK ( mask, op_size );
	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		auto cur = state.get_reg ( dst, op_size );

		uint64_t cur_val = cur & mask;
		uint64_t src_val = src & mask;
		uint64_t carry_val = carry;
		uint64_t result = cur_val + src_val + carry_val;
		state.set_reg ( dst, result & mask, op_size, effect );
		state.update_flags_adc ( cur_val, src_val, carry_val, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( addr == 0 ) {
			return;
		}
		auto cur = state.get_memory ( addr, op_size );
		uint64_t cur_val = cur & mask;
		uint64_t src_val = src & mask;
		uint64_t carry_val = carry;
		uint64_t result = cur_val + src_val + carry_val;
		if ( state.is_within_stack_bounds ( addr, op_size ) ) {
			state.set_stack ( addr, result & mask, effect, op_size );
		}
		else {
			state.set_memory ( addr, result & mask, op_size, effect );
		}
		state.update_flags_adc ( cur_val, src_val, carry_val, op_size, effect );
		effect.modified_mem.insert ( addr );
	}
}

void sbb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	uint64_t src = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	uint64_t borrow = state.cpu->cpu_flags.flags.CF;
	GET_OPERAND_MASK ( mask, op_size );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		auto cur = state.get_reg ( dst, op_size );
		uint64_t cur_val = cur & mask;
		uint64_t src_val = src & mask;
		uint64_t borrow_val = borrow;
		uint64_t result = cur_val - src_val - borrow_val;

		// Handle partial register writes (e.g., DH)
		uint8_t shift = state.get_access_shift ( dst, op_size );
		uint64_t access_mask = state.get_access_mask ( dst, op_size );
		x86_reg full_reg = state.to_64bit_reg ( dst );
		uint64_t old_full = state.get_reg ( full_reg, 8 );
		uint64_t new_full = ( old_full & ~access_mask ) | ( ( result << shift ) & access_mask );

		state.set_reg ( full_reg, new_full, 8, effect );
		state.update_flags_sub ( cur_val, src_val + borrow_val, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( addr == 0 ) {
			return;
		}
		auto cur = state.get_memory ( addr, op_size );
		uint64_t cur_val = cur & mask;
		uint64_t src_val = src & mask;
		uint64_t borrow_val = borrow;
		uint64_t result = cur_val - src_val - borrow_val;

		if ( state.is_within_stack_bounds ( addr, op_size ) ) {
			state.set_stack ( addr, result, effect, op_size );
		}
		else {
			state.set_memory ( addr, result, op_size, effect );
		}
		state.update_flags_sub ( cur_val, src_val + borrow_val, op_size, effect );
		effect.modified_mem.insert ( addr );
	}
}
void neg ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	GET_OPERAND_MASK ( mask, op_size );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		auto cur = state.get_reg ( dst, op_size );

		int64_t val = cur & mask;
		int64_t result = -val;
		state.set_reg ( dst, result, op_size, effect );
		//state.update_flags_neg ( val, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( addr == 0 ) {
			return;
		}
		auto cur = state.get_memory ( addr, op_size );
		int64_t val = cur & mask;
		int64_t result = -val;
		if ( state.is_within_stack_bounds ( addr, op_size ) ) {
			state.set_stack ( addr, result, effect, op_size );
		}
		else {
			state.set_memory ( addr, result, op_size, effect );
		}
		//state.update_flags_neg ( val, op_size, effect );
		effect.modified_mem.insert ( addr );
	}
}

void xadd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	GET_OPERAND_MASK ( mask, op_size );

	if ( ops [ 0 ].type == X86_OP_REG && ops [ 1 ].type == X86_OP_REG ) {
		x86_reg dst_reg = ops [ 0 ].reg;
		x86_reg src_reg = ops [ 1 ].reg;
		auto dst_val = state.get_reg ( dst_reg, op_size );
		auto src_val = state.get_reg ( src_reg, op_size );

		uint64_t orig_dst = dst_val & mask;
		uint64_t orig_src = src_val & mask;
		uint64_t sum = orig_dst + orig_src;

		state.set_reg ( src_reg, orig_dst, op_size, effect );
		state.set_reg ( dst_reg, sum, op_size, effect );
		state.update_flags_add ( orig_dst, orig_src, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM && ops [ 1 ].type == X86_OP_REG ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( addr == 0 ) {
			return;
		}
		x86_reg src_reg = ops [ 1 ].reg;
		auto mem_val = state.get_memory ( addr, op_size );
		auto reg_val = state.get_reg ( src_reg, op_size );

		uint64_t orig_mem = mem_val & mask;
		uint64_t orig_reg = reg_val & mask;
		uint64_t sum = orig_mem + orig_reg;

		state.set_reg ( src_reg, orig_mem, op_size, effect );
		if ( state.is_within_stack_bounds ( addr, op_size ) ) {
			state.set_stack ( addr, sum, effect, op_size );
		}
		else {
			state.set_memory ( addr, sum, op_size, effect );
		}
		state.update_flags_add ( orig_mem, orig_reg, op_size, effect );
		effect.modified_mem.insert ( addr );
	}
	else {
		state.exit_due_to_critical_error = true;
	}

}

void io_out ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	const auto op_count = instr.operand_count ( );

	std::println ( "io_out: Executing at IP=0x{:016x}", instr.ip ( ) );

	switch ( op_count ) {
		case 2:
			break;
		default:
			state.exit_due_to_critical_error = true;
			std::println ( "io_out: Invalid operand count {}", static_cast< int >( op_count ) );
			return;
	}

	uint8_t op_size = 0;
	uint64_t data_val = 0;
	x86_reg data_reg = X86_REG_INVALID;

	switch ( ops [ 1 ].type ) {
		case X86_OP_REG:
			data_reg = ops [ 1 ].reg;
			op_size = ops [ 1 ].size;
			switch ( data_reg ) {
				case X86_REG_AL:
					switch ( op_size ) {
						case 1:
							data_val = state.get_reg ( X86_REG_AL, 1 );
							std::println ( "io_out: AL=0x{:x}", data_val );
							break;
						default:
							state.exit_due_to_critical_error = true;
							std::println ( "io_out: Invalid size {} for AL", static_cast< int >( op_size ) );
							return;
					}
					break;
				case X86_REG_AX:
					switch ( op_size ) {
						case 2:
							data_val = state.get_reg ( X86_REG_AX, 2 );
							std::println ( "io_out: AX=0x{:x}", data_val );
							break;
						default:
							state.exit_due_to_critical_error = true;
							std::println ( "io_out: Invalid size {} for AX", static_cast< int >( op_size ) );
							return;
					}
					break;
				case X86_REG_EAX:
					switch ( op_size ) {
						case 4:
							data_val = state.get_reg ( X86_REG_EAX, 4 );
							std::println ( "io_out: EAX=0x{:x}", data_val );
							break;
						default:
							state.exit_due_to_critical_error = true;
							std::println ( "io_out: Invalid size {} for EAX", static_cast< int >( op_size ) );
							return;
					}
					break;
				default:
					state.exit_due_to_critical_error = true;
					std::println ( "io_out: Invalid data register {}", static_cast< int >( data_reg ) );
					return;
			}
			break;
		default:
			state.exit_due_to_critical_error = true;
			std::println ( "io_out: Invalid data operand type {}", static_cast< int >( ops [ 1 ].type ) );
			return;
	}

	uint16_t port_addr = 0;
	switch ( ops [ 0 ].type ) {
		case X86_OP_IMM:
			switch ( ops [ 0 ].size ) {
				case 1:
				case 2:
					port_addr = static_cast< uint16_t >( ops [ 0 ].imm );
					break;
				default:
					state.exit_due_to_critical_error = true;
					std::println ( "io_out: Invalid port address size {}", static_cast< int >( ops [ 0 ].size ) );
					return;
			}
			break;
		case X86_OP_REG:
			switch ( ops [ 0 ].reg ) {
				case X86_REG_DX:
					switch ( ops [ 0 ].size ) {
						case 2:
							port_addr = static_cast< uint16_t >( state.get_reg ( X86_REG_DX, 2 ) );
							break;
						default:
							state.exit_due_to_critical_error = true;
							std::println ( "io_out: Invalid size {} for DX", static_cast< int >( ops [ 0 ].size ) );
							return;
					}
					break;
				default:
					state.exit_due_to_critical_error = true;
					std::println ( "io_out: Invalid port register {}", static_cast< int >( ops [ 0 ].reg ) );
					return;
			}
			break;
		default:
			state.exit_due_to_critical_error = true;
			std::println ( "io_out: Invalid port operand type {}", static_cast< int >( ops [ 0 ].type ) );
			return;
	}

	uint64_t mask = 0;
	switch ( op_size ) {
		case 1:
			mask = 0xFF;
			break;
		case 2:
			mask = 0xFFFF;
			break;
		case 4:
			mask = 0xFFFFFFFF;
			break;
		default:
			state.exit_due_to_critical_error = true;
			std::println ( "io_out: Invalid operand size {}", static_cast< int >( op_size ) );
			return;
	}
	data_val &= mask;

	state.windows->io_ports [ port_addr ] = data_val;
	std::println ( "OUT: Port 0x{:04x} <- 0x{:x}", port_addr, data_val );
	std::println ( "RAX after OUT (unchanged): 0x{:x}", state.get_reg ( X86_REG_RAX, 8 ) );
}






void io_in ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	const auto op_count = instr.operand_count ( );

	if ( op_count != 2 ) {
		state.exit_due_to_critical_error = true;
		return;
	}

	if ( ops [ 0 ].type != X86_OP_REG ) {
		state.exit_due_to_critical_error = true;
		return;
	}

	x86_reg dest_reg = ops [ 0 ].reg;
	uint8_t op_size = ops [ 0 ].size;

	switch ( dest_reg ) {
		case X86_REG_AL:
			if ( op_size != 1 ) {
				state.exit_due_to_critical_error = true;
				return;
			}
			break;
		case X86_REG_AX:
			if ( op_size != 2 ) {
				state.exit_due_to_critical_error = true;
				return;
			}
			break;
		case X86_REG_EAX:
			if ( op_size != 4 ) {
				state.exit_due_to_critical_error = true;
				return;
			}
			break;
		default:
			state.exit_due_to_critical_error = true;
			return;
	}

	uint16_t port_addr = 0;
	if ( ops [ 1 ].type == X86_OP_IMM ) {
		if ( ops [ 1 ].size > 2 ) {
			state.exit_due_to_critical_error = true;
			return;
		}
		port_addr = static_cast< uint16_t >( ops [ 1 ].imm );
	}
	else if ( ops [ 1 ].type == X86_OP_REG && ops [ 1 ].reg == X86_REG_DX ) {
		port_addr = static_cast< uint16_t >( state.get_reg ( X86_REG_DX, 2 ) );
	}
	else {
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t data_val = state.windows->io_ports.count ( port_addr ) ? state.windows->io_ports [ port_addr ] : 0;

	uint64_t mask = 0;
	switch ( op_size ) {
		case 1:
			mask = 0xFF;
			data_val &= mask;
			state.set_reg ( X86_REG_AL, data_val, 1, effect );
			break;
		case 2:
			mask = 0xFFFF;
			data_val &= mask;
			state.set_reg ( X86_REG_AX, data_val, 2, effect );
			break;
		case 4:
			mask = 0xFFFFFFFF;
			data_val &= mask;
			state.set_reg ( X86_REG_EAX, data_val, 4, effect );
			break;
		default:
			state.exit_due_to_critical_error = true;
			return;
	}

	std::println ( "IN: 0x{:X} -> Port 0x{:04X}", data_val, port_addr );
}

void outx ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint8_t op_size = 0;
	const char* size_suffix = "";

	switch ( instr.mnemonic ( ) ) {
		case X86_INS_OUTSB:
			op_size = 1;
			size_suffix = "BYTE";
			break;
		case X86_INS_OUTSW:
			op_size = 2;
			size_suffix = "WORD";
			break;
		case X86_INS_OUTSD:
			op_size = 4;
			size_suffix = "DWORD";
			break;
		default:
			effect.push_to_changes ( state, std::format ( "OUTS: Unexpected instruction ID {} for outs_generic handler", instr.mnemonic ( ) ) );
			state.exit_due_to_critical_error = true;
			return;
	}

	bool is_rep = instr.is_rep ( );
	uint16_t port_addr = static_cast< uint16_t >( state.get_reg ( X86_REG_DX, 2 ) ); // Port is in DX
	uint64_t rsi_val = state.get_reg ( X86_REG_RSI, 8 ); // Source address is in RSI (64-bit mode)
	bool df = state.cpu->cpu_flags.flags.DF != 0; // Direction Flag
	int64_t step = df ? -static_cast< int64_t >( op_size ) : static_cast< int64_t >( op_size );

	uint64_t count = 1;
	uint64_t initial_rcx = 0; // For logging REP case

	if ( is_rep ) {
		initial_rcx = state.get_reg ( X86_REG_RCX, 8 );
		count = initial_rcx;

		if ( count == 0 ) { // If RCX is 0, REP has no effect
			if ( state.options.enable_logging ) {
				effect.push_to_changes ( state, std::format ( "REP OUTS{}: RCX is 0, no I/O operation. Port=0x{:04x}",
																 size_suffix, port_addr ) );
			}
			return;
		}
		if ( state.options.enable_logging ) {
			effect.push_to_changes ( state, std::format ( "REP OUTS{}: Count = {} ({:x}h), Port=0x{:04x}, Initial RSI=0x{:016x}",
															 size_suffix, count, count, port_addr, rsi_val ) );
		}
	}
	else {
		if ( state.options.enable_logging ) {
			effect.push_to_changes ( state, std::format ( "OUTS{}: Port=0x{:04x}, RSI=0x{:016x}",
															 size_suffix, port_addr, rsi_val ) );
		}
	}

	uint64_t current_rsi = rsi_val;
	GET_OPERAND_MASK ( operand_mask, op_size );

	for ( uint64_t i = 0; i < count; ++i ) {
		if ( state.exit_due_to_critical_error ) {
			effect.push_to_changes ( state, "OUTS: Exiting due to critical error during REP loop." );
			break;
		}

		uint64_t data_to_send = 0;
		try {
			data_to_send = state.get_memory ( current_rsi, op_size );
		}
		catch ( const GuestExceptionInfo& /* e */ ) {
			state.set_reg ( X86_REG_RSI, current_rsi, 8, effect );
			if ( is_rep ) {
				state.set_reg ( X86_REG_RCX, count - i, 8, effect );
				if ( state.options.enable_logging ) {
					effect.push_to_changes ( state, std::format ( "  REP OUTS{}: Fault at [0x{:016x}]. Updated RSI=0x{:016x}, RCX={}",
																	 size_suffix, current_rsi, current_rsi, count - i ) );
				}
			}
			else {
				if ( state.options.enable_logging ) {
					effect.push_to_changes ( state, std::format ( "  OUTS{}: Fault at [0x{:016x}]. Updated RSI=0x{:016x}",
																	 size_suffix, current_rsi, current_rsi ) );
				}
			}
			throw;
		}

		state.windows->io_ports [ port_addr ] = data_to_send & operand_mask;

		if ( state.options.enable_logging ) {
			effect.push_to_changes ( state, std::format ( "  I/O Write: Port 0x{:04x} <- 0x{:x} (from [0x{:016x}], {} bytes)",
															 port_addr, data_to_send & operand_mask, current_rsi, op_size ) );
		}

		current_rsi += step; // Update RSI for the next iteration or for after a single operation
	}

	state.set_reg ( X86_REG_RSI, current_rsi, 8, effect );

	if ( is_rep && initial_rcx > 0 ) { // Check initial_rcx to ensure RCX is only zeroed if REP actually ran
		state.set_reg ( X86_REG_RCX, 0, 8, effect );
	}

	if ( state.options.enable_logging ) {
		if ( is_rep && initial_rcx > 0 ) {
			effect.push_to_changes ( state, std::format ( "  Final REP OUTS{} state: RSI=0x{:016x}, RCX=0",
															 size_suffix, current_rsi ) );
		}
		else if ( !is_rep ) {
			effect.push_to_changes ( state, std::format ( "  Final OUTS{} state: RSI=0x{:016x}",
															 size_suffix, current_rsi ) );
		}
	}
}

void helpers::bind_arithmetic ( ) {
	BIND ( add );
	BIND ( sub );
	BIND ( inc );
	BIND ( dec );
	BIND ( mul );
	BIND ( imul );
	BIND2 ( div, _div );
	BIND ( idiv );
	BIND ( cdq );
	BIND ( cdqe );
	BIND ( adc );
	BIND ( sbb );
	BIND ( neg );
	BIND ( xadd );

	BIND ( io_in );
	BIND ( io_out );
	BIND ( outx );
}
```

`semantics/src/avx.cpp`:

```cpp
#include "pch.hpp"
#include <cmath>
#include <cfenv>
#include <boost/multiprecision/cpp_bin_float.hpp>
#include <boost/math/special_functions/modf.hpp>

void vpxor ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint8_t op_size_bytes = ops [ 0 ].size; // Size of the destination register in bytes (16 for XMM, 32 for YMM, 64 for ZMM)

	// Get src1 value (always a register for 3-operand form)
	uint512_t src1_val_full;
	switch ( op_size_bytes ) {
		case 16: // XMM
			src1_val_full = state.get_xmm_raw ( ops [ 1 ].reg );
			break;
		case 32: // YMM
			src1_val_full = state.get_ymm_raw ( ops [ 1 ].reg );
			break;
		case 64: // ZMM (AVX-512)
			src1_val_full = state.get_zmm_raw ( ops [ 1 ].reg );
			break;
		default:
			effect.push_to_changes ( state, std::format ( "VPXOR: Unsupported operand size {} bytes for src1.", op_size_bytes ) );
			state.exit_due_to_critical_error = true;
			return;
	}

	// Get src2 value (register or memory)
	uint512_t src2_val_full;
	if ( ops [ 2 ].type == X86_OP_REG ) {
		switch ( op_size_bytes ) {
			case 16:
				src2_val_full = state.get_xmm_raw ( ops [ 2 ].reg );
				break;
			case 32:
				src2_val_full = state.get_ymm_raw ( ops [ 2 ].reg );
				break;
			case 64:
				src2_val_full = state.get_zmm_raw ( ops [ 2 ].reg );
				break;
			default:
				effect.push_to_changes ( state, std::format ( "VPXOR: Unsupported operand size {} bytes for src2 register.", op_size_bytes ) );
				state.exit_due_to_critical_error = true; return;
		}
	}
	else if ( ops [ 2 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 2 ], instr, state );
		if ( state.exit_due_to_critical_error ) return;

		switch ( op_size_bytes ) {
			case 16: // XMM - 128 bit
				src2_val_full = state.get_memory_128 ( addr );
				break;
			case 32:
			{
				src2_val_full = state.get_memory_256 ( addr );
			}
			break;
			case 64:
			{
				src2_val_full = state.get_memory_512 ( addr );
			}
			break;
			default:
				effect.push_to_changes ( state, std::format ( "VPXOR: Unsupported operand size {} bytes for src2 memory.", op_size_bytes ) );
				state.exit_due_to_critical_error = true; return;
		}
	}
	else {
		effect.push_to_changes ( state, "VPXOR: Invalid type for src2 operand." );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint512_t result_full = src1_val_full ^ src2_val_full;

	// Store the result based on destination register size
	if ( op_size_bytes == 16 ) state.set_xmm_raw ( dst_reg, result_full.convert_to<uint128_t> ( ), effect );
	else if ( op_size_bytes == 32 ) state.set_ymm_raw ( dst_reg, result_full.convert_to<uint256_t> ( ), effect );
	else if ( op_size_bytes == 64 ) state.set_zmm_raw ( dst_reg, result_full, effect );
	// No else needed due to prior checks

	effect.push_to_changes ( state, std::format ( "vpxor {}, {}, {}", cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 0 ].reg ), cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 1 ].reg ), ops [ 2 ].type == X86_OP_REG ? cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 2 ].reg ) : "[mem]" ) );
	effect.modified_regs.insert ( dst_reg );
}

void vpcmpeqw ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint8_t op_size_bytes = ops [ 0 ].size; // 16 for XMM, 32 for YMM, 64 for ZMM
	int num_elements = op_size_bytes / sizeof ( uint16_t ); // Number of 16-bit words

	uint512_t src1_full, src2_full, result_full = 0;

	// Get src1
	if ( ops [ 1 ].type == X86_OP_REG ) {
		if ( op_size_bytes == 16 ) src1_full = state.get_xmm_raw ( ops [ 1 ].reg );
		else if ( op_size_bytes == 32 ) src1_full = state.get_ymm_raw ( ops [ 1 ].reg );
		else if ( op_size_bytes == 64 ) src1_full = state.get_zmm_raw ( ops [ 1 ].reg );
	}

	// Get src2
	if ( ops [ 2 ].type == X86_OP_REG ) {
		if ( op_size_bytes == 16 ) src2_full = state.get_xmm_raw ( ops [ 2 ].reg );
		else if ( op_size_bytes == 32 ) src2_full = state.get_ymm_raw ( ops [ 2 ].reg );
		else if ( op_size_bytes == 64 ) src2_full = state.get_zmm_raw ( ops [ 2 ].reg );
	}
	else if ( ops [ 2 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 2 ], instr, state );
		if ( state.exit_due_to_critical_error ) return;
		if ( op_size_bytes == 16 ) src2_full = state.get_memory_128 ( addr );
		else if ( op_size_bytes == 32 ) src2_full = state.get_memory_256 ( addr );
		else if ( op_size_bytes == 64 ) src2_full = state.get_memory_512 ( addr );
	}

	// Perform element-wise comparison
	for ( int i = 0; i < num_elements; ++i ) {
		uint16_t element1 = static_cast< uint16_t > ( ( src1_full >> ( i * 16 ) ) & 0xFFFF );
		uint16_t element2 = static_cast< uint16_t > ( ( src2_full >> ( i * 16 ) ) & 0xFFFF );

		if ( element1 == element2 ) {
			result_full |= ( uint512_t ( 0xFFFF ) << ( i * 16 ) ); // Set all bits to 1 for this element
		}
		// Else, bits for this element remain 0
	}

	// Store the result
	if ( op_size_bytes == 16 ) state.set_xmm_raw ( dst_reg, result_full.convert_to<uint128_t> ( ), effect );
	else if ( op_size_bytes == 32 ) state.set_ymm_raw ( dst_reg, result_full.convert_to<uint256_t> ( ), effect );
	else if ( op_size_bytes == 64 ) state.set_zmm_raw ( dst_reg, result_full, effect );

	effect.push_to_changes ( state, std::format ( "vpcmpeqw {}, {}, {}",
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 0 ].reg ),
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 1 ].reg ),
													 ops [ 2 ].type == X86_OP_REG ? cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 2 ].reg ) : "[mem]"
	) );
	effect.modified_regs.insert ( dst_reg );
}

void vpmovmskb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_gpr_reg = ops [ 0 ].reg;
	uint8_t dst_gpr_size = ops [ 0 ].size; // Should be 4 or 8 for the GPR
	x86_reg src_vec_reg = ops [ 1 ].reg;
	uint8_t src_vec_size_bytes = ops [ 1 ].size; // 16 for XMM, 32 for YMM, 64 for ZMM
	int num_bytes_in_vector = src_vec_size_bytes;

	uint512_t src_vec_full;
	if ( src_vec_size_bytes == 16 ) src_vec_full = state.get_xmm_raw ( src_vec_reg );
	else if ( src_vec_size_bytes == 32 ) src_vec_full = state.get_ymm_raw ( src_vec_reg );
	else src_vec_full = state.get_zmm_raw ( src_vec_reg );

	uint64_t result_mask = 0;
	for ( int i = 0; i < num_bytes_in_vector; ++i ) {
		uint8_t byte_val = static_cast< uint8_t > ( ( src_vec_full >> ( i * 8 ) ) & 0xFF );
		if ( ( byte_val >> 7 ) & 1 ) { // Check MSB of the byte
			result_mask |= ( 1ULL << i );
		}
	}

	state.set_reg ( dst_gpr_reg, result_mask, dst_gpr_size, effect );

	effect.push_to_changes ( state, std::format ( "vpmovmskb {}, {}",
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), dst_gpr_reg ),
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), src_vec_reg )
	) );
	// effect.modified_regs is handled by set_reg
}

void vzeroupper ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	for ( int i = 0; i < 16; ++i ) {
		x86_reg ymm_reg = static_cast< x86_reg > ( X86_REG_YMM0 + i );
		uint256_t current_ymm_val = state.get_ymm_raw ( ymm_reg );
		uint128_t lower_128_bits = current_ymm_val.convert_to<uint128_t> ( );
		state.set_ymm_raw ( ymm_reg, lower_128_bits, effect );
	}

	effect.push_to_changes ( state, "upper ymm zeroed" );
}

void vinsertf128 ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg ymm_dest_reg = ops [ 0 ].reg;
	x86_reg ymm_src1_reg = ops [ 1 ].reg;

	uint128_t xmm_src2_val;
	if ( ops [ 2 ].type == X86_OP_REG && ops [ 2 ].reg >= X86_REG_XMM0 && ops [ 2 ].reg <= X86_REG_XMM15 ) {
		xmm_src2_val = state.get_xmm_raw ( ops [ 2 ].reg );
	}
	else if ( ops [ 2 ].type == X86_OP_MEM && ops [ 2 ].size == 16 ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 2 ], instr, state );
		if ( state.exit_due_to_critical_error ) return;
		xmm_src2_val = state.get_memory_128 ( addr );
	}

	uint8_t imm = static_cast< uint8_t >( ops [ 3 ].imm );
	uint256_t ymm_src1_val = state.get_ymm_raw ( ymm_src1_reg );
	uint256_t result_val;

	if ( ( imm & 0x01 ) == 0 ) { // Insert into lower lane
		result_val = ( ymm_src1_val & ( uint256_t ( "0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF" ) ) | uint256_t ( xmm_src2_val ) );
	}
	else { // Insert into upper lane
		result_val = ( uint256_t ( xmm_src2_val ) << 128 ) | ( ymm_src1_val & uint256_t ( "0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF" ) );
	}

	state.set_ymm_raw ( ymm_dest_reg, result_val, effect );

	effect.push_to_changes ( state, std::format ( "vinsertf128 {}, {}, {}, 0x{:x}",
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), ymm_dest_reg ),
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), ymm_src1_reg ),
													 ops [ 2 ].type == X86_OP_REG ? cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 2 ].reg ) : "[m128]",
													 imm ) );
}

void vmovups ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	const cs_x86_op& dst_op = ops [ 0 ];
	const cs_x86_op& src_op = ops [ 1 ];
	uint8_t op_size_bytes = dst_op.size;
	if ( dst_op.type == X86_OP_MEM ) {
		op_size_bytes = src_op.size;
	}


	uint512_t val_to_move;

	// Read source
	if ( src_op.type == X86_OP_REG ) {
		if ( op_size_bytes == 16 ) val_to_move = state.get_xmm_raw ( src_op.reg );
		else if ( op_size_bytes == 32 ) val_to_move = state.get_ymm_raw ( src_op.reg );
		else val_to_move = state.get_zmm_raw ( src_op.reg );
	}
	else if ( src_op.type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( src_op, instr, state );
		if ( state.exit_due_to_critical_error ) return;
		if ( op_size_bytes == 16 ) val_to_move = state.get_memory_128 ( addr );
		else if ( op_size_bytes == 32 ) val_to_move = state.get_memory_256 ( addr );
		else val_to_move = state.get_memory_512 ( addr );
	}
	else { state.exit_due_to_critical_error = true; return; }

	// Write destination
	if ( dst_op.type == X86_OP_REG ) {
		if ( op_size_bytes == 16 ) state.set_xmm_raw ( dst_op.reg, val_to_move.convert_to<uint128_t> ( ), effect );
		else if ( op_size_bytes == 32 ) state.set_ymm_raw ( dst_op.reg, val_to_move.convert_to<uint256_t> ( ), effect );
		else state.set_zmm_raw ( dst_op.reg, val_to_move, effect );
	}
	else if ( dst_op.type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( dst_op, instr, state );
		if ( state.exit_due_to_critical_error ) return;
		if ( op_size_bytes == 16 ) state.set_memory_128 ( addr, val_to_move.convert_to<uint128_t> ( ), effect );
		else if ( op_size_bytes == 32 ) state.set_memory_256 ( addr, val_to_move.convert_to<uint256_t> ( ), effect );
		else state.set_memory_512 ( addr, val_to_move, effect );
	}
	else { state.exit_due_to_critical_error = true; return; }

	effect.push_to_changes ( state, std::format ( "vmovups {}, {}",
													 dst_op.type == X86_OP_REG ? cs_reg_name ( state.decoder.back ( )->get_handle ( ), dst_op.reg ) : "[mem]",
													 src_op.type == X86_OP_REG ? cs_reg_name ( state.decoder.back ( )->get_handle ( ), src_op.reg ) : "[mem]"
	) );
}

void vmovaps(capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect) {
    const cs_x86_op* ops = instr.operands();
    const cs_x86_op& dst_op = ops[0];
    const cs_x86_op& src_op = ops[1];
    uint8_t op_size_bytes = dst_op.size; 
    if (dst_op.type == X86_OP_MEM) {
        op_size_bytes = src_op.size;
    }
    uint8_t alignment_requirement = op_size_bytes;

    uint512_t val_to_move;

    // Read source
    if (src_op.type == X86_OP_REG) {
        if (op_size_bytes == 16) val_to_move = state.get_xmm_raw(src_op.reg);
        else if (op_size_bytes == 32) val_to_move = state.get_ymm_raw(src_op.reg);
        else val_to_move = state.get_zmm_raw(src_op.reg);
    } else if (src_op.type == X86_OP_MEM) {
        uint64_t addr = helpers::calculate_mem_addr(src_op, instr, state);
        if (state.exit_due_to_critical_error) return;
        if ((addr % alignment_requirement) != 0) {
            GuestExceptionInfo ex;
            ex.set_exception(EXCEPTION_ACCESS_VIOLATION, instr.ip(), addr); // General Protection Fault for misaligned access
            effect.push_to_changes(state, std::format("VMOVAPS: Misaligned memory access at 0x{:x} for source (required {} byte alignment).", addr, alignment_requirement));
            throw ex;
        }
        if (op_size_bytes == 16) val_to_move = state.get_memory_128(addr);
        else if (op_size_bytes == 32) val_to_move = state.get_memory_256(addr);
        else val_to_move = state.get_memory_512(addr);
    }

    // Write destination
    if (dst_op.type == X86_OP_REG) {
        if (op_size_bytes == 16) state.set_xmm_raw(dst_op.reg, val_to_move.convert_to<uint128_t>(), effect);
        else if (op_size_bytes == 32) state.set_ymm_raw(dst_op.reg, val_to_move.convert_to<uint256_t>(), effect);
        else state.set_zmm_raw(dst_op.reg, val_to_move, effect);
    } else if (dst_op.type == X86_OP_MEM) {
        uint64_t addr = helpers::calculate_mem_addr(dst_op, instr, state);
        if (state.exit_due_to_critical_error) return;
        if ((addr % alignment_requirement) != 0) {
            GuestExceptionInfo ex;
            ex.set_exception(EXCEPTION_ACCESS_VIOLATION, instr.ip(), addr); // General Protection Fault
            effect.push_to_changes(state, std::format("VMOVAPS: Misaligned memory access at 0x{:x} for destination (required {} byte alignment).", addr, alignment_requirement));
            throw ex;
        }
        if (op_size_bytes == 16) state.set_memory_128(addr, val_to_move.convert_to<uint128_t>(), effect);
        else if (op_size_bytes == 32) state.set_memory_256(addr, val_to_move.convert_to<uint256_t>(), effect);
        else state.set_memory_512(addr, val_to_move, effect);
    }

    effect.push_to_changes(state, std::format("vmovaps {}, {}",
        dst_op.type == X86_OP_REG ? cs_reg_name(state.decoder.back()->get_handle(), dst_op.reg) : "[mem]",
        src_op.type == X86_OP_REG ? cs_reg_name(state.decoder.back()->get_handle(), src_op.reg) : "[mem]"
    ));
}


void helpers::bind_avx ( ) {
	BIND ( vpxor );
	BIND ( vpcmpeqw );
	BIND ( vpmovmskb );
	BIND ( vzeroupper );
	BIND ( vinsertf128 );
	BIND ( vmovups );
	BIND ( vmovaps );
	BIND2 ( vmovdqu, vmovups );
	BIND2 ( movdqu, vmovups );
}
```

`semantics/src/bit.cpp`:

```cpp
#include "pch.hpp"

void bzhi ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;
	x86_reg dst = ops [ 0 ].reg;
	const auto src = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	const auto index_reg_val = helpers::get_src<uint64_t> ( &instr, 2, state, op_size );

	GET_OPERAND_MASK ( operand_mask, op_size );
	uint64_t src_val = src & operand_mask;
	uint64_t index_val = index_reg_val;

	uint8_t index_pos = index_val & 0xFF;
	uint8_t size_in_bits = op_size * 8;

	uint64_t res = 0;
	uint64_t temp_mask = 0;

	// Calculate the mask ((1 << index_pos) - 1) carefully
	if ( index_pos == 0 ) {
		temp_mask = 0; // Mask is zero if index is 0
	}
	else if ( index_pos >= size_in_bits ) {
		// If index >= size, mask includes all bits of the operand
		temp_mask = operand_mask;
	}
	else {
		// Calculate 1 << index_pos safely (won't overflow uint64_t)
		temp_mask = ( 1ULL << index_pos ) - 1;
	}

	// Apply the mask: DEST = SRC & temp_mask
	res = src_val & temp_mask;

	// Store the result (already masked to operand size)
	state.set_reg ( dst, res, op_size, effect );

	// --- Correct Flag Updates ---
	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_ZF = state.cpu->cpu_flags.flags.ZF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;
	uint64_t old_SF = state.cpu->cpu_flags.flags.SF;
	uint64_t old_AF = state.cpu->cpu_flags.flags.AF;
	uint64_t old_PF = state.cpu->cpu_flags.flags.PF;

	// CF is set if the index value (bits 7:0) >= operand size in bits
	state.cpu->cpu_flags.flags.CF = ( index_pos >= size_in_bits );
	// ZF is set if the result is zero
	state.cpu->cpu_flags.flags.ZF = ( res == 0 );
	// OF, SF, AF, PF are cleared
	state.cpu->cpu_flags.flags.OF = 0;
	state.cpu->cpu_flags.flags.SF = 0;
	state.cpu->cpu_flags.flags.AF = 0;
	state.cpu->cpu_flags.flags.PF = 0;

	// Log flag changes if any occurred
	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_ZF != state.cpu->cpu_flags.flags.ZF ) state.log_flag_change ( effect, "ZF", old_ZF, state.cpu->cpu_flags.flags.ZF );
	// Only log cleared flags if they were previously non-zeo
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
	if ( old_SF != state.cpu->cpu_flags.flags.SF ) state.log_flag_change ( effect, "SF", old_SF, state.cpu->cpu_flags.flags.SF );
	if ( old_AF != state.cpu->cpu_flags.flags.AF ) state.log_flag_change ( effect, "AF", old_AF, state.cpu->cpu_flags.flags.AF );
	if ( old_PF != state.cpu->cpu_flags.flags.PF ) state.log_flag_change ( effect, "PF", old_PF, state.cpu->cpu_flags.flags.PF );
}

void andn ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	x86_reg dst = ops [ 0 ].reg;
	const auto src1 = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	const auto src2 = helpers::get_src<uint64_t> ( &instr, 2, state, op_size );
	const auto res = ~src1 & src2;
	state.set_reg ( dst, res, op_size, effect );
	state.update_flags_and ( ~src1, src2, op_size, effect );
}

void bextr ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;

	x86_reg dst = ops [ 0 ].reg;
	auto src = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	auto control = helpers::get_src<uint64_t> ( &instr, 2, state, op_size );

	uint64_t operand_mask = ( op_size == 8 ) ? 0xFFFFFFFFFFFFFFFFULL : ( 1ULL << ( op_size * 8 ) ) - 1;
	uint64_t src_val = src & operand_mask;
	uint64_t control_val = control;

	uint8_t start = control_val & 0xFF;
	uint8_t len = ( control_val >> 8 ) & 0xFF;
	uint64_t res = 0;

	if ( len == 0 ) {
		res = 0;
	}
	else {
		uint64_t result_mask = 0;
		int bits_in_operand = op_size * 8;
		if ( len >= bits_in_operand ) {
			result_mask = operand_mask;
		}
		else {
			result_mask = ( 1ULL << len ) - 1;
		}
		if ( start < bits_in_operand ) {
			res = ( src_val >> start ) & result_mask;
		}
		else {
			res = 0;
		}
	}

	state.set_reg ( dst, res, op_size, effect );

	uint64_t old_ZF = state.cpu->cpu_flags.flags.ZF;
	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;
	uint64_t old_SF = state.cpu->cpu_flags.flags.SF;
	uint64_t old_AF = state.cpu->cpu_flags.flags.AF;
	uint64_t old_PF = state.cpu->cpu_flags.flags.PF;

	state.cpu->cpu_flags.flags.ZF = ( res == 0 );
	state.cpu->cpu_flags.flags.CF = 0;
	state.cpu->cpu_flags.flags.OF = 0;

	if ( old_ZF != state.cpu->cpu_flags.flags.ZF ) state.log_flag_change ( effect, "ZF", old_ZF, state.cpu->cpu_flags.flags.ZF );
	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
	if ( old_SF != state.cpu->cpu_flags.flags.SF ) state.log_flag_change ( effect, "SF", old_SF, state.cpu->cpu_flags.flags.SF );
	if ( old_AF != state.cpu->cpu_flags.flags.AF ) state.log_flag_change ( effect, "AF", old_AF, state.cpu->cpu_flags.flags.AF );
	if ( old_PF != state.cpu->cpu_flags.flags.PF ) state.log_flag_change ( effect, "PF", old_PF, state.cpu->cpu_flags.flags.PF );
}

void popcnt ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	x86_reg dst = ops [ 0 ].reg;
	auto src = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	uint64_t val = static_cast< uint64_t >( src );
	uint64_t result = __popcnt64 ( val );
	state.set_reg ( dst, result, op_size, effect );
	state.cpu->cpu_flags.flags.ZF = result == 0;
	state.cpu->cpu_flags.flags.CF = 0;
	state.cpu->cpu_flags.flags.OF = 0;
	state.cpu->cpu_flags.flags.SF = 0;
	state.cpu->cpu_flags.flags.PF = 0;
	state.cpu->cpu_flags.flags.AF = 0;
}

void bswap ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	x86_reg dst = ops [ 0 ].reg;
	auto cur = state.get_reg ( dst, op_size );
	uint64_t val = static_cast< uint64_t >( cur );
	if ( op_size == 4 ) val = _byteswap_ulong ( static_cast< uint32_t >( val ) );
	else if ( op_size == 8 ) val = _byteswap_uint64 ( val );
	state.set_reg ( dst, val, op_size, effect );
}

void setb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.CF; } );
}

void setnp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return ~state.cpu->cpu_flags.flags.PF; } );
}

void sets ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF; } );
}

void setnl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF; } );
}

void seto ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.OF; } );
}

void setbe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.CF | state.cpu->cpu_flags.flags.ZF; } );
}

void setz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.ZF; } );
}

void setnb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return ~state.cpu->cpu_flags.flags.CF; } );
}

void setno ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return ~state.cpu->cpu_flags.flags.OF; } );
}


void setp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.PF; } );
}

void setle ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.ZF | ( state.cpu->cpu_flags.flags.SF ^ state.cpu->cpu_flags.flags.OF ); } );
}

void setnle ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.ZF && ( state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF ); } );
}

void setns ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return ~state.cpu->cpu_flags.flags.SF; } );
}

void setl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF != state.cpu->cpu_flags.flags.OF; } );
}

void setnbe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return ~state.cpu->cpu_flags.flags.CF & ~state.cpu->cpu_flags.flags.ZF; } );
}

void setnz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_setcc ( instr, state, effect, [ ] ( const auto& state ) { return ~state.cpu->cpu_flags.flags.ZF; } );
}

void rol ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;
	x86_reg dst = ops [ 0 ].reg;
	auto src_count = helpers::get_src<uint64_t> ( &instr, 1, state, 1 );
	auto cur = state.get_reg ( dst, op_size );

	uint64_t val = cur;
	uint64_t count_val = src_count;
	uint8_t size_in_bits = op_size * 8;
	uint64_t mask = ( op_size == 8 ) ? 0xFFFFFFFFFFFFFFFFULL : ( 1ULL << size_in_bits ) - 1;
	uint64_t current_val = val & mask;

	uint8_t count_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t rot = count_val & count_mask;

	uint64_t final_result = current_val;
	uint64_t final_cf = state.cpu->cpu_flags.flags.CF;

	if ( rot > 0 ) {
		uint64_t temp_val = current_val;
		uint64_t temp_cf = 0;

		for ( uint8_t i = 0; i < rot; ++i ) {
			uint64_t msb = ( temp_val >> ( size_in_bits - 1 ) ) & 1;
			temp_cf = msb;
			temp_val = ( ( temp_val << 1 ) | msb ) & mask;
		}
		final_result = temp_val;
		final_cf = temp_cf;
	}

	state.set_reg ( dst, final_result, op_size, effect );

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;

	uint8_t count_raw = count_val & 0xFF;
	if ( count_raw != 0 ) {
		state.cpu->cpu_flags.flags.CF = final_cf;

		if ( count_raw == 1 ) {
			uint64_t result_msb = ( final_result >> ( size_in_bits - 1 ) ) & 1;
			state.cpu->cpu_flags.flags.OF = result_msb ^ final_cf;
		}

		if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
	}
}

void ror ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;

	x86_reg dst = ops [ 0 ].reg;
	auto src_count = helpers::get_src<uint64_t> ( &instr, 1, state, 1 );
	auto cur = state.get_reg ( dst, op_size );

	uint64_t val = cur;
	uint64_t count_val = src_count;
	uint8_t size_in_bits = op_size * 8;
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t current_val = val & mask;
	uint8_t count_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t rot = count_val & count_mask;

	uint64_t final_result = current_val;
	uint64_t final_cf = state.cpu->cpu_flags.flags.CF;

	if ( rot > 0 ) {
		uint64_t temp_val = current_val;
		uint64_t temp_cf = 0;

		for ( uint8_t i = 0; i < rot; ++i ) {
			uint64_t lsb = temp_val & 1;
			temp_cf = lsb;
			temp_val = ( temp_val >> 1 ) | ( lsb << ( size_in_bits - 1 ) );
		}
		final_result = temp_val;
		final_cf = temp_cf;
	}

	state.set_reg ( dst, final_result, op_size, effect );

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;

	uint8_t count_raw = count_val & 0xFF;
	if ( count_raw != 0 ) {
		state.cpu->cpu_flags.flags.CF = final_cf;
		if ( count_raw == 1 ) {
			uint64_t result_msb = ( final_result >> ( size_in_bits - 1 ) ) & 1;
			uint64_t result_msb_minus_1 = 0;
			if ( size_in_bits > 1 ) {
				result_msb_minus_1 = ( final_result >> ( size_in_bits - 2 ) ) & 1;
			}
			state.cpu->cpu_flags.flags.OF = result_msb ^ result_msb_minus_1;
		}

		if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
	}
}

void rcl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;
	x86_reg dst = ops [ 0 ].reg;
	auto src_count = helpers::get_src<uint64_t> ( &instr, 1, state, 1 );
	auto cur = state.get_reg ( dst, op_size );

	uint64_t val = cur;
	uint64_t count_val = src_count;
	uint8_t size_in_bits = op_size * 8;
	uint64_t mask = ( op_size == 8 ) ? 0xFFFFFFFFFFFFFFFFULL : ( 1ULL << size_in_bits ) - 1;

	// --- Count masking like Rust version (MOD size_in_bits) ---
	uint8_t count_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t rot = count_val & count_mask;
	// ---

	// Promote to 128 bits conceptually (only lower 64 + carry needed)
	uint64_t current_val = val & mask;
	uint64_t current_cf = state.cpu->cpu_flags.flags.CF; // Use boolean/int directly

	// Iterative loop based on Rust logic
	for ( uint8_t i = 0; i < rot; ++i ) {
		uint64_t msb = ( current_val >> ( size_in_bits - 1 ) ) & 1; // Bit rotating out
		// Perform the shift and bring in carry
		current_val = ( ( current_val << 1 ) | current_cf ) & mask;
		// Update carry for next step
		current_cf = msb;
	}

	uint64_t final_result = current_val;
	uint64_t final_cf = current_cf; // CF after last iteration

	// --- Update State ---
	state.set_reg ( dst, final_result, op_size, effect );

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;

	state.cpu->cpu_flags.flags.CF = final_cf; // Set CF based on loop result

	// OF logic from previous C++ version (only count_raw=1 matters)
	uint8_t count_raw = count_val & 0xFF; // Get original raw count for OF check
	if ( count_raw == 1 ) {
		uint64_t result_msb = ( final_result >> ( size_in_bits - 1 ) ) & 1;
		state.cpu->cpu_flags.flags.OF = result_msb ^ final_cf;
	}
	else {
		state.cpu->cpu_flags.flags.OF = 0; // Undefined for count > 1
	}

	// Log changes
	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
}
void rcr ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;

	x86_reg dst = ops [ 0 ].reg;
	auto src_count = helpers::get_src<uint64_t> ( &instr, 1, state, 1 );
	auto cur = state.get_reg ( dst, op_size );

	uint64_t val = cur;
	uint64_t count_val = src_count;
	uint8_t size_in_bits = op_size * 8;
	uint64_t mask = ( op_size == 8 ) ? 0xFFFFFFFFFFFFFFFFULL : ( 1ULL << size_in_bits ) - 1;
	uint64_t original_val = val & mask; 
	uint8_t count_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t rot = count_val & count_mask;

	uint64_t current_val = original_val;
	uint64_t current_cf = state.cpu->cpu_flags.flags.CF;

	for ( uint8_t i = 0; i < rot; ++i ) {
		uint64_t lsb = current_val & 1;
		current_val = ( current_val >> 1 ) | ( current_cf << ( size_in_bits - 1 ) );
		current_cf = lsb;
	}

	uint64_t final_result = current_val & mask;
	state.set_reg ( dst, final_result, op_size, effect );

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;

	uint8_t cnt_mod_size_plus_1 = count_val % ( size_in_bits + 1 );
	uint64_t final_cf;
	if ( cnt_mod_size_plus_1 == 0 ) {
		final_cf = ( original_val >> ( size_in_bits - 1 ) ) & 1;
		final_cf = ( original_val >> ( cnt_mod_size_plus_1 - 1 ) ) & 1;
	}
	else if ( cnt_mod_size_plus_1 == 1 ) {
		final_cf = original_val & 1;
	}
	else {
		final_cf = ( original_val >> ( cnt_mod_size_plus_1 - 1 ) ) & 1;
	}
	state.cpu->cpu_flags.flags.CF = final_cf;

	uint8_t count_raw = count_val & 0xFF;
	if ( count_raw == 1 ) {
		uint64_t result_msb = ( final_result >> ( size_in_bits - 1 ) ) & 1;
		uint64_t result_msb_minus_1 = 0;
		if ( size_in_bits > 1 ) {
			result_msb_minus_1 = ( final_result >> ( size_in_bits - 2 ) ) & 1;
			state.cpu->cpu_flags.flags.OF = result_msb ^ result_msb_minus_1;
		}
		else {
			state.cpu->cpu_flags.flags.OF = result_msb ^ final_cf;
		}
	}
	else {
		state.cpu->cpu_flags.flags.OF = 0;
	}

	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
}

void bt ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	auto src1 = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	auto src2 = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	uint64_t val = static_cast< uint64_t >( src1 );
	uint64_t bit_idx = src2 & ( ( op_size * 8 ) - 1 );
	state.cpu->cpu_flags.flags.CF = ( val >> bit_idx ) & 1;
	effect.push_to_changes ( state,std::format ( "Bit {} of {:#x} tested, CF={}", bit_idx, src1, ( char ) state.cpu->cpu_flags.flags.CF ) );
}

void bts ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	auto src1 = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	auto src2 = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		uint64_t value = static_cast< uint64_t >( src1 );
		uint64_t bit_idx = src2 & ( op_size * 8 - 1 );
		uint64_t original_bit = ( value >> bit_idx ) & 1;
		uint64_t result = value | ( 1ULL << bit_idx );

		uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
		state.cpu->cpu_flags.flags.CF = original_bit;

		state.set_reg ( dst, result, op_size, effect );

		if ( old_CF != state.cpu->cpu_flags.flags.CF ) {
			state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		}

		effect.push_to_changes ( state,std::format ( "BTS: Bit {} set in {:#x}, CF={}", bit_idx, src1, original_bit ) );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		int64_t addr = 0;
		if ( ops [ 0 ].mem.base == X86_REG_RSP ) {
			addr = state.cpu->rsp_offset;
		}
		else if ( ops [ 0 ].mem.base != X86_REG_INVALID ) {
			addr = state.get_reg ( ops [ 0 ].mem.base );
		}
		if ( ops [ 0 ].mem.index != X86_REG_INVALID ) {
			addr += state.get_reg ( ops [ 0 ].mem.index ) * ops [ 0 ].mem.scale;
		}
		addr += ops [ 0 ].mem.disp;

		uint64_t value = static_cast< uint64_t >( src1 );
		uint64_t bit_idx = src2 & ( op_size * 8 - 1 );
		uint64_t original_bit = ( value >> bit_idx ) & 1;
		uint64_t result = value | ( 1ULL << bit_idx );

		uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
		state.cpu->cpu_flags.flags.CF = original_bit;

		state.set_memory ( addr, result, 8, effect );
		effect.modified_mem.insert ( addr );

		if ( old_CF != state.cpu->cpu_flags.flags.CF ) {
			state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
		}

		effect.push_to_changes ( state,std::format ( "[{:016x}h] = {:x}h (bit {} set, CF={})", addr, result, bit_idx, original_bit ) );
	}
}

void cli ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	effect.push_to_changes ( state,"Interrupt Flag cleared (IF=0)" );
}

void btr ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;
	const auto src = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	const auto bit_idx = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );

	uint64_t value = src;
	int64_t index = bit_idx & ( op_size * 8 - 1 );
	uint64_t mask = 1ULL << index;

	uint64_t old_cf = state.cpu->cpu_flags.flags.CF;
	state.cpu->cpu_flags.flags.CF = ( value & mask ) != 0;
	if ( old_cf != state.cpu->cpu_flags.flags.CF ) {
		state.log_flag_change ( effect, "CF", old_cf, state.cpu->cpu_flags.flags.CF );
	}

	uint64_t new_value = value & ~mask;

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, new_value, op_size, effect );
		effect.modified_regs.insert ( ops [ 0 ].reg );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		int64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		state.set_memory ( addr, new_value, 8, effect );
		state.log_stack_change ( effect, addr, src, new_value );
		effect.modified_mem.insert ( addr );
	}

	effect.push_to_changes ( state,std::format ( "BTR: bit {} reset, value 0x{:x} -> 0x{:x}, CF={}",
														 index, value, new_value, ( char ) state.cpu->cpu_flags.flags.CF ) );
}

void cwd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto ax = state.get_reg ( X86_REG_AX, 2 );
	int16_t ax_val = static_cast< int16_t >( ax );
	int32_t eax_val = static_cast< int32_t >( ax_val );
	uint16_t dx_val = ( ax_val < 0 ) ? 0xFFFF : 0;
	state.set_reg ( X86_REG_EAX, eax_val, 4, effect );
	state.set_reg ( X86_REG_DX, dx_val, 2, effect );
}

void btc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	auto src = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		x86_reg dst = ops [ 0 ].reg;
		auto cur = state.get_reg ( dst, op_size );
		uint64_t val = cur;
		int64_t bit_pos = src % ( op_size * 8 );
		state.cpu->cpu_flags.flags.CF = ( val >> bit_pos ) & 1;
		val ^= ( 1ULL << bit_pos );
		state.set_reg ( dst, val, op_size, effect );
		effect.push_to_changes ( state,std::format ( "CF={}", ( char ) state.cpu->cpu_flags.flags.CF ) );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		int64_t addr = 0;
		if ( ops [ 0 ].mem.base == X86_REG_RSP ) addr = state.cpu->rsp_offset;
		else if ( ops [ 0 ].mem.base != X86_REG_INVALID ) addr = state.get_reg ( ops [ 0 ].mem.base );
		addr += ops [ 0 ].mem.disp;
		auto cur = state.get_memory ( addr, op_size );
		uint64_t val = cur;
		uint64_t bit_pos = src % ( op_size * 8 );
		state.cpu->cpu_flags.flags.CF = ( val >> bit_pos ) & 1;
		val ^= ( 1ULL << bit_pos );
		state.set_memory ( addr, val, 8, effect );
		effect.modified_mem.insert ( addr );
		effect.push_to_changes ( state,std::format ( "[{:016x}h] = {:x}h, CF={}", addr, val, ( char ) state.cpu->cpu_flags.flags.CF ) );
	}
}

void bsr(capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect) {
    const cs_x86_op* ops = instr.operands();
    // BSR dest_reg, src_reg/mem
    // dest_reg must be 16, 32, or 64-bit.
    // src_operand must be the same size as dest_reg.

    x86_reg dst_reg = ops[0].reg;
    uint8_t op_size = ops[0].size; // Should be 2, 4, or 8
    uint64_t src_val = helpers::get_src<uint64_t>(&instr, 1, state, op_size);
    if (state.exit_due_to_critical_error) return;

    // Mask src_val to the operand size, though get_src should ideally handle this.
    GET_OPERAND_MASK(operand_mask, op_size);
    src_val &= operand_mask;

    uint64_t old_zf = state.cpu->cpu_flags.flags.ZF;

    if (src_val == 0) {
        state.cpu->cpu_flags.flags.ZF = 1; // Source is zero, set ZF
        // Destination register is undefined (Intel) / unchanged (AMD).
        // We'll follow the common behavior of leaving it unchanged.
        effect.push_to_changes(state, "BSR: Source is 0, ZF=1, destination unchanged.");
    } else {
        state.cpu->cpu_flags.flags.ZF = 0; // Source is non-zero, clear ZF
        unsigned long index = 0UL;
        // _BitScanReverse for 16/32-bit, _BitScanReverse64 for 64-bit.
        bool found = false;
        if (op_size == 8) found = _BitScanReverse64(&index, src_val);
        else if (op_size == 4) found = _BitScanReverse(&index, static_cast<uint32_t>(src_val));
        else if (op_size == 2) found = _BitScanReverse(&index, static_cast<uint16_t>(src_val));
        // 'found' should always be true here because we checked src_val != 0
        state.set_reg(dst_reg, static_cast<uint64_t>(index), op_size, effect);
    }

    if (old_zf != state.cpu->cpu_flags.flags.ZF) state.log_flag_change(effect, "ZF", old_zf, state.cpu->cpu_flags.flags.ZF);
    // Other flags (CF, OF, SF, AF, PF) are undefined after BSR.
    // For simplicity in emulation, we might choose to leave them, or explicitly clear them.
    // Let's clear them to denote undefined behavior for those not explicitly set.
    uint64_t old_cf = state.cpu->cpu_flags.flags.CF; state.cpu->cpu_flags.flags.CF = 0; if (old_cf != 0) state.log_flag_change(effect, "CF", old_cf, 0);
    uint64_t old_of = state.cpu->cpu_flags.flags.OF; state.cpu->cpu_flags.flags.OF = 0; if (old_of != 0) state.log_flag_change(effect, "OF", old_of, 0);
    uint64_t old_sf = state.cpu->cpu_flags.flags.SF; state.cpu->cpu_flags.flags.SF = 0; if (old_sf != 0) state.log_flag_change(effect, "SF", old_sf, 0);
    uint64_t old_af = state.cpu->cpu_flags.flags.AF; state.cpu->cpu_flags.flags.AF = 0; if (old_af != 0) state.log_flag_change(effect, "AF", old_af, 0);
    uint64_t old_pf = state.cpu->cpu_flags.flags.PF; state.cpu->cpu_flags.flags.PF = 0; if (old_pf != 0) state.log_flag_change(effect, "PF", old_pf, 0);
}

void cbw ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto al = state.get_reg ( X86_REG_AL, 1 );
	int8_t al_val = static_cast< int8_t >( al );
	int16_t ax_val = static_cast< int16_t >( al_val );
	state.set_reg ( X86_REG_AX, ax_val, 2, effect );
}

void cqo ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto rax = state.get_reg ( X86_REG_RAX, 8 );
	uint64_t rax_val = rax;
	uint64_t rdx_val = ( rax_val < 0 ) ? 0xFFFFFFFFFFFFFFFFULL : 0;
	state.set_reg ( X86_REG_RAX, rax_val, 8, effect );
	state.set_reg ( X86_REG_RDX, rdx_val, 8, effect );
}

void cwde ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto ax = state.get_reg ( X86_REG_AX, 2 );
	int16_t ax_val = static_cast< int16_t > ( ax );
	int32_t eax_val = static_cast< int32_t > ( ax_val );
	state.set_reg ( X86_REG_EAX, eax_val, 4, effect );
}

void cld ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.cpu->cpu_flags.flags.DF = 0;
}
void clc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.cpu->cpu_flags.flags.CF = 0;
}

void clui ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.cpu->cpu_flags.flags.IF = 0;
}

void cmc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.cpu->cpu_flags.flags.CF ^= 1;
}

void stc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.cpu->cpu_flags.flags.CF = 1;
}

void tzcnt(capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect) {
    const cs_x86_op* ops = instr.operands();
    // TZCNT dest_reg, src_reg/mem
    // dest_reg must be 16, 32, or 64-bit.
    // src_operand must be the same size as dest_reg.

    x86_reg dst_reg = ops[0].reg;
    uint8_t op_size = ops[0].size; // Should be 2, 4, or 8

    if (op_size != 2 && op_size != 4 && op_size != 8) {
        effect.push_to_changes(state, std::format("TZCNT: Invalid operand size {} for destination register.", op_size));
        state.exit_due_to_critical_error = true;
        return;
    }

    uint64_t src_val = helpers::get_src<uint64_t>(&instr, 1, state, op_size);
    if (state.exit_due_to_critical_error) return;

    GET_OPERAND_MASK(operand_mask, op_size);
    src_val &= operand_mask; // Ensure src_val is masked to operand size

    uint64_t result_count = 0;
    uint8_t size_in_bits = op_size * 8;

    uint64_t old_cf = state.cpu->cpu_flags.flags.CF;
    uint64_t old_zf = state.cpu->cpu_flags.flags.ZF;

    if (src_val == 0) {
        result_count = size_in_bits;
        state.cpu->cpu_flags.flags.CF = 1; // Source is zero, CF = 1
    } else {
        result_count = static_cast<uint64_t>(std::countr_zero(src_val));
        state.cpu->cpu_flags.flags.CF = 0; // Source is non-zero, CF = 0
    }
    state.cpu->cpu_flags.flags.ZF = (result_count == 0); // ZF = 1 if result is 0, else 0

    state.set_reg(dst_reg, result_count, op_size, effect);

    if (old_cf != state.cpu->cpu_flags.flags.CF) state.log_flag_change(effect, "CF", old_cf, state.cpu->cpu_flags.flags.CF);
    if (old_zf != state.cpu->cpu_flags.flags.ZF) state.log_flag_change(effect, "ZF", old_zf, state.cpu->cpu_flags.flags.ZF);

    // OF, SF, AF, PF are undefined (cleared)
    uint64_t old_of = state.cpu->cpu_flags.flags.OF; state.cpu->cpu_flags.flags.OF = 0; if (old_of != 0) state.log_flag_change(effect, "OF", old_of, 0);
    uint64_t old_sf = state.cpu->cpu_flags.flags.SF; state.cpu->cpu_flags.flags.SF = 0; if (old_sf != 0) state.log_flag_change(effect, "SF", old_sf, 0);
    uint64_t old_af = state.cpu->cpu_flags.flags.AF; state.cpu->cpu_flags.flags.AF = 0; if (old_af != 0) state.log_flag_change(effect, "AF", old_af, 0);
    uint64_t old_pf = state.cpu->cpu_flags.flags.PF; state.cpu->cpu_flags.flags.PF = 0; if (old_pf != 0) state.log_flag_change(effect, "PF", old_pf, 0);
}


void bsf ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint8_t op_size = ops [ 0 ].size;

	if ( op_size != 2 && op_size != 4 && op_size != 8 ) {
		effect.push_to_changes ( state, std::format ( "BSF: Invalid operand size {} for destination register.", op_size ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t src_val = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	if ( state.exit_due_to_critical_error ) return;

	uint64_t operand_mask = ( op_size == 8 ) ? UINT64_MAX : ( ( 1ULL << ( op_size * 8 ) ) - 1 );
	src_val &= operand_mask;

	uint64_t old_zf = state.cpu->cpu_flags.flags.ZF;

	if ( src_val == 0 ) {
		state.cpu->cpu_flags.flags.ZF = 1;
		effect.push_to_changes ( state, "BSF: Source is 0, ZF=1, destination unchanged." );
	}
	else {
		unsigned long index = 0;
		uint8_t size_in_bits = op_size * 8;
		while ( index < size_in_bits && ( src_val & ( 1ULL << index ) ) == 0 ) {
			++index;
		}
		state.set_reg ( dst_reg, static_cast< uint64_t > ( index ), op_size, effect );
		state.cpu->cpu_flags.flags.ZF = 0;
	}

	if ( old_zf != state.cpu->cpu_flags.flags.ZF ) {
		state.log_flag_change ( effect, "ZF", old_zf, state.cpu->cpu_flags.flags.ZF );
	}

	uint64_t old_cf = state.cpu->cpu_flags.flags.CF;
	state.cpu->cpu_flags.flags.CF = 0;
	if ( old_cf != 0 ) state.log_flag_change ( effect, "CF", old_cf, 0 );

	uint64_t old_of = state.cpu->cpu_flags.flags.OF;
	state.cpu->cpu_flags.flags.OF = 0;
	if ( old_of != 0 ) state.log_flag_change ( effect, "OF", old_of, 0 );

	uint64_t old_sf = state.cpu->cpu_flags.flags.SF;
	state.cpu->cpu_flags.flags.SF = 0;
	if ( old_sf != 0 ) state.log_flag_change ( effect, "SF", old_sf, 0 );

	uint64_t old_af = state.cpu->cpu_flags.flags.AF;
	state.cpu->cpu_flags.flags.AF = 0;
	if ( old_af != 0 ) state.log_flag_change ( effect, "AF", old_af, 0 );

	uint64_t old_pf = state.cpu->cpu_flags.flags.PF;
	state.cpu->cpu_flags.flags.PF = 0;
	if ( old_pf != 0 ) state.log_flag_change ( effect, "PF", old_pf, 0 );
}

void helpers::bind_bit ( ) {
	BIND ( bzhi );
	BIND ( andn );
	BIND ( bextr );
	BIND ( ror );
	BIND ( popcnt );
	BIND ( bswap );
	BIND ( tzcnt );
	BIND ( bsr );
	BIND ( setb );
	BIND ( setnp );
	BIND ( sets );
	BIND ( rcr );
	BIND ( setnl );
	BIND ( seto );
	BIND ( setbe );
	BIND ( setz );
	BIND ( setnb );
	BIND ( setno );
	BIND ( rol );
	BIND ( rcl );
	BIND ( bt );
	BIND ( bts );
	BIND ( setp );
	BIND ( setle );
	BIND ( setnle );
	BIND ( setns );
	BIND ( setl );
	BIND ( setnbe );
	BIND ( setnz );
	BIND ( cli );
	BIND ( clc );
	BIND ( cmc );
	BIND ( stc );
	BIND ( clui );
	BIND ( cld );
	BIND ( btr );
	BIND ( cwd );
	BIND ( btc );
	BIND ( cbw );
	BIND ( cqo );
	BIND ( cwde );
	BIND ( bsf );
}
```

`semantics/src/control_flow.cpp`:

```cpp
#include "pch.hpp"

void cmp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	auto src1 = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	auto src2 = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );

	state.update_flags_sub ( src1, src2, op_size, effect );
}

void test ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	auto src1 = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	auto src2 = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	state.update_flags_test ( src1, src2, op_size, effect );
}

void ret ( capstone::Instruction& instr,
				 EmulationContext& state,
				 InstructionEffect& effect ) {
	int64_t imm = 0;
	if ( instr.operand_count ( ) > 0 && instr.operands ( ) [ 0 ].type == X86_OP_IMM )
		imm = instr.operands ( ) [ 0 ].imm;
	uint64_t pop_size = 8 + imm;

	if ( state.call_stack.empty ( ) ) {
		state.exit_due_to_critical_error = true;
		return;
	}
	CallFrame frame = state.call_stack.back ( );
	uint64_t return_ip = frame.return_addr;
	state.call_stack.pop_back ( );

	uint64_t old_rsp = state.get_reg ( X86_REG_RSP, 8 );
	uint64_t new_rsp = old_rsp + pop_size;
	state.set_reg ( X86_REG_RSP, new_rsp, 8, effect );
	effect.modified_regs.insert ( X86_REG_RSP );
	effect.push_to_changes ( state,
			std::format ( "RET: popped 0x{:x}, RSP += 0x{:x}", return_ip, pop_size )
	);

	for ( auto& [base, mod] : state.windows->loaded_modules ) {
		if ( return_ip >= base && return_ip < base + mod.size ) {
			if ( state.windows->current_module_base != base ) {
				size_t match_index = 0;
				bool found = false;

				for ( size_t i = 0; i < state.decoder.size ( ); ++i ) {
					if ( state.decoder [ i ]->data_ == mod.decoder->data_ ) {
						match_index = i;
						found = true;
						break;
					}
				}

				if ( found ) {
					state.decoder.resize ( match_index + 1 ); // Shrink to just after match
				}
				else {
					state.decoder.emplace_back ( mod.decoder.get ( ) ); // Use shared_ptr
				}
				state.windows->current_module_base = base;
				effect.push_to_changes ( state,
						std::format ( "RET -> switch decoder to module @0x{:x}", base )
				);
			}
			break;
		}
	}

	state.decoder.back ( )->set_ip ( return_ip );
	effect.push_to_changes ( state,
			std::format ( "RET -> 0x{:x} (module+{:#x}", return_ip, return_ip - state.windows->current_module_base )
	);
}

void call ( capstone::Instruction& instr,
					EmulationContext& state,
					InstructionEffect& effect ) {
	uint64_t raw_target = helpers::get_target2 ( instr, state, effect );
	if ( !raw_target ) {
		effect.push_to_changes ( state, "CALL Error: could not decode target" );
		state.exit_due_to_critical_error = true;
		return;
	}
	if ( raw_target <= state.windows->loaded_base_address || raw_target >= state.windows->loaded_base_address + state.windows->loaded_module_size ) {
		auto ait = state.windows->api_hooks.find ( raw_target );
		if ( ait == state.windows->api_hooks.end() ) { // handle indirection
			ait = state.windows->api_hooks.find ( state.get_reg<uint64_t> ( X86_REG_RAX ) );
		}
		if ( ait != state.windows->api_hooks.end ( ) ) {
			effect.push_to_changes ( state,
					std::format ( "CALL hits API hook at 0x{:x}, dispatching hook inline.", raw_target ) );
			ait->second ( instr, state, effect, raw_target );

			return;
		}
	}
	auto it = state.windows->imports.find ( raw_target );
	if ( it != state.windows->imports.end ( ) ) {
		uint64_t return_ip = instr.ip ( ) + instr.length ( );

		uint64_t old_rsp = state.get_reg ( X86_REG_RSP, 8 );
		uint64_t new_rsp = old_rsp - 8;
		state.set_reg ( X86_REG_RSP, new_rsp, 8, effect );
		state.set_stack ( new_rsp, return_ip, effect, /*size=*/8 );
		effect.modified_regs.insert ( X86_REG_RSP );
		effect.modified_mem.insert ( new_rsp );

		// record the frame so RET still works
		state.push_call_frame ( return_ip, effect );

		state.set_reg ( X86_REG_RAX, 0, /*size=*/8, effect );

		state.pop_call_frame ( effect );
		state.set_reg ( X86_REG_RSP, old_rsp, 8, effect );
		state.decoder.back ( )->set_ip ( return_ip );
		effect.push_to_changes ( state,
				std::format ( "Stubbed import call to {}!{} -> returned 0, jumping to 0x{:x}",
														 it->second.first, it->second.second, return_ip ) );
		return;
	}

	uint64_t return_ip = instr.ip ( ) + instr.length ( );
	uint64_t old_rsp = state.get_reg ( X86_REG_RSP, 8 );
	uint64_t new_rsp = old_rsp - 8;
	state.set_reg ( X86_REG_RSP, new_rsp, 8, effect );
	state.set_stack ( new_rsp, return_ip, effect, /*size=*/8 );
	effect.modified_regs.insert ( X86_REG_RSP );
	effect.modified_mem.insert ( new_rsp );

	state.push_call_frame ( return_ip, effect );

	uint64_t landed = helpers::resolve_and_switch_target (
			instr, state, raw_target, effect,
			/*is_call=*/true
	);
	if ( !landed ) {
		effect.push_to_changes ( state, "CALL Error: unable to switch to target" );
		state.exit_due_to_critical_error = true;
	}
	effect.push_to_changes ( state, std::format ( "module+{:#x}", state.decoder.back ( )->ip ( ) - landed ) );
}


void helpers::bind_cf ( ) {
	BIND ( cmp );
	BIND ( test );
	BIND ( call );
	BIND ( ret );
}
```

`semantics/src/cpu.cpp`:

```cpp
#include "pch.hpp"


void rdtsc ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.increment_tsc ( );

	const auto tsc = state.cpu->tsc;
	const auto low = static_cast< uint32_t >( tsc & 0xFFFFFFFF );
	const auto high = static_cast< uint32_t >( tsc >> 32 );

	state.set_reg ( X86_REG_RAX, low, 4, effect );
	state.set_reg ( X86_REG_RDX, high, 4, effect );

	effect.push_to_changes ( state, std::format ( "RDTSC: RAX=0x{:08x}, RDX=0x{:08x} (TSC=0x{:016x})", low, high, tsc ) );
	effect.modified_regs.insert ( X86_REG_RAX );
	effect.modified_regs.insert ( X86_REG_RDX );
}

void cpuid ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const auto eax_in = state.get_reg<uint32_t> ( X86_REG_RAX );
	const auto ecx_in = state.get_reg<uint32_t> ( X86_REG_RCX );

	int cpu_info [ 4 ] = { 0 }; // EAX, EBX, ECX, EDX

	__cpuidex ( cpu_info, eax_in, ecx_in );

	state.set_reg ( X86_REG_RAX, static_cast< uint32_t >( cpu_info [ 0 ] ), 4, effect );
	state.set_reg ( X86_REG_RBX, static_cast< uint32_t >( cpu_info [ 1 ] ), 4, effect );
	state.set_reg ( X86_REG_RCX, static_cast< uint32_t >( cpu_info [ 2 ] ), 4, effect );
	state.set_reg ( X86_REG_RDX, static_cast< uint32_t >( cpu_info [ 3 ] ), 4, effect );

	effect.push_to_changes ( state, std::format ( "CPUID[RAX={:#x}, RCX={:#x}]: RAX={:#08x}, RBX={:#08x}, RCX={:#08x}, RDX={:#08x}",
													 eax_in, ecx_in, cpu_info [ 0 ], cpu_info [ 1 ], cpu_info [ 2 ], cpu_info [ 3 ] ) );

	effect.modified_regs.insert ( X86_REG_RAX );
	effect.modified_regs.insert ( X86_REG_RBX );
	effect.modified_regs.insert ( X86_REG_RCX );
	effect.modified_regs.insert ( X86_REG_RDX );
}

void xgetbv ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const auto ecx_in = state.get_reg <uint32_t> ( X86_REG_RCX );
	const auto xcr_val = _xgetbv ( ecx_in ); // Intrinsic to get XCR value from host

	const auto eax_out = static_cast< uint32_t >( xcr_val & 0xFFFFFFFF );
	const auto edx_out = static_cast< uint32_t >( xcr_val >> 32 );

	state.set_reg ( X86_REG_RAX, eax_out, 4, effect );
	state.set_reg ( X86_REG_RDX, edx_out, 4, effect );

	effect.push_to_changes ( state, std::format ( "XGETBV[ECX=0x{:x}]: RAX=0x{:08x}, RDX=0x{:08x} (XCR=0x{:016x})",
													 ecx_in, eax_out, edx_out, xcr_val ) );
	effect.modified_regs.insert ( X86_REG_RAX );
	effect.modified_regs.insert ( X86_REG_RDX );
}

struct SyscallState {
	uint64_t rax;
	uint64_t rcx;
	uint64_t rdx;
	uint64_t r8;
	uint64_t r9;
	uint64_t r10;
	uint64_t rsp;
};

extern "C" void execute_raw_syscall (
		uint64_t rax, uint64_t rcx, uint64_t rdx, uint64_t r8, uint64_t r9,
		uint64_t* stack_args, size_t stack_arg_count, SyscallState* state
);

void syscall ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto syscall_num = state.get_reg ( X86_REG_RAX );
	auto arg1 = state.get_reg ( X86_REG_RCX );
	auto arg2 = state.get_reg ( X86_REG_RDX );
	auto arg3 = state.get_reg ( X86_REG_R8 );
	auto arg4 = state.get_reg ( X86_REG_R9 );
	auto current_rsp = state.get_reg ( X86_REG_RSP );

	std::vector<uint64_t> stack_args;
	if ( syscall_num == 0x18 ) {
		for ( size_t i = 4; i < 9; ++i ) {
			uint64_t addr = current_rsp + ( i - 4 ) * 8;
			stack_args.push_back ( state.get_stack ( addr, false ) );
		}
	}

	struct RealBuffer {
		uint64_t virtual_addr;
		std::unique_ptr<uint8_t [ ]> real_mem;
		size_t size;
	};
	std::vector<RealBuffer> real_buffers;

	if ( syscall_num == 0x1c ) {
		size_t len = ( size_t ) arg4;
		if ( len ) {
			RealBuffer buf { arg3, std::make_unique<uint8_t [ ]> ( len ), len };
			for ( size_t i = 0; i < len; ++i )
				buf.real_mem [ i ] = static_cast< uint8_t > ( state.get_memory ( arg3 + i, 1 ) );
			real_buffers.push_back ( std::move ( buf ) );
		}
	}

	SyscallState post;
	execute_raw_syscall ( syscall_num,
											arg1, arg2, arg3, arg4,
											stack_args.data ( ), stack_args.size ( ),
											&post );

	state.set_reg ( X86_REG_RAX, post.rax, 8, effect );
	state.set_reg ( X86_REG_RCX, post.rcx, 8, effect );
	state.set_reg ( X86_REG_RDX, post.rdx, 8, effect );
	state.set_reg ( X86_REG_R8, post.r8, 8, effect );
	state.set_reg ( X86_REG_R9, post.r9, 8, effect );
	state.set_reg ( X86_REG_R10, post.r10, 8, effect );


	for ( auto& buf : real_buffers ) {
		for ( size_t i = 0; i < buf.size; i += 8 ) {
			uint64_t v = 0;
			memcpy ( &v, buf.real_mem.get ( ) + i, sizeof ( v ) );
			uint64_t va = buf.virtual_addr + i;
			if ( state.is_within_stack_bounds ( ( int64_t ) va, 8 ) )
				state.set_stack ( va, v, effect );
			else {
				state.set_memory ( va, v, 8, effect );
				effect.modified_mem.insert ( va );
			}
		}
	}

	effect.push_to_changes (
			state,
			std::format ( "syscall 0x{:x} returned 0x{:016x}", syscall_num, post.rax )
	);
}




void hlt ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	if ( state.cpu->current_privilege_level == 3 ) {
		if ( state.options.enable_logging ) {
			effect.push_to_changes ( state, "HLT executed in user mode (pre-check failed?). Forcing PRIV_INSTRUCTION exception." );
		}

		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_PRIV_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}
	else {
		if ( state.options.enable_logging ) {
			effect.push_to_changes ( state, "HLT executed in non-user mode. Halting emulation simulation." );
		}

		state.exit_due_to_critical_error = true;
	}
}


void int1 (
		capstone::Instruction& instr,
		EmulationContext& state,
		InstructionEffect& effect
) {
	effect.push_to_changes ( state, "INT 0x01 - Debug exception" );
	GuestExceptionInfo ex;
	ex.set_exception ( EXCEPTION_DEBUG_EVENT, instr.ip ( ) ); // TODO: find correct wincode
	throw ex;
}

void int3 (
		capstone::Instruction& instr,
		EmulationContext& state,
		InstructionEffect& effect
) {
	effect.push_to_changes ( state, "INT 0x03 - Breakpoint" );
	GuestExceptionInfo ex;
	ex.set_exception ( EXCEPTION_BREAKPOINT, instr.ip ( ) );
	throw ex;
}

void int_ (
		capstone::Instruction& instr,
		EmulationContext& state,
		InstructionEffect& effect
) {
	// must be an immediate interrupt
	const auto ops = instr.operands ( );
	if ( instr.operand_count ( ) < 1 || ops [ 0 ].type != X86_OP_IMM ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	uint8_t vector = static_cast< uint8_t >( ops [ 0 ].imm & 0xFF );
	switch ( vector ) {
		case 0x00:
		{
			effect.push_to_changes ( state, "INT 0x0 - Divide Error" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_INT_DIVIDE_BY_ZERO, instr.ip ( ) );
			throw ex;
		}
		case 0x01:
		{
			effect.push_to_changes ( state, "INT 0x01 - Debug Exception" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_SINGLE_STEP, instr.ip ( ) );
			throw ex;
		}
		case 0x02:
		{
			effect.push_to_changes ( state, "INT 0x02 - Non-Maskable Interrupt" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_NONCONTINUABLE_EXCEPTION, instr.ip ( ) );
			throw ex;
		}
		case 0x03:
		{
			effect.push_to_changes ( state, "INT 0x03 - Breakpoint" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_BREAKPOINT, instr.ip ( ) );
			throw ex;
		}
		case 0x04:
		{
			effect.push_to_changes ( state, "INT 0x04 - Overflow" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_INT_OVERFLOW, instr.ip ( ) );
			throw ex;
		}
		case 0x05:
		{
			effect.push_to_changes ( state, "INT 0x05 - Bounds Check" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ARRAY_BOUNDS_EXCEEDED, instr.ip ( ) );
			throw ex;
		}
		case 0x06:
		{
			effect.push_to_changes ( state, "INT 0x06 - Invalid Opcode" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x07:
		{
			effect.push_to_changes ( state, "INT 0x07 - Device Not Available" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x08:
		{
			effect.push_to_changes ( state, "INT 0x08 - Double Fault" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x09:
		{
			effect.push_to_changes ( state, "INT 0x09 - Coprocessor Segment Overrun" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x0A:
		{
			effect.push_to_changes ( state, "INT 0x0A - Invalid TSS" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x0B:
		{
			effect.push_to_changes ( state, "INT 0x0B - Segment Not Present" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x0C:
		{
			effect.push_to_changes ( state, "INT 0x0C - Stack-Segment Fault" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ACCESS_VIOLATION, instr.ip ( ) );
			throw ex;
		}
		case 0x0D:
		{
			effect.push_to_changes ( state, "INT 0x0D - General Protection Fault" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ACCESS_VIOLATION, instr.ip ( ) );
			throw ex;
		}
		case 0x0E:
		{
			effect.push_to_changes ( state, "INT 0x0E - Page Fault" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ACCESS_VIOLATION, instr.ip ( ) );
			throw ex;
		}
		case 0x10:
		{
			effect.push_to_changes ( state, "INT 0x10 - x87 FPU Math Fault" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x11:
		{
			effect.push_to_changes ( state, "INT 0x11 - Alignment Check" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_DATATYPE_MISALIGNMENT, instr.ip ( ) );
			throw ex;
		}
		case 0x12:
		{
			effect.push_to_changes ( state, "INT 0x12 - Machine Check" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_NONCONTINUABLE_EXCEPTION, instr.ip ( ) );
			throw ex;
		}
		case 0x13:
		{
			effect.push_to_changes ( state, "INT 0x13 - SIMD FP Exception" );
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
		case 0x29:
		{
			uint8_t ch = static_cast< uint8_t >( state.get_reg<uint32_t> ( X86_REG_EAX ) & 0xFF );
			effect.push_to_changes (
					state,
					std::format ( "INT29 -> byte 0x{:02x} ('{}')", ch, static_cast< char >( ch ) )
			);
			state.console_output.push_back ( static_cast< char >( ch ) );
			uint32_t next_eip = static_cast< uint32_t >( instr.ip ( ) + instr.length ( ) );
			state.set_reg ( X86_REG_EIP, next_eip, 4, effect );
			effect.modified_regs.insert ( X86_REG_EIP );
			return;
		}
		default:
		{
			GuestExceptionInfo ex;
			ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
			throw ex;
		}
	}
}

void fxsave ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) != 1 || ops [ 0 ].type != X86_OP_MEM ) {
		effect.push_to_changes ( state, "FXSAVE: Invalid operand (must be memory)." );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	uint64_t base_addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
	if ( state.exit_due_to_critical_error ) return;

	// --- Save FPU State ---
	// 0-1: FCW
	state.set_memory ( base_addr + 0, state.cpu->fpu.fpu_control_word, 2, effect );
	// 2-3: FSW
	state.set_memory ( base_addr + 2, state.cpu->fpu.fpu_status_word, 2, effect );
	// 4-5: FTW (Abridged FPU Tag Word - compact form)
	// Each ST(i) has a 2-bit tag. FTW[i] = tag_is_empty(ST(i)) ? 1 : 0
	// This is the "abridged" version for FXSAVE.
	// The full 16-bit FPU Tag Word (FTW) has 2 bits per register.
	// FXSAVE saves an 8-bit "FTW" (sometimes called FTAG or Abridged FTW)
	// where bit i corresponds to ST(i). Bit is 0 if tag is valid/zero/special, 1 if empty.
	uint8_t ftag = 0;
	for ( int i = 0; i < 8; ++i ) {
		int phys_idx = state.get_fpu_phys_idx ( i );
		if ( state.get_fpu_tag ( phys_idx ) == FPU_TAG_EMPTY ) {
			ftag |= ( 1 << i );
		}
	}
	state.set_memory ( base_addr + 4, ftag, 1, effect ); // Store as byte
	state.set_memory ( base_addr + 5, 0, 1, effect );    // Reserved byte after FTAG, should be 0.
	// Some diagrams show FTW as 2 bytes, with byte 5 being part of it.
	// Let's be safe and zero byte 5.

// 6-7: FOP (Last FPU Opcode)
// This is usually the last non-control FPU instruction's opcode (11 bits).
// Emulating this accurately is complex. For now, set to 0.
	state.set_memory ( base_addr + 6, 0, 2, effect );

	// 8-15: FIP (FPU Instruction Pointer - 64-bit in 64-bit mode)
	// This should be the RIP of the last non-control FPU instruction. Complex to track perfectly.
	// For now, 0 or a placeholder. Ideally, it would be the RIP of the last x87 instruction.
	uint64_t last_fpu_instr_ip = 0; // Placeholder
	state.set_memory ( base_addr + 8, last_fpu_instr_ip, 8, effect );

	// 16-23: FDP (FPU Data Pointer - 64-bit in 64-bit mode)
	// Address of the last FPU memory operand. Also complex.
	uint64_t last_fpu_data_ptr = 0; // Placeholder
	state.set_memory ( base_addr + 16, last_fpu_data_ptr, 8, effect );

	// --- Save SSE/MXCSR State ---
	// 24-27: MXCSR
	state.set_memory ( base_addr + 24, *( uint32_t* ) &state.cpu->cpu_flags.mxcsr, 4, effect );
	// 28-31: MXCSR_MASK (Typically 0x0000FFBF, can be changed by LDMXCSR but rare for mask)
	state.set_memory ( base_addr + 28, 0x0000FFBF, 4, effect );

	// --- Save ST(i)/MMX Registers ---
	// 32-159: ST0/MM0 through ST7/MM7 (8 registers * 16 bytes/reg = 128 bytes)
	// Each 80-bit FPU register is saved in a 16-byte memory region, bottom-aligned.
	// The upper 6 bytes of each 16-byte region are reserved and should be written as 0.
	for ( int i = 0; i < 8; ++i ) {
		int phys_idx = state.get_fpu_phys_idx ( i ); // Get physical stack index for ST(i)
		const float80_t& st_val = state.cpu->fpu.fpu_stack [ phys_idx ];
		uint64_t current_reg_addr = base_addr + 32 + ( i * 16 );

		// This is tricky. float80_t needs to be serialized to 10 bytes.
		// For simplicity, if write_float80_to_memory handles the 10-byte write:
		state.write_float80_to_memory ( current_reg_addr, st_val, effect );
		// Then zero out the remaining 6 reserved bytes in that 16-byte slot
		for ( int j = 10; j < 16; ++j ) {
			state.set_memory ( current_reg_addr + j, 0, 1, effect );
		}
	}

	// --- Save XMM Registers ---
	// 160-415: XMM0 through XMM15 (16 registers * 16 bytes/reg = 256 bytes)
	for ( int i = 0; i < 16; ++i ) {
		x86_reg xmm_reg = static_cast< x86_reg > ( X86_REG_XMM0 + i );
		uint128_t xmm_val = state.get_xmm_raw ( xmm_reg );
		state.set_memory_128 ( base_addr + 160 + ( i * 16 ), xmm_val, effect );
	}

	// 416-511: Reserved, must be zeroed by FXSAVE. (96 bytes)
	for ( int i = 0; i < 96; i += 8 ) { // Zero out in 8-byte chunks
		state.set_memory ( base_addr + 416 + i, 0, 8, effect );
	}

	effect.push_to_changes ( state, std::format ( "fxsave to [0x{:016x}]", base_addr ) );
	// FXSAVE does not modify any flags.
}

void fxrstor ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) != 1 || ops [ 0 ].type != X86_OP_MEM ) {
		effect.push_to_changes ( state, "FXRSTOR: Invalid operand (must be memory)." );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	uint64_t base_addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
	if ( state.exit_due_to_critical_error ) return;

	// Alignment Check: Must be 16-byte aligned
	if ( ( base_addr % 16 ) != 0 ) {
		effect.push_to_changes ( state, std::format ( "FXRSTOR: Misaligned memory access at 0x{:x} (must be 16-byte aligned).", base_addr ) );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ACCESS_VIOLATION, instr.ip ( ), base_addr ); // #GP(0)
		throw ex;
	}

	// --- Restore FPU State ---
	// 0-1: FCW
	uint16_t fcw = static_cast< uint16_t >( state.get_memory ( base_addr + 0, 2 ) );
	// Check reserved bits in FCW (bits 6, 7, 13, 14, 15 must be 0 for FXRSTOR)
	if ( ( fcw & 0xE0C0 ) != 0 ) { // Mask for bits 6,7,13,14,15
		effect.push_to_changes ( state, std::format ( "FXRSTOR: FCW 0x{:04x} has reserved bits set.", fcw ) );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ACCESS_VIOLATION, instr.ip ( ) ); throw ex; // #GP
	}
	state.cpu->fpu.fpu_control_word = fcw;

	// 2-3: FSW
	uint16_t fsw = static_cast< uint16_t >( state.get_memory ( base_addr + 2, 2 ) );
	// FSW reserved bits are implicitly handled by what we store/use.
	state.cpu->fpu.fpu_status_word = fsw;
	state.cpu->fpu.fpu_top = ( fsw & FSW_TOP_MASK ) >> FSW_TOP_SHIFT; // Update TOP from FSW

	// 4-5: FTW (Abridged FPU Tag Word)
	uint8_t ftag_abridged = static_cast< uint8_t >( state.get_memory ( base_addr + 4, 1 ) );
	// Convert abridged FTAG back to full 16-bit FTW for internal representation
	// An abridged bit of 1 means EMPTY. 0 means NOT EMPTY (valid, zero, or special).
	// For FXRSTOR, if a tag is loaded as "not empty", the actual ST(i) content determines if it's V/Z/S.
	// The TAG word is restored based on the value in memory.
	// For now, we'll just store the tags. A full FPU model would validate ST(i) against its tag.
	state.cpu->fpu.fpu_tag_word = 0; // Will be reconstructed based on loaded ST values later.
	// The FTAG in memory is more of a hint for FXRSTOR.
	// The actual tags will be re-evaluated when ST registers are loaded.

// 6-7: FOP (FPU Opcode) - Loaded, but its use in emulation is minor unless for deep x87 exception debugging.
// state.cpu->fpu.fpu_last_opcode = static_cast<uint16_t>(state.get_memory(base_addr + 6, 2));

// 8-15: FIP (FPU Instruction Pointer - 64-bit)
// state.cpu->fpu.fpu_last_ip = state.get_memory(base_addr + 8, 8);

// 16-23: FDP (FPU Data Pointer - 64-bit)
// state.cpu->fpu.fpu_last_dp = state.get_memory(base_addr + 16, 8);

// --- Restore SSE/MXCSR State ---
// 24-27: MXCSR
	uint32_t mxcsr_val = static_cast< uint32_t >( state.get_memory ( base_addr + 24, 4 ) );
	// Check reserved bits in MXCSR (bits 16-31 must be 0)
	if ( ( mxcsr_val >> 16 ) != 0 ) {
		effect.push_to_changes ( state, std::format ( "FXRSTOR: MXCSR 0x{:08x} has reserved bits set.", mxcsr_val ) );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ACCESS_VIOLATION, instr.ip ( ) ); throw ex; // #GP
	}
	*( uint32_t* ) &state.cpu->cpu_flags.mxcsr = mxcsr_val;

	// 28-31: MXCSR_MASK - Generally not loaded by FXRSTOR; MXCSR is validated against the current CPU's mask.
	// uint32_t mxcsr_mask_from_mem = static_cast<uint32_t>(state.get_memory(base_addr + 28, 4));
	// For simplicity, we assume MXCSR value itself was valid or FXSAVE produced a valid one.

	// --- Restore ST(i)/MMX Registers ---
	// 32-159: ST0/MM0 through ST7/MM7 (8 registers * 16 bytes/reg = 128 bytes)
	// Each 80-bit FPU register is loaded from a 16-byte memory region.
	// The upper 6 bytes are ignored.
	for ( int i = 0; i < 8; ++i ) {
		int phys_idx = state.get_fpu_phys_idx ( i ); // Get physical stack index for ST(i)
		uint64_t current_reg_addr = base_addr + 32 + ( i * 16 );
		state.cpu->fpu.fpu_stack [ phys_idx ] = state.read_float80_from_memory ( current_reg_addr, effect );
		// After loading all ST regs, re-evaluate and set tags based on loaded values and the FTAG from memory.
		// This is important because the FTAG from memory only says "empty" or "not empty".
		// If "not empty", the actual value determines if it's V, Z, or S.
		if ( ( ftag_abridged >> i ) & 1 ) { // If abridged tag says empty
			state.set_fpu_tag ( phys_idx, FPU_TAG_EMPTY );
		}
		else { // Abridged tag says not empty, classify based on loaded value.
			state.set_fpu_tag ( phys_idx, state.classify_fpu_operand ( state.cpu->fpu.fpu_stack [ phys_idx ] ) );
		}
	}

	// --- Restore XMM Registers ---
	// 160-415: XMM0 through XMM15 (16 registers * 16 bytes/reg = 256 bytes)
	for ( int i = 0; i < 16; ++i ) {
		x86_reg xmm_reg = static_cast< x86_reg > ( X86_REG_XMM0 + i );
		uint128_t xmm_val = state.get_memory_128 ( base_addr + 160 + ( i * 16 ) );
		state.set_xmm_raw ( xmm_reg, xmm_val, effect );
	}

	// 416-511: Reserved, ignored by FXRSTOR.

	effect.push_to_changes ( state, std::format ( "fxrstor from [0x{:016x}]", base_addr ) );
	// FXRSTOR can change all the loaded FPU/SSE flags and registers.
}

// And register it in bind_cpu():
void helpers::bind_cpu ( ) {
	BIND ( rdtsc );
	BIND ( cpuid );
	BIND ( xgetbv );
	BIND ( syscall );
	BIND ( int_ );
	BIND ( int1 );
	BIND ( int3 );
	BIND ( fxsave );
	BIND ( fxrstor );

	BIND ( hlt );
}

```

`semantics/src/data.cpp`:

```cpp
#include "pch.hpp"

void mov ( capstone::Instruction& instr,
				 EmulationContext& state,
				 InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	const uint8_t    size = ops [ 0 ].size;

	if ( state.get_reg<uint64_t> ( X86_REG_RSP ) !=
			reinterpret_cast< uint64_t >( state.rsp_base.get ( ) + state.cpu->rsp_offset ) ) {
		state.set_reg ( X86_REG_RSP,
									reinterpret_cast< uint64_t >( state.rsp_base.get ( ) + state.cpu->rsp_offset ),
									8, effect );
	}

	const uint64_t src = helpers::get_src<uint64_t> ( &instr, 1, state, size );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, src, size, effect );
		return;
	}

	const uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );

	if ( state.is_within_stack_bounds ( addr, size ) ) {
		state.set_stack ( addr, src, effect, size );
	}
	else {
		state.set_memory ( addr, src, size, effect );
		effect.push_to_changes ( state,
				std::format ( "[{:016x}] = {:#x} (size={})", addr, src, size ) );
	}

	effect.modified_mem.insert ( addr );
}


void movabs ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	x86_reg dst = ops [ 0 ].reg;
	uint64_t imm = ops [ 1 ].imm;

	state.set_reg ( dst, imm, 8, effect );
}

void movaps ( capstone::Instruction& instr,
						EmulationContext& ctx,
						InstructionEffect& eff ) {
	auto ops = instr.operands ( );
	const auto& dst = ops [ 0 ];
	const auto& src = ops [ 1 ];

	if ( dst.type == X86_OP_REG && src.type == X86_OP_REG ) {
		ctx.set_xmm_raw ( dst.reg, ctx.get_xmm_raw ( src.reg ), eff );
		eff.push_to_changes ( ctx,
			std::format ( "XMM{}=XMM{}", dst.reg - X86_REG_XMM0, src.reg - X86_REG_XMM0 ) );
		return;
	}

	if ( dst.type == X86_OP_REG && src.type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( src, instr, ctx );
		if ( addr % 16 != 0 ) {
			if ( ctx.cpu->cpu_flags.flags.AC ) throw GuestExceptionInfo {/*...*/ };
			return;
		}
		auto val = ctx.get_memory_128 ( addr );
		ctx.set_xmm_raw ( dst.reg, val, eff );
		eff.push_to_changes ( ctx,
			std::format ( "XMM{}=[0x{:016x}]", dst.reg - X86_REG_XMM0, addr ) );
		eff.modified_mem.insert ( addr );
		return;
	}

	if ( dst.type == X86_OP_MEM && src.type == X86_OP_REG ) {
		uint64_t addr = helpers::calculate_mem_addr ( dst, instr, ctx );
		if ( addr % 16 != 0 ) return;
		auto val = ctx.get_xmm_raw ( src.reg );
		if ( ctx.is_within_stack_bounds ( addr, 16 ) )
			ctx.set_stack_128 ( addr, val, eff );
		else
			ctx.set_memory_128 ( addr, val, eff );
		eff.push_to_changes ( ctx,
			std::format ( "[0x{:016x}]=XMM{}", addr, src.reg - X86_REG_XMM0 ) );
		eff.modified_mem.insert ( addr );
		return;
	}

	std::println ( "MOVAPS: unsupported at 0x{:x}", instr.ip ( ) );
}

void movzx ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( ); // ops[0] is DEST, ops[1] is SRC

	// Validate destination: must be a register
	if ( ops [ 0 ].type != X86_OP_REG ) {
		effect.push_to_changes ( state, std::format ( "MOVZX Error: Destination operand is not a register at IP 0x{:x}", instr.ip ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}
	x86_reg dst_reg = ops [ 0 ].reg;
	uint8_t dst_size = ops [ 0 ].size;

	// Validate source: must be register or memory
	const cs_x86_op& src_op = ops [ 1 ];
	if ( src_op.type != X86_OP_REG && src_op.type != X86_OP_MEM ) {
		effect.push_to_changes ( state, std::format ( "MOVZX Error: Source operand is not register or memory at IP 0x{:x}", instr.ip ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}
	uint8_t src_size = src_op.size;

	// Validate operand sizes for MOVZX
	// Valid forms (src_size -> possible dst_sizes):
	// 1 (byte)  -> 2 (word), 4 (dword), 8 (qword)
	// 2 (word)  -> 4 (dword), 8 (qword)
	// 4 (dword) -> 8 (qword) (e.g., movzx rax, ebx; requires REX.W if src is GPR)
	bool valid_size_combination = false;
	if ( src_size == 1 && ( dst_size == 2 || dst_size == 4 || dst_size == 8 ) ) {
		valid_size_combination = true;
	}
	else if ( src_size == 2 && ( dst_size == 4 || dst_size == 8 ) ) {
		valid_size_combination = true;
	}
	else if ( src_size == 4 && dst_size == 8 ) {
		valid_size_combination = true;
	}

	if ( !valid_size_combination ) {
		effect.push_to_changes ( state, std::format ( "MOVZX Error: Invalid operand size combination (src: {}, dst: {}) at IP 0x{:x}", src_size, dst_size, instr.ip ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	// Fetch the source value using its actual size.
	// helpers::get_src should correctly retrieve 'src_size' bytes from the source operand.
	uint64_t src_val_raw = helpers::get_src<uint64_t> ( &instr, 1, state, src_size );

	// Create a mask for the source operand's actual size.
	// GET_OPERAND_MASK is defined in context.hpp:
	// #define GET_OPERAND_MASK(x, y) uint64_t x = (1ULL << (y*8)) - 1; if (y == 8) {x = 0xFFFFFFFFFFFFFFFFULL;}
	GET_OPERAND_MASK ( source_mask, src_size );

	// Apply the mask to ensure only the source operand's bits are considered.
	// This effectively performs the zero-extension because src_val_raw is uint64_t.
	uint64_t value_to_set = src_val_raw & source_mask;

	// Set the destination register.
	// EmulationContext::set_reg handles writing to partial registers and
	// zeroing upper bits for 32-bit destinations (e.g., EAX when RAX is the full register).
	state.set_reg ( dst_reg, value_to_set, dst_size, effect );
}

void push ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto src = helpers::get_src<uint64_t> ( &instr, 0, state, instr.operands ( ) [ 0 ].size );

	state.allocate_stack ( 8, effect );

	uint64_t new_rsp = state.get_reg ( X86_REG_RSP );
	state.set_stack ( new_rsp, src, effect, 8 );
	effect.modified_mem.insert ( new_rsp );
}

void pop ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t dst_op_size = ops [ 0 ].size;
	int64_t stack_addr = state.get_reg ( X86_REG_RSP );
	auto val_popped = state.get_stack ( stack_addr, false );

	if ( ops [ 0 ].type == X86_OP_REG ) {
		uint64_t result = val_popped;
		state.set_reg ( ops [ 0 ].reg, result, dst_op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		int64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		state.set_memory ( addr, val_popped, 8, effect );
		effect.modified_mem.insert ( addr );
	}


	uint64_t new_rsp = stack_addr + 8; // Increment RSP by 8
	state.set_reg ( X86_REG_RSP, new_rsp, 8, effect );

	state.stack_allocated -= 8; // Decrease allocation tracking
	if ( state.stack_allocated < 0 ) state.stack_allocated = 0; // Prevent underflow

	if ( state.options.enable_logging ) {
		effect.push_to_changes ( state, std::format ( "Adjusted stack allocation by -0x8" ) );
	}
}

void lea ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t dst_size = ops [ 0 ].size;
	x86_reg dst_reg = ops [ 0 ].reg;
	const cs_x86_op& mem_op = ops [ 1 ]; // Source is memory operand structure

	uint64_t effective_address = 0;

	// --- FIX: Handle RIP-relative addressing directly ---
	if ( mem_op.mem.base == X86_REG_RIP ) {
		effective_address = static_cast< int64_t >( instr.ip ( ) + instr.length ( ) ) + mem_op.mem.disp;
		if ( mem_op.mem.index != X86_REG_INVALID ) {
			std::print ( "Warning: LEA with RIP-relative addressing should not have an index register in instruction {}\n", instr.to_string ( ) );
			// Decide how to handle - ignore index? error? For LEA, we just calculate, so ignoring might be okay.
		}
	}
	// --- Handle other addressing modes ---
	else {
		if ( mem_op.mem.base != X86_REG_INVALID ) {
			uint64_t base_val = state.get_reg ( mem_op.mem.base, 8 ); // Address calculation uses 64-bit regs
			effective_address = base_val;
		}
		if ( mem_op.mem.index != X86_REG_INVALID ) {
			uint64_t index_val = state.get_reg ( mem_op.mem.index, 8 );
			effective_address += index_val * mem_op.mem.scale;
		}
		effective_address += mem_op.mem.disp;
	}

	// --- END FIX ---


	// Store the calculated effective address in the destination register
	// Truncate/zero-extend according to destination register size (set_reg handles this)
	state.set_reg ( dst_reg, effective_address, dst_size, effect );

	// Updatestate.rsp_offsetif RSP was the destination
	if ( dst_reg == X86_REG_RSP ) {
		// Syncstate.rsp_offset*after* RSP is updated
	}
}
void movsx ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t dst_size = ops [ 0 ].size;
	uint8_t src_size = ops [ 1 ].size;
	auto dst = ops [ 0 ].reg;
	auto src = helpers::get_src<uint64_t> ( &instr, 1, state, src_size );
	uint64_t val = src;
	if ( src_size == 1 ) val = static_cast< int8_t >( val );
	else if ( src_size == 2 ) val = static_cast< int16_t >( val );
	else if ( src_size == 4 ) val = static_cast< int32_t >( val );
	state.set_reg ( dst, val, dst_size, effect );
}

void sahf ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto ah = state.get_reg ( X86_REG_AH, 1 );
	uint8_t ah_val = static_cast< uint8_t >( ah );
	auto& flags = state.cpu->cpu_flags.flags;
	flags.SF = ( ( ah_val >> 7 ) & 1 );
	flags.ZF = ( ( ah_val >> 6 ) & 1 );
	flags.AF = ( ( ah_val >> 4 ) & 1 );
	flags.PF = ( ( ah_val >> 2 ) & 1 );
	flags.CF = ( ah_val & 1 );
	effect.push_to_changes ( state, std::format ( "Flags updated from AH: {:x}h", ah_val ) );
}

void lahf ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	auto& flags = state.cpu->cpu_flags.flags;
	uint8_t ah_val = static_cast< uint8_t >( ( flags.SF << 7 ) | ( flags.ZF << 6 ) |
		( flags.AF << 4 ) | ( flags.PF << 2 ) |
		( flags.CF ) );
	state.set_reg ( X86_REG_AH, ah_val, 1, effect );
}

void movsxd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t dst_size = ops [ 0 ].size;
	uint8_t src_size = ops [ 1 ].size;
	auto dst = ops [ 0 ].reg;
	auto src = helpers::get_src<uint64_t> ( &instr, 1, state, src_size );
	uint64_t val = static_cast< int32_t >( src );
	state.set_reg ( dst, val, dst_size, effect );
}

void xchg ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	auto val1 = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	x86_reg reg1 = ( ops [ 0 ].type == X86_OP_REG ) ? ops [ 0 ].reg : X86_REG_INVALID;
	int64_t addr1 = ( ops [ 0 ].type == X86_OP_MEM ) ?
		state.get_reg ( ops [ 0 ].mem.base ) + ops [ 0 ].mem.disp : 0;

	auto val2 = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	x86_reg reg2 = ( ops [ 1 ].type == X86_OP_REG ) ? ops [ 1 ].reg : X86_REG_INVALID;
	int64_t addr2 = ( ops [ 1 ].type == X86_OP_MEM ) ?
		state.get_reg ( ops [ 1 ].mem.base ) + ops [ 1 ].mem.disp : 0;

	if ( ops [ 0 ].type == X86_OP_REG && ops [ 1 ].type == X86_OP_REG ) {
		state.set_reg ( reg1, val2, op_size, effect );
		state.set_reg ( reg2, val1, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM && ops [ 1 ].type == X86_OP_REG ) {
		state.set_memory ( addr1, val2, 8, effect );
		state.set_reg ( reg2, val1, op_size, effect );
		effect.push_to_changes ( state, std::format ( "[{:016x}h] = {:#x}", addr1, val2 ) );
		effect.modified_mem.insert ( addr1 );
	}
	else if ( ops [ 0 ].type == X86_OP_REG && ops [ 1 ].type == X86_OP_MEM ) {
		state.set_reg ( reg1, val2, op_size, effect );
		state.set_memory ( addr2, val1, 8, effect );
		effect.push_to_changes ( state, std::format ( "[{:016x}h] = {:#x}", addr2, val1 ) );
		effect.modified_mem.insert ( addr2 );
	}
}

void pushfq ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	// allocate 8 bytes
	state.allocate_stack ( 8, effect );

	uint64_t addr = state.get_reg ( X86_REG_RSP );
	uint64_t rflags = state.get_rflags ( );
	state.set_stack ( addr, rflags, effect );
	effect.modified_mem.insert ( addr );
}

void popfq ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	int64_t stack_addr = state.get_reg ( X86_REG_RSP );
	auto val = state.get_stack ( stack_addr );
	state.cpu->rsp_offset += 8;
	state.set_reg ( X86_REG_RSP, ( uint64_t ) state.rsp_base.get ( ) + state.cpu->rsp_offset, 8, effect );

	state.set_rflags ( val, effect );
}

//void movsb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
//	bool is_rep = instr.is_rep ( );
//	auto rcx = state.get_reg ( X86_REG_RCX, 8 );
//	auto rsi = state.get_reg ( X86_REG_RSI, 8 );
//	auto rdi = state.get_reg ( X86_REG_RDI, 8 );
//	bool df = state.cpu->cpu_flags.flags.DF & 0; // Direction flag: 0 = increment, 1 = decrement
//
//	int64_t count = is_rep ? rcx : 1; // REP uses RCX, non-REP moves 1 byte
//	int64_t src_addr = rsi;
//	int64_t dst_addr = rdi;
//	int64_t step = df ? -1 : 1; // Step size based on DF
//
//	if ( count < 0 ) {
//		effect.push_to_changes ( state, std::format ( "Invalid RCX count for REP MOVSB: {:x}h", count ) );
//		return;
//	}
//
//	for ( int64_t i = 0; i < count; ++i ) {
//		uint8_t byte = state.get_memory ( src_addr + i * step, 1 );
//
//		state.set_memory ( dst_addr + i * step, byte, 8, effect );
//		effect.modified_mem.insert ( dst_addr + i * step );
//	}
//
//	// Update registers
//	uint64_t new_rsi = src_addr + count * step;
//	uint64_t new_rdi = dst_addr + count * step;
//	state.set_reg ( X86_REG_RSI, new_rsi, 8, effect );
//	state.set_reg ( X86_REG_RDI, new_rdi, 8, effect );
//	if ( is_rep ) {
//		state.set_reg ( X86_REG_RCX, 0, 8, effect );
//	} // Non-REP doesn't affect RCX
//
//	// Log changes
//	effect.push_to_changes ( state, std::format ( "Moved {} byte(s) from [{:016x}h] to [{:016x}h]", count, src_addr, dst_addr ) );
//	effect.push_to_changes ( state, std::format ( "RSI: {:016x}h -> {:016x}h", src_addr, new_rsi ) );
//	effect.push_to_changes ( state, std::format ( "RDI: {:016x}h -> {:016x}h", dst_addr, new_rdi ) );
//	if ( is_rep ) {
//		effect.push_to_changes ( state, std::format ( "RCX: {:016x}h -> 0h", count ) );
//	}
//}



void movups ( capstone::Instruction& instr,
						EmulationContext& ctx,
						InstructionEffect& eff ) {
	auto ops = instr.operands ( );
	const auto& dst = ops [ 0 ];
	const auto& src = ops [ 1 ];

	if ( dst.type == X86_OP_REG && src.type == X86_OP_REG ) {
		ctx.set_xmm_raw ( dst.reg, ctx.get_xmm_raw ( src.reg ), eff );
		eff.push_to_changes ( ctx,
			std::format ( "XMM{}=XMM{}", dst.reg - X86_REG_XMM0, src.reg - X86_REG_XMM0 ) );
		return;
	}

	if ( dst.type == X86_OP_REG && src.type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( src, instr, ctx );
		auto val = ctx.get_memory_128 ( addr );
		ctx.set_xmm_raw ( dst.reg, val, eff );
		eff.push_to_changes ( ctx,
			std::format ( "XMM{}=[0x{:016x}]", dst.reg - X86_REG_XMM0, addr ) );
		eff.modified_mem.insert ( addr );
		return;
	}

	if ( dst.type == X86_OP_MEM && src.type == X86_OP_REG ) {
		uint64_t addr = helpers::calculate_mem_addr ( dst, instr, ctx );
		auto val = ctx.get_xmm_raw ( src.reg );
		if ( ctx.is_within_stack_bounds ( addr, 16 ) )
			ctx.set_stack_128 ( addr, val, eff );
		else
			ctx.set_memory_128 ( addr, val, eff );
		eff.push_to_changes ( ctx,
			std::format ( "[0x{:016x}]=XMM{}", addr, src.reg - X86_REG_XMM0 ) );
		eff.modified_mem.insert ( addr );
		return;
	}

	std::println ( "MOVUPS: unsupported at 0x{:x}", instr.ip ( ) );
}

void movq ( capstone::Instruction& instr,
					EmulationContext& ctx,
					InstructionEffect& eff ) {
	const cs_x86_op* op = instr.operands ( );
	const cs_x86_op& dst = op [ 0 ];
	const cs_x86_op& src = op [ 1 ];

	constexpr uint8_t OP_SIZE = 8;

	if ( dst.type == X86_OP_REG && src.type == X86_OP_REG &&
			dst.reg >= X86_REG_XMM0 && dst.reg <= X86_REG_XMM15 &&
			src.reg >= X86_REG_XMM0 && src.reg <= X86_REG_XMM15 ) {
		uint64_t lo64 = ctx.get_xmm_raw ( src.reg ).convert_to<uint64_t> ( );
		ctx.set_xmm_raw ( dst.reg, lo64, eff );
		eff.push_to_changes ( ctx, std::format ( "XMM{} = XMM{} (64?bit)",
													dst.reg - X86_REG_XMM0,
													src.reg - X86_REG_XMM0 ) );
		return;
	}

	if ( dst.type == X86_OP_REG && src.type == X86_OP_REG &&
			dst.reg >= X86_REG_RAX && dst.reg <= X86_REG_R15 &&
			src.reg >= X86_REG_XMM0 && src.reg <= X86_REG_XMM15 ) {
		uint64_t lo64 = ctx.get_xmm_raw ( src.reg ).convert_to<uint64_t> ( );
		ctx.set_reg ( dst.reg, lo64, OP_SIZE, eff );
		eff.push_to_changes ( ctx, std::format ( "{} = XMM{} (64?bit)",
													cs_reg_name ( ctx.decoder.back ( )->get_handle ( ), dst.reg ),
													src.reg - X86_REG_XMM0 ) );
		return;
	}

	if ( dst.type == X86_OP_REG && src.type == X86_OP_REG &&
			dst.reg >= X86_REG_XMM0 && dst.reg <= X86_REG_XMM15 &&
			src.reg >= X86_REG_RAX && src.reg <= X86_REG_R15 ) {
		uint64_t val = ctx.get_reg ( src.reg, OP_SIZE );
		ctx.set_xmm_raw ( dst.reg, val, eff );
		eff.push_to_changes ( ctx, std::format ( "XMM{} = {} (64?bit)",
													dst.reg - X86_REG_XMM0,
													cs_reg_name ( ctx.decoder.back ( )->get_handle ( ), src.reg ) ) );
		return;
	}

	if ( dst.type == X86_OP_REG && src.type == X86_OP_MEM &&
			dst.reg >= X86_REG_XMM0 && dst.reg <= X86_REG_XMM15 ) {
		uint64_t addr = helpers::calculate_mem_addr ( src, instr, ctx );
		uint64_t lo64 = ctx.get_memory ( addr, OP_SIZE );
		ctx.set_xmm_raw ( dst.reg, lo64, eff );
		eff.push_to_changes ( ctx, std::format ( "XMM{} = [0x{:016x}] (64?bit)",
													dst.reg - X86_REG_XMM0, addr ) );
		eff.modified_mem.insert ( addr );
		return;
	}


	if ( dst.type == X86_OP_MEM && src.type == X86_OP_REG &&
			src.reg >= X86_REG_XMM0 && src.reg <= X86_REG_XMM15 ) {
		uint64_t addr = helpers::calculate_mem_addr ( dst, instr, ctx );
		uint64_t lo64 = ctx.get_xmm_raw ( src.reg ).convert_to<uint64_t> ( );

		if ( ctx.is_within_stack_bounds ( addr, OP_SIZE ) )
			ctx.set_stack ( addr, lo64, eff, OP_SIZE );
		else
			ctx.set_memory ( addr, lo64, OP_SIZE, eff );

		eff.push_to_changes ( ctx, std::format ( "[0x{:016x}] = XMM{} (64?bit)",
													addr, src.reg - X86_REG_XMM0 ) );
		eff.modified_mem.insert ( addr );
		return;
	}

	std::println ( "MOVQ: unsupported operand combination at 0x{:016x}", instr.ip ( ) );
}

void cmpxchg ( capstone::Instruction& instr,
						 EmulationContext& state,
						 InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t          op_size = ops [ 0 ].size ? ops [ 0 ].size : 8;

	if ( op_size != 1 && op_size != 2 && op_size != 4 && op_size != 8 ) {
		effect.push_to_changes ( state,
				 std::format ( "cmpxchg: unsupported operand size {}", op_size ) );
		state.exit_due_to_critical_error = true;
		return;
	}
	const uint64_t mask = ( op_size == 8 )
		? 0xFFFFFFFFFFFFFFFFull
		: ( ( 1ull << ( op_size * 8 ) ) - 1ull );


	bool     dst_is_mem = ( ops [ 0 ].type == X86_OP_MEM );
	uint64_t dst_addr = 0;
	uint64_t dst_val = 0;

	if ( dst_is_mem ) {
		dst_addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );

		dst_val = state.is_within_stack_bounds ( dst_addr, op_size )
			? state.get_stack ( dst_addr, false )
			: state.get_memory ( dst_addr, op_size );
	}
	else {
		dst_val = state.get_reg ( ops [ 0 ].reg, op_size );
	}
	dst_val &= mask;

	uint64_t rax_full = state.get_reg ( X86_REG_RAX, 8 );
	uint64_t acc_bits = rax_full & mask;
	uint64_t src_bits = state.get_reg ( ops [ 1 ].reg, op_size ) & mask;

	bool has_lock = instr.prefix ( ) [ 0 ] == X86_PREFIX_LOCK;

	bool success = ( acc_bits == dst_val );
	auto next_zf = 0;
	if ( success ) {
		if ( dst_is_mem ) {
			if ( state.is_within_stack_bounds ( dst_addr, op_size ) )
				state.set_stack ( dst_addr, src_bits, effect, op_size );
			else
				state.set_memory ( dst_addr, src_bits, op_size, effect );

			effect.modified_mem.insert ( dst_addr );
			effect.push_to_changes ( state,
					std::format ( "[0x{:016x}] = 0x{:x} (cmpxchg ok{})",
															 dst_addr, src_bits, has_lock ? ", lock" : "" ) );
		}
		else {
			state.set_reg ( ops [ 0 ].reg, src_bits, op_size, effect );
			effect.modified_regs.insert ( ops [ 0 ].reg );
		}

		next_zf = 1;
	}
	else {
		uint64_t new_rax = ( rax_full & ~mask ) | dst_val;
		state.set_reg ( X86_REG_RAX, new_rax, 8, effect );
		effect.modified_regs.insert ( X86_REG_RAX );

		effect.push_to_changes ( state,
				std::format ( "RAX = 0x{:x} (cmpxchg fail{})",
														 dst_val, has_lock ? ", lock" : "" ) );
	}

	state.update_flags_sub ( acc_bits, dst_val, op_size, effect );
	state.cpu->cpu_flags.flags.ZF = next_zf;
}


void cmpxchg16b ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	if ( ops [ 0 ].type != X86_OP_MEM ) {
		effect.push_to_changes ( state, "CMPXCHG16B: Operand must be memory" );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );

	if ( addr % 16 != 0 ) {
		throw GuestExceptionInfo { };
	}

	uint128_t mem_val = state.get_memory_128 ( addr );

	uint64_t rax = state.get_reg ( X86_REG_RAX, 8 );
	uint64_t rdx = state.get_reg ( X86_REG_RDX, 8 );
	uint128_t rdx_rax = ( uint128_t ( rdx ) << 64 ) | rax;

	uint64_t rbx = state.get_reg ( X86_REG_RBX, 8 );
	uint64_t rcx = state.get_reg ( X86_REG_RCX, 8 );
	uint128_t rcx_rbx = ( uint128_t ( rcx ) << 64 ) | rbx;

	bool equal = ( mem_val == rdx_rax );

	bool has_lock = instr.prefix ( ) [ 0 ] == X86_PREFIX_LOCK;

	if ( equal ) {
		if ( state.is_within_stack_bounds ( addr, 16 ) ) {
			state.set_stack_128 ( addr, rcx_rbx, effect );
		}
		else {
			state.set_memory_128 ( addr, rcx_rbx, effect );
		}
		effect.modified_mem.insert ( addr );
		effect.push_to_changes ( state, std::format ( "CMPXCHG16B: Set [0x{:016x}] to RCX:RBX (success{})",
														 addr, has_lock ? ", lock" : "" ) );
	}
	else {
		uint64_t mem_low = static_cast< uint64_t >( mem_val );
		uint64_t mem_high = static_cast< uint64_t >( mem_val >> 64 );
		state.set_reg ( X86_REG_RAX, mem_low, 8, effect );
		state.set_reg ( X86_REG_RDX, mem_high, 8, effect );
		effect.push_to_changes ( state, std::format ( "CMPXCHG16B: Set RDX:RAX to [0x{:016x}] (fail{})",
														 addr, has_lock ? ", lock" : "" ) );
	}

	uint64_t old_ZF = state.cpu->cpu_flags.flags.ZF;
	state.cpu->cpu_flags.flags.ZF = equal ? 1 : 0;
	if ( old_ZF != state.cpu->cpu_flags.flags.ZF ) {
		state.log_flag_change ( effect, "ZF", old_ZF, state.cpu->cpu_flags.flags.ZF );
	}
}



void stos ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint8_t op_size = 0;
	const char* size_suffix = "";

	switch ( instr.mnemonic ( ) ) {
		case X86_INS_STOSB:
			op_size = 1;
			size_suffix = "BYTE";
			break;
		case X86_INS_STOSW:
			op_size = 2;
			size_suffix = "WORD";
			break;
		case X86_INS_STOSD:
			op_size = 4;
			size_suffix = "DWORD";
			break;
		case X86_INS_STOSQ:
			op_size = 8;
			size_suffix = "QWORD";
			break;
		default:
			effect.push_to_changes ( state, std::format ( "STOS: Unexpected instruction ID {}", instr.mnemonic ( ) ) );
			state.exit_due_to_critical_error = true;
			return;
	}

	bool is_rep = instr.is_rep ( );
	auto rdi_emu = state.get_reg ( X86_REG_RDI, 8 );
	auto rax_emu = state.get_reg ( X86_REG_RAX, 8 );
	bool df = state.cpu->cpu_flags.flags.DF != 0;
	int64_t step = df ? -static_cast< int64_t >( op_size ) : static_cast< int64_t >( op_size );

	uint64_t rdi_val = rdi_emu;
	uint64_t rax_val = rax_emu;
	int64_t count = 1;
	int64_t initial_rcx = 0;

	if ( is_rep ) {
		initial_rcx = state.get_reg ( X86_REG_RCX, 8 );
		count = initial_rcx;

		if ( count <= 0 ) {
			effect.push_to_changes ( state, std::format ( "REP STOS: RCX is 0 or negative ({}), no memory operation.", count ) );
			state.set_reg ( X86_REG_RCX, 0ULL, 8, effect );
			return;
		}
		effect.push_to_changes ( state, std::format ( "REP STOS{}: Count = {} ({:x}h)", size_suffix, count, count ) );
	}

	GET_OPERAND_MASK ( operand_mask, op_size );
	const auto masked_rax_val = rax_val & operand_mask;
	int64_t initial_rdi = rdi_val;

	for ( int64_t i = 0; i < count; ++i ) {
		int64_t current_dst_addr = rdi_val;

		state.set_memory ( current_dst_addr, masked_rax_val, op_size, effect );
		effect.modified_mem.insert ( current_dst_addr );

		rdi_val += step;
	}

	state.set_reg ( X86_REG_RDI, rdi_val, 8, effect );
	if ( is_rep ) {
		state.set_reg ( X86_REG_RCX, 0ULL, 8, effect );
		effect.push_to_changes ( state, std::format ( "Stored value 0x{:x} ({} bytes from RAX) {} times.",
														 masked_rax_val, op_size, count ) );
		effect.push_to_changes ( state, std::format ( "RDI: 0x{:016x} -> 0x{:016x}", initial_rdi, rdi_val ) );
		effect.push_to_changes ( state, std::format ( "RCX: 0x{:016x} -> 0h", initial_rcx ) );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Stored value 0x{:x} ({} bytes from RAX) to [0x{:016x}].",
														 masked_rax_val, op_size, initial_rdi ) );
		effect.push_to_changes ( state, std::format ( "RDI: 0x{:016x} -> 0x{:016x}", initial_rdi, rdi_val ) );
	}
}




static void movs_rep (
		capstone::Instruction& instr,
		EmulationContext& ctx,
		InstructionEffect& eff,
		uint8_t elemSize /* 1,2,4,8 */ ) {
	bool rep = instr.is_rep ( );
	uint64_t count = rep ? ctx.get_reg ( X86_REG_RCX, 8 ) : 1;
	if ( !count ) return;

	bool df = ( ctx.cpu->cpu_flags.flags.DF != 0 );
	int64_t step = df ? -int64_t ( elemSize ) : int64_t ( elemSize );

	uint64_t rsi = ctx.get_reg ( X86_REG_RSI, 8 );
	uint64_t rdi = ctx.get_reg ( X86_REG_RDI, 8 );

	for ( uint64_t i = 0; i < count; ++i ) {
		uint64_t src = rsi + i * step;
		uint64_t dst = rdi + i * step;
		try {
			auto val = ctx.get_memory ( src, elemSize );
			ctx.set_memory ( dst, val, elemSize, eff );
			eff.modified_mem.insert ( dst );
		}
		catch ( const GuestExceptionInfo& ) {
			break;
		}
	}

	ctx.set_reg ( X86_REG_RSI, rsi + count * step, 8, eff );
	ctx.set_reg ( X86_REG_RDI, rdi + count * step, 8, eff );
	if ( rep ) ctx.set_reg ( X86_REG_RCX, 0, 8, eff );

	if ( ctx.options.enable_logging ) {
		eff.push_to_changes ( ctx,
				std::format ( "MOVS{}  copied {} bytes  DF={}",
													elemSize == 1 ? 'B' :
													elemSize == 2 ? 'W' :
													elemSize == 4 ? 'D' : 'Q',
													elemSize * ( rep ? count : 1 ),
													df ) );
	}
}



void movsw ( capstone::Instruction& instr, EmulationContext& ctx, InstructionEffect& eff ) {
	movs_rep ( instr, ctx, eff, 2 );
}

void movsb ( capstone::Instruction& instr,
					 EmulationContext& ctx,
					 InstructionEffect& eff ) {
	movs_rep ( instr, ctx, eff, 1 );
}

void movsd ( capstone::Instruction& instr, EmulationContext& ctx, InstructionEffect& eff ) {
	movs_rep ( instr, ctx, eff, 4 );
}

void movsq ( capstone::Instruction& instr, EmulationContext& ctx, InstructionEffect& eff ) {
	movs_rep ( instr, ctx, eff, 8 );
}

void punpcklqdq ( capstone::Instruction& instr,
																EmulationContext& state,
																InstructionEffect& effect ) {



	const auto& ops = instr.operands ( );
	x86_reg dst = static_cast< x86_reg >( ops [ 0 ].reg );
	x86_reg src = static_cast< x86_reg >( ops [ 1 ].reg );

	uint128_t v1 = state.get_xmm_raw ( dst );
	uint128_t v2 = state.get_xmm_raw ( src );

	uint64_t lo1 = static_cast< uint64_t >( v1 );
	uint64_t lo2 = static_cast< uint64_t >( v2 );

	uint128_t result = ( uint128_t ( lo2 ) << 64 ) | lo1;

	state.set_xmm_raw ( dst, result, effect );

	effect.push_to_changes ( state,
			std::format ( "PUNPCKLQDQ: {} = [{:016x}, {:016x}]",
													 cs_reg_name ( state.decoder.back ( )->get_handle ( ), dst ),
													 lo1, lo2 ) );

}

void movlhps ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	if ( ops [ 0 ].type != X86_OP_REG || ops [ 1 ].type != X86_OP_REG ) {
		effect.push_to_changes ( state, "MOVLHPS: Operands must be registers" );
		return;
	}

	x86_reg dst = ops [ 0 ].reg;
	x86_reg src = ops [ 1 ].reg;

	if ( dst < X86_REG_XMM0 || dst > X86_REG_XMM15 ||
			src < X86_REG_XMM0 || src > X86_REG_XMM15 ) {
		effect.push_to_changes ( state, "MOVLHPS: Operands must be XMM registers" );
		return;
	}



	uint128_t dst_val = state.get_xmm_raw ( dst );
	uint128_t src_val = state.get_xmm_raw ( src );

	uint64_t dst_low = static_cast< uint64_t >( dst_val );
	uint64_t src_low = static_cast< uint64_t >( src_val );

	uint128_t new_dst = ( uint128_t ( src_low ) << 64 ) | dst_low;

	state.set_xmm_raw ( dst, new_dst, effect );

	csh handle = state.decoder.back ( )->get_handle ( );
	effect.push_to_changes ( state,
			std::format ( "MOVLHPS: {} high = {} low",
													 cs_reg_name ( handle, dst ),
													 cs_reg_name ( handle, src ) ) );
}

//could just like, not.
void prefetchw ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	if ( ops [ 0 ].type != X86_OP_MEM ) {
		effect.push_to_changes ( state, "PREFETCHW: Operand must be a memory address" );
		return;
	}

	uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );

	effect.push_to_changes ( state, std::format ( "PREFETCHW: Prefetch hint for write at [0x{:016x}]", addr ) );

}

void psrldq ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	if ( ops [ 0 ].type != X86_OP_REG || ops [ 1 ].type != X86_OP_IMM ) {
		effect.push_to_changes ( state, "PSRLDQ: Invalid operand types" );
		state.exit_due_to_critical_error = true;
		return;
	}

	x86_reg dst_reg = ops [ 0 ].reg;
	if ( dst_reg < X86_REG_XMM0 || dst_reg > X86_REG_XMM15 ) {
		effect.push_to_changes ( state, "PSRLDQ: Destination must be an XMM register" );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint8_t shift_amount = static_cast< uint8_t >( ops [ 1 ].imm );

	uint128_t val = state.get_xmm_raw ( dst_reg );

	if ( shift_amount > 15 ) {
		val = 0;
	}
	else {
		val = val >> ( shift_amount * 8 );
	}

	state.set_xmm_raw ( dst_reg, val, effect );

	csh handle = state.decoder.back ( )->get_handle ( );
	effect.push_to_changes ( state, std::format ( "PSRLDQ: {} >> {} bytes", cs_reg_name ( handle, dst_reg ), shift_amount ) );
}

void helpers::bind_data ( ) {
	BIND ( mov );
	BIND ( movsw );
	BIND ( movsd );
	BIND ( movsq );
	BIND ( movabs );
	BIND ( movsb );
	BIND ( movaps );
	BIND ( movups );
	BIND ( movzx );
	BIND ( push );
	BIND ( pop );
	BIND ( lea );
	BIND ( movsx );
	BIND ( sahf );
	BIND ( lahf );
	BIND ( movsxd );
	BIND ( xchg );
	BIND ( pushfq );
	BIND ( popfq );
	BIND ( movq );
	BIND ( cmpxchg );
	BIND ( cmpxchg16b );
	BIND ( stos );
	BIND ( punpcklqdq );
	BIND ( movlhps );
	BIND ( prefetchw );
	BIND ( psrldq );
}
```

`semantics/src/flags.cpp`:

```cpp
// --- START OF FILE flags.cpp ---

#include "pch.hpp"
#include <cfenv>
void EmulationContext::update_flags_add ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	const auto ua = a & mask;
	const auto ub = b & mask;
	const auto res = ( ua + ub ) & mask;

	int64_t sa = static_cast< int64_t >( a << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	int64_t sb = static_cast< int64_t >( b << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	int64_t sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;
	flags.CF = ( res < ua );
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.AF = ( ( ua & 0xF ) + ( ub & 0xF ) ) > 0xF;
	flags.SF = ( res >> ( op_size * 8 - 1 ) ) & 1;
	flags.OF = ( ( sa > 0 && sb > 0 && sres < 0 ) || ( sa < 0 && sb < 0 && sres > 0 ) );

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_adc ( uint64_t dst, uint64_t src, uint64_t carry, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	const auto udst = dst & mask;
	const auto usrc = src & mask;
	const auto ucarry = carry & 1;

	const auto temp_res = udst + usrc;
	const auto res = ( temp_res + ucarry ) & mask;

	int64_t sdst = static_cast< int64_t >( udst << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	int64_t ssrc = static_cast< int64_t >( usrc << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	int64_t sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	flags.CF = ( temp_res < udst ) || ( ( temp_res + ucarry ) < temp_res ); // Check carry out from dst+src OR from (dst+src)+carry
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.AF = ( ( ( udst & 0xF ) + ( usrc & 0xF ) ) > 0xF ) || ( ( ( temp_res & 0xF ) + ucarry ) > 0xF ); // Check carry out of bit 3
	flags.SF = ( res >> ( op_size * 8 - 1 ) ) & 1;

	// OF Check: Check sign change when it shouldn't happen
	// Overflow if (dst >= 0 && src >= 0 && res < 0) or (dst < 0 && src < 0 && res >= 0) considering carry
	bool dst_sign = ( sdst >= 0 );
	bool src_sign = ( ssrc >= 0 );
	bool res_sign = ( sres >= 0 );
	flags.OF = ( dst_sign == src_sign ) && ( dst_sign != res_sign );

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_sub ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	const auto ua = a & mask;
	const auto ub = b & mask;
	const auto res = ( ua - ub ) & mask;

	const auto sa = static_cast< int64_t >( ua << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	const auto sb = static_cast< int64_t >( ub << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	const auto sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	flags.CF = ( ua < ub );
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.AF = ( ( ( ua ^ ub ^ res ) & 0x10 ) != 0 );
	flags.SF = ( sres < 0 );
	flags.OF = ( ( sa >= 0 && sb < 0 && sres < 0 ) || ( sa < 0 && sb >= 0 && sres >= 0 ) );


	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_shl ( uint64_t val, uint64_t raw_count, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t uval = val & mask;
	uint8_t size_in_bits = op_size * 8;

	uint8_t count_limit_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t effective_count = static_cast< uint8_t >( raw_count & count_limit_mask );

	if ( raw_count == 0 ) { // Per Intel: "If the count is 0, flags are not affected."
		return;
	}

	uint64_t res = uval;
	if ( effective_count > 0 ) {
		if ( effective_count < size_in_bits ) {
			res = ( uval << effective_count ) & mask;
		}
		else {
			res = 0;
		}
	}
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	if ( effective_count == 0 ) {
		flags.CF = 0;
	}
	else if ( effective_count <= size_in_bits ) {
		flags.CF = ( uval >> ( size_in_bits - effective_count ) ) & 1;
	}
	else {
		flags.CF = 0;
	}

	flags.SF = ( res >> ( size_in_bits - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( static_cast< uint8_t >( res & 0xFF ) ) % 2 == 0;
	flags.AF = 0;

	if ( ( raw_count & 0xFF ) == 1 ) {
		flags.OF = ( ( res >> ( size_in_bits - 1 ) ) & 1 ) != flags.CF;
	}
	else {
		flags.OF = 0;
	}

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF && flags.AF == 0 && old_AF != 0 ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_sar ( uint64_t val, uint64_t raw_count, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t uval_masked = val & mask;
	uint8_t size_in_bits = op_size * 8;

	uint8_t count_limit_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t effective_count = static_cast< uint8_t >( raw_count & count_limit_mask );

	if ( raw_count == 0 ) {
		return;
	}

	int64_t sval_extended = helpers::sign_extend ( uval_masked, op_size );

	uint64_t res = uval_masked;
	if ( effective_count > 0 ) {
		if ( effective_count < size_in_bits ) {
			res = static_cast< uint64_t > ( sval_extended >> effective_count ) & mask;
		}
		else {
			if ( ( sval_extended >> ( size_in_bits - 1 ) ) & 1 ) {
				res = mask;
			}
			else {
				res = 0;
			}
		}
	}
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	if ( effective_count == 0 ) {
		flags.CF = 0;
	}
	else if ( effective_count <= size_in_bits ) {
		flags.CF = ( sval_extended >> ( effective_count - 1 ) ) & 1;
	}
	else {
		flags.CF = ( sval_extended >> ( size_in_bits - 1 ) ) & 1;
	}

	flags.OF = 0;
	flags.SF = ( res >> ( size_in_bits - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( static_cast< uint8_t >( res & 0xFF ) ) % 2 == 0;
	flags.AF = 0;

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF && flags.AF == 0 && old_AF != 0 ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_inc ( uint64_t val, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t uval = static_cast< uint64_t >( val ) & mask;
	uint64_t res = ( uval + 1 ) & mask;

	int64_t sval = static_cast< int64_t >( uval << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	int64_t sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	// OF is set if result sign is opposite operand sign, specifically for positive -> negative overflow
	flags.OF = ( sval >= 0 && sres < 0 );
	flags.SF = ( res >> ( op_size * 8 - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.AF = ( ( uval & 0xF ) + 1 ) > 0xF;
	// INC does not affect CF

	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_dec ( uint64_t val, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t uval = static_cast< uint64_t >( val ) & mask;
	uint64_t res = ( uval - 1 ) & mask;

	int64_t sval = static_cast< int64_t >( uval << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	int64_t sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	// OF is set if result sign is opposite operand sign, specifically for negative -> positive overflow
	flags.OF = ( sval < 0 && sres >= 0 );
	flags.SF = ( res >> ( op_size * 8 - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.AF = ( ( uval & 0xF ) < 1 ); // Borrow from bit 4
	// DEC does not affect CF

	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_mul ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	const auto ua = a & mask;
	const auto ub = b & mask;
	uint64_t res_low, res_high;

	uint128_t full_res_128 = uint128_t ( ua ) * uint128_t ( ub );

	// 2. Create a mask for the operand size (works for 1, 2, 4 bytes)
	//    For op_size 8, we need the full 64 bits, so use a specific mask.
	uint128_t mask_128 = 0;
	int shift_amount = op_size * 8;

	if ( op_size == 8 ) {
		mask_128 = 0xFFFFFFFFFFFFFFFFULL; // Mask for 64 bits
	}
	else {
		mask_128 = ( uint128_t ( 1 ) << shift_amount ) - 1; // Mask for op_size*8 bits
	}

	// 3. Extract the lower part using the mask
	res_low = static_cast< uint64_t >( full_res_128 & mask_128 );

	// 4. Extract the higher part by shifting down and then masking
	res_high = static_cast< uint64_t >( ( full_res_128 >> shift_amount ) & mask_128 );
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_OF = flags.OF;
	// For unsigned MUL, CF and OF are set if the upper half of the full result is non-zero
	flags.CF = ( res_high != 0 );
	flags.OF = flags.CF;

	// SF, ZF, PF, AF are undefined after MUL
	flags.SF = 0;
	flags.ZF = 0;
	flags.PF = 0;
	flags.AF = 0;

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	// Log undefined flags being cleared if needed for debugging, though not strictly necessary
	log_flag_change ( effect, "SF", 1, 0 ); // Assume old value could be 1
	log_flag_change ( effect, "ZF", 1, 0 );
	log_flag_change ( effect, "PF", 1, 0 );
	log_flag_change ( effect, "AF", 1, 0 );
}

void EmulationContext::update_flags_div ( uint64_t dividend, uint64_t divisor, uint8_t op_size, InstructionEffect& effect ) {
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_OF = flags.OF, old_SF = flags.SF, old_ZF = flags.ZF, old_AF = flags.AF, old_PF = flags.PF;

	if ( divisor == 0 ) {
		effect.push_to_changes ( "Division by zero occurred (flags undefined)" );
	}
	effect.push_to_changes ( "Flags (CF, OF, SF, ZF, AF, PF) are undefined after DIV/IDIV" );
}

void EmulationContext::update_flags_and ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t res = ( a & b ) & mask;
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_CF = flags.CF, old_OF = flags.OF;
	int64_t sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	flags.SF = sres < 0;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.CF = 0;
	flags.OF = 0;

	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
}

void EmulationContext::update_flags_or ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t res = ( a | b ) & mask;
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_CF = flags.CF, old_OF = flags.OF;
	int64_t sres = static_cast< int64_t >( res << ( 64 - op_size * 8 ) ) >> ( 64 - op_size * 8 );
	flags.SF = sres < 0;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.CF = 0;
	flags.OF = 0;

	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
}

void EmulationContext::update_flags_xor ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t res = ( a ^ b ) & mask;
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_CF = flags.CF, old_OF = flags.OF;
	flags.SF = ( res >> ( op_size * 8 - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.CF = 0;
	flags.OF = 0;
	// AF is undefined
	flags.AF = 0; // Explicitly clear

	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
}

void EmulationContext::update_flags_not ( uint64_t val, uint8_t op_size, InstructionEffect& effect ) {
	// NOT doesnt affect flags, no changes needed
}

void EmulationContext::update_flags_shr ( uint64_t val, uint64_t raw_count, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t uval = val & mask;
	uint8_t size_in_bits = op_size * 8;

	uint8_t count_limit_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t effective_count = static_cast< uint8_t >( raw_count & count_limit_mask );

	if ( raw_count == 0 ) {
		return;
	}

	uint64_t res = uval;
	if ( effective_count > 0 ) {
		if ( effective_count < size_in_bits ) {
			res = uval >> effective_count;
		}
		else {
			res = 0;
		}
	}
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_CF = flags.CF, old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_OF = flags.OF, old_AF = flags.AF;

	if ( effective_count == 0 ) {
		flags.CF = 0;
	}
	else if ( effective_count <= size_in_bits ) {
		flags.CF = ( uval >> ( effective_count - 1 ) ) & 1;
	}
	else {
		flags.CF = 0;
	}

	flags.SF = ( res >> ( size_in_bits - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( static_cast< uint8_t >( res & 0xFF ) ) % 2 == 0;
	flags.AF = 0;

	if ( ( raw_count & 0xFF ) == 1 ) {
		flags.OF = ( uval >> ( size_in_bits - 1 ) ) & 1;
	}
	else {
		flags.OF = 0;
	}

	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
	if ( old_AF != flags.AF && flags.AF == 0 && old_AF != 0 ) log_flag_change ( effect, "AF", old_AF, flags.AF );
}

void EmulationContext::update_flags_test ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect ) {
	GET_OPERAND_MASK ( mask, op_size );
	uint64_t res = ( a & b ) & mask;
	auto& flags = cpu->cpu_flags.flags;
	uint64_t old_PF = flags.PF, old_ZF = flags.ZF, old_SF = flags.SF, old_CF = flags.CF, old_OF = flags.OF;
	flags.SF = ( res >> ( op_size * 8 - 1 ) ) & 1;
	flags.ZF = ( res == 0 );
	flags.PF = std::popcount ( res & 0xFF ) % 2 == 0;
	flags.CF = 0;
	flags.OF = 0;
	// AF is undefined
	flags.AF = 0; // Explicitly clear

	if ( old_PF != flags.PF ) log_flag_change ( effect, "PF", old_PF, flags.PF );
	if ( old_ZF != flags.ZF ) log_flag_change ( effect, "ZF", old_ZF, flags.ZF );
	if ( old_SF != flags.SF ) log_flag_change ( effect, "SF", old_SF, flags.SF );
	if ( old_CF != flags.CF ) log_flag_change ( effect, "CF", old_CF, flags.CF );
	if ( old_OF != flags.OF ) log_flag_change ( effect, "OF", old_OF, flags.OF );
}

void EmulationContext::log_mxcsr_flag_change ( InstructionEffect& effect, const char* flag_name, uint32_t old_val, uint32_t new_val ) {
	if ( !options.enable_logging || old_val == new_val ) return;
	effect.push_to_changes ( std::format ( "MXCSR.{} : {} -> {}", flag_name, old_val, new_val ) );
}

template<std::floating_point T>
void EmulationContext::update_mxcsr_arithmetic ( T a, T b, T result, InstructionEffect& effect ) {
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_flags = *(uint32_t*)&mxcsr;
	mxcsr.IE = 0; mxcsr.DE = 0; mxcsr.ZE = 0; mxcsr.OE = 0; mxcsr.UE = 0; mxcsr.PE = 0; // Clear status flags

	bool is_a_denormal = std::fpclassify ( a ) == FP_SUBNORMAL;
	bool is_b_denormal = std::fpclassify ( b ) == FP_SUBNORMAL;
	bool is_result_denormal = std::fpclassify ( result ) == FP_SUBNORMAL;
	bool is_a_nan = std::isnan ( a );
	bool is_b_nan = std::isnan ( b );
	bool is_result_nan = std::isnan ( result );
	bool is_a_inf = std::isinf ( a );
	bool is_b_inf = std::isinf ( b );
	bool is_result_inf = std::isinf ( result );
	bool is_a_zero = ( a == 0.0 ); // Use 0.0 for generic float/double
	bool is_b_zero = ( b == 0.0 );
	bool is_result_zero = ( result == 0.0 );

	// --- Determine Exceptions ---
	// Invalid Operation (IE) - Needs refinement for specific ops (e.g., 0*inf, inf/inf, 0/0, sqrt(-ve))
	if ( is_a_nan || is_b_nan ) { // Basic NaN check
		// TODO: Check for SNaN specifically if possible
		mxcsr.IE = 1;
	}
	// Check for division-specific IE cases
	if constexpr ( std::is_same_v<decltype( a / b ), T> ) { // Check applies if division is the context
		if ( is_a_zero && is_b_zero ) mxcsr.IE = 1; // 0/0
		if ( is_a_inf && is_b_inf ) mxcsr.IE = 1; // inf/inf
	}
	// Check for multiplication-specific IE case
	if constexpr ( std::is_same_v<decltype( a * b ), T> ) {
		if ( ( is_a_zero && is_b_inf ) || ( is_a_inf && is_b_zero ) ) mxcsr.IE = 1; // 0 * inf
	}


	// Denormal Operand (DE) - if DAZ=0
	if ( !mxcsr.DAZ && ( is_a_denormal || is_b_denormal ) ) {
		mxcsr.DE = 1;
	}

	// Divide by Zero (ZE) - Specific to division
	if constexpr ( std::is_same_v<decltype( a / b ), T> ) {
		if ( is_b_zero && !is_a_zero && !is_a_nan ) { // x/0 where x is finite non-zero
			mxcsr.ZE = 1;
			if ( mxcsr.IE && is_a_inf ) { } // Let inf/0 be IE if IE already set
			else mxcsr.IE = 0; // ZE overrides 0/0 IE if it wasn't inf/0 etc.
		}
	}

	// Overflow (OE) - Result is Inf, but operands were finite
	if ( is_result_inf && !is_a_inf && !is_b_inf ) {
		mxcsr.OE = 1;
	}

	// Underflow (UE) - Result is tiny (zero/denormal) AND inexact
	// Inexact check is tricky without higher precision. Use fenv for approximation.
	std::feclearexcept ( FE_ALL_EXCEPT );
	volatile T dummy_result = a + b; // Re-perform op to potentially set fenv flags (example for add)
	// Replace above with the actual operation type context if possible, or pass operation type
	bool inexact = ( std::fetestexcept ( FE_INEXACT ) != 0 );
	bool underflow_occurred = ( std::fetestexcept ( FE_UNDERFLOW ) != 0 ); // Use fenv underflow

	if ( underflow_occurred ) { // Rely on fenv for underflow detection
		mxcsr.UE = 1;
		// If UE is set, PE (inexact) must also be set according to SSE rules
		inexact = true;
	}

	// Precision (PE) / Inexact
	if ( inexact ) {
		mxcsr.PE = 1;
	}
	// Handle FZ (Flush-to-Zero): If UE=1 and UM=1 and FZ=1, result becomes signed zero, PE=1.
	if ( mxcsr.UE && mxcsr.UM && mxcsr.FZ ) {
		// The handler should have already set the result register to zero if FZ active.
		mxcsr.PE = 1; // Ensure PE is set if FZ triggered by underflow
	}
	// Handle DAZ (Denormals-Are-Zero): If DAZ=1, denormal inputs are treated as zero.
	// This should ideally be handled *before* the operation in the main handler.

	if ( mxcsr.IE != ( ( old_flags >> 0 ) & 1 ) ) log_mxcsr_flag_change ( effect, "IE", ( old_flags >> 0 ) & 1, mxcsr.IE );
	if ( mxcsr.DE != ( ( old_flags >> 1 ) & 1 ) ) log_mxcsr_flag_change ( effect, "DE", ( old_flags >> 1 ) & 1, mxcsr.DE );
	if ( mxcsr.ZE != ( ( old_flags >> 2 ) & 1 ) ) log_mxcsr_flag_change ( effect, "ZE", ( old_flags >> 2 ) & 1, mxcsr.ZE );
	if ( mxcsr.OE != ( ( old_flags >> 3 ) & 1 ) ) log_mxcsr_flag_change ( effect, "OE", ( old_flags >> 3 ) & 1, mxcsr.OE );
	if ( mxcsr.UE != ( ( old_flags >> 4 ) & 1 ) ) log_mxcsr_flag_change ( effect, "UE", ( old_flags >> 4 ) & 1, mxcsr.UE );
	if ( mxcsr.PE != ( ( old_flags >> 5 ) & 1 ) ) log_mxcsr_flag_change ( effect, "PE", ( old_flags >> 5 ) & 1, mxcsr.PE );
}
// Explicit instantiations (optional but can improve compile times/visibility)
template void EmulationContext::update_mxcsr_arithmetic<float> ( float, float, float, InstructionEffect& );
template void EmulationContext::update_mxcsr_arithmetic<double> ( double, double, double, InstructionEffect& );


// --- Templated Compare Updater ---
template<std::floating_point T>
void EmulationContext::update_flags_for_compare ( T a, T b, bool is_unordered_quiet, InstructionEffect& effect ) {
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_rflags = get_eflags ( );
	uint32_t old_mxcsr_flags = *(uint32_t*)&mxcsr;

	bool is_nan_a = std::isnan ( a );
	bool is_nan_b = std::isnan ( b );
	bool unordered = is_nan_a || is_nan_b;

	// Placeholder: Check for SNaN if needed
	bool is_sNaN_a = false;
	bool is_sNaN_b = false;
	bool signal_ie = ( is_sNaN_a || is_sNaN_b );

	// Clear flags
	auto& flags = cpu->cpu_flags.flags;
	flags.ZF = 0; flags.PF = 0; flags.CF = 0; flags.OF = 0; flags.SF = 0; flags.AF = 0;
	mxcsr.IE = 0;

	if ( unordered ) {
		flags.ZF = 1;
		flags.PF = 1;
		flags.CF = 1;
		// UCOMISS/UCOMISD (is_unordered_quiet = true): IE=0 for QNaN operands. IE=1 if SNaN operand.
		// COMISS/COMISD   (is_unordered_quiet = false): IE=1 for any NaN operand (QNaN or SNaN).
		if ( signal_ie || !is_unordered_quiet ) {
			mxcsr.IE = 1;
		}
	}
	else { // Ordered compare
		flags.ZF = ( a == b );
		flags.PF = 0;
		flags.CF = ( a < b );
		// mxcsr.IE remains 0 for ordered
	}

	if ( flags.ZF != ( ( old_rflags >> 6 ) & 1 ) ) log_flag_change ( effect, "ZF", ( old_rflags >> 6 ) & 1, flags.ZF );
	if ( flags.PF != ( ( old_rflags >> 2 ) & 1 ) ) log_flag_change ( effect, "PF", ( old_rflags >> 2 ) & 1, flags.PF );
	if ( flags.CF != ( ( old_rflags >> 0 ) & 1 ) ) log_flag_change ( effect, "CF", ( old_rflags >> 0 ) & 1, flags.CF );
	if ( ( ( old_rflags >> 11 ) & 1 ) != 0 ) log_flag_change ( effect, "OF", ( old_rflags >> 11 ) & 1, 0 );
	if ( ( ( old_rflags >> 7 ) & 1 ) != 0 ) log_flag_change ( effect, "SF", ( old_rflags >> 7 ) & 1, 0 );
	if ( ( ( old_rflags >> 4 ) & 1 ) != 0 ) log_flag_change ( effect, "AF", ( old_rflags >> 4 ) & 1, 0 );
	if ( mxcsr.IE != ( ( old_mxcsr_flags >> 0 ) & 1 ) ) log_mxcsr_flag_change ( effect, "IE", ( old_mxcsr_flags >> 0 ) & 1, mxcsr.IE );
}
// Explicit instantiations
template void EmulationContext::update_flags_for_compare<float> ( float, float, bool, InstructionEffect& );
template void EmulationContext::update_flags_for_compare<double> ( double, double, bool, InstructionEffect& );

// --- Conversion Updaters ---
template<std::floating_point F, typename I>
void EmulationContext::update_mxcsr_conversion_float_to_int ( F src, I dst, bool is_truncate, InstructionEffect& effect ) {
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_flags = *(uint32_t*)&mxcsr;
	mxcsr.IE = 0; mxcsr.PE = 0; // Clear relevant status flags

	std::feclearexcept ( FE_ALL_EXCEPT );
	// Re-perform conversion concept to check flags (actual result 'dst' is passed in)
	if constexpr ( std::is_same_v<I, int32_t> ) {
		volatile int32_t temp_dst = is_truncate ? static_cast< int32_t >( src ) : static_cast< int32_t >( std::lrintf ( src ) ); // Or lrint
	}
	else { // int64_t
		volatile int64_t temp_dst = is_truncate ? static_cast< int64_t >( src ) : std::lrint ( src ); // Or lrintf
	}
	int fenv_excepts = std::fetestexcept ( FE_INVALID | FE_INEXACT );

	if ( fenv_excepts & FE_INVALID ) {
		mxcsr.IE = 1; // Set Invalid Operation (NaN, Inf, Overflow)
	}
	// Precision (Inexact) flag is set if the result was rounded (or truncated and different)
	// Note: FE_INEXACT might be set by fenv even for valid conversions if rounding occurred.
	// A more precise check compares the converted int back to the original float.
	if ( static_cast< F >( dst ) != src ) {
		mxcsr.PE = 1;
	}
	// Ensure PE is set if IE is set
	if ( mxcsr.IE ) {
		mxcsr.PE = 1;
	}


	// Log changes
	if ( mxcsr.IE != ( ( old_flags >> 0 ) & 1 ) ) log_mxcsr_flag_change ( effect, "IE", ( old_flags >> 0 ) & 1, mxcsr.IE );
	if ( mxcsr.PE != ( ( old_flags >> 5 ) & 1 ) ) log_mxcsr_flag_change ( effect, "PE", ( old_flags >> 5 ) & 1, mxcsr.PE );
}
// Explicit Instantiations
template void EmulationContext::update_mxcsr_conversion_float_to_int<float, int32_t> ( float, int32_t, bool, InstructionEffect& );
template void EmulationContext::update_mxcsr_conversion_float_to_int<float, int64_t> ( float, int64_t, bool, InstructionEffect& );
template void EmulationContext::update_mxcsr_conversion_float_to_int<double, int32_t> ( double, int32_t, bool, InstructionEffect& );
template void EmulationContext::update_mxcsr_conversion_float_to_int<double, int64_t> ( double, int64_t, bool, InstructionEffect& );


template<typename I, std::floating_point F>
void EmulationContext::update_mxcsr_conversion_int_to_float ( I src, F dst, InstructionEffect& effect ) {
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_flags = *(uint32_t*)&mxcsr;
	mxcsr.PE = 0; // Clear PE (only relevant flag)

	// Check for inexact conversion
	// Compare the float result back to the original integer
	if ( static_cast< I >( dst ) != src ) {
		mxcsr.PE = 1;
	}

	// Log change
	if ( mxcsr.PE != ( ( old_flags >> 5 ) & 1 ) ) log_mxcsr_flag_change ( effect, "PE", ( old_flags >> 5 ) & 1, mxcsr.PE );
}
// Explicit Instantiations
template void EmulationContext::update_mxcsr_conversion_int_to_float<int32_t, float> ( int32_t, float, InstructionEffect& );
template void EmulationContext::update_mxcsr_conversion_int_to_float<int64_t, float> ( int64_t, float, InstructionEffect& );
template void EmulationContext::update_mxcsr_conversion_int_to_float<int32_t, double> ( int32_t, double, InstructionEffect& );
template void EmulationContext::update_mxcsr_conversion_int_to_float<int64_t, double> ( int64_t, double, InstructionEffect& );


void EmulationContext::update_mxcsr_conversion ( float src, double dst, InstructionEffect& effect ) {
	// float -> double is always exact, no flags set typically (unless SNaN source -> IE)
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_flags = *(uint32_t*)&mxcsr;
	mxcsr.IE = 0; // Clear relevant flags
	// TODO: Check if src is SNaN -> set IE=1
	if ( mxcsr.IE != ( ( old_flags >> 0 ) & 1 ) ) log_mxcsr_flag_change ( effect, "IE", ( old_flags >> 0 ) & 1, mxcsr.IE );
}

void EmulationContext::update_mxcsr_conversion ( double src, float dst, InstructionEffect& effect ) {
	// double -> float can be inexact, overflow, underflow
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_flags = *( uint32_t* ) &mxcsr;
	mxcsr.IE = 0; mxcsr.OE = 0; mxcsr.UE = 0; mxcsr.PE = 0; // Clear relevant flags

	std::feclearexcept ( FE_ALL_EXCEPT );
	volatile float temp_dst = static_cast< float >( src ); // Re-perform conversion
	int fenv_excepts = std::fetestexcept ( FE_INVALID | FE_OVERFLOW | FE_UNDERFLOW | FE_INEXACT );

	if ( fenv_excepts & FE_INVALID ) mxcsr.IE = 1;   // NaN/Inf source?
	if ( fenv_excepts & FE_OVERFLOW ) mxcsr.OE = 1;
	if ( fenv_excepts & FE_UNDERFLOW ) mxcsr.UE = 1;
	if ( fenv_excepts & FE_INEXACT ) mxcsr.PE = 1;

	// Ensure PE is set if OE or UE occurred
	if ( mxcsr.OE || mxcsr.UE ) mxcsr.PE = 1;
	// Handle FZ (Flush-to-Zero): If UE=1 and UM=1 and FZ=1, result becomes signed zero, PE=1.
	if ( mxcsr.UE && mxcsr.UM && mxcsr.FZ ) {
		// Handler should have set result register to zero
		mxcsr.PE = 1;
	}

	// Log changes
	if ( mxcsr.IE != ( ( old_flags >> 0 ) & 1 ) ) log_mxcsr_flag_change ( effect, "IE", ( old_flags >> 0 ) & 1, mxcsr.IE );
	if ( mxcsr.OE != ( ( old_flags >> 3 ) & 1 ) ) log_mxcsr_flag_change ( effect, "OE", ( old_flags >> 3 ) & 1, mxcsr.OE );
	if ( mxcsr.UE != ( ( old_flags >> 4 ) & 1 ) ) log_mxcsr_flag_change ( effect, "UE", ( old_flags >> 4 ) & 1, mxcsr.UE );
	if ( mxcsr.PE != ( ( old_flags >> 5 ) & 1 ) ) log_mxcsr_flag_change ( effect, "PE", ( old_flags >> 5 ) & 1, mxcsr.PE );
}


// --- SQRT Updater ---
template<std::floating_point T>
void EmulationContext::update_mxcsr_sqrt ( T src, T result, InstructionEffect& effect ) {
	auto& mxcsr = cpu->cpu_flags.mxcsr;
	uint32_t old_flags = *(uint32_t*)&mxcsr;
	mxcsr.IE = 0; mxcsr.DE = 0; mxcsr.PE = 0; // Clear relevant flags

	bool is_src_denormal = std::fpclassify ( src ) == FP_SUBNORMAL;
	bool is_src_nan = std::isnan ( src );
	// TODO: Check for SNaN

	if ( is_src_nan ) {
		mxcsr.IE = 1;
	}
	else if ( src < 0.0 ) { // Domain error (sqrt of negative)
		mxcsr.IE = 1;
	}

	if ( !mxcsr.DAZ && is_src_denormal ) { // Denormal source operand
		mxcsr.DE = 1;
	}

	// Check for inexact result (only possible for denormal sqrt?)
	// float exact_res_sq = result * result;
	// if (exact_res_sq != src) mxcsr.PE = 1;

	// Log changes
	if ( mxcsr.IE != ( ( old_flags >> 0 ) & 1 ) ) log_mxcsr_flag_change ( effect, "IE", ( old_flags >> 0 ) & 1, mxcsr.IE );
	if ( mxcsr.DE != ( ( old_flags >> 1 ) & 1 ) ) log_mxcsr_flag_change ( effect, "DE", ( old_flags >> 1 ) & 1, mxcsr.DE );
	if ( mxcsr.PE != ( ( old_flags >> 5 ) & 1 ) ) log_mxcsr_flag_change ( effect, "PE", ( old_flags >> 5 ) & 1, mxcsr.PE );
}
// Explicit Instantiations
template void EmulationContext::update_mxcsr_sqrt<float> ( float, float, InstructionEffect& );
template void EmulationContext::update_mxcsr_sqrt<double> ( double, double, InstructionEffect& );
```

`semantics/src/fpu.cpp`:

```cpp
// --- START OF FILE fpu.cpp ---
#include "pch.hpp"
#include <cmath>
#include <cfenv>
#include <boost/multiprecision/cpp_bin_float.hpp>
#include <boost/math/special_functions/modf.hpp>


namespace mp = boost::multiprecision;
using float80_t = mp::number<mp::cpp_bin_float<64, mp::digit_base_2, void, std::int16_t, -16382, 16383>, mp::et_off>;

void addss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	const float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	const float a = dst_val;
	const float b = src_val;
	const float result = a + b;

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );
	state.update_mxcsr_arithmetic ( a, b, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = {} + {} = {}", reg_idx, a, b, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void subss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	float a = dst_val;
	float b = src_val;
	float result = a - b;

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );
	state.update_mxcsr_arithmetic ( a, b, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = {} - {} = {}", reg_idx, a, b, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void mulss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	float a = dst_val;
	float b = src_val;
	float result = a * b;

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;
	state.update_mxcsr_arithmetic ( a, b, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = {} * {} = {}", reg_idx, a, b, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void divss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	float a = dst_val;
	float b = src_val;
	float result = a / b;

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;
	state.update_mxcsr_arithmetic ( a, b, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = {} / {} = {}", reg_idx, a, b, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void sqrtss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	if (
		std::signbit ( src_val ) || std::isnan ( src_val )
		) {
		GuestExceptionInfo ex;
		ex.set_exception ( STATUS_FLOAT_INVALID_OPERATION, instr.ip ( ) );
		throw ex;
	}

	float a = src_val;
	float result = std::sqrtf ( a );

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;
	state.update_mxcsr_sqrt ( a, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = sqrt({}) = {}", reg_idx, a, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void sqrtsd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	double dst_val = state.get_xmm_double ( ops [ 0 ].reg );
	double src_val = helpers::get_src<double> ( &instr, 1, state, 8 );

	if ( std::signbit ( src_val ) || std::isnan ( src_val ) ) {
		GuestExceptionInfo ex;
		ex.set_exception ( STATUS_FLOAT_INVALID_OPERATION, instr.ip ( ) );
		throw ex;
	}

	double a = src_val;
	double result = std::sqrt ( a );

	state.set_xmm_double ( ops [ 0 ].reg, result, effect );;
	state.update_mxcsr_sqrt ( a, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[63:0] = sqrt({}) = {}", reg_idx, a, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}


void comiss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	float src1 = state.get_xmm_float ( ops [ 0 ].reg );
	float src2 = helpers::get_src<float> ( &instr, 1, state, 4 );

	state.update_flags_for_compare ( src1, src2, false, effect );
}

void ucomiss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	float src1 = state.get_xmm_float ( ops [ 0 ].reg );
	float src2 = helpers::get_src<float> ( &instr, 1, state, 4 );

	state.update_flags_for_compare ( src1, src2, true, effect );
}

void comisd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	double src1 = state.get_xmm_double ( ops [ 0 ].reg );
	double src2 = helpers::get_src<double> ( &instr, 1, state, 8 );

	state.update_flags_for_compare ( src1, src2, false, effect );
}

void cmpss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float op1_val = state.get_xmm_float ( ops [ 0 ].reg );
	float op2_val = helpers::get_src<float> ( &instr, 1, state, 4 );
	uint8_t predicate = ops [ 2 ].imm & 0x07;

	float a = op1_val;
	float b = op2_val;

	bool is_nan_a = std::isnan ( a );
	bool is_nan_b = std::isnan ( b );
	bool unordered = is_nan_a || is_nan_b;
	bool result = false;

	uint32_t old_mxcsr_flags = *( uint32_t* ) &state.cpu->cpu_flags.mxcsr;
	state.cpu->cpu_flags.mxcsr.IE = 0;

	bool is_sNaN_a = false;
	bool is_sNaN_b = false;
	bool signal_ie = ( is_sNaN_a || is_sNaN_b );

	switch ( predicate ) {
		case 0: if ( unordered ) { signal_ie = true; result = false; }
					else { result = ( a == b ); } break;
		case 1: if ( unordered ) { signal_ie = true; result = false; }
					else { result = ( a < b ); } break;
		case 2: if ( unordered ) { signal_ie = true; result = false; }
					else { result = ( a <= b ); } break;
		case 3: result = unordered; break;
		case 4: if ( unordered ) { result = true; }
					else { result = ( a != b ); } break;
		case 5: if ( unordered ) { result = true; }
					else { result = !( a < b ); } break;
		case 6: if ( unordered ) { result = true; }
					else { result = !( a <= b ); } break;
		case 7: result = !unordered; break;
	}

	if ( signal_ie ) {
		state.cpu->cpu_flags.mxcsr.IE = 1;
	}
	if ( state.cpu->cpu_flags.mxcsr.IE != ( ( old_mxcsr_flags >> 0 ) & 1 ) ) state.log_mxcsr_flag_change ( effect, "IE", ( old_mxcsr_flags >> 0 ) & 1, state.cpu->cpu_flags.mxcsr.IE );


	uint32_t mask = result ? 0xFFFFFFFF : 0x00000000;
	state.set_xmm_float ( ops [ 0 ].reg, std::bit_cast< float >( mask ), effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = 0x{:08x} (Pred={}, {}, {} vs {})",
													 reg_idx, mask, predicate, result ? "True" : "False", a, b ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void cvtss2si ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type != X86_OP_REG || ( ops [ 0 ].size != 4 && ops [ 0 ].size != 8 ) ) {
		effect.push_to_changes ( state, "Invalid destination for CVTSS2SI (expected 32/64-bit GP reg)" );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	uint8_t op_size = ops [ 0 ].size;
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	fesetround ( state.cpu->cpu_flags.mxcsr.RC );

	int64_t result = 0;
	bool exception = false;
	int64_t indefinite_int = ( op_size == 8 ) ? INT64_MIN : INT32_MIN;

	std::feclearexcept ( FE_ALL_EXCEPT );
	if ( op_size == 4 ) {
		result = static_cast< int64_t >( std::lrintf ( src_val ) );
	}
	else {
		result = std::lrintf ( src_val );
	}

	int fenv_excepts = std::fetestexcept ( FE_INVALID | FE_INEXACT );

	if ( ( fenv_excepts & FE_INVALID ) ||
			( op_size == 4 && ( result > INT32_MAX || result < INT32_MIN ) ) ||
			( op_size == 8 && ( src_val > ( float ) INT64_MAX || src_val < ( float ) INT64_MIN ) ) ) {
		exception = true;
		result = indefinite_int;
		state.update_mxcsr_conversion_float_to_int ( src_val, result, false, effect );
	}
	else {
		if constexpr ( std::is_same_v<decltype( result ), int32_t> ) {
			state.update_mxcsr_conversion_float_to_int ( src_val, static_cast< int32_t > ( result ), false, effect );
		}
		else {
			state.update_mxcsr_conversion_float_to_int ( src_val, result, false, effect );
		}
	}

	state.set_reg ( ops [ 0 ].reg, result, op_size, effect );
	effect.push_to_changes ( state, std::format ( "{} = 0x{:x} (from {})", cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 0 ].reg ), result & ( ( 1ULL << ( op_size * 8 ) ) - 1 ), src_val ) );
}

void cvttss2si ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type != X86_OP_REG || ( ops [ 0 ].size != 4 && ops [ 0 ].size != 8 ) ) {
		effect.push_to_changes ( state, "Invalid destination for CVTTSS2SI (expected 32/64-bit GP reg)" );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t op_size = ops [ 0 ].size;
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	int64_t result = 0;
	bool exception = false;
	int64_t indefinite_int = ( op_size == 8 ) ? INT64_MIN : INT32_MIN;

	std::feclearexcept ( FE_ALL_EXCEPT );
	if ( op_size == 4 ) {
		result = static_cast< int32_t >( src_val );
	}
	else {
		result = static_cast< int64_t >( src_val );
	}
	int fenv_excepts = std::fetestexcept ( FE_INVALID );

	if ( ( fenv_excepts & FE_INVALID ) || std::isnan ( src_val ) || std::isinf ( src_val ) ||
		 ( op_size == 4 && ( src_val >= 2147483648.0f || src_val < -2147483648.0f ) ) ||
		 ( op_size == 8 && ( src_val >= ( float ) INT64_MAX || src_val <= ( float ) INT64_MIN ) )
		) {
		exception = true;
		result = indefinite_int;
		state.update_mxcsr_conversion_float_to_int ( src_val, result, true, effect );
	}
	else {
		if constexpr ( std::is_same_v<decltype( result ), int32_t> ) {
			state.update_mxcsr_conversion_float_to_int ( src_val, static_cast< int32_t > ( result ), true, effect );
		}
		else {
			state.update_mxcsr_conversion_float_to_int ( src_val, result, true, effect );
		}
	}


	state.set_reg ( ops [ 0 ].reg, result, op_size, effect );
	effect.push_to_changes ( state, std::format ( "{} = 0x{:x} (truncated from {})", cs_reg_name ( state.decoder.back ( )->get_handle ( ), ops [ 0 ].reg ), result & ( ( 1ULL << ( op_size * 8 ) ) - 1 ), src_val ) );
}

void cvtsi2ss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type != X86_OP_REG || ops [ 0 ].reg < X86_REG_XMM0 ) {
		effect.push_to_changes ( state, "CVTSI2SS: Invalid destination (expected XMM)" );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t src_size = ( ops [ 1 ].size == 4 || ops [ 1 ].size == 8 ) ? ops [ 1 ].size : 4;
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	int64_t src_int = helpers::get_src<int64_t> ( &instr, 1, state, src_size );

	if ( src_size == 4 ) src_int = static_cast< int32_t > ( src_int );

	std::fesetround ( state.cpu->cpu_flags.mxcsr.RC );
	std::feclearexcept ( FE_ALL_EXCEPT );
	float result = static_cast< float >( src_int );
	int fenv_excepts = std::fetestexcept ( FE_INEXACT );

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;
	if ( src_size == 4 ) {
		state.update_mxcsr_conversion_int_to_float ( static_cast< int32_t >( src_int ), result, effect );
	}
	else {
		state.update_mxcsr_conversion_int_to_float ( src_int, result, effect );
	}


	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = (float)({}) = {}", reg_idx, src_int, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void cvtsi2sd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type != X86_OP_REG || ops [ 0 ].reg < X86_REG_XMM0 ) {
		effect.push_to_changes ( state, "CVTSI2SD: Invalid destination (expected XMM)" );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t src_size = ( ops [ 1 ].size == 4 || ops [ 1 ].size == 8 ) ? ops [ 1 ].size : 4;
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	int64_t src_int = helpers::get_src<int64_t> ( &instr, 1, state, src_size );

	if ( src_size == 4 ) src_int = static_cast< int32_t > ( src_int );

	double result = static_cast< double > ( src_int );

	state.set_xmm_double ( ops [ 0 ].reg, result, effect );;
	if ( src_size == 4 ) {
		state.update_mxcsr_conversion_int_to_float ( static_cast< int32_t >( src_int ), result, effect );
	}
	else {
		state.update_mxcsr_conversion_int_to_float ( src_int, result, effect );
	}

	effect.push_to_changes ( state, std::format ( "xmm{}[63:0] = (double)({}) = {}", reg_idx, src_int, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void cvtss2sd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type != X86_OP_REG || ops [ 0 ].reg < X86_REG_XMM0 ) {
		effect.push_to_changes ( state, "CVTSS2SD: Invalid destination (expected XMM)" );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	double result = static_cast< double > ( src_val );

	state.set_xmm_double ( ops [ 0 ].reg, result, effect );;
	state.update_mxcsr_conversion ( src_val, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[63:0] = (double)({}) = {}", reg_idx, src_val, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void cvtsd2ss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type != X86_OP_REG || ops [ 0 ].reg < X86_REG_XMM0 ) {
		effect.push_to_changes ( state, "CVTSD2SS: Invalid destination (expected XMM)" );
		GuestExceptionInfo ex; ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) ); throw ex;
	}
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	double src_val = helpers::get_src<double> ( &instr, 1, state, 8 );

	std::fesetround ( state.cpu->cpu_flags.mxcsr.RC );
	std::feclearexcept ( FE_ALL_EXCEPT );
	float result = static_cast< float > ( src_val );
	int fenv_excepts = std::fetestexcept ( FE_INVALID | FE_OVERFLOW | FE_UNDERFLOW | FE_INEXACT );

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;
	state.update_mxcsr_conversion ( src_val, result, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = (float)({}) = {}", reg_idx, src_val, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void minss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	float a = dst_val;
	float b = src_val;
	float result;
	bool set_ie = false;

	bool is_nan_a = std::isnan ( a );
	bool is_nan_b = std::isnan ( b );


	if ( is_nan_a || is_nan_b ) {
		result = b;

	}
	else if ( a == 0.0f && b == 0.0f ) {

		result = std::signbit ( a ) ? a : b;
	}
	else {
		result = ( a < b ) ? a : b;
	}

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;

	uint32_t old_ie = state.cpu->cpu_flags.mxcsr.IE;
	state.cpu->cpu_flags.mxcsr.IE = set_ie;
	if ( old_ie != state.cpu->cpu_flags.mxcsr.IE ) state.log_mxcsr_flag_change ( effect, "IE", old_ie, state.cpu->cpu_flags.mxcsr.IE );


	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = minss({}, {}) = {}", reg_idx, a, b, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}

void maxss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t reg_idx = ops [ 0 ].reg - X86_REG_XMM0;
	float dst_val = state.get_xmm_float ( ops [ 0 ].reg );
	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	float a = dst_val;
	float b = src_val;
	float result;
	bool set_ie = false;

	bool is_nan_a = std::isnan ( a );
	bool is_nan_b = std::isnan ( b );


	if ( is_nan_a || is_nan_b ) {
		result = b;

	}
	else if ( a == 0.0f && b == 0.0f ) {

		result = std::signbit ( b ) ? a : b;
	}
	else {
		result = ( a > b ) ? a : b;
	}

	state.set_xmm_float ( ops [ 0 ].reg, result, effect );;

	uint32_t old_ie = state.cpu->cpu_flags.mxcsr.IE;
	state.cpu->cpu_flags.mxcsr.IE = set_ie;
	if ( old_ie != state.cpu->cpu_flags.mxcsr.IE ) state.log_mxcsr_flag_change ( effect, "IE", old_ie, state.cpu->cpu_flags.mxcsr.IE );

	effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = maxss({}, {}) = {}", reg_idx, a, b, result ) );
	effect.modified_regs.insert ( ops [ 0 ].reg );
}


void andps ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint128_t dst_val = state.get_xmm_raw ( dst_reg );
	uint128_t src_val = helpers::get_src<uint128_t> ( &instr, 1, state, 16 );

	dst_val &= src_val;
	state.set_xmm_raw ( dst_reg, dst_val, effect );
	effect.push_to_changes ( state, std::format ( "xmm{} = xmm{} & src", dst_reg - X86_REG_XMM0, dst_reg - X86_REG_XMM0 ) );
	effect.modified_regs.insert ( dst_reg );
}

void orps ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint128_t dst_val = state.get_xmm_raw ( dst_reg );
	uint128_t src_val = helpers::get_src<uint128_t> ( &instr, 1, state, 16 );

	dst_val |= src_val;
	state.set_xmm_raw ( dst_reg, dst_val, effect );
	effect.push_to_changes ( state, std::format ( "xmm{} = xmm{} | src", dst_reg - X86_REG_XMM0, dst_reg - X86_REG_XMM0 ) );
	effect.modified_regs.insert ( dst_reg );
}

void xorps ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint128_t dst_val = state.get_xmm_raw ( dst_reg );
	uint128_t src_val = helpers::get_src<uint128_t> ( &instr, 1, state, 16 );


	if ( ops [ 1 ].type == X86_OP_REG && ops [ 1 ].reg == dst_reg ) {
		dst_val = uint128_t { 0 };
	}
	else {
		dst_val ^= src_val;
	}
	state.set_xmm_raw ( dst_reg, dst_val, effect );
	effect.push_to_changes ( state, std::format ( "xmm{} = xmm{} ^ src", dst_reg - X86_REG_XMM0, dst_reg - X86_REG_XMM0 ) );
	effect.modified_regs.insert ( dst_reg );
}

void roundss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {

	effect.push_to_changes ( state, "ROUNDSS handler needs implementation for rounding modes and PE flag." );
}
void rcpss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {

	effect.push_to_changes ( state, "RCPSS handler needs implementation for approximation and MXCSR flags." );
}
void rsqrtss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {

	effect.push_to_changes ( state, "RSQRTSS handler needs implementation for approximation and MXCSR flags." );
}

void movhlps ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {

	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	x86_reg src_reg = ops [ 1 ].reg;
	uint128_t dst_val = state.get_xmm_raw ( dst_reg );
	const uint128_t src_val = state.get_xmm_raw ( src_reg );

	uint64_t src_high_bits_as_u64 = static_cast< uint64_t >( src_val >> 64 );
	uint128_t new_low_part = src_high_bits_as_u64;

	uint128_t result_val = ( dst_val & ( uint128_t ( 0xFFFFFFFFFFFFFFFF ) << 64 ) ) | new_low_part;

	state.set_xmm_raw ( dst_reg, result_val, effect );

	effect.push_to_changes ( state, std::format ( "xmm{}[63:0] = xmm{}[127:64]", dst_reg - X86_REG_XMM0, src_reg - X86_REG_XMM0 ) );
	effect.modified_regs.insert ( dst_reg );
}

void unpcklps ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {

	const cs_x86_op* ops = instr.operands ( );
	x86_reg dst_reg = ops [ 0 ].reg;
	uint128_t dst_val = state.get_xmm_raw ( dst_reg );
	uint128_t src_val = helpers::get_src<uint128_t> ( &instr, 1, state, 16 );



	const uint32_t dst0 = static_cast< uint32_t >( dst_val );
	const uint32_t dst1 = static_cast< uint32_t >( dst_val >> 32 );
	const uint32_t src0 = static_cast< uint32_t >( src_val );
	const uint32_t src1 = static_cast< uint32_t >( src_val >> 32 );

	uint128_t result = 0;
	result |= static_cast< uint128_t >( dst0 );
	result |= static_cast< uint128_t >( src0 ) << 32;
	result |= static_cast< uint128_t >( dst1 ) << 64;
	result |= static_cast< uint128_t >( src1 ) << 96;

	state.set_xmm_raw ( dst_reg, result, effect );

	effect.push_to_changes ( state, "UNPCKLPS executed (interleave low)" );
	effect.modified_regs.insert ( dst_reg );
}

void movss ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	const cs_x86_op& dst_op = ops [ 0 ];
	const cs_x86_op& src_op = ops [ 1 ];

	float src_val = helpers::get_src<float> ( &instr, 1, state, 4 );

	if ( dst_op.type == X86_OP_REG && src_op.type == X86_OP_REG ) {
		if ( dst_op.reg < X86_REG_XMM0 || dst_op.reg > X86_REG_XMM31 || src_op.reg < X86_REG_XMM0 || src_op.reg > X86_REG_XMM31 ) return;
		uint8_t dst_reg_idx = dst_op.reg - X86_REG_XMM0;
		uint8_t src_reg_idx = src_op.reg - X86_REG_XMM0;

		state.set_xmm_float ( dst_op.reg, src_val, effect );
		effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = xmm{}[31:0] ({})",
														 dst_reg_idx, src_reg_idx, state.get_xmm_float ( dst_op.reg ) ) );
		effect.modified_regs.insert ( dst_op.reg );

	}
	else if ( dst_op.type == X86_OP_REG && src_op.type == X86_OP_MEM ) {
		if ( dst_op.reg < X86_REG_XMM0 || dst_op.reg > X86_REG_XMM31 ) return;
		uint8_t dst_reg_idx = dst_op.reg - X86_REG_XMM0;

		state.set_xmm_float ( dst_op.reg, src_val, effect );
		effect.push_to_changes ( state, std::format ( "xmm{}[31:0] = mem32 ({})", dst_reg_idx, src_val ) );
		effect.modified_regs.insert ( dst_op.reg );

	}
	else if ( dst_op.type == X86_OP_MEM && src_op.type == X86_OP_REG ) {
		if ( src_op.reg < X86_REG_XMM0 || src_op.reg > X86_REG_XMM31 ) return;

		int64_t addr = helpers::calculate_mem_addr ( dst_op, instr, state );
		if ( addr == 0 ) {
			effect.push_to_changes ( state, "MOVSS: Failed to compute memory address" );
			return;
		}

		uint32_t val_to_write = std::bit_cast< uint32_t >( src_val );

		if ( state.is_within_stack_bounds ( addr, 4 ) ) {
			state.set_stack ( addr, val_to_write, effect, 4 );
		}
		else {
			state.set_memory ( addr, val_to_write, 4, effect );
		}
		effect.push_to_changes ( state, std::format ( "mem32 at 0x{:x} = xmm{}[31:0] ({})",
														 addr, src_op.reg - X86_REG_XMM0, src_val ) );
		effect.modified_mem.insert ( addr );
	}
}


void mulsd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	x86_reg dst_reg = ops [ 0 ].reg;
	uint8_t reg_idx = dst_reg - X86_REG_XMM0;
	double dst_val = state.get_xmm_double ( ops [ 0 ].reg );
	double src_val = helpers::get_src<double> ( &instr, 1, state, 8 );

	double a = dst_val;
	double b = src_val;
	double result = a * b;

	state.set_xmm_double ( ops [ 0 ].reg, result, effect );;
	effect.push_to_changes ( state, std::format ( "xmm{}[63:0] = {} * {} = {}", reg_idx, a, b, result ) );

	state.update_mxcsr_arithmetic ( a, b, result, effect );

	effect.modified_regs.insert ( dst_reg );
}

void stmxcsr ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) != 1 || ops [ 0 ].type != X86_OP_MEM ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}
	if ( ops [ 0 ].size != 4 ) {
		effect.push_to_changes ( state, "STMXCSR: Invalid memory operand size (must be 4 bytes)" );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	const cs_x86_op& mem_op = ops [ 0 ];

	uint64_t dest_addr = helpers::calculate_mem_addr ( mem_op, instr, state );
	if ( dest_addr == 0 && !state.exit_due_to_critical_error ) {
		state.exit_due_to_critical_error = true;
		return;
	}

	uint32_t mxcsr_value = *( uint32_t* ) &state.cpu->cpu_flags.mxcsr;

	try {
		state.set_memory ( dest_addr, mxcsr_value, 4, effect );
	}
	catch ( const GuestExceptionInfo& mem_ex ) {
		throw mem_ex;
	}

	if ( state.options.enable_logging ) {
		effect.push_to_changes ( state, std::format ( "STMXCSR: Stored MXCSR (0x{:08X}) to [0x{:016X}]", mxcsr_value, dest_addr ) );
	}
}

void ldmxcsr ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) != 1 || ops [ 0 ].type != X86_OP_MEM ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}
	if ( ops [ 0 ].size != 4 ) {
		effect.push_to_changes ( state, "LDMXCSR: Invalid memory operand size (must be 4 bytes)" );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	const cs_x86_op& mem_op = ops [ 0 ];

	uint64_t src_addr = helpers::calculate_mem_addr ( mem_op, instr, state );
	if ( src_addr == 0 && !state.exit_due_to_critical_error ) {
		state.exit_due_to_critical_error = true;
		return;
	}

	uint32_t new_mxcsr_value = 0;
	try {
		new_mxcsr_value = static_cast< uint32_t >( state.get_memory ( src_addr, 4 ) );
	}
	catch ( const GuestExceptionInfo& mem_ex ) {
		throw mem_ex;
	}

	if ( ( new_mxcsr_value >> 16 ) != 0 ) {
		effect.push_to_changes ( state, std::format ( "LDMXCSR: Attempted to load value 0x{:08X} with reserved bits set", new_mxcsr_value ) );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}


	uint32_t old_val = *( uint32_t* ) &state.cpu->cpu_flags.mxcsr;
	*( uint32_t* ) ( &state.cpu->cpu_flags.mxcsr ) = new_mxcsr_value;

	if ( state.options.enable_logging ) {
		effect.push_to_changes ( state, std::format ( "LDMXCSR: Loaded MXCSR from [0x{:016X}], value 0x{:08X} -> 0x{:08X}", src_addr, old_val, new_mxcsr_value ) );
	}
}

void fld ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	float80_t value_to_load;
	bool is_sti = false;
	uint16_t determined_fsw_flags = 0;

	int next_top = ( state.cpu->fpu.fpu_top - 1 + 8 ) % 8;
	int st7_phys_idx = ( next_top + 7 ) % 8;
	if ( state.get_fpu_tag ( st7_phys_idx ) != FPU_TAG_EMPTY ) {
		determined_fsw_flags |= ( FSW_IE | FSW_SF | FSW_C1 );
		state.check_fpu_exception ( determined_fsw_flags );
		effect.push_to_changes ( state, "FLD: FPU Stack Overflow (#IS)" );
		return;
	}

	try {
		if ( ops [ 0 ].type == X86_OP_MEM ) {
			uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
			if ( addr == 0 && !state.exit_due_to_critical_error ) {
				state.exit_due_to_critical_error = true;
				return;
			}
			switch ( op_size ) {
				case 4:
					value_to_load = helpers::get_operand_value<float> ( instr, 0, state, effect );
					break;
				case 8:
					value_to_load = helpers::get_operand_value<double> ( instr, 0, state, effect );
					break;
				case 10:
					value_to_load = state.read_float80_from_memory ( addr, effect );
					break;
				default:
					effect.push_to_changes ( state, std::format ( "FLD: Unsupported memory operand size {}", op_size ) );
					throw std::runtime_error ( "Invalid FLD size" );
			}

			if ( state.classify_fpu_operand ( value_to_load ) == FPU_TAG_SPECIAL ) {
				if ( boost::multiprecision::fpclassify ( value_to_load ) == FP_SUBNORMAL ) {
					determined_fsw_flags |= FSW_DE;
				}
				else if ( boost::multiprecision::isnan ( value_to_load ) ) {
					determined_fsw_flags |= FSW_IE;
				}
			}

		}
		else if ( ops [ 0 ].type == X86_OP_REG && ops [ 0 ].reg >= X86_REG_ST0 && ops [ 0 ].reg <= X86_REG_ST7 ) {
			is_sti = true;
			int src_sti = ops [ 0 ].reg - X86_REG_ST0;
			int src_phys_idx = state.get_fpu_phys_idx ( src_sti );
			if ( state.get_fpu_tag ( src_phys_idx ) == FPU_TAG_EMPTY ) {
				determined_fsw_flags |= ( FSW_IE | FSW_SF );
				state.check_fpu_exception ( determined_fsw_flags );
				effect.push_to_changes ( state, std::format ( "FLD: Source ST({}) is empty (#IS)", src_sti ) );
				return;
			}
			value_to_load = state.cpu->fpu.fpu_stack [ src_phys_idx ];
		}
		else {
			effect.push_to_changes ( state, "FLD: Invalid operand type." );
			throw std::runtime_error ( "Invalid FLD operand" );
		}
	}
	catch ( const GuestExceptionInfo& e ) { UNREFERENCED_PARAMETER ( e ); throw; }
	catch ( const std::exception& e ) {
		effect.push_to_changes ( state, std::format ( "FLD: Error getting operand: {}", e.what ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}


	if ( state.exit_due_to_critical_error ) return;

	state.cpu->fpu.fpu_top = next_top;
	state.cpu->fpu.fpu_stack [ state.cpu->fpu.fpu_top ] = value_to_load;

	state.cpu->fpu.fpu_status_word &= ~FSW_C1;
	state.update_fsw_top ( );
	uint8_t new_tag = state.classify_fpu_operand ( value_to_load );
	state.set_fpu_tag ( state.cpu->fpu.fpu_top, new_tag );

	state.check_fpu_exception ( determined_fsw_flags );

	if ( state.options.enable_logging ) {
		double log_val = value_to_load.convert_to<double> ( );
		if ( is_sti ) {
			effect.push_to_changes ( state, std::format ( "FLD ST({}), ApproxValue: {}, NewTop: {}", ops [ 0 ].reg - X86_REG_ST0, log_val, state.cpu->fpu.fpu_top ) );
		}
		else {
			effect.push_to_changes ( state, std::format ( "FLD mem{}, ApproxValue: {}, NewTop: {}", op_size * 8, log_val, state.cpu->fpu.fpu_top ) );
		}
	}
	effect.modified_regs.insert ( X86_REG_ST0 );
}

void fprem ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint16_t determined_fsw_flags = 0;

	int st0_phys_idx = state.cpu->fpu.fpu_top;
	int st1_phys_idx = ( state.cpu->fpu.fpu_top + 1 ) % 8;
	if ( state.get_fpu_tag ( st0_phys_idx ) == FPU_TAG_EMPTY ||
			state.get_fpu_tag ( st1_phys_idx ) == FPU_TAG_EMPTY ) {
		determined_fsw_flags |= ( FSW_IE | FSW_SF | FSW_C2 );
		state.check_fpu_exception ( determined_fsw_flags );
		effect.push_to_changes ( state, "FPREM: Stack Underflow (#IS)" );
		return;
	}

	float80_t st0_val = state.cpu->fpu.fpu_stack [ st0_phys_idx ];
	float80_t st1_val = state.cpu->fpu.fpu_stack [ st1_phys_idx ];
	float80_t result;

	bool is_st0_denormal = ( boost::multiprecision::fpclassify ( st0_val ) == FP_SUBNORMAL );
	bool is_st1_denormal = ( boost::multiprecision::fpclassify ( st1_val ) == FP_SUBNORMAL );
	if ( is_st0_denormal || is_st1_denormal ) {
		determined_fsw_flags |= FSW_DE;
	}
	if ( boost::multiprecision::isnan ( st0_val ) || boost::multiprecision::isnan ( st1_val ) ||
			boost::multiprecision::isinf ( st0_val ) || boost::multiprecision::isinf ( st1_val ) ||
			st1_val == 0 ) {
		determined_fsw_flags |= FSW_IE;
		state.cpu->fpu.fpu_status_word |= FSW_C2;
		state.check_fpu_exception ( determined_fsw_flags );
		effect.push_to_changes ( state, "FPREM: Invalid operand (NaN, Inf, Zero Divisor) (#IE)" );
		return;
	}

	result = boost::math::modf ( st0_val, &st1_val );
	if ( result == 0.0 && st0_val != 0.0 ) {
		result = st0_val;
	}

	bool is_result_denormal = ( boost::multiprecision::fpclassify ( result ) == FP_SUBNORMAL );
	if ( result != 0 && is_result_denormal ) {
		determined_fsw_flags |= FSW_UE;
		determined_fsw_flags |= FSW_DE;
	}

	int exp0 = st0_val.backend ( ).exponent ( );
	int exp1 = st1_val.backend ( ).exponent ( );

	if ( exp0 - exp1 >= 64 ) {
		state.cpu->fpu.fpu_status_word |= FSW_C2;
		state.cpu->fpu.fpu_status_word &= ~( FSW_C0 | FSW_C1 | FSW_C3 );
	}
	else {
		state.cpu->fpu.fpu_status_word &= ~FSW_C2;
		state.cpu->fpu.fpu_status_word &= ~( FSW_C0 | FSW_C1 | FSW_C3 );
	}


	state.cpu->fpu.fpu_stack [ st0_phys_idx ] = result;
	state.set_fpu_tag ( st0_phys_idx, state.classify_fpu_operand ( result ) );
	state.check_fpu_exception ( determined_fsw_flags );

	if ( state.options.enable_logging ) {
		double log_st0 = st0_val.convert_to<double> ( );
		double log_st1 = st1_val.convert_to<double> ( );
		double log_res = result.convert_to<double> ( );
		effect.push_to_changes ( state, std::format ( "FPREM ST(0)={}, ST(1)={}, Result ST(0)={}, FSW=0x{:04x}", log_st0, log_st1, log_res, state.cpu->fpu.fpu_status_word ) );
	}
	effect.modified_regs.insert ( X86_REG_ST0 );
}

void fstp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	bool is_sti = false;
	uint16_t determined_fsw_flags = 0;

	int st0_phys_idx = state.cpu->fpu.fpu_top;
	if ( state.get_fpu_tag ( st0_phys_idx ) == FPU_TAG_EMPTY ) {
		determined_fsw_flags |= ( FSW_IE | FSW_SF | FSW_C1 );
		state.check_fpu_exception ( determined_fsw_flags );
		effect.push_to_changes ( state, "FSTP: FPU Stack Empty (#IS)" );
		return;
	}

	float80_t value_to_store = state.cpu->fpu.fpu_stack [ st0_phys_idx ];

	if ( boost::multiprecision::isnan ( value_to_store ) ) determined_fsw_flags |= FSW_IE;
	if ( boost::multiprecision::fpclassify ( value_to_store ) == FP_SUBNORMAL ) determined_fsw_flags |= FSW_DE;

	int original_round_mode = std::fegetround ( );
	std::fesetround ( state.get_std_rounding_mode ( ) );

	try {
		if ( ops [ 0 ].type == X86_OP_MEM ) {
			uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
			if ( addr == 0 && !state.exit_due_to_critical_error ) {
				state.exit_due_to_critical_error = true;
				std::fesetround ( original_round_mode );
				return;
			}
			switch ( op_size ) {
				case 4:
				{
					float f_res = value_to_store.convert_to<float> ( );
					helpers::set_dst_value<uint32_t> ( instr, 0, std::bit_cast< uint32_t >( f_res ), state, effect );
					float80_t check_back = f_res;
					if ( f_res != 0 && value_to_store != 0 && check_back == 0 ) determined_fsw_flags |= FSW_UE;
					if ( !boost::multiprecision::isinf ( check_back ) && boost::multiprecision::isinf ( value_to_store ) ) determined_fsw_flags |= FSW_OE;
					if ( check_back != value_to_store ) determined_fsw_flags |= FSW_PE;
				}
				break;
				case 8:
				{
					double d_res = value_to_store.convert_to<double> ( );
					helpers::set_dst_value<uint64_t> ( instr, 0, std::bit_cast< uint64_t >( d_res ), state, effect );
					float80_t check_back = d_res;
					if ( d_res != 0 && value_to_store != 0 && check_back == 0 ) determined_fsw_flags |= FSW_UE;
					if ( !boost::multiprecision::isinf ( check_back ) && boost::multiprecision::isinf ( value_to_store ) ) determined_fsw_flags |= FSW_OE;
					if ( check_back != value_to_store ) determined_fsw_flags |= FSW_PE;
				}
				break;
				case 10:
				{
					state.write_float80_to_memory ( addr, value_to_store, effect );
				}
				break;
				default:
					effect.push_to_changes ( state, std::format ( "FSTP: Unsupported memory operand size {}", op_size ) );
					std::fesetround ( original_round_mode );
					throw std::runtime_error ( "Invalid FSTP size" );
			}
		}
		else if ( ops [ 0 ].type == X86_OP_REG && ops [ 0 ].reg >= X86_REG_ST0 && ops [ 0 ].reg <= X86_REG_ST7 ) {
			is_sti = true;
			int dst_sti = ops [ 0 ].reg - X86_REG_ST0;
			int dst_phys_idx = state.get_fpu_phys_idx ( dst_sti );
			state.cpu->fpu.fpu_stack [ dst_phys_idx ] = value_to_store;
			state.set_fpu_tag ( dst_phys_idx, state.classify_fpu_operand ( value_to_store ) );
			effect.modified_regs.insert ( ops [ 0 ].reg );
		}
		else {
			effect.push_to_changes ( state, "FSTP: Invalid destination operand type." );
			std::fesetround ( original_round_mode );
			throw std::runtime_error ( "Invalid FSTP operand" );
		}
	}
	catch ( const GuestExceptionInfo& e ) {
		std::fesetround ( original_round_mode );
		throw e;
	}
	catch ( const std::exception& e ) {
		std::fesetround ( original_round_mode );
		effect.push_to_changes ( state, std::format ( "FSTP: Error during store: {}", e.what ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}
	catch ( ... ) {
		std::fesetround ( original_round_mode );
		throw;
	}

	std::fesetround ( original_round_mode );

	if ( state.exit_due_to_critical_error ) return;

	state.cpu->fpu.fpu_status_word &= ~FSW_C1;
	if ( determined_fsw_flags & ( FSW_UE | FSW_OE ) ) {
		state.cpu->fpu.fpu_status_word |= FSW_C1;
	}
	state.check_fpu_exception ( determined_fsw_flags );

	state.set_fpu_tag ( st0_phys_idx, FPU_TAG_EMPTY );
	state.cpu->fpu.fpu_top = ( state.cpu->fpu.fpu_top + 1 ) % 8;
	state.update_fsw_top ( );


	if ( state.options.enable_logging ) {
		double log_val = value_to_store.convert_to<double> ( );
		if ( is_sti ) {
			effect.push_to_changes ( state, std::format ( "FSTP ST({}), ApproxValue: {}, NewTop: {}", ops [ 0 ].reg - X86_REG_ST0, log_val, state.cpu->fpu.fpu_top ) );
		}
		else {
			effect.push_to_changes ( state, std::format ( "FSTP mem{}, ApproxValue: {}, NewTop: {}", op_size * 8, log_val, state.cpu->fpu.fpu_top ) );
		}
	}
	effect.modified_regs.insert ( X86_REG_ST0 );
}

void ffree ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( ops [ 0 ].type == X86_OP_REG && ops [ 0 ].reg >= X86_REG_ST0 && ops [ 0 ].reg <= X86_REG_ST7 ) {
		int sti_to_free = ops [ 0 ].reg - X86_REG_ST0;
		int phys_idx = state.get_fpu_phys_idx ( sti_to_free );
		state.set_fpu_tag ( phys_idx, FPU_TAG_EMPTY );
		if ( state.options.enable_logging ) {
			effect.push_to_changes ( state, std::format ( "FFREE ST({}) (Phys Idx {})", sti_to_free, phys_idx ) );
		}
		effect.modified_regs.insert ( ops [ 0 ].reg );
	}
	else {
		effect.push_to_changes ( state, "FFREE: Invalid operand." );

	}
}

void fincstp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	state.cpu->fpu.fpu_top = ( state.cpu->fpu.fpu_top + 1 ) % 8;
	state.cpu->fpu.fpu_status_word &= ~FSW_C1;
	state.update_fsw_top ( );
	if ( state.options.enable_logging ) {
		effect.push_to_changes ( state, std::format ( "FINCSTP, New Top: {}", state.cpu->fpu.fpu_top ) );
	}
	effect.modified_regs.insert ( X86_REG_ST0 );
}

void fmul ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	auto op_count = instr.operand_count ( );
	uint16_t determined_fsw_flags = 0;
	bool pop_stack = ( instr.mnemonic ( ) == X86_INS_FMULP ); // Use ID for checking popping variant

	int st0_phys_idx = state.cpu->fpu.fpu_top;
	float80_t operand1, operand2, result;
	int destination_phys_idx = st0_phys_idx;
	int destination_sti = 0;

	try {
		if ( op_count == 0 ) {
			pop_stack = true;
			int st1_phys_idx = state.get_fpu_phys_idx ( 1 );
			destination_phys_idx = st1_phys_idx;
			destination_sti = 1;

			if ( state.get_fpu_tag ( st0_phys_idx ) == FPU_TAG_EMPTY ||
					state.get_fpu_tag ( st1_phys_idx ) == FPU_TAG_EMPTY ) {
				determined_fsw_flags |= ( FSW_IE | FSW_SF );
				effect.push_to_changes ( state, "FMUL(P) implicit: Stack Underflow (#IS)" );
				goto handle_exceptions;
			}
			operand1 = state.cpu->fpu.fpu_stack [ st1_phys_idx ];
			operand2 = state.cpu->fpu.fpu_stack [ st0_phys_idx ];

		}
		else if ( op_count == 1 ) {
			destination_phys_idx = st0_phys_idx;
			destination_sti = 0;

			if ( state.get_fpu_tag ( st0_phys_idx ) == FPU_TAG_EMPTY ) {
				determined_fsw_flags |= ( FSW_IE | FSW_SF );
				effect.push_to_changes ( state, "FMUL mem: ST(0) empty (#IS)" );
				goto handle_exceptions;
			}
			operand1 = state.cpu->fpu.fpu_stack [ st0_phys_idx ];

			if ( ops [ 0 ].type == X86_OP_MEM ) {
				uint8_t op_size = ops [ 0 ].size;
				if ( op_size == 4 ) {
					operand2 = helpers::get_operand_value<float> ( instr, 0, state, effect );
				}
				else if ( op_size == 8 ) {
					operand2 = helpers::get_operand_value<double> ( instr, 0, state, effect );
				}
				else {
					effect.push_to_changes ( state, std::format ( "FMUL: Unsupported memory operand size {}", op_size ) );
					throw std::runtime_error ( "Invalid FMUL mem size" );
				}
			}
			else if ( ops [ 0 ].type == X86_OP_REG && ops [ 0 ].reg >= X86_REG_ST0 && ops [ 0 ].reg <= X86_REG_ST7 ) { // FMUL ST(i) implies FMUL ST(0), ST(i) -> ST(0)
				int sti = ops [ 0 ].reg - X86_REG_ST0;
				int sti_phys_idx = state.get_fpu_phys_idx ( sti );
				if ( state.get_fpu_tag ( sti_phys_idx ) == FPU_TAG_EMPTY ) {
					determined_fsw_flags |= ( FSW_IE | FSW_SF );
					effect.push_to_changes ( state, "FMUL ST(i): Stack Underflow (#IS)" );
					goto handle_exceptions;
				}
				operand2 = state.cpu->fpu.fpu_stack [ sti_phys_idx ];
			}
			else {
				effect.push_to_changes ( state, "FMUL: Invalid operand count/type combination." );
				throw std::runtime_error ( "Invalid FMUL form" );
			}

		}
		else if ( op_count == 2 ) {
			int sti = -1;
			if ( ops [ 0 ].type == X86_OP_REG && ops [ 0 ].reg >= X86_REG_ST0 && ops [ 0 ].reg <= X86_REG_ST7 &&
					ops [ 1 ].type == X86_OP_REG && ops [ 1 ].reg == X86_REG_ST0 ) { // FMUL ST(i), ST(0) -> ST(i)
				sti = ops [ 0 ].reg - X86_REG_ST0;
				destination_phys_idx = state.get_fpu_phys_idx ( sti );
				destination_sti = sti;
			}
			else if ( ops [ 1 ].type == X86_OP_REG && ops [ 1 ].reg >= X86_REG_ST0 && ops [ 1 ].reg <= X86_REG_ST7 &&
					ops [ 0 ].type == X86_OP_REG && ops [ 0 ].reg == X86_REG_ST0 ) { // FMUL ST(0), ST(i) -> ST(0)
				sti = ops [ 1 ].reg - X86_REG_ST0;
				destination_phys_idx = st0_phys_idx;
				destination_sti = 0;
			}
			else {
				effect.push_to_changes ( state, "FMUL: Invalid ST(i) operand combination." );
				throw std::runtime_error ( "Invalid FMUL ST(i) form" );
			}

			int sti_phys_idx = state.get_fpu_phys_idx ( sti );
			if ( state.get_fpu_tag ( st0_phys_idx ) == FPU_TAG_EMPTY ||
					state.get_fpu_tag ( sti_phys_idx ) == FPU_TAG_EMPTY ) {
				determined_fsw_flags |= ( FSW_IE | FSW_SF );
				effect.push_to_changes ( state, "FMUL ST(i): Stack Underflow (#IS)" );
				goto handle_exceptions;
			}
			operand1 = state.cpu->fpu.fpu_stack [ destination_phys_idx ];
			operand2 = ( destination_sti == 0 ) ? state.cpu->fpu.fpu_stack [ sti_phys_idx ] : state.cpu->fpu.fpu_stack [ st0_phys_idx ];
		}
		else {
			effect.push_to_changes ( state, "FMUL: Unexpected operand count." );
			throw std::runtime_error ( "Invalid FMUL operand count" );
		}

	}
	catch ( const GuestExceptionInfo& e ) { UNREFERENCED_PARAMETER ( e ); throw; }
	catch ( const std::exception& e ) {
		effect.push_to_changes ( state, std::format ( "FMUL: Error getting operand: {}", e.what ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	if ( state.exit_due_to_critical_error ) return;

	{
		using namespace boost::multiprecision;
		int class1 = fpclassify ( operand1 );
		int class2 = fpclassify ( operand2 );

		if ( class1 == FP_SUBNORMAL || class2 == FP_SUBNORMAL ) determined_fsw_flags |= FSW_DE;

		if ( class1 == FP_NAN || class2 == FP_NAN ) determined_fsw_flags |= FSW_IE;

		if ( ( class1 == FP_ZERO && class2 == FP_INFINITE ) || ( class1 == FP_INFINITE && class2 == FP_ZERO ) ) {
			determined_fsw_flags |= FSW_IE;
		}
	}

	if ( determined_fsw_flags & FSW_IE ) {
		effect.push_to_changes ( state, "FMUL: Invalid operand (NaN, 0*Inf) (#IE)" );
		goto handle_exceptions;
	}

	result = operand1 * operand2;

	{
		using namespace boost::multiprecision;
		int res_class = fpclassify ( result );

		if ( res_class == FP_INFINITE ) determined_fsw_flags |= FSW_OE;
		if ( res_class == FP_SUBNORMAL ) determined_fsw_flags |= FSW_DE;

		if ( ( res_class == FP_SUBNORMAL || res_class == FP_ZERO ) &&
				fpclassify ( operand1 ) == FP_NORMAL && fpclassify ( operand2 ) == FP_NORMAL ) {
			determined_fsw_flags |= FSW_UE;
		}

		if ( !( determined_fsw_flags & ( FSW_OE | FSW_UE ) ) && res_class != FP_ZERO ) {
			determined_fsw_flags |= FSW_PE;
		}
	}

handle_exceptions:

	state.cpu->fpu.fpu_status_word &= ~FSW_C1;

	state.check_fpu_exception ( determined_fsw_flags );

	if ( !( state.cpu->fpu.fpu_status_word & FSW_ES ) || ( determined_fsw_flags & FSW_SF ) ) {
		if ( ( determined_fsw_flags & FSW_IE ) && !( determined_fsw_flags & FSW_SF ) && ( state.cpu->fpu.fpu_control_word & FCW_IM ) ) {
			result = std::numeric_limits<float80_t>::quiet_NaN ( ); // Use standard NaN
			effect.push_to_changes ( state, "FMUL: Masked #IE, setting result to QNaN" );
		}

		if ( !( determined_fsw_flags & FSW_SF ) ) {
			state.cpu->fpu.fpu_stack [ destination_phys_idx ] = result;
			state.set_fpu_tag ( destination_phys_idx, state.classify_fpu_operand ( result ) );
			effect.modified_regs.insert ( static_cast< x86_reg >( X86_REG_ST0 + destination_sti ) );
		}
	}


	if ( pop_stack && !( state.cpu->fpu.fpu_status_word & FSW_ES ) ) {
		state.set_fpu_tag ( st0_phys_idx, FPU_TAG_EMPTY );
		state.cpu->fpu.fpu_top = ( state.cpu->fpu.fpu_top + 1 ) % 8;
		state.update_fsw_top ( );
		effect.modified_regs.insert ( X86_REG_ST0 );
	}


	if ( state.options.enable_logging ) {
		double log_op1 = operand1.convert_to<double> ( );
		double log_op2 = operand2.convert_to<double> ( );
		double log_res = result.convert_to<double> ( );
		effect.push_to_changes ( state, std::format ( "FMUL{} -> ST({}), Op1={}, Op2={}, Result={}, FSW=0x{:04x}",
														 pop_stack ? "P" : "", destination_sti, log_op1, log_op2, log_res, state.cpu->fpu.fpu_status_word ) );
	}
}


void fnstcw ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	if ( ops [ 0 ].type != X86_OP_MEM ) {
		effect.push_to_changes ( state, "FNSTCW: Operand must be a 16-bit memory location" );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );

	uint16_t control_word = state.cpu->fpu.fpu_control_word;

	if ( state.is_within_stack_bounds ( addr, 2 ) ) {
		state.set_stack ( addr, control_word, effect, 2 );
	}
	else {
		state.set_memory ( addr, control_word, 2, effect );
	}

	effect.push_to_changes ( state, std::format ( "FNSTCW: Stored FPU control word 0x{:04x} to [0x{:016x}]", control_word, addr ) );
}


void helpers::bind_fpu ( ) {
	BIND ( addss );
	BIND ( cmpss );
	BIND ( subss );
	BIND ( mulss );
	BIND ( divss );
	BIND ( sqrtss );
	BIND ( sqrtsd );
	BIND ( movss );
	BIND ( cvtss2si );
	BIND ( minss );
	BIND ( maxss );
	BIND ( comiss );
	BIND ( roundss );
	BIND ( rcpss );
	BIND ( rsqrtss );
	BIND ( ucomiss );
	BIND ( cvtsi2ss );
	BIND ( cvttss2si );
	BIND ( cvtss2sd );
	BIND ( cvtsd2ss );
	BIND ( andps );
	BIND ( orps );
	BIND ( xorps );
	BIND ( movhlps );
	BIND ( unpcklps );
	BIND ( cvtsi2sd );
	BIND ( mulsd );
	BIND ( comisd );

	BIND ( ldmxcsr );
	BIND ( stmxcsr );

	BIND ( fld );
	BIND ( fprem );
	BIND ( fstp );
	BIND ( ffree );
	BIND ( fincstp );
	BIND ( fmul );
	BIND2 ( fmulp, fmul );
	BIND ( fnstcw );
}
```

`semantics/src/frame.cpp`:

```cpp
#include "pch.hpp"

void enter ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
  const auto* ops = instr.operands ( );

  int64_t size = ops [ 0 ].imm;   
  int64_t nesting = ops [ 1 ].imm;

  if ( nesting != 0 ) {
    if ( state.options.enable_logging ) {
      effect.push_to_changes ( state,"Warning: Non-zero ENTER nesting level not fully implemented" );
    }
  }

  uint64_t current_rsp = state.get_reg ( X86_REG_RSP );
  uint64_t current_rbp = state.get_reg ( X86_REG_RBP );

  current_rsp -= 8;
  state.set_stack ( current_rsp, current_rbp, effect, 8 );
  state.stack_allocated += 8;
  effect.modified_mem.insert ( current_rsp );

  state.set_reg ( X86_REG_RBP, current_rsp , 8, effect );

  current_rsp -= size;
  state.set_reg ( X86_REG_RSP, current_rsp , 8, effect );
  state.stack_allocated += size;

  if ( nesting > 0 ) {
    int64_t nest_adjust = nesting * 8;
    current_rsp -= nest_adjust;
    state.set_reg ( X86_REG_RSP, current_rsp , 8, effect );
    state.stack_allocated += nest_adjust;
    if ( state.options.enable_logging ) {
      effect.push_to_changes ( state,std::format ( "Adjusted stack for nesting level {}: -0x{:x}", nesting, nest_adjust ) );
    }
  }

  if ( state.options.enable_logging ) {
    effect.push_to_changes ( state,std::format ( "ENTER: Allocated 8(RBP) + 0x{:x}(locals) + 0x{:x}(nesting)", size, nesting * 8 ) );
    effect.push_to_changes ( state,std::format ( "Adjusted stack allocation by +0x{:x}", 8 + size + nesting * 8 ) );
  }
}


void leave ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
  uint64_t current_rbp_emu = state.get_reg ( X86_REG_RBP );
  uint64_t current_rbp_val = current_rbp_emu;
  uint64_t current_rsp_val = state.get_reg ( X86_REG_RSP );

  int64_t frame_locals_size = current_rbp_val - current_rsp_val;
  if ( frame_locals_size < 0 ) {
    effect.push_to_changes ( state,std::format ( "LEAVE Warning: RBP (0x{:x}) is below RSP (0x{:x})", current_rbp_val, current_rsp_val ) );
    frame_locals_size = 0;
  }

  state.set_reg ( X86_REG_RSP, current_rbp_emu, 8, effect );

  uint64_t saved_rbp_val = state.get_stack ( current_rbp_val, false );
  state.set_reg ( X86_REG_RBP, saved_rbp_val, 8, effect );
  state.set_reg ( X86_REG_RSP, current_rbp_val + 8 , 8, effect );

  int64_t dealloc_size = frame_locals_size + 8;
  state.stack_allocated -= dealloc_size;
  if ( state.stack_allocated < 0 ) state.stack_allocated = 0;

  if ( state.options.enable_logging ) {
    effect.push_to_changes ( state,std::format ( "LEAVE: Deallocated frame. Adjusted stack allocation by -0x{:x}", dealloc_size ) );
  }

}

void nop ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
  effect.is_no_op = true;
}

void helpers::bind_frame ( ) {
  BIND ( enter );
  BIND ( leave );
  BIND ( nop );
}
```

`semantics/src/jcc.cpp`:

```cpp
#include "pch.hpp"

uint64_t get_target (
		capstone::Instruction& instr,
		EmulationContext& state,
		InstructionEffect& effect
) {
	const auto& ops = instr.operands ( );
	if ( instr.operand_count ( ) == 0 ) {
		effect.push_to_changes ( state, "get_target: No operands to determine target." );
		state.exit_due_to_critical_error = true;
		return 0;
	}

	const cs_x86_op& op = ops [ 0 ];
	uint64_t next_ip = instr.branch_target ( );

	if ( op.type == X86_OP_MEM ) {
		auto addr = helpers::calculate_mem_addr ( op, instr, state );

		if ( parser && parser->is_address_in_iat ( addr ) ) {
			try {
				uint64_t image_base = parser->get_image_base ( );
				uint64_t image_size = image_base + parser->pe_info_.optional_header.size_of_image;
				if ( addr >= image_base && addr < image_base + image_size ) {
					uint64_t rva = addr - image_base;
					uint64_t iat_value = *( uint64_t* ) addr;
					effect.push_to_changes (
							state,
							std::format ( "get_target: IAT[0x{:x}] -> 0x{:x}", addr, iat_value )
					);
					return iat_value;
				}
				else {
					effect.push_to_changes (
							state,
							std::format ( "get_target: IAT addr 0x{:x} out of image bounds", addr )
					);
				}
			}
			catch ( ... ) {
				effect.push_to_changes (
						state,
						std::format ( "get_target: Failed reading IAT at 0x{:x}, falling back", addr )
				);
			}
		}

		if ( state.is_within_stack_bounds ( addr, 8 ) ) {
			uint64_t val = state.get_stack ( addr, false );
			effect.push_to_changes (
					state,
					std::format ( "get_target: Stack[0x{:x}] -> 0x{:x}", addr, val )
			);
			return val;
		}

		uint64_t val = state.get_memory ( addr, 8 );
		effect.push_to_changes (
				state,
				std::format ( "get_target: Mem[0x{:x}] -> 0x{:x}", addr, val )
		);
		return val;
	}

	if ( op.type == X86_OP_REG ) {
		uint64_t val = state.get_reg ( op.reg, 8 );
		effect.push_to_changes (
				state,
				std::format (
			"get_target: Reg {} -> 0x{:x}",
			cs_reg_name ( state.decoder.back ( )->get_handle ( ), op.reg ),
			val
		)
		);
		return val;
	}

	if ( op.type == X86_OP_IMM ) {
		uint64_t val = instr.branch_target ( );
		effect.push_to_changes (
				state,
				std::format ( "get_target: Imm -> 0x{:x}", val )
		);
		return val;
	}

	if ( instr.branch_target ( ) != 0 ) {
		uint64_t val = instr.branch_target ( );
		effect.push_to_changes (
				state,
				std::format ( "get_target: branch_target() -> 0x{:x}", val )
		);
		return val;
	}

	effect.push_to_changes ( state, "get_target: Could not determine target." );
	state.exit_due_to_critical_error = true;
	return 0;
}

bool is_api_hook ( EmulationContext& state, capstone::Instruction& instr, uint64_t final_addr, InstructionEffect& effect ) {
	if ( final_addr <= state.windows->loaded_base_address || final_addr >= state.windows->loaded_base_address + state.windows->loaded_module_size ) {
		auto ait = state.windows->api_hooks.find ( final_addr );
		if ( ait == state.windows->api_hooks.end ( ) ) { // handle indirection
			ait = state.windows->api_hooks.find ( state.get_reg<uint64_t> ( X86_REG_RAX ) );
		}
		if ( ait != state.windows->api_hooks.end ( ) ) {
			effect.push_to_changes ( state,
					std::format ( "JMP hits API hook at 0x{:x}, dispatching hook inline.", final_addr ) );
			ait->second ( instr, state, effect, final_addr );

			state.decoder.back ( )->set_ip ( state.call_stack.back ( ).return_addr );
			std::ignore = state.decoder.back ( )->decode ( );
			uint64_t old_rsp = state.get_reg ( X86_REG_RSP, 8 );
			uint64_t new_rsp = old_rsp + 8;
			state.set_reg ( X86_REG_RSP, new_rsp, 8, effect );
			state.pop_call_frame ( effect );
			return true;
		}
	}
	return false;
}

void handle_jump_target (
		capstone::Instruction& instr,
		EmulationContext& state,
		InstructionEffect& effect,
		uint64_t initial_target
) {
	if ( initial_target == 0 ) {
		effect.push_to_changes ( state,
				std::format ( "JMP/Jcc ({}) Error: no target", instr.mnemonic ( ) ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t final_addr = initial_target;
	if ( is_api_hook ( state, instr, final_addr, effect ) || is_api_hook ( state, instr, state.get_reg<uint64_t> ( X86_REG_RAX ), effect ) ) { // indirect, direct
		return;
	}
	if ( parser && parser->is_address_in_iat ( initial_target ) ) {
		uint64_t image_base = parser->get_image_base ( );
		uint64_t image_size = parser->pe_info_.optional_header.size_of_image;
		if ( initial_target >= image_base && initial_target < image_base + image_size ) {
			uint64_t rva = initial_target - image_base;
			uint64_t iat_val = parser->read_qword_at_rva ( rva );
			effect.push_to_changes ( state,
					std::format ( "Resolved IAT[0x{:x}] -> 0x{:x}", initial_target, iat_val ) );
			final_addr = iat_val;
		}
		else {
			effect.push_to_changes ( state,
					std::format ( "IAT address 0x{:x} out of bounds", initial_target ) );
		}
	}

	uint64_t chosen_base = 0;
	for ( auto& [base, mod] : state.windows->loaded_modules ) {
		if ( final_addr >= base && final_addr < base + mod.size ) {
			chosen_base = base;
			break;
		}
	}
	if ( chosen_base == 0 ) {
		effect.push_to_changes ( state,
				std::format ( "JMP/Jcc ({}) target 0x{:x} not in any loaded module",
														 instr.mnemonic ( ), final_addr ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	if ( state.windows->current_module_base != chosen_base ) {
		LoadedModule& lm = state.windows->loaded_modules.at ( chosen_base );
		if ( state.decoder.back ( )->data_ != lm.decoder.get ( )->data_ ) {
			state.decoder.emplace_back ( lm.decoder.get ( ) );
		}
		state.windows->current_module_base = chosen_base;
		effect.push_to_changes ( state,
				std::format ( "Switched decoder -> module @0x{:x} (size 0x{:x})",
														 chosen_base, lm.size ) );
	}

	state.decoder.back ( )->set_ip ( final_addr );
	effect.push_to_changes ( state,
			std::format ( "JMP/Jcc ({}) -> module+{:#x}",
													 instr.mnemonic ( ), final_addr - chosen_base ) );
}



uint64_t get_initial_target ( const EmulationContext& state, const capstone::Instruction& instr ) {
	uint64_t initial_target = instr.branch_target ( );
	const auto operand = instr.operands ( ) [ 0 ];
	switch ( operand.type ) {
		case X86_OP_MEM:
			return 0;
		case X86_OP_IMM:
			return initial_target + instr.ip ( ) + instr.length ( );
		case X86_OP_REG:
			return state.get_reg<uint64_t> ( operand.reg );
		default:
			__debugbreak ( );
			return 0;
	}
}


void jmp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	handle_jump_target ( instr, state, effect, target );
}

void je ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.ZF;
	effect.push_to_changes ( state, std::format ( "JE: ZF={} -> {}", taken ? '1' : '0', taken ? "taken" : "not taken" ) );

	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jne ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.ZF;
	effect.push_to_changes ( state, std::format ( "JNE: ZF={} -> {}", taken, taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jnbe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.CF && !state.cpu->cpu_flags.flags.ZF;
	effect.push_to_changes ( state, std::format ( "JNBE: CF={} ZF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.CF,
													 ( char ) state.cpu->cpu_flags.flags.ZF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jg ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.ZF && state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF;
	effect.push_to_changes ( state, std::format ( "JG: ZF={} SF={} OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.ZF,
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.SF != state.cpu->cpu_flags.flags.OF;
	effect.push_to_changes ( state, std::format ( "JL: SF={} OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jnb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.CF;
	effect.push_to_changes ( state, std::format ( "JNB: CF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.CF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.CF;
	effect.push_to_changes ( state, std::format ( "JB: CF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.CF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jns ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.SF;
	effect.push_to_changes ( state, std::format ( "JNS: SF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jnl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF;
	effect.push_to_changes ( state, std::format ( "JNL: SF={} OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jo ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.OF;
	effect.push_to_changes ( state, std::format ( "JO: OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jno ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.OF;
	effect.push_to_changes ( state, std::format ( "JNO: OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jbe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.CF || state.cpu->cpu_flags.flags.ZF;
	effect.push_to_changes ( state, std::format ( "JBE: CF={} ZF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.CF,
													 ( char ) state.cpu->cpu_flags.flags.ZF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void js ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.SF;
	effect.push_to_changes ( state, std::format ( "JS: SF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void ja ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.CF && !state.cpu->cpu_flags.flags.ZF;
	effect.push_to_changes ( state, std::format ( "JA: CF={} ZF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.CF,
													 ( char ) state.cpu->cpu_flags.flags.ZF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jae ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.CF;
	effect.push_to_changes ( state, std::format ( "JAE: CF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.CF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jge ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF;
	effect.push_to_changes ( state, std::format ( "JGE: SF={} OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jle ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = ( state.cpu->cpu_flags.flags.ZF || state.cpu->cpu_flags.flags.SF != state.cpu->cpu_flags.flags.OF );
	effect.push_to_changes ( state, std::format ( "JLE: ZF={} SF={} OF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.ZF,
													 ( char ) state.cpu->cpu_flags.flags.SF,
													 ( char ) state.cpu->cpu_flags.flags.OF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = state.cpu->cpu_flags.flags.PF;
	effect.push_to_changes ( state, std::format ( "JP: PF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.PF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jnp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	bool taken = !state.cpu->cpu_flags.flags.PF;
	effect.push_to_changes ( state, std::format ( "JNP: PF={} -> {}",
													 ( char ) state.cpu->cpu_flags.flags.PF,
													 taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jcxz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	uint64_t cx = state.get_reg ( X86_REG_CX, 2 );
	bool taken = cx == 0;
	effect.push_to_changes ( state, std::format ( "JCXZ: CX={} -> {}", cx, taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jecxz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	uint64_t ecx = state.get_reg ( X86_REG_ECX, 4 );
	bool taken = ecx == 0;
	effect.push_to_changes ( state, std::format ( "JECXZ: ECX={} -> {}", ecx, taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void jrcxz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	uint64_t target = get_target ( instr, state, effect );
	uint64_t rcx = state.get_reg ( X86_REG_RCX, 8 );
	bool taken = rcx == 0;
	effect.push_to_changes ( state, std::format ( "JRCXZ: RCX={} -> {}", rcx, taken ? "taken" : "not taken" ) );
	if ( taken ) {
		handle_jump_target ( instr, state, effect, target );
	}
	else {
		effect.push_to_changes ( state, std::format ( "Fallthrough to 0x{:x} is invalid", instr.branch_target ( ) ) );
	}
}

void helpers::bind_jx ( ) {
	BIND ( jmp );
	BIND ( je );
	BIND ( jne );
	BIND ( jnbe );  // JA
	BIND ( jg );
	BIND ( jl );
	BIND ( jnb );   // JAE
	BIND ( jb );
	BIND ( jns );
	BIND ( jnl );   // JGE
	BIND ( jo );
	BIND ( jno );
	BIND ( jbe );
	BIND ( js );
	BIND ( ja );
	BIND ( jae );
	BIND ( jge );
	BIND ( jle );
	BIND ( jp );
	BIND ( jnp );
	BIND ( jcxz );
	BIND ( jecxz );
	BIND ( jrcxz );
}
```

`semantics/src/logical.cpp`:

```cpp
#include "pch.hpp"
void and_ ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_binary_op ( instr, state, effect,
			[ ] ( uint64_t a, uint64_t b ) { return a & b; },
			&EmulationContext::update_flags_and
	);
}

void or_ ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_binary_op ( instr, state, effect,
			[ ] ( uint64_t a, uint64_t b ) { return a | b; },
			&EmulationContext::update_flags_or
	);
}

void xor_ ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_binary_op ( instr, state, effect,
			[ ] ( uint64_t a, uint64_t b ) { return a ^ b; },
			&EmulationContext::update_flags_xor
	);
}

void not_ ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_unary_op ( instr, state, effect,
			[ ] ( uint64_t a ) { return ~a; },
			NO_FLAG_HANDLER
	);
}

void shl_sal_common ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect, bool is_sal ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	if ( op_size == 0 || ( op_size != 1 && op_size != 2 && op_size != 4 && op_size != 8 ) ) {
		effect.push_to_changes ( state, std::format ( "{}: Invalid operand size {}", is_sal ? "SAL" : "SHL", op_size ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t val_operand = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	uint64_t count_operand = helpers::get_src<uint64_t> ( &instr, 1, state, 1 ); // Count is usually CL or imm8

	if ( state.exit_due_to_critical_error ) return;

	GET_OPERAND_MASK ( operand_mask, op_size );
	uint64_t original_val_masked = val_operand & operand_mask; // Value to operate on

	uint8_t count_raw = count_operand & 0xFF;
	uint8_t size_in_bits = op_size * 8;
	uint8_t count_limit_mask = ( op_size == 8 ) ? 0x3F : 0x1F; // Or (size_in_bits -1) for some interpretations, but 31/63 is common.
	// Intel manual states "The count is masked to 5 bits (or 6 bits if in 64-bit mode and REX.W is used)."
	uint8_t effective_count = count_raw & count_limit_mask;

	uint64_t result = original_val_masked; // Initialize
	if ( effective_count > 0 && effective_count < size_in_bits ) { // Shift count > 0 and < operand size
		result = ( original_val_masked << effective_count ) & operand_mask;
	}
	else if ( effective_count >= size_in_bits ) { // If count >= operand size, result is 0 (for SHL/SAL)
		result = 0;
	}
	// If effective_count is 0, result remains original_val_masked

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, result, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( state.exit_due_to_critical_error ) return;
		state.set_memory ( addr, result, op_size, effect );
		// effect.modified_mem and push_to_changes are handled by set_memory
	}
	else {
		state.exit_due_to_critical_error = true; // Should not happen with valid Capstone decoding
		return;
	}

	state.update_flags_shl ( original_val_masked, count_raw, op_size, effect ); // Pass raw count for flag logic if it needs it for OF with count=1
}

void shl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	shl_sal_common ( instr, state, effect, false );
}

void sal ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	shl_sal_common ( instr, state, effect, true ); // SAL is an alias for SHL
}

void shr ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	if ( op_size == 0 || ( op_size != 1 && op_size != 2 && op_size != 4 && op_size != 8 ) ) {
		effect.push_to_changes ( state, std::format ( "SHR: Invalid operand size {}", op_size ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t val_operand = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	uint64_t count_operand = helpers::get_src<uint64_t> ( &instr, 1, state, 1 );

	if ( state.exit_due_to_critical_error ) return;

	GET_OPERAND_MASK ( operand_mask, op_size );
	uint64_t original_val_masked = val_operand & operand_mask; // Use this for operations and flag updates

	uint8_t count_raw = count_operand & 0xFF;
	uint8_t size_in_bits = op_size * 8;
	uint8_t count_limit_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t effective_count = count_raw & count_limit_mask;

	uint64_t result = original_val_masked; // Initialize
	if ( effective_count > 0 && effective_count < size_in_bits ) {
		result = ( original_val_masked >> effective_count ); // No further mask needed for SHR
	}
	else if ( effective_count >= size_in_bits ) { // If count >= operand size, result is 0
		result = 0;
	}
	// If effective_count is 0, result remains original_val_masked

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, result, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( state.exit_due_to_critical_error ) return;
		state.set_memory ( addr, result, op_size, effect );
	}
	else {
		state.exit_due_to_critical_error = true;
		return;
	}
	state.update_flags_shr ( original_val_masked, count_raw, op_size, effect );
}

void shld ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );

	uint8_t op_size = ops [ 0 ].size;
	uint8_t size_in_bits = op_size * 8;

	auto dest_emu = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	auto src_reg_emu = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	auto count_emu = helpers::get_src<uint64_t> ( &instr, 2, state, 1 );

	uint64_t value0 = dest_emu;     
	uint64_t value1 = src_reg_emu;  
	uint64_t pcounter = count_emu;	
	uint64_t original_dest = value0;

	uint64_t counter;
	if ( size_in_bits == 64 ) {
		counter = pcounter % 64;
	}
	else {
		counter = pcounter % 32;
		counter = pcounter % size_in_bits;
	}

	uint64_t final_result = value0; // Initialize result
	uint64_t final_cf = state.cpu->cpu_flags.flags.CF; // Default CF

	if ( counter == 0 ) {
		if ( ( pcounter & 0xFF ) == 1 ) {
			state.cpu->cpu_flags.flags.OF = 0;
			state.log_flag_change ( effect, "OF", state.cpu->cpu_flags.flags.OF, 0 );
		}
	}
	else if ( counter > size_in_bits ) {
		effect.push_to_changes ( state,"SHLD: Undefined behavior (count > size), result set to 0." );
		final_result = 0;
		state.update_flags_shl ( original_dest, 0, op_size, effect ); // Use count 0 for flags? Or set directly?
		state.cpu->cpu_flags.flags.ZF = 1; state.cpu->cpu_flags.flags.SF = 0; state.cpu->cpu_flags.flags.PF = 1; state.cpu->cpu_flags.flags.CF = 0; state.cpu->cpu_flags.flags.OF = 0; state.cpu->cpu_flags.flags.AF = 0;
		final_cf = 0; // Set CF to 0
	}
	else {
		GET_OPERAND_MASK ( operand_mask, op_size );
		uint64_t temp_result = value0 & operand_mask;

		final_cf = ( temp_result >> ( size_in_bits - counter ) ) & 1;

		for ( uint64_t i = size_in_bits - 1; i >= counter; --i ) {
			bool bit = ( temp_result >> ( i - counter ) ) & 1;
			temp_result = ( temp_result & ~( 1ULL << i ) ) | ( static_cast< uint64_t >( bit ) << i );
		}
		for ( uint64_t i = 0; i < counter; ++i ) {
			bool bit = ( value1 >> ( i + size_in_bits - counter ) ) & 1;
			temp_result = ( temp_result & ~( 1ULL << i ) ) | ( static_cast< uint64_t > ( bit ) << i );
		}
		final_result = temp_result & operand_mask;

		if ( ( pcounter & 0xFF ) == 1 ) {
			uint64_t original_msb = ( original_dest >> ( size_in_bits - 1 ) ) & 1;
			uint64_t result_msb = ( final_result >> ( size_in_bits - 1 ) ) & 1;
			state.cpu->cpu_flags.flags.OF = original_msb ^ result_msb;
		}
		else {
			state.cpu->cpu_flags.flags.OF = 0;
		}

		state.cpu->cpu_flags.flags.SF = ( final_result >> ( size_in_bits - 1 ) ) & 1;
		state.cpu->cpu_flags.flags.ZF = ( final_result == 0 );
		state.cpu->cpu_flags.flags.PF = std::popcount ( static_cast< uint8_t >( final_result & 0xFF ) ) % 2 == 0;
		state.cpu->cpu_flags.flags.AF = 0;
	}

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, final_result, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		int64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		state.set_memory ( addr, final_result, op_size, effect );
		effect.modified_mem.insert ( addr );
		effect.push_to_changes ( state,std::format ( "[{:016x}h] = {:x}h", addr, final_result ) );
	}
	else {
		return;
	}

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;
	state.cpu->cpu_flags.flags.CF = final_cf;

	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );

}

void shrd ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;
	uint8_t size_in_bits = op_size * 8;

	auto dest_emu = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	auto src_reg_emu = helpers::get_src<uint64_t> ( &instr, 1, state, op_size );
	auto count_emu = helpers::get_src<uint64_t> ( &instr, 2, state, 1 );

	uint64_t value0 = dest_emu;     
	uint64_t value1 = src_reg_emu;  
	uint64_t pcounter = count_emu;	
	uint64_t original_dest = value0;

	uint64_t counter;
	if ( size_in_bits == 64 ) {
		counter = pcounter % 64;
	}
	else {
		counter = pcounter % size_in_bits;
	}

	uint64_t final_result = value0; 
	uint64_t final_cf = state.cpu->cpu_flags.flags.CF;

	if ( counter == 0 ) {
		if ( ( pcounter & 0xFF ) == 1 ) {
			uint64_t original_msb = ( original_dest >> ( size_in_bits - 1 ) ) & 1;
			state.cpu->cpu_flags.flags.OF = original_msb;
			state.log_flag_change ( effect, "OF", state.cpu->cpu_flags.flags.OF, state.cpu->cpu_flags.flags.OF );
		}

	}
	else if ( counter >= size_in_bits ) {
		effect.push_to_changes ( state,"SHRD: Undefined behavior (count >= size), result set to 0." );
		final_result = 0;
		state.update_flags_shr ( original_dest, 0, op_size, effect );
		state.cpu->cpu_flags.flags.ZF = 1; state.cpu->cpu_flags.flags.SF = 0; state.cpu->cpu_flags.flags.PF = 1; state.cpu->cpu_flags.flags.CF = 0; state.cpu->cpu_flags.flags.OF = 0; state.cpu->cpu_flags.flags.AF = 0;
		final_cf = 0;
	}
	else {
		GET_OPERAND_MASK ( operand_mask, op_size );
		uint64_t temp_result = value0 & operand_mask;

		final_cf = ( temp_result >> ( counter - 1 ) ) & 1;

		for ( uint64_t i = 0; i <= ( size_in_bits - 1 - counter ); ++i ) {
			bool bit = ( temp_result >> ( i + counter ) ) & 1;
			temp_result = ( temp_result & ~( 1ULL << i ) ) | ( static_cast< uint64_t >( bit ) << i );
		}

		for ( uint64_t i = size_in_bits - counter; i < size_in_bits; ++i ) {
			bool bit = ( value1 >> ( i + counter - size_in_bits ) ) & 1;
			temp_result = ( temp_result & ~( 1ULL << i ) ) | ( static_cast< uint64_t > ( bit ) << i );
		}
		final_result = temp_result & operand_mask;

		if ( ( pcounter & 0xFF ) == 1 ) {
			uint64_t original_msb = ( original_dest >> ( size_in_bits - 1 ) ) & 1;
			uint64_t result_msb = ( final_result >> ( size_in_bits - 1 ) ) & 1;
			state.cpu->cpu_flags.flags.OF = original_msb ^ result_msb;
		}
		else {
			state.cpu->cpu_flags.flags.OF = 0;
		}

		state.cpu->cpu_flags.flags.SF = ( final_result >> ( size_in_bits - 1 ) ) & 1;
		state.cpu->cpu_flags.flags.ZF = ( final_result == 0 );
		state.cpu->cpu_flags.flags.PF = std::popcount ( static_cast< uint8_t >( final_result & 0xFF ) ) % 2 == 0;
	}

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, final_result, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		int64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		state.set_memory ( addr, final_result, op_size, effect );
		effect.modified_mem.insert ( addr );
		effect.push_to_changes ( state,std::format ( "[{:016x}h] = {:x}h", addr, final_result ) );
	}
	else {
		return;
	}

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;
	state.cpu->cpu_flags.flags.CF = final_cf;

	if ( old_CF != state.cpu->cpu_flags.flags.CF ) state.log_flag_change ( effect, "CF", old_CF, state.cpu->cpu_flags.flags.CF );
	if ( old_OF != state.cpu->cpu_flags.flags.OF ) state.log_flag_change ( effect, "OF", old_OF, state.cpu->cpu_flags.flags.OF );
}

void sar ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	uint8_t op_size = ops [ 0 ].size;

	if ( op_size == 0 || ( op_size != 1 && op_size != 2 && op_size != 4 && op_size != 8 ) ) {
		effect.push_to_changes ( state, std::format ( "SAR: Invalid operand size {}", op_size ) );
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t val_operand = helpers::get_src<uint64_t> ( &instr, 0, state, op_size );
	uint64_t count_operand = helpers::get_src<uint64_t> ( &instr, 1, state, 1 );

	if ( state.exit_due_to_critical_error ) return;

	GET_OPERAND_MASK ( operand_mask, op_size );
	uint64_t original_val_masked = val_operand & operand_mask; // Value as it exists in op_size

	uint8_t count_raw = count_operand & 0xFF;
	uint8_t size_in_bits = op_size * 8;
	uint8_t count_limit_mask = ( op_size == 8 ) ? 0x3F : 0x1F;
	uint8_t effective_count = count_raw & count_limit_mask;

	uint64_t result = original_val_masked; // Initialize
	if ( effective_count > 0 ) {
		// For SAR, we need to treat the original_val_masked as signed for the shift.
		// Convert to int64_t after proper sign extension from its original op_size.
		int64_t signed_val_for_shift = helpers::sign_extend ( original_val_masked, op_size );

		if ( effective_count < size_in_bits ) {
			result = ( static_cast< uint64_t > ( signed_val_for_shift >> effective_count ) ) & operand_mask;
		}
		else { // If count >= size_in_bits, result is all 0s or all 1s based on original sign bit
			if ( ( signed_val_for_shift >> ( size_in_bits - 1 ) ) & 1 ) { // Check sign bit of original op_size value
				result = operand_mask; // All 1s
			}
			else {
				result = 0; // All 0s
			}
		}
	}
	// If effective_count is 0, result remains original_val_masked

	if ( ops [ 0 ].type == X86_OP_REG ) {
		state.set_reg ( ops [ 0 ].reg, result, op_size, effect );
	}
	else if ( ops [ 0 ].type == X86_OP_MEM ) {
		uint64_t addr = helpers::calculate_mem_addr ( ops [ 0 ], instr, state );
		if ( state.exit_due_to_critical_error ) return;
		state.set_memory ( addr, result, op_size, effect );
	}
	else {
		state.exit_due_to_critical_error = true;
		return;
	}
	state.update_flags_sar ( original_val_masked, count_raw, op_size, effect );
}

void cmovo ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.OF; } );
}

void cmovnl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF; } );
}

void cmovbe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.CF || state.cpu->cpu_flags.flags.ZF; } );
}

void cmovz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.ZF; } );
}

void cmovle ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.ZF || ( state.cpu->cpu_flags.flags.SF != state.cpu->cpu_flags.flags.OF ); } );
}

void cmovl ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF != state.cpu->cpu_flags.flags.OF; } );
}

void cmovnp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.PF; } );
}

void cmovns ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.SF; } );
}

void cmovp ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.PF; } );
}

void cmovnb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.CF; } );
}

void cmovno ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.OF; } );
}

void cmovs ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF; } );
}

void cmovnz ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.ZF; } );
}

void cmovnbe ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return !state.cpu->cpu_flags.flags.ZF && !state.cpu->cpu_flags.flags.CF; } );
}

void cmovb ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.CF; } );
}

void cmovnle ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	helpers::handle_cmovcc ( instr, state, effect, [ ] ( const auto& state ) { return state.cpu->cpu_flags.flags.SF == state.cpu->cpu_flags.flags.OF; } );
}

// defined for heaven's gate memes
void bound ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	const cs_x86_op* ops = instr.operands ( );
	if ( instr.operand_count ( ) < 2 || ops [ 0 ].type != X86_OP_REG || ops [ 1 ].type != X86_OP_MEM ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	uint8_t op_size = ops [ 0 ].size;
	x86_reg index_reg = ops [ 0 ].reg;
	const cs_x86_op& mem_op = ops [ 1 ];

	if ( op_size != 2 && op_size != 4 ) {
		effect.push_to_changes ( state,std::format ( "BOUND: Invalid operand size {} (must be 2 or 4)", op_size ) );
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ILLEGAL_INSTRUCTION, instr.ip ( ) );
		throw ex;
	}

	uint64_t bounds_addr = helpers::calculate_mem_addr ( mem_op, instr, state );

	int32_t signed_index = 0;
	int32_t signed_lower_bound = 0;
	int32_t signed_upper_bound = 0;

	if ( op_size == 2 ) {
		signed_index = static_cast< int16_t >( state.get_reg ( index_reg, op_size ) );
		signed_lower_bound = static_cast< int16_t >( state.get_memory ( bounds_addr, op_size ) );
		signed_upper_bound = static_cast< int16_t >( state.get_memory ( bounds_addr + op_size, op_size ) );
	}
	else {
		signed_index = static_cast< int32_t >( state.get_reg ( index_reg, op_size ) );
		signed_lower_bound = static_cast< int32_t >( state.get_memory ( bounds_addr, op_size ) );
		signed_upper_bound = static_cast< int32_t >( state.get_memory ( bounds_addr + op_size, op_size ) );
	}

	if ( signed_index < signed_lower_bound || signed_index > signed_upper_bound ) {
		GuestExceptionInfo ex;
		ex.set_exception ( EXCEPTION_ARRAY_BOUNDS_EXCEEDED, instr.ip ( ) );
		throw ex;
	}

	if ( state.options.enable_logging ) {
		effect.push_to_changes ( state,std::format ( "BOUND check passed: {} <= {} <= {}", signed_lower_bound, signed_index, signed_upper_bound ) );
	}
}

#include <random>
void rdrand ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
	static std::mt19937 gen ( std::random_device {}( ) );
	const cs_x86_op* ops = instr.operands ( );

	if ( instr.operand_count ( ) != 1 || ops [ 0 ].type != X86_OP_REG ) {
		state.exit_due_to_critical_error = true;
		return;
	}

	x86_reg dst_reg = ops [ 0 ].reg;
	uint8_t op_size = ops [ 0 ].size;

	if ( op_size != 2 && op_size != 4 && op_size != 8 ) {
		state.exit_due_to_critical_error = true;
		return;
	}

	uint64_t rand_val;

	if ( op_size == 2 ) {
		std::uniform_int_distribution<uint16_t> dist;
		uint16_t rand_val_16 = dist ( gen );
		rand_val = static_cast< uint64_t >( rand_val_16 );
	}
	else if ( op_size == 4 ) {
		std::uniform_int_distribution<uint32_t> dist;
		uint32_t rand_val_32 = dist ( gen );
		rand_val = static_cast< uint64_t >( rand_val_32 );
	}
	else if ( op_size == 8 ) {
		std::uniform_int_distribution<uint64_t> dist;
		rand_val = dist ( gen );
	}

	state.set_reg ( dst_reg, rand_val, op_size, effect );

	uint64_t old_CF = state.cpu->cpu_flags.flags.CF;
	uint64_t old_OF = state.cpu->cpu_flags.flags.OF;
	uint64_t old_SF = state.cpu->cpu_flags.flags.SF;
	uint64_t old_ZF = state.cpu->cpu_flags.flags.ZF;
	uint64_t old_AF = state.cpu->cpu_flags.flags.AF;
	uint64_t old_PF = state.cpu->cpu_flags.flags.PF;

	state.cpu->cpu_flags.flags.CF = 1;
	state.cpu->cpu_flags.flags.OF = 0;
	state.cpu->cpu_flags.flags.SF = 0;
	state.cpu->cpu_flags.flags.ZF = 0;
	state.cpu->cpu_flags.flags.AF = 0;
	state.cpu->cpu_flags.flags.PF = 0;

	if ( old_CF != 1 ) state.log_flag_change ( effect, "CF", old_CF, 1 );
	if ( old_OF != 0 ) state.log_flag_change ( effect, "OF", old_OF, 0 );
	if ( old_SF != 0 ) state.log_flag_change ( effect, "SF", old_SF, 0 );
	if ( old_ZF != 0 ) state.log_flag_change ( effect, "ZF", old_ZF, 0 );
	if ( old_AF != 0 ) state.log_flag_change ( effect, "AF", old_AF, 0 );
	if ( old_PF != 0 ) state.log_flag_change ( effect, "PF", old_PF, 0 );
}

void helpers::bind_logical ( ) {
	BIND ( and_ );
	BIND ( or_ );
	BIND ( xor_ );
	BIND ( not_ );
	BIND ( shl );
	BIND ( shld );
	BIND ( shr );
	BIND ( shrd );
	BIND ( sar );
	BIND ( sal );
	BIND ( cmovo );
	BIND ( cmovnl );
	BIND ( cmovbe );
	BIND ( cmovz );
	BIND ( cmovle );
	BIND ( cmovl );
	BIND ( cmovnp );
	BIND ( cmovns );
	BIND ( cmovp );
	BIND ( cmovnb );
	BIND ( cmovno );
	BIND ( cmovs );
	BIND ( cmovnz );
	BIND ( cmovnbe );
	BIND ( cmovb );
	BIND ( cmovnle );
	BIND ( bound );
	BIND ( rdrand );


}
```

`semantics/src/pch.cpp`:

```cpp
#include "pch.hpp"

template const uint8_t& EmulationContext::get_reg<uint8_t> ( x86_reg ) const;
template const uint16_t& EmulationContext::get_reg<uint16_t> ( x86_reg ) const;
template const uint32_t& EmulationContext::get_reg<uint32_t> ( x86_reg ) const;
template const uint64_t& EmulationContext::get_reg<uint64_t> ( x86_reg ) const;
template uint8_t& EmulationContext::get_reg_mut<uint8_t> ( x86_reg );
template uint16_t& EmulationContext::get_reg_mut<uint16_t> ( x86_reg );
template uint32_t& EmulationContext::get_reg_mut<uint32_t> ( x86_reg );
template uint64_t& EmulationContext::get_reg_mut<uint64_t> ( x86_reg );
```

`semantics/src/pch.hpp`:

```hpp
#pragma once

#include <shared/context.hpp>
#include <shared/types.hpp>
#include <bit>

#define KB_PREFIX(name) kb_##name
#define BIND(x) handlers::x = std::bind ( x, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3 )
#define BIND2(x, y) handlers::x = std::bind ( y, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3 )
#define BINDW(x) handlers::winapi::x = std::bind ( KB_PREFIX(x), std::placeholders::_1, std::placeholders::_2, std::placeholders::_3, std::placeholders::_4 )
#define NO_FLAG_HANDLER nullptr

namespace mp = boost::multiprecision;
using int128_t = mp::int128_t;
using uint128_t = mp::uint128_t;

namespace helpers
{
	inline uint64_t calculate_mem_addr ( const cs_x86_op& mem_op, capstone::Instruction& instr, EmulationContext& state ) {
		if ( mem_op.type != X86_OP_MEM ) {
			state.exit_due_to_critical_error = true;
			return 0;
		}

		uint64_t address = 0;
		if ( mem_op.mem.base != X86_REG_INVALID ) {
			address = state.get_reg ( mem_op.mem.base, 8 );
		}
		if ( mem_op.mem.index != X86_REG_INVALID ) {
			address += state.get_reg ( mem_op.mem.index, 8 ) * mem_op.mem.scale;
		}
		if ( mem_op.mem.segment != X86_REG_INVALID ) {
			address += state.get_reg ( mem_op.mem.segment, 8 );
		}

		address += mem_op.mem.disp;
		return address;
	}

	inline uint64_t get_target2 ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect ) {
		const cs_x86_op* ops = instr.operands ( );

		if ( instr.operand_count ( ) > 0 && ops [ 0 ].type == X86_OP_MEM ) {
			const cs_x86_op& op = ops [ 0 ];
			uint64_t addr = calculate_mem_addr ( op, instr, state );

			if ( parser && parser->is_address_in_iat ( addr ) ) {
				return *( uint64_t* ) addr;
			}

			return state.get_memory ( addr, 8 );
		}
		else if ( instr.operand_count ( ) > 0 && ops [ 0 ].type == X86_OP_REG ) {
			return state.get_reg ( ops [ 0 ].reg );
		}
		else if ( instr.operand_count ( ) > 0 && ops [ 0 ].type == X86_OP_IMM ) {
			return ops [ 0 ].imm;
		}
		else if ( instr.branch_target ( ) != 0 ) {
			return instr.branch_target ( );
		}

		return 0;
	}

	inline void binary_op (
		x86_reg dst, uint64_t src, EmulationContext& state, uint8_t op_size,
		std::function<uint64_t ( uint64_t, uint64_t )> op, const char* op_str,
		std::function<void ( uint64_t, uint64_t, uint8_t, InstructionEffect& )> flag_updater,
		InstructionEffect& effect ) {

		const uint64_t operand_mask = ( op_size == 8 ) ? 0xFFFFFFFFFFFFFFFFULL : ( 1ULL << ( op_size * 8 ) ) - 1;
		const uint64_t src_val_raw = static_cast< uint64_t >( src );
		const uint64_t operand_val = src_val_raw & operand_mask;

		const x86_reg full_reg = state.to_64bit_reg ( dst );
		const uint64_t full_val = state.get_reg ( full_reg, 8 );
		const uint64_t access_mask = state.get_access_mask ( dst, op_size );
		const uint8_t access_shift = state.get_access_shift ( dst, op_size );

		const uint64_t target_val = ( full_val & access_mask ) >> access_shift;
		const uint64_t result_val_unmasked = op ( target_val, operand_val );
		const uint64_t merged_val = ( full_val & ~access_mask ) | ( ( result_val_unmasked << access_shift ) & access_mask );

		state.set_reg ( full_reg, merged_val, 8, effect );

		if ( flag_updater ) {
			flag_updater ( target_val, operand_val, op_size, effect );
		}
	}

	inline uint64_t rebase_executable_address ( EmulationContext& state, uint64_t addr ) {
		if ( addr >= state.windows->loaded_base_address && addr < state.windows->loaded_base_address + state.windows->loaded_module_size ) {
			return addr - state.windows->loaded_base_address + parser->get_image_base ( );
		}
		return addr;
	}

	inline uint64_t resolve_and_switch_target (
		capstone::Instruction& instr,
		EmulationContext& state,
		uint64_t final_target_address,
		InstructionEffect& effect,
		bool is_call
	) {

		if ( final_target_address == 0 ) {
			state.decoder.back ( )->set_ip ( 0 );
			state.exit_due_to_critical_error = true;
			return 0;
		}

		auto import_it = state.windows->imports.find ( final_target_address );
		if ( import_it != state.windows->imports.end ( ) ) {
			std::string dll_name = import_it->second.first;
			std::string func_name = import_it->second.second;

			HMODULE hMod = GetModuleHandleA ( dll_name.c_str ( ) );
			if ( !hMod ) hMod = LoadLibraryA ( dll_name.c_str ( ) );
			if ( !hMod ) {
				state.decoder.back ( )->set_ip ( 0 );
				state.exit_due_to_critical_error = true;
				return 0;
			}

			auto proc_addr = reinterpret_cast< uint64_t >( GetProcAddress ( hMod, func_name.c_str ( ) ) );
			if ( !proc_addr ) {
				state.decoder.back ( )->set_ip ( 0 );
				state.exit_due_to_critical_error = true;
				return 0;
			}

			uint64_t module_base = reinterpret_cast< uint64_t >( hMod );

			if ( state.windows->loaded_modules.find ( module_base ) == state.windows->loaded_modules.end ( ) ) {
				try {
					auto dep_parser = std::make_unique<PE::Parser> ( module_base );
					uint64_t module_size = dep_parser->pe_info_.optional_header.size_of_image;
					const uint8_t* code = reinterpret_cast< const uint8_t* >( module_base );
					state.windows->add_module ( hMod, module_base, module_size, code );
				}
				catch ( const std::exception& ) {
					state.decoder.back ( )->set_ip ( 0 );
					state.exit_due_to_critical_error = true;
					return 0;
				}
			}

			auto* new_decoder = state.get_decoder_for_address ( proc_addr );
			if ( !new_decoder ) {
				state.decoder.back ( )->set_ip ( 0 );
				state.exit_due_to_critical_error = true;
				return 0;
			}
			if ( state.decoder.back ( )->data_ != new_decoder->data_ ) {
				state.decoder.emplace_back ( new_decoder );
			}
			state.decoder.back ( )->set_ip ( proc_addr );
			state.windows->current_module_base = reinterpret_cast< uint64_t >( state.decoder.back ( )->data_ );
			return proc_addr;
		}

		auto* target_decoder = state.get_decoder_for_address ( final_target_address );
		if ( target_decoder ) {
			if ( state.decoder.back ( )->data_ != target_decoder->data_ ) {
				state.decoder.emplace_back ( target_decoder );
			}
			state.decoder.back ( )->set_ip ( final_target_address );
			state.windows->current_module_base = reinterpret_cast< uint64_t >( target_decoder->data_ );
			return final_target_address;
		}

		state.decoder.back ( )->set_ip ( 0 );
		state.exit_due_to_critical_error = true;
		return 0;
	}

	namespace
	{
		template <typename T>
		T handle_operand ( const cs_x86_op& op, capstone::Instruction* instr, EmulationContext& state, uint8_t op_size ) {
			switch ( op.type ) {
				case X86_OP_IMM:
					return static_cast< T >( op.imm );
				case X86_OP_REG:
				{
					x86_reg reg = op.reg;
					if constexpr ( std::is_same_v<T, float> ) {
						if ( reg >= X86_REG_XMM0 && reg <= X86_REG_XMM15 ) {
							return state.get_xmm_float ( reg );
						}
					}
					else if constexpr ( std::is_same_v<T, double> ) {
						if ( reg >= X86_REG_XMM0 && reg <= X86_REG_XMM15 ) {
							return state.get_xmm_double ( reg );
						}
					}
					else if constexpr ( std::is_same_v<T, uint128_t> ) {
						if ( reg >= X86_REG_XMM0 && reg <= X86_REG_XMM15 ) {
							return state.get_xmm_raw ( reg );
						}
					}
					else if constexpr ( std::is_same_v<T, uint256_t> ) {
						if ( reg >= X86_REG_YMM0 && reg <= X86_REG_YMM15 ) {
							return state.get_zmm_raw ( reg );
						}
					}
					else if constexpr ( std::is_same_v<T, uint512_t> ) {
						if ( reg >= X86_REG_YMM0 && reg <= X86_REG_YMM15 ) {
							return state.get_ymm_raw ( reg );
						}
					}
					else {
						return static_cast< T >( state.get_reg ( reg, op_size ) );
					}
				}
				case X86_OP_MEM:
				{
					uint64_t addr = calculate_mem_addr ( op, *instr, state );
					if constexpr ( std::is_same_v<T, uint128_t> ) {
						return state.get_memory_128 ( addr );
					}
					if constexpr ( std::is_same_v<T, uint256_t> ) {
						return state.get_memory_256 ( addr );
					}
					if constexpr ( std::is_same_v<T, uint512_t> ) {
						return state.get_memory_512 ( addr );
					}
					else {
						return static_cast< T > ( state.get_memory ( addr, op_size ) );
					}
				}
				default:
					break;
			}
			return T {};
		}
	}

	template <typename T>
	T get_src ( capstone::Instruction* instr, size_t idx, EmulationContext& state, uint8_t op_size ) {
		const cs_x86_op* ops = instr->operands ( );
		return handle_operand<T> ( ops [ idx ], instr, state, op_size );
	}

	template <typename T>
	T get_operand_value (
			capstone::Instruction& instr,
			size_t operand_index,
			EmulationContext& state,
			InstructionEffect& effect
	) {
		const cs_x86_op& op = instr.operands ( ) [ operand_index ];
		uint8_t op_size = op.size;

		switch ( op.type ) {
			case X86_OP_REG:
			{
				if constexpr ( std::is_same_v<T, uint128_t> ) {
					if ( op.reg >= X86_REG_XMM0 && op.reg <= X86_REG_XMM15 ) {
						return state.get_xmm_raw ( op.reg );
					}
					else { state.exit_due_to_critical_error = true; return T {}; }
				}
				else if constexpr ( std::is_same_v<T, float> ) {
					if ( op.reg >= X86_REG_XMM0 && op.reg <= X86_REG_XMM15 ) {
						return state.get_xmm_float ( op.reg );
					}
					else { state.exit_due_to_critical_error = true; return T {}; }
				}
				else if constexpr ( std::is_same_v<T, double> ) {
					if ( op.reg >= X86_REG_XMM0 && op.reg <= X86_REG_XMM15 ) {
						return state.get_xmm_double ( op.reg );
					}
					else { state.exit_due_to_critical_error = true; return T {}; }
				}
				else {
					uint64_t val = state.get_reg ( op.reg, op_size );
					return static_cast< T >( val );
				}
			}
			case X86_OP_MEM:
			{
				uint64_t addr = calculate_mem_addr ( op, instr, state );
				if constexpr ( std::is_same_v<T, uint128_t> ) {
					return state.get_memory_128 ( addr );
				}
				else {
					uint64_t mem_val = state.get_memory ( addr, op_size );
					if constexpr ( std::is_same_v<T, float> ) {
						if ( op_size == 4 ) return std::bit_cast< float >( static_cast< uint32_t >( mem_val ) );
						state.exit_due_to_critical_error = true; return T {};
					}
					else if constexpr ( std::is_same_v<T, double> ) {
						if ( op_size == 8 ) return std::bit_cast< double >( mem_val );
						state.exit_due_to_critical_error = true; return T {};
					}
					else {
						return static_cast< T >( mem_val );
					}
				}
			}
			case X86_OP_IMM:
			{
				return static_cast< T >( op.imm );
			}
			default:
				break;
		}
		return {};
	}

	template <typename T>
	void set_dst_value (
			capstone::Instruction& instr,
			size_t operand_index,
			const T& value,
			EmulationContext& state,
			InstructionEffect& effect
	) {
		const cs_x86_op& dst = instr.operands ( ) [ operand_index ];
		uint8_t op_size = dst.size;

		switch ( dst.type ) {
			case X86_OP_REG:
			{
				if constexpr ( std::is_same_v<T, uint128_t> ) {
					if ( dst.reg >= X86_REG_XMM0 && dst.reg <= X86_REG_XMM15 ) {
						state.set_xmm_raw ( dst.reg, value, effect );
					}
					else { state.exit_due_to_critical_error = true; }
				}
				else if constexpr ( std::is_same_v<T, float> ) {
					if ( dst.reg >= X86_REG_XMM0 && dst.reg <= X86_REG_XMM15 ) {
						state.set_xmm_float ( dst.reg, value, effect );
					}
					else { state.exit_due_to_critical_error = true; }
				}
				else if constexpr ( std::is_same_v<T, double> ) {
					if ( dst.reg >= X86_REG_XMM0 && dst.reg <= X86_REG_XMM15 ) {
						state.set_xmm_double ( dst.reg, value, effect );
					}
					else { state.exit_due_to_critical_error = true; }
				}
				else {
					state.set_reg ( dst.reg, static_cast< uint64_t >( value ), op_size, effect );
				}
				break;
			}
			case X86_OP_MEM:
			{
				uint64_t addr = calculate_mem_addr ( dst, instr, state );
				bool is_stack = state.is_within_stack_bounds ( addr, op_size );

				if constexpr ( std::is_same_v<T, uint128_t> ) {
					if ( is_stack ) { /* Error? set_stack doesn't handle 128 */ state.exit_due_to_critical_error = true; }
					else state.set_memory_128 ( addr, value, effect );
				}
				else if constexpr ( std::is_same_v<T, float> ) {
					if ( is_stack ) state.set_stack ( addr, std::bit_cast< uint32_t >( value ), effect, 4 );
					else state.set_memory ( addr, std::bit_cast< uint32_t >( value ), 4, effect );
				}
				else if constexpr ( std::is_same_v<T, double> ) {
					if ( is_stack ) state.set_stack ( addr, std::bit_cast< uint64_t >( value ), effect, 8 );
					else state.set_memory ( addr, std::bit_cast< uint64_t >( value ), 8, effect );
				}
				else {
					if ( is_stack ) state.set_stack ( addr, static_cast< uint64_t >( value ), effect, op_size );
					else state.set_memory ( addr, static_cast< uint64_t >( value ), op_size, effect );
				}
				effect.modified_mem.insert ( addr );
				break;
			}
			default:
				state.exit_due_to_critical_error = true;
				break;
		}
	}

	inline void handle_unary_op (
		capstone::Instruction& instr,
		EmulationContext& state,
		InstructionEffect& effect,
		std::function<uint64_t ( uint64_t )> operation,
		std::function<void ( EmulationContext&, uint64_t, uint8_t, InstructionEffect& )> flag_updater
	) {
		const cs_x86_op* ops = instr.operands ( );
		uint8_t op_size = ops [ 0 ].size;

		uint64_t dst_val = helpers::get_operand_value<uint64_t> ( instr, 0, state, effect );
		if ( state.exit_due_to_critical_error ) return;

		uint64_t result = operation ( dst_val );

		helpers::set_dst_value<uint64_t> ( instr, 0, result, state, effect );
		if ( state.exit_due_to_critical_error ) return;

		if ( flag_updater ) {
			GET_OPERAND_MASK ( operand_mask, op_size );
			flag_updater ( state, dst_val & operand_mask, op_size, effect );
		}
	}

	inline void handle_cmovcc (
			capstone::Instruction& instr,
			EmulationContext& state,
			InstructionEffect& effect,
			std::function<bool ( const EmulationContext& )> condition
	) {
		if ( condition ( state ) ) {
			const cs_x86_op* ops = instr.operands ( );
			uint8_t op_size = ops [ 0 ].size;
			uint64_t src_val = helpers::get_operand_value<uint64_t> ( instr, 1, state, effect );
			if ( state.exit_due_to_critical_error ) return;

			state.set_reg ( ops [ 0 ].reg, src_val, op_size, effect );
		}
	}

	inline void handle_binary_op (
		 capstone::Instruction& instr,
		 EmulationContext& state,
		 InstructionEffect& effect,
		 std::function<uint64_t ( uint64_t, uint64_t )> operation,
		 std::function<void ( EmulationContext&, uint64_t, uint64_t, uint8_t, InstructionEffect& )> flag_updater
	) {
		const cs_x86_op* ops = instr.operands ( );
		uint8_t op_size = ops [ 0 ].size;

		uint64_t dst_val = helpers::get_operand_value<uint64_t> ( instr, 0, state, effect );
		uint64_t src_val = helpers::get_operand_value<uint64_t> ( instr, 1, state, effect );
		if ( state.exit_due_to_critical_error ) {
			return;
		}
		uint64_t result = operation ( dst_val, src_val );

		helpers::set_dst_value<uint64_t> ( instr, 0, result, state, effect );
		if ( state.exit_due_to_critical_error ) {
			return;
		}
		if ( flag_updater ) {
			GET_OPERAND_MASK ( operand_mask, op_size );
			flag_updater ( state, dst_val & operand_mask, src_val & operand_mask, op_size, effect );
		}
	}

	inline void handle_setcc (
			capstone::Instruction& instr,
			EmulationContext& state,
			InstructionEffect& effect,
			std::function<bool ( const EmulationContext& )> condition
	) {
		const cs_x86_op* ops = instr.operands ( );
		uint8_t result = condition ( state ) ? 1 : 0;

		helpers::set_dst_value<uint8_t> ( instr, 0, result, state, effect );
		if ( state.exit_due_to_critical_error ) {
			return;
		}
	}

	inline int64_t sign_extend ( uint64_t val, uint8_t size_bytes ) {
		if ( size_bytes >= 8 ) return static_cast< int64_t >( val );
		int bits = size_bytes * 8;
		uint64_t mask = ( 1ULL << bits ) - 1;
		uint64_t sign_bit_mask = 1ULL << ( bits - 1 );
		uint64_t val_masked = val & mask;
		if ( ( val_masked & sign_bit_mask ) != 0 ) {
			uint64_t extension = ~mask;
			return static_cast< int64_t >( val_masked | extension );
		}
		else {
			return static_cast< int64_t >( val_masked );
		}
	}

	inline int128_t sign_extend ( uint128_t val, uint8_t size_bytes ) {
		if ( size_bytes >= 16 ) return int128_t ( val );
		int bits = size_bytes * 8;
		uint128_t mask = ( uint128_t ( 1 ) << bits ) - 1;
		uint128_t sign_bit_mask = uint128_t ( 1 ) << ( bits - 1 );
		uint128_t val_masked = val & mask;
		if ( ( val_masked & sign_bit_mask ) != 0 ) {
			uint128_t extension = ~mask;
			return int128_t ( val_masked | extension );
		}
		else {
			return int128_t ( val_masked );
		}
	}

	template uint8_t get_src<uint8_t> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );
	template uint16_t get_src<uint16_t> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );
	template uint32_t get_src<uint32_t> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );
	template uint64_t get_src<uint64_t> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );
	template uint128_t get_src<uint128_t> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );
	template float get_src<float> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );
	template double get_src<double> ( capstone::Instruction*, size_t, EmulationContext&, uint8_t );

	template uint8_t get_operand_value<uint8_t> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );
	template uint16_t get_operand_value<uint16_t> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );
	template uint32_t get_operand_value<uint32_t> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );
	template uint64_t get_operand_value<uint64_t> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );
	template uint128_t get_operand_value<uint128_t> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );
	template float get_operand_value<float> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );
	template double get_operand_value<double> ( capstone::Instruction&, size_t, EmulationContext&, InstructionEffect& );

	template void set_dst_value<uint8_t> ( capstone::Instruction&, size_t, const uint8_t&, EmulationContext&, InstructionEffect& );
	template void set_dst_value<uint16_t> ( capstone::Instruction&, size_t, const uint16_t&, EmulationContext&, InstructionEffect& );
	template void set_dst_value<uint32_t> ( capstone::Instruction&, size_t, const uint32_t&, EmulationContext&, InstructionEffect& );
	template void set_dst_value<uint64_t> ( capstone::Instruction&, size_t, const uint64_t&, EmulationContext&, InstructionEffect& );
	template void set_dst_value<uint128_t> ( capstone::Instruction&, size_t, const uint128_t&, EmulationContext&, InstructionEffect& );
	template void set_dst_value<float> ( capstone::Instruction&, size_t, const float&, EmulationContext&, InstructionEffect& );
	template void set_dst_value<double> ( capstone::Instruction&, size_t, const double&, EmulationContext&, InstructionEffect& );

	void bind_arithmetic ( );
	void bind_bit ( );
	void bind_cf ( );
	void bind_jx ( );
	void bind_cpu ( );
	void bind_fpu ( );
	void bind_avx ( );
	void bind_data ( );
	void bind_logical ( );
	void bind_frame ( );
	void bind_winapi ( );
};
```

`semantics/src/syscall.asm`:

```asm
; syscall.asm (MASM)

; Define the SyscallState structure
SyscallState STRUCT
    vrax QWORD ?
    vrcx QWORD ?
    vrdx QWORD ?
    vr8  QWORD ?
    vr9  QWORD ?
    vr10 QWORD ?
    vrsp QWORD ?
SyscallState ENDS

.CODE

; Declare the function as external C linkage
execute_raw_syscall PROC
    push rbp
    mov rbp, rsp
    push rbx
    push rsi
    push rdi

    ; Arguments (Windows x64 calling convention):
    ; rcx = rax (syscall number)
    ; rdx = rcx (arg1)
    ; r8  = rdx (arg2)
    ; r9  = r8  (arg3)
    ; Stack: r9 (arg4), stack_args pointer, stack_arg_count, SyscallState pointer

    mov rax, rcx    ; Syscall number
    mov rcx, rdx    ; Arg1
    mov rdx, r8     ; Arg2
    mov r8, r9      ; Arg3
    mov r9, [rbp+48]; Arg4 (5th arg on stack)
    mov r10, rcx    ; Windows syscall moves RCX to R10

    ; Save initial RSP
    mov rbx, rsp

    ; Handle stack arguments
    mov rsi, [rbp+56] ; stack_args pointer (6th arg)
    mov rcx, [rbp+64] ; stack_arg_count (7th arg)
    test rcx, rcx
    jz no_stack_args

    ; Allocate shadow space + stack args (32 bytes shadow + 8 per arg)
    lea rdi, [rcx*8 + 32]
    sub rsp, rdi
    and rsp, -16    ; Align to 16 bytes

    ; Copy stack arguments
    xor rdi, rdi
copy_loop:
    cmp rdi, rcx
    jae done_copy
    mov rax, [rsi + rdi*8]
    mov [rsp + 32 + rdi*8], rax
    inc rdi
    jmp copy_loop

done_copy:
no_stack_args:
    sub rsp, 32     ; Shadow space if no extra args

    ; Save registers to stack before syscall
    push r10
    push r9
    push r8
    push rdx
    push rcx

    syscall         ; Execute syscall

    ; Save post-syscall register state
    mov rdi, [rbp+72]  ; SyscallState pointer (8th arg)
    mov [rdi + SyscallState.vrax], rax
    pop rcx
    mov [rdi + SyscallState.vrcx], rcx
    pop rdx
    mov [rdi + SyscallState.vrdx], rdx
    pop r8
    mov [rdi + SyscallState.vr8], r8
    pop r9
    mov [rdi + SyscallState.vr9], r9
    pop r10
    mov [rdi + SyscallState.vr10], r10
    mov [rdi + SyscallState.vrsp], rsp

    ; Restore stack
    mov rsp, rbx    ; Reset RSP to pre-syscall state

    pop rdi
    pop rsi
    pop rbx
    mov rsp, rbp
    pop rbp
    ret
execute_raw_syscall ENDP

END
```

`semantics/src/syscalls.cpp`:

```cpp
#include "pch.hpp"
```

`semantics/src/winapi.cpp`:

```cpp
#include "pch.hpp"

#include <cstddef>       // For std::size_t
#include <type_traits>   // For std::integral_constant, std::is_void_v, etc.
#include <array>
#include <string>
#include <tuple>         // For std::tuple, std::tuple_element_t
#include <utility>       // For std::index_sequence, std::make_index_sequence
#include <vector>        // For parsing argument types in log
#include <print>         // C++23 Printing library
#include <concepts>      // For std::integral constraint
#include <algorithm>     // For std::transform (in logging)
#include <iterator>      // For std::back_inserter (in logging)
#include <format>        // For std::format

void kb_forward ( capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect, uint64_t target ) {
  auto it = state.windows->imports.find ( target );
  if ( it == state.windows->imports.end ( ) ) {
    std::print ( "Direct call to unknown address {:016x}h\n", target );
    state.set_reg ( X86_REG_RAX, 0x0, 8, effect );
    return;
  }
  std::string dll_name = it->second.first;
  std::string func_name = it->second.second;
  std::print ( "Direct call to {}!{}\n", dll_name, func_name );

  HMODULE hMod = GetModuleHandleA ( dll_name.c_str ( ) );
  if ( !hMod ) hMod = LoadLibraryA ( dll_name.c_str ( ) );
  if ( !hMod ) {
    std::print ( "Failed to load {}\n", dll_name );
    state.set_reg ( X86_REG_RAX, 0x0, 8, effect );
    return;
  }

  FARPROC proc = GetProcAddress ( hMod, func_name.c_str ( ) );
  if ( !proc ) {
    std::print ( "Failed to resolve {}!{}\n", dll_name, func_name );
    state.set_reg ( X86_REG_RAX, 0x0, 8, effect );
    return;
  }

  std::println ( "[{}] - {} -> unhandled api call", dll_name, func_name );
  //capstone::Decoder new_decoder ( reinterpret_cast< uint8_t* >( hMod ), 0x1000, 0x0 );
  //new_decoder.set_ip ( reinterpret_cast< uint64_t >( proc ) );
  //auto old_decoder = std::exchange ( state.decoder, &new_decoder );
  //
  //std::exchange ( state.decoder, old_decoder );
}

#define _GET_NTH_ARG_PRIVATE(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, N, ...) N
#define COUNT_ARGS_IMPL(...) _GET_NTH_ARG_PRIVATE(dummy, ##__VA_ARGS__, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)
#define COUNT_ARGS(...) (std::integral_constant<std::size_t, COUNT_ARGS_IMPL(__VA_ARGS__)>::value)
#define KB_PREFIX(name) kb_##name
#define STRINGIFY_VA_ARGS_SAFE(...) "" #__VA_ARGS__ // Keep this helper

// --- Function Traits Helper ---
template<typename T> struct function_traits; // Primary template

template<typename R, typename... Args> // Specialization for WINAPI function pointers
struct function_traits<R ( WINAPI* )( Args... )> {
  using return_type = R;
  using argument_tuple = std::tuple<Args...>;
  static constexpr std::size_t arity = sizeof...( Args );

  template <std::size_t N>
  using argument_type = std::tuple_element_t<N, argument_tuple>;
};

// --- Casting Helper ---
template <typename TargetType>
TargetType safe_arg_cast ( uint64_t raw_value ) {
  if constexpr ( std::is_pointer_v<TargetType> ) {
    return reinterpret_cast< TargetType >( raw_value );
  }
  else if constexpr ( std::is_integral_v<TargetType> || std::is_enum_v<TargetType> ) {
    // Use static_cast for integrals/enums - handles size differences safely
    return static_cast< TargetType >( raw_value );
  }
  else {
    // Add handling for other types (float, double, structs) if needed for your ABI
    static_assert( std::is_pointer_v<TargetType> || std::is_integral_v<TargetType> || std::is_enum_v<TargetType>,
                  "Unsupported argument type in safe_arg_cast for WRAP_WINAPI. Add support if needed." );
    // Fallback (use with caution, might be incorrect for non-pod types)
    return reinterpret_cast< TargetType >( raw_value );
  }
}

// --- invoke_winapi_internal Helper (Fixed to properly manage function types) ---
template <typename Func, typename RetType, std::size_t N, std::size_t... Is>
RetType invoke_winapi_internal (
    Func func,
    const std::array<uint64_t, ( N > 0 ? N : 1 )>& packed_args,
    std::index_sequence<Is...> ) {
  using traits = function_traits<Func>;
  static_assert( traits::arity == N, "Argument count mismatch in invoke_winapi_internal" );
  static_assert( traits::arity == sizeof...( Is ), "Index sequence size mismatch in invoke_winapi_internal" );

  if constexpr ( std::is_void_v<RetType> ) {
    func ( safe_arg_cast< typename std::tuple_element<Is, typename traits::argument_tuple>::type >( packed_args [ Is ] )... );
  }
  else {
    return func ( safe_arg_cast< typename std::tuple_element<Is, typename traits::argument_tuple>::type >( packed_args [ Is ] )... );
  }
}

template <typename VoidFuncPtrType>
void call_and_log_void_return (
    VoidFuncPtrType pfnApi,
    const std::array<uint64_t, ( function_traits<VoidFuncPtrType>::arity > 0 ? function_traits<VoidFuncPtrType>::arity : 1 )>& args_raw ) {
  using traits = function_traits<VoidFuncPtrType>;
  constexpr std::size_t N = traits::arity;

  invoke_winapi_internal<VoidFuncPtrType, void, N> (
      pfnApi,
      args_raw,
      std::make_index_sequence<N>{}
  );

  std::print ( "void" );
}

template <typename NonVoidFuncPtrType>
void call_and_log_non_void_return (
    NonVoidFuncPtrType pfnApi,
    const std::array<uint64_t, ( function_traits<NonVoidFuncPtrType>::arity > 0 ? function_traits<NonVoidFuncPtrType>::arity : 1 )>& args_raw,
    EmulationContext& state ) {
  using traits = function_traits<NonVoidFuncPtrType>;
  using RetType = typename traits::return_type;
  constexpr std::size_t N = traits::arity;

  static_assert( !std::is_void_v<RetType>, "Non-void helper called with void function pointer type" );

  RetType ret_val = invoke_winapi_internal<NonVoidFuncPtrType, RetType, N> (
      pfnApi,
      args_raw,
      std::make_index_sequence<N>{}
  );

  // Set RAX register
  InstructionEffect effect {};
  state.set_reg ( X86_REG_RAX, (uint64_t)ret_val, 8, effect );

  // Log the return value
  if constexpr ( std::is_pointer_v<RetType> ) {
    std::print ( "{:p}", static_cast< const void* >( ret_val ) );
  }
  else if constexpr ( std::is_same_v<RetType, bool> ) {
    std::print ( "{}", ret_val );
  }
  else if constexpr ( std::is_integral_v<RetType> || std::is_enum_v<RetType> ) {
    std::print ( "0x{:x}", ( uint64_t ) ( ret_val ) );
  }
  else {
    std::print ( "{}", ret_val );
  }
}

#define WRAP_WINAPI(api_name, ret_type, ...) \
void KB_PREFIX(api_name) (capstone::Instruction& instr, EmulationContext& state, InstructionEffect& effect, uint64_t target) { \
    /* Define function pointer type using the specific API name and return type */ \
    using func_ptr_type = ret_type(WINAPI *)(__VA_ARGS__); \
    /* Use function_traits to get the correct arity */ \
    using traits = function_traits<func_ptr_type>; \
    constexpr std::size_t arg_count = traits::arity; /* <-- Use traits::arity */ \
    \
    /* Get function pointer to the actual API */ \
    func_ptr_type pfnApi = ::api_name; \
    \
    /* Array to hold arguments (size >= 1 avoids zero-size array issues) */ \
    /* Now uses the correctly determined arg_count */ \
    std::array<uint64_t, (arg_count > 0 ? arg_count : 1)> args_raw{}; \
    \
    /* Read arguments from registers and stack */ \
    if constexpr (arg_count > 0) { \
        constexpr std::array<x86_reg, 4> arg_regs = { X86_REG_RCX, X86_REG_RDX, X86_REG_R8, X86_REG_R9 }; \
        /* Corrected loop bounds */ \
        constexpr std::size_t reg_arg_limit = std::min(arg_count, arg_regs.size()); \
        for (std::size_t i = 0; i < reg_arg_limit; ++i) { \
            args_raw[i] = state.get_reg(arg_regs[i]); \
        } \
        /* Corrected stack argument loop */ \
        constexpr std::size_t stack_arg_count = (arg_count > arg_regs.size()) ? (arg_count - arg_regs.size()) : 0; \
        uint64_t stack_base = state.get_reg(X86_REG_RSP) + 8; /* Skip return address */ \
        for (std::size_t i = 0; i < stack_arg_count; ++i) { \
            /* Index in args_raw is reg_arg_limit + i */ \
            /* Address on stack is stack_base + i * 8 */ \
            args_raw[reg_arg_limit + i] = state.get_memory(stack_base + i * 8, 8); \
        } \
    } \
    \
    /* Declare string for logging args */ \
    const std::string args_as_string{ STRINGIFY_VA_ARGS_SAFE(__VA_ARGS__) }; \
    \
    /* --- Start Logging --- */ \
    std::print("[API] {} (", #api_name); \
    /* Argument parsing and printing logic (existing code seems okay) */ \
    if constexpr (arg_count > 0) { \
        std::vector<std::string> arg_type_names; \
        std::size_t current_pos = 0; int template_level = 0; \
        /* Edge case: handle empty __VA_ARGS__ for arg_count = 0 */ \
        if (!args_as_string.empty()) { \
            for (std::size_t i = 0; i < arg_count; ++i) { \
                std::size_t comma_pos = current_pos; \
                while (comma_pos < args_as_string.length()) { \
                     if (args_as_string[comma_pos] == '<') template_level++; \
                     else if (args_as_string[comma_pos] == '>') template_level--; \
                     else if (args_as_string[comma_pos] == ',' && template_level == 0) break; \
                     comma_pos++; \
                } \
                if (i == arg_count - 1) comma_pos = args_as_string.length(); \
                std::string type_str = args_as_string.substr(current_pos, comma_pos - current_pos); \
                type_str.erase(0, type_str.find_first_not_of(" \t\n\r\f\v")); \
                type_str.erase(type_str.find_last_not_of(" \t\n\r\f\v") + 1); \
                arg_type_names.push_back(type_str); \
                current_pos = comma_pos + 1; \
             } \
         } \
        for (std::size_t i = 0; i < arg_count; ++i) { \
            const std::string& type_name = arg_type_names[i]; \
            uint64_t arg_val = args_raw[i]; \
            bool is_pointer_type = type_name.find('*') != std::string::npos || \
                                   type_name.find("HANDLE") != std::string::npos || \
                                   /* Add other pointer-like types if needed */ \
                                   type_name.find("LP") == 0 || type_name.find("P") == 0; \
            if (type_name.find("LPCSTR") != std::string::npos || type_name.find("char*") != std::string::npos) { \
                 std::print("{}", arg_val ? std::format("\"{}\"", (char*)arg_val) : "NULL"); \
            } else if (type_name.find("LPCWSTR") != std::string::npos || type_name.find("wchar_t*") != std::string::npos) { \
                 if (arg_val) { \
                     std::wstring wstr((wchar_t*)arg_val); std::string narrow_str; \
                     std::transform(wstr.begin(), wstr.end(), std::back_inserter(narrow_str), [](wchar_t wc){ return static_cast<char>(wc); }); /* Safer cast */ \
                     std::print("L\"{}\"", narrow_str); \
                 } else { std::print("NULL"); } \
            } else if (is_pointer_type) { std::print("{:p}", (void*)arg_val); \
            } else { std::print("0x{:x}", arg_val); } \
            if (i < arg_count - 1) std::print(", "); \
        } \
    } \
    std::print(") -> "); /* Print separator before return value */ \
    \
    /* --- Call API and Handle Return using Updated Helpers --- */ \
    /* This part should now work because args_raw has the correct size */ \
    if constexpr (std::is_void_v<ret_type>) { \
        call_and_log_void_return(pfnApi, args_raw); \
    } else { \
        call_and_log_non_void_return(pfnApi, args_raw, state); \
    } \
    \
    std::println(""); /* End the log line */ \
    \
    /* Update RSP offset based on __cdecl calling convention */ \
    /* Note: x64 uses a shadow space, args passed in regs don't affect RSP directly */ \
    /* For __cdecl on x86, caller cleans up stack, but here we model the call */ \
    /* In x64, the called function doesn't change RSP for args passed in regs. */ \
    /* Stack args occupy space, but typically managed within the called func prologue/epilogue */ \
    /* Let's assume for emulation, we don't need to adjust RSP here unless */ \
    /* the called function explicitly manipulates it beyond the standard ABI */ \
    /*state.rsp_offsetmodification might be unnecessary or incorrect here for x64 ABI */ \
}

/* --- Remove or comment out the COUNT_ARGS macros if no longer needed elsewhere ---
#define _GET_NTH_ARG_PRIVATE(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, N, ...) N
#define COUNT_ARGS_IMPL(...) _GET_NTH_ARG_PRIVATE(dummy, ##__VA_ARGS__, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0)
#define COUNT_ARGS(...) (std::integral_constant<std::size_t, COUNT_ARGS_IMPL(__VA_ARGS__)>::value)
*/
uint64_t __fastcall RtlInitializeCriticalSectionEx ( PRTL_CRITICAL_SECTION a1, DWORD a2, uint64_t a3, uint64_t a4 ) {
  return 0;
}
uint64_t __fastcall RtlInitializeCriticalSectionAndSpinCount ( PRTL_CRITICAL_SECTION a1, DWORD a2, uint64_t a3, uint64_t a4 ) {
  return 0;
}
uint64_t __fastcall RtlEnterCriticalSection ( PRTL_CRITICAL_SECTION a1 ) {
  return 0;
}uint64_t __fastcall RtlLeaveCriticalSection ( PRTL_CRITICAL_SECTION a1 ) {
  return 0;
}uint64_t __fastcall RtlDeleteCriticalSection ( PRTL_CRITICAL_SECTION* a1 ) {
  return 0;
}
WRAP_WINAPI ( LoadLibraryA, HMODULE, LPCSTR );
WRAP_WINAPI ( LoadLibraryW, HMODULE, LPCWSTR );
WRAP_WINAPI ( LoadLibraryExA, HMODULE, LPCSTR, HANDLE, DWORD );
WRAP_WINAPI ( LoadLibraryExW, HMODULE, LPCWSTR, HANDLE, DWORD );
WRAP_WINAPI ( GetProcAddress, FARPROC, HMODULE, LPCSTR );
WRAP_WINAPI ( InitializeCriticalSectionAndSpinCount, BOOL, LPCRITICAL_SECTION, DWORD );
WRAP_WINAPI ( InitializeCriticalSectionEx, BOOL, LPCRITICAL_SECTION, DWORD, DWORD );
WRAP_WINAPI ( RtlInitializeCriticalSectionEx, uint64_t, PRTL_CRITICAL_SECTION, DWORD, uint64_t, uint64_t );
WRAP_WINAPI ( RtlInitializeCriticalSectionAndSpinCount, uint64_t, PRTL_CRITICAL_SECTION, DWORD, uint64_t, uint64_t );
WRAP_WINAPI ( RtlEnterCriticalSection, uint64_t, PRTL_CRITICAL_SECTION );
WRAP_WINAPI ( RtlLeaveCriticalSection, uint64_t, PRTL_CRITICAL_SECTION );
WRAP_WINAPI ( RtlDeleteCriticalSection, uint64_t, PRTL_CRITICAL_SECTION* );
WRAP_WINAPI ( FlsAlloc, DWORD, PFLS_CALLBACK_FUNCTION );
WRAP_WINAPI ( FlsGetValue, PVOID, DWORD );
WRAP_WINAPI ( FlsSetValue, BOOL, DWORD, PVOID );
WRAP_WINAPI ( FlsFree, BOOL, DWORD );
WRAP_WINAPI ( TlsAlloc, DWORD );
WRAP_WINAPI ( TlsGetValue, LPVOID, DWORD );
WRAP_WINAPI ( TlsSetValue, BOOL, DWORD, LPVOID );
WRAP_WINAPI ( TlsFree, BOOL, DWORD );
WRAP_WINAPI ( VirtualProtect, BOOL, LPVOID, SIZE_T, DWORD, PDWORD );
WRAP_WINAPI ( InitializeSListHead, void, PSLIST_HEADER );
WRAP_WINAPI ( GetProcessHeap, HANDLE );
WRAP_WINAPI ( IsProcessorFeaturePresent, BOOL, DWORD );
WRAP_WINAPI ( GetLastError, DWORD );

void helpers::bind_winapi ( ) {
  BINDW ( forward );
  BINDW ( LoadLibraryA );
  BINDW ( LoadLibraryW );
  BINDW ( LoadLibraryExA );
  BINDW ( LoadLibraryExW );
  BINDW ( GetProcAddress );

  BINDW ( InitializeCriticalSectionAndSpinCount );
  BINDW ( InitializeCriticalSectionEx );
  BINDW ( RtlInitializeCriticalSectionEx );
  BINDW ( RtlInitializeCriticalSectionAndSpinCount );
  BINDW ( RtlEnterCriticalSection );
  BINDW ( RtlLeaveCriticalSection );
  BINDW ( RtlDeleteCriticalSection );

  BINDW ( InitializeSListHead );

  BINDW ( FlsAlloc );
  BINDW ( FlsGetValue );
  BINDW ( FlsSetValue );
  BINDW ( FlsFree );
  
  BINDW ( TlsAlloc );
  BINDW ( TlsGetValue );
  BINDW ( TlsSetValue );
  BINDW ( TlsFree );

  BINDW ( VirtualProtect );
  BINDW ( GetProcessHeap );

  BINDW ( IsProcessorFeaturePresent );
  BINDW ( GetLastError );
}
```

`shared/capstone++.hpp`:

```hpp
#pragma once

#include <cstdint>
#include <vector>
#include <memory>
#include <string> // Added for std::string
#include <cstring> // Added for memcpy/memset
#include <capstone/capstone.h>
#include <capstone/x86.h>
#include <string_view>
#include <array>
#include <format>
#include <print>
#include <utility>

constexpr std::array<uint8_t, ( X86_INS_ENDING + 7 ) / 8> create_conditional_branch_bitfield ( ) {
	std::array<uint8_t, ( X86_INS_ENDING + 7 ) / 8> bits = {};
	auto set_bit = [ &bits ] ( unsigned int mnemonic_id )
	{
		if ( mnemonic_id < X86_INS_ENDING ) { // Basic bounds check
			bits [ mnemonic_id / 8 ] |= ( 1 << ( mnemonic_id % 8 ) );
		}
	};
	set_bit ( X86_INS_JB );
	set_bit ( X86_INS_JAE );
	set_bit ( X86_INS_JBE );
	set_bit ( X86_INS_JA );
	set_bit ( X86_INS_JE );
	set_bit ( X86_INS_JNE );
	set_bit ( X86_INS_JL );
	set_bit ( X86_INS_JGE );
	set_bit ( X86_INS_JLE );
	set_bit ( X86_INS_JG );
	set_bit ( X86_INS_JO );
	set_bit ( X86_INS_JNO );
	set_bit ( X86_INS_JP );
	set_bit ( X86_INS_JNP );
	set_bit ( X86_INS_JS );
	set_bit ( X86_INS_JNS );
	set_bit ( X86_INS_JCXZ );
	set_bit ( X86_INS_JECXZ );
	set_bit ( X86_INS_JRCXZ );
	set_bit ( X86_INS_LOOP );
	set_bit ( X86_INS_LOOPE );
	set_bit ( X86_INS_LOOPNE );
	return bits;
}

static constexpr auto conditional_branch_bits = create_conditional_branch_bitfield ( );

enum class OperandType : uint8_t {
	OP_INVALID,
	OP_REG,
	OP_IMM,
	OP_MEM
};

using Register = x86_reg;
using Segment = x86_reg;

#define SHOULD_BREAK_ON_INVALID_TYPE

namespace capstone
{
	class MemoryOperand {
	private:
		const Segment segment_;
		const Register base_;
		const Register index_;
		const int scale_;
		const int64_t disp_;

	public:
		MemoryOperand ( ) noexcept = default;
		MemoryOperand ( MemoryOperand&& other ) noexcept = default;
		MemoryOperand& operator=( MemoryOperand&& other ) noexcept = default;
		MemoryOperand ( const MemoryOperand& other ) = default;
		MemoryOperand& operator=( const MemoryOperand& other ) = default;
		~MemoryOperand ( ) = default;

		[[nodiscard]] Segment segment ( ) const noexcept {
			return segment_;
		}

		[[nodiscard]] Register base_register ( ) const noexcept {
			return base_;
		}

		[[nodiscard]] Register index_register ( ) const noexcept {
			return index_;
		}

		[[nodiscard]] int scale ( ) const noexcept {
			return scale_;
		}

		[[nodiscard]] int64_t displacement ( ) const noexcept {
			return disp_;
		}
	};
	class Operand {
	private:
		const OperandType type_;
		union {
			Register reg_;
			int64_t imm_;
			MemoryOperand mem_;
		};
	public:
		Operand ( ) noexcept = default;
		Operand ( Operand&& other ) noexcept = default;
		Operand& operator=( Operand&& other ) noexcept = default;
		Operand ( const Operand& other ) = default;
		Operand& operator=( const Operand& other ) = default;
		~Operand ( ) = default;

		[[nodiscard]] OperandType type ( ) const noexcept {
			return type_;
		}

		[[nodiscard]] Register reg ( ) const noexcept {
		#ifdef SHOULD_BREAK_ON_INVALID_TYPE
			if ( type ( ) != OperandType::OP_REG ) {
				__debugbreak ( );
			}
		#endif
			return reg_;
		}

		[[nodiscard]] int64_t immediate ( ) const noexcept {
		#ifdef SHOULD_BREAK_ON_INVALID_TYPE
			if ( type ( ) != OperandType::OP_IMM ) {
				__debugbreak ( );
			}
		#endif
			return imm_;
		}

		[[nodiscard]] MemoryOperand memory ( ) const noexcept {
		#ifdef SHOULD_BREAK_ON_INVALID_TYPE
			if ( type ( ) != OperandType::OP_MEM ) {
				__debugbreak ( );
			}
		#endif
			return mem_;
		}
	};
	class Instruction {
	public:
		Instruction ( ) noexcept = default;

		explicit Instruction ( cs_insn* insn, uint64_t ip, csh handle ) noexcept
			: ip_ ( ip ) {
			if ( insn && insn->id != X86_INS_INVALID && insn->size > 0 ) {
				valid_ = true;
				id_ = insn->id;
				size_ = static_cast< uint8_t >( insn->size );

				mnemonic_str_ = insn->mnemonic;
				op_str_ = insn->op_str;

				if ( insn->detail ) {
					x86_detail_copy_ = insn->detail->x86;
					detail_copied_ = true;
				}
			}
		}

		Instruction ( Instruction&& other ) noexcept = default;
		Instruction& operator=( Instruction&& other ) noexcept = default;
		Instruction ( const Instruction& other ) = default;
		Instruction& operator=( const Instruction& other ) = default;
		~Instruction ( ) = default;

		// --- Accessors ---
		[[nodiscard]] inline uint64_t ip ( ) const noexcept {
			return ip_;
		}
		[[nodiscard]] inline uint8_t length ( ) const noexcept {
			return size_;
		}
		[[nodiscard]] inline bool is_valid ( ) const noexcept {
			return valid_;
		}
		[[nodiscard]] inline unsigned int mnemonic ( ) const noexcept {
			return id_;
		}

		// --- String Conversion ---
		[[nodiscard]] std::string to_string ( ) const noexcept {
			if ( !valid_ ) {
				// Use the stored IP even if invalid, maybe helps debugging
				return std::format ( "0x{:016x}: invalid instruction", ip_ );
			}
			// Use stored strings
			return std::format ( "0x{:016x}: {} {}", ip_, mnemonic_str_, op_str_ );
		}

		[[nodiscard]] std::string to_string_no_address ( ) const noexcept {
			if ( !valid_ ) {
				return "invalid instruction";
			}
			// Use stored strings
			return std::format ( "{} {}", mnemonic_str_, op_str_ );
		}

		[[nodiscard]] const std::string& mnemonic_string ( ) const noexcept {
			return mnemonic_str_;
		}
		[[nodiscard]] const std::string& operand_string ( ) const noexcept {
			return op_str_;
		}

		// --- Classification Methods ---
		[[nodiscard]] inline bool is_call ( ) const noexcept {
			return valid_ && id_ == X86_INS_CALL;
		}
		[[nodiscard]] inline bool is_conditional_branch ( ) const noexcept {
			return valid_ && ( id_ < X86_INS_ENDING ) &&
				( conditional_branch_bits [ id_ / 8 ] & ( 1 << ( id_ % 8 ) ) ) != 0;
		}
		[[nodiscard]] inline bool is_jump ( ) const noexcept {
			return valid_ && ( is_conditional_branch ( ) || id_ == X86_INS_JMP );
		}
		[[nodiscard]] inline bool is_unconditional_branch ( ) const noexcept {
			return valid_ && id_ == X86_INS_JMP;
		}
		[[nodiscard]] inline bool is_return ( ) const noexcept {
			return valid_ && ( id_ == X86_INS_RET || id_ == X86_INS_RETF || id_ == X86_INS_RETFQ ||
												 id_ == X86_INS_IRET || id_ == X86_INS_IRETD || id_ == X86_INS_IRETQ );
		}
		[[nodiscard]] inline bool is_int3 ( ) const noexcept {
			return valid_ && id_ == X86_INS_INT3;
		}
		[[nodiscard]] inline bool is_branching ( ) const noexcept {
			return is_jump ( ) || is_call ( );
		}
		[[nodiscard]] bool is_lea_or_mov ( ) const noexcept {
			return valid_ && ( id_ == X86_INS_MOV || id_ == X86_INS_LEA );
		}
		[[nodiscard]] bool is_indirect_call ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || id_ != X86_INS_CALL || x86_detail_copy_.op_count == 0 ) {
				return false;
			}
			const auto& op = x86_detail_copy_.operands [ 0 ];
			return op.type == X86_OP_REG || op.type == X86_OP_MEM;
		}

		[[nodiscard]] inline bool is_avx ( ) const noexcept {
			return valid_ && detail_copied_ && x86_detail_copy_.avx_cc != X86_AVX_CC_INVALID;
		}
		[[nodiscard]] inline bool is_nop ( ) const noexcept {
			return valid_ && id_ == X86_INS_NOP;
		}
		[[nodiscard]] inline bool is_halt ( ) const noexcept {
			return valid_ && id_ == X86_INS_HLT;
		}
		[[nodiscard]] inline bool affects_flags ( ) const noexcept {
			return valid_ && detail_copied_ && x86_detail_copy_.eflags != 0;
		}
		[[nodiscard]] inline bool is_rep ( ) const noexcept {
			return x86_detail_copy_.prefix [ 0 ];
		}		
		[[nodiscard]] inline bool is_lock ( ) const noexcept {
			return x86_detail_copy_.prefix [ 0 ];
		}

		// --- Operand Access ---
		[[nodiscard]] inline const cs_x86_op* operands ( ) const noexcept {
			return ( valid_ && detail_copied_ ) ? x86_detail_copy_.operands : nullptr;
		}
		[[nodiscard]] inline uint8_t operand_count ( ) const noexcept {
			return ( valid_ && detail_copied_ ) ? x86_detail_copy_.op_count : 0;
		}

		// --- Target Resolution ---
		// Note: These now rely on the copied detail structure

		/**
		 * @brief For immediate branches/calls, returns the immediate value (target address).
		 * @return Target address or 0 if not an immediate branch/call or details unavailable.
		 */
		[[nodiscard]] uint64_t near_branch_target ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || !is_branching ( ) || x86_detail_copy_.op_count == 0 ) {
				return 0;
			}
			const auto& op = x86_detail_copy_.operands [ 0 ];
			if ( op.type == X86_OP_IMM ) {
				return static_cast< uint64_t >( op.imm );
			}
			return 0;
		}

		[[nodiscard]] bool has_displacement ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || !is_branching ( ) || x86_detail_copy_.op_count == 0 ) {
				return 0;
			}

			const auto& op = x86_detail_copy_.operands [ 0 ];
			return op.type == X86_OP_MEM;
		}

		[[nodiscard]] bool has_immediate ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || !is_branching ( ) || x86_detail_copy_.op_count == 0 ) {
				return 0;
			}
			const auto& op = x86_detail_copy_.operands [ 0 ];
			return op.type == X86_OP_IMM;
		}

		/**
		 * @brief Resolves target for immediate and RIP-relative branches/calls.
		 * @return Target address or 0 if not resolvable statically or details unavailable.
		 */
		[[nodiscard]] uint64_t branch_target ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || !is_branching ( ) || x86_detail_copy_.op_count == 0 ) {
				return 0;
			}
			const auto& op = x86_detail_copy_.operands [ 0 ];
			if ( op.type == X86_OP_IMM ) {
				return static_cast< uint64_t >( op.imm );
			}
			else if ( op.type == X86_OP_MEM && op.mem.base == X86_REG_RIP ) {
				return ip_ + size_ + static_cast< uint64_t >( op.mem.disp );
			}

			return 0;
		}

		[[nodiscard]] x86_reg branch_target_register ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || !is_branching ( ) || x86_detail_copy_.op_count == 0 ) {
				return X86_REG_INVALID;
			}
			const auto& op = x86_detail_copy_.operands [ 0 ];
			if ( op.type == X86_OP_REG ) {
				return op.reg;
			}

			return X86_REG_INVALID;
		}

		/**
		 * @brief Computes the effective memory address for RIP-relative or absolute memory operands.
		 * @param mem_op The memory operand structure from the copied details.
		 * @return Computed address or 0 if not RIP-relative/absolute or details unavailable.
		 */
		[[nodiscard]] uint64_t compute_memory_address ( const x86_op_mem& mem_op ) const noexcept {
			// Can only resolve statically if RIP-relative or absolute displacement
			if ( mem_op.base == X86_REG_RIP ) {
				// Address = Next IP + Displacement
				return ip_ + size_ + static_cast< uint64_t >( mem_op.disp );
			}
			// Check for absolute address (no base, no index)
			if ( mem_op.base == X86_REG_INVALID && mem_op.index == X86_REG_INVALID ) {
				return static_cast< uint64_t >( mem_op.disp ); // The displacement is the absolute address
			}
			// Cannot resolve addresses involving other base/index registers statically
			return 0;
		}

		/**
		 * @brief For MOV/LEA instructions, resolves the target memory address if it's static (RIP-relative or absolute).
		 * @return Target address or 0 if not MOV/LEA, no memory operand, not statically resolvable, or details unavailable.
		 */
		[[nodiscard]] uint64_t resolve_memory_target ( ) const noexcept {
			if ( !valid_ || !detail_copied_ || ( id_ != X86_INS_MOV && id_ != X86_INS_LEA ) ) {
				return 0;
			}
			// Look through operands for a memory operand we can resolve
			for ( uint8_t i = 0; i < x86_detail_copy_.op_count; ++i ) {
				const auto& op = x86_detail_copy_.operands [ i ];
				if ( op.type == X86_OP_MEM ) {
					// Attempt to compute address statically
					return compute_memory_address ( op.mem );
				}
			}
			return 0; // No resolvable memory operand found
		}
		/**
		* @return Prefix is a uint8_t[4]
		*/
		[[nodiscard]] const uint8_t* prefix ( ) const noexcept {
			return x86_detail_copy_.prefix;
		}

	private:
		uint64_t ip_ = 0;
		unsigned int id_ = X86_INS_INVALID;
		uint8_t size_ = 0;
		bool valid_ = false;
		bool detail_copied_ = false;
		std::string mnemonic_str_; // Store strings to avoid lifetime issues
		std::string op_str_;
		cs_x86 x86_detail_copy_ = {}; // Store the detail struct content
	};


	// --- Decoder Class ---
	class Decoder {
	public:
		Decoder ( const uint8_t* data = nullptr, size_t size = 0, uint64_t base_addr = 0 ) noexcept
			: data_ ( data ), ip_ ( base_addr ), base_addr_ ( base_addr ), size_ ( static_cast< uint32_t >( size ) ),
			offset_ ( 0 ), remaining_size_ ( static_cast< uint32_t >( size ) ) {
			if ( data_ == nullptr || size_ == 0 ) {
				handle_ = 0; // Cannot initialize without data/size
				return;
			}
			auto result = cs_open ( CS_ARCH_X86, CS_MODE_64, &handle_ );
			if ( result != CS_ERR_OK ) {
				std::println ( "[engine - capstone] Failed to initialize decoder {}", ( int ) result );
				handle_ = 0;
			}
			else {
				// Enable detail only if handle is valid
				cs_option ( handle_, CS_OPT_DETAIL, CS_OPT_ON );
			}
		}

		// Rule of 5 for Decoder (handle needs careful management)
		Decoder ( const Decoder& ) = delete; // Disallow copying
		Decoder& operator=( const Decoder& ) = delete;

		Decoder ( Decoder&& other ) noexcept
			: handle_ ( std::exchange ( other.handle_, 0 ) ), // Transfer ownership
			data_ ( other.data_ ),
			ip_ ( other.ip_ ),
			base_addr_ ( other.base_addr_ ),
			size_ ( other.size_ ),
			offset_ ( other.offset_ ),
			remaining_size_ ( other.remaining_size_ ),
			last_successful_ip_ ( other.last_successful_ip_ ),
			last_successful_length_ ( other.last_successful_length_ ) { }

		Decoder& operator=( Decoder&& other ) noexcept {
			if ( this != &other ) {
				// Close existing handle if present
				if ( handle_ ) {
					cs_close ( &handle_ );
				}
				// Move resources from other
				handle_ = std::exchange ( other.handle_, 0 );
				data_ = other.data_;
				ip_ = other.ip_;
				base_addr_ = other.base_addr_;
				size_ = other.size_;
				offset_ = other.offset_;
				remaining_size_ = other.remaining_size_;
				last_successful_ip_ = other.last_successful_ip_;
				last_successful_length_ = other.last_successful_length_;
			}
			return *this;
		}


		~Decoder ( ) noexcept {
			if ( handle_ ) {
				cs_close ( &handle_ );
			}
		}

		void set_ip ( uint64_t ip ) noexcept {
			// Check if base_addr_ and size_ are valid before calculation
			if ( size_ > 0 && ip >= base_addr_ && ( ip - base_addr_ ) < size_ ) {
				ip_ = ip;
				offset_ = static_cast< uint32_t >( ip - base_addr_ );
				remaining_size_ = size_ - offset_;
			}
			else if ( size_ > 0 && ip == base_addr_ + size_ ) {
				// Allow setting IP exactly at the end
				ip_ = ip;
				offset_ = size_;
				remaining_size_ = 0;
			}
			else {
				// IP is out of bounds, set state to prevent decoding
				ip_ = ip; // Store the requested IP anyway
				offset_ = size_; // Point offset to end
				remaining_size_ = 0; // No remaining size
			}
		}

		[[nodiscard]] uint64_t ip ( ) const noexcept {
			return ip_;
		}
		[[nodiscard]] bool can_decode ( ) const noexcept {
			// Need valid handle and remaining data within buffer bounds
			return handle_ != 0 && remaining_size_ > 0 && offset_ < size_;
		}
		[[nodiscard]] const csh& get_handle ( ) const noexcept {
			return handle_;
		}

		[[nodiscard]] const Instruction& get_current_instruction ( ) const noexcept {
			return current_instruction_;
		}

		[[nodiscard]] inline Instruction decode ( ) noexcept {
			if ( !can_decode ( ) ) [[unlikely]] {
				return Instruction ( ); // Return invalid instruction
			}

			// Prepare for iteration
			const uint8_t* current_ptr = data_ + offset_;
			size_t code_size = remaining_size_; // Available size from current offset
			uint64_t address = ip_;             // Start address for this decode attempt

			// cs_malloc is required by cs_disasm_iter documentation
			cs_insn* insn = cs_malloc ( handle_ );
			if ( !insn ) { // Check malloc result
				std::println ( "[engine - capstone] cs_malloc failed" );
				return Instruction ( );
			}

			// Attempt to disassemble one instruction
			if ( cs_disasm_iter ( handle_, &current_ptr, &code_size, &address, insn ) ) [[likely]] {
				// Success!
				// Create our wrapper instruction (copies necessary data)
				current_instruction_ = Instruction ( insn, ip_, handle_ );

				// Update state *before* freeing Capstone instruction
				last_successful_ip_ = ip_;             // Store IP *before* advancing
				last_successful_length_ = insn->size; // Store length
				ip_ += insn->size;
				offset_ += insn->size;
				remaining_size_ -= insn->size;

				cs_free ( insn, 1 ); // Free the Capstone instruction
				return current_instruction_; // Return our valid wrapper
			}
			else {
				// Decoding failed at this position
				cs_free ( insn, 1 ); // Free the allocated instruction even on failure
				// Invalidate last successful? Or keep previous? Keep previous for now.
				// Stop further decoding by setting remaining size to 0?
				remaining_size_ = 0;
				return Instruction ( ); // Return invalid instruction
			}
		}

		// --- Added Functions ---
		/**
		 * @brief Gets the starting IP address of the last instruction successfully decoded by decode().
		 * @return IP address, or 0 if no instruction has been successfully decoded yet.
		 */
		[[nodiscard]] inline uint64_t last_successful_ip ( ) const noexcept {
			return last_successful_ip_;
		}

		/**
		 * @brief Gets the length in bytes of the last instruction successfully decoded by decode().
		 * @return Length in bytes, or 0 if no instruction has been successfully decoded yet.
		 */
		[[nodiscard]] inline uint16_t last_successful_length ( ) const noexcept {
			return last_successful_length_;
		}

		void reconfigure ( uint8_t* data, uint64_t size, uint64_t base_address = 0 ) noexcept {
			data_ = data;
			size_ = static_cast< uint32_t >( size );
			base_addr_ = base_address;
			remaining_size_ = static_cast< uint32_t >( size );
			offset_ = 0;
		}
		// --- End Added Functions ---


		const uint8_t* data_ = nullptr;
	private:
		csh handle_ = 0;
		Instruction current_instruction_ { };
		uint64_t ip_ = 0;
		uint64_t base_addr_ = 0;
		uint32_t size_ = 0;
		uint32_t offset_ = 0;
		uint32_t remaining_size_ = 0;
		uint64_t last_successful_ip_ = 0;
		uint16_t last_successful_length_ = 0;
	};
} // namespace capstone_wrapper
```

`shared/context.hpp`:

```hpp
#pragma once

#define USE_CAPSTONE
#define STATE_TRACKING true
#define GET_OPERAND_MASK(x, y) uint64_t x = ( 1ULL << ( y * 8 ) ) - 1; if ( y == 8 ) {x = 0xFFFFFFFFFFFFFFFFULL;}

#include <shared/capstone++.hpp>
#include <shared/portable_executable.hpp>
#include <shared/types.hpp>


template<typename T = void>
concept X64MODE = ( sizeof ( void* ) == 8 );

extern std::unique_ptr<PE::Parser> parser;
struct EmulationContext;

struct EmuOptions {
	uint8_t allow_reserved_write : 1;
	uint8_t enable_logging : 1;
	uint8_t exit_on_infinite_loop : 1;
	uint8_t reserved : 5;
};

using Handler = std::function<void ( capstone::Instruction&, EmulationContext&, InstructionEffect& )>;
using APIHandler = std::function<void ( capstone::Instruction&, EmulationContext&, InstructionEffect&, uint64_t )>;
using ImportHandler = std::function<void ( capstone::Instruction&, EmulationContext&, InstructionEffect& )>;

enum class Platform : uint64_t {
	WINDOWS = 0,
	LINUX = 1
};

struct alignas( 64 ) KCPU {
	/* HOT */
	CPUFlags cpu_flags {};
	std::array<uint64_t, KGPR_COUNT> registers;
	int64_t rsp_offset = 0;
	uint64_t tsc = 0;
	/* COLD */
	FPUStack fpu {};
	uint8_t current_privilege_level = 3;
	std::unique_ptr<std::array<uint512_t, 16>> avx_registers; // we need this because of the size, it will ruin cache locality

};

struct alignas( 64 ) WindowsCompat {
	std::unordered_map<uint64_t, std::pair<std::string, std::string>> imports;
	std::unordered_map<uint64_t, std::vector<uint64_t>> memory_writes;
	std::unordered_map<std::string, ImportHandler> import_handlers;
	std::unordered_map<uint64_t, APIHandler> api_hooks;
	std::map<uint16_t, uint64_t> io_ports;
	std::multimap<std::string, uint64_t> import_multi_map;
	HMODULE loaded_module = nullptr;
	uint64_t loaded_base_address = 0;
	uint64_t loaded_module_size = 0;

	uint64_t ntdll_base = 0;
	uint64_t kernel32_base = 0;
	uint64_t ldr_initialize_thunk = 0;
	uint64_t rtl_user_thread_start = 0;
	uint64_t ki_user_apc_dispatcher = 0;
	uint64_t ki_user_exception_dispatcher = 0;

	std::unique_ptr<_TEB64> teb = nullptr;

	std::unordered_map<uint64_t, LoadedModule> loaded_modules;
	uint64_t current_module_base = 0;

	void add_module ( HMODULE handle, uint64_t base, uint64_t size, const uint8_t* code ) {
		loaded_modules [ base ] = LoadedModule {
			.handle = handle,
			.base_address = base,
			.size = size,
			.decoder = std::make_unique<capstone::Decoder> ( code, size, base )
		};
		if ( !loaded_base_address ) {
			loaded_module = handle;
			loaded_base_address = base;
			loaded_module_size = size;
		}
	}
};

struct EmulationContext {
	EmulationContext ( );
	std::unique_ptr<KCPU> cpu;
	std::unique_ptr<WindowsCompat> windows;
	Platform host_os = Platform::WINDOWS;

	std::vector<capstone::Decoder*> decoder;

	/* metadata */

	bool exit_due_to_critical_error = false;
	bool exit_due_to_termination = false;

	/* Windows structures */

	/* Timing */
	void increment_tsc ( );

	std::string console_output;

	/* Module */
	void initialize_imports ( std::unique_ptr<PE::Parser>& parser );

	/* Stack */
	std::unique_ptr<uint8_t [ ], void( * )( uint8_t* )> rsp_base = { nullptr, [ ] ( uint8_t* ) { } };
	int64_t stack_allocated = 0x200000;

	/* Call Frames */
	std::vector<CallFrame> call_stack;
	void push_call_frame ( uint64_t ret_addr, InstructionEffect& effect );
	void pop_call_frame ( InstructionEffect& effect );

	/* State */
	EmuOptions options {
		.allow_reserved_write = false,
		.enable_logging = false,
		.exit_on_infinite_loop = true
	};

	/* Checks */
	bool is_within_stack_bounds ( uint64_t address, uint8_t size ) const noexcept;

	/* Getters & Setters */
	uint64_t get_access_mask ( x86_reg reg, uint8_t size ) const noexcept;
	uint8_t get_access_shift ( x86_reg reg, uint8_t size ) const noexcept;
	uint32_t get_eflags ( ) const noexcept;
	uint64_t get_rflags ( ) const noexcept;
	void set_eflags ( uint32_t rflags, InstructionEffect& effect ) noexcept;
	void set_rflags ( uint64_t rflags, InstructionEffect& effect ) noexcept;

	uint64_t get_reg ( x86_reg reg, uint8_t size = 8 ) const;
	uint64_t get_stack ( uint64_t address, uint8_t size = 8 ) const;
	uint128_t get_stack_128 ( uint64_t address ) const;
	uint64_t get_memory ( uint64_t addr, uint8_t size = 8 ) const;
	void allocate_kuser_shared_data ( InstructionEffect& effect );
	void set_rcx_to_ioport ( uint16_t port, InstructionEffect& effect );

	template <typename T>
	const T& get_reg ( x86_reg reg ) const;

	template <typename T>
	T& get_reg_mut ( x86_reg reg );

	uint128_t get_xmm_raw ( x86_reg reg ) const;
	void set_xmm_raw ( x86_reg reg, const uint128_t& value, InstructionEffect& effect );

	uint256_t get_ymm_raw ( x86_reg reg ) const;
	void set_ymm_raw ( x86_reg reg, const uint256_t& value, InstructionEffect& effect );

	uint512_t get_zmm_raw ( x86_reg reg ) const;
	void set_zmm_raw ( x86_reg reg, const uint512_t& value, InstructionEffect& effect );

	float get_xmm_float ( x86_reg reg ) const;
	void set_xmm_float ( x86_reg reg, float value, InstructionEffect& effect );

	double get_xmm_double ( x86_reg reg ) const;
	void set_xmm_double ( x86_reg reg, double value, InstructionEffect& effect );

	uint128_t get_memory_128 ( uint64_t addr ) const;
	void set_memory_128 ( uint64_t addr, const uint128_t& val, InstructionEffect& effect );	

	uint256_t get_memory_256 ( uint64_t addr ) const;
	void set_memory_256 ( uint64_t addr, const uint256_t& val, InstructionEffect& effect );	

	uint512_t get_memory_512 ( uint64_t addr ) const;
	void set_memory_512 ( uint64_t addr, const uint512_t& val, InstructionEffect& effect );

	void set_reg ( x86_reg reg, uint64_t val, uint8_t size, InstructionEffect& effect );
	void set_stack ( uint64_t offset, uint64_t val, InstructionEffect& effect, uint8_t size = 8 );
	void set_stack_128 ( uint64_t offset, uint128_t val, InstructionEffect& effect );
	void set_memory ( uint64_t addr, uint64_t val, uint8_t size, InstructionEffect& effect );

	void save_context ( CONTEXT* ms_context );
	/* Helpers */
	uint64_t translate_reg ( x86_reg reg, uint64_t value, uint8_t op_size ) const noexcept;
	x86_reg to_64bit_reg ( x86_reg reg ) const noexcept; // Helper to map sub-registers to their 64-bit parent for storage
	void dump_state ( ) const;
	bool is_string_at ( int64_t base, int64_t max_len ) const;
	void allocate_stack ( int64_t size, InstructionEffect& effect ) noexcept;

	/* State logging */
	InstructionEffect log_effect ( capstone::Instruction& instr );
	void log_reg_change ( InstructionEffect& effect, x86_reg reg, uint64_t old_val, uint64_t new_val, const char* op );
	void log_reg_change ( InstructionEffect& effect, x86_reg reg, int128_t old_val, int128_t new_val, const char* op );
	void log_flag_change ( InstructionEffect& effect, const char* flag, uint64_t old_val, uint64_t new_val );
	void log_stack_change ( InstructionEffect& effect, int64_t addr, uint64_t old_val, uint64_t new_val, uint8_t size = 8 );
	void log_mxcsr_flag_change ( InstructionEffect& effect, const char* flag_name, uint32_t old_val, uint32_t new_val );

	/* Update flags */
	void update_flags_add ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );
	void update_flags_adc ( uint64_t a, uint64_t b, uint64_t carry, uint8_t op_size, InstructionEffect& effect );
	void update_flags_sub ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );
	void update_flags_shl ( uint64_t val, uint64_t shift, uint8_t op_size, InstructionEffect& effect );
	void update_flags_sar ( uint64_t val, uint64_t shift, uint8_t op_size, InstructionEffect& effect );
	void update_flags_inc ( uint64_t val, uint8_t op_size, InstructionEffect& effect );
	void update_flags_dec ( uint64_t val, uint8_t op_size, InstructionEffect& effect );
	void update_flags_mul ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );
	void update_flags_div ( uint64_t dividend, uint64_t divisor, uint8_t op_size, InstructionEffect& effect );
	void update_flags_and ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );
	void update_flags_or ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );
	void update_flags_xor ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );
	void update_flags_not ( uint64_t val, uint8_t op_size, InstructionEffect& effect );
	void update_flags_shr ( uint64_t val, uint64_t shift, uint8_t op_size, InstructionEffect& effect );
	void update_flags_test ( uint64_t a, uint64_t b, uint8_t op_size, InstructionEffect& effect );

	template<std::floating_point T>
	void update_mxcsr_arithmetic ( T a, T b, T result, InstructionEffect& effect );
	template<std::floating_point T>
	void update_flags_for_compare ( T a, T b, bool is_unorderd_quiet, InstructionEffect& effect );
	template<std::floating_point F, typename I> // F = float/double, I = int32/int64
	void update_mxcsr_conversion_float_to_int ( F src, I dst, bool is_truncate, InstructionEffect& effect );
	template<typename I, std::floating_point F> // I = int32/int64, F = float/double
	void update_mxcsr_conversion_int_to_float ( I src, F dst, InstructionEffect& effect );
	void update_mxcsr_conversion ( float src, double dst, InstructionEffect& effect );
	void update_mxcsr_conversion ( double src, float dst, InstructionEffect& effect );
	template<std::floating_point T>
	void update_mxcsr_sqrt ( T src, T result, InstructionEffect& effect );

	/* Exception related */
	bool is_alignment_check_enabled ( ) const noexcept;
	static void initialize_exception_table ( ) noexcept;

	capstone::Decoder* get_decoder_for_address ( uint64_t addr ) {
		for ( const auto& [base, mod] : windows->loaded_modules ) {
			if ( addr >= base && addr < base + mod.size ) {
				return mod.decoder.get ( );
			}
		}
		return decoder.back ( ); // Fallback to default decoder
	}

	int get_fpu_phys_idx ( int sti ) const {
		return ( cpu->fpu.fpu_top + sti ) % 8;
	}
	void set_fpu_tag ( int phys_idx, uint8_t tag ) {
		int shift = phys_idx * 2;
		cpu->fpu.fpu_tag_word = ( cpu->fpu.fpu_tag_word & ~( 0b11 << shift ) ) | ( tag << shift );
	}
	uint8_t get_fpu_tag ( int phys_idx ) const {
		return ( cpu->fpu.fpu_tag_word >> ( phys_idx * 2 ) ) & 0b11;
	}
	void update_fsw_top ( ) {
		cpu->fpu.fpu_status_word = ( cpu->fpu.fpu_status_word & ~FSW_TOP_MASK ) | ( ( cpu->fpu.fpu_top & 0b111 ) << FSW_TOP_SHIFT );
	}

	// Checks determined FSW flags against FCW masks and raises OS exception if needed.
	void check_fpu_exception ( uint16_t determined_fsw_flags ) {
		cpu->fpu.fpu_status_word |= determined_fsw_flags; // Set determined flags in actual FSW

		// Check if any *unmasked* exception occurred
		bool unmasked_occurred = false;
		if ( ( determined_fsw_flags & FSW_IE ) && !( cpu->fpu.fpu_control_word & FCW_IM ) ) unmasked_occurred = true;
		if ( ( determined_fsw_flags & FSW_DE ) && !( cpu->fpu.fpu_control_word & FCW_DM ) ) unmasked_occurred = true;
		if ( ( determined_fsw_flags & FSW_ZE ) && !( cpu->fpu.fpu_control_word & FCW_ZM ) ) unmasked_occurred = true;
		if ( ( determined_fsw_flags & FSW_OE ) && !( cpu->fpu.fpu_control_word & FCW_OM ) ) unmasked_occurred = true;
		if ( ( determined_fsw_flags & FSW_UE ) && !( cpu->fpu.fpu_control_word & FCW_UM ) ) unmasked_occurred = true;
		if ( ( determined_fsw_flags & FSW_PE ) && !( cpu->fpu.fpu_control_word & FCW_PM ) ) unmasked_occurred = true;
		// Stack Fault (#IS involving stack) is generally unmaskable
		if ( determined_fsw_flags & FSW_SF ) unmasked_occurred = true;

		if ( unmasked_occurred ) {
			cpu->fpu.fpu_status_word |= FSW_ES; // Set Error Summary
			uint64_t faulting_rip = decoder.back ( )->last_successful_ip ( );
			std::println ( "!!!! Unmasked FPU Exception Flags: 0x{:04x} !!!!", determined_fsw_flags );

			// Map to Windows STATUS_FLOAT_* code
			DWORD win_code = EXCEPTION_FLT_INVALID_OPERATION; // Default
			if ( ( determined_fsw_flags & FSW_SF ) ) win_code = EXCEPTION_FLT_STACK_CHECK; // Map #IS Stack fault
			else if ( ( determined_fsw_flags & FSW_ZE ) && !( cpu->fpu.fpu_control_word & FCW_ZM ) ) win_code = EXCEPTION_FLT_DIVIDE_BY_ZERO;
			else if ( ( determined_fsw_flags & FSW_OE ) && !( cpu->fpu.fpu_control_word & FCW_OM ) ) win_code = EXCEPTION_FLT_OVERFLOW;
			else if ( ( determined_fsw_flags & FSW_UE ) && !( cpu->fpu.fpu_control_word & FCW_UM ) ) win_code = EXCEPTION_FLT_UNDERFLOW;
			else if ( ( determined_fsw_flags & FSW_DE ) && !( cpu->fpu.fpu_control_word & FCW_DM ) ) win_code = EXCEPTION_FLT_DENORMAL_OPERAND;
			else if ( ( determined_fsw_flags & FSW_PE ) && !( cpu->fpu.fpu_control_word & FCW_PM ) ) win_code = EXCEPTION_FLT_INEXACT_RESULT; // Often masked
			// Prioritize stack, then other specific unmasked flags, then general invalid

			GuestExceptionInfo ex;
			ex.set_exception ( win_code, faulting_rip );
			throw ex;
		}
	}
	uint8_t classify_fpu_operand ( const float80_t& val ) const {
		using namespace boost::multiprecision;
		int c = fpclassify ( val );
		switch ( c ) {
			case FP_NAN:       return FPU_TAG_SPECIAL;
			case FP_INFINITE:  return FPU_TAG_SPECIAL;
			case FP_ZERO:      return FPU_TAG_ZERO;
			case FP_SUBNORMAL: return FPU_TAG_SPECIAL; // Denormals treated as Special for tag
			case FP_NORMAL:    return FPU_TAG_VALID;
			default:           return FPU_TAG_SPECIAL; // Should not happen
		}
	}

	int get_std_rounding_mode ( ) const {
		int fcw_round = ( cpu->fpu.fpu_control_word & FCW_RC_MASK ) >> FCW_RC_SHIFT;
		switch ( fcw_round ) {
			case 0: return FE_TONEAREST;
			case 1: return FE_DOWNWARD;
			case 2: return FE_UPWARD;
			case 3: return FE_TOWARDZERO;
			default: return FE_TONEAREST;
		}
	}

	float80_t read_float80_from_memory ( uint64_t addr, InstructionEffect& effect );
	void write_float80_to_memory ( uint64_t addr, const float80_t& val, InstructionEffect& effect );
};


// Instruction Handlers
namespace handlers
{
	/* Data handlers */
	inline Handler mov = nullptr;
	inline Handler movsw = nullptr;
	inline Handler movsd = nullptr;
	inline Handler movsq = nullptr;
	inline Handler movabs = nullptr;
	inline Handler movaps = nullptr;
	inline Handler movzx = nullptr;
	inline Handler push = nullptr;
	inline Handler pushfq = nullptr;
	inline Handler pop = nullptr;
	inline Handler popfq = nullptr;
	inline Handler lea = nullptr;
	inline Handler movsx = nullptr;
	inline Handler sahf = nullptr;
	inline Handler lahf = nullptr;
	inline Handler movsxd = nullptr;
	inline Handler xchg = nullptr;
	inline Handler stos = nullptr;
	inline Handler punpcklqdq = nullptr;
	inline Handler prefetchw = nullptr;
	inline Handler psrldq = nullptr;

	/* Arithmetic handlers */

	inline Handler add = nullptr;
	inline Handler sub = nullptr;
	inline Handler inc = nullptr;
	inline Handler dec = nullptr;
	inline Handler mul = nullptr;
	inline Handler imul = nullptr;
	inline Handler div = nullptr;
	inline Handler idiv = nullptr;
	inline Handler cdq = nullptr;
	inline Handler cdqe = nullptr;
	inline Handler adc = nullptr;
	inline Handler neg = nullptr;
	inline Handler sbb = nullptr;



	/**** Float airthmetic */
	inline Handler movsb = nullptr;
	inline Handler movss = nullptr;
	inline Handler movq = nullptr;
	inline Handler movups = nullptr;
	inline Handler movdqu = nullptr;
	inline Handler addss = nullptr;
	inline Handler cmpss = nullptr;
	inline Handler mulss = nullptr;
	inline Handler divss = nullptr;
	inline Handler sqrtss = nullptr;
	inline Handler sqrtsd = nullptr;
	inline Handler cvtss2si = nullptr;
	inline Handler subss = nullptr;
	inline Handler minss = nullptr;
	inline Handler maxss = nullptr;
	inline Handler comiss = nullptr;
	inline Handler roundss = nullptr;
	inline Handler rcpss = nullptr;
	inline Handler rsqrtss = nullptr;
	inline Handler ucomiss = nullptr;
	inline Handler cvtsi2ss = nullptr;
	inline Handler cvttss2si = nullptr;
	inline Handler cvtss2sd = nullptr;
	inline Handler cvtsd2ss = nullptr;
	inline Handler andps = nullptr;
	inline Handler orps = nullptr;
	inline Handler xorps = nullptr;
	inline Handler movhlps = nullptr;
	inline Handler unpcklps = nullptr;
	inline Handler cvtsi2sd = nullptr;
	inline Handler mulsd = nullptr;
	inline Handler comisd = nullptr;

	inline Handler fld = nullptr;
	inline Handler fprem = nullptr;
	inline Handler fstp = nullptr;
	inline Handler ffree = nullptr;
	inline Handler fincstp = nullptr;
	inline Handler fmul = nullptr;
	inline Handler fmulp = nullptr;



	/* Logical handlers */
	inline Handler and_ = nullptr;
	inline Handler xadd = nullptr;
	inline Handler or_ = nullptr;
	inline Handler xor_ = nullptr;
	inline Handler not_ = nullptr;
	inline Handler shl = nullptr;
	inline Handler shld = nullptr;
	inline Handler shr = nullptr;
	inline Handler shrd = nullptr;
	inline Handler sar = nullptr;
	inline Handler sal = nullptr;
	inline Handler cmovo = nullptr;
	inline Handler cmovnl = nullptr;
	inline Handler cmovbe = nullptr;
	inline Handler cmovz = nullptr;
	inline Handler cmovle = nullptr;
	inline Handler cmovl = nullptr;
	inline Handler cmovnp = nullptr;
	inline Handler cmovns = nullptr;
	inline Handler cmovp = nullptr;
	inline Handler cmovnb = nullptr;
	inline Handler cmovno = nullptr;
	inline Handler cmovs = nullptr;
	inline Handler cmovnz = nullptr;
	inline Handler cmovnle = nullptr;
	inline Handler cmovnbe = nullptr;
	inline Handler cmovb = nullptr;
	inline Handler movlhps = nullptr;
	inline Handler rdrand = nullptr;

	/* Control-flow altering */
	inline Handler cmp = nullptr;
	inline Handler cmpxchg = nullptr;
	inline Handler cmpxchg16b = nullptr;
	inline Handler test = nullptr;
	inline Handler call = nullptr;
	inline Handler ret = nullptr;

	/* JX Handlers */
	inline Handler jmp = nullptr;
	inline Handler je = nullptr;
	inline Handler jnbe = nullptr;
	inline Handler jne = nullptr;
	inline Handler jg = nullptr;
	inline Handler jl = nullptr;
	inline Handler jnb = nullptr;
	inline Handler jb = nullptr;
	inline Handler jns = nullptr;
	inline Handler jnl = nullptr;
	inline Handler jo = nullptr;
	inline Handler jno = nullptr;
	inline Handler jbe = nullptr;
	inline Handler js = nullptr;
	inline Handler ja = nullptr;
	inline Handler jae = nullptr;
	inline Handler jge = nullptr;
	inline Handler jle = nullptr;
	inline Handler jp = nullptr;
	inline Handler jnp = nullptr;
	inline Handler jcxz = nullptr;
	inline Handler jecxz = nullptr;
	inline Handler jrcxz = nullptr;

	/* Function related */
	inline Handler enter = nullptr;
	inline Handler leave = nullptr;
	inline Handler nop = nullptr;

	/* Bit operations */
	inline Handler bzhi = nullptr;
	inline Handler andn = nullptr;
	inline Handler bextr = nullptr;
	inline Handler ror = nullptr;
	inline Handler rol = nullptr;
	inline Handler popcnt = nullptr;
	inline Handler tzcnt = nullptr;
	inline Handler bswap = nullptr;
	inline Handler bsr = nullptr;
	inline Handler setb = nullptr;
	inline Handler setbe = nullptr;
	inline Handler setnp = nullptr;
	inline Handler setnl = nullptr;
	inline Handler sets = nullptr;
	inline Handler seto = nullptr;
	inline Handler setz = nullptr;
	inline Handler setnb = nullptr;
	inline Handler setno = nullptr;
	inline Handler rcr = nullptr;
	inline Handler rcl = nullptr;
	inline Handler bt = nullptr;
	inline Handler bts = nullptr;
	inline Handler setp = nullptr;
	inline Handler setle = nullptr;
	inline Handler setnle = nullptr;
	inline Handler setns = nullptr;
	inline Handler setl = nullptr;
	inline Handler setnbe = nullptr;
	inline Handler setnz = nullptr;
	inline Handler cli = nullptr;
	inline Handler btr = nullptr;
	inline Handler cbw = nullptr;
	inline Handler cqo = nullptr;
	inline Handler btc = nullptr;
	inline Handler cwd = nullptr;
	inline Handler cwde = nullptr;
	inline Handler cld = nullptr;
	inline Handler clc = nullptr;
	inline Handler clui = nullptr;
	inline Handler cmc = nullptr;
	inline Handler stc = nullptr;
	inline Handler bsf = nullptr;

	/* AVX */
	inline Handler vpxor = nullptr;
	inline Handler vpcmpeqw = nullptr;
	inline Handler vpmovmskb = nullptr;
	inline Handler vzeroupper = nullptr;
	inline Handler vinsertf128 = nullptr;
	inline Handler vmovups = nullptr;
	inline Handler vmovaps = nullptr;
	inline Handler vmovdqu = nullptr;

	/* Other */
	inline Handler rdtsc = nullptr;
	inline Handler cpuid = nullptr;
	inline Handler xgetbv = nullptr;
	inline Handler syscall = nullptr;
	inline Handler bound = nullptr;
	inline Handler hlt = nullptr;
	inline Handler stmxcsr = nullptr;
	inline Handler ldmxcsr = nullptr;
	inline Handler fnstcw = nullptr;
	inline Handler int_ = nullptr;
	inline Handler int1 = nullptr;
	inline Handler int3 = nullptr;
	inline Handler fxsave = nullptr;
	inline Handler fxrstor = nullptr;

	/* IO */
	inline Handler io_in = nullptr;
	inline Handler io_out = nullptr;
	inline Handler outx = nullptr;

	namespace winapi
	{
		inline APIHandler forward = nullptr;

		/* Processor related */
		inline APIHandler IsProcessorFeaturePresent = nullptr;

		/* Module related*/
		inline APIHandler LoadLibraryA = nullptr;
		inline APIHandler LoadLibraryW = nullptr;
		inline APIHandler LoadLibraryExA = nullptr;
		inline APIHandler LoadLibraryExW = nullptr;

		/* Procedure related */
		inline APIHandler GetProcAddress = nullptr;

		/* Critical sections */
		inline APIHandler InitializeCriticalSectionAndSpinCount = nullptr;
		inline APIHandler InitializeCriticalSectionEx = nullptr;
		inline APIHandler RtlInitializeCriticalSectionEx = nullptr;
		inline APIHandler RtlInitializeCriticalSectionAndSpinCount = nullptr;
		inline APIHandler RtlEnterCriticalSection = nullptr;
		inline APIHandler RtlLeaveCriticalSection = nullptr;
		inline APIHandler RtlDeleteCriticalSection = nullptr;

		/* CRT */
		inline APIHandler InitializeSListHead = nullptr;

		/* FLS & TLS */
		inline APIHandler FlsAlloc = nullptr;
		inline APIHandler FlsGetValue = nullptr;
		inline APIHandler FlsSetValue = nullptr;
		inline APIHandler FlsFree = nullptr;

		inline APIHandler TlsAlloc = nullptr;
		inline APIHandler TlsGetValue = nullptr;
		inline APIHandler TlsSetValue = nullptr;
		inline APIHandler TlsFree = nullptr;

		/* Memory related */
		inline APIHandler VirtualProtect = nullptr;
		inline APIHandler GetProcessHeap = nullptr;

		inline APIHandler GetLastError = nullptr;

	};
}

extern InstructionExceptionInfo g_instruction_exception_table [ X86_INS_ENDING ];

struct StateSnapshot {
	std::array<uint64_t, KGPR_COUNT> registers;
	std::unordered_map<uint64_t, uint64_t> memory; // Stack and memory
	int64_t rsp_value;
	std::unordered_set<x86_reg> modified_regs; // Normalized
	std::unordered_set<uint64_t> modified_mem;
};


extern template void EmulationContext::update_mxcsr_arithmetic<float> ( float, float, float, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_arithmetic<double> ( double, double, double, InstructionEffect& );
extern template void EmulationContext::update_flags_for_compare<float> ( float, float, bool, InstructionEffect& );
extern template void EmulationContext::update_flags_for_compare<double> ( double, double, bool, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_float_to_int<float, int32_t> ( float, int32_t, bool, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_float_to_int<float, int64_t> ( float, int64_t, bool, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_float_to_int<double, int32_t> ( double, int32_t, bool, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_float_to_int<double, int64_t> ( double, int64_t, bool, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_int_to_float<int32_t, float> ( int32_t, float, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_int_to_float<int64_t, float> ( int64_t, float, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_int_to_float<int32_t, double> ( int32_t, double, InstructionEffect& );
extern template void EmulationContext::update_mxcsr_conversion_int_to_float<int64_t, double> ( int64_t, double, InstructionEffect& );
extern template const uint8_t& EmulationContext::get_reg<uint8_t> ( x86_reg ) const;
extern template const uint16_t& EmulationContext::get_reg<uint16_t> ( x86_reg ) const;
extern template const uint32_t& EmulationContext::get_reg<uint32_t> ( x86_reg ) const;
extern template const uint64_t& EmulationContext::get_reg<uint64_t> ( x86_reg ) const;
extern template uint8_t& EmulationContext::get_reg_mut<uint8_t> ( x86_reg );
extern template uint16_t& EmulationContext::get_reg_mut<uint16_t> ( x86_reg );
extern template uint32_t& EmulationContext::get_reg_mut<uint32_t> ( x86_reg );
extern template uint64_t& EmulationContext::get_reg_mut<uint64_t> ( x86_reg );

GuestExceptionInfo check_instruction_exceptions (
		EmulationContext& state,
		class capstone::Instruction& instr,
		const PreCheckInfo& check_info
);

// --- Forward declarations for post-checkers ---
GuestExceptionInfo check_post_execution_arithmetic (
		EmulationContext& state,
		const InstructionExceptionInfo& baseInfo,
		uint64_t ip,
		uint8_t op_size // Pass operand size used by the instruction
);

GuestExceptionInfo check_post_execution_fpu_simd (
		EmulationContext& state,
		const InstructionExceptionInfo& baseInfo, // Needed to know if instr could raise FP exceptions
		uint64_t ip
);

void populate_pre_check_info (
		PreCheckInfo& check_info,           // Out parameter
		EmulationContext& state,            // Current state
		capstone::Instruction& instr, // Decoded instruction
		const InstructionExceptionInfo& baseInfo // Static info from table
);

void setup_guest_exception_dispatch ( EmulationContext& state, const GuestExceptionInfo& ex_info );

inline const std::unordered_map<x86_insn, Handler*> instruction_handlers = {
	// Data movement
	{X86_INS_MOV, &handlers::mov},
	{X86_INS_MOVABS, &handlers::movabs},
	{X86_INS_MOVAPS, &handlers::movaps},
	{X86_INS_MOVUPS, &handlers::movups},
	{X86_INS_MOVDQU, &handlers::movdqu},
	{X86_INS_MOVQ, &handlers::movq},
	{X86_INS_MOVZX, &handlers::movzx},
	{X86_INS_MOVSX, &handlers::movsx},
	{X86_INS_PUSH, &handlers::push},
	{X86_INS_PUSHFQ, &handlers::pushfq},
	{X86_INS_POPFQ, &handlers::popfq},
	{X86_INS_POP, &handlers::pop},
	{X86_INS_LEA, &handlers::lea},
	{X86_INS_SAHF, &handlers::sahf},
	{X86_INS_LAHF, &handlers::lahf},
	{X86_INS_MOVSXD, &handlers::movsxd},
	{X86_INS_XCHG, &handlers::xchg},
	{X86_INS_STOSB, &handlers::stos},
	{X86_INS_STOSW, &handlers::stos},
	{X86_INS_STOSD, &handlers::stos},
	{X86_INS_STOSQ, &handlers::stos},
	{X86_INS_PUNPCKLQDQ , &handlers::punpcklqdq},
	{X86_INS_PREFETCHW , &handlers::prefetchw},
	{X86_INS_PSRLDQ , &handlers::psrldq},
	// Arithmetic
	{X86_INS_ADD, &handlers::add},
	{X86_INS_XADD, &handlers::xadd},
	{X86_INS_SUB, &handlers::sub},
	{X86_INS_INC, &handlers::inc},
	{X86_INS_DEC, &handlers::dec},
	{X86_INS_MUL, &handlers::mul},
	{X86_INS_IMUL, &handlers::imul},
	{X86_INS_DIV, &handlers::div},
	{X86_INS_IDIV, &handlers::idiv},
	{X86_INS_CDQ, &handlers::cdq},
	{X86_INS_CDQE, &handlers::cdqe},
	{X86_INS_ADC, &handlers::adc},
	{X86_INS_NEG, &handlers::neg},
	{X86_INS_SBB, &handlers::sbb},

	// Logical and shifts
	{X86_INS_AND, &handlers::and_},
	{X86_INS_OR, &handlers::or_},
	{X86_INS_XOR, &handlers::xor_},
	{X86_INS_NOT, &handlers::not_},
	{X86_INS_SHL, &handlers::shl},
	{X86_INS_SHLD, &handlers::shld},
	{X86_INS_SHR, &handlers::shr},
	{X86_INS_SHRD, &handlers::shrd},
	{X86_INS_SAR, &handlers::sar},
	{X86_INS_SAL, &handlers::sal},
	{X86_INS_MOVLHPS , &handlers::movlhps},

	// Conditional moves
	{X86_INS_CMOVO, &handlers::cmovo},
	{X86_INS_CMOVGE, &handlers::cmovnl},
	{X86_INS_CMOVBE, &handlers::cmovbe},
	{X86_INS_CMOVE, &handlers::cmovz},
	{X86_INS_CMOVLE, &handlers::cmovle},
	{X86_INS_CMOVL, &handlers::cmovl},
	{X86_INS_CMOVNP, &handlers::cmovnp},
	{X86_INS_CMOVNS, &handlers::cmovns},
	{X86_INS_CMOVP, &handlers::cmovp},
	{X86_INS_CMOVAE, &handlers::cmovnb},
	{X86_INS_CMOVNO, &handlers::cmovno},
	{X86_INS_CMOVS, &handlers::cmovs},
	{X86_INS_CMOVNE, &handlers::cmovnz},
	{X86_INS_CMOVA, &handlers::cmovnbe},
	{X86_INS_CMOVG, &handlers::cmovnle},
	{X86_INS_CMOVB, &handlers::cmovb},
	{X86_INS_RDRAND, &handlers::rdrand},

	// Comparisons and jumps
	{X86_INS_CMP, &handlers::cmp},
	{X86_INS_CMPXCHG, &handlers::cmpxchg},
	{X86_INS_CMPXCHG16B, &handlers::cmpxchg16b},
	{X86_INS_TEST, &handlers::test},
	{X86_INS_CALL, &handlers::call},
	{X86_INS_RET, &handlers::ret},
	{X86_INS_JMP, &handlers::jmp},
	{X86_INS_JE, &handlers::je},
	{X86_INS_JNE, &handlers::jne},
	{X86_INS_JA, &handlers::jnbe},
	{X86_INS_JG, &handlers::jg},
	{X86_INS_JL, &handlers::jl},
	{X86_INS_JAE, &handlers::jnb},
	{X86_INS_JB, &handlers::jb},
	{X86_INS_JNS, &handlers::jns},
	{X86_INS_JGE, &handlers::jnl},
	{X86_INS_JO, &handlers::jo},
	{X86_INS_JNO, &handlers::jno},
	{X86_INS_JS, &handlers::js},
	{X86_INS_JBE, &handlers::jbe},
	{X86_INS_JLE, &handlers::jle},
	{X86_INS_JP, &handlers::jp},
	{X86_INS_JNP, &handlers::jnp},
	{X86_INS_JCXZ, &handlers::jcxz},
	{X86_INS_JECXZ, &handlers::jecxz},
	{X86_INS_JRCXZ, &handlers::jrcxz},

	// Stack and control
	{X86_INS_ENTER, &handlers::enter},
	{X86_INS_LEAVE, &handlers::leave},
	{X86_INS_NOP, &handlers::nop},

	// Bit manipulation and misc
	{X86_INS_BZHI, &handlers::bzhi},
	{X86_INS_ANDN, &handlers::andn},
	{X86_INS_BEXTR, &handlers::bextr},
	{X86_INS_ROR, &handlers::ror},
	{X86_INS_ROL, &handlers::rol},
	{X86_INS_POPCNT, &handlers::popcnt},
	{X86_INS_TZCNT, &handlers::tzcnt },
	{X86_INS_BSWAP, &handlers::bswap},
	{X86_INS_BSR, &handlers::bsr },
	{X86_INS_SETB, &handlers::setb},
	{X86_INS_SETBE, &handlers::setbe},
	{X86_INS_SETNP, &handlers::setnp},
	{X86_INS_SETGE, &handlers::setnl},
	{X86_INS_SETS, &handlers::sets},
	{X86_INS_SETO, &handlers::seto},
	{X86_INS_SETE, &handlers::setz},
	{X86_INS_SETAE, &handlers::setnb},
	{X86_INS_SETNO, &handlers::setno},
	{X86_INS_RCR, &handlers::rcr},
	{X86_INS_RCL, &handlers::rcl},
	{X86_INS_BT, &handlers::bt},
	{X86_INS_SETP, &handlers::setp},
	{X86_INS_SETLE, &handlers::setle},
	{X86_INS_SETG, &handlers::setnle},
	{X86_INS_SETNS, &handlers::setns},
	{X86_INS_SETL, &handlers::setl},
	{X86_INS_SETA, &handlers::setnbe},
	{X86_INS_SETNE, &handlers::setnz},
	{X86_INS_CLI, &handlers::cli},
	{X86_INS_BTR, &handlers::btr},
	{X86_INS_BTS, &handlers::bts},
	{X86_INS_CBW, &handlers::cbw},
	{X86_INS_CQO, &handlers::cqo},
	{X86_INS_BTC, &handlers::btc},
	{X86_INS_CWD, &handlers::cwd},
	{X86_INS_CWDE, &handlers::cwde},
	{X86_INS_CLD, &handlers::cld},
	{X86_INS_CLC, &handlers::clc},
	{X86_INS_CMC, &handlers::cmc},
	{X86_INS_STC, &handlers::stc},
	{ X86_INS_BSF, &handlers::bsf },

	// SIMD

	{ X86_INS_MOVSB, &handlers::movsb },
	{ X86_INS_MOVSW, &handlers::movsw },
	{ X86_INS_MOVSQ, &handlers::movsq },
	{ X86_INS_MOVSD, &handlers::movsd },

	{X86_INS_MOVSS, &handlers::movss},
	{X86_INS_ADDSS, &handlers::addss},
	{X86_INS_CMPSS, &handlers::cmpss},
	{X86_INS_MULSS, &handlers::mulss},
	{X86_INS_DIVSS, &handlers::divss},
	{X86_INS_SQRTSS, &handlers::sqrtss},
	{X86_INS_SQRTSD, &handlers::sqrtsd},
	{X86_INS_CVTSS2SI, &handlers::cvtss2si},
	{X86_INS_SUBSS, &handlers::subss},
	{X86_INS_MINSS, &handlers::minss},
	{X86_INS_MAXSS, &handlers::maxss},
	{X86_INS_COMISS, &handlers::comiss},
	{X86_INS_ROUNDSS, &handlers::roundss},
	{X86_INS_RCPSS, &handlers::rcpss},
	{X86_INS_RSQRTSS, &handlers::rsqrtss},
	{X86_INS_UCOMISS, &handlers::ucomiss},
	{X86_INS_CVTSI2SS, &handlers::cvtsi2ss},
	{X86_INS_CVTTSS2SI, &handlers::cvttss2si},
	{X86_INS_CVTSS2SD, &handlers::cvtss2sd},
	{X86_INS_CVTSD2SS, &handlers::cvtsd2ss},
	{X86_INS_ANDPS, &handlers::andps},
	{X86_INS_ORPS, &handlers::orps},
	{X86_INS_XORPS, &handlers::xorps},
	{X86_INS_MOVHLPS, &handlers::movhlps},
	{X86_INS_UNPCKLPS, &handlers::unpcklps},
	{X86_INS_CVTSI2SD, &handlers::cvtsi2sd},
	{X86_INS_MULSD, &handlers::mulsd},
	{X86_INS_COMISD, &handlers::comisd},
	{X86_INS_FLD, &handlers::fld },
	{X86_INS_FPREM, &handlers::fprem },
	{X86_INS_FSTP, &handlers::fstp },
	{X86_INS_FFREE, &handlers::ffree },
	{X86_INS_FINCSTP, &handlers::fincstp },
	{X86_INS_FMUL, &handlers::fmul },
	{X86_INS_FMULP, &handlers::fmulp },

	// AVX
	{X86_INS_VPXOR, &handlers::vpxor },
	{X86_INS_VPCMPEQW, &handlers::vpcmpeqw },
	{X86_INS_VPMOVMSKB, &handlers::vpmovmskb },
	{X86_INS_VZEROUPPER, &handlers::vzeroupper },
	{X86_INS_VINSERTF128, &handlers::vinsertf128 },
	{X86_INS_VMOVUPS, &handlers::vmovups },
	{X86_INS_VMOVAPS, &handlers::vmovaps },
	{X86_INS_VMOVDQU, &handlers::vmovdqu },

	// System & Others
	{X86_INS_RDTSC, &handlers::rdtsc},
	{X86_INS_CPUID, &handlers::cpuid},
	{X86_INS_XGETBV, &handlers::xgetbv},
	{X86_INS_SYSCALL, &handlers::syscall},
	{X86_INS_BOUND, &handlers::bound},
	{X86_INS_FXSAVE, &handlers::fxsave },
	{X86_INS_FXRSTOR, &handlers::fxrstor },
	{X86_INS_INT, &handlers::int_},
	{X86_INS_INT1, &handlers::int1},
	{X86_INS_INT3, &handlers::int3},
	{X86_INS_HLT, &handlers::hlt},
	{X86_INS_STMXCSR, &handlers::stmxcsr},
	{X86_INS_LDMXCSR, &handlers::ldmxcsr},
	{ X86_INS_FNSTCW, &handlers::fnstcw },

	{ X86_INS_IN, &handlers::io_in },
	{ X86_INS_OUT, &handlers::io_out },
	{ X86_INS_OUTSB, &handlers::outx },
	{ X86_INS_OUTSW, &handlers::outx },
	{ X86_INS_OUTSD, &handlers::outx },

};
```

`shared/module_loader.hpp`:

```hpp
#pragma once

#include <shared/portable_executable.hpp>

#include <string>
#include <filesystem>
#include <memory>

class KModule {
private:
	PE::Parser parser;
	std::unique_ptr<uint8_t [ ]> mapping;
public:
	KModule ( ) = delete;
	KModule ( std::filesystem::path dll_path );
};
```

`shared/portable_executable.hpp`:

```hpp
#pragma once

#include <cstdint>
#include <vector>
#include <array>
#include <string>
#include <fstream>
#include <stdexcept>
#include <optional>
#include <tuple>
#include <ranges>
#include <span>
#include <map>
#include "capstone++.hpp"

// Packed structures using #pragma pack
#pragma pack(push, 1)

struct DosHeader {
  uint16_t e_magic;       // Magic number "MZ" (0x5A4D)
  uint16_t e_cblp;        // Bytes on last page of file
  uint16_t e_cp;          // Pages in file
  uint16_t e_crlc;        // Relocations
  uint16_t e_cparhdr;     // Size of header in paragraphs
  uint16_t e_minalloc;    // Minimum extra paragraphs needed
  uint16_t e_maxalloc;    // Maximum extra paragraphs needed
  uint16_t e_ss;          // Initial (relative) SS value
  uint16_t e_sp;          // Initial SP value
  uint16_t e_csum;        // Checksum
  uint16_t e_ip;          // Initial IP value
  uint16_t e_cs;          // Initial (relative) CS value
  uint16_t e_lfarlc;      // File address of relocation table
  uint16_t e_ovno;        // Overlay number
  std::array<uint16_t, 4> e_res;    // Reserved words
  uint16_t e_oemid;       // OEM identifier
  uint16_t e_oeminfo;     // OEM information
  std::array<uint16_t, 10> e_res2;  // Reserved words
  uint32_t e_lfanew;      // File address of new exe header (PE header)
};

struct FileHeader {
  uint16_t machine;              // Target machine (0x8664 for x64)
  uint16_t number_of_sections;   // Number of sections
  uint32_t time_date_stamp;      // Timestamp
  uint32_t pointer_to_symbol_table; // File offset of symbol table (or 0)
  uint32_t number_of_symbols;    // Number of symbols
  uint16_t size_of_optional_header; // Size of optional header
  uint16_t characteristics;      // Flags (executable, DLL, etc.)
};

struct DataDirectory {
  uint32_t virtual_address;
  uint32_t size;
};

struct OptionalHeader {
  uint16_t magic;                // 0x20b for PE32+ (64-bit)
  uint8_t major_linker_version;
  uint8_t minor_linker_version;
  uint32_t size_of_code;
  uint32_t size_of_initialized_data;
  uint32_t size_of_uninitialized_data;
  uint32_t address_of_entry_point;
  uint32_t base_of_code;
  uint64_t image_base;
  uint32_t section_alignment;
  uint32_t file_alignment;
  uint16_t major_os_version;
  uint16_t minor_os_version;
  uint16_t major_image_version;
  uint16_t minor_image_version;
  uint16_t major_subsystem_version;
  uint16_t minor_subsystem_version;
  uint32_t win32_version_value;
  uint32_t size_of_image;
  uint32_t size_of_headers;
  uint32_t checksum;
  uint16_t subsystem;
  uint16_t dll_characteristics;
  uint64_t size_of_stack_reserve;
  uint64_t size_of_stack_commit;
  uint64_t size_of_heap_reserve;
  uint64_t size_of_heap_commit;
  uint32_t loader_flags;
  uint32_t number_of_rva_and_sizes;
  std::array<DataDirectory, 16> data_directories;
};

struct SectionHeader {
  std::array<uint8_t, 8> name;
  uint32_t virtual_size;
  uint32_t virtual_address;
  uint32_t size_of_raw_data;
  uint32_t pointer_to_raw_data;
  uint32_t pointer_to_relocations;
  uint32_t pointer_to_line_numbers;
  uint16_t number_of_relocations;
  uint16_t number_of_line_numbers;
  uint32_t characteristics;
};

struct ImportDirectory {
  uint32_t import_lookup_table_rva;
  uint32_t time_date_stamp;
  uint32_t forwarder_chain;
  uint32_t name_rva;
  uint32_t import_address_table_rva;
};

struct ImportLookupEntry64 {
  uint64_t data;
};

struct BaseRelocationBlock {
  uint32_t virtual_address;
  uint32_t size_of_block;
};

struct BaseRelocationEntry {
  uint16_t offset;
};

struct RuntimeFunction {
  uint32_t begin_address;
  uint32_t end_address;
  uint32_t unwind_info_address;
};

struct UnwindCode {
  union {
    struct {
      uint8_t code_offset;
      uint8_t unwind_opcode : 4;
      uint8_t opcode_info : 4;

    } s;

    uint16_t FrameOffset;
    uint16_t Value;
  } u;
};

struct UnwindInfo {
  uint8_t version : 3;
  uint8_t flags : 5;
  uint8_t size_of_prolog;
  uint8_t count_of_codes;
  uint8_t frame_register : 4;
  uint8_t frame_offset : 4;
  UnwindCode unwind_code [ 1 ];
};

struct TlsDirectory64 {
  uint64_t start_address_of_raw_data;
  uint64_t end_address_of_raw_data;
  uint64_t address_of_index;
  uint64_t address_of_callbacks;
  uint32_t size_of_zero_fill;
  uint32_t characteristics;
};

struct DebugDirectory {
  uint32_t characteristics;
  uint32_t time_date_stamp;
  uint16_t major_version;
  uint16_t minor_version;
  uint32_t type_;
  uint32_t size_of_data;
  uint32_t address_of_raw_data;
  uint32_t pointer_to_raw_data;
};

struct ImageLoadConfigDirectory64 {
  uint32_t size;
  uint32_t time_date_stamp;
  uint16_t major_version;
  uint16_t minor_version;
  uint32_t global_flags_clear;
  uint32_t global_flags_set;
  uint32_t critical_section_default_timeout;
  uint64_t de_commit_free_block_threshold;
  uint64_t de_commit_total_free_threshold;
  uint64_t lock_prefix_table;
  uint64_t maximum_allocation_size;
  uint64_t virtual_memory_threshold;
  uint64_t process_affinity_mask;
  uint32_t process_heap_flags;
  uint16_t csd_version;
  uint16_t dependent_load_flags;
  uint64_t edit_list;
  uint64_t security_cookie;
  uint64_t se_handler_table;
  uint64_t se_handler_count;
  uint64_t guard_cf_check_function_pointer;
  uint64_t guard_cf_dispatch_function_pointer;
  uint64_t guard_cf_function_table;
  uint64_t guard_cf_function_count;
  uint32_t guard_flags;
  struct ImageLoadConfigCodeIntegrity {
    uint16_t flags;
    uint16_t catalog;
    uint32_t catalog_offset;
    uint32_t reserved;
  } code_integrity;
  uint64_t guard_address_taken_iat_entry_table;
  uint64_t guard_address_taken_iat_entry_count;
  uint64_t guard_long_jump_target_table;
  uint64_t guard_long_jump_target_count;
  uint64_t dynamic_value_reloc_table;
  uint64_t chpe_metadata_pointer;
  uint64_t guard_rf_failure_routine;
  uint64_t guard_rf_failure_routine_function_pointer;
  uint32_t dynamic_value_reloc_table_offset;
  uint16_t dynamic_value_reloc_table_section;
  uint16_t reserved2;
  uint64_t guard_rf_verify_stack_pointer_function_pointer;
  uint32_t hot_patch_table_offset;
  uint32_t reserved3;
  uint64_t enclave_configuration_pointer;
  uint64_t volatile_metadata_pointer;
  uint64_t guard_eh_continuation_table;
  uint64_t guard_eh_continuation_count;
  uint64_t guard_xfg_check_function_pointer;
  uint64_t guard_xfg_dispatch_function_pointer;
  uint64_t guard_xfg_table_dispatch_function_pointer;
  uint64_t cast_guard_os_determined_failure_mode;
  uint64_t guard_memcpy_function_pointer;
};

struct CV_INFO_PDB70 { // RSDS format (PDB 7.0)
  uint32_t cv_signature; // 'RSDS' (0x53445352)
  uint32_t guid_data1;   // First part of GUID
  uint16_t guid_data2;   // Second part of GUID
  uint16_t guid_data3;   // Third part of GUID
  uint8_t  guid_data4 [ 8 ]; // Fourth part of GUID (8 bytes)
  uint32_t age;          // Age of the PDB
  char     pdb_name [ 1 ];  // Null-terminated PDB filename (variable length)
};

struct CV_INFO_PDB20 { // NB10 format (PDB 2.0)
  uint32_t cv_signature; // 'NB10' (0x3031424E)
  uint32_t offset;       // Offset (usually 0)
  uint32_t signature;    // Timestamp/Signature
  uint32_t age;          // Age of the PDB
  char     pdb_name [ 1 ];  // Null-terminated PDB filename (variable length)
};

struct ExportDirectory {
  uint32_t characteristics;
  uint32_t time_date_stamp;
  uint16_t major_version;
  uint16_t minor_version;
  uint32_t name_rva;
  uint32_t base;
  uint32_t number_of_functions;
  uint32_t number_of_names;
  uint32_t address_of_functions;
  uint32_t address_of_names;
  uint32_t address_of_name_ordinals;
};

struct TypeDescriptor {
  uint64_t pVFTable;          // Pointer to vtable (usually points to type_info's vtable)
  uint64_t spare;            // Unused (padding or reserved)
  char name [ 1 ];              // Null-terminated type name (variable length)
};

struct BaseClassDescriptor {
  uint32_t type_descriptor_rva; // RVA to TypeDescriptor
  uint32_t num_contained_bases; // Number of bases in the hierarchy
  uint32_t mdisp;              // Member displacement
  uint32_t pdisp;              // VBase displacement
  uint32_t vdisp;              // Displacement inside vbase
  uint32_t attributes;         // Flags (e.g., virtual inheritance)
};

struct ClassHierarchyDescriptor {
  uint32_t signature;          // Always 1 for MSVC RTTI
  uint32_t attributes;         // Flags (e.g., multiple inheritance)
  uint32_t num_base_classes;   // Number of base classes
  uint32_t base_class_array_rva; // RVA to array of BaseClassDescriptor RVAs
};

#pragma pack(pop)

// Aligned versions
struct DosHeaderAligned {
  uint16_t e_magic;
  uint16_t e_cblp;
  uint16_t e_cp;
  uint16_t e_crlc;
  uint16_t e_cparhdr;
  uint16_t e_minalloc;
  uint16_t e_maxalloc;
  uint16_t e_ss;
  uint16_t e_sp;
  uint16_t e_csum;
  uint16_t e_ip;
  uint16_t e_cs;
  uint16_t e_lfarlc;
  uint16_t e_ovno;
  uint32_t e_lfanew;
};

struct FileHeaderAligned {
  uint16_t machine;
  uint16_t number_of_sections;
  uint32_t time_date_stamp;
  uint32_t pointer_to_symbol_table;
  uint32_t number_of_symbols;
  uint16_t size_of_optional_header;
  uint16_t characteristics;
};

struct DataDirectoryAligned {
  uint32_t virtual_address;
  uint32_t size;
};

struct OptionalHeaderAligned {
  uint16_t magic;
  uint8_t major_linker_version;
  uint8_t minor_linker_version;
  uint32_t size_of_code;
  uint32_t size_of_initialized_data;
  uint32_t size_of_uninitialized_data;
  uint32_t address_of_entry_point;
  uint32_t base_of_code;
  uint64_t image_base;
  uint32_t section_alignment;
  uint32_t file_alignment;
  uint16_t major_os_version;
  uint16_t minor_os_version;
  uint16_t major_image_version;
  uint16_t minor_image_version;
  uint16_t major_subsystem_version;
  uint16_t minor_subsystem_version;
  uint32_t win32_version_value;
  uint32_t size_of_image;
  uint32_t size_of_headers;
  uint32_t checksum;
  uint16_t subsystem;
  uint16_t dll_characteristics;
  uint64_t size_of_stack_reserve;
  uint64_t size_of_stack_commit;
  uint64_t size_of_heap_reserve;
  uint64_t size_of_heap_commit;
  uint32_t loader_flags;
  uint32_t number_of_rva_and_sizes;
  std::vector<DataDirectoryAligned> data_directories;
};

struct SectionHeaderAligned {
  std::array<uint8_t, 8> name;
  uint32_t virtual_size;
  uint32_t virtual_address;
  uint32_t size_of_raw_data;
  uint32_t pointer_to_raw_data;
  uint32_t pointer_to_relocations;
  uint32_t pointer_to_line_numbers;
  uint16_t number_of_relocations;
  uint16_t number_of_line_numbers;
  uint32_t characteristics;
};

struct PEInfoAligned {
  DosHeader dos_header;
  FileHeader file_header;
  OptionalHeader optional_header;
  std::vector<SectionHeader> section_headers;
  std::vector<DataDirectory> data_directories;
};

namespace PE
{
  constexpr uint32_t scn_mem_execute = 0x20000000;

  using ExecutableSectionData = std::vector<std::tuple<std::string, std::vector<uint8_t>, uint64_t, bool>>;
  using ImportEntry = std::tuple<uint16_t, std::optional<std::string>, uint64_t>;
  using ImportDirectoryData = std::vector<std::pair<std::string, std::vector<ImportEntry>>>;
  using RelocationEntry = std::pair<uint16_t, uint16_t>;
  using RelocationDirectoryData = std::vector<std::pair<uint32_t, std::vector<RelocationEntry>>>;
  using ExceptionEntry = std::pair<RuntimeFunction, std::optional<UnwindInfo>>;
  using ExceptionDirectoryData = std::vector<ExceptionEntry>;
  using TlsDirectoryData = std::pair<TlsDirectory64, std::vector<uint64_t>>;
  using DebugEntry = std::pair<DebugDirectory, std::optional<std::vector<uint8_t>>>;
  using DebugDirectoryData = std::vector<DebugEntry>;
  using ExportEntry = std::tuple<std::string, uint32_t, std::optional<uint16_t>, uint64_t>; // name, ordinal, hint, rva
  using ExportDirectoryData = std::pair<ExportDirectory, std::vector<ExportEntry>>;

  class Parser {
  public:
    std::vector<uint8_t> buffer_;
    uint64_t override_base_address_ = 0;
    uint64_t override_entry_point_ = 0;
    bool mapped_image = false;
    uint64_t mapped_address = 0ull;

    auto rva_to_offset ( uint32_t rva ) const->size_t;

    template<typename T>
    static auto read_struct ( std::span<const uint8_t> data, size_t offset ) -> T;

    static auto parse ( std::span<const uint8_t> buffer ) -> PEInfoAligned;

    auto resolve_chained_function ( uint64_t base_offset, RuntimeFunction func ) const->RuntimeFunction;


    explicit Parser ( std::string_view file_path );
    explicit Parser ( uint64_t module_base );

    [[nodiscard]] auto get_section_data ( std::string_view section_name ) const->std::vector<uint8_t>;
    [[nodiscard]] auto get_entry_point ( ) const noexcept -> uint64_t;
    [[nodiscard]] auto get_text_section_data ( ) const->std::vector<uint8_t>;
    [[nodiscard]] auto get_image_base ( ) const noexcept -> uint64_t;
    [[nodiscard]] auto get_executable_sections_data ( ) const->ExecutableSectionData;
    [[nodiscard]] auto get_all_sections_data ( ) const->ExecutableSectionData;
    [[nodiscard]] auto get_import_directory ( ) const->ImportDirectoryData;
    [[nodiscard]] auto get_relocation_directory ( ) const->RelocationDirectoryData;
    [[nodiscard]] auto get_exception_directory ( ) const->ExceptionDirectoryData;
    [[nodiscard]] auto get_tls_directory ( ) const->TlsDirectoryData;
    [[nodiscard]] auto get_debug_directory ( ) const->DebugDirectoryData;
    [[nodiscard]] auto get_export_directory ( ) const->ExportDirectoryData;
    [[nodiscard]] auto chase_entry_point ( const std::vector<uint8_t>& text, uint64_t image_base, size_t initial_offset ) const->std::vector<capstone::Instruction>;
    [[nodiscard]] auto try_detect_compiler ( ) const->std::string;
    [[nodiscard]] auto section_name_for_address ( uint64_t address ) const->std::string;
    [[nodiscard]] auto get_pdb_path ( ) const->std::optional<std::string>;
    [[nodiscard]] auto get_pdb_url ( ) const->std::optional<std::string>;
    [[nodiscard]] auto get_imports ( ) const->std::map<std::string, std::map<std::string, uint64_t>>;
    auto fix_security_cookie ( ) -> void;
    auto override_base_address ( uint64_t address ) -> void;
    auto override_entry_point ( uint64_t address ) -> void;
    auto is_address_in_iat ( uint64_t va ) const -> bool;
    auto read_qword_at_rva ( uint64_t rva ) const -> uint64_t;

    auto is_executable_address ( uint64_t va ) const noexcept -> bool;

    PEInfoAligned pe_info_;
  };
}
```

`shared/shared.vcxproj`:

```vcxproj
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="capstone++.hpp" />
    <ClInclude Include="context.hpp" />
    <ClInclude Include="module_loader.hpp" />
    <ClInclude Include="portable_executable.hpp" />
    <ClInclude Include="types.hpp" />
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="src\portable_executable.cpp" />
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>17.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{f882b8d0-1a48-4bd7-8559-8c63e540bd68}</ProjectGuid>
    <RootNamespace>shared</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>StaticLibrary</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>MultiByte</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <IncludePath>$(SolutionDir);$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
    <LibraryPath>$(SolutionDir)\x64\Debug;$(VC_LibraryPath_x64);$(WindowsSDK_LibraryPath_x64)</LibraryPath>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg">
    <VcpkgEnableManifest>true</VcpkgEnableManifest>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <PropertyGroup Label="Vcpkg" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <VcpkgUseStatic>true</VcpkgUseStatic>
  </PropertyGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>Use</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <MultiProcessorCompilation>true</MultiProcessorCompilation>
      <RuntimeLibrary>MultiThreadedDebug</RuntimeLibrary>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_LIB;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
      <PrecompiledHeader>NotUsing</PrecompiledHeader>
      <PrecompiledHeaderFile>pch.h</PrecompiledHeaderFile>
      <LanguageStandard>stdcpplatest</LanguageStandard>
      <MultiProcessorCompilation>true</MultiProcessorCompilation>
      <RuntimeLibrary>MultiThreaded</RuntimeLibrary>
      <EnableEnhancedInstructionSet>NotSet</EnableEnhancedInstructionSet>
    </ClCompile>
    <Link>
      <SubSystem>
      </SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
```

`shared/shared.vcxproj.filters`:

```filters
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup>
    <Filter Include="Source Files">
      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
      <Extensions>cpp;c;cc;cxx;c++;cppm;ixx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
    </Filter>
    <Filter Include="Header Files">
      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
      <Extensions>h;hh;hpp;hxx;h++;hm;inl;inc;ipp;xsd</Extensions>
    </Filter>
    <Filter Include="Resource Files">
      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
    </Filter>
  </ItemGroup>
  <ItemGroup>
    <ClInclude Include="capstone++.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
    <ClInclude Include="portable_executable.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
    <ClInclude Include="context.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
    <ClInclude Include="types.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
    <ClInclude Include="module_loader.hpp">
      <Filter>Header Files</Filter>
    </ClInclude>
  </ItemGroup>
  <ItemGroup>
    <ClCompile Include="src\portable_executable.cpp">
      <Filter>Source Files</Filter>
    </ClCompile>
  </ItemGroup>
</Project>
```

`shared/src/portable_executable.cpp`:

```cpp
#include <shared/portable_executable.hpp>
#include <fstream>
#include <algorithm>
#include <ranges>
#include <format>
#include <functional>

#define WIN32_LEAN_AND_MEAN
#define NOMINMAX
#include <Windows.h>

namespace PE
{
	auto is_rva_in_section ( uint32_t rva, const SectionHeader& section ) -> bool {
		return rva >= section.virtual_address &&
			rva <= section.virtual_address + section.virtual_size;
	}

	auto mapped_rva_in_section ( uint32_t rva, const SectionHeader& section ) -> bool {
		return rva >= section.pointer_to_raw_data &&
			rva <= section.pointer_to_raw_data + section.size_of_raw_data;
	}

	auto Parser::is_executable_address ( uint64_t va ) const noexcept -> bool {
		static auto executable_sections = this->get_executable_sections_data ( );
		//auto rva = va - mapped_address;
		for ( const auto& [_, data, virt, ___] : executable_sections ) {
			if ( va >= virt && va <= virt + data.size ( ) ) {
				return true;
			}
		}
		return false;
	}

	auto Parser::rva_to_offset ( uint32_t rva ) const -> size_t {
		if ( mapped_image ) {
			return rva;
		}
		auto pred = std::bind ( is_rva_in_section, rva, std::placeholders::_1 );
		auto it = std::ranges::find_if ( pe_info_.section_headers, pred );

		if ( it == pe_info_.section_headers.end ( ) ) {
			return 0;
			throw std::runtime_error ( "RVA not found in any section" );
		}

		return rva - it->virtual_address + it->pointer_to_raw_data;
	}

	template<typename T>
	auto Parser::read_struct ( std::span<const uint8_t> data, size_t offset ) -> T {
		if ( offset + sizeof ( T ) > data.size ( ) ) {
			throw std::runtime_error ( "Buffer overflow reading structure" );
		}
		T result;
		std::memcpy ( &result, data.data ( ) + offset, sizeof ( T ) );
		return result;
	}

	auto Parser::parse ( std::span<const uint8_t> buffer ) -> PEInfoAligned {
		auto dos_header = read_struct<DosHeader> ( buffer, 0 );
		if ( dos_header.e_magic != 0x5A4D ) {
			return {};
			throw std::runtime_error ( "Not a valid PE file" );
		}

		size_t pe_offset = dos_header.e_lfanew;
		if ( uint32_t signature = read_struct<uint32_t> ( buffer, pe_offset );
				 signature != 0x00004550 ) {
			throw std::runtime_error ( "Invalid PE signature" );
		}

		auto file_header = read_struct<FileHeader> ( buffer, pe_offset + 4 );
		if ( file_header.machine != 0x8664 ) {
			throw std::runtime_error ( "Not an x64 binary" );
		}

		auto optional_header = read_struct<OptionalHeader> (
			buffer, pe_offset + 4 + sizeof ( FileHeader ) );
		if ( optional_header.magic != 0x20b ) {
			throw std::runtime_error ( "Not a PE32+ binary" );
		}

		std::vector<DataDirectory> data_dirs { optional_header.data_directories.begin ( ),
			optional_header.data_directories.end ( ) };

		size_t section_offset = pe_offset + 4 + sizeof ( FileHeader ) +
			file_header.size_of_optional_header;
		std::vector<SectionHeader> sections;
		sections.reserve ( file_header.number_of_sections );

		for ( uint16_t i : std::views::iota ( 0u, file_header.number_of_sections ) ) {
			sections.push_back ( read_struct<SectionHeader> (
				buffer, section_offset + i * sizeof ( SectionHeader ) ) );
		}

		return { dos_header,file_header,optional_header,std::move ( sections ),std::move ( data_dirs ) };
	}

	Parser::Parser ( std::string_view file_path ) {
		std::ifstream file { file_path.data ( ),std::ios::binary };
		if ( !file ) {
			throw std::runtime_error ( std::string ( "Failed to open file: " ) + file_path.data ( ) );
		}

		file.seekg ( 0, std::ios::end );
		buffer_.resize ( file.tellg ( ) );
		file.seekg ( 0, std::ios::beg );
		file.read ( reinterpret_cast< char* >( buffer_.data ( ) ), buffer_.size ( ) );
		pe_info_ = parse ( buffer_ );
	}

	Parser::Parser ( uint64_t address ) {
		buffer_.resize ( 0x1000 );
		std::memcpy ( buffer_.data ( ), ( void* ) address, 0x1000 );
		pe_info_ = parse ( buffer_ );
		buffer_.resize ( pe_info_.optional_header.size_of_image );
		std::memcpy ( buffer_.data ( ), ( void* ) address, buffer_.size ( ) );
		mapped_image = true;
		mapped_address = address;
	}

	auto Parser::get_section_data ( std::string_view section_name ) const -> std::vector<uint8_t> {
		auto section = std::ranges::find_if ( pe_info_.section_headers,
																					[ section_name ] ( const auto& s )
		{
			std::string name { reinterpret_cast< const char* >( s.name.data ( ) ),8 };
			return name.starts_with ( section_name );
		} );

		if ( section == pe_info_.section_headers.end ( ) ) {
			throw std::runtime_error ( "Section " + std::string ( section_name ) + " not found" );
		}

		return std::vector<uint8_t> (
			buffer_.begin ( ) + section->pointer_to_raw_data,
			buffer_.begin ( ) + section->pointer_to_raw_data + section->size_of_raw_data );
	}

	auto Parser::get_entry_point ( ) const noexcept -> uint64_t {
		if ( override_entry_point_ ) {
			return get_image_base ( ) + override_entry_point_;
		}

		return pe_info_.optional_header.image_base +
			pe_info_.optional_header.address_of_entry_point;
	}

	auto Parser::get_text_section_data ( ) const -> std::vector<uint8_t> {
		return get_section_data ( ".text" );
	}

	auto Parser::get_image_base ( ) const noexcept -> uint64_t {
		if ( override_base_address_ ) {
			return override_base_address_;
		}

		return pe_info_.optional_header.image_base;
	}

	auto Parser::get_executable_sections_data ( ) const -> ExecutableSectionData {
		ExecutableSectionData result;

		for ( const auto& section : pe_info_.section_headers |
					std::views::filter ( [ ] ( const auto& s )
		{
			return s.characteristics & scn_mem_execute;
		} ) ) {
			std::string name { reinterpret_cast< const char* >( section.name.data ( ) ),8 };
			name = name.substr ( 0, name.find ( '\0' ) );
			size_t start = section.pointer_to_raw_data;
			result.emplace_back (
				name,
				std::vector<uint8_t> ( buffer_.begin ( ) + start,
				buffer_.begin ( ) + start + section.size_of_raw_data ),
				get_image_base ( ) + section.virtual_address,
				true
			);
		}

		if ( result.empty ( ) ) {
			return {};
		}
		return result;
	}

	auto Parser::get_all_sections_data ( ) const -> ExecutableSectionData {
		ExecutableSectionData result;

		for ( const auto& section : pe_info_.section_headers ) {
			std::string name { reinterpret_cast< const char* >( section.name.data ( ) ),8 };
			name = name.substr ( 0, name.find ( '\0' ) );
			size_t start = section.pointer_to_raw_data;
			result.emplace_back (
				name,
				std::vector<uint8_t> ( buffer_.begin ( ) + start,
				buffer_.begin ( ) + start + section.size_of_raw_data ),
				get_image_base ( ) + section.virtual_address,
				static_cast< bool >( section.characteristics & scn_mem_execute )
			);
		}

		if ( result.empty ( ) ) {
			return {};
		}
		return result;
	}

	auto Parser::get_import_directory ( ) const -> ImportDirectoryData {
		const auto& import_dir = pe_info_.data_directories [ 1 ];
		if ( import_dir.virtual_address == 0 ) {
			return {};
		}

		ImportDirectoryData result;
		size_t offset = rva_to_offset ( import_dir.virtual_address );
		if ( !offset ) {
			return {};
		}

		for ( size_t current_offset = offset; current_offset + sizeof ( ImportDirectory ) <= buffer_.size ( ); current_offset += sizeof ( ImportDirectory ) ) {
			auto import = read_struct<ImportDirectory> ( buffer_, current_offset );
			if ( import.import_lookup_table_rva == 0 ) break;

			auto name_offset = rva_to_offset ( import.name_rva );
			if ( !offset ) {
				break;
			}

			auto name_start = buffer_.begin ( ) + name_offset;
			auto name_end = std::find ( name_start, buffer_.end ( ), 0 );
			std::string dll_name { name_start,name_end };

			std::vector<ImportEntry> entries;
			size_t lookup_offset = rva_to_offset ( import.import_lookup_table_rva );
			uint32_t iat_base_rva = import.import_address_table_rva;
			size_t index = 0;

			while ( true ) {
				auto entry = read_struct<ImportLookupEntry64> ( buffer_, lookup_offset );
				if ( entry.data == 0 ) break;

				// Calculate the thunk RVA as the IAT entry's address
				uint64_t thunk_rva = iat_base_rva + index * sizeof ( uint64_t );

				if ( entry.data & ( 1ULL << 63 ) ) {
					// Ordinal import
					entries.emplace_back ( static_cast< uint16_t >( entry.data & 0xFFFF ), std::nullopt, thunk_rva );
				}
				else {
					// Name import
					size_t name_offset = rva_to_offset ( entry.data & 0x7FFFFFFF ) + 2;
					auto _name_start = buffer_.begin ( ) + name_offset;
					auto _name_end = std::find ( _name_start, buffer_.end ( ), 0 );
					std::string name { _name_start,_name_end };
					entries.emplace_back ( static_cast< uint16_t >( 0 ), std::move ( name ), thunk_rva );
				}
				lookup_offset += sizeof ( ImportLookupEntry64 );
				index++;
			}
			result.emplace_back ( std::move ( dll_name ), std::move ( entries ) );
		}
		return result;
	}

	auto Parser::get_relocation_directory ( ) const -> RelocationDirectoryData {
		const auto& reloc_dir = pe_info_.data_directories [ 5 ];
		if ( reloc_dir.virtual_address == 0 ) {
			return {};
		}

		RelocationDirectoryData result;
		size_t offset = rva_to_offset ( reloc_dir.virtual_address );
		size_t current_offset = offset;

		while ( current_offset < offset + reloc_dir.size ) {
			auto block = read_struct<BaseRelocationBlock> ( buffer_, current_offset );
			uint32_t entry_count = ( block.size_of_block - 8 ) / 2;
			std::vector<RelocationEntry> entries;
			entries.reserve ( entry_count );

			for ( uint32_t i : std::views::iota ( 0u, entry_count ) ) {
				auto entry = read_struct<BaseRelocationEntry> (
					buffer_, current_offset + 8 + i * sizeof ( BaseRelocationEntry ) );
				entries.emplace_back ( static_cast< uint16_t > ( ( entry.offset >> 12 ) & 0xF ), static_cast< uint16_t > ( entry.offset & 0xFFF ) );
			}
			result.emplace_back ( block.virtual_address, std::move ( entries ) );
			current_offset += block.size_of_block;
		}
		return result;
	}

	auto Parser::resolve_chained_function ( uint64_t base_offset, RuntimeFunction func ) const -> RuntimeFunction {
		if ( !func.unwind_info_address ) {
			return func;
		}

		try {
			auto unwind_info = read_struct<UnwindInfo> (
					buffer_, rva_to_offset ( func.unwind_info_address ) );

			if ( ( unwind_info.flags & 0x4 ) != 0 ) { // UNW_FLAG_CHAININFO
				uint32_t index = unwind_info.count_of_codes;
				if ( ( index & 1 ) != 0 ) {
					index += 1;
				}

				uint64_t chain_offset = rva_to_offset ( func.unwind_info_address ) +
					offsetof ( UnwindInfo, unwind_code ) +
					( index * sizeof ( UnwindCode ) );

				auto chain_func = read_struct<RuntimeFunction> ( buffer_, chain_offset );
				return resolve_chained_function ( base_offset, chain_func );
			}
		}
		catch ( ... ) {
			return func;
		}

		return func;
	}

	auto Parser::get_exception_directory ( ) const -> ExceptionDirectoryData {
		const auto& exception_dir = pe_info_.data_directories [ 3 ];
		if ( exception_dir.virtual_address == 0 ) {
			return {};
		}

		ExceptionDirectoryData result;
		size_t offset = rva_to_offset ( exception_dir.virtual_address );
		if ( !offset ) {
			return {};
		}
		uint32_t entry_count = exception_dir.size / sizeof ( RuntimeFunction );
		result.reserve ( entry_count );

		for ( uint32_t i : std::views::iota ( 0u, entry_count ) ) {
			auto func = read_struct<RuntimeFunction> (
					buffer_, offset + i * sizeof ( RuntimeFunction ) );

			auto resolved_func = resolve_chained_function ( offset, func );
			std::optional<UnwindInfo> unwind_info;
			if ( resolved_func.unwind_info_address ) {
				try {
					unwind_info = read_struct<UnwindInfo> (
							buffer_, rva_to_offset ( resolved_func.unwind_info_address ) );
				}
				catch ( ... ) {
					unwind_info = std::nullopt;
				}
			}

			result.emplace_back ( resolved_func, unwind_info );
		}
		return result;
	}

	auto Parser::get_tls_directory ( ) const -> TlsDirectoryData {
		const auto& tls_dir = pe_info_.data_directories [ 9 ];
		if ( tls_dir.virtual_address == 0 ) {
			return {};
		}

		size_t offset = rva_to_offset ( tls_dir.virtual_address );
		auto tls = read_struct<TlsDirectory64> ( buffer_, offset );
		std::vector<uint64_t> callbacks;

		if ( tls.address_of_callbacks ) {
			size_t callback_offset = rva_to_offset (
				static_cast< uint32_t >( tls.address_of_callbacks ) );

			for ( size_t current_offset = callback_offset; ;
						current_offset += sizeof ( uint64_t ) ) {
				uint64_t callback = read_struct<uint64_t> ( buffer_, current_offset );
				if ( callback == 0 ) break;
				callbacks.push_back ( callback );
			}
		}
		return { tls,std::move ( callbacks ) };
	}

	auto Parser::get_debug_directory ( ) const -> DebugDirectoryData {
		const auto& debug_dir = pe_info_.data_directories [ 6 ];
		if ( debug_dir.virtual_address == 0 ) {
			return {};
		}

		DebugDirectoryData result;
		size_t offset = rva_to_offset ( debug_dir.virtual_address );
		uint32_t entry_count = debug_dir.size / sizeof ( DebugDirectory );
		result.reserve ( entry_count );

		for ( uint32_t i : std::views::iota ( 0u, entry_count ) ) {
			auto entry = read_struct<DebugDirectory> (
				buffer_, offset + i * sizeof ( DebugDirectory ) );
			std::optional<std::vector<uint8_t>> debug_data;

			if ( entry.pointer_to_raw_data && entry.size_of_data ) {
				size_t start = entry.pointer_to_raw_data;
				debug_data = std::vector<uint8_t> (
					buffer_.begin ( ) + start,
					buffer_.begin ( ) + start + entry.size_of_data );
			}
			result.emplace_back ( entry, std::move ( debug_data ) );
		}
		return result;
	}

	auto Parser::get_export_directory ( ) const -> ExportDirectoryData {
		const auto& export_dir = pe_info_.data_directories [ 0 ];
		if ( export_dir.virtual_address == 0 ) {
			return {};
		}

		size_t offset = rva_to_offset ( export_dir.virtual_address );
		auto export_table = read_struct<ExportDirectory> ( buffer_, offset );

		std::string dll_name;
		if ( export_table.name_rva ) {
			auto name_start = buffer_.begin ( ) + rva_to_offset ( export_table.name_rva );
			auto name_end = std::find ( name_start, buffer_.end ( ), 0 );
			dll_name = std::string ( name_start, name_end );
		}

		std::vector<ExportEntry> entries;
		entries.reserve ( export_table.number_of_names );

		auto functions_offset = rva_to_offset ( export_table.address_of_functions );
		auto names_offset = rva_to_offset ( export_table.address_of_names );
		auto ordinals_offset = rva_to_offset ( export_table.address_of_name_ordinals );

		for ( uint32_t i = 0; i < export_table.number_of_names; ++i ) {
			uint32_t name_rva = read_struct<uint32_t> ( buffer_, names_offset + i * sizeof ( uint32_t ) );
			uint16_t ordinal = read_struct<uint16_t> ( buffer_, ordinals_offset + i * sizeof ( uint16_t ) );
			uint32_t function_rva = read_struct<uint32_t> ( buffer_, functions_offset + ordinal * sizeof ( uint32_t ) );

			std::string name;
			if ( name_rva ) {
				auto name_start = buffer_.begin ( ) + rva_to_offset ( name_rva );
				auto name_end = std::find ( name_start, buffer_.end ( ), 0 );
				name = std::string ( name_start, name_end );
			}

			std::optional<uint16_t> forwarder_ordinal;
			if ( function_rva >= export_dir.virtual_address &&
					function_rva < export_dir.virtual_address + export_dir.size ) {
				forwarder_ordinal = ordinal;
			}

			entries.emplace_back (
					std::move ( name ),
					ordinal + export_table.base,
					forwarder_ordinal,
					function_rva ? get_image_base ( ) + function_rva : 0
			);
		}

		return { export_table,std::move ( entries ) };
	}

	auto Parser::chase_entry_point ( const std::vector<uint8_t>& text, uint64_t image_base, size_t initial_offset ) const->std::vector<capstone::Instruction> {
		size_t offset = initial_offset;
		capstone::Decoder decoder { text.data ( ) + offset,text.size ( ) - offset,image_base + offset };
		std::vector<capstone::Instruction> instrs;

		for ( int i = 0; i < 5 && decoder.can_decode ( ); ++i ) {
			auto instr = decoder.decode ( );
			if ( !instr.is_valid ( ) ) break;
			auto should_stop = instr.is_call ( ) || instr.is_return ( );
			instrs.push_back ( std::move ( instr ) );
			if ( should_stop ) break;
		}

		return instrs;
	}

	auto Parser::try_detect_compiler ( ) const->std::string {
		auto text = get_text_section_data ( );
		size_t ep_offset = rva_to_offset ( pe_info_.optional_header.address_of_entry_point );
		if ( ep_offset + 32 > text.size ( ) ) {
			return "Unknown"; // Too short
		}

		uint64_t image_base = get_image_base ( );
		auto instrs = chase_entry_point ( text, image_base, ep_offset );
		if ( instrs.empty ( ) ) return "Unknown";

		auto sections = get_all_sections_data ( );
		bool has_pdata = std::ranges::any_of ( sections, [ ] ( const auto& s )
		{
			return std::get<0> ( s ) == ".pdata";
		} );
		bool has_rodata = std::ranges::any_of ( sections, [ ] ( const auto& s )
		{
			return std::get<0> ( s ) == ".rodata";
		} );

		// MSVC: push rbp; mov rbp, rsp + call (likely __security_init_cookie)
		if ( instrs.size ( ) >= 3 &&
				instrs [ 0 ].mnemonic ( ) == X86_INS_PUSH &&
				instrs [ 0 ].operands ( ) [ 0 ].reg == X86_REG_RBP &&
				instrs [ 1 ].mnemonic ( ) == X86_INS_MOV &&
				instrs [ 1 ].operands ( ) [ 0 ].reg == X86_REG_RBP &&
				instrs [ 1 ].operands ( ) [ 1 ].reg == X86_REG_RSP &&
				instrs [ 2 ].is_call ( ) ) {
			if ( has_pdata ) return "MSVC";
			if ( !has_rodata ) return "MSVC";
		}

		// GCC: push rbp; mov rbp, rsp + call (likely _pei386_runtime_relocator)
		if ( instrs.size ( ) >= 3 &&
				instrs [ 0 ].mnemonic ( ) == X86_INS_PUSH &&
				instrs [ 0 ].operands ( ) [ 0 ].reg == X86_REG_RBP &&
				instrs [ 1 ].mnemonic ( ) == X86_INS_MOV &&
				instrs [ 1 ].operands ( ) [ 0 ].reg == X86_REG_RBP &&
				instrs [ 1 ].operands ( ) [ 1 ].reg == X86_REG_RSP &&
				instrs [ 2 ].is_call ( ) ) {
			if ( has_rodata ) return "GCC";
			if ( !has_pdata ) return "GCC";
		}

		// Clang: sub rsp, xx + call (likely __main)
		if ( instrs.size ( ) >= 2 &&
				instrs [ 0 ].mnemonic ( ) == X86_INS_SUB &&
				instrs [ 0 ].operands ( ) [ 0 ].reg == X86_REG_RSP &&
				instrs [ 1 ].is_call ( ) ) {
			if ( !has_pdata ) return "Clang";
			if ( has_rodata ) return "Clang";
		}

		// Fallback: Prologue only
		if ( instrs [ 0 ].mnemonic ( ) == X86_INS_PUSH &&
				instrs [ 0 ].operands ( ) [ 0 ].reg == X86_REG_RBP &&
				instrs.size ( ) > 1 &&
				instrs [ 1 ].mnemonic ( ) == X86_INS_MOV &&
				instrs [ 1 ].operands ( ) [ 0 ].reg == X86_REG_RBP &&
				instrs [ 1 ].operands ( ) [ 1 ].reg == X86_REG_RSP ) {
			if ( has_pdata ) return "MSVC";
			if ( has_rodata ) return "GCC";
			return "GCC"; // Default to GCC
		}
		if ( instrs [ 0 ].mnemonic ( ) == X86_INS_SUB &&
				instrs [ 0 ].operands ( ) [ 0 ].reg == X86_REG_RSP ) {
			return "Clang";
		}

		if ( instrs [ 0 ].mnemonic ( ) == X86_INS_SUB ) {
			if ( instrs.size ( ) >= 4 ) {
				if ( instrs [ 1 ].mnemonic ( ) == X86_INS_CALL && instrs [ 2 ].mnemonic ( ) == X86_INS_ADD && instrs [ 3 ].mnemonic ( ) == X86_INS_JMP ) {
					return "MSVC";
				}
			}
		}

		return "Unknown";
	}
	auto Parser::section_name_for_address ( uint64_t address ) const -> std::string {
		for ( const auto& section : pe_info_.section_headers ) {
			std::string name { reinterpret_cast< const char* >( section.name.data ( ) ),8 };
			name = name.substr ( 0, name.find ( '\0' ) );
			size_t start = get_image_base ( ) + section.virtual_address;
			size_t end = section.size_of_raw_data + start;
			if ( address >= start && address <= end ) {
				return name;
			}
		}
		return std::string ( );
	}
	auto Parser::override_base_address ( uint64_t address ) -> void {
		override_base_address_ = address;
	}
	auto Parser::override_entry_point ( uint64_t address ) -> void {
		override_entry_point_ = address;
	}

	auto Parser::get_pdb_path ( ) const -> std::optional<std::string> {
		auto debug_data = get_debug_directory ( );
		for ( const auto& [entry, data] : debug_data ) {
			if ( entry.type_ == 2 ) { // IMAGE_DEBUG_TYPE_CODEVIEW
				if ( !data.has_value ( ) || data->size ( ) < 4 ) {
					continue;
				}

				// Check for CV signature (RSDS or NB10)
				const uint8_t* raw_data = data->data ( );
				if ( std::memcmp ( raw_data, "RSDS", 4 ) == 0 ) {
					// RSDS format (newer PDB 7.0)
					if ( data->size ( ) < 24 ) { // Signature (4) + GUID (16) + Age (4)
						continue;
					}
					// Path starts after signature (4), GUID (16), and age (4)
					size_t path_offset = 24;
					auto path_start = raw_data + path_offset;
					auto path_end = std::find ( path_start, raw_data + data->size ( ), 0 );
					if ( path_end != raw_data + data->size ( ) ) {
						return std::string ( path_start, path_end );
					}
				}
				else if ( std::memcmp ( raw_data, "NB10", 4 ) == 0 ) {
					// NB10 format (older PDB 2.0)
					if ( data->size ( ) < 16 ) { // Signature (4) + Offset (4) + Sig (4) + Age (4)
						continue;
					}
					size_t path_offset = 16;
					auto path_start = raw_data + path_offset;
					auto path_end = std::find ( path_start, raw_data + data->size ( ), 0 );
					if ( path_end != raw_data + data->size ( ) ) {
						return std::string ( path_start, path_end );
					}
				}
			}
		}
		return std::nullopt;
	}

	auto Parser::get_pdb_url ( ) const -> std::optional<std::string> {
		auto debug_data = get_debug_directory ( );
		for ( const auto& [entry, data_opt] : debug_data ) {
			if ( entry.type_ != 2 || !data_opt.has_value ( ) ) { // IMAGE_DEBUG_TYPE_CODEVIEW
				continue;
			}

			const auto& data = *data_opt;
			if ( data.size ( ) < 4 ) {
				continue;
			}

			uint32_t signature = read_struct<uint32_t> ( data, 0 );
			if ( signature == 0x53445352 ) { // 'RSDS'
				if ( data.size ( ) < sizeof ( CV_INFO_PDB70 ) ) {
					continue;
				}

				auto cv_info = read_struct<CV_INFO_PDB70> ( data, 0 );
				size_t name_offset = sizeof ( CV_INFO_PDB70 ) - 1;
				auto name_end = std::find ( data.begin ( ) + name_offset, data.end ( ), 0 );
				if ( name_end == data.end ( ) ) {
					continue;
				}

				std::string pdb_name ( data.begin ( ) + name_offset, name_end );
				std::string pdb_filename = pdb_name.substr ( pdb_name.find_last_of ( "\\/" ) + 1 );

				char guid_str [ 33 ];
				snprintf ( guid_str, sizeof ( guid_str ), "%08X%04X%04X%02X%02X%02X%02X%02X%02X%02X%02X",
								 cv_info.guid_data1, cv_info.guid_data2, cv_info.guid_data3,
								 cv_info.guid_data4 [ 0 ], cv_info.guid_data4 [ 1 ], cv_info.guid_data4 [ 2 ],
								 cv_info.guid_data4 [ 3 ], cv_info.guid_data4 [ 4 ], cv_info.guid_data4 [ 5 ],
								 cv_info.guid_data4 [ 6 ], cv_info.guid_data4 [ 7 ] );
				std::string guid_upper = guid_str;

				return std::format (
					"https://msdl.microsoft.com/download/symbols/{}/{}{}/{}",
					pdb_filename,
					guid_upper,
					cv_info.age,
					pdb_filename
				);
			}
			else if ( signature == 0x3031424E ) { // 'NB10'
				if ( data.size ( ) < sizeof ( CV_INFO_PDB20 ) ) {
					continue;
				}

				auto cv_info = read_struct<CV_INFO_PDB20> ( data, 0 );
				size_t name_offset = sizeof ( CV_INFO_PDB20 ) - 1; // -1 for pdb_name[1]
				auto name_end = std::find ( data.begin ( ) + name_offset, data.end ( ), 0 );
				if ( name_end == data.end ( ) ) {
					continue;
				}

				std::string pdb_name ( data.begin ( ) + name_offset, name_end );
				std::string pdb_filename = pdb_name.substr ( pdb_name.find_last_of ( "\\/" ) + 1 );

				char guid_str [ 9 ];
				snprintf ( guid_str, sizeof ( guid_str ), "%08X", cv_info.signature );
				std::string guid_upper = guid_str;

				return std::format (
					"https://msdl.microsoft.com/download/symbols/{}/{}{}/{}",
					pdb_filename,
					guid_upper,
					cv_info.age,
					pdb_filename
				);
			}
		}
		return std::nullopt;
	}

	auto Parser::get_imports ( ) const -> std::map<std::string, std::map<std::string, uint64_t>> {
		std::map<std::string, std::map<std::string, uint64_t>> result;
		auto import_dir = get_import_directory ( );

		for ( const auto& [dll_name, entries] : import_dir ) {
			std::map<std::string, uint64_t> func_map;
			for ( const auto& [ordinal, opt_name, thunk_rva] : entries ) {
				std::string func_name;
				if ( opt_name.has_value ( ) ) {
					func_name = opt_name.value ( );
				}
				else {
					func_name = std::format ( "Ordinal_{}", ordinal ); // Fallback for ordinal-only imports
				}
				uint64_t iat_addr = get_image_base ( ) + thunk_rva;
				func_map [ func_name ] = iat_addr;

				std::print ( "Mapping {}!{} to {:016x}h\n", dll_name, func_name, iat_addr );
			}
			result [ dll_name ] = std::move ( func_map );
		}

		return result;
	}

	auto Parser::fix_security_cookie ( ) -> void {
		__debugbreak ( );
	}

	bool Parser::is_address_in_iat ( uint64_t va ) const {
		uint64_t image_base = get_image_base ( );
		uint64_t rva = va - image_base;

		// Get Import Directory Table info
		IMAGE_DATA_DIRECTORY* import_dir = ( IMAGE_DATA_DIRECTORY* ) &pe_info_.optional_header.data_directories [ IMAGE_DIRECTORY_ENTRY_IMPORT ];
		if ( import_dir->VirtualAddress == 0 || import_dir->Size == 0 ) {
			return false;
		}

		size_t import_desc_offset = rva_to_offset ( import_dir->VirtualAddress );
		auto import_descriptor = reinterpret_cast< const IMAGE_IMPORT_DESCRIPTOR* >( buffer_.data ( ) + import_desc_offset );

		// Iterate through import descriptors
		while ( import_descriptor->Characteristics != 0 ) {
			uint32_t iat_rva = import_descriptor->FirstThunk; // OriginalFirstThunk for INT
			if ( iat_rva == 0 ) continue; // Skip if no IAT

			// We need the *size* of the IAT for this descriptor.
			// This is tricky, as the size isn't directly in the descriptor.
			// We infer it by finding the end marker (null QWORD).
			size_t iat_offset = rva_to_offset ( iat_rva );
			uint64_t current_iat_entry_rva = iat_rva;
			size_t current_iat_offset = iat_offset;

			while ( true ) {
				// Boundary check for reading QWORD
				if ( current_iat_offset + sizeof ( uint64_t ) > buffer_.size ( ) ) {
					// Or throw an exception / log error
					break;
				}
				uint64_t entry_value = *reinterpret_cast< const uint64_t* >( buffer_.data ( ) + current_iat_offset );
				if ( entry_value == 0 ) {
					break; // End of this IAT
				}

				// Check if the target RVA falls within this specific entry's address
				if ( rva == current_iat_entry_rva ) {
					return true;
				}

				current_iat_entry_rva += sizeof ( uint64_t );
				current_iat_offset += sizeof ( uint64_t );
			}
			// If we reach here, 'rva' wasn't found in this specific IAT.
			// Move to the next import descriptor.
			import_descriptor++;
		}

		return false; // Not found in any IAT
	}

	uint64_t Parser::read_qword_at_rva ( uint64_t rva ) const {
		size_t offset = rva_to_offset ( static_cast< uint32_t >( rva ) ); // This throws if RVA is invalid or out of section bounds
		if ( offset + sizeof ( uint64_t ) > buffer_.size ( ) ) {
			throw std::out_of_range ( std::format ( "RVA 0x{:x} read (offset 0x{:x}) exceeds PE buffer bounds (size 0x{:x})", rva, offset, buffer_.size ( ) ) );
		}
		return *reinterpret_cast< const uint64_t* >( buffer_.data ( ) + offset );
	}
}
```

`shared/types.hpp`:

```hpp
#pragma once

#include <cstdint>
#include <immintrin.h>
#include <string>
#include <bit>
#include <numeric>
#include <format>
#include <array>
#include <unordered_map>
#include <unordered_set>
#include <print>
#include <variant>
#include <intrin.h>
#include <functional>
#include <concepts>

#include "capstone++.hpp"

#include <boost/multiprecision/cpp_bin_float.hpp>
#include <boost/multiprecision/cpp_int.hpp>
#include <cfenv>

#define WIN32_LEAN_AND_MEAN
#define NOMINMAX
#include <Windows.h>

struct EmulationContext;

namespace mp = boost::multiprecision;
using int128_t = mp::int128_t;
using uint128_t = mp::uint128_t;
using uint256_t = mp::uint256_t;
using uint512_t = mp::uint512_t;
using float80_t = mp::number<mp::cpp_bin_float<
  64, // Number of significand bits (including explicit leading bit when non-zero)
  mp::digit_base_2, // Binary representation
  void, std::int16_t, // Use 16-bit exponent type
  -16382, 16383      // Min/Max exponent values
>, mp::et_off>;    // Disable expression templates for simplicity

static constexpr uint8_t FPU_TAG_VALID = 0b00;
static constexpr uint8_t FPU_TAG_ZERO = 0b01;
static constexpr uint8_t FPU_TAG_SPECIAL = 0b10;
static constexpr uint8_t FPU_TAG_EMPTY = 0b11;
static constexpr uint16_t FSW_IE = ( 1 << 0 );
static constexpr uint16_t FSW_DE = ( 1 << 1 );
static constexpr uint16_t FSW_ZE = ( 1 << 2 );
static constexpr uint16_t FSW_OE = ( 1 << 3 );
static constexpr uint16_t FSW_UE = ( 1 << 4 );
static constexpr uint16_t FSW_PE = ( 1 << 5 );
static constexpr uint16_t FSW_SF = ( 1 << 6 );
static constexpr uint16_t FSW_ES = ( 1 << 7 );
static constexpr uint16_t FSW_C0 = ( 1 << 8 );
static constexpr uint16_t FSW_C1 = ( 1 << 9 );
static constexpr uint16_t FSW_C2 = ( 1 << 10 );
static constexpr uint16_t FSW_TOP_SHIFT = 11;
static constexpr uint16_t FSW_TOP_MASK = ( 0b111 << FSW_TOP_SHIFT );
static constexpr uint16_t FSW_C3 = ( 1 << 14 );
static constexpr uint16_t FSW_B = ( 1 << 15 );
static constexpr uint16_t FCW_IM = ( 1 << 0 );
static constexpr uint16_t FCW_DM = ( 1 << 1 );
static constexpr uint16_t FCW_ZM = ( 1 << 2 );
static constexpr uint16_t FCW_OM = ( 1 << 3 );
static constexpr uint16_t FCW_UM = ( 1 << 4 );
static constexpr uint16_t FCW_PM = ( 1 << 5 );
// Bits 8-9: Precision Control (PC) - 00=24b, 01=N/A, 10=53b, 11=64b
static constexpr uint16_t FCW_PC_SHIFT = 8;
static constexpr uint16_t FCW_PC_MASK = ( 0b11 << FCW_PC_SHIFT );
static constexpr uint16_t FCW_RC_SHIFT = 10;
static constexpr uint16_t FCW_RC_MASK = ( 0b11 << FCW_RC_SHIFT );

struct ExceptCategories {
  bool MEMORY : 1 = false; // Checks for general non-stack memory operands ([mem])
  bool STACK : 1 = false; // Checks specifically related to RSP and stack accesses
  bool ARITHMETIC : 1 = false; // Checks for integer calculation errors (#DE, #BR, #OF)
  bool INVALID_USAGE : 1 = false; // Checks for privilege, I/O, LOCK, invalid forms, traps (#UD, #GP, #BP, #DB, #NM)
  bool ALIGNMENT : 1 = false; // Checks for memory alignment requirements (#AC, intrinsic #GP)
  bool FPU_SIMD : 1 = false; // Checks for FPU/MMX/SSE/AVX errors (#MF, #XF)
  bool CONTROL_FLOW : 1 = false; // Checks for branch target validity (less common exception source)
};

struct MemExcepConditions {
  // --- Segment Related (User-Mode) ---
  bool CHECK_NULL_FS_SELECTOR : 1 = false; // Usage of FS override with NULL FS selector -> #GP(0) -> AV
  bool CHECK_NULL_GS_SELECTOR : 1 = false; // Usage of GS override with NULL GS selector -> #GP(0) -> AV
  // --- Address Related ---
  bool CHECK_CANONICAL_ADDRESS : 1 = false; // Effective Address is non-canonical -> #GP(0) -> AV
  // General page faults (#PF) and segment protection (#GP writing read-only) -> Handled by Host OS AV
};

struct StackExcepConditions {
  bool CHECK_STACK_BOUNDS : 1 = false; // RSP change or access exceeds TEB StackLimit/StackBase -> StackOverflow/AV
  bool CHECK_STACK_ALIGNMENT : 1 = false; // RSP not correctly aligned for operation (PUSH/POP/CALL/RET/SSE stack mem) -> #AC or #SS -> AV/Misaligned
  bool CHECK_NULL_SS_SELECTOR : 1 = false; // SS Selector is NULL -> #SS(0) -> AV (Less likely in 64-bit user mode unless explicitly loaded)
  bool CHECK_CANONICAL_STACK_ADDRESS : 1 = false; // RSP becomes non-canonical -> #SS(0) -> AV
};

struct ArithExcepConditions {
  bool CHECK_DIVIDE_ERROR : 1 = false; // DIV/IDIV divisor=0 or quotient overflow -> #DE -> DivByZero
  bool CHECK_BOUND_RANGE : 1 = false; // BOUND index < lower or index > upper -> #BR -> BoundsExceeded
  bool CHECK_INTO_OVERFLOW : 1 = false; // INTO executed when RFLAGS.OF=1 -> #OF -> Overflow
};

struct InvalidUsageExcepConditions {
  // --- Privilege & I/O ---
  bool CHECK_PRIVILEGED_INSTRUCTION : 1 = false; // HLT, LGDT, MOV CRn etc. from CPL=3 -> #GP(0) -> PrivInstr
  bool CHECK_IO_INSTRUCTION : 1 = false; // IN/OUT/INS/OUTS without permission -> #GP(0) -> PrivInstr

  // --- LOCK Prefix ---
  bool CHECK_INVALID_LOCK_PREFIX : 1 = false; // LOCK on invalid instruction or non-mem dest -> #UD -> IllegalInstr

  // --- Opcode/Instruction Form ---
  bool CHECK_INVALID_OPCODE_FORM : 1 = false; // Undefined opcode, invalid operands, missing mandatory prefix (VEX/EVEX etc.) -> #UD -> IllegalInstr
  bool CHECK_OPERAND_SIZE_MISMATCH : 1 = false; // e.g., String ops with mismatched operand sizes if not allowed -> #UD? or #GP? (Check specific instr)

  // --- Traps ---
  bool CHECK_INT3_BREAKPOINT : 1 = false; // INT 3 encountered -> #BP -> Breakpoint
  bool CHECK_DEBUG_TRAP : 1 = false; // Debug register match or RF=1 or TF=1 (if emulating) -> #DB -> SingleStep/DebugTrap

  // --- FPU/SIMD State ---
  bool CHECK_FPU_DEVICE_NOT_AVAILABLE : 1 = false; // Access FPU/MMX/SSE when CR0.TS=1 or CR0.EM=1 -> #NM -> DeviceNotAvailable
};

struct AlignExcepConditions {
  bool CHECK_GENERAL_AC_FLAG : 1 = false; // Unaligned access + CPL=3 + RFLAGS.AC=1 + CR0.AM=1 -> #AC -> Misaligned
  bool CHECK_INTRINSIC_ALIGNMENT : 1 = false; // Instruction requires specific alignment (MOVAPS/DQA, FXSAVE, etc.) regardless of AC flag -> #GP(0) -> AV (often)
};

struct FpuSimdExcepConditions {
  // These are typically checked *after* execution based on status flags and control masks
  bool CHECK_X87_FAULT_MF : 1 = false; // Unmasked x87 exception occurred (check FSW vs FCW) -> #MF -> FPUError
  bool CHECK_SIMD_FP_FAULT_XF : 1 = false; // Unmasked SIMD FP exception occurred (check MXCSR status vs mask) -> #XF -> SIMDFPError
};

struct ControlFlowExcepConditions {
  // These often result in AV due to bad memory access, but represent control flow logic errors
  bool CHECK_NON_CANONICAL_TARGET : 1 = false; // JMP/CALL target address is non-canonical -> #GP(0) -> AV
  bool CHECK_RETURN_STACK_MISMATCH : 1 = false; // RET executed when stack pointer is invalid (not a direct exception, but leads to crash/AV)
};

struct InstructionExceptionInfo {
  ExceptCategories categories {}; // Default categories based on mnemonic

  // --- Intrinsic Properties ---
  bool is_privileged : 1 = false;
  bool is_io : 1 = false;
  bool is_int3 : 1 = false;
  bool is_invalid_by_default : 1 = false;
  bool is_fpu_related : 1 = false; // Touches x87 state
  bool is_mmx_related : 1 = false; // Touches MMX state
  bool is_sse_avx_related : 1 = false; // Touches SSE/AVX state

  bool lock_prefix_allowed : 1 = false;
  bool lock_prefix_always_invalid : 1 = false;

  bool is_divide : 1 = false;
  bool is_bound : 1 = false;
  bool is_into : 1 = false;

  bool requires_intrinsic_alignment : 1 = false;
  uint8_t intrinsic_alignment_bytes : 4 = 0; // e.g., 8, 16, 32, 64

  bool is_explicit_push : 1 = false;
  bool is_explicit_pop : 1 = false;
  bool uses_string_registers : 1 = false; // Uses RSI/RDI implicitly (MOVS, etc.)
  bool modifies_rsp_implicitly : 1 = false; // CALL, RET, PUSH, POP, ENTER, LEAVE
};

struct GuestExceptionInfo {
  bool exception_occurred = false;

  // Fields matching EXCEPTION_RECORD
  DWORD    ExceptionCode = 0;
  DWORD    ExceptionFlags = 0; // e.g., EXCEPTION_NONCONTINUABLE
  uint64_t ExceptionAddress = 0; // RIP of faulting instruction
  DWORD    NumberParameters = 0;
  std::array<ULONG_PTR, EXCEPTION_MAXIMUM_PARAMETERS> ExceptionInformation = { 0 };

  // Additional info needed for CONTEXT setup or dispatch
  uint64_t FaultingVa = 0; // VA causing fault (used for Param[1] in AV)

  // --- Helper methods to populate for standard exceptions ---
  void set_exception ( DWORD code, uint64_t rip, uint64_t fault_va = 0 ) {
    exception_occurred = true;
    ExceptionCode = code;
    ExceptionAddress = rip;
    FaultingVa = fault_va; // Store separately for potential use
    ExceptionFlags = 0;    // Hardware exceptions usually start continuable
    NumberParameters = 0;
    ExceptionInformation.fill ( 0 );

    // Populate standard parameters based on code
    if ( code == EXCEPTION_ACCESS_VIOLATION ) {
      NumberParameters = 2;
      ExceptionInformation [ 0 ] = 0; // Default to Read access violation
      ExceptionInformation [ 1 ] = fault_va;
    }
    else if ( code == EXCEPTION_STACK_OVERFLOW ) {
      // Kernel typically raises AV for guard page hit, but if we detect
      // stack bounds violation directly, we might use Stack Overflow code.
      // Parameters for Stack Overflow itself are often zero from hardware.
      NumberParameters = 0; // Or potentially ExceptionInformation[0] = fault_va; Check MSDN/tests.
    }
    else if ( code == EXCEPTION_DATATYPE_MISALIGNMENT ||
            code == EXCEPTION_ILLEGAL_INSTRUCTION ||
            code == EXCEPTION_PRIV_INSTRUCTION ||
            code == EXCEPTION_INT_DIVIDE_BY_ZERO ||
            code == EXCEPTION_BREAKPOINT ||
            code == EXCEPTION_ARRAY_BOUNDS_EXCEEDED || // For #BR
            code == EXCEPTION_INT_OVERFLOW ) {         // For #OF (INTO)
      NumberParameters = 0;
    }
  }

  // Specific helper for Access Violation to set read/write/exec type
  void set_access_violation ( uint64_t rip, uint64_t va, bool is_write, bool is_execute = false ) {
    set_exception ( EXCEPTION_ACCESS_VIOLATION, rip, va );
    ExceptionInformation [ 0 ] = is_write ? 1 : ( is_execute ? 8 : 0 ); // Write=1, Exec=8, Read=0
    ExceptionInformation [ 1 ] = va;
    NumberParameters = 2;
  }

  // Helper to simulate RaiseException (if needed later)
  void set_from_raise_exception ( DWORD code, DWORD flags, DWORD num_params, const ULONG_PTR* params, uint64_t rip ) {
    exception_occurred = true;
    ExceptionCode = code;
    ExceptionFlags = flags;
    ExceptionAddress = rip; // Address of RaiseException call site
    FaultingVa = 0; // Not applicable directly
    NumberParameters = ( num_params > EXCEPTION_MAXIMUM_PARAMETERS ) ? EXCEPTION_MAXIMUM_PARAMETERS : num_params;
    ExceptionInformation.fill ( 0 );
    if ( params && NumberParameters > 0 ) {
      memcpy ( ExceptionInformation.data ( ), params, NumberParameters * sizeof ( ULONG_PTR ) );
    }
  }
};

struct PreCheckInfo {
  bool has_lock_prefix = false;
  bool has_mem_operand = false;
  uint64_t mem_effective_addr = 0;
  uint8_t mem_op_size = 0;
  x86_reg mem_segment_reg = X86_REG_INVALID;
  bool uses_fs = false;
  bool uses_gs = false;
  bool mem_is_write = false; // <<< ADDED
  bool is_stack_push = false;
  bool is_stack_pop = false;
  uint64_t stack_access_addr = 0;
  uint8_t stack_access_size = 0;
  bool alignment_required_by_ac = false;
  bool alignment_required_intrinsic = false;
  uint8_t required_alignment_bytes = 1;
};

inline int parity ( uint64_t x ) {
#ifdef _MSC_VER
  return static_cast< int >( __popcnt64 ( x ) & 1 );
#elif defined(__GNUC__) || defined(__clang__)
  return __builtin_popcountll ( x ) & 1;
#else
  // Portable fallback (can be slow)
  int count = 0;
  while ( x ) {
    count += ( x & 1 );
    x >>= 1;
  }
  return count & 1;
#endif
}

struct __NT_TIB64 {
  uint64_t ExceptionList;                                                //0x0
  uint64_t StackBase;                                                    //0x8
  uint64_t StackLimit;                                                   //0x10
  uint64_t SubSystemTib;                                                 //0x18
  union {
    uint64_t FiberData;                                                //0x20
    unsigned long Version;                                                      //0x20
  };
  uint64_t ArbitraryUserPointer;                                         //0x28
  uint64_t Self;                                                         //0x30
};

struct _CLIENT_ID64 {
  uint64_t UniqueProcess;                                                //0x0
  uint64_t UniqueThread;                                                 //0x8
};

struct _LIST_ENTRY64 {
  uint64_t Flink;
  uint64_t Blink;
};

struct _ACTIVATION_CONTEXT_STACK64 {
  uint64_t ActiveFrame;                                                  //0x0
  _LIST_ENTRY64 FrameListCache;                                     //0x8
  unsigned long Flags;                                                            //0x18
  unsigned long NextCookieSequenceNumber;                                         //0x1c
  unsigned long StackId;                                                          //0x20
};

struct _GDI_TEB_BATCH64 {
  ULONG Offset : 30;                                                        //0x0
  ULONG InProcessing : 1;                                                   //0x0
  ULONG HasRenderingCommand : 1;                                            //0x0
  ULONGLONG HDC;                                                          //0x8
  ULONG Buffer [ 310 ];                                                      //0x10
};

struct _STRING64 {
  USHORT Length;                                                          //0x0
  USHORT MaximumLength;                                                   //0x2
  ULONGLONG Buffer;                                                       //0x8
};

struct _TEB64 {
  __NT_TIB64 NtTib;                                                 //0x0
  uint64_t EnvironmentPointer;                                           //0x38
  _CLIENT_ID64 ClientId;                                           //0x40
  uint64_t ActiveRpcHandle;                                              //0x50
  uint64_t ThreadLocalStoragePointer;                                    //0x58
  uint64_t ProcessEnvironmentBlock;                                      //0x60
  unsigned long LastErrorValue;                                                   //0x68
  unsigned long CountOfOwnedCriticalSections;                                     //0x6c
  uint64_t CsrClientThread;                                              //0x70
  uint64_t Win32ThreadInfo;                                              //0x78
  unsigned long User32Reserved [ 26 ];                                               //0x80
  unsigned long UserReserved [ 5 ];                                                  //0xe8
  uint64_t WOW32Reserved;                                                //0x100
  unsigned long CurrentLocale;                                                    //0x108
  unsigned long FpSoftwareStatusRegister;                                         //0x10c
  uint64_t ReservedForDebuggerInstrumentation [ 16 ];                       //0x110
  uint64_t SystemReserved1 [ 25 ];                                          //0x190
  uint64_t HeapFlsData;                                                  //0x258
  uint64_t RngState [ 4 ];                                                  //0x260
  
  CHAR PlaceholderCompatibilityMode;                                      //0x280
  UCHAR PlaceholderHydrationAlwaysExplicit;                               //0x281
  CHAR PlaceholderReserved [ 10 ];                                           //0x282
  unsigned long ProxiedProcessId;                                                 //0x28c
  _ACTIVATION_CONTEXT_STACK64 _ActivationStack;                    //0x290
  UCHAR WorkingOnBehalfTicket [ 8 ];                                         //0x2b8
  LONG ExceptionCode;                                                     //0x2c0
  UCHAR Padding0 [ 4 ];                                                      //0x2c4
  uint64_t ActivationContextStackPointer;                                //0x2c8
  uint64_t InstrumentationCallbackSp;                                    //0x2d0
  uint64_t InstrumentationCallbackPreviousPc;                            //0x2d8
  uint64_t InstrumentationCallbackPreviousSp;                            //0x2e0
  unsigned long TxFsContext;                                                      //0x2e8
  UCHAR InstrumentationCallbackDisabled;                                  //0x2ec
  UCHAR UnalignedLoadStoreExceptions;                                     //0x2ed
  UCHAR Padding1 [ 2 ];                                                      //0x2ee
  _GDI_TEB_BATCH64 GdiTebBatch;                                    //0x2f0
  _CLIENT_ID64 RealClientId;                                       //0x7d8
  uint64_t GdiCachedProcessHandle;                                       //0x7e8
  unsigned long GdiClientPID;                                                     //0x7f0
  unsigned long GdiClientTID;                                                     //0x7f4
  uint64_t GdiThreadLocalInfo;                                           //0x7f8
  uint64_t Win32ClientInfo [ 62 ];                                          //0x800
  uint64_t glDispatchTable [ 233 ];                                         //0x9f0
  uint64_t glReserved1 [ 29 ];                                              //0x1138
  uint64_t glReserved2;                                                  //0x1220
  uint64_t glSectionInfo;                                                //0x1228
  uint64_t glSection;                                                    //0x1230
  uint64_t glTable;                                                      //0x1238
  uint64_t glCurrentRC;                                                  //0x1240
  uint64_t glContext;                                                    //0x1248
  unsigned long LastStatusValue;                                                  //0x1250
  UCHAR Padding2 [ 4 ];                                                      //0x1254
  _STRING64 StaticUnicodeString;                                   //0x1258
  WCHAR StaticUnicodeBuffer [ 261 ];                                         //0x1268
  UCHAR Padding3 [ 6 ];                                                      //0x1472
  uint64_t DeallocationStack;                                            //0x1478
  uint64_t TlsSlots [ 64 ];                                                 //0x1480
  LIST_ENTRY64 TlsLinks;                                           //0x1680
  uint64_t Vdm;                                                          //0x1690
  uint64_t ReservedForNtRpc;                                             //0x1698
  uint64_t DbgSsReserved [ 2 ];                                             //0x16a0
  unsigned long HardErrorMode;                                                    //0x16b0
  UCHAR Padding4 [ 4 ];                                                      //0x16b4
  uint64_t Instrumentation [ 11 ];                                          //0x16b8
  _GUID ActivityId;                                                //0x1710
  uint64_t SubProcessTag;                                                //0x1720
  uint64_t PerflibData;                                                  //0x1728
  uint64_t EtwTraceData;                                                 //0x1730
  uint64_t WinSockData;                                                  //0x1738
  unsigned long GdiBatchCount;                                                    //0x1740
  union {
    _PROCESSOR_NUMBER CurrentIdealProcessor;                     //0x1744
    unsigned long IdealProcessorValue;                                          //0x1744
    struct {
      UCHAR ReservedPad0;                                             //0x1744
      UCHAR ReservedPad1;                                             //0x1745
      UCHAR ReservedPad2;                                             //0x1746
      UCHAR IdealProcessor;                                           //0x1747
    };
  };
  unsigned long GuaranteedStackBytes;                                             //0x1748
  UCHAR Padding5 [ 4 ];                                                      //0x174c
  uint64_t ReservedForPerf;                                              //0x1750
  uint64_t ReservedForOle;                                               //0x1758
  unsigned long WaitingOnLoaderLock;                                              //0x1760
  UCHAR Padding6 [ 4 ];                                                      //0x1764
  uint64_t SavedPriorityState;                                           //0x1768
  uint64_t ReservedForCodeCoverage;                                      //0x1770
  uint64_t ThreadPoolData;                                               //0x1778
  uint64_t TlsExpansionSlots;                                            //0x1780
  uint64_t ChpeV2CpuAreaInfo;                                            //0x1788
  uint64_t Unused;                                                       //0x1790
  unsigned long MuiGeneration;                                                    //0x1798
  unsigned long IsImpersonating;                                                  //0x179c
  uint64_t NlsCache;                                                     //0x17a0
  uint64_t pShimData;                                                    //0x17a8
  unsigned long HeapData;                                                         //0x17b0
  UCHAR Padding7 [ 4 ];                                                      //0x17b4
  uint64_t CurrentTransactionHandle;                                     //0x17b8
  uint64_t ActiveFrame;                                                  //0x17c0
  uint64_t FlsData;                                                      //0x17c8
  uint64_t PreferredLanguages;                                           //0x17d0
  uint64_t UserPrefLanguages;                                            //0x17d8
  uint64_t MergedPrefLanguages;                                          //0x17e0
  unsigned long MuiImpersonation;                                                 //0x17e8
  union {
    volatile USHORT CrossTebFlags;                                      //0x17ec
    USHORT SpareCrossTebBits : 16;                                        //0x17ec
  };
  union {
    USHORT SameTebFlags;                                                //0x17ee
    struct {
      USHORT SafeThunkCall : 1;                                         //0x17ee
      USHORT InDebugPrint : 1;                                          //0x17ee
      USHORT HasFiberData : 1;                                          //0x17ee
      USHORT SkipThreadAttach : 1;                                      //0x17ee
      USHORT WerInShipAssertCode : 1;                                   //0x17ee
      USHORT RanProcessInit : 1;                                        //0x17ee
      USHORT ClonedThread : 1;                                          //0x17ee
      USHORT SuppressDebugMsg : 1;                                      //0x17ee
      USHORT DisableUserStackWalk : 1;                                  //0x17ee
      USHORT RtlExceptionAttached : 1;                                  //0x17ee
      USHORT InitialThread : 1;                                         //0x17ee
      USHORT SessionAware : 1;                                          //0x17ee
      USHORT LoadOwner : 1;                                             //0x17ee
      USHORT LoaderWorker : 1;                                          //0x17ee
      USHORT SkipLoaderInit : 1;                                        //0x17ee
      USHORT SkipFileAPIBrokering : 1;                                  //0x17ee
    };
  };
  uint64_t TxnScopeEnterCallback;                                        //0x17f0
  uint64_t TxnScopeExitCallback;                                         //0x17f8
  uint64_t TxnScopeContext;                                              //0x1800
  unsigned long LockCount;                                                        //0x1808
  LONG WowTebOffset;                                                      //0x180c
  uint64_t ResourceRetValue;                                             //0x1810
  uint64_t ReservedForWdf;                                               //0x1818
  uint64_t ReservedForCrt;                                               //0x1820
  _GUID EffectiveContainerId;                                      //0x1828
  uint64_t LastSleepCounter;                                             //0x1838
  unsigned long SpinCallCount;                                                    //0x1840
  UCHAR Padding8 [ 4 ];                                                      //0x1844
  uint64_t ExtendedFeatureDisableMask;                                   //0x1848
  uint64_t SchedulerSharedDataSlot;                                      //0x1850
  uint64_t HeapWalkContext;                                              //0x1858
  _GROUP_AFFINITY64 PrimaryGroupAffinity;                          //0x1860
  unsigned long Rcu [ 2 ];                                                           //0x1870
};

inline const wchar_t* driverName = L"\\Driver\\EasyAntiCheat_EOS";
inline const wchar_t* registryBuffer = L"\\REGISTRY\\MACHINE\\SYSTEM\\ControlSet001\\Services\\EasyAntiCheat_EOSSys";
struct _UNICODE_STRING {
  USHORT Length;                                                          //0x0
  USHORT MaximumLength;                                                   //0x2
  WCHAR* Buffer;                                                          //0x8
};
struct _DRIVER_OBJECT {
  SHORT Type;                                                             //0x0
  SHORT Size;                                                             //0x2
  struct _DEVICE_OBJECT* DeviceObject;                                    //0x8
  ULONG Flags;                                                            //0x10
  VOID* DriverStart;                                                      //0x18
  ULONG DriverSize;                                                       //0x20
  VOID* DriverSection;                                                    //0x28
  struct _DRIVER_EXTENSION* DriverExtension;                              //0x30
  struct _UNICODE_STRING DriverName;                                      //0x38
  struct _UNICODE_STRING* HardwareDatabase;                               //0x48
  struct _FAST_IO_DISPATCH* FastIoDispatch;                               //0x50
  LONG ( *DriverInit )( struct _DRIVER_OBJECT* arg1, struct _UNICODE_STRING* arg2 ); //0x58
  VOID ( *DriverStartIo )( struct _DEVICE_OBJECT* arg1, struct _IRP* arg2 );  //0x60
  VOID ( *DriverUnload )( struct _DRIVER_OBJECT* arg1 );                      //0x68
  LONG ( *MajorFunction [ 28 ] )( struct _DEVICE_OBJECT* arg1, struct _IRP* arg2 ); //0x70
};

struct MXCSRFlags {
  uint32_t IE : 1;  // Bit 0: Invalid Operation Exception
  uint32_t DE : 1;  // Bit 1: Denormal Exception
  uint32_t ZE : 1;  // Bit 2: Divide-by-Zero Exception
  uint32_t OE : 1;  // Bit 3: Overflow Exception
  uint32_t UE : 1;  // Bit 4: Underflow Exception
  uint32_t PE : 1;  // Bit 5: Precision Exception
  uint32_t DAZ : 1;  // Bit 6: Denormals Are Zero
  uint32_t IM : 1;  // Bit 7: Invalid Operation Mask
  uint32_t DM : 1;  // Bit 8: Denormal Mask
  uint32_t ZM : 1;  // Bit 9: Zero-Divide Mask
  uint32_t OM : 1;  // Bit 10: Overflow Mask
  uint32_t UM : 1;  // Bit 11: Underflow Mask
  uint32_t PM : 1;  // Bit 12: Precision Mask
  uint32_t RC : 2;  // Bits 13-14: Rounding Control (00=RN, 01=RD, 10=RU, 11=RZ)
  uint32_t FZ : 1;  // Bit 15: Flush to Zero
  uint32_t reserved : 16; // Bits 16-31: Reserved (0)
};

struct RFLAGS {
  uint64_t CF : 1;  // Bit 0: Carry Flag
  uint64_t reserved1 : 1;  // Bit 1: Always 1
  uint64_t PF : 1;  // Bit 2: Parity Flag
  uint64_t reserved2 : 1;  // Bit 3: Reserved (0)
  uint64_t AF : 1;  // Bit 4: Auxiliary Carry Flag
  uint64_t reserved3 : 1;  // Bit 5: Reserved (0)
  uint64_t ZF : 1;  // Bit 6: Zero Flag
  uint64_t SF : 1;  // Bit 7: Sign Flag
  uint64_t TF : 1;  // Bit 8: Trap Flag
  uint64_t IF : 1;  // Bit 9: Interrupt Enable Flag (if is reserved, so if_)
  uint64_t DF : 1;  // Bit 10: Direction Flag
  uint64_t OF : 1;  // Bit 11: Overflow Flag
  uint64_t IOPL : 2;  // Bits 12-13: I/O Privilege Level
  uint64_t NT : 1;  // Bit 14: Nested Task
  uint64_t reserved4 : 1;  // Bit 15: Reserved (0)
  uint64_t RF : 1;  // Bit 16: Resume Flag
  uint64_t VM : 1;  // Bit 17: Virtual-8086 Mode
  uint64_t AC : 1;  // Bit 18: Alignment Check
  uint64_t VIF : 1;  // Bit 19: Virtual Interrupt Flag
  uint64_t VIP : 1;  // Bit 20: Virtual Interrupt Pending
  uint64_t ID : 1;  // Bit 21: Identification Flag
  uint64_t reserved5 : 10; // Bits 22-31: Reserved (0)
  uint64_t reserved6 : 32; // Bits 32-63: Reserved (0)
};

struct CallFrame {
  uint64_t return_addr;              // Address to return to
  int64_t rsp_before_call;           // RSP before the call
  std::unordered_map<x86_reg, uint64_t> caller_saved_regs; // Save caller-saved registers
};


struct InstructionEffect {
  std::string instr_str;
  std::vector<std::string> changes;
  std::unordered_set<x86_reg> modified_regs;
  std::unordered_set<uint64_t> modified_mem;
  bool is_no_op = false;
  bool no_log = false;

  void normalize_registers ( EmulationContext* ctx );
  void push_to_changes ( const EmulationContext& ctx, const std::string& data );
  void push_to_changes ( const EmulationContext* ctx, const std::string& data );
  void push_to_changes ( const std::string& data );
};

struct LoadedModule {
  HMODULE handle;
  uint64_t base_address;
  uint64_t size;
  std::unique_ptr<capstone::Decoder> decoder;
};

struct FPUStack {
  std::array<float80_t, 8> fpu_stack;
  uint16_t fpu_tag_word = 0xFFFF;
  uint16_t fpu_status_word = 0;         // Includes B, C3-C0, TOP, ES, SF, PE, UE, OE, ZE, DE, IE
  uint16_t fpu_control_word = 0x037F;   // Default masks, RC=0 (nearest), PC=3 (64b)
  uint16_t mxcsr_control = 0x1F80;
  uint8_t fpu_top = 0;
};

struct CPUFlags {
  RFLAGS flags; // TODO: default init based on HW
  MXCSRFlags mxcsr = {
          .IE = 0,
          .DE = 0,
          .ZE = 0,
          .OE = 0,
          .UE = 0,
          .PE = 0,
          .DAZ = 0,
          .IM = 1,
          .DM = 1,
          .ZM = 1,
          .OM = 1,
          .UM = 1,
          .PM = 1, // Masks default to 1 (masked)
          .RC = 0,
          .FZ = 0,
          .reserved = 0
  };
};


enum KGPR {
  // General-purpose registers (64-bit)
  KRAX,
  KRBX,
  KRCX,
  KRDX,
  KRSI,
  KRDI,
  KRBP,
  KRSP,
  KR8,
  KR9,
  KR10,
  KR11,
  KR12,
  KR13,
  KR14,
  KR15,
  KRIP, // Instruction pointer

  // Debug registers
  KDR0,
  KDR1,
  KDR2,
  KDR3,
  KDR4,
  KDR5,
  KDR6,
  KDR7,

  // Control registers
  KCR0, // Flags
  KCR2, // Page fault linear address
  KCR3, // Page table base
  KCR4, // CPU features/extensions
  KCR8, // CPU priority, interrupts

  // Segment registers
  KCS,
  KDS,
  KES,
  KFS,
  KGS,
  KSS,

  KGPR_COUNT // Total count for array sizing
};
```

`vcpkg-configuration.json`:

```json
{
  "default-registry": {
    "kind": "git",
    "baseline": "0c4cf19224a049cf82f4521e29e39f7bd680440c",
    "repository": "https://github.com/microsoft/vcpkg"
  },
  "registries": [
    {
      "kind": "artifact",
      "location": "https://github.com/microsoft/vcpkg-ce-catalog/archive/refs/heads/main.zip",
      "name": "microsoft"
    }
  ]
}

```

`vcpkg.json`:

```json
{
  "dependencies": [
    "boost-multiprecision",
    {
      "name": "capstone",
      "features": [
        "x86"
      ]
    },
    {
      "name": "imgui",
      "features": [
        "dx11-binding",
        "win32-binding"
      ]
    },
    "zlib",
    "asmjit"
  ]
}

```