Project Path: arc_gmh5225_vmlinux-to-elf_a5iyr5on

Source Tree:

```txt
arc_gmh5225_vmlinux-to-elf_a5iyr5on
├── LICENSE
├── README.md
├── kallsyms-finder
├── pics
│   └── landing_illustration.png
├── setup.py
├── vmlinux-to-elf
└── vmlinux_to_elf
    ├── __init__.py
    ├── architecture_detecter.py
    ├── elf_symbolizer.py
    ├── kallsyms_finder.py
    ├── main.py
    ├── tests.py
    ├── utils
    │   ├── __init__.py
    │   ├── elf.py
    │   ├── elf_tests
    │   │   ├── ls_arm32_le.elf
    │   │   ├── ls_mips32_be.elf
    │   │   ├── ls_mips32_le.elf
    │   │   ├── ls_mips64_be.elf
    │   │   ├── ls_renesas.elf
    │   │   ├── ls_x64.elf
    │   │   └── x86_shared_library.so
    │   ├── lz4_legacy.py
    │   └── pretty_print.py
    └── vmlinuz_decompressor.py

```

`LICENSE`:

```
                    GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.

```

`README.md`:

```md
# vmlinux-to-elf

This tool allows to obtain a fully analyzable .ELF file from a vmlinux/vmlinuz/bzImage/zImage kernel image (either a raw binary blob or a preexisting but stripped .ELF file), with recovered function and variable symbols.

<p align="center"><img src="https://raw.githubusercontent.com/marin-m/vmlinux-to-elf/master/pics/landing_illustration.png"></p>

For this, it scans your kernel for a kernel symbol table ([kallsyms](https://github.com/torvalds/linux/blob/master/kernel/kallsyms.c)), a compressed symbol table that is present in almost every kernel, mostly unaltered.

Because the concerned symbol table is originally compressed, it should recover strings that aren't visible in the original binary.

It produces an .ELF file that you can analyze using IDA Pro and Ghidra. This tool is hence useful for embedded systems reverse engineering.

Usage:

```bash
./vmlinux-to-elf <input_kernel.bin> <output_kernel.elf>
```

System-wide installation (the second command may not be needed as PIP should find the dependencies within the `setup.py` file):

```bash
sudo apt install python3-pip
sudo pip3 install --upgrade lz4 zstandard git+https://github.com/clubby789/python-lzo@b4e39df
sudo pip3 install --upgrade git+https://github.com/marin-m/vmlinux-to-elf
```

## Features
* Take a raw binary blob or ELF kernel file as an input  [OK]
* Automatically detect and unpack the main compression formats used for the Linux kernel [OK]
* Find and extract the embedded kernel symbols table (kallsyms) from the input file  [OK]
* Infer the instruction set architecture, endianness, bit size, relying upon other things on common function prologue signatures [OK]
* Infer the entry point of the kernel from the symbols contained in the kallsyms table  [OK]
* Provide basic inference for the kernel base address  [OK] (for now, consider that it is the first "TEXT" symbol address of the binary with the lower 0xfff bits clear - seems to work well enough)
* Unpack certain types of Android `boot.img` files, starting with an `ANDROID!` or `UNCOMPRESSED_IMG` magic [OK]
* Produce an .ELF file fully analyzable with IDA Pro or Ghidra as an output  [OK]


## How does it work, really?

A brief history of the "kallsyms" symbol table can be found at the top of the "[kallsyms_finder.py](vmlinux_to_elf/kallsyms_finder.py)" file. Briefly, this was introduced circa 2004 in the Linux kernel in its current form and is used to print the "Kernel oops" messages, among other things.

It contains tuples of "symbol name", "symbol address", "symbol type" (symbol types being designated with a single letter in a fashion similar to the [`nm`](http://man7.org/linux/man-pages/man1/nm.1p.html) utility), this information being tightly packed with a simple compression algorithm.

The schema below displays how this information is serialized into the kernel, the offset of each respective structure being detected by `vmlinux-to-elf` through [heuristics](vmlinux_to_elf/kallsyms_finder.py):

| Array name | Description | Sample contents |
| ---------- | ----------- | --------------- |
| `kallsyms_addresses` (or `kallsyms_offsets` + `kallsyms_relative_base`) |  The addresses (or offsets relative to a base, in recent kernels) of each symbol, as an array | `80 82 00 C0  80 82 00 C0  80 82 00 C0  0C 84 00 C0  B4 84 00 C0  5C 85 00 C0  60 85 00 C0  60 85 00 C0` ...
| `kallsyms_num_syms`      | The total number of symbols, as an integer (useful for checking for endianness, alignment, correct decoding of the symbols table) | `54 D4 00 00`
| `kallsyms_names`         | The compressed, length-separated symbol names themselves. Each byte in the compressed symbol strings references an index in the "kallsyms_token_index" array, that itself references the offset of a character or string fragment in the "kallsyms_token_table" array. | `09 54 64 6F  5F E1 F1 66  F5 25 05 54  F3 74 AB 74  0E 54 FF AB` ...
| `kallsyms_markers`       | A lookup table serving to find quickly the approximative offset of a compressed symbol name in "kallsyms_names": every 256 symbols, an offset to the concerned symbol in "kallsyms_names" is added as a long to this table. | `00 00 00 00  03 0C 00 00  0C 18 00 00  1B 24 00 00  0F 31 00 00  DA 3D 00 00  CF 4A 00 00` ...
| `kallsyms_token_table`   | Null-terminated string fragments or characters that may be contained in kernel symbol names. This can contain at most 256 string fragments or characters. Indexes corresponding to ASCII code points which are actually used in any kernel symbol will correspond to the concerned ASCII character, other positions will contain a statistically chosen string fragment. This tool tries to heuristically find this array across the passed file first in order to find the `kallsyms` symbols table. | `73 69 00 67  70 00 74 74  00 79 6E 00  69 6E 74 5F  00 66 72 00  ` ...
| `kallsyms_token_index`   | 256 words, each mapping to the offsets of the characters or string fragments designated by their respective indexes in "kallsyms_token_table". |  `00 00 03 00  06 00 09 00  0C 00 11 00  14 00 1B 00  1E 00 22 00  2C 00 30 00  35 00 38 00` ...

These fields have variable alignment and field size. The field sizes may vary over architecture and kernel version too. For this reason, `vmlinux-to-elf` has been tested over a variety of cases.

OpenWRT [since 2013](https://git.openwrt.org/?p=openwrt/svn-archive/archive.git;a=commit;h=5317e9cb69bb42dee167e0552a5e1f01147ba072) has a [patch](https://github.com/openwrt-mirror/openwrt/blob/9b4650b/target/linux/generic/patches-4.4/203-kallsyms_uncompressed.patch) that removes compression over the `kallsyms` table by default (when building `kallsyms` has been enabled by the user). They do this in order to save space when re-compressing over the kernel using LZMA.

This means that the `kallsyms_token_table` and `kallsyms_token_address` entries disappear, and that the symbol names use plain text ASCII instead. This case is supported too.

## Kernels support
It supports kernels from version 2.6.10 (December 2004) until now. Only kernels explicitly configured without `CONFIG_KALLSYMS` should not be supported. If this kernel configuration variable was not set at build, then you will get: `KallsymsNotFoundException: No embedded symbol table found in this kernel`.

For raw kernels, the following architectures can be detected (using magics from [binwalk](https://github.com/ReFirmLabs/binwalk/blob/master/src/binwalk/magic/binarch)): MIPSEL, MIPSEB, ARMEL, ARMEB, PowerPC, SPARC, x86, x86-64, ARM64, MIPS64, SuperH, ARC.

The following kernel compression formats can be automatically detected: XZ, LZMA, GZip, BZ2, LZ4, LZO and Zstd.

## Advanced usage

You can also obtain a text-only output of the kernel's symbol names, addresses and types through using the `kallsyms-finder` utility, also bundled with this tool. The format of its output will be similar to the `/proc/kallsyms` procfs file.

Some parameters that should be automatically inferred by the tool (such as the instruction set or base address) may be overriden in case of issue. The full specification of the arguments allowing to do that is presented below:

```
$ vmlinux-to-elf -h
usage: vmlinux-to-elf [-h] [--e-machine DECIMAL_NUMBER] [--bit-size BIT_SIZE]
                      [--file-offset HEX_NUMBER] [--base-address HEX_NUMBER]
                      input_file output_file

Turn a raw or compressed kernel binary, or a kernel ELF without symbols, into
a fully analyzable ELF whose symbols were extracted from the kernel symbol
table

positional arguments:
  input_file            Path to the
                        vmlinux/vmlinuz/zImage/bzImage/kernel.bin/kernel.elf
                        file to make into an analyzable .ELF
  output_file           Path to the analyzable .ELF to output

optional arguments:
  -h, --help            show this help message and exit
  --e-machine DECIMAL_NUMBER
                        Force overriding the output ELF "e_machine" field with
                        this integer value (rather than auto-detect)
  --bit-size BIT_SIZE   Force overriding the input kernel bit size, providing
                        32 or 64 bit (rather than auto-detect)
  --file-offset HEX_NUMBER
                        Consider that the raw kernel starts at this offset of
                        the provided raw file or compressed stream (rather
                        than 0, or the beginning of the ELF sections if an ELF
                        header was present in the input)
  --base-address HEX_NUMBER
                        Force overriding the output ELF base address field
                        with this integer value (rather than auto-detect)

$ kallsyms-finder -h
usage: kallsyms-finder [-h] [--bit-size BIT_SIZE] input_file

Find the kernel's embedded symbol table from a raw or stripped ELF kernel
file, and print these to the standard output with their addresses

positional arguments:
  input_file           Path to the kernel file to extract symbols from

optional arguments:
  -h, --help           show this help message and exit
  --bit-size BIT_SIZE  Force overriding the input kernel bit size, providing
                       32 or 64 bit (rather than auto-detect)

```

Don't hesitate to [open an issue](https://github.com/marin-m/vmlinux-to-elf/issues/new) for any suggestion of improvement.








```

`kallsyms-finder`:

```
#!/usr/bin/env python3
#-*- encod
```

`setup.py`:

```py
#!/usr/bin/python3

from distutils.core import setup

setup(name='vmlinux-to-elf',
      version='1.0',
      description='A tool to recover a fully analyzable .ELF from a raw kernel, through extracting the kernel symbol table (kallsyms)',
      author='Marin Moulinier',
      author_email='',
      url='https://github.com/marin-m/vmlinux-to-elf',
      install_requires=['lz4', 'zstandard',
        'python-lzo @ git+https://github.com/clubby789/python-lzo@b4e39df'],
      packages=['vmlinux_to_elf', 'vmlinux_to_elf.utils'],
      scripts=['vmlinux-to-elf', 'kallsyms-finder']
     )

```

`vmlinux-to-elf`:

```
#!/usr/bin/env python3
```

`vmlinux_to_elf/architecture_detecter.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-
from typing import Dict, Union, Sequence, Set, Tuple, List
from re import search, findall, finditer, DOTALL
from collections import Counter
from argparse import Namespace
from enum import IntEnum
from io import BytesIO
from time import time
import logging

"""
    Guess the architecture of a given binary.
    
    For this, scan it for simple function prologues.
    Inspiration: https://github.com/ReFirmLabs/binwalk/blob/master/src/binwalk/magic/binarch
    
    Also, return a sequence of the spacing in bytes
    between each detected function prologue, so that
    it can be matched with function symbols from the
    kallsys table and the base address at the offset
    0 of the binary can be guessed.
"""

class ArchitectureGuessError(Exception):
    pass

class ArchitectureName(IntEnum):
    mipsle = 1
    mipsbe = 2
    mips64le = 3
    mips64be = 4
    x86 = 5
    x86_64 = 6
    powerpcbe = 7
    powerpcle = 8
    armle = 9
    armbe = 10
    aarch64 = 11
    mips16e = 12
    superhle = 13
    superhbe = 14
    sparc = 15
    arcompact = 16

# Prologues taken from the binwalk file linked above
architecture_to_prologue_regex : Dict[ArchitectureName, bytes] = {
    ArchitectureName.mipsle: br'.\xFF\xBD\x27..[\xA0-\xBF]\xAF',
    ArchitectureName.mipsbe: br'\x27\xBD\xFF.\xAF[\xA0-\xBF]..',
    ArchitectureName.mips64le: br'.\xFF\xBD\x67..[\xA0-\xBF]\xFF',
    ArchitectureName.mips64be: br'\x67\xBD\xFF.\xFF[\xA0-\xBF]..',
    ArchitectureName.x86: br'\x55\x89\xE5(?:\x83\xEC|\x57\x56)',
    ArchitectureName.x86_64: br'(?:\xe8....)?\x55\x48\x89\xE5', # Assume that a "call __fentry__" instruction may be present at the beginning of the prologue in recent x86_64 kernels
    ArchitectureName.powerpcbe: br'\x7C\x08\x02\xA6',
    ArchitectureName.powerpcle: br'\xA6\x02\x08\x7C',
    ArchitectureName.armbe: br'(?:\xE1\xA0\xC0\x0D)?\xE9\x2D..(?:[\xE0-\xEF]...){2}',
    ArchitectureName.armle: br'(?:\x0D\xC0\xA0\xE1)?..\x2D\xE9(?:...[\xE0-\xEF]){2}',
    ArchitectureName.mips16e: br'\xf0\x08\x64.\x01.',
    ArchitectureName.superhle: br'\xF6\x69\x0B\x00\xF6\x68', # This is an epilogue
    ArchitectureName.superhbe: br'\x69\xF6\x00\x0B\x68\xF6', # This is an epilogue
    ArchitectureName.aarch64: br'\xc0\x03\x5f\xd6', # This is an epilogue
    ArchitectureName.sparc: br'\x81\xC7\xE0\x08\x81\xE8', # This is an epilogue
    ArchitectureName.arcompact: b'\xF1\xC0.\x1C\x48[\xB0-\xBF]' # push_s blink; st.a r??, [sp, -??]
}


# From https://github.com/torvalds/linux/blob/master/include/uapi/linux/elf-em.h

# These constants define the various ELF target machines
EM_NONE = 0
EM_M32 = 1
EM_SPARC = 2
EM_386 = 3
EM_68K = 4
EM_88K = 5
EM_486 = 6 # Perhaps disused
EM_860 = 7
EM_MIPS = 8 # MIPS R3000 (officially, big-endian only)
# Next two are historical and binaries and
# modules of these types will be rejected by
# Linux. 
EM_MIPS_RS3_LE = 10 # MIPS R3000 little-endian
EM_MIPS_RS4_BE = 10 # MIPS R4000 big-endian

EM_PARISC = 15 # HPPA
EM_SPARC32PLUS = 18 # Sun's "v8plus"
EM_PPC = 20 # PowerPC
EM_PPC64 = 21 # PowerPC64
EM_SPU = 23 # Cell BE SPU
EM_ARM = 40 # ARM 32 bit
EM_SH = 42 # SuperH
EM_SPARCV9 = 43 # SPARC v9 64-bit
EM_H8_300 = 46 # Renesas H8/300
EM_IA_64 = 50 # HP/Intel IA-64
EM_X86_64 = 62 # AMD x86-64
EM_S390 = 22 # IBM S/390
EM_CRIS = 76 # Axis Communications 32-bit embedded processor
EM_M32R = 88 # Renesas M32R
EM_MN10300 = 89 # Panasonic/MEI MN10300, AM33
EM_OPENRISC = 92 # OpenRISC 32-bit embedded processor
EM_ARCOMPACT = 93 # ARCompact processor
EM_XTENSA = 94 # Tensilica Xtensa Architecture
EM_BLACKFIN = 106 # ADI Blackfin Processor
EM_UNICORE = 110 # UniCore-32
EM_ALTERA_NIOS2 = 113 # Altera Nios II soft-core processor
EM_TI_C6000 = 140 # TI C6X DSPs
EM_HEXAGON = 164 # QUALCOMM Hexagon
EM_NDS32 = 167 # Andes Technology compact code size embedded RISC processor family
EM_AARCH64 = 183 # ARM 64 bit
EM_TILEPRO = 188 # Tilera TILEPro
EM_MICROBLAZE = 189 # Xilinx MicroBlaze
EM_TILEGX = 191 # Tilera TILE-Gx
EM_ARCV2 = 195 # ARCv2 Cores
EM_RISCV = 243 # RISC-V
EM_BPF = 247 # Linux BPF - in-kernel virtual machine
EM_CSKY = 252 # C-SKY
EM_FRV = 0x5441 # Fujitsu FR-V

# This is an interim value that we will use until the committee comes
# up with a final number.
EM_ALPHA = 0x9026

# Bogus old m32r magic number, used by old tools.
EM_CYGNUS_M32R = 0x9041
# This is the old interim value for S/390 architecture
EM_S390_OLD = 0xA390
# Also Panasonic/MEI MN10300, AM33
EM_CYGNUS_MN10300 = 0xbeef


architecture_name_to_elf_machine_and_is64bits_and_isbigendian : Dict[ArchitectureName, Tuple[int, bool, bool]] = {
    ArchitectureName.mipsle: (EM_MIPS, False, False),
    ArchitectureName.mipsbe: (EM_MIPS, False, True),
    ArchitectureName.mips64le: (EM_MIPS, True, False),
    ArchitectureName.mips64be: (EM_MIPS, True, True),
    ArchitectureName.x86: (EM_386, False, False),
    ArchitectureName.x86_64: (EM_X86_64, True, False),
    ArchitectureName.powerpcbe: (EM_PPC, False, True),
    ArchitectureName.powerpcle: (EM_PPC, False, False),
    ArchitectureName.armbe: (EM_ARM, False, True),
    ArchitectureName.armle: (EM_ARM, False, False),
    ArchitectureName.mips16e: (EM_MIPS, False, True),
    ArchitectureName.superhle: (EM_SH, False, False),
    ArchitectureName.superhbe: (EM_SH, False, True),
    ArchitectureName.aarch64: (EM_AARCH64, True, False),
    ArchitectureName.sparc: (EM_SPARC, False, True),
    ArchitectureName.arcompact: (EM_ARCOMPACT, False, False),
}

"""
    Guess the architecture based on special knowledge, like custom signatures or binary format
"""
def guess_architecture_special(binary : bytes) -> ArchitectureName:

    if binary[:2] == b'MZ':

        # Maybe UEFI boot stub ?
        if binary[0x38:0x3C] == b'ARMd':
            return ArchitectureName.aarch64

    return None

"""
    Guess the architecture based on common patterns
"""
def guess_architecture_common(binary : bytes) -> ArchitectureName:

    architecture_to_number_of_prologues :  Dict[ArchitectureName, int] = Counter()

    for architecture, prologue in architecture_to_prologue_regex.items():
        
        architecture_to_number_of_prologues[architecture] = len(findall(prologue, binary,  flags = DOTALL))
    
    best_architecture_guess, number_of_prologues = architecture_to_number_of_prologues.most_common(1)[0]

    return None if number_of_prologues < 100 else best_architecture_guess

"""
    Main architecture guess function
"""
def guess_architecture(binary : bytes) -> ArchitectureName:
        
    begin_time = time()

    architecture_guess = guess_architecture_special(binary)
    if not architecture_guess:
        architecture_guess = guess_architecture_common(binary)

    if not architecture_guess:
        raise ArchitectureGuessError('The architecture could not be guessed successfully')

    logging.info('[+] Guessed architecture: %s successfully in %.2f seconds' % (architecture_guess.name, time() - begin_time))

    return architecture_guess

```

`vmlinux_to_elf/elf_symbolizer.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-
from re import search, IGNORECASE
from argparse import Namespace
from io import BytesIO
import logging

"""
    The ElfSymbolizer class, defined in this file, gathers information from
    the other modules (such as kallsyms_finder, which extracts the kernel's
    runtime symbol table, or vmlinuz_decompressor, which processes possible
    kernel compressions), in order to generate the output ELF file.
"""

try:
    from kallsyms_finder import KallsymsFinder, KallsymsSymbolType

    from utils.elf import ElfFile, ElfSymtab, ElfRel, Elf32LittleEndianSymbolTableEntry, Elf32BigEndianSymbolTableEntry, Elf64LittleEndianSymbolTableEntry, Elf64BigEndianSymbolTableEntry, SPECIAL_SECTION_INDEX, ST_INFO_TYPE, ST_INFO_BINDING, ElfStrtab, ElfProgbits, ElfNullSection, ElfNoBits, SH_FLAGS

except ImportError:
    from vmlinux_to_elf.kallsyms_finder import KallsymsFinder, KallsymsSymbolType

    from vmlinux_to_elf.utils.elf import ElfFile, ElfSymtab, ElfRel, Elf32LittleEndianSymbolTableEntry, Elf32BigEndianSymbolTableEntry, Elf64LittleEndianSymbolTableEntry, Elf64BigEndianSymbolTableEntry, SPECIAL_SECTION_INDEX, ST_INFO_TYPE, ST_INFO_BINDING, ElfStrtab, ElfProgbits, ElfNullSection, ElfNoBits, SH_FLAGS


class ElfSymbolizer():
    
    def __init__(self, file_contents : bytes, output_file : str,
        elf_machine : int = None, bit_size : int = None,
        base_address : int = None, file_offset : int = None):
        
        if file_contents.startswith(b'\x27\x05\x19\x56'): # uImage header magic (always big-endian)
            
            if file_offset is None:
                file_offset = 64 # uImage header size (image_header_t from u-boot/image.h)
            
            if base_address is None:
                base_address = int.from_bytes(file_contents[4 * 4:4 * 5], 'big')
            
            
        if file_offset:
            file_contents = file_contents[file_offset:]
        
        kallsyms_finder = KallsymsFinder(file_contents, bit_size)
        
        
        if file_contents.startswith(b'\x7fELF'):
            
            kernel = ElfFile.from_bytes(BytesIO(file_contents))
        
        else:
            
            kernel = ElfFile(kallsyms_finder.is_big_endian, kallsyms_finder.is_64_bits)
            
            #  Previsouly the register size was based on the kernel version string:       bool(kallsyms_finder.offset_table_element_size >= 8 or search('itanium|(?:amd|aarch|ia|arm|x86_|\D-)64', kallsyms_finder.version_string, flags = IGNORECASE))
            
            if elf_machine is not None:
                kernel.file_header.e_machine = elf_machine
            else:
                kernel.file_header.e_machine = kallsyms_finder.elf_machine
            
            ET_EXEC = 2
            kernel.file_header.e_type = ET_EXEC
            
            null = ElfNullSection(kernel)
            null.section_name = ''
            
            progbits = ElfProgbits(kernel)
            progbits.section_name = '.kernel'
            progbits.section_header.sh_flags = SH_FLAGS.SHF_ALLOC | SH_FLAGS.SHF_EXECINSTR | SH_FLAGS.SHF_WRITE
            progbits.section_header.sh_size = len(file_contents)
            
            first_symbol_virtual_address = next((symbol.virtual_address for symbol in kallsyms_finder.symbols if symbol.symbol_type == KallsymsSymbolType.TEXT), None)
            
            if kallsyms_finder.has_base_relative:
                first_symbol_virtual_address = min(first_symbol_virtual_address, kallsyms_finder.relative_base_address)
            
            if base_address is not None:
                progbits.section_header.sh_addr = base_address
            elif kallsyms_finder.kernel_text_candidate:
                progbits.section_header.sh_addr = kallsyms_finder.kernel_text_candidate
            else:
                progbits.section_header.sh_addr = first_symbol_virtual_address & 0xfffffffffffff000
            
            progbits.section_contents = file_contents
            
            
            bss = ElfNoBits(kernel)
            bss.section_name = '.bss'
            bss.section_header.sh_flags = SH_FLAGS.SHF_ALLOC | SH_FLAGS.SHF_EXECINSTR | SH_FLAGS.SHF_WRITE
            bss.section_header.sh_size = 0x100000
            bss.section_header.sh_addr = progbits.section_header.sh_addr + len(file_contents)
            
            kernel.sections += [null, progbits, bss]
            

        
        """
            Find the entry point symbol. Based on executing this command
            on the Linux tree source:
            
            for i in $(find -iname 'vmlinux.lds.S' -o -iname 'dyn.lds.S' -o -iname 'vmlinux-std.lds');
                do echo "$i:"$(grep -P '^ENTRY\(' $i);
            done | grep -Po 'ENTRY\((.+?)\)' | sort -u

            You can find the possible symbols that are used as an entry
            point for the kernel, here sorted from the most specific to
            the less specific
        """
        
        POSSIBLE_ENTRY_POINT_SYMBOLS = [
            'kernel_entry', 'microblaze_start', 'parisc_kernel_start',
            'phys_startup_32', 'phys_startup_64', 'phys_start', '_stext_lma',
            'res_service', '_c_int00',
            'startup_32', 'startup_64', 'startup_continue', 'startup',
            '__start', '_start', 'start_kernel',
            'stext', '_stext', '_text'
        ]
        
        entry_point_address : int = None
        
        for symbol_name in POSSIBLE_ENTRY_POINT_SYMBOLS:
            
            symbol = kallsyms_finder.name_to_symbol.get(symbol_name)
            
            if symbol:
                entry_point_address = symbol.virtual_address
                
                break
        
        if entry_point_address is None:
            
            raise ValueError('No entry point symbol found in the kallsyms')
        
        kernel.file_header.e_entry = entry_point_address
    
        # Add symbols
        
        symtab = next((i for i in kernel.sections if i.section_name == '.symtab'), None)
        
        if not symtab:
            symtab = ElfSymtab(kernel)
            symtab.section_name = '.symtab'
            
            strtab = ElfStrtab(kernel)
            strtab.section_name = '.strtab'
            symtab.string_table = strtab
            
            shstrtab = ElfStrtab(kernel)
            shstrtab.section_name = '.shstrtab'
            
            kernel.section_string_table = shstrtab
            kernel.sections += [symtab, strtab, shstrtab]
                
        # symtab.symbol_table = [symtab.symbol_table[0]]
        
        for symbol in kallsyms_finder.symbols:
            
            elf_symbol_class = {
                (False, False): Elf32LittleEndianSymbolTableEntry,
                (True, False): Elf32BigEndianSymbolTableEntry,
                (False, True): Elf64LittleEndianSymbolTableEntry,
                (True, True): Elf64BigEndianSymbolTableEntry,
            }[(kernel.is_big_endian, kernel.is_64_bits)]

            elf_symbol = elf_symbol_class(kernel.is_big_endian, kernel.is_64_bits)
            
            elf_symbol.symbol_name = symbol.name
            elf_symbol.st_value = symbol.virtual_address
            
            if symbol.symbol_type not in (KallsymsSymbolType.TEXT, KallsymsSymbolType.WEAK_SYMBOL_WITH_DEFAULT):
                elf_symbol.st_info_type = ST_INFO_TYPE.STT_OBJECT
            
            else:
                elf_symbol.st_info_type = ST_INFO_TYPE.STT_FUNC
            
            if symbol.symbol_type in (KallsymsSymbolType.WEAK_OBJECT_WITH_DEFAULT, KallsymsSymbolType.WEAK_SYMBOL_WITH_DEFAULT):
                elf_symbol.st_info_binding = ST_INFO_BINDING.STB_WEAK
            
            elif symbol.is_global:
                elf_symbol.st_info_binding = ST_INFO_BINDING.STB_GLOBAL
            
            else:
                elf_symbol.st_info_binding = ST_INFO_BINDING.STB_LOCAL

            if symbol.symbol_type == KallsymsSymbolType.ABSOLUTE:
                elf_symbol.st_shndx = SPECIAL_SECTION_INDEX.SHN_ABS
            
            else:
                elf_symbol.associated_section = next((i for i in kernel.sections
                    if i.section_header.sh_addr <= symbol.virtual_address <= i.section_header.sh_addr + i.section_header.sh_size), None)

            symtab.symbol_table.append(elf_symbol)
        
        # Save the modified ELF
        
        with open(output_file, 'wb') as fd:
            
            kernel.serialize(fd)
        
        logging.info('[+] Successfully wrote the new ELF kernel to %s' % output_file)
    
    




        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        

```

`vmlinux_to_elf/kallsyms_finder.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-

from re import search, findall, IGNORECASE, match
from struct import pack, unpack_from
from typing import List, Dict, Tuple
from argparse import ArgumentParser
from io import BytesIO
from enum import Enum
from sys import argv, stdout
import logging

try:
    from architecture_detecter import guess_architecture, ArchitectureName, architecture_name_to_elf_machine_and_is64bits_and_isbigendian, ArchitectureGuessError
    from vmlinuz_decompressor import obtain_raw_kernel_from_file
    
except ImportError:
    from vmlinux_to_elf.architecture_detecter import guess_architecture, ArchitectureName, architecture_name_to_elf_machine_and_is64bits_and_isbigendian, ArchitectureGuessError
    from vmlinux_to_elf.vmlinuz_decompressor import obtain_raw_kernel_from_file

"""
    This class will take a raw kernel image (.IMG), and return the file
    offsets for all kernel symbols, as well as the kallsyms_* structs and
    base addresses, etc.
    
    It is used as an import by "vmlinuz_extractor.py" and "elf_symbolizer.py".
    
    The kallsyms table's current layout was introduced in August 2004 (since
    kernel 2.6.10), its 2004+ implementation can be found here for parsing:
    https://github.com/torvalds/linux/blob/v2.6.32/kernel/kallsyms.c
    And here for generation:
    https://github.com/torvalds/linux/blob/v2.6.32/scripts/kallsyms.c
    
    ^ This format is fully supported.
    
    A major evolution is that since v4.6 (2016), by default on all architectures
    except IA64, a new label called "kallsyms_relative_base" was added and
    addresses are now offsets relative to this base, rather than relative
    addresses. Also, these offsets are stored as the GNU As ".long" type, which
    is 32-bits on x86_64.
    
    https://github.com/torvalds/linux/commit/2213e9a66bb87d8344a1256b4ef568220d9587fb
    
    ^ This format should be supported.
    
    In v4.20 (2018), more fields were shrunk down independently.
    
    https://github.com/torvalds/linux/commit/80ffbaa5b1bd98e80e3239a3b8cfda2da433009a
    
    ^ This format should be supported.
    
    Its 2002-2004 (versions 2.5.54-2.6.9) implementation code with basic "stem
    compression" can be found here for parsing:
    https://github.com/sarnobat/knoppix/blob/master/kernel/kallsyms.c
    Here for generation:
    https://github.com/sarnobat/knoppix/blob/master/scripts/kallsyms.c
    (patch https://lwn.net/Articles/18837/)
    
    In 2002 (versions 2.5.49-2.5.53) it shortly had a version of this code
    without compression:
    https://kernel.googlesource.com/pub/scm/linux/kernel/git/ralf/linux/+/refs/tags/linux-2.5.49/kernel/kallsyms.c
    https://kernel.googlesource.com/pub/scm/linux/kernel/git/ralf/linux/+/refs/tags/linux-2.5.49/scripts/kallsyms
    
    In earlier implementations (2000-2002), it was part of the modutils package
    and was more primitive (no real compression). Its implementation code can be found
    here for parsing:
    https://github.com/carlobar/uclinux_leon3_UD/blob/master/user/modutils-2.4.26/example/kallsyms.c
    Here for generation:
    https://github.com/carlobar/uclinux_leon3_UD/blob/master/user/modutils-2.4.26/obj/obj_kallsyms.c
    
    Kernels 2.5.39-2.5.48 (2002) also had a transitory parser at "kernel/kallsyms.c", but the generation
    was still in modutils:
    
    https://kernel.googlesource.com/pub/scm/linux/kernel/git/ralf/linux/+/refs/tags/linux-2.5.39/kernel/kallsyms.c
    (patch https://lwn.net/Articles/10796/)

    
"""


# Symbol types are the same as exposed by "man nm"

class KallsymsSymbolType(Enum):
    
    # Seen in actual kernels
    ABSOLUTE = 'A'
    BSS = 'B'
    DATA = 'D'
    RODATA = 'R'
    TEXT = 'T'
    WEAK_OBJECT_WITH_DEFAULT = 'V'
    WEAK_SYMBOL_WITH_DEFAULT = 'W'
    
    # Seen on nm's manpage
    SMALL_DATA = 'G'
    INDIRECT_FUNCTION = 'I'
    DEBUGGING = 'N'
    STACK_UNWIND = 'P'
    COMMON = 'C'
    SMALL_BSS = 'S'
    UNDEFINED = 'U'
    UNIQUE_GLOBAL = 'u'
    WEAK_OBJECT = 'v'
    WEAK_SYMBOL = 'w'
    STABS_DEBUG = '-'
    UNKNOWN = '?'



class KallsymsSymbol:
    
    name : str = None
    
    file_offset : int = None
    virtual_address : int = None
    
    symbol_type : KallsymsSymbolType = None
    is_global : bool = False
    

class KallsymsNotFoundException(ValueError):
    pass

class KallsymsFinder:

    # Structure offsets to find
        
    kallsyms_addresses_or_offsets__offset : int = None
    kallsyms_num_syms__offset : int = None
    
    kallsyms_names__offset : int = None  
    kallsyms_markers__offset : int = None
    
    kallsyms_token_table__offset : int = None
    kallsyms_token_index__offset : int = None

    elf64_rela : List[Tuple[int, int, int]] = None
    kernel_text_candidate : int = None
    
    # Inferred information
    
    is_big_endian : bool = None
    offset_table_element_size : int = None
    
    # Parsed information
    
    num_symbols : int = None
    symbol_names : list = None
    symbol_addresses : list = None
    
    symbols : List[KallsymsSymbol] = None
    name_to_symbol : Dict[str, KallsymsSymbol] = None
    

    """
        Symbols are output in this order:
    
        $ curl -sL https://github.com/torvalds/linux/raw/v2.6.32/scripts/kallsyms.c | grep output_label
        
            output_label("kallsyms_addresses");
            output_label("kallsyms_num_syms");
            output_label("kallsyms_names");
            output_label("kallsyms_markers");
            output_label("kallsyms_token_table");
            output_label("kallsyms_token_index");
            
        We'll find kallsyms_token_table and infer the rest
    """
    
    def __init__(self, kernel_img : bytes, bit_size : int = None):
        
        self.kernel_img = kernel_img
        
        # -
        
        self.find_linux_kernel_version()
        
        if not bit_size:
            self.guess_architecture()
        elif bit_size not in (64, 32):
            exit('[!] Please specify a register bit size of either 32 or 64 ' +
                'bits')
        else:
            self.is_64_bits = (bit_size == 64)

        if self.is_64_bits:
            self.find_elf64_rela()
            self.apply_elf64_rela()
        
        # -
        
        try:
            self.find_kallsyms_token_table()
            self.find_kallsyms_token_index()
            self.uncompressed_kallsyms = False
        
        except KallsymsNotFoundException as first_error: # Maybe an OpenWRT kernel with an uncompressed kallsyms
            
            try:
                self.find_kallsyms_names_uncompressed()
                self.find_kallsyms_markers_uncompressed()
                self.uncompressed_kallsyms =  True
            
            except KallsymsNotFoundException:
                raise first_error
        
        else:
            self.find_kallsyms_markers()
            self.find_kallsyms_names()
        
        self.find_kallsyms_num_syms()
        self.find_kallsyms_addresses_or_symbols()
        
        # -
        
        self.parse_symbol_table()
    
    def find_linux_kernel_version(self):
        
        regex_match = search(b'Linux version (\d+\.[\d.]*\d)[ -~]+', self.kernel_img)
        
        if not regex_match:
            
            raise ValueError('No version string found in this kernel')
        
        self.version_string = regex_match.group(0).decode('ascii')
        self.version_number = regex_match.group(1).decode('ascii')
        
        logging.info('[+] Version string: {0:s}'.format(self.version_string))
        #logging.info('[+] Other related strings containing the version number: {0:s}'.format(findall(b'[ -~]*%s[ -~]*' % regex_match.group(1), self.kernel_img)))
        #logging.info('[+] Architecture string: {0:s}'.format(search(b'mod_unload[ -~]+', self.kernel_img).group(0)))
    
    def guess_architecture(self):
        
        self.architecture : ArchitectureName = guess_architecture(self.kernel_img)
        # self.architecture  =  ArchitectureName.mipsle # DEBUG

        self.elf_machine,  self.is_64_bits,  self.is_big_endian = architecture_name_to_elf_machine_and_is64bits_and_isbigendian[self.architecture]

    def find_elf64_rela(self) -> bool:

        """
            Find relocations table, return True if success, False
            otherwise
        """

        if ArchitectureName.aarch64 != self.architecture:

            # I've tested this only for ARM64
            return False

        rela64_size = 24
        offset = len(self.kernel_img)
        offset -= (offset & 3) # align to pointer size
        R_AARCH64_RELATIVE = 0x403
        elf64_rela = []
        minimal_heuristic_count = 1000
        minimal_kernel_va = 0xFFFFFF8008080000
        maximal_kernel_va = 0xFFFFFFFFFFFFFFFF
        kernel_text_candidate = maximal_kernel_va

        # Relocations table located at 'init' part of kernel image
        # Thus reverse-search is more efficient

        while offset >= rela64_size:
            rela = unpack_from('<QQQ', self.kernel_img, offset - rela64_size)
            r_offset, r_info, r_addend = rela
            if (0 == r_offset) and (0 == r_info) and (0 == r_addend):

                # possible empty entry ?

                if elf64_rela:

                    # just skip empty entries inside relocation table

                    offset -= rela64_size   # move to one rela64 struct backward
                    continue

            if R_AARCH64_RELATIVE != r_info:

                # Relocations must be the same type

                if len(elf64_rela) >= minimal_heuristic_count:
                    break

                # reset current state

                elf64_rela = []
                kernel_text_candidate = maximal_kernel_va
                
                # move to the next candidate
                
                possible_offset = offset - 1

                while possible_offset % 8 != 0: # Find a pointer-aligned r_info entry
                    possible_offset = self.kernel_img.rfind(R_AARCH64_RELATIVE.to_bytes(8, 'little'), 8, possible_offset - rela64_size + 1)
                    if possible_offset == -1:
                        offset = 0
                        break

                if possible_offset != -1:
                    offset = possible_offset - 8

                continue

            elf64_rela.append(rela)
            if (0 == (r_addend & 0xFFF)) and (minimal_kernel_va <= r_addend < kernel_text_candidate):
                kernel_text_candidate = r_addend
            offset -= rela64_size   # move to one rela64 struct backward

        count = len(elf64_rela)
        
        if count < minimal_heuristic_count:
            return False

        self.kernel_text_candidate = kernel_text_candidate
        self.elf64_rela = elf64_rela
        logging.info('[+] Found relocations table at file offset 0x%04x (count=%d)' % (offset, count))
        logging.info('[+] Found kernel text candidate: 0x%08x' % (kernel_text_candidate))
        return True

    def apply_elf64_rela(self) -> bool:
        """
            Apply relocations table, return True if success, False
            otherwise
        """
        if self.elf64_rela is None or self.kernel_text_candidate is None:
            return False

        img = bytearray(self.kernel_img)
        offset_max = len(img) - 8 # size of ptr
        kernel_base = self.kernel_text_candidate

        # There is no guarantee that relocation addresses are monotonous

        count = 0
        for rela in self.elf64_rela:

            r_offset, r_info, r_addend = rela
            offset = (r_offset - kernel_base)

            if offset < 0 or offset >= offset_max:
                logging.warning('WARNING! bad rela offset %08x' % (r_offset))

                self.kernel_text_candidate = None
                self.elf64_rela = None
                return False # Don't try more to apply relocations

            value, = unpack_from('<Q', self.kernel_img, offset)
            if value == r_addend:

                # don't know why, but some relocations already initialized

                continue

            # BUG: Sometimes 'r_addend' has pretty small value, and applied to 0.
            # BUG: Result much smaller that valid kernel address.
            # BUG: Probably 'r_addend' can represent offset from kernel_base. Need further investigation.

            value += r_addend
            value &= (1 << 64) - 1

            img[offset:offset+8] = pack('<Q', value)
            count += 1

        self.kernel_img = bytes(img)
        logging.info('[+] Successfully applied %d relocations.' % count)
        return True
        

    def find_kallsyms_token_table(self):
        
        """
            kallsyms_token_table is an array of 256 variable length null-
            terminated string fragments. Positions which correspond to
            an ASCII character which is used in at least one symbol 
            contain the corresponing character (1), other position contain 
            a string fragment chosen by the compression algorithm (2).
            
            Hence, characters [0-9] and [a-z] are always present at their 
            respective positions, but ":" (which comes after "9") never does.
            
            (1) See "insert_real_symbols_in_table" of "scripts/kallsyms.c"
            (2) See "optimize_result" of "scripts/kallsyms.c"
        """
        
        position = 0
        
        candidates_offsets = [] # offsets at which sequence_to_find was found
        candidates_offsets_followed_with_ascii = [] # variant with an higher certainty
        
        sequence_to_find = b''.join(b'%c\0' % i for i in range(ord('0'), ord('9') + 1))
        
        sequences_to_avoid = [
            b':\0',
            b'\0\0',
            b'\0\1',
            b'\0\2',
            b'ASCII\0'
        ]

        while True:
            
            position = self.kernel_img.find(sequence_to_find, position + 1)
            if position == -1:
                break
            
            for seq in sequences_to_avoid:
                pos = position + len(sequence_to_find)
                if self.kernel_img[pos:pos + len(seq)] == seq:
                    break
            else:
                candidates_offsets.append(position)
                
                if self.kernel_img[pos:pos + 1].isalnum():
                    candidates_offsets_followed_with_ascii.append(position)
        
        if len(candidates_offsets) != 1:
            
            if len(candidates_offsets_followed_with_ascii) == 1:
                candidates_offsets = candidates_offsets_followed_with_ascii
            elif len(candidates_offsets) == 0:
                raise KallsymsNotFoundException('%d candidates for kallsyms_token_table in kernel image' % len(candidates_offsets))
            else:
                raise ValueError('%d candidates for kallsyms_token_table in kernel image' % len(candidates_offsets))
        
        position = candidates_offsets[0]
        
        # Get back to the beginning of the table
        
        current_index_in_array = ord('0')
        
        position -= 1
        assert position >= 0 and self.kernel_img[position] == 0

        for tokens_backwards in range(current_index_in_array):
                        
            for chars_in_token_backwards in range(50):
                
                position -= 1
                assert position >= 0
                
                # (caveat: we may overlap on "kallsyms_markers" for the
                # last entry, so also check for high-range characters)
                
                if (self.kernel_img[position] == 0 or
                    self.kernel_img[position] > ord('z')):
                    break
                
                if chars_in_token_backwards >= 50 - 1:
                    
                    raise ValueError('This structure is not a kallsyms_token_table')
        
        position += 1
        position += -position % 4
        
        self.kallsyms_token_table__offset = position
        
        logging.info('[+] Found kallsyms_token_table at file offset 0x%08x' % self.kallsyms_token_table__offset)
    
    
    def find_kallsyms_token_index(self):
        
        # Get to the end of the kallsyms_token_table
        
        current_index_in_array = 0
        
        position = self.kallsyms_token_table__offset
        
        all_token_offsets = []
        
        position -= 1

        for tokens_forward in range(256):
                
            position += 1
            
            all_token_offsets.append(position - self.kallsyms_token_table__offset)
                        
            for chars_in_token_forward in range(50):
                
                position += 1
                
                if self.kernel_img[position] == 0:
                    break
                
                if chars_in_token_forward >= 50 - 1:
                    
                    raise ValueError('This structure is not a kallsyms_token_table')
        
        
        # Find kallsyms_token_index through the offset through searching
        # the reconstructed structure, also use this to guess endianness
        
        MAX_ALIGNMENT = 256
        KALLSYMS_TOKEN_INDEX__SIZE = 256 * 2
        
        memory_to_search = bytes(self.kernel_img[position:
            position + KALLSYMS_TOKEN_INDEX__SIZE + MAX_ALIGNMENT])
        
        
        little_endian_offsets = pack('<%dH' % len(all_token_offsets), *all_token_offsets)
        big_endian_offsets = pack('>%dH' % len(all_token_offsets), *all_token_offsets)
        
        found_position_for_le_value = memory_to_search.find(little_endian_offsets)
        found_position_for_be_value = memory_to_search.find(big_endian_offsets)
        
        if found_position_for_le_value == found_position_for_be_value == -1:
            
            raise ValueError('The value of kallsyms_token_index was not found')
        
        elif found_position_for_le_value > found_position_for_be_value:
            
            self.is_big_endian = False
        
            self.kallsyms_token_index__offset = position + found_position_for_le_value
        
        elif found_position_for_be_value > found_position_for_le_value:
            
            self.is_big_endian = True
        
            self.kallsyms_token_index__offset = position + found_position_for_be_value
        
        logging.info('[+] Found kallsyms_token_index at file offset 0x%08x' % self.kallsyms_token_index__offset)
    

    def find_kallsyms_names_uncompressed(self):
        
        """
            OpenWRT versions since 2013 may have an
            uncompressed kallsyms table built-in.
        """

        # Find the length byte-separated symbol names
        
        ksymtab_match = search(b'(?:[\x05-\x23][TWtbBrRAdD][a-z0-9_.]{4,34}){14}', self.kernel_img)
        
        if not ksymtab_match:
            
            raise KallsymsNotFoundException('No embedded symbol table found in this kernel')
        
        self.kallsyms_names__offset = ksymtab_match.start(0)
        
        # Count the number of symbol names
        
        position = self.kallsyms_names__offset
        self.number_of_symbols = 0
        
        self.symbol_names : List[str] = []
        
        while position + 1 < len(self.kernel_img):
            
            if self.kernel_img[position] < 2 or chr(self.kernel_img[position + 1]).lower() not in 'abdrtvwginpcsu-?':
                break
            
            symbol_name_and_type : bytes = self.kernel_img[
                position + 1:
                position + 1 + self.kernel_img[position]
            ]
            
            if not match(b'^[\x21-\x7e]+$', symbol_name_and_type):
                break
                        
            position += 1 + self.kernel_img[position]
            self.number_of_symbols += 1
        
        if self.number_of_symbols < 100:
            
            raise KallsymsNotFoundException('No embedded symbol table found in this kernel')
        
        logging.info('[+] Kernel symbol names found at file offset 0x%08x' % ksymtab_match.start(0))
        
        logging.info('[+] Found %d uncompressed kernel symbols (end at 0x%08x)' % (self.number_of_symbols, position))
        
        self.end_of_kallsyms_names_uncompressed = position

    def find_kallsyms_markers_uncompressed(self):
        
        """
            This is the OpenWRT-specific version of the
            "find_kallsyms_markers" method below. It works
            the same except that is tries to guess the integer
            size forward rather than backard.
        """
        
        position =  self.end_of_kallsyms_names_uncompressed
        position += -position % 4
        
        max_number_of_space_between_two_nulls = 0
        
        # Go just after the first chunk of non-null bytes
        
        while position + 1 < len(self.kernel_img) and self.kernel_img[position + 1] == 0:
            
            position += 1
        
        
        for null_separated_bytes_chunks in range(20):
            
            num_non_null_bytes = 1 # we always start at a non-null byte in this loop
            num_null_bytes = 1 # we will at least encounter one null byte before the end of this loop
            
            while True:
                position += 1
                assert position >= 0
                
                if self.kernel_img[position] == 0:
                    break
                num_non_null_bytes += 1
            
            while True:
                position += 1
                assert position >= 0
                
                if self.kernel_img[position] != 0:
                    break
                num_null_bytes += 1
            
            max_number_of_space_between_two_nulls = max(
                max_number_of_space_between_two_nulls,
                num_non_null_bytes + num_null_bytes)
        
        if max_number_of_space_between_two_nulls % 2 == 1: # There may be a leap to a shorter offset in the latest processed entries
            max_number_of_space_between_two_nulls -= 1
        
        if max_number_of_space_between_two_nulls not in (2, 4, 8):
            
            raise ValueError('Could not guess the architecture register ' +
                'size for kernel')
        

        self.offset_table_element_size = max_number_of_space_between_two_nulls

        # Once the size of a long has been guessed, use it to find
        # the first offset (0)
        
        position =  self.end_of_kallsyms_names_uncompressed
        position += -position % 4

        # Go just at the first non-null byte
        
        while position < len(self.kernel_img) and self.kernel_img[position] == 0:
            
            position += 1
        
        
        likely_is_big_endian = (position % self.offset_table_element_size > 1)
        if self.is_big_endian is None: # Manual architecture specification
            self.is_big_endian = likely_is_big_endian
        
        if position % self.offset_table_element_size == 0:
            position += self.offset_table_element_size
        else:
            position += -position + self.offset_table_element_size
        
        position -= self.offset_table_element_size
        position -= self.offset_table_element_size
        
        position -= position % self.offset_table_element_size
        
        
        self.kallsyms_markers__offset = position
        
        logging.info('[+] Found kallsyms_markers at file offset 0x%08x' % position)
        
    
    def find_kallsyms_markers(self):
        
        """
            kallsyms_markers contains one offset in kallsyms_names for each
            1 in 256 entries of it. Offsets are stored as either ".long"
            (a Gnu AS type that corresponds for example to 4 bytes in
            x86_64) since kernel v4.20, either as the maximum register
            byte of the system (the C "long" type) on older kernels.
            Remember about the size of this field for later.
        """
        
        max_number_of_space_between_two_nulls = 0
        
        position = self.kallsyms_token_table__offset
        
        # Go just before the first chunk of non-null bytes
        
        while position > 0 and self.kernel_img[position - 1] == 0:
            
            position -= 1
        
        
        for null_separated_bytes_chunks in range(20):
            
            num_non_null_bytes = 1 # we always start at a non-null byte in this loop
            num_null_bytes = 1 # we will at least encounter one null byte before the end of this loop
            
            while True:
                position -= 1
                assert position >= 0
                
                if self.kernel_img[position] == 0:
                    break
                num_non_null_bytes += 1
            
            while True:
                position -= 1
                assert position >= 0
                
                if self.kernel_img[position] != 0:
                    break
                num_null_bytes += 1
            
            max_number_of_space_between_two_nulls = max(
                max_number_of_space_between_two_nulls,
                num_non_null_bytes + num_null_bytes)
        
        if max_number_of_space_between_two_nulls % 2 == 1: # There may be a leap to a shorter offset in the latest processed entries
            max_number_of_space_between_two_nulls -= 1
        
        if max_number_of_space_between_two_nulls not in (2, 4, 8):
            
            raise ValueError('Could not guess the architecture register ' +
                'size for kernel')
        

        self.offset_table_element_size = max_number_of_space_between_two_nulls
        
        
        # Once the size of a long has been guessed, use it to find
        # the first offset (0)
        
        position = self.kallsyms_token_table__offset
        
        MAX_ARRAY_SIZE = 3000 * self.offset_table_element_size

        position -= 1
        while position > 0 and self.kernel_img[position] == 0:
            position -= 1
        
        memory_to_search = bytes(self.kernel_img[position - MAX_ARRAY_SIZE:
            position])
        
        needle = memory_to_search.rfind(b'\x00' * self.offset_table_element_size)
        
        if needle == -1:
            
            raise ValueError('Could not find kallsyms_markers')
        
        position = (position - MAX_ARRAY_SIZE) + needle
        
        position -= position % self.offset_table_element_size
        
        
        self.kallsyms_markers__offset = position
        
        logging.info('[+] Found kallsyms_markers at file offset 0x%08x' % position)
    
    def find_kallsyms_names(self):
        
        position = self.kallsyms_markers__offset
        
        
        # Approximate the position of kallsyms_names based on the
        # last entry of "kallsyms_markers" - we'll determine the
        # precise position in the next method
        
        endianness_marker = '>' if self.is_big_endian else '<'
            
        long_size_marker = {2: 'H', 4: 'I', 8: 'Q'}[self.offset_table_element_size]
        
        num_of_kallsyms_markers_entries = (self.kallsyms_token_table__offset -  self.kallsyms_markers__offset)  // self.offset_table_element_size
        
        kallsyms_markers_entries = unpack_from(endianness_marker + str(num_of_kallsyms_markers_entries) + long_size_marker, self.kernel_img, self.kallsyms_markers__offset)
        
        last_kallsyms_markers_entry = list(filter(None, kallsyms_markers_entries))[-1]
        
        position -= last_kallsyms_markers_entry
        
        position += -position % self.offset_table_element_size
        
        assert position > 0
        
        
        self.kallsyms_names__offset = position
        
        # Guessing continues in the function below (in order to handle the
        # absence of padding)
        
    def find_kallsyms_num_syms(self):
        
        needle = -1
        
        while needle == -1:
            
            position =  self.kallsyms_names__offset
            
            # Count the number of symbols
            
            num_symbols = 0
            
            symbol_counting_position = position
            
            # Check whether this looks like the correct symbol
            # table, first depending on the beginning of the
            # first symbol (as this is where an uncertain gap
            # of 4 padding bytes may be present depending on
            # versions or builds), then thorough the whole
            # table. Raise an issue further in the code (in
            # another function) if an exotic kind of symbol is
            # found somewhere else than in the first entry.

            token_table = self.get_token_table()
            first_token_index_of_first_name = self.kernel_img[symbol_counting_position + 1]
            first_token_of_first_name = token_table[first_token_index_of_first_name]
            possible_symbol_types = [i.value for i in KallsymsSymbolType]
            
            if (not (first_token_of_first_name[0].lower() in 'uvw' and
                first_token_of_first_name[0] in possible_symbol_types) and
                first_token_of_first_name[0].upper() not in possible_symbol_types):
                    
                if 0 <= self.kallsyms_names__offset - 4 < self.kallsyms_markers__offset:
                    self.kallsyms_names__offset -= 4
                else:
                    raise ValueError('Could not find kallsyms_names')
                continue
            
            while True:
            
                symbol_size = self.kernel_img[symbol_counting_position]
                
                if not symbol_size:
                    break
                
                symbol_counting_position += symbol_size + 1
                num_symbols += 1
                
                if not (0 <= symbol_counting_position < self.kallsyms_markers__offset):
                    break
            
            if num_symbols < 256 or symbol_counting_position > self.kallsyms_markers__offset:
                if 0 <= self.kallsyms_names__offset - 4 < self.kallsyms_markers__offset:
                    self.kallsyms_names__offset -= 4
                else:
                    raise ValueError('Could not find kallsyms_names')
                continue
            
            self.num_symbols = num_symbols
            
            # Find the long or PTR (it should be the same size as a kallsyms_marker
            # entry) encoding the number of symbols right before kallsyms_names
            
            endianness_marker = '>' if self.is_big_endian else '<'
            
            long_size_marker = {2: 'H', 4: 'I', 8: 'Q'}[self.offset_table_element_size]
            
            
            MAX_ALIGNMENT = 256
            
            encoded_num_symbols = pack(endianness_marker + long_size_marker, num_symbols)
            
            memory_to_search = bytes(self.kernel_img[self.kallsyms_names__offset - MAX_ALIGNMENT - 20:
                self.kallsyms_names__offset])
            
            needle = memory_to_search.rfind(encoded_num_symbols)
            
            if needle == -1: # There may be no padding between kallsyms_names and kallsyms_num_syms, if the alignment is already correct: in this case: try other offsets for "kallsyms_names"
                if 0 <= self.kallsyms_names__offset - 4 < self.kallsyms_markers__offset:
                    self.kallsyms_names__offset -= 4
                else:
                    raise ValueError('Could not find kallsyms_names')
        
        logging.info('[+] Found kallsyms_names at file offset 0x%08x' % self.kallsyms_names__offset)
        
        position = (self.kallsyms_names__offset - MAX_ALIGNMENT - 20) + needle
        
        
        self.kallsyms_num_syms__offset = position
        
        logging.info('[+] Found kallsyms_num_syms at file offset 0x%08x' % position)
    
    """
        This method defines self.kallsyms_addresses_or_offsets__offset,
        self.has_base_relative, self.has_absolute_percpu, self.relative_base_address (may be None)
        and the "self.kernel_addresses" list (the only one variable that shoud le
        externally used, it contains the decoded addresses for items, calculated
        from offsets relative to the specified base for recent kernels with
        CONFIG_KALLSYMS_BASE_RELATIVE)
    """
    
    def find_kallsyms_addresses_or_symbols(self):
        
        # --- New checks here
        
        kernel_major = int(self.version_number.split('.')[0])
        kernel_minor = int(self.version_number.split('.')[1])
        
        # Is CONFIG_KALLSYMS_BASE_RELATIVE (https://github.com/torvalds/linux/blob/v5.4/init/Kconfig#L1609) likely enabled?
        
        likely_has_base_relative = False
        
        if (kernel_major > 4 or (kernel_major == 4 and kernel_minor >= 6)
            and 'ia64' not in self.version_string.lower()
            and 'itanium' not in self.version_string.lower()):
            
            likely_has_base_relative = True
        
        # Does the system seem to be 64-bits?
        
        # Previously: inference from kernel version string
        # likely_is_64_bits = bool(self.offset_table_element_size >= 8 or search('itanium|(?:amd|aarch|ia|arm|x86_|\D-)64', self.version_string, flags = IGNORECASE))
        
        # Now: inference from ISA prologues signature detection
        likely_is_64_bits = self.is_64_bits
        
        # Is CONFIG_KALLSYMS_ABSOLUTE_PERCPU (https://github.com/torvalds/linux/blob/v5.4/init/Kconfig#L1604) likely enabled?
        
        # ==> We'll guess through looking for negative symbol values
        
        # Try different possibilities heuristically:
        
        for (has_base_relative, can_skip) in (
            [(True, True), (False, False)]
            if likely_has_base_relative else
            [(False, True), (False, False)]
        ):
            
            position = self.kallsyms_num_syms__offset
            
            address_byte_size = 8 if likely_is_64_bits else self.offset_table_element_size
            offset_byte_size = min(4, self.offset_table_element_size) # Size of an assembly ".long"
            
            
            # Go right after the previous address
            
            while True:
                assert position > 0  # >= self.offset_table_element_size # Needed?
                
                previous_word = self.kernel_img[position - address_byte_size:position]
                
                if previous_word != address_byte_size * b'\x00':
                    break
                position -= address_byte_size
            
            if has_base_relative:
                
                self.has_base_relative = True
                
                position -= address_byte_size
                
                # Parse the base_relative value
                
                self.relative_base_address :  int  =  int.from_bytes(self.kernel_img[position:position + address_byte_size], 'big' if self.is_big_endian else 'little')
            
                # Go right after the previous offset
                
                while True:
                    assert position > 0  # >= self.offset_table_element_size # Needed?
                    
                    previous_word = self.kernel_img[position - offset_byte_size:position]
                    
                    if previous_word != offset_byte_size * b'\x00':
                        break
                    position -= offset_byte_size
                
                position -= self.num_symbols * offset_byte_size
                
            else:
                
                self.has_base_relative = False
            
                position -= self.num_symbols * address_byte_size
            
            self.kallsyms_addresses_or_offsets__offset = position
            
            # Check the obtained values
            
            endianness_marker = '>' if self.is_big_endian else '<'
            
            if self.has_base_relative:
                long_size_marker = {2: 'h', 4: 'i'}[offset_byte_size] # offsets may be negative, contrary to addresses
            else:
                long_size_marker = {2: 'H', 4: 'I', 8: 'Q'}[address_byte_size]
            
            # Parse symbols addresses
                
            tentative_addresses_or_offsets = list(unpack_from(
                endianness_marker + str(self.num_symbols) + long_size_marker,
                self.kernel_img,
                self.kallsyms_addresses_or_offsets__offset))

            if self.has_base_relative:
                number_of_negative_items = len([offset for offset in tentative_addresses_or_offsets if offset < 0])
                
                logging.info('[i] Negative offsets overall: %g %%' % (number_of_negative_items / len(tentative_addresses_or_offsets) * 100))
            
                if number_of_negative_items / len(tentative_addresses_or_offsets) >= 0.5: # Non-absolute symbols are negative with CONFIG_KALLSYMS_ABSOLUTE_PERCPU
                    self.has_absolute_percpu = True
                    
                    tentative_addresses_or_offsets = [((self.relative_base_address - 1 - offset) if offset < 0 else offset) for offset in tentative_addresses_or_offsets] # https://github.com/torvalds/linux/blob/v5.4/kernel/kallsyms.c#L159
                else:
                    self.has_absolute_percpu = False

                    tentative_addresses_or_offsets = [offset + self.relative_base_address for offset in tentative_addresses_or_offsets]
            
            else:
                self.has_absolute_percpu = False

            number_of_null_items = len([address for address in tentative_addresses_or_offsets if address == 0])
            
            logging.info('[i] Null addresses overall: %g %%' % (number_of_null_items / len(tentative_addresses_or_offsets) * 100))
        
            if number_of_null_items / len(tentative_addresses_or_offsets) >= 0.2: # If there are too much null symbols we have likely tried to parse the wrong integer size
                
                if can_skip:
                    continue
                
            
            logging.info('[+] Found %s at file offset 0x%08x' % ('kallsyms_offsets' if self.has_base_relative else 'kallsyms_addresses', position))
            
            self.kernel_addresses = tentative_addresses_or_offsets
            
            break # DEBUG
    
    def get_token_table(self) -> list:
        
        if not self.uncompressed_kallsyms:
            
            # Parse symbol name tokens
            
            tokens = []
            
            position = self.kallsyms_token_table__offset
            
            for num_token in range(256):
                
                token = ''
                
                while self.kernel_img[position]:
                    
                    token += chr(self.kernel_img[position])
                    position += 1
                
                position += 1
                
                tokens.append(token)
        
        else:
            tokens = [chr(i) for i in range(256)]
        
        return tokens
    
    def parse_symbol_table(self):
        
        tokens = self.get_token_table()
        
        # Parse symbol names
        
        self.symbol_names = []
        
        position = self.kallsyms_names__offset
        
        for num_symbol in range(self.num_symbols):
        
            symbol_name = ''
            
            length = self.kernel_img[position]
            position += 1
            
            for i in range(length):
                
                symbol_token_index = self.kernel_img[position]
                symbol_token = tokens[symbol_token_index]
                position += 1
            
                symbol_name += symbol_token
        
            self.symbol_names.append(symbol_name)
        
        # Build consistent objects
        
        self.symbols = []
        self.name_to_symbol = {}
        
        for symbol_address, symbol_name in zip(self.kernel_addresses, self.symbol_names):
            
            symbol = KallsymsSymbol()
        
            symbol.name = symbol_name[1:] # Exclude the type letter
            
            symbol.virtual_address = symbol_address
            # symbol.file_offset = 
            
            if symbol_name[0].lower() in 'uvw':
                
                symbol.symbol_type = KallsymsSymbolType(symbol_name[0])
                symbol.is_global = True
            
            else:
                
                symbol.symbol_type = KallsymsSymbolType(symbol_name[0].upper())
                symbol.is_global = symbol_name[0].isupper()
            
        
            self.symbols.append(symbol)
            
            self.name_to_symbol[symbol.name] = symbol
    
    
    def print_symbols_debug(self):
        
        # Print symbol types (debug)
        
        symbol_types = set()
        
        for symbol_name in self.symbol_names:
            
            symbol_types.add(symbol_name[0])
        
        logging.info('Symbol types => %r' % sorted(symbol_types))
        logging.info('')
        
        
        # Print symbols, in a fashion similar to /proc/kallsyms
        
        for symbol_address, symbol_name in zip(self.kernel_addresses, self.symbol_names):
            
            logging.info( "{0:s} {1:s} {2:s}".format(
                '%016x' % symbol_address if self.is_64_bits else '%08x' % symbol_address,
                symbol_name[0], # The symbol type
                symbol_name[1:] # The symbol name itself
            ))
        
        
if __name__ == '__main__':

    logging.basicConfig(stream=stdout, level=logging.INFO, format='%(message)s')

    args = ArgumentParser(description = "Find the kernel's embedded symbol table from a raw " +
        "or stripped ELF kernel file, and print these to the standard output with their " +
        "addresses")
    
    args.add_argument('input_file', help = "Path to the kernel file to extract symbols from")
    args.add_argument('--bit-size', help = 'Force overriding the input kernel ' +
        'bit size, providing 32 or 64 bit (rather than auto-detect)', type = int)
    
    args = args.parse_args()


    with open(args.input_file, 'rb') as kernel_bin:
        
        try:
            kallsyms = KallsymsFinder(obtain_raw_kernel_from_file(kernel_bin.read()), args.bit_size)
        
        except ArchitectureGuessError:
           exit('[!] The architecture of your kernel could not be guessed ' +
                'successfully. Please specify the --bit-size argument manually ' +
                '(use --help for its precise specification).')
        
        kallsyms.print_symbols_debug()
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        

```

`vmlinux_to_elf/main.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-
from argparse import ArgumentParser
from io import BytesIO
from sys import argv, stdout
import logging

try:
    from vmlinuz_decompressor import obtain_raw_kernel_from_file
    from elf_symbolizer import ElfSymbolizer
    from architecture_detecter import ArchitectureGuessError

except ImportError:
    from vmlinux_to_elf.vmlinuz_decompressor import obtain_raw_kernel_from_file
    from vmlinux_to_elf.elf_symbolizer import ElfSymbolizer
    from vmlinux_to_elf.architecture_detecter import ArchitectureGuessError

if __name__ == '__main__':

    logging.basicConfig(stream=stdout, level=logging.INFO, format='%(message)s')
    
    args = ArgumentParser(description = 'Turn a raw or compressed kernel binary, ' +
        'or a kernel ELF without symbols, into a fully analyzable ELF whose ' +
        'symbols were extracted from the kernel symbol table')
    
    args.add_argument('input_file', help = 'Path to the vmlinux/vmlinuz/zImage/' +
        'bzImage/kernel.bin/kernel.elf file to make into an analyzable .ELF')
    
    args.add_argument('output_file', help = 'Path to the analyzable .ELF to output')
    
    args.add_argument('--e-machine', help = 'Force overriding the output ELF ' +
        '"e_machine" field with this integer value (rather than auto-detect)',
        type = lambda string: int(string, 0), metavar = 'DECIMAL_NUMBER')
    
    args.add_argument('--bit-size', help = 'Force overriding the input kernel ' +
        'bit size, providing 32 or 64 bit (rather than auto-detect)', type = int)
    
    args.add_argument('--file-offset', help = 'Consider that the raw kernel starts ' +
        'at this offset of the provided raw file or compressed stream (rather than ' +
        '0, or the beginning of the ELF sections if an ELF header was present in the ' +
        'input)', type = lambda string: int(string.replace('0x', ''), 16), metavar = 'HEX_NUMBER')
    
    args.add_argument('--base-address', help = 'Force overriding the output ELF ' +
        'base address field with this integer value (rather than auto-detect)',
        type = lambda string: int(string.replace('0x', ''), 16), metavar = 'HEX_NUMBER')

    args = args.parse_args()
    
    if ((args.e_machine is not None and args.bit_size is None) or
        (args.e_machine is None and args.bit_size is not None)):
        
        logging.error('[!] Please specify both an addressing bit size ' +
            'and the ELF "e_machine" field, or neither for ' +
            'auto-detection')
        
        exit()
            
    
    with open(args.input_file, 'rb') as kernel_bin:
        
        try:
            
            ElfSymbolizer(
                obtain_raw_kernel_from_file(
                    kernel_bin.read()
                ), args.output_file, args.e_machine, args.bit_size,
                args.base_address, args.file_offset
            )
        
        except ArchitectureGuessError:
        
            exit('[!] The architecture of your kernel could not be guessed ' +
                'successfully. Please specify the --e-machine and --bit-size ' +
                'arguments manually (use --help for their precise specification).')


```

`vmlinux_to_elf/tests.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-

"""
    Check the program's ability to decompress
    the files files whose the absolute path
    is referenced by the "test_kernels.txt"
    present in the current directory (one kernel
    path per line, separated with LF)
    
    As this file is local to your own machine,
    it is ignored by the ".gitignore"
    
    It will also write successfully reconstructed
    ELF files to an automatically created "tests_output/" folder.
"""


try:
    from vmlinuz_decompressor import obtain_raw_kernel_from_file
    from elf_symbolizer import ElfSymbolizer

except ImportError:
    from vmlinux_to_elf.vmlinuz_decompressor import obtain_raw_kernel_from_file
    from vmlinux_to_elf.elf_symbolizer import ElfSymbolizer

from os.path import dirname, realpath, exists
from traceback import print_exc
from os import makedirs
from re import sub
from sys import stdout
import logging

SCRIPT_DIR = dirname(realpath(__file__))
TEST_KERNELS_PATH = realpath(SCRIPT_DIR + '/test_kernels.txt')
ELF_KERNELS_OUTPUT_PATH = realpath(SCRIPT_DIR + '/tests_output')

def slugify(file_path):
    
    return sub('[^a-z0-9]+', '-', file_path.lower()).strip('-')

if __name__ == '__main__':

    logging.basicConfig(stream=stdout, level=logging.INFO, format='%(message)s')

    if not exists(TEST_KERNELS_PATH):
        
        exit(('[!] In order to use this script, please ' +
             'create a file at %s, containing to path ' +
             'to one kernel to extract per line. Quitting.') % (TEST_KERNELS_PATH))
    
    makedirs(ELF_KERNELS_OUTPUT_PATH, exist_ok = True)


    for file_name in filter(None, map(str.strip, open(TEST_KERNELS_PATH, 'r'))):
        
        logging.info('Testing ' + file_name)
        
        with open(file_name, 'rb') as fd:
            contents = fd.read()
        
        raw_data = obtain_raw_kernel_from_file(contents)
        try:
            ElfSymbolizer(raw_data, ELF_KERNELS_OUTPUT_PATH + '/' + slugify(file_name) + '.elf')
        except Exception:
            logging.error('=> No symbols!')
            print_exc()
        
        







```

`vmlinux_to_elf/utils/elf.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-
from ctypes import BigEndianStructure, LittleEndianStructure
from ctypes import c_uint8, c_uint16, c_int32, c_uint32, c_int64, c_uint64, c_char
from io import SEEK_END, BytesIO
from enum import Enum, IntEnum
from typing import List, Dict

from sys import path
from os.path import dirname, realpath

path.append(realpath(dirname(__file__)))

from pretty_print import pretty_print_structure

"""
    This file contains a wrapper for parsing and writing ELF files.
    
    o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o
    o                                                                         o 
    o The ELF specification is here => https://uclibc.org/docs/elf-64-gen.pdf o
    o                                                                         o
    o ftp://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf           o
    o                                                                         o
    o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o o
    
    Each exposed object may have the following methods, which are called in
        this order when all present:
    
    - from_bytes (classmethod, taking at least a BytesIO): return an instance of
        a subclass of the concerned object while automatically inferring parameters
        such as endianness, bit size or section type
        
    
    - __init__ (taking two booleans): initialize the structure with the knowledge
        of whether the structure should be 64-bit or 32-bit, and whether it should
        be big- or little-endian
    
    - unserialize (taking a BytesIO): unserialize the structure at the current offset
    - _unserialize_contents (taking a BytesIO): unserialize the contents of a section
        (if the concerned object is a section) at the current offset, while unserialize()
        will unserialize the section header
    - post_unserialize (taking no arguments): called once all sections have been unserialized,
        complete fields of the concerned object based on the contents of other sections
        (interlink a relocation entry with symbol table entry, a symbol table entry with
        string table entry...)
    
    - pre_serialize (taking no arguments): counterpart of post_unserialize, updating the
        internal state of objects holding string tables from other sections
    - serialize (taking a BytesIO): serialize the structure at the current offset
    - _serialize_contents (taking a BytesIO): serialize the contents of a section
        (if the concerned object is a section), while serialize() will serialize
        the section header
    
"""



Elf32_Addr = c_uint32
Elf32_Half = c_uint16
Elf32_Off = c_uint32
Elf32_Sword = c_int32
Elf32_Word = c_uint32

Elf64_Addr = c_uint64
Elf64_Half = c_uint16
Elf64_Off = c_uint64
Elf64_Sword = c_int32
Elf64_Sxword = c_int64
Elf64_Word = c_uint32
Elf64_Lword = c_uint64
Elf64_Xword = c_uint64



class VariableEndiannessAndWordsizeStructure:
    
    def __new__(cls, is_big_endian = False, is_64_bits = False):
        
        actual_class = type(
            cls.__name__,
            
            (
                BigEndianStructure
                if is_big_endian
                else LittleEndianStructure,
                VariableEndiannessAndWordsizeStructure,
            ),
            
            {
                **{name: getattr(cls, name) for name in dir(cls) if '__' not in name or name == '__init__'},
                
                'is_big_endian': is_big_endian,
                'is_64_bits': is_64_bits,
            
                '_pack_': True,
                '_fields_': [
                    (
                        field[0], field[1] if is_64_bits else {
                            c_int64: c_int32,
                            c_uint64: c_uint32
                        }.get(field[1], field[1]), field[2] if len(field) > 2 else None
                    )[:3 if len(field) > 2 else 2]
                    
                    for field
                    in cls._fields_
                ]
            }
        )
        
        return actual_class()
    
    def unserialize(self, data : BytesIO):
        
        data.readinto(self)
        
    
    def serialize(self, data : BytesIO):
        
        data.write(self)
    
    
    def pretty_print(self):
        
      pretty_print_structure(self)  
        


class ElfFile:
    
    def __init__(self, is_big_endian = False, is_64_bits = False):

        self.is_big_endian = is_big_endian
        self.is_64_bits = is_64_bits
        
        # Exposed to the user
        
        self.sections : List[ElfSection] = []
        
        self.section_string_table : ElfStrtab = None
        
        self.file_header = ElfFileHeader(is_big_endian, is_64_bits)
        
        # Not exposed to the user (inferred from sections)
        
        self.segments : List[Elf32ProgramHeaderEntry] = []
    
    @classmethod
    def from_bytes(cls, data : BytesIO):
    
        file_header = data.read(E_IDENT_INDEXES.EI_NIDENT)
        
        is_64_bits = {
            EI_CLASS.ELFCLASS32: False,
            EI_CLASS.ELFCLASS64: True
        }[file_header[E_IDENT_INDEXES.EI_CLASS]]
        
        is_big_endian = {
            EI_DATA.ELFDATA2LSB: False,
            EI_DATA.ELFDATA2MSB: True
        }[file_header[E_IDENT_INDEXES.EI_DATA]]

        obj = cls(is_big_endian, is_64_bits)
        
        data.seek(0)
        obj.unserialize(data)
        
        return obj
    
    def unserialize(self, data : BytesIO):
        
        self.file_header.unserialize(data)
        
        # Parse sections and data
        
        for num_section in range(self.file_header.e_shnum):
        
            data.seek(self.file_header.e_shoff + self.file_header.e_shentsize * num_section)
            
            self.sections.append(ElfSection.from_bytes(data, self))
        
        # Name sections and link relocations (now that string and symbol tables are parsed)
        
        for section in self.sections:
            
            section.post_unserialize()
        
        
        # Remember about the string symbol table section
        
        self.section_string_table = self.sections[self.file_header.e_shstrndx]
            
        
        # Parse the segment headers
        
        for num_segment in range(self.file_header.e_phnum):
        
            data.seek(self.file_header.e_phoff + self.file_header.e_phentsize * num_segment)
            
            segment_class = Elf32ProgramHeaderEntry if not self.is_64_bits else Elf64ProgramHeaderEntry
            
            segment = segment_class(self.is_big_endian, self.is_64_bits)
            
            segment.unserialize(data)
            
            self.segments.append(segment)
    
    
    def serialize(self, data : BytesIO):
        
        # Filter out .gnu.version not to confuse readelf for now TODO
        self.sections = list(filter(lambda section: '.gnu.version' not in section.section_name, self.sections))
            
            
        self.file_header.e_ehsize = memoryview(self.file_header).nbytes

        self.file_header.e_shstrndx = self.sections.index(self.section_string_table)
        
        self.file_header.e_shoff = self.file_header.e_ehsize
        
        self.file_header.e_shnum = len(self.sections)
        
        self.file_header.e_shentsize = memoryview(self.sections[0].section_header).nbytes
        
        # Update the string tables

        for section in self.sections:
            
            if isinstance(section, ElfStrtab):
                
                section.raw_string_table = b''
                
                section.add_string_and_return_offset('')
        
        for section in self.sections:
            
            section.pre_serialize()
        
        # Write sections and data
        
        for num_section, section in enumerate(self.sections):
            
            data.seek(self.file_header.e_shoff + self.file_header.e_shentsize * num_section)
            
            section.serialize(data)
        
            
        
        # Calculate the address of segments
        
        section_type_to_segment_type = {
            SH_TYPE.SHT_DYNAMIC: P_TYPE.PT_DYNAMIC,
            SH_TYPE.SHT_NOTE: P_TYPE.PT_NOTE
        }
        
        self.segments = []
        
        for section in self.sections:
            
            if section.section_header.sh_flags & SH_FLAGS.SHF_ALLOC:
                
                segment_class = Elf32ProgramHeaderEntry if not self.is_64_bits else Elf64ProgramHeaderEntry
                
                segment = segment_class(self.is_big_endian, self.is_64_bits)
                
                segment.p_type = section_type_to_segment_type.get(section.section_header.sh_type, P_TYPE.PT_LOAD)
                
                segment.p_flags = P_FLAGS.PF_R | P_FLAGS.PF_X | P_FLAGS.PF_W
                if section.section_header.sh_flags & SH_FLAGS.SHF_EXECINSTR:
                    segment.p_flags |= P_FLAGS.PF_X
                if section.section_header.sh_flags & SH_FLAGS.SHF_WRITE:
                    segment.p_flags |= P_FLAGS.PF_W
                
                segment.p_vaddr = section.section_header.sh_addr
                segment.p_paddr = section.section_header.sh_addr
                segment.p_memsz = section.section_header.sh_size
                segment.p_offset = section.section_header.sh_offset
                segment.p_filesz = section.section_header.sh_size if not isinstance(section, ElfNoBits) else 0
                
                self.segments.append(segment)
                
        if not self.segments:
            
            raise ValueError('This ELF object does not have a section with SH_ALLOC flag')
        
        
        
        # Write the segment headers
        
        data.seek(0, SEEK_END)
        
        
        
        
        
        
        self.file_header.e_phoff = data.tell()
        
        self.file_header.e_phnum = len(self.segments)
        
        self.file_header.e_phentsize = memoryview(self.segments[0]).nbytes
        
        for num_segment, segment in enumerate(self.segments):
        
            data.seek(self.file_header.e_phoff + self.file_header.e_phentsize * num_segment)
            
            segment.serialize(data)
        
        
        
        
        # Write the program headers
        
        data.seek(0)
        
        self.file_header.serialize(data)
        
        
        
        """
        self._program_header.unserialize(data)
        """
    
    """
        When writing sections, make sure to 
    """



# class ElfSectionTable


class SH_TYPE(IntEnum):
    
    SHT_NULL = 0 # Inactive section.
    SHT_PROGBITS = 1 # Information defined by the program
    SHT_SYMTAB = 2 # Symbol table (one per object file)
    SHT_STRTAB = 3 # String table (multiple sections OK)
    SHT_RELA = 4 # Relocation with explicit addends
    SHT_HASH = 5 # Symbol hash table (one per object)
    SHT_DYNAMIC = 6 # Dynamic linking information
    SHT_NOTE = 7 # Vendor-specific file information
    SHT_NOBITS = 8 # Section contains no bits in object file
    SHT_REL = 9 # Relocation without explicit addends
    SHT_SHLIB = 10 # Reserved — non-conforming
    SHT_DYNSYM = 11 # Dynamic linking symbol table (one)
    
    SHT_INIT_ARRAY = 14 # Array of constructors
    SHT_FINI_ARRAY = 15 # Array of destructors
    SHT_PREINIT_ARRAY = 16 # Array of pre-constructors
    SHT_GROUP = 17 # Section group
    SHT_SYMTAB_SHNDX = 18 # Extended section indeces
    SHT_NUM = 19 # Number of defined types.
    
    
    SHT_GNU_ATTRIBUTES = 0x6ffffff5
    SHT_GNU_HASH = 0x6ffffff6
    SHT_GNU_LIBLIST = 0x6ffffff7
    SHT_GNU_VERDEF = 0x6ffffffd
    SHT_GNU_VERNEED = 0x6ffffffe
    SHT_GNU_VERSYM = 0x6fffffff
    SHT_MIPS_REGINFO = 0x70000006
    SHT_MIPS_ABIFLAGS = 0x7000002a


class SH_FLAGS(IntEnum):
    
    SHF_WRITE = 0x1 # Section writable during execution
    SHF_ALLOC = 0x2 # Section occupies memory
    SHF_EXECINSTR = 0x4 # Section contains executable instruc-tions





class ElfSectionHeader(VariableEndiannessAndWordsizeStructure):
    
    _fields_ = [
    
          ('sh_name', Elf64_Word), # Section name, index in string table
          ('sh_type', Elf64_Word), # Type of section
          ('sh_flags', Elf64_Xword), # Miscellaneous section attributes
          ('sh_addr', Elf64_Addr), # Section virtual addr at execution
          ('sh_offset', Elf64_Off), # Section file offset
          ('sh_size', Elf64_Xword), # Size of section in bytes
          ('sh_link', Elf64_Word), # Index of another section -> REL(A)|HASH->SYMTAB, SYMTAB->STRTAB, DYNAMIC|DYMSYM->DYNSTR
          ('sh_info', Elf64_Word), # Additional section information
          ('sh_addralign', Elf64_Xword), # Section alignment
          ('sh_entsize', Elf64_Xword), # Entry size if section holds table
    ]
    
    # The library will set sh_name and sh_offset when serializing, as well
    # as sh_size except if the section is a NOBITS

        
class ElfSection:
    
    section_name : str = None # will be written to section_string_table when serializing
    
    section_table : list = None # reference to the ElfFile.sections list
    elf_file : ElfFile = None
    
    section_header : ElfSectionHeader = None
    section_contents : bytes = None
    
    
    def __init__(self, elf_file : ElfFile):
        
        self.elf_file = elf_file
        
        self.is_big_endian = elf_file.is_big_endian
        self.is_64_bits = elf_file.is_64_bits

        self.section_header = ElfSectionHeader(self.is_big_endian, self.is_64_bits)
        
        if self.__class__ in SECTION_CLASS_TO_TYPE:
            
            self.section_header.sh_type = SECTION_CLASS_TO_TYPE[self.__class__]
    
    @classmethod
    def from_bytes(cls, data : BytesIO, elf_file : ElfFile):
    
        section_header_offset = data.tell()
        
        # Guess the correct type for the class to create
        # based on the section header
    
        impersonal_section = cls(elf_file)
        impersonal_section.unserialize(data)
        
        section_class = SECTION_TYPE_TO_CLASS.get(
            SH_TYPE(impersonal_section.section_header.sh_type), 
            ElfSection
        )
        
        data.seek(section_header_offset)
        
        obj = section_class(elf_file)
        obj.unserialize(data)
        
        return obj
    
    def unserialize(self, data : BytesIO):
        
        """
            Consider that:
            a) We are at the position of the section header corresponding
               to the current section
        """
        
        self.section_header.unserialize(data)
        
        data.seek(self.section_header.sh_offset)
        
        self._unserialize_contents(data)
    
    def _unserialize_contents(self, data : BytesIO):
        
        self.section_contents = data.read(self.section_header.sh_size)
            
    
    def post_unserialize(self):
        
        # Name sections (now that .shstrndx is parsed)
        
        section_string_table = self.elf_file.sections[self.elf_file.file_header.e_shstrndx]
        
        self.section_name = section_string_table.return_string_from_offset(self.section_header.sh_name)
    
    # -
    
    def pre_serialize(self):
        
        # Write our entry in .shstrtab
        
        section_string_table = self.elf_file.sections[self.elf_file.file_header.e_shstrndx]
        
        self.section_header.sh_name = section_string_table.add_string_and_return_offset(self.section_name)
    
    def serialize(self, data : BytesIO):
        
        """
            Consider that:
            a) Sections are serialized in order
            b) The file is laid out like this: [ File header | Section headers | Section contents | Segment headers ]
            c) We are located at our section header's offset when called
        """
        
        section_header_offset = data.tell()
        
        # a) Calculate where the contents will start
        
        start_of_contents = self.elf_file.file_header.e_shoff
        start_of_contents += self.elf_file.file_header.e_shentsize * self.elf_file.file_header.e_shnum
        
        data.seek(0, SEEK_END)
        start_of_contents = max(data.tell(), start_of_contents)
        
        if self.section_header.sh_addralign:
            start_of_contents += -start_of_contents % self.section_header.sh_addralign
        
        # b) Write our section contents
        
        data.seek(start_of_contents)
        
        self._serialize_contents(data)
        
        end_of_contents = data.tell()
        
        # c) Write the section header
        
        data.seek(section_header_offset)
        
        self.section_header.sh_offset = start_of_contents
        
        if not isinstance(self, ElfNoBits):
            self.section_header.sh_size = end_of_contents - start_of_contents
        
        self.section_header.serialize(data)
    
    def _serialize_contents(self, data : BytesIO):
        
        data.write(self.section_contents)

        



class ElfNullSection(ElfSection):
    
    def _unserialize_contents(self, data : BytesIO):
        
        pass
    
    def _serialize_contents(self, data : BytesIO):
        
        pass
    
    
class ElfProgbits(ElfSection):
    
    # virtual adress stored in self.section_header.sh_addr

    # Only PROGBITS and NOBITS will have their virtual address specified
    # in their ElfSection structure. For sections like INTERP or DYNAMIC
    # which also have a segment, the serialization code will choose an
    # arbitrary address located right after.
    
    def unserialize(self, data : BytesIO):
        
        super().unserialize(data)
            
    def serialize(self, data : BytesIO):
                
        super().serialize(data)

class ElfNoBits(ElfProgbits):
    
    # virtual adress stored in self.section_header.sh_addr
    
    
    def _unserialize_contents(self, data : BytesIO):
        
        pass
    
    def _serialize_contents(self, data : BytesIO):
        
        pass
        

class ST_INFO_TYPE(IntEnum): # SYMBOL_TYPE

    STT_NOTYPE = 0 # Not specified
    STT_OBJECT = 1 # Data object: variable, array, etc.
    STT_FUNC = 2 # Function or other executable code
    STT_SECTION = 3 # Section. Exists primarily for relocation
    STT_FILE = 4 # Name (pathname?) of the source file associated with object. Binding is STT_LOCAL, section index is SHN_ABS, and it precedes other STB_LOCAL symbols if present

class ST_INFO_BINDING(IntEnum): # SYMBOL_BINDING
    
    STB_LOCAL = 0 # Not visible outside object file where defined
    STB_GLOBAL = 1 # Visible to all object files. Multiple definitions cause errors. Force extraction of defining object from archive file.
    STB_WEAK = 2 # Visible to all object files. Ignored if STB_GLOBAL with same name found. Do not force extraction of defining object from archive file. Value is 0 if undefined.

class SPECIAL_SECTION_INDEX(IntEnum):
    
    SHN_UNDEF = 0
    SHN_LORESERVE = 0xff00
    SHN_LOPROC = 0xff00
    SHN_HIPROC = 0xff1f
    SHN_LIVEPATCH = 0xff20
    SHN_ABS = 0xfff1
    SHN_COMMON = 0xfff2
    SHN_HIRESERVE = 0xffff

class Elf32LittleEndianSymbolTableEntry(VariableEndiannessAndWordsizeStructure):
    
    _fields_ = [
        ('st_name', Elf32_Word), # Symbol name, index in string tbl
        ('st_value', Elf32_Addr), # Value of the symbol
        ('st_size', Elf32_Word), # Associated symbol size
        ('st_info_type', c_uint8, 4), # Type and binding attributes
        ('st_info_binding', c_uint8, 4),
        ('st_other', c_uint8), # No defined meaning, 0
        ('st_shndx', Elf32_Half), # Associated section index
    ]
    
    symbol_name : str = None
    
    associated_section : ElfSection = None
    
    
    # The user should fill st_name, st_info_type, st_info_binding, st_value

class Elf32BigEndianSymbolTableEntry(Elf32LittleEndianSymbolTableEntry):
    
    _fields_ = [
        ('st_name', Elf32_Word), # Symbol name, index in string tbl
        ('st_value', Elf32_Addr), # Value of the symbol
        ('st_size', Elf32_Word), # Associated symbol size
        ('st_info_binding', c_uint8, 4), # Type and binding attributes
        ('st_info_type', c_uint8, 4),
        ('st_other', c_uint8), # No defined meaning, 0
        ('st_shndx', Elf32_Half), # Associated section index
    ]
    
    
class Elf64LittleEndianSymbolTableEntry(Elf32LittleEndianSymbolTableEntry):
    
    _fields_ = [
        ('st_name', Elf64_Word), # Symbol name, index in string tbl
        ('st_info_type', c_uint8, 4), # Type and binding attributes
        ('st_info_binding', c_uint8, 4),
        ('st_other', c_uint8), # No defined meaning, 0
        ('st_shndx', Elf64_Half), # Associated section index
        ('st_value', Elf64_Addr), # Value of the symbol
        ('st_size', Elf64_Xword), # Associated symbol size
    ]
    
    
class Elf64BigEndianSymbolTableEntry(Elf64LittleEndianSymbolTableEntry):
    
    _fields_ = [
        ('st_name', Elf64_Word), # Symbol name, index in string tbl
        ('st_info_binding', c_uint8, 4), # Type and binding attributes
        ('st_info_type', c_uint8, 4),
        ('st_other', c_uint8), # No defined meaning, 0
        ('st_shndx', Elf64_Half), # Associated section index
        ('st_value', Elf64_Addr), # Value of the symbol
        ('st_size', Elf64_Xword), # Associated symbol size
    ]



class ElfSymtab(ElfSection):

    string_table : ElfSection = None # .dynstr or .strtab
    
    symbol_table : List[Elf32LittleEndianSymbolTableEntry] = None
    
    def __init__(self, elf_file : ElfFile):
        
        super().__init__(elf_file)
        
        self.symbol_table = []
    
    def _unserialize_contents(self, data : BytesIO):
        
        self.symbol_table = []
        
        for num_symbol in range(self.section_header.sh_size // self.section_header.sh_entsize):
            
            data.seek(self.section_header.sh_offset + num_symbol * self.section_header.sh_entsize)
            
            symbol_class = {
                (False, False): Elf32LittleEndianSymbolTableEntry,
                (True, False): Elf32BigEndianSymbolTableEntry,
                (False, True): Elf64LittleEndianSymbolTableEntry,
                (True, True): Elf64BigEndianSymbolTableEntry,
            }[(self.is_big_endian, self.is_64_bits)]
            
            symbol = symbol_class(self.is_big_endian, self.is_64_bits)
            
            symbol.unserialize(data)
            
            self.symbol_table.append(symbol)
            
    
    def post_unserialize(self):
            
        super().post_unserialize()
        
        # print('=> Interpreting symbol table at', self.section_name, 'at', hex(self.section_header.sh_offset))
        
        # Link strings to symbols
            
        self.string_table  = self.elf_file.sections[self.section_header.sh_link]
        
        for symbol in self.symbol_table:
            
            # symbol.pretty_print()
        
            # print(self.string_table.offset_to_string)
            symbol.symbol_name = self.string_table.return_string_from_offset(symbol.st_name)
        
            # In addition to strings, add a reference to
            # the associated section
            
            if symbol.st_shndx not in SPECIAL_SECTION_INDEX.__members__.values():
                
                symbol.associated_section = self.elf_file.sections[symbol.st_shndx]
            
            else:
                
                symbol.associated_section = SPECIAL_SECTION_INDEX(symbol.st_shndx)
        
    def pre_serialize(self):
        
        super().pre_serialize()
        
        self.section_header.sh_link = self.elf_file.sections.index(self.string_table)
        
        for symbol in self.symbol_table:
            
            symbol.st_name = self.string_table.add_string_and_return_offset(symbol.symbol_name)
            
            if symbol.associated_section and not isinstance(symbol.associated_section, SPECIAL_SECTION_INDEX):
            
                symbol.st_shndx = self.elf_file.sections.index(symbol.associated_section)
        
        self.section_header.sh_entsize = memoryview(self.symbol_table[0]).nbytes
    
    def _serialize_contents(self, data : BytesIO):
        
        local_symbols_first = lambda symbol: symbol.st_info_binding != ST_INFO_BINDING.STB_LOCAL
        
        found_a_non_local_symbol = False
        
        for num_symbol, symbol in enumerate(sorted(self.symbol_table, key = local_symbols_first)):
            
            if (symbol.st_info_binding != ST_INFO_BINDING.STB_LOCAL
                and not found_a_non_local_symbol):
                 
                found_a_non_local_symbol = True
                
                
                self.section_header.sh_info = num_symbol
                
            
            symbol.serialize(data)
            
        
        
    
class ElfDynsym(ElfSymtab):
    
    pass
    
class ElfStrtab(ElfSection):

    is_shstrtab : bool = None
    
    raw_string_table : bytes = None
    
    def _unserialize_contents(self, data : BytesIO):
        
        self.raw_string_table = data.read(self.section_header.sh_size)
    
    def _serialize_contents(self, data : BytesIO):
        
        data.write(self.raw_string_table)
    
    def return_string_from_offset(self, offset):
        
        return self.raw_string_table.decode('ascii')[offset:].split('\x00', 1)[0]
    
    def add_string_and_return_offset(self, string):
        
        string_offset = self.raw_string_table.find(string.encode('ascii') + b'\x00')
        
        if string_offset != -1:
            return string_offset
        
        string_offset = len(self.raw_string_table)
        
        self.raw_string_table += string.encode('ascii') + b'\x00'
        
        return string_offset




class Elf32LittleEndianRelocationTableEntry(VariableEndiannessAndWordsizeStructure):
    
    _fields_ = [
       ('r_offset', Elf32_Addr), # Location at which to apply the relocaction
       ('r_info_type', Elf32_Word, 8), # index and type of relocation
       ('r_info_sym', Elf32_Word, 24),
    ]
    
    # symbol_name : str = None
    
    associated_symbol : Elf32LittleEndianSymbolTableEntry = None


class Elf32BigEndianRelocationTableEntry(Elf32LittleEndianRelocationTableEntry):
    
    _fields_ = [
       ('r_offset', Elf32_Addr), # Location at which to apply the relocaction
       ('r_info_sym', Elf32_Word, 24), # index and type of relocation
       ('r_info_type', Elf32_Word, 8),
    ]
    

class Elf64LittleEndianRelocationTableEntry(Elf32LittleEndianRelocationTableEntry):
    
    _fields_ = [
       ('r_offset', Elf64_Addr), # Location at which to apply the action
       ('r_info_type', Elf64_Xword, 32), # index and type of relocation
       ('r_info_sym', Elf64_Xword, 32),
    ]
    

class Elf64BigEndianRelocationTableEntry(Elf64LittleEndianRelocationTableEntry):
    
    _fields_ = [
       ('r_offset', Elf64_Addr), # Location at which to apply the action
       ('r_info_sym', Elf64_Xword, 32), # index and type of relocation
       ('r_info_type', Elf64_Xword, 32),
    ]
    





















class Elf32LittleEndianRelocationWithAddendTableEntry(Elf32LittleEndianRelocationTableEntry):

    _fields_ = [
        *Elf32LittleEndianRelocationTableEntry._fields_,
        ('r_addend', Elf32_Sword), # Constant addend used to compute value
    ]


class Elf32BigEndianRelocationWithAddendTableEntry(Elf32LittleEndianRelocationTableEntry):

    _fields_ = [
        *Elf32BigEndianRelocationTableEntry._fields_,
        ('r_addend', Elf32_Sword), # Constant addend used to compute value
    ]


class Elf64LittleEndianRelocationWithAddendTableEntry(Elf32LittleEndianRelocationWithAddendTableEntry):

    _fields_ = [
        *Elf64LittleEndianRelocationTableEntry._fields_,
        ('r_addend', Elf64_Sxword), # Constant addend used to compute value
    ]

class Elf64BigEndianRelocationWithAddendTableEntry(Elf64LittleEndianRelocationWithAddendTableEntry):

    _fields_ = [
        *Elf64BigEndianRelocationTableEntry._fields_,
        ('r_addend', Elf64_Sxword), # Constant addend used to compute value
    ]
        
        



class ElfRel(ElfSection):
    
    relocation_table : List[Elf32LittleEndianRelocationTableEntry] = None
    
    
    def _unserialize_contents(self, data : BytesIO):
        
        self.relocation_table = []
        
        for num_symbol in range(self.section_header.sh_size // self.section_header.sh_entsize):
            
            
            relocation_class = {
                (False, False): Elf32LittleEndianRelocationTableEntry,
                (True, False): Elf32BigEndianRelocationTableEntry,
                (False, True): Elf64LittleEndianRelocationTableEntry,
                (True, True): Elf64BigEndianRelocationTableEntry,
            }[(self.is_big_endian, self.is_64_bits)]
            
            relocation = relocation_class(self.is_big_endian, self.is_64_bits)
            
            
            relocation.unserialize(data)
            
            self.relocation_table.append(relocation)
            
            
            
            
            
        
        
    
    def post_unserialize(self):
        
        super().post_unserialize()
        
        self.symtab_section  = self.elf_file.sections[self.section_header.sh_link]
        
        for relocation in self.relocation_table:
            
            relocation.associated_symbol = self.symtab_section.symbol_table[relocation.r_info_sym]
            
            # relocation.pretty_print()
            
            # print('le', relocation.associated_symbol.symbol_name)
            
            # relocation.symbol_name = relocation.associated_symbol.symbol_name
    
    
    def pre_serialize(self):
        
        super().pre_serialize()
        
        for relocation in self.relocation_table:
            
            relocation.r_info_sym = self.symtab_section.symbol_table.index(relocation.associated_symbol)
        
        self.section_header.sh_entsize = memoryview(self.relocation_table[0]).nbytes
    
    def _serialize_contents(self, data : BytesIO):
        
        for relocation in self.relocation_table:
            
            relocation.serialize(data)
            
            

class ElfRela(ElfRel):
    
    relocation_table : List[Elf32LittleEndianRelocationWithAddendTableEntry] = None
    
    
    def unserialize(self, data : BytesIO):
        
        super().unserialize(data)
        
        data.seek(self.section_header.sh_offset)
        
        self.relocation_table = []
        
        for num_symbol in range(self.section_header.sh_size // self.section_header.sh_entsize):

            relocation_class = {
                (False, False): Elf32LittleEndianRelocationWithAddendTableEntry,
                (True, False): Elf32BigEndianRelocationWithAddendTableEntry,
                (False, True): Elf64LittleEndianRelocationWithAddendTableEntry,
                (True, True): Elf64BigEndianRelocationWithAddendTableEntry,
            }[(self.is_big_endian, self.is_64_bits)]
            
            relocation = relocation_class(self.is_big_endian, self.is_64_bits)
            
            relocation.unserialize(data)
            
            self.relocation_table.append(relocation)
            
    

class ElfDynamic(ElfSection):
    
    pass

class ElfHash(ElfSection):
    
    symbol_table : ElfSection = None
        
        
        
        
SECTION_TYPE_TO_CLASS = {
    SH_TYPE.SHT_NULL: ElfNullSection,
    SH_TYPE.SHT_PROGBITS: ElfProgbits,
    SH_TYPE.SHT_NOBITS: ElfNoBits,
    SH_TYPE.SHT_SYMTAB: ElfSymtab,
    SH_TYPE.SHT_STRTAB: ElfStrtab,
    SH_TYPE.SHT_RELA: ElfRela,
    SH_TYPE.SHT_HASH: ElfHash,
    SH_TYPE.SHT_DYNAMIC: ElfDynamic,
    SH_TYPE.SHT_REL: ElfRel,
    SH_TYPE.SHT_DYNSYM: ElfDynsym
}

SECTION_CLASS_TO_TYPE = {v: k for k, v in    SECTION_TYPE_TO_CLASS.items()} 
        
        

class E_IDENT_INDEXES(IntEnum):

    EI_MAG0 = 0
    EI_MAG1 = 1
    EI_MAG2 = 2
    EI_MAG3 = 3
    EI_CLASS = 4
    EI_DATA = 5
    EI_VERSION = 6
    EI_OSABI = 7
    EI_ABIVERSION = 8
    EI_NIDENT = 16


class EI_VERSION(IntEnum):
    
    EV_CURRENT = 1   


class EI_CLASS(IntEnum):
    
    ELFCLASS32 = 1
    
    ELFCLASS64 = 2


class EI_DATA(IntEnum):
    
    ELFDATA2LSB = 1 # 32-bit objects
    
    ELFDATA2MSB = 2 # 64-bit objects


class EI_OSABI(IntEnum):
    
    ELFOSABI_SYSV = 0 # System V ABI
    
    ELFOSABI_HPUX = 1 # HP-UX operating system
    
    ELFOSABI_STANDALONE = 255 # Standalone (embedded) application


class E_TYPE(IntEnum):
    
    ET_NONE = 0 # No file type
    
    ET_REL = 1 # Relocatable object file
    
    ET_EXEC = 2 # Executable file
    
    ET_DYN = 3 # Shared object file
    
    ET_CORE = 4 # Core file


class ElfFileHeader(VariableEndiannessAndWordsizeStructure):
    
    _fields_ = [
    
      ('EI_MAG', c_char * 4), # ELF "magic number"
      ('EI_CLASS', c_uint8), # File class
      ('EI_DATA', c_uint8), # Data encoding
      ('EI_VERSION', c_uint8), # File version
      ('EI_OSABI', c_uint8), # OS/ABI identification
      ('EI_ABIVERSION', c_uint8), # ABI version
      ('EI_PAD', c_uint8 * 7),
      
      ('e_type', Elf64_Half),
      ('e_machine', Elf64_Half),
      ('e_version', Elf64_Word),
      ('e_entry', Elf64_Addr), # Entry point virtual address
      ('e_phoff', Elf64_Off), # Program header table file offset
      ('e_shoff', Elf64_Off), # Section header table file offset
      ('e_flags', Elf64_Word),
      ('e_ehsize', Elf64_Half),
      ('e_phentsize', Elf64_Half),
      ('e_phnum', Elf64_Half),
      ('e_shentsize', Elf64_Half),
      ('e_shnum', Elf64_Half),
      ('e_shstrndx', Elf64_Half),
    ]
    
    def __init__(self):
                
        self.EI_MAG = b'\x7fELF'
        
        self.EI_CLASS = {
            False: EI_CLASS.ELFCLASS32,
            True: EI_CLASS.ELFCLASS64
        }[self.is_64_bits]
        
        self.EI_DATA = {
            False: EI_DATA.ELFDATA2LSB,
            True: EI_DATA.ELFDATA2MSB
        }[self.is_big_endian]
        
        self.EI_OSABI = EI_OSABI.ELFOSABI_SYSV
        
        self.e_version = self.EI_VERSION = EI_VERSION.EV_CURRENT
        
        
        
        # Let the user set e_flags, e_machine, e_entry
        
        



class P_TYPE: # PROGRAM_HEADER_TYPE
    
    PT_NULL = 0 # Null descriptor — ignore
    PT_LOAD = 1 # Loadable segment
    PT_DYNAMIC = 2 # Dynamic segment
    PT_INTERP = 3 # Interpreter pathname
    PT_NOTE = 4 # Auxiliary information segment
    PT_SHLIB = 5 # Reserved
    PT_PHDR = 6 # Program header segment


class P_FLAGS: # PROGRAM_HEADER_FLAGS
    
    PF_X = 0x1 # Executable
    PF_W = 0x2 # Writable
    PF_R = 0x4 # Readable

    
    

class Elf32ProgramHeaderEntry(VariableEndiannessAndWordsizeStructure):
    
    _fields_ = [
        ('p_type', Elf32_Word),
        ('p_offset', Elf32_Off), # Segment file offset
        ('p_vaddr', Elf32_Addr), # Segment virtual address
        ('p_paddr', Elf32_Addr), # Segment physical address
        ('p_filesz', Elf32_Word), # Segment size in file
        ('p_memsz', Elf32_Word), # Segment size in memory
        ('p_flags', Elf32_Word),
        ('p_align', Elf32_Word), # Segment alignment, file & memory
    ]
    

class Elf64ProgramHeaderEntry(Elf32ProgramHeaderEntry):
    
    _fields_ = [
        ('p_type', Elf64_Word),
        ('p_flags', Elf64_Word),
        ('p_offset', Elf64_Off), # Segment file offset
        ('p_vaddr', Elf64_Addr), # Segment virtual address
        ('p_paddr', Elf64_Addr), # Segment physical address
        ('p_filesz', Elf64_Xword), # Segment size in file
        ('p_memsz', Elf64_Xword), # Segment size in memory
        ('p_align', Elf64_Xword), # Segment alignment, file & memory
    ]
    











```

`vmlinux_to_elf/utils/lz4_legacy.py`:

```py
#!/usr/bin/python3
#-*- encoding: Utf-8 -*-
from lz4.block import decompress
from io import BytesIO

"""
    This file  contains a basic translator for turning compression
    streams using the legacy LZ4 format [1] (magic 0x184C2102),
    used by various old or less old Linux kernels, into the newer
    LZ4 format [2] (magic 0x184D2204).
    
    [1] 02 21 4C 18 - https://github.com/lz4/lz4/blob/dev/doc/lz4_Frame_format.md#legacy-frame
    [2] 04 22 4D 18 - https://github.com/lz4/lz4/blob/dev/doc/lz4_Frame_format.md#general-structure-of-lz4-frame-format
"""

def decompress_lz4_buffer(lz4_buffer : BytesIO):
    
    assert lz4_buffer.read(4) == (0x184C2102).to_bytes(4, 'little') # Check the legacy magic
    
    MAX_LEGACY_BLOCK_SIZE = 8 * 1024 * 1024 # 8 MB
    
    uncompressed_stream = b''
    
    while True:
        compressed_block_size_raw = lz4_buffer.read(4)
        if len(compressed_block_size_raw) < 4:
            break
        
        compressed_block_size = int.from_bytes(compressed_block_size_raw, 'little')
        
        compressed_block = lz4_buffer.read(compressed_block_size)
        if len(compressed_block) < compressed_block_size or not compressed_block_size:
            break
        
        uncompressed_block = decompress(compressed_block, MAX_LEGACY_BLOCK_SIZE)
        uncompressed_stream += uncompressed_block
        if len(uncompressed_block) < MAX_LEGACY_BLOCK_SIZE:
            break
        
    return uncompressed_stream
        
        


```

`vmlinux_to_elf/utils/pretty_print.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-

from collections import OrderedDict


"""
    Pretty print a file name in an ASCII rectangle.
    
    :param header_text: The file name.
"""

def pretty_print_header(header_text):
    
    max_text_length = max(len(header_text), 72)
    
    print()
    print()
    
    print('+-%s-+' % ('-' * max_text_length))
    
    print('| %s |' % header_text.ljust(max_text_length))
    
    print('+-%s-+' % ('-' * max_text_length))


"""
    Turn a parsed C structure in a dict of human-readable key-value
    pairs, for displayal in ASCII tables
    
    :param ctypes_structure: A parsed ctypes structures to consume.
    
    :returns An OrderedDict of strings/strings.
"""

def structure_to_key_values_strings(ctypes_structure):
    
    key_values = OrderedDict()
    
    for key, ctype in (field[:2] for field in ctypes_structure._fields_):
        
        value = getattr(ctypes_structure, key)
        
        # Turn "key_name" into "Key name"
        
        pretty_key = key[0].upper() + key[1:]
        pretty_key = pretty_key.replace('_', ' ')
        
        # Stringify the value
        
        if type(value) == bytes: # Strings
            
            key_values[pretty_key] = value.decode('ascii')
        
        elif key in field_name_to_structure: # Integer enums
            
            try:
                enum_field = field_name_to_structure[key](value)
                
                key_values[pretty_key] = enum_field.name
            
            except ValueError:
            
                key_values[pretty_key] = str(value) + ' ?'
        
        elif type(value) == int: # Integer
            
            key_values[pretty_key] = '0x%08x' % value if value else 'N/A'
    
    return key_values


"""
    Return an ASCII table from a parsed C structure, with field names as
    column 1 and values as column 2.
"""

def pretty_print_structure(ctypes_structure):
    
    key_values = structure_to_key_values_strings(ctypes_structure)
    
    pretty_print_table(list(key_values.items()))


"""
    Return an ASCII table from an array of parsed C structures, with field names
    as row 1 and values as further rows.
"""

def pretty_print_array_of_structures(array_of_structures):
    
    if array_of_structures:
        
        key_values_pairs = [
            structure_to_key_values_strings(structure)
            
            for structure in array_of_structures
        ]
        
        pretty_print_table(
            [list(key_values_pairs[0].keys())] + # Row 1: field names
            
            [list(key_values.values()) for key_values in key_values_pairs] # Rows 2+: field values
        )


"""
    Return an ascii table from a list (rows) of list (columns) of strings (cells)
"""

def pretty_print_table(rows):
    
    # Calculate columns length
    
    number_of_columns = len(rows[0])
    
    column_to_max_length = [

        max(len(row[column]) for row in rows)
        
        for column in range(number_of_columns)
    ]
    
    # Do a nice table
    
    print()
    
    print('+-%s-+' % '---'.join('-' * max_len for max_len in column_to_max_length))
    
    for row in rows:
        
        print('| %s |' % ' | '.join(
        
            row[column].ljust(column_to_max_length[column])
            
            for column in range(number_of_columns))
        )
        
        print('+-%s-+' % '---'.join('-' * max_len for max_len in column_to_max_length))
        


from sys import path
from os.path import dirname, realpath

path.append(realpath(dirname(__file__)))

import elf

field_name_to_structure = {
    key.lower(): value for key, value in vars(elf).items()
    if 'FLAGS' not in key
}


```

`vmlinux_to_elf/vmlinuz_decompressor.py`:

```py
#!/usr/bin/env python3
#-*- encoding: Utf-8 -*-
from lzma import LZMADecompressor
from io import BytesIO, SEEK_END
from bz2 import BZ2Decompressor
from gzip import _GzipReader
from struct import unpack
from typing import Union
from re import search
import importlib
import logging

"""
    How to detect a vmlinuz file?
    
    A "standard" script for it does not
    attempt to interprete architecture-specific
    details, but just scans for a file compression
    signature:
    https://github.com/torvalds/linux/blob/master/scripts/extract-vmlinux
    
    This script uses supports the following compression formats, which are all
    the standard compression formats for the kernel, some of which have been
    added quite recently (including LZO, LZ4 and Facebook's ZSTD):
    
    try_decompress b'\x1f\x8b\x08'  xy    gunzip          1f8b08
    try_decompress b'\xfd7zXZ\x00'  abcde unxz            fd377a585a00   (AND NOT "fd377a585a00000000".decode('hex')+"XZ decompressor")
    try_decompress b'BZh'           xy    bunzip2
    try_decompress b']\x00\x00\x00' xxx   unlzma
    try_decompress b'\x89LZ'        xy    'lzop -d'
    try_decompress b'\x02!L\x18'    xxx   'lz4 -d'
    try_decompress b'(\xb5/\xfd'    xxx   unzstd
    
    On x86:
    Sample assembly is here https://github.com/torvalds/linux/blob/master/arch/x86/boot/header.S#L300
    => How does libmagic detect it?
    ==> https://github.com/threatstack/libmagic/blob/master/magic/Magdir/linux#L99
    
    On ARM:
    Sample assembly is here https://github.com/torvalds/linux/blob/master/arch/arm/boot/compressed/head.S#L180
    => Magics defined here: https://github.com/torvalds/linux/blob/master/arch/arm/boot/compressed/vmlinux.lds.S#L111
    ==> Magic numbers are: 0x04030201 and 0x016f2818
    ==> The data put after allows to know the offset of the end of the compressed vmlinuz executable (the total file size normally), and jump from the end of the size to the offset of the integer containing the offset to the compressed XZ data (located at -0x28 from the end (is this an appended dtb?))
    ==> Additional information with magics numbers 0x45454545 and 0x5a534c4b has been added as of September 2017 (kernel 4.15)
    => How does binwalk detect it?
    => How does libmagic detect it?
    ==> https://github.com/threatstack/libmagic/blob/master/magic/Magdir/linux#L194
"""

"""
    This class contains well-known vmlinux signatures
"""

class Signature:
    Compressed_GZIP = b'\x1f\x8b\x08'
    Compressed_XZ   = b'\xfd7zXZ\x00'
    Compressed_LZMA = b']\x00\x00'
    Compressed_BZ2  = b'BZh'
    Compressed_LZ4  = b'\x04"M\x18'     # https://github.com/lz4/lz4/blob/dev/doc/lz4_Frame_format.md
    Compressed_LZ4_Legacy = b'\x02!L\x18'
    Compressed_ZSTD = b'(\xb5/\xfd'
    Compressed_LZO  = b'\x89LZ'
    DTB_Appended_Qualcomm = b'UNCOMPRESSED_IMG' # https://www.google.com/search?q="PATCHED_KERNEL_MAGIC"
    Android_Bootimg = b'ANDROID!' # https://source.android.com/devices/bootloader/boot-image-header

    Compressed = [
        Compressed_GZIP,
        Compressed_XZ,
        Compressed_LZMA,
        Compressed_BZ2,
        Compressed_LZ4,
        Compressed_LZ4_Legacy,
        Compressed_ZSTD,
        Compressed_LZO,
    ]

    @staticmethod
    def check(data, offset, sign):
        return sign == data[offset:offset + len(sign)]

    @staticmethod
    def is_compressed(data, offset):
        for sign in Signature.Compressed:
            if Signature.check(data, offset, sign):
                return True
        return False    

"""
    This class will try to read a single GZip file
    out of a given input buffer, rather than an unlimited
    number of succeeding GZip files.
    
    The constructor takes a single BytesIO instance as an
    argument.
"""

class SingleGzipReader(_GzipReader):
    read_one_gzip_header : bool = False
    __new_member : bool = None
    
    @property
    def _new_member(self):
        return self.__new_member
    
    @_new_member.setter
    def _new_member(self, new_value): # Property normally set to True once per GZip header to be read
        if new_value:
            if self.read_one_gzip_header:
                self._fp.file.seek(0, SEEK_END) # Simulate EOF when called for the second time
                self._fp._read = None
            self.read_one_gzip_header = True
        self.__new_member = new_value
        

"""
    Try to decompress a file at a given offset, without
    knowing the compression algorithm
"""


def try_decompress_at(input_file : bytes, offset : int) -> bytes:
    
    decoded = None
    try:
        
        if Signature.check(input_file, offset, Signature.DTB_Appended_Qualcomm): # Merely unpack a Qualcomm kernel file containing a magic and DTB offset at the start (so that offsets aren't wrong)
            
            dtb_offset_le = int.from_bytes(input_file[offset + 16:offset + 20], 'little')
            dtb_offset_be = int.from_bytes(input_file[offset + 16:offset + 20], 'big')
            
            decoded = input_file[offset + 20:offset + 20 + min(dtb_offset_le, dtb_offset_be)]
        
        elif Signature.check(input_file, offset, Signature.Android_Bootimg): # Unpack an uncompressed Android Bootimg file, version 0, 1, 2 or 3
            
            # See, for reference:
            # - https://github.com/osm0sis/mkbootimg/blob/master/unpackbootimg.c
            # - https://github.com/osm0sis/mkbootimg/blob/master/bootimg.h
            
            assert len(input_file) > 4096
            
            header_version_raw = input_file[offset + 10 * 4: offset + 11 * 4]
            
            endianness = 'little'

            if header_version_raw in (b'\0\0\0\3', b'\3\0\0\0'):
                page_size = 4096
                
                if header_version_raw == b'\0\0\0\3':
                    endianness = 'big'
                
            else:
                page_size_raw = input_file[offset + 9 * 4:offset + 10 * 4]
                
                page_size_le = int.from_bytes(page_size_raw, 'little')
                page_size_be = int.from_bytes(page_size_raw, 'big')
                
                if page_size_le < page_size_be:
                    page_size = page_size_le
                else:
                    endianness = 'big'
                    page_size = page_size_be
            
            kernel_size = int.from_bytes(input_file[offset + 2 * 4:offset + 3 * 4], endianness)
            
            assert len(input_file) > kernel_size > 0x1000
            assert len(input_file) > page_size > 0x200
            
            decoded = input_file[offset + page_size:offset + page_size + kernel_size]
            
            # Also try to re-unpack the output image in the case where the nested
            # kernel would start with a "UNCOMPRESSED_IMG" Qualcomm magic, for example
            
            decoded = try_decompress_at(decoded, 0) or decoded
        
        
        elif Signature.check(input_file, offset, Signature.Compressed_GZIP):
            decoded = SingleGzipReader(BytesIO(input_file[offset:])).read(-1) # GZIP - Will stop reading after the GZip footer thanks to our modification above.
        
        elif (Signature.check(input_file, offset, Signature.Compressed_XZ) or
              Signature.check(input_file, offset, Signature.Compressed_LZMA)):
            try:
                decoded = LZMADecompressor().decompress(input_file[offset:]) # LZMA - Will discard the extra bytes and put it an attribute.
                
            except Exception:
                decoded = LZMADecompressor().decompress(input_file[offset:offset + 5] + b'\xff' * 8 + input_file[offset + 5:]) # pylzma format compatibility
        
        elif Signature.check(input_file, offset, Signature.Compressed_BZ2):
            decoded = BZ2Decompressor().decompress(input_file[offset:]) # BZ2 - Will discard the extra bytes and put it an attribute.

        elif Signature.check(input_file, offset, Signature.Compressed_LZ4): # LZ4 support
            try:
                LZ4Decompressor = importlib.import_module('lz4.frame')
                
            except ModuleNotFoundError:
                logging.error('ERROR: This kernel requres LZ4 decompression.')
                logging.error('       But "lz4" python package was not found.')
                logging.error('       Example installation command: "sudo pip3 install lz4"')
                logging.error()
                return

            context = LZ4Decompressor.create_decompression_context()
            decoded, bytes_read, end_of_frame = LZ4Decompressor.decompress_chunk(context, input_file[offset:])
        
        elif Signature.check(input_file, offset, Signature.Compressed_LZ4_Legacy): # LZ4 support (legacy format)
            
            try:
                from utils.lz4_legacy import decompress_lz4_buffer
            except ImportError:
                try:
                    from vmlinux_to_elf.utils.lz4_legacy import decompress_lz4_buffer
                except ModuleNotFoundError:
                    logging.error('ERROR: This kernel requres LZ4 decompression.')
                    logging.error('       But "lz4" python package was not found.')
                    logging.error('       Example installation command: "sudo pip3 install lz4"')
                    logging.error()
                    return
                
            decoded = decompress_lz4_buffer(BytesIO(input_file[offset:]))

        elif Signature.check(input_file, offset, Signature.Compressed_ZSTD):
            try:
                import zstandard as zstd
            except ModuleNotFoundError:
                logging.error('ERROR: This kernel requres ZSTD decompression.')
                logging.error('       But "zstandard" python package was not found.')
                logging.error('       Example installation command: "sudo pip3 install zstandard"')
                logging.error()
                return
            buf = BytesIO()
            context = zstd.ZstdDecompressor()
            for chunk in context.read_to_iter(BytesIO(input_file[offset:])):
                buf.write(chunk)
            buf.seek(0)
            decoded = buf.read()

        elif Signature.check(input_file, offset, Signature.Compressed_LZO):
            try:
                import lzo
            except ModuleNotFoundError:
                logging.error('ERROR: This kernel requres LZO decompression.')
                logging.error('       But "python-lzo" python package was not found.')
                logging.error('       Example installation command: "sudo pip3 install git+https://github.com/clubby789/python-lzo@b4e39df"')
                logging.error()
                return
            buf = BytesIO(input_file[offset:])
            decoded = lzo.LzoFile(fileobj=buf, mode='rb').read()
    except Exception:
        pass
    
    if decoded and len(decoded) > 0x1000:
        logging.info(('[+] Kernel successfully decompressed in-memory (the offsets that ' +
            'follow will be given relative to the decompressed binary)'))
    
        return decoded

def obtain_raw_kernel_from_file(input_file: bytes) -> bytes:
    
    # Check for known signatures at fixed offsets.
    # 
    # Note that mangled semi-correct kernel version strings may be present
    # in the compressed output at this point, so don't check for a kernel
    # version string for now.
    
    file_size = len(input_file)

    # Try offsets that may be stored in the
    # last words of the file, as well for
    # the start of the file
    
    possible_offsets :     Set[int] =         set([0])

    for possible_endianness in '<>':
        possible_offsets |=       set(unpack(possible_endianness + '20I',  input_file[file_size - 4 * 20:]))
    
    for possible_offset in sorted(possible_offsets):
        decompressed_data = try_decompress_at(input_file, possible_offset)
        if decompressed_data:
            return decompressed_data
    
    if not search(b'Linux version (\d+\.[\d.]*\d)[ -~]+', input_file):  # No kernel version string found

        # If not successful, scan for compression signatures in the whole document
        for possible_signature in Signature.Compressed:
            
            possible_offset = input_file.find(possible_signature)
            
            while possible_offset > -1:
                decompressed_data = try_decompress_at(input_file, possible_offset)
                if decompressed_data:
                    return decompressed_data
                possible_offset = input_file.find(possible_signature, possible_offset + 1)

    
    return input_file
    
    



```