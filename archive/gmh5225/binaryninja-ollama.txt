Project Path: arc_gmh5225_binaryninja-ollama_o95d_q64

Source Tree:

```txt
arc_gmh5225_binaryninja-ollama_o95d_q64
├── LICENSE
├── README.md
├── __init__.py
├── ollama_client.py
├── plugin.json
├── plugin.py
├── rename_tasks.py
├── requirements.txt
├── resources
│   ├── ls-rename-all-func-after.png
│   ├── ls-rename-all-func-after2.png
│   ├── ls-rename-all-func-before.png
│   ├── ls-rename-all-variables-after.png
│   ├── ls-rename-all-variables-before.png
│   ├── settings-connection.png
│   ├── settings-model.png
│   └── settings-options.png
└── ui.py

```

`LICENSE`:

```
Copyright (c) 2024 ahaggard2013

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

```

`README.md`:

```md
[!["Buy Me A Coffee"](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/ahaggard)

# Binary Ninja Ollama (v1.0.5)
Author: **Austin Haggard**

_Binary Ninja Ollama integrates with your own locally hosted ollama server to rename functions and variables with AI_

## Description:
Ollama is a tool that allows you to pull open source AI models and run them locally.
Some models require extensive computing power, while others can be ran on your personal laptop.
Results will vary greatly depending on the model you choose to use :).

Why use this over sidekick/openai?
1. It's FREE and easy to setup locally.
2. Did I say it's FREE?
3. It can be ran anywhere without internet!
4. Your data kept between you and your ollama server with no third party.

# Features
This plugin integrates Ollama with Binary Ninja and supports the actions listed below:

- Setting which server/port binary ninja should use to connect to ollama.
  - Have a (very) high powered gaming PC? Use it to host ollama and point binja to llama3:70b/gemma2:27b.
  - Running this on a laptop? Host it locally, set it to localhost and run gemma2:latest/llama3:latest.
  - There are tons of other models to try, but I've primarily tested this with varients of llama3/gemma2 with decent results.
- Query your locally hosted ollama server to determine what a given function does.
  - This can be utilized to rename all function in bulk, or individually targeted functions.
- Allows users to rename variables in HLIL using ollama.
  - This can be utilized to rename individual variables within an instruction.
  - This can be used to rename all variables within a function.

# Installation

If you're installing this as a standalone plugin, you can place (or sym-link)
this in Binary Ninja's plugin path. Default paths are detailed on
[Vector 35's documentation](https://docs.binary.ninja/guide/plugins.html).

# Dependencies

- Python 3.10+
- `ollama` installed with `pip3 install ollama`

# Ollama Server 

This requires you to have access to or host your own ollama server and pull down any models you would like to use.

Follow the instructions on https://ollama.com to setup your server and pull any models you would like to try.
Once this is done a server should be automatically started and accessed via localhost:11434.

# Usage

## Rename all function variables

The rename all function variables option will parse all varaibles within a function and attempt to rename them based on the following prompt:

```
prompt = (
             f"In one word, what should the variable '{variable}' be named in the below Function? "
             f"The name must meet the following criteria: all lowercase letters, usable in Python code"
)

```

![Before variables renaming](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/ls-rename-all-variables-before.png?raw=true)
![After variables renaming](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/ls-rename-all-variables-after.png?raw=true)

## Rename all functions
The rename all functions option will loop through all functions, smallest to largest, within a binaryview and rename them based on the prompt:

```
prompt = (
    f"Given the following HLIL decompiled code snippet, provide a Python-style function name that describes what the code is doing. "
    f"The name must meet the following criteria: all lowercase letters, usable in Python code, with underscores between words. "
    f"Only return the function name and no other explanation or text data included."
)
```

![Before functions renaming](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/ls-rename-all-func-before.png?raw=true)
![After functions renaming](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/ls-rename-all-func-after.png?raw=true)
![After functions renaming](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/ls-rename-all-func-after2.png?raw=true)

## Rename target function
Renaming a target function uses the same prompt as renaming all functions, but limits it the selected function when triggering the plugin.

## Rename target function variable
Renaming a target variable uses the same prompt as renaming all variables, but limits it the selected function when triggering the plugin.

## Settings
Settings is triggered at the first call to any renaming operation when binary ninja is first started, or by triggering it manually. The appplied settings will persist within a binary ninja session.

The settings window allows you to set the IP, port, and model to use within ollama. Only downloaded models are selectable.


![Plugin settings option](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/settings-options.png?raw=true)
![Plugin connection options](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/settings-connection.png?raw=true)
![Plugin model options](https://github.com/ahaggard2013/binaryninja-ollama/blob/main/resources/settings-model.png?raw=true)

## Known Issues
- On larger functions AI will ignore the prompt and return large blocks of text describing the function. This is mitigated by ignoring the returned value and throwing a "can't rename function' log, but could be further investigated
- The chosen server being non-existent could be handled better.

## Feature Request
- Anything you are intesested in that is not included? 
    - Open an issue!
    - Make a pull request.

- Ideas:
    - Improved 'all function' renaming (see code comments)
    - target single variable naming instead of all variables on a line
    - generate AI comments describing code
    - Structure Recovery

## License

This plugin is released under a MIT license.

```

`__init__.py`:

```py
from .plugin import *

PluginCommand.register(r"Ollama\Rename all functions", "Rename all functions based on (HLIL)", rename_all_functions_command)

PluginCommand.register_for_high_level_il_function(r"Ollama\Rename target function", "Rename target function based on (HLIL)",
                            rename_function_HLIL_command)

PluginCommand.register_for_high_level_il_function(r"Ollama\Rename all function variables", "Rename target function variables based on (HLIL)",
                            rename_function_variables_command)

PluginCommand.register_for_high_level_il_instruction(r"Ollama\Rename target variable", "Rename target variable based on (HLIL)",
                            rename_variable_command)

PluginCommand.register(r"Ollama\Settings\Set ollama model", "set the model you want to run", set_model_dialog)

PluginCommand.register(r"Ollama\Settings\Set ollama server", "set the server where you want to access ollama", set_server_dialog)


```

`ollama_client.py`:

```py
from ollama import Client
from binaryninja import log_info
from .rename_tasks import RenameAllFunctions, RenameVariable, RenameFunction, RenameFunctionVariables

class OllamaClient:
    """
    A singleton class to interact with the Ollama server for renaming functions and variables.
    """
    _instance = None

    def __new__(cls, bv):
        """
        Ensure that only one instance of the class is created.

        Args:
            bv (BinaryView): The current BinaryView instance.

        Returns:
            OllamaClient: The single instance of the OllamaClient class.
        """
        if cls._instance is None:
            cls._instance = super(OllamaClient, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, bv):
        """
        Initialize the OllamaClient instance.

        Args:
            bv (BinaryView): The current BinaryView instance.
        """
        if not self._initialized:
            self.bv = bv
            self.host = None
            self.port = None
            self.client = None
            self.model = None
            self._initialized = True

    def get_host(self):
        """
        Get the current host.

        Returns:
            str: The current host.
        """
        return self.host

    def get_port(self):
        """
        Get the current port.

        Returns:
            str: The current port.
        """
        return self.port

    def get_model(self):
        """
        Get the current model.

        Returns:
            str: The current model.
        """
        return self.model

    def set_host(self, host):
        """
        Set the host.

        Args:
            host (str): The host to be set.
        """
        self.host = host

    def set_port(self, port):
        """
        Set the port.

        Args:
            port (str): The port to be set.
        """
        self.port = port 

    def set_model(self, model):
        """
        Set the model.

        Args:
            model (str): The model to be set.
        """
        self.model = model
    
    def init_client(self):
        """
        Initialize the Ollama client.
        """
        if self.host is not None and self.port is not None:
            self.client = Client(host=f"{self.host}:{self.port}")

    def is_set(self):
        """
        Check if the host, port, and model are set.

        Returns:
            bool: True if all are set, False otherwise.
        """
        if all(x is not None for x in (self.host, self.port, self.model)):
            return True
        return False

    def get_available_models(self):
        """
        Get the available models from the Ollama server.

        Returns:
            list: A list of available models.
        """
        if self.host is not None and self.port is not None:
            return [model['name'] for model in self.client.list()['models']]

    def get_variable_name(self, variable, hlil):
        """
        Get a suggested name for a variable.

        Args:
            variable (str): The current variable name.
            hlil (str): The HLIL decompiled code snippet.

        Returns:
            str: The suggested variable name.
        """
        prompt = (
                     f"In one word, what should the variable '{variable}' be named in the below Function? "
                     f"The name must meet the following criteria: all lowercase letters, usable in Python code"
        )
        prompt += f"Function:\n{hlil}\n\n"
        response = self.generate(
            model=self.model,
            prompt=prompt,
            stream=False
        ) 
        variable_name = response['response']
        
        # Check if the variable name is a single word with no spaces
        if " " not in variable_name.strip():
            return variable_name.strip()
        else:
            return None

    def get_function_name(self, hlil):
        """
        Get a suggested name for a function.

        Args:
            hlil (str): The HLIL decompiled code snippet.

        Returns:
            str: The suggested function name.
        """
        prompt = (
            f"Given the following HLIL decompiled code snippet, provide a Python-style function name that describes what the code is doing. "
            f"The name must meet the following criteria: all lowercase letters, usable in Python code, with underscores between words. "
            f"Only return the function name and no other explanation or text data included."
        )
        prompt += f"Function:\n{hlil}\n\n"
        response = self.generate(
            model=self.model,
            prompt=prompt,
            stream=False
        ) 
        function_name = response['response']
        
        # Check if the function name is a single word with no spaces
        if " " not in function_name.strip():
            return function_name.strip()
        else:
            return None
    
    def generate(self, model, prompt, stream):
        """
        Generate a response from the Ollama server.

        Args:
            model (str): The model to be used.
            prompt (str): The prompt to be sent.
            stream (bool): Whether to stream the response.

        Returns:
            dict: The response from the server.
        """
        return self.client.generate(model=model, prompt=prompt, stream=stream)

    def rename_function_variables(self, hlil):
        """
        Rename the variables of a function.

        Args:
            hlil (str): The HLIL decompiled code snippet.
        """
        rename_function_variables = RenameFunctionVariables(self, self.bv, hlil)
        rename_function_variables.start()

    def rename_target_variable(self, inst):
        """
        Rename a target variable.

        Args:
            inst (Instruction): The instruction containing the variable to be renamed.
        """
        rename_target_variable = RenameVariable(self, self.bv, inst)
        rename_target_variable.start()

    def rename_target_function(self, hlil):
        """
        Rename a target function.

        Args:
            hlil (str): The HLIL decompiled code snippet.
        """
        rename_target_function = RenameFunction(self, self.bv, hlil)
        rename_target_function.start()

    def rename_all_functions(self):
        """
        Rename all functions in the current BinaryView.
        """
        rename_all_functions = RenameAllFunctions(self, self.bv)
        rename_all_functions.start()


```

`plugin.json`:

```json
{
    "pluginmetadataversion": 2,
    "name": "Binary Ninja Ollama",
    "type": [
        "core",
        "ui",
        "architecture",
        "binaryview",
        "helper"
    ],
    "api": [
        "python3"
    ],
    "description": "Binary Ninja Ollama integrates with your own locally hosted ollama server to rename functions and variables with AI",
    "longdescription": "Ollama is a free, open source tool that allows you to host locally run AI models. Binary Ninja Ollama allows you to utilize your locally hosted ollama server to preform reverse engineering tasks such as renaming functions and variables with AI FOR FREE.",
    "license": {
        "name": "MIT",
        "text": "Copyright (c) 2024 ahaggard2013 \n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
    },
    "platforms": [
        "Darwin",
        "Linux",
        "Windows"
    ],
    "installinstructions": {
        "Darwin": "",
        "Linux": "",
        "Windows": ""
    },
    "dependencies": {
        "pip": [
            "ollama"
        ],
        "other": [
            "This plugin requires you to run an ollama server which can be setup at https://ollama.com. All models are free and open source and can be run on your own hardware."
        ]
    },
    "version": "1.0.2",
    "author": "Austin Haggard",
    "minimumbinaryninjaversion": 4
}

```

`plugin.py`:

```py
import os
from binaryninja import PluginCommand, BinaryView, log_info, show_message_box, MessageBoxButtonSet, MessageBoxIcon
from .ollama_client import OllamaClient
from .ui import OllamaConnectionDialog, OllamaModelDialog

def set_server_dialog(bv):
    """
    Display a dialog to set the server connection details for the Ollama client.

    Args:
        bv (BinaryView): The current BinaryView instance.

    Returns:
        bool: True if the server details were set successfully, False otherwise.
    """
    client = OllamaClient(bv)
    dialog = OllamaConnectionDialog(client.get_host(), client.get_port())
    if dialog.exec_():
        host = dialog.host.text()
        port = dialog.port.text()
        client.set_host(host)
        client.set_port(port)
        client.init_client()
        return True
    return False

def set_model_dialog(bv):
    """
    Display a dialog to set the model for the Ollama client.

    Args:
        bv (BinaryView): The current BinaryView instance.

    Returns:
        bool: True if the model was set successfully, False otherwise.
    """
    client = OllamaClient(bv)
    if not client.is_set():
        set_server_dialog(bv)
    model_dialog = OllamaModelDialog(client.get_model(), client.get_available_models())
    if model_dialog.exec_():
        model = model_dialog.model_combo.currentText()
        client.set_model(model)
        return True
    return False

def rename_function_variables_command(bv, func):
    """
    Rename the variables of a function using the Ollama client.

    Args:
        bv (BinaryView): The current BinaryView instance.
        func (Function): The function whose variables are to be renamed.
    """
    client = OllamaClient(bv)
    if not client.is_set():
        set_model_dialog(bv)
    client.rename_function_variables(func)

def rename_variable_command(bv, inst):
    """
    Rename a target variable using the Ollama client.

    Args:
        bv (BinaryView): The current BinaryView instance.
        inst (Instruction): The instruction containing the variable to be renamed.
    """
    client = OllamaClient(bv)
    if not client.is_set():
        set_model_dialog(bv)
    client.rename_target_variable(inst)

def rename_function_HLIL_command(bv, func):
    """
    Rename a function using the Ollama client based on its HLIL representation.

    Args:
        bv (BinaryView): The current BinaryView instance.
        func (Function): The function to be renamed.
    """
    client = OllamaClient(bv)
    if not client.is_set():
        set_model_dialog(bv)
    client.rename_target_function(func)

def rename_all_functions_command(bv):
    """
    Rename all functions in the current BinaryView using the Ollama client.

    Args:
        bv (BinaryView): The current BinaryView instance.
    """
    client = OllamaClient(bv)
    if not client.is_set():
        set_model_dialog(bv)
    client.rename_all_functions()


```

`rename_tasks.py`:

```py
from binaryninja import PluginCommand, BackgroundTaskThread, log_info, show_message_box, MessageBoxButtonSet, MessageBoxIcon

class RenameAllFunctions(BackgroundTaskThread):
    """
    A background task to rename all functions in the current BinaryView.

    Attributes:
        client (OllamaClient): The Ollama client instance.
        bv (BinaryView): The current BinaryView instance.
    """
    def __init__(self, client, bv):
        """
        Initialize the RenameAllFunctions task.

        Args:
            client (OllamaClient): The Ollama client instance.
            bv (BinaryView): The current BinaryView instance.
        """
        super().__init__("Starting renaming task...", True)
        self.bv = bv
        self.client = client

    def run(self):
        """
        Execute the task to rename all functions in the BinaryView.
        """
        self.bv.begin_undo_actions()
        # Get all functions and their sizes.
        functions = [(function, function.total_bytes) for function in self.bv.functions]

        # Sort functions by size (total_bytes). Starting with smaller functions will allow larger functions to receive more accurate names
        # due to them containing properly named functions prior to analysis. a more accurate solution would be to follow all called functions
        # to it's deepest call depth and naming them prior to naming the top level function. This allow all functions to contain AI generated
        # call names prior to receiving it's own name, which should allow the AI to better determine what the function is doing. The current
        # solution is easier to implement though for v1 :)
        sorted_functions = sorted(functions, key=lambda x: x[1])
        name_counter = {}
        for function, _ in sorted_functions:
            if function.name.startswith("sub_") or function.name.startswith("func_"):  # Ignore functions that are already named
                hlil = function.hlil
                if hlil:
                    function_hlil = "\n".join([str(instr) for instr in hlil.instructions])
                    new_name = self.client.get_function_name(function_hlil)

                    if new_name:
                        if new_name in name_counter:
                            name_counter[new_name] += 1
                            new_name = f"{new_name}_{name_counter[new_name]}"
                        else:
                            name_counter[new_name] = 1
                        log_info(f'Renamed {function.name} to {new_name}')
                        function.name = new_name
                    else:
                        log_info(f"Ollama didn't identify a proper name for {function.name}")
        self.bv.commit_undo_actions()

class RenameFunction(BackgroundTaskThread):
    """
    A background task to rename a function in the current BinaryView.

    Attributes:
        client (OllamaClient): The Ollama client instance.
        bv (BinaryView): The current BinaryView instance.
        hlil (HighLevelILFunction): The HighLevelIL representation of the function.
    """
    def __init__(self, client, bv, hlil):
        """
        Initialize the RenameFunction task.

        Args:
            client (OllamaClient): The Ollama client instance.
            bv (BinaryView): The current BinaryView instance.
            hlil (HighLevelILFunction): The HighLevelIL representation of the function.
        """
        super().__init__("Starting renaming task...", True)
        self.hlil = hlil
        self.bv = bv
        self.client = client

    def run(self):
        """
        Execute the task to rename the function in the BinaryView.
        """
        self.bv.begin_undo_actions()
        function_hlil = "\n".join([str(instr) for instr in self.hlil.instructions])
        new_name = self.client.get_function_name(function_hlil)
        if new_name:
            self.progress = f"Renamed function to {new_name}."
            log_info(f"Renamed function to {new_name}.")
            self.hlil.source_function.name = new_name.strip()
        else:
            self.progress = f"ollama didn't identify a proper name"
            log_info(f"ollama didn't identify a proper name")
        self.bv.commit_undo_actions()


class RenameFunctionVariables(BackgroundTaskThread):
    """
    A background task to rename variables in a function in the current BinaryView.

    Attributes:
        client (OllamaClient): The Ollama client instance.
        bv (BinaryView): The current BinaryView instance.
        hlil (HighLevelILFunction): The HighLevelIL representation of the function.
    """
    def __init__(self, client, bv, hlil):
        """
        Initialize the RenameFunctionVariables task.

        Args:
            client (OllamaClient): The Ollama client instance.
            bv (BinaryView): The current BinaryView instance.
            hlil (HighLevelILFunction): The HighLevelIL representation of the function.
        """
        super().__init__("Starting renaming task...", True)
        self.hlil = hlil
        self.bv = bv 
        self.client = client

    def run(self):
        """
        Execute the task to rename variables in the function in the BinaryView.
        """
        self.bv.begin_undo_actions()
        function_hlil = "\n".join([str(instr) for instr in self.hlil.instructions])

        vars = []
        for inst in self.hlil.instructions:
            for var in inst.vars:
                vars.append(var)

        unique_vars = list(set(vars))
        name_counter = {}

        for var in unique_vars:
            name = self.client.get_variable_name(var, function_hlil)
            if name:
                if name in name_counter:
                    name_counter[name] += 1
                    name = f"{name}_{name_counter[name]}"
                else:
                    name_counter[name] = 1
                self.progress = f'Renamed {var.name} to {name}'
                log_info(f'Renamed {var.name} to {name}') 
                var.name = name
            else:
                self.progress = f"ollama didn't identify a proper name for {var.name}"
                log_info(f"ollama didn't identify a proper name for {var.name}")
        self.bv.commit_undo_actions()

class RenameVariable(BackgroundTaskThread):
    """
    A background task to rename a specific variable in the current BinaryView.

    Attributes:
        client (OllamaClient): The Ollama client instance.
        bv (BinaryView): The current BinaryView instance.
        inst (Instruction): The instruction containing the variable to be renamed.
    """
    def __init__(self, client, bv, inst):
        """
        Initialize the RenameVariable task.

        Args:
            client (OllamaClient): The Ollama client instance.
            bv (BinaryView): The current BinaryView instance.
            inst (Instruction): The instruction containing the variable to be renamed.
        """
        super().__init__("Starting renaming task...", True)
        self.inst = inst
        self.bv = bv 
        self.client = client

    def run(self):
        """
        Execute the task to rename the variable in the BinaryView.
        """
        self.bv.begin_undo_actions()
        func = self.bv.get_functions_containing(self.inst.address)[0]
        function_hlil = "\n".join([str(instr) for instr in func.hlil.instructions])

        unique_vars = list(set(self.inst.vars))
        for var in unique_vars:
            name = self.client.get_variable_name(var, function_hlil) 
            if name:
                self.progress = f'Renamed {var.name} to {name}'
                log_info(f'Renamed {var.name} to {name}') 
                var.name = name
            else:
                self.progress = f"Ollama didn't identify a proper name for {var.name}"
                log_info(f"Ollama didn't identify a proper name for {var.name}")
        self.bv.commit_undo_actions()

```

`requirements.txt`:

```txt
ollama

```

`ui.py`:

```py
from PySide6.QtWidgets import QDialog, QVBoxLayout, QLabel, QLineEdit, QDialogButtonBox, QComboBox

class OllamaConnectionDialog(QDialog):
    """
    A dialog to set the connection settings for the Ollama client.

    Attributes:
        host (QLineEdit): A QLineEdit widget for the host input.
        port (QLineEdit): A QLineEdit widget for the port input.
    """
    def __init__(self, host, port):
        """
        Initialize the OllamaConnectionDialog.

        Args:
            host (str): The initial host value.
            port (str): The initial port value.
        """
        super().__init__()
        self.setWindowTitle("Ollama Client Settings")

        layout = QVBoxLayout()
        
        layout.addWidget(QLabel("Host:"))
        if host is not None:
            self.host = QLineEdit(host)
        else:
            self.host = QLineEdit("http://localhost")
        layout.addWidget(self.host)

        layout.addWidget(QLabel("Port:"))
        if port is not None:
            self.port = QLineEdit(port)
        else:
            self.port = QLineEdit("11434")
        layout.addWidget(self.port)

        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)

        self.setLayout(layout)

class OllamaModelDialog(QDialog):
    """
    A dialog to select the model for the Ollama client.

    Attributes:
        model_combo (QComboBox): A QComboBox widget to display available models.
    """
    def __init__(self, cur_model, models):
        """
        Initialize the OllamaModelDialog.

        Args:
            cur_model (str): The currently selected model.
            models (list): A list of available models.
        """
        super().__init__()
        self.setWindowTitle("Ollama Available Models")

        layout = QVBoxLayout()
        
        layout.addWidget(QLabel("Models:"))
        self.model_combo = QComboBox()
        self.model_combo.addItems(models)
        if cur_model is not None:
            self.model_combo.setCurrentIndex(self.model_combo.findText(cur_model))
        layout.addWidget(self.model_combo)

        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)

        self.setLayout(layout)


```