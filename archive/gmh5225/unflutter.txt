Project Path: arc_gmh5225_unflutter_sbccnab_

Source Tree:

```txt
arc_gmh5225_unflutter_sbccnab_
├── Makefile
├── README.md
├── cmd
│   └── unflutter
│       ├── artifacts.go
│       ├── clusters.go
│       ├── cmd_debug.go
│       ├── cmd_doctor.go
│       ├── cmd_ghidra.go
│       ├── cmd_ida.go
│       ├── cmd_meta.go
│       ├── cmd_run.go
│       ├── cmd_signal.go
│       ├── dart2_buckets.go
│       ├── decompile.go
│       ├── disasm.go
│       ├── disasm_test.go
│       ├── dump.go
│       ├── find_libapp.go
│       ├── find_libapp_batch.go
│       ├── flutter_meta.go
│       ├── graph.go
│       ├── ida.go
│       ├── inventory.go
│       ├── main.go
│       ├── objects.go
│       ├── parity.go
│       ├── pool.go
│       ├── render.go
│       ├── resolve.go
│       ├── scan.go
│       ├── signal.go
│       ├── strings.go
│       ├── thr_audit.go
│       ├── thr_classify.go
│       └── thr_cluster.go
├── ghidra_scripts
│   ├── AARCH64_dart.cspec
│   ├── unflutter_apply.py
│   └── unflutter_prescript.py
├── go.mod
├── go.sum
├── ida_scripts
│   └── unflutter_apply.py
└── internal
    ├── callgraph
    │   ├── callgraph.go
    │   ├── cfg.go
    │   └── cfg_test.go
    ├── cli
    │   └── color.go
    ├── cluster
    │   ├── cid.go
    │   ├── cluster.go
    │   ├── cluster_test.go
    │   ├── fill.go
    │   ├── fillspec.go
    │   ├── instrtable.go
    │   ├── instrtable_test.go
    │   └── trace.go
    ├── dartfmt
    │   ├── diag.go
    │   ├── stream.go
    │   └── stream_test.go
    ├── disasm
    │   ├── annotate.go
    │   ├── annotate_test.go
    │   ├── branch.go
    │   ├── branch_test.go
    │   ├── calledge.go
    │   ├── calledge_test.go
    │   ├── cfg.go
    │   ├── cfg_test.go
    │   ├── disasm.go
    │   ├── disasm_test.go
    │   ├── pipeline.go
    │   ├── thraudit.go
    │   ├── thrclassify.go
    │   ├── thrclassify_test.go
    │   ├── thrfields.go
    │   └── thrfields_test.go
    ├── elfx
    │   ├── elfx.go
    │   └── elfx_test.go
    ├── output
    │   └── output.go
    ├── pipeline
    │   ├── disasm_stage.go
    │   ├── helpers.go
    │   ├── meta_stage.go
    │   ├── pipeline.go
    │   └── signal_stage.go
    ├── render
    │   ├── callgraph.go
    │   ├── cfg.go
    │   ├── classgraph.go
    │   ├── helpers.go
    │   ├── html.go
    │   ├── reachability.go
    │   ├── signal_cfg_dot.go
    │   ├── signal_dot.go
    │   ├── signal_html.go
    │   └── theme.go
    ├── signal
    │   ├── classify.go
    │   ├── classify_test.go
    │   └── graph.go
    └── snapshot
        ├── image.go
        ├── probe.go
        ├── profile.go
        ├── snapshot.go
        ├── snapshot_test.go
        └── version.go

```

`Makefile`:

```
.PHONY: build test fuzz boot clean scan disasm render report skills flutter-meta ghidra inventory parity install

BINARY := unflutter
SAMPLE ?= samples/blutter-lce.so
SAMPLE_NAME := $(basename $(notdir $(SAMPLE)))
OUT_DIR := out/$(SAMPLE_NAME)
GHIDRA_HOME ?= /Volumes/tank4a - Data/opt/homebrew/Caskroom/ghidra/11.4-20250620/ghidra_11.4_PUBLIC
GHIDRA_PROJECTS ?= scratch/ghidra-projects

build:
	go build -o $(BINARY) ./cmd/unflutter

test:
	go test ./...

fuzz:
	go test -fuzz=FuzzELFOpen -fuzztime=30s ./internal/elfx/
	go test -fuzz=FuzzExtract -fuzztime=30s ./internal/snapshot/

boot:
	@echo "CLAUDE=$$(shasum -a 256 CLAUDE.md | cut -c1-8)"
	@test -f br/BR-C.md && echo "BR-C=$$(shasum -a 256 br/BR-C.md | cut -c1-8)" || echo "BR-C=NA"
	@test -f br/BR-L.md && echo "BR-L=$$(shasum -a 256 br/BR-L.md | cut -c1-8)" || echo "BR-L=NA"

scan: build
	./$(BINARY) scan --libapp $(SAMPLE)

scan-json: build
	./$(BINARY) scan --libapp $(SAMPLE) --json

disasm: build
	./$(BINARY) disasm --libapp $(SAMPLE) --out $(OUT_DIR)

render: build
	./$(BINARY) render --in $(OUT_DIR) --no-dot
	@echo "render output: $(OUT_DIR)/render/"

render-svg: build
	./$(BINARY) render --in $(OUT_DIR) --max-nodes 100
	@echo "render output: $(OUT_DIR)/render/"

report: disasm render
	@echo "report complete: $(OUT_DIR)/"

flutter-meta: build
	./$(BINARY) flutter-meta --in $(OUT_DIR)

SCRIPT_DIR ?= $(HOME)/.unflutter/ghidra_scripts

ghidra: flutter-meta
	mkdir -p "$(GHIDRA_PROJECTS)"
	"$(GHIDRA_HOME)/support/analyzeHeadless" \
		"$(GHIDRA_PROJECTS)" unflutter_$(SAMPLE_NAME) \
		-import $(SAMPLE) -overwrite \
		-scriptPath "$(SCRIPT_DIR)" \
		-preScript unflutter_prescript.py \
		-postScript unflutter_apply.py "$(CURDIR)/$(OUT_DIR)/flutter_meta.json" "$(CURDIR)/$(OUT_DIR)/decompiled" \
		2>&1 | tee $(OUT_DIR)/ghidra_apply.log

inventory: build
	mkdir -p out
	./$(BINARY) inventory --dir samples/flutter --out out/flutter_inventory.jsonl

parity: build
	mkdir -p out/parity
	./$(BINARY) parity --samples scratch/samples --out out/parity

install: build
	install -d ~/.unflutter/ghidra_scripts
	install -d ~/.unflutter/ida_scripts
	install -m 755 $(BINARY) /usr/local/bin/$(BINARY)
	install -m 644 ghidra_scripts/*.py ~/.unflutter/ghidra_scripts/
	install -m 644 ida_scripts/*.py ~/.unflutter/ida_scripts/
	@echo "installed: /usr/local/bin/$(BINARY)"
	@echo "installed: ~/.unflutter/ghidra_scripts/"
	@ls ~/.unflutter/ghidra_scripts/
	@echo "installed: ~/.unflutter/ida_scripts/"
	@ls ~/.unflutter/ida_scripts/

clean:
	rm -f $(BINARY)
	go clean ./...

skills:
	@echo "Available skills:"
	@ls -1 .claude/skills/ 2>/dev/null | while read d; do echo "  /$$d"; done || echo "  (none)"

```

`README.md`:

```md
# unflutter

Static analyzer for Flutter/Dart AOT snapshots. Recovers function names, class hierarchies, call graphs, and behavioral signals from `libapp.so` — without embedding or executing the Dart VM.

## Why Not Blutter

[Blutter](https://github.com/aspect-sec/blutter) solves Flutter reverse engineering by embedding the Dart VM itself. It calls `Dart_Initialize`, creates an isolate group from the snapshot, and walks the deserialized heap with internal VM APIs. No Dart code from the snapshot is executed — the VM is used purely for introspection. But this still means Blutter must compile a matching Dart SDK for every target version and link against VM internals.

unflutter takes a different path. No VM. No SDK compilation. The snapshot is a byte stream with a known grammar. We parse it directly.

The tradeoff: Blutter gets perfect fidelity because it deserializes through the VM's own code paths. unflutter gets portability, speed, and the ability to analyze snapshots from any Dart version without building anything version-specific. The cost is that every format change across Dart versions must be handled explicitly in our parser — there is no runtime to fall back on.

## Design

Constraint elimination. We treat the snapshot as a deterministic binary grammar.

```
Omega = all possible interpretations of the byte stream

C = {
  ELF invariants,
  snapshot magic (0xf5f5dcdc),
  version hash (32-byte ASCII),
  CID table (class ID -> cluster handler),
  cluster grammar (alloc counts, fill encoding),
  instruction layout (stubs + code regions)
}

R = Omega reduced by C
```

Each constraint narrows the space. ELF validation eliminates non-ARM64 binaries. The snapshot magic eliminates non-Dart data. The version hash selects exactly one CID table and tag encoding. Cluster alloc counts fix the object population. Fill parsing recovers field values within that fixed population. What survives all constraints is the analysis result.

```
if |R| == 0  → HALT: overconstrained (bug in our model)
if |R| > 1   → HALT: underdetermined (missing constraint)
if |R| == 1  → COMMIT: the answer
```

No heuristics. No runtime fallback. No inference outside constraints.

## How It Works

### Snapshot reconstruction

Dart AOT snapshot = two-phase serialization: **alloc** then **fill**.

**Alloc** walks clusters in CID order. Each cluster declares how many objects of that class exist. This assigns sequential reference IDs to every object. No data is read yet — just counts.

**Fill** walks the same clusters again. This time it reads the actual field values: string bytes, reference IDs pointing to other objects, integer scalars. The fill encoding varies by object type and Dart version.

We replay both phases from raw bytes. The alloc phase gives us the object census. The fill phase gives us names, strings, and cross-references. Combined with the instructions table (which maps code objects to their machine code offsets), we recover the full function-name-to-address mapping that Blutter gets from the VM API.

### Code recovery

The isolate instructions image contains two regions:

**Stubs** (indices 0 through `FirstEntryWithCode-1`): runtime trampolines — type-check handlers, allocation stubs, dispatch helpers — that Dart AOT places before user code.

**Code** (indices `FirstEntryWithCode` onward): user functions and framework code. Each Code object maps to a PC offset via the instructions table.

We resolve both regions, producing a complete function map that covers the entire executable range.

### ARM64 disassembly and call edges

Each function's code bytes are decoded instruction-by-instruction using `arm64asm.Decode`. Branch detection handles B, B.cond, CBZ, CBNZ, TBZ, TBNZ, RET — all from raw 32-bit encodings.

**CFG construction** follows a 3-phase algorithm:
1. Collect block leaders: instruction 0, branch targets, instructions after terminators
2. Sort and partition into basic blocks
3. Walk blocks, compute successor edges from terminal instructions

**Call edge extraction** distinguishes two kinds:

- **BL (direct call)**: decode target address from imm26 field, resolve to function name via symbol map
- **BLR (indirect call)**: resolve target register provenance via `RegTracker` (sliding window W=8)

The register tracker traces how BLR target registers get their values:

| Provenance | Pattern | Description |
|------------|---------|-------------|
| PP (object pool) | `LDR Xt, [X27, #imm]` | X27 is the pool pointer. Pool index = byte_offset / 8 |
| THR (thread) | `LDR Xt, [X26, #imm]` | X26 is the thread pointer. Resolved via version-specific offset maps |
| Peephole PP | `ADD Xd, X27, #hi; LDR Xt, [Xd, #lo]` | Two-instruction PP for large pool indices |
| Dispatch table | `LDR Xn, [X21, Xm, LSL #3]` | X21 is the dispatch table register |

Each BLR gets annotated with its provenance (e.g., `PP[42] Widget.build`, `THR.AllocateArray_ep`, `dispatch_table`).

### Graph construction

Call edges and CFGs are converted to [lattice](https://github.com/zboralski/lattice) types — an architecture-neutral graph IR shared with SpiderMonkey-dumper (for JS bytecode analysis). The lattice library provides DOT rendering.

### Decompilation (Ghidra + IDA)

Both decompilers share a common metadata pipeline. `flutter-meta` generates `flutter_meta.json` with function names, class struct layouts, THR fields, string references, and pointer size metadata. Each decompiler's script consumes this file.

**Ghidra** (`unflutter decompile`) runs a headless pipeline:

1. Pre-script registers a `__dartcall` calling convention via `SpecExtension` (marks X15/X26-X28 as unaffected, kills scratch registers)
2. Post-script applies all metadata:
   - Disassembles at all known function addresses
   - Creates/renames functions
   - Creates Dart class struct types with correct field sizes (4-byte for compressed pointers, 8-byte otherwise)
   - Creates a `DartThread` struct (200 fields) for THR (X26) accesses
   - Applies typed function signatures (`this` pointer, parameter count, return type)
   - Sets EOL comments for THR fields, PP pool references, and string literals
   - **Register retyping**: renames decompiler variables for Dart-specific registers and types X26 as `DartThread*`, enabling struct field resolution:

| Register | Variable | Purpose |
| -------- | ------------------- | ----------------------------------------------- |
| X15      | `SHADOW_SP`         | Dart shadow call stack                          |
| X21      | `DT`                | Dispatch table pointer                          |
| X22      | `DART_NULL`         | Dart null object                                |
| X26      | `THR` (DartThread*) | Thread pointer — field accesses resolve to names |
| X27      | `PP`                | Object pool pointer                             |
| X28      | `HEAP_BASE`         | Compressed pointer base                         |
| X29      | `FP`                | Frame pointer                                   |
| X30      | `LR`                | Link register                                   |

**IDA** (`unflutter ida`) runs via idalib (headless):

1. Generates C header with all struct types, parsed via `idc_parse_types()` in one shot
2. Creates functions with Dart checked/unchecked entry point splitting (splits IDA-merged functions at metadata addresses)
3. Applies function signatures via `apply_type()` (IL2CppDumper pattern)
4. Sets repeatable comments (visible in Hex-Rays decompiler)
5. Hex-Rays register retyping (same register table as Ghidra)

**Ghidra vs IDA output quality:**

Ghidra wins on readability: struct field resolution (`THR->stack_limit` vs `THR + 72`), indexed access (`SHADOW_SP[-2]` vs `*(_QWORD*)(SHADOW_SP - 16)`), and no `_QWORD`/`_DWORD` casts.

IDA wins on type cleanliness: zero `undefined` types, zero `unaff_` register names, zero warnings. IDA uses `__int64` and `_QWORD` casts which are verbose but type-correct.

The THR struct field resolution gap is a Hex-Rays microcode limitation — `set_lvar_type()` doesn't restructure the decompiler's AST to use struct member syntax.

### Version handling

| Dart | Tag Style | Pointers | Key change |
|------|-----------|----------|------------|
| 2.10.0 | CID-Int32 | Uncompressed | 4 header fields, pre-canonical-split |
| 2.13.0 | CID-Int32 | Uncompressed | 5 header fields, split canonical |
| 2.14.0 | CID-Shift1 | Uncompressed | CID shifted into uint64 tag |
| 2.15.0 | CID-Shift1 | Uncompressed | NativePointer CID inserted |
| 2.16.0 | CID-Shift1 | Uncompressed | ConstMap/ConstSet added |
| 2.17.6 | CID-Shift1 | Uncompressed | Last unsigned-ref version |
| 2.18.0 | CID-Shift1 | Compressed | Signed refs, compressed pointers |
| 2.19.0 | CID-Shift1 | Compressed | 64-byte alignment |
| 3.0.5-3.3.0 | CID-Shift1 | Compressed | Progressive CID table changes |
| 3.4.3-3.10.7 | ObjectHeader | Compressed | New tag encoding, record types |

No version-conditional architecture. The version hash selects a constraint set. Same pipeline runs.

## Build and Install

Requires Go 1.24+. One external dependency: `golang.org/x/arch` (ARM64 instruction decoding).

```bash
make build          # build ./unflutter binary
make install        # install binary to /usr/local/bin, scripts to ~/.unflutter/
make test           # run tests
```

Ghidra integration requires Ghidra 11.x with Jython support. Auto-detected from `GHIDRA_HOME`, `PATH`, or common brew locations.

## Usage

### Full pipeline (default)

```bash
unflutter libapp.so
```

Runs ELF parse, disassembly, signal analysis, and metadata generation in one shot:

```text
elf Dart SDK 3.10.7

code 284352 bytes at VA 0x569a8
  instructions: 1465 entries (0 stubs + 1465 code)
  ranges: 1465 (0 stubs + 1465 code)
  classes: 402 layouts

disasm 1465 functions, pool 1511 entries (1318 resolved)
  functions: 1465 -> samples/evil-patched.unflutter/asm
  call edges: 5937 (822 BLR: 757 annotated, 65 unannotated)
  string refs: 620
  BLR annotation: 92.1%

signal 71 signal + 1076 context, 4178 edges
  net: 40
  url: 4
  base64: 1
  cloaking: 1
  asm snippets: 1142
  -> signal_graph.json (900218 bytes)
  -> signal.html (456296 bytes)
  -> signal.dot (5809 bytes)
  -> signal_cfg.dot (51 functions, 50855 bytes)
  -> signal.svg (18136 bytes)
  -> signal_cfg.svg (145979 bytes)

meta 1465 functions
  focus: 71 signal functions (use --all for everything)
  dart: 3.10.7  ptr_size: 4  thr_fields: 272
  classes: 402 layouts
  comments: 1363 from asm files
  string refs: +461 comments
  -> flutter_meta.json (577230 bytes)

summary
  output:     samples/evil-patched.unflutter
  dart:       3.10.7
  functions:  1465
  classes:    402
  signal:     71

next
  open samples/evil-patched.unflutter/signal.html
  unflutter ghidra libapp.so --from samples/evil-patched.unflutter
  unflutter ida libapp.so --from samples/evil-patched.unflutter
```

Use `--quiet` / `-q` to suppress verbose output. Use `--out` to set the output directory (default: `<basename>.unflutter/`).

### Quick scan

```bash
unflutter scan libapp.so           # print snapshot info
```

### Signal only (skip metadata)

The default pipeline already includes signal analysis. Use `unflutter signal` to run the same pipeline but skip the metadata generation stage:

```bash
unflutter signal libapp.so                    # default pipeline without meta
unflutter signal libapp.so -k 3               # custom context depth (default: 2)
unflutter signal libapp.so --from out/target   # rerun signal from existing disasm
```

### Ghidra decompilation

```bash
unflutter ghidra libapp.so                    # full pipeline + Ghidra headless
unflutter ghidra libapp.so --from out/target   # reuse existing disasm output
unflutter ghidra libapp.so --all               # decompile ALL functions
```

### IDA decompilation

```bash
unflutter ida libapp.so                       # full pipeline + IDA idalib
unflutter ida libapp.so --from out/target      # reuse existing disasm output
unflutter ida libapp.so --all                  # decompile ALL functions
```

### Metadata only

```bash
unflutter meta libapp.so                      # full pipeline, produce flutter_meta.json
unflutter meta --from out/target               # regenerate from existing disasm
```

### Output artifacts

| File | Description |
|------|-------------|
| `functions.jsonl` | Function records: name, address, size, owner, param count |
| `call_edges.jsonl` | Call edges: BL/BLR with resolved targets and provenance |
| `classes.jsonl` | Class layouts: fields, offsets, instance sizes |
| `string_refs.jsonl` | String references from PP loads |
| `dart_meta.json` | Snapshot metadata: Dart version, pointer size, THR fields |
| `flutter_meta.json` | Unified metadata for Ghidra/IDA: functions, classes, THR fields, comments |
| `asm/*.txt` | Annotated ARM64 disassembly per function |
| `cfg/*.dot` | Per-function control flow graphs (with `--graph`) |
| `callgraph.dot` | Full call graph (with `--graph`) |
| `signal.html` | Behavioral signal report |
| `decompiled/*.c` | Ghidra decompiled C output |

## Architecture

```
internal/
  elfx/       ELF validation, ARM64 symbol extraction
  snapshot/   Region extraction, header parsing, version profiles
  dartfmt/    Dart VM stream encoding (variable-length integers)
  cluster/    Two-phase snapshot deserialization (alloc + fill)
  disasm/     ARM64 decode, CFG, call edge provenance, register tracking
  callgraph/  Lattice graph builders (call graph + CFG)
  signal/     Behavioral string classification
  render/     HTML/DOT visualization
  output/     JSONL serialization
```

### Pipeline

```
libapp.so
  → ELF parse (elfx)
  → snapshot region extraction (snapshot)
  → header + version detection (snapshot)
  → cluster alloc scan (cluster)
  → cluster fill parse (cluster)
  → instructions table: stubs + code (cluster)
  → ARM64 disassembly + CFG (disasm)
  → call edge extraction with register tracking (disasm)
  → lattice graph construction (callgraph)
  → signal classification (signal)
  → Ghidra metadata + decompilation (ghidra-meta / decompile)
  → JSON / DOT / HTML artifacts
```

Each stage is a pure function from bytes to structured data. No mutable global state. No VM runtime. Same input, same output.

## Known Limitations

- **AOT only.** No JIT mode support.
- **ARM64 only.** No x86 or RISC-V.
- **No source reconstruction.** Output is function names, call edges, structs, strings — not Dart source.
- **BLR tracking window.** Register provenance uses a sliding window (W=8). Complex register chains outside the window are unresolved.
- **Dart 2.12.x not validated.** No samples available.
- **Every format change must be modeled.** There is no runtime to handle it automatically.

```

`cmd/unflutter/artifacts.go`:

```go
package main

import (
	"fmt"
	"os"
	"path/filepath"
)

// copyGhidraArtifacts copies Ghidra scripts into outDir/ghidra/.
func copyGhidraArtifacts(outDir string) error {
	scriptDir, err := findScriptPath()
	if err != nil {
		return err
	}

	ghidraDir := filepath.Join(outDir, "ghidra")
	if err := os.MkdirAll(ghidraDir, 0755); err != nil {
		return fmt.Errorf("mkdir ghidra artifacts: %w", err)
	}

	scripts := []string{"unflutter_apply.py", "unflutter_prescript.py"}
	for _, name := range scripts {
		src := filepath.Join(scriptDir, name)
		dst := filepath.Join(ghidraDir, name)
		data, err := os.ReadFile(src)
		if err != nil {
			return fmt.Errorf("read %s: %w", name, err)
		}
		if err := os.WriteFile(dst, data, 0644); err != nil {
			return fmt.Errorf("write %s: %w", name, err)
		}
	}

	fmt.Fprintf(os.Stderr, "copied Ghidra scripts → %s\n", ghidraDir)
	return nil
}

// copyIDAArtifacts copies IDA scripts into outDir/ida/.
func copyIDAArtifacts(outDir string) error {
	scriptPath, err := findIDAScript()
	if err != nil {
		return err
	}

	idaDir := filepath.Join(outDir, "ida")
	if err := os.MkdirAll(idaDir, 0755); err != nil {
		return fmt.Errorf("mkdir ida artifacts: %w", err)
	}

	dst := filepath.Join(idaDir, "unflutter_apply.py")
	data, err := os.ReadFile(scriptPath)
	if err != nil {
		return fmt.Errorf("read ida script: %w", err)
	}
	if err := os.WriteFile(dst, data, 0644); err != nil {
		return fmt.Errorf("write ida script: %w", err)
	}

	fmt.Fprintf(os.Stderr, "copied IDA script → %s\n", idaDir)
	return nil
}

```

`cmd/unflutter/clusters.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"

	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

func cmdClusters(args []string) error {
	fs := flag.NewFlagSet("clusters", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	which := fs.String("which", "both", "which snapshot: vm, isolate, or both")
	debugFill := fs.Bool("debug-fill", false, "print fill position per cluster")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *libapp == "" {
		return fmt.Errorf("--lib is required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}

	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	if info.Version != nil && info.Version.DartVersion != "" {
		fmt.Printf("Dart SDK version: %s (header fields: %d, tag style: %d)\n",
			info.Version.DartVersion, info.Version.HeaderFields, info.Version.Tags)
	}
	if info.Version != nil && !info.Version.Supported {
		return fmt.Errorf("HALT_UNSUPPORTED_VERSION: Dart %s (hash %s)", info.Version.DartVersion, info.VmHeader.SnapshotHash)
	}

	type target struct {
		name string
		data []byte
	}
	var targets []target
	switch *which {
	case "vm":
		targets = []target{{"VM", info.VmData.Data}}
	case "isolate":
		targets = []target{{"Isolate", info.IsolateData.Data}}
	default:
		targets = []target{
			{"VM", info.VmData.Data},
			{"Isolate", info.IsolateData.Data},
		}
	}

	for _, t := range targets {
		if len(t.data) < 64 {
			fmt.Fprintf(os.Stderr, "%s: data too short (%d bytes)\n", t.name, len(t.data))
			continue
		}

		clusterStart, err := cluster.FindClusterDataStart(t.data)
		if err != nil {
			fmt.Fprintf(os.Stderr, "%s: %v\n", t.name, err)
			continue
		}

		isVM := t.name == "VM"
		result, err := cluster.ScanClusters(t.data, clusterStart, info.Version, isVM, opts)
		if err != nil {
			fmt.Fprintf(os.Stderr, "%s: scan error: %v\n", t.name, err)
			continue
		}

		fmt.Printf("\n%s Snapshot Clusters:\n", t.name)
		fmt.Printf("  ClusterDataStart=0x%x\n", clusterStart)
		fmt.Printf("  NumBaseObjects=%d  NumObjects=%d  NumClusters=%d\n",
			result.Header.NumBaseObjects, result.Header.NumObjects, result.Header.NumClusters)
		fmt.Printf("  InstructionsTableLen=%d  InstructionTableDataOffset=%d\n",
			result.Header.InstructionsTableLen, result.Header.InstructionTableDataOffset)

		fmt.Printf("  Clusters (%d decoded):\n", len(result.Clusters))
		var ct *snapshot.CIDTable
		if info.Version != nil {
			ct = info.Version.CIDs
		}
		for _, c := range result.Clusters {
			var name string
			if ct != nil {
				name = cluster.CidNameV(c.CID, ct)
			} else {
				name = cluster.CidName(c.CID)
			}
			if name == "" {
				name = fmt.Sprintf("CID_%d", c.CID)
			}
			flags := ""
			if c.IsCanonical {
				flags += " canonical"
			}
			if c.IsImmutable {
				flags += " immutable"
			}
			fmt.Printf("    [%d] CID=%-3d %-24s count=%-5d  off=0x%x..0x%x%s\n",
				c.Index, c.CID, name, c.Count, c.StartOffset, c.EndOffset, flags)
		}

		if len(result.Diags) > 0 {
			fmt.Printf("  Diagnostics (%d):\n", len(result.Diags))
			for _, d := range result.Diags {
				fmt.Printf("    %s\n", d)
			}
		}

		if *debugFill {
			fmt.Printf("\n  Fill Positions (%s, fill_start=0x%x):\n", t.name, result.FillStart)
			err := cluster.DebugFillPositions(t.data, result, info.Version, isVM, os.Stdout)
			if err != nil {
				fmt.Fprintf(os.Stderr, "  fill debug error: %v\n", err)
			}
		}
	}

	return nil
}

```

`cmd/unflutter/cmd_debug.go`:

```go
package main

import (
	"fmt"
	"os"
)

// cmdDebug handles "unflutter _debug <cmd>" — internal/debug commands.
func cmdDebug(args []string) error {
	if len(args) < 1 {
		fmt.Fprintf(os.Stderr, `unflutter _debug — internal commands

Usage:
  unflutter _debug <command> [args]

Commands:
  scan            Scan ELF and print snapshot info
  dump            Disassemble and dump symbols
  objects         Dump object pool
  strings         Extract strings from snapshot
  graph           Extract named object graph
  clusters        Parse clusters
  render          Render callgraph and HTML from JSONL
  thr-audit       Audit THR-relative memory accesses
  thr-cluster     Cluster unresolved THR offsets
  thr-classify    Classify unresolved THR offsets
  dart2-buckets   Dart 2.x bucket analysis
  find-libapp-batch   Batch find-libapp + report
`)
		return nil
	}

	cmd := args[0]
	subArgs := args[1:]

	switch cmd {
	case "scan":
		return cmdScan(subArgs)
	case "dump":
		return cmdDump(subArgs)
	case "objects":
		return cmdObjects(subArgs)
	case "strings":
		return cmdStrings(subArgs)
	case "graph":
		return cmdGraph(subArgs)
	case "clusters":
		return cmdClusters(subArgs)
	case "render":
		return cmdRender(subArgs)
	case "thr-audit":
		return cmdTHRAudit(subArgs)
	case "thr-cluster":
		return cmdTHRCluster(subArgs)
	case "thr-classify":
		return cmdTHRClassify(subArgs)
	case "dart2-buckets":
		return cmdDart2Buckets(subArgs)
	case "find-libapp-batch":
		return cmdFindLibappBatch(subArgs)
	default:
		return fmt.Errorf("unknown debug command: %s", cmd)
	}
}

```

`cmd/unflutter/cmd_doctor.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

// cmdDoctor handles "unflutter doctor <libapp.so>" — diagnostic scan.
func cmdDoctor(args []string) error {
	args = reorderPositionalArg(args)
	fs := flag.NewFlagSet("doctor", flag.ExitOnError)
	maxSteps := fs.Int("max-steps", 0, "global loop cap")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if fs.NArg() < 1 {
		return fmt.Errorf("usage: unflutter doctor <libapp.so>")
	}

	libPath := fs.Arg(0)
	if resolvePositionalLib(libPath) == "" {
		return fmt.Errorf("file not found: %s", libPath)
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}

	ef, err := elfx.Open(libPath)
	if err != nil {
		fmt.Fprintf(os.Stdout, "ELF:        FAIL (%v)\n", err)
		return fmt.Errorf("elf: %w", err)
	}
	defer ef.Close()
	fmt.Fprintf(os.Stdout, "ELF:        OK (%d bytes)\n", ef.FileSize())

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		fmt.Fprintf(os.Stdout, "Snapshot:    FAIL (%v)\n", err)
		return fmt.Errorf("snapshot: %w", err)
	}
	fmt.Fprintf(os.Stdout, "Snapshot:    OK\n")

	if info.Version != nil {
		fmt.Fprintf(os.Stdout, "Dart:        %s\n", info.Version.DartVersion)
		if info.Version.CompressedPointers {
			fmt.Fprintf(os.Stdout, "Pointers:    compressed (4 bytes)\n")
		} else {
			fmt.Fprintf(os.Stdout, "Pointers:    uncompressed (8 bytes)\n")
		}
		if !info.Version.Supported {
			fmt.Fprintf(os.Stdout, "Support:     UNSUPPORTED\n")
			return fmt.Errorf("unsupported dart version: %s", info.Version.DartVersion)
		}
		fmt.Fprintf(os.Stdout, "Support:     OK\n")
	}

	if info.VmHeader != nil {
		fmt.Fprintf(os.Stdout, "Hash:        %s\n", info.VmHeader.SnapshotHash)
	}

	if len(info.Diags) > 0 {
		fmt.Fprintf(os.Stdout, "Diagnostics: %d\n", len(info.Diags))
		for _, d := range info.Diags {
			fmt.Fprintf(os.Stdout, "  %s\n", d)
		}
	}

	return nil
}

```

`cmd/unflutter/cmd_ghidra.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"

	"unflutter/internal/pipeline"
)

// cmdGhidra handles "unflutter ghidra <libapp.so>" — full pipeline + Ghidra decompilation.
func cmdGhidra(args []string) error {
	args = reorderPositionalArg(args)
	fs := flag.NewFlagSet("ghidra", flag.ExitOnError)
	outDir := fs.String("out", "", "output directory (default: <basename>.unflutter/)")
	ghidraHome := fs.String("ghidra-home", "", "Ghidra installation directory")
	all := fs.Bool("all", false, "decompile ALL functions")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	var quiet bool
	fs.BoolVar(&quiet, "quiet", false, "suppress verbose output")
	fs.BoolVar(&quiet, "q", false, "suppress verbose output")
	var _verbose bool // accepted for backwards compat, now default
	fs.BoolVar(&_verbose, "verbose", false, "")
	fs.BoolVar(&_verbose, "v", false, "")
	projectDir := fs.String("projects", "scratch/ghidra-projects", "Ghidra project directory")
	from := fs.String("from", "", "reuse existing disasm output directory")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if fs.NArg() < 1 {
		return fmt.Errorf("usage: unflutter ghidra <libapp.so> [flags]")
	}

	libPath := fs.Arg(0)
	absLibPath := resolvePositionalLib(libPath)
	if absLibPath == "" {
		return fmt.Errorf("file not found: %s", libPath)
	}

	if *outDir == "" {
		*outDir = defaultOutDir(libPath)
	}

	// Step 1: Run pipeline (disasm + signal + meta).
	var pipeResult *pipeline.Result
	if *from != "" {
		// Reuse existing output: just regenerate signal + meta.
		_, err := pipeline.RunSignalStage(*from, 2, false, quiet, os.Stderr)
		if err != nil {
			return fmt.Errorf("signal: %w", err)
		}
		metaPath, err := pipeline.RunMetaStage(*from, "", *all, quiet, os.Stderr)
		if err != nil {
			return fmt.Errorf("meta: %w", err)
		}
		pipeResult = &pipeline.Result{OutDir: *from, MetaPath: metaPath}
	} else {
		var err error
		pipeResult, err = pipeline.Run(pipeline.Opts{
			LibPath:   libPath,
			OutDir:    *outDir,
			MaxSteps:  *maxSteps,
			Signal:    true,
			Meta:      true,
			DecompAll: *all,
			Quiet:     quiet,
		})
		if err != nil {
			return err
		}
	}

	metaPath := pipeResult.MetaPath
	if metaPath == "" {
		metaPath = filepath.Join(pipeResult.OutDir, "flutter_meta.json")
	}

	// Step 2: Copy scripts into artifact directory.
	if copyErr := copyGhidraArtifacts(pipeResult.OutDir); copyErr != nil {
		fmt.Fprintf(os.Stderr, "warning: could not copy Ghidra scripts: %v\n", copyErr)
	}

	// Step 3: Find Ghidra.
	ghLauncher, ghHome, err := findGhidra(*ghidraHome)
	if err != nil {
		return err
	}
	fmt.Fprintf(os.Stderr, "ghidra: %s\n", ghHome)

	// Step 4: Run headless analysis.
	decompDir := filepath.Join(pipeResult.OutDir, "decompiled")
	absMetaPath, _ := filepath.Abs(metaPath)
	absDecompDir, _ := filepath.Abs(decompDir)

	projectName := "unflutter_" + filepath.Base(filepath.Dir(pipeResult.OutDir))
	if projectName == "unflutter_." {
		projectName = "unflutter_decompile"
	}

	absProjDir, _ := filepath.Abs(*projectDir)
	if err := os.MkdirAll(absProjDir, 0o755); err != nil {
		return fmt.Errorf("create project dir: %w", err)
	}

	scriptPath, err := findScriptPath()
	if err != nil {
		return err
	}

	if *all {
		fmt.Fprintf(os.Stderr, "running Ghidra headless analysis (decompiling ALL functions)...\n")
	} else {
		fmt.Fprintf(os.Stderr, "running Ghidra headless analysis (signal functions only, use --all for everything)...\n")
	}
	fmt.Fprintf(os.Stderr, "  project: %s/%s\n", absProjDir, projectName)
	fmt.Fprintf(os.Stderr, "  import: %s\n", absLibPath)
	fmt.Fprintf(os.Stderr, "  decompile output: %s\n", absDecompDir)

	ghidraArgs := []string{
		absProjDir,
		projectName,
		"-import", absLibPath,
		"-overwrite",
		"-processor", "AARCH64:LE:64:v8A",
		"-scriptPath", scriptPath,
		"-preScript", "unflutter_prescript.py",
		"-postScript", "unflutter_apply.py", absMetaPath, absDecompDir,
	}

	env := os.Environ()
	if os.Getenv("JAVA_HOME") == "" {
		javaHome := findJavaHome(ghHome)
		if javaHome != "" {
			env = append(env, "JAVA_HOME="+javaHome)
		}
	}

	cmd := exec.Command(ghLauncher.cmd, append(ghLauncher.prefix, ghidraArgs...)...)
	cmd.Env = env
	cmd.Stdout = os.Stderr
	cmd.Stderr = os.Stderr

	if err := cmd.Run(); err != nil {
		return fmt.Errorf("analyzeHeadless failed: %w", err)
	}

	cCount := countDecompiledFiles(absDecompDir)
	fmt.Fprintf(os.Stderr, "decompiled %d functions → %s\n", cCount, absDecompDir)

	return nil
}

```

`cmd/unflutter/cmd_ida.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"

	"unflutter/internal/pipeline"
)

// cmdIDA handles "unflutter ida <libapp.so>" — full pipeline + IDA decompilation.
func cmdIDA(args []string) error {
	args = reorderPositionalArg(args)
	fs := flag.NewFlagSet("ida", flag.ExitOnError)
	outDir := fs.String("out", "", "output directory (default: <basename>.unflutter/)")
	all := fs.Bool("all", false, "decompile ALL functions")
	pythonBin := fs.String("python", "", "python3 binary (default: auto-detect)")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	var quiet bool
	fs.BoolVar(&quiet, "quiet", false, "suppress verbose output")
	fs.BoolVar(&quiet, "q", false, "suppress verbose output")
	var _verbose bool // accepted for backwards compat, now default
	fs.BoolVar(&_verbose, "verbose", false, "")
	fs.BoolVar(&_verbose, "v", false, "")
	from := fs.String("from", "", "reuse existing disasm output directory")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if fs.NArg() < 1 {
		return fmt.Errorf("usage: unflutter ida <libapp.so> [flags]")
	}

	libPath := fs.Arg(0)
	absLibPath := resolvePositionalLib(libPath)
	if absLibPath == "" {
		return fmt.Errorf("file not found: %s", libPath)
	}

	if *outDir == "" {
		*outDir = defaultOutDir(libPath)
	}

	// Step 1: Run pipeline (disasm + signal + meta).
	var pipeResult *pipeline.Result
	if *from != "" {
		_, err := pipeline.RunSignalStage(*from, 2, false, quiet, os.Stderr)
		if err != nil {
			return fmt.Errorf("signal: %w", err)
		}
		metaPath, err := pipeline.RunMetaStage(*from, "", *all, quiet, os.Stderr)
		if err != nil {
			return fmt.Errorf("meta: %w", err)
		}
		pipeResult = &pipeline.Result{OutDir: *from, MetaPath: metaPath}
	} else {
		var err error
		pipeResult, err = pipeline.Run(pipeline.Opts{
			LibPath:   libPath,
			OutDir:    *outDir,
			MaxSteps:  *maxSteps,
			Signal:    true,
			Meta:      true,
			DecompAll: *all,
			Quiet:     quiet,
		})
		if err != nil {
			return err
		}
	}

	metaPath := pipeResult.MetaPath
	if metaPath == "" {
		metaPath = filepath.Join(pipeResult.OutDir, "flutter_meta.json")
	}

	// Step 2: Copy script into artifact directory.
	if copyErr := copyIDAArtifacts(pipeResult.OutDir); copyErr != nil {
		fmt.Fprintf(os.Stderr, "warning: could not copy IDA script: %v\n", copyErr)
	}

	// Step 3: Find python3 with idapro.
	python, err := findPython(*pythonBin)
	if err != nil {
		return err
	}
	fmt.Fprintf(os.Stderr, "python: %s\n", python)

	// Step 4: Find IDA script.
	scriptPath, err := findIDAScript()
	if err != nil {
		return err
	}
	fmt.Fprintf(os.Stderr, "script: %s\n", scriptPath)

	// Step 5: Run idalib.
	decompDir := filepath.Join(pipeResult.OutDir, "decompiled")
	absMetaPath, _ := filepath.Abs(metaPath)
	absDecompDir, _ := filepath.Abs(decompDir)

	if *all {
		fmt.Fprintf(os.Stderr, "running IDA idalib analysis (decompiling ALL functions)...\n")
	} else {
		fmt.Fprintf(os.Stderr, "running IDA idalib analysis (signal functions only, use --all for everything)...\n")
	}
	fmt.Fprintf(os.Stderr, "  decompile output: %s\n", absDecompDir)

	cmd := exec.Command(python, scriptPath, absLibPath, absMetaPath, absDecompDir)
	cmd.Stdout = os.Stderr
	cmd.Stderr = os.Stderr

	if err := cmd.Run(); err != nil {
		return fmt.Errorf("ida script failed: %w", err)
	}

	cCount := countDecompiledFiles(absDecompDir)
	fmt.Fprintf(os.Stderr, "decompiled %d functions → %s\n", cCount, absDecompDir)

	return nil
}

```

`cmd/unflutter/cmd_meta.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"

	"unflutter/internal/pipeline"
)

// cmdMeta handles "unflutter meta <libapp.so>" — full pipeline producing flutter_meta.json.
func cmdMeta(args []string) error {
	args = reorderPositionalArg(args)
	fs := flag.NewFlagSet("meta", flag.ExitOnError)
	outDir := fs.String("out", "", "output directory (default: <basename>.unflutter/)")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	all := fs.Bool("all", false, "include all functions in focus list")
	var quiet bool
	fs.BoolVar(&quiet, "quiet", false, "suppress verbose output")
	fs.BoolVar(&quiet, "q", false, "suppress verbose output")
	var _verbose bool // accepted for backwards compat, now default
	fs.BoolVar(&_verbose, "verbose", false, "")
	fs.BoolVar(&_verbose, "v", false, "")
	from := fs.String("from", "", "reuse existing disasm output directory")

	if err := fs.Parse(args); err != nil {
		return err
	}

	// If --from is set, skip ELF parse and just regenerate meta.
	if *from != "" {
		if *outDir == "" {
			*outDir = *from
		}
		metaPath, err := pipeline.RunMetaStage(*from, "", *all, quiet, os.Stderr)
		if err != nil {
			return err
		}
		fmt.Fprintf(os.Stderr, "wrote %s\n", metaPath)
		return nil
	}

	if fs.NArg() < 1 {
		return fmt.Errorf("usage: unflutter meta <libapp.so> [flags]")
	}

	libPath := fs.Arg(0)
	if resolvePositionalLib(libPath) == "" {
		return fmt.Errorf("file not found: %s", libPath)
	}

	if *outDir == "" {
		*outDir = defaultOutDir(libPath)
	}

	result, err := pipeline.Run(pipeline.Opts{
		LibPath:   libPath,
		OutDir:    *outDir,
		MaxSteps:  *maxSteps,
		Signal:    true,
		Meta:      true,
		DecompAll: *all,
		Quiet:     quiet,
	})
	if err != nil {
		return err
	}

	fmt.Fprintf(os.Stderr, "wrote %s\n", result.MetaPath)
	return nil
}

```

`cmd/unflutter/cmd_run.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/cli"
	"unflutter/internal/pipeline"
)

// cmdRun handles "unflutter <libapp.so>" — full pipeline.
func cmdRun(args []string) error {
	// Go's flag package stops at the first non-flag arg.
	// If the first arg is a file path (not a flag), move it to the end
	// so flags like --quiet after it are parsed correctly.
	args = reorderPositionalArg(args)

	fs := flag.NewFlagSet("unflutter", flag.ExitOnError)
	outDir := fs.String("out", "", "output directory (default: <basename>.unflutter/)")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	limit := fs.Int("limit", 0, "max functions (0 = all)")
	graph := fs.Bool("graph", false, "build call graph and per-function CFGs")
	strict := fs.Bool("strict", false, "fail on structural errors")
	all := fs.Bool("all", false, "include all functions in focus list")
	var quiet bool
	fs.BoolVar(&quiet, "quiet", false, "suppress verbose output")
	fs.BoolVar(&quiet, "q", false, "suppress verbose output")
	var _verbose bool // accepted for backwards compat, now default
	fs.BoolVar(&_verbose, "verbose", false, "")
	fs.BoolVar(&_verbose, "v", false, "")
	signalK := fs.Int("k", 2, "signal context hops")
	from := fs.String("from", "", "reuse existing disasm output directory")

	if err := fs.Parse(args); err != nil {
		return err
	}

	// --from mode: reuse existing output, just rerun signal+meta.
	if *from != "" {
		if *outDir == "" {
			*outDir = *from
		}
		result, err := pipeline.Run(pipeline.Opts{
			FromDir:   *from,
			OutDir:    *outDir,
			Signal:    true,
			SignalK:   *signalK,
			Meta:      true,
			DecompAll: *all,
			Quiet:     quiet,
		})
		if err != nil {
			return err
		}
		printSummary(result)
		return nil
	}

	if fs.NArg() < 1 {
		return fmt.Errorf("usage: unflutter <libapp.so> [flags]")
	}

	libPath := fs.Arg(0)
	if resolvePositionalLib(libPath) == "" {
		return fmt.Errorf("file not found: %s", libPath)
	}

	if *outDir == "" {
		*outDir = defaultOutDir(libPath)
	}

	result, err := pipeline.Run(pipeline.Opts{
		LibPath:   libPath,
		OutDir:    *outDir,
		MaxSteps:  *maxSteps,
		Limit:     *limit,
		Graph:     *graph,
		Strict:    *strict,
		Signal:    true,
		SignalK:   *signalK,
		Meta:      true,
		DecompAll: *all,
		Quiet:     quiet,
	})
	if err != nil {
		return err
	}

	printSummary(result)
	return nil
}

func printSummary(result *pipeline.Result) {
	fmt.Fprintf(os.Stderr, "\n%ssummary%s\n", cli.Pink, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %soutput:%s     %s%s%s\n", cli.Muted, cli.Reset, cli.Blue, result.OutDir, cli.Reset)
	if result.DartVersion != "" {
		fmt.Fprintf(os.Stderr, "  %sdart:%s       %s%s%s\n", cli.Muted, cli.Reset, cli.Gold, result.DartVersion, cli.Reset)
	}
	fmt.Fprintf(os.Stderr, "  %sptr_size:%s   %s%d%s\n", cli.Muted, cli.Reset, cli.Gold, result.PointerSize, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %sfunctions:%s %s%d%s\n", cli.Muted, cli.Reset, cli.Gold, result.FuncCount, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %sclasses:%s   %s%d%s\n", cli.Muted, cli.Reset, cli.Gold, result.ClassCount, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %ssignal:%s    %s%d%s\n", cli.Muted, cli.Reset, cli.Gold, result.SignalCount, cli.Reset)
	if result.MetaPath != "" {
		fmt.Fprintf(os.Stderr, "  %smeta:%s      %s%s%s\n", cli.Muted, cli.Reset, cli.Blue, result.MetaPath, cli.Reset)
	}

	// Follow-up commands.
	absOut, _ := filepath.Abs(result.OutDir)
	signalHTML := filepath.Join(absOut, "signal.html")
	fmt.Fprintf(os.Stderr, "\n%snext%s\n", cli.Pink, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %sopen %s%s\n", cli.White, signalHTML, cli.Reset)
	if result.LibPath != "" {
		fmt.Fprintf(os.Stderr, "  %sunflutter ghidra %s --from %s%s\n", cli.White, result.LibPath, absOut, cli.Reset)
		fmt.Fprintf(os.Stderr, "  %sunflutter ida %s --from %s%s\n", cli.White, result.LibPath, absOut, cli.Reset)
	}
}

```

`cmd/unflutter/cmd_signal.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/cli"
	"unflutter/internal/pipeline"
)

// cmdSignalPipeline handles "unflutter signal <libapp.so>" — full pipeline through signal.
func cmdSignalPipeline(args []string) error {
	args = reorderPositionalArg(args)
	fs := flag.NewFlagSet("signal", flag.ExitOnError)
	outDir := fs.String("out", "", "output directory (default: <basename>.unflutter/)")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	k := fs.Int("k", 2, "context hops from signal functions")
	var quiet bool
	fs.BoolVar(&quiet, "quiet", false, "suppress verbose output")
	fs.BoolVar(&quiet, "q", false, "suppress verbose output")
	var _verbose bool // accepted for backwards compat, now default
	fs.BoolVar(&_verbose, "verbose", false, "")
	fs.BoolVar(&_verbose, "v", false, "")
	from := fs.String("from", "", "reuse existing disasm output directory")

	if err := fs.Parse(args); err != nil {
		return err
	}

	// If --from is set, skip ELF parse and just run signal.
	if *from != "" {
		if *outDir == "" {
			*outDir = *from
		}
		sigResult, err := pipeline.RunSignalStage(*from, *k, false, quiet, os.Stderr)
		if err != nil {
			return err
		}
		printSignalSummary(sigResult, *outDir, "")
		return nil
	}

	if fs.NArg() < 1 {
		return fmt.Errorf("usage: unflutter signal <libapp.so> [flags]")
	}

	libPath := fs.Arg(0)
	if resolvePositionalLib(libPath) == "" {
		return fmt.Errorf("file not found: %s", libPath)
	}

	if *outDir == "" {
		*outDir = defaultOutDir(libPath)
	}

	result, err := pipeline.Run(pipeline.Opts{
		LibPath:  libPath,
		OutDir:   *outDir,
		MaxSteps: *maxSteps,
		Signal:   true,
		SignalK:  *k,
		Quiet:    quiet,
	})
	if err != nil {
		return err
	}

	printSignalSummary(&pipeline.SignalResult{SignalCount: result.SignalCount}, result.OutDir, libPath)
	return nil
}

func printSignalSummary(sig *pipeline.SignalResult, outDir, libPath string) {
	absOut, _ := filepath.Abs(outDir)
	signalHTML := filepath.Join(absOut, "signal.html")

	fmt.Fprintf(os.Stderr, "\n%ssignal complete%s  %s%d%s functions\n",
		cli.Pink, cli.Reset, cli.Gold, sig.SignalCount, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %ssignal.html%s     interactive signal graph\n", cli.Blue, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %ssignal.svg%s      signal graph visualization\n", cli.Blue, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %ssignal_cfg.dot%s  connected CFG\n", cli.Blue, cli.Reset)

	fmt.Fprintf(os.Stderr, "\n%snext%s\n", cli.Pink, cli.Reset)
	fmt.Fprintf(os.Stderr, "  %sopen %s%s\n", cli.White, signalHTML, cli.Reset)
	if libPath != "" {
		fmt.Fprintf(os.Stderr, "  %sunflutter ghidra %s --from %s%s\n", cli.White, libPath, absOut, cli.Reset)
		fmt.Fprintf(os.Stderr, "  %sunflutter ida %s --from %s%s\n", cli.White, libPath, absOut, cli.Reset)
	} else {
		fmt.Fprintf(os.Stderr, "  %sunflutter ghidra <libapp.so> --from %s%s\n", cli.White, absOut, cli.Reset)
		fmt.Fprintf(os.Stderr, "  %sunflutter ida <libapp.so> --from %s%s\n", cli.White, absOut, cli.Reset)
	}
}

```

`cmd/unflutter/dart2_buckets.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"
	"sort"
)

type dart2Bucket struct {
	Hash        string `json:"hash"`
	Count       int    `json:"count"`
	DartVersion string `json:"dart_version"`
	Example     string `json:"example"`
	Features    string `json:"features"`
}

func cmdDart2Buckets(args []string) error {
	fs := flag.NewFlagSet("dart2-buckets", flag.ExitOnError)
	inventoryPath := fs.String("inventory", "", "path to flutter_inventory.jsonl")
	outPath := fs.String("out", "", "output JSONL path")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inventoryPath == "" || *outPath == "" {
		return fmt.Errorf("--inventory and --out are required")
	}

	// Read inventory.
	data, err := os.ReadFile(*inventoryPath)
	if err != nil {
		return fmt.Errorf("read inventory: %w", err)
	}

	type invRow struct {
		SampleID     string `json:"sample_id"`
		SnapshotHash string `json:"snapshot_hash"`
		DartVersion  string `json:"dart_version"`
		Features     string `json:"features"`
	}

	// Parse rows, filter for unsupported Dart 2.x.
	buckets := map[string]*dart2Bucket{}
	lines := splitLines(data)
	for _, line := range lines {
		if len(line) == 0 {
			continue
		}
		var row invRow
		if err := json.Unmarshal(line, &row); err != nil {
			continue
		}
		if row.SnapshotHash == "" || row.DartVersion == "" {
			continue
		}
		if row.DartVersion[0] != '2' {
			continue
		}
		b, ok := buckets[row.SnapshotHash]
		if !ok {
			b = &dart2Bucket{
				Hash:        row.SnapshotHash,
				DartVersion: row.DartVersion,
				Example:     row.SampleID,
				Features:    row.Features,
			}
			buckets[row.SnapshotHash] = b
		}
		b.Count++
	}

	// Sort by version then hash.
	sorted := make([]*dart2Bucket, 0, len(buckets))
	for _, b := range buckets {
		sorted = append(sorted, b)
	}
	sort.Slice(sorted, func(i, j int) bool {
		if sorted[i].DartVersion != sorted[j].DartVersion {
			return sorted[i].DartVersion < sorted[j].DartVersion
		}
		return sorted[i].Hash < sorted[j].Hash
	})

	// Write output.
	f, err := os.Create(*outPath)
	if err != nil {
		return fmt.Errorf("create: %w", err)
	}
	defer f.Close()

	enc := json.NewEncoder(f)
	for _, b := range sorted {
		if err := enc.Encode(b); err != nil {
			return fmt.Errorf("encode: %w", err)
		}
	}

	fmt.Fprintf(os.Stderr, "dart2-buckets: %d hashes, %d total samples\n", len(sorted), func() int {
		n := 0
		for _, b := range sorted {
			n += b.Count
		}
		return n
	}())

	return nil
}

// splitLines splits data into non-empty lines.
func splitLines(data []byte) [][]byte {
	var lines [][]byte
	start := 0
	for i := 0; i < len(data); i++ {
		if data[i] == '\n' {
			if i > start {
				lines = append(lines, data[start:i])
			}
			start = i + 1
		}
	}
	if start < len(data) {
		lines = append(lines, data[start:])
	}
	return lines
}

```

`cmd/unflutter/decompile.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
)

// ghidraLauncher holds the command and any prefix args needed to run Ghidra headless.
// For Ghidra <12 (Jython): cmd=analyzeHeadless, prefix=nil.
// For Ghidra 12+ (PyGhidra): cmd=pyghidraRun, prefix=["-H"].
type ghidraLauncher struct {
	cmd    string   // path to the launcher binary
	prefix []string // args inserted before analyzeHeadless args (e.g. ["-H"])
}

func cmdDecompile(args []string) error {
	fs := flag.NewFlagSet("decompile", flag.ExitOnError)
	inDir := fs.String("in", "", "input directory (disasm output)")
	libPath := fs.String("lib", "", "path to libapp.so (default: auto-detect from disasm)")
	projectDir := fs.String("projects", "scratch/ghidra-projects", "Ghidra project directory")
	ghidraHome := fs.String("ghidra-home", "", "Ghidra installation directory (auto-detected if omitted)")
	decompAll := fs.Bool("all", false, "decompile ALL functions (default: signal functions only)")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inDir == "" {
		return fmt.Errorf("--in is required")
	}

	// 1. Find Ghidra.
	ghLauncher, ghHome, err := findGhidra(*ghidraHome)
	if err != nil {
		return err
	}
	fmt.Fprintf(os.Stderr, "ghidra: %s\n", ghHome)

	// 2. Generate flutter_meta.json (always regenerate to pick up --all).
	metaPath := filepath.Join(*inDir, "flutter_meta.json")
	metaArgs := []string{"--in", *inDir, "--out", metaPath}
	if *decompAll {
		metaArgs = append(metaArgs, "--decompile-all")
	}
	fmt.Fprintf(os.Stderr, "generating flutter_meta.json...\n")
	if err := cmdFlutterMeta(metaArgs); err != nil {
		return fmt.Errorf("flutter-meta: %w", err)
	}

	// 3. Find libapp.so if not specified.
	if *libPath == "" {
		// Try common locations relative to --in.
		candidates := []string{
			filepath.Join(filepath.Dir(*inDir), "libapp.so"),
			filepath.Join(*inDir, "..", "libapp.so"),
		}
		for _, c := range candidates {
			if _, err := os.Stat(c); err == nil {
				abs, _ := filepath.Abs(c)
				*libPath = abs
				break
			}
		}
		if *libPath == "" {
			return fmt.Errorf("cannot find libapp.so; specify with --lib")
		}
	}
	fmt.Fprintf(os.Stderr, "libapp: %s\n", *libPath)

	// 4. Prepare output paths.
	decompDir := filepath.Join(*inDir, "decompiled")
	absMetaPath, _ := filepath.Abs(metaPath)
	absDecompDir, _ := filepath.Abs(decompDir)
	absLibPath, _ := filepath.Abs(*libPath)

	// Ghidra project name from the input directory.
	projectName := "unflutter_" + filepath.Base(filepath.Dir(*inDir))
	if projectName == "unflutter_." {
		projectName = "unflutter_decompile"
	}

	// 5. Create project directory.
	absProjDir, _ := filepath.Abs(*projectDir)
	if err := os.MkdirAll(absProjDir, 0o755); err != nil {
		return fmt.Errorf("create project dir: %w", err)
	}

	// 6. Get script path.
	scriptPath, err := findScriptPath()
	if err != nil {
		return err
	}

	// 7. Run analyzeHeadless.
	if *decompAll {
		fmt.Fprintf(os.Stderr, "running Ghidra headless analysis (decompiling ALL functions)...\n")
	} else {
		fmt.Fprintf(os.Stderr, "running Ghidra headless analysis (signal functions only, use --all for everything)...\n")
	}
	fmt.Fprintf(os.Stderr, "  project: %s/%s\n", absProjDir, projectName)
	fmt.Fprintf(os.Stderr, "  import: %s\n", absLibPath)
	fmt.Fprintf(os.Stderr, "  decompile output: %s\n", absDecompDir)

	ghidraArgs := []string{
		absProjDir,
		projectName,
		"-import", absLibPath,
		"-overwrite",
		"-processor", "AARCH64:LE:64:v8A",
		"-scriptPath", scriptPath,
		"-preScript", "unflutter_prescript.py",
		"-postScript", "unflutter_apply.py", absMetaPath, absDecompDir,
	}

	// Set JAVA_HOME if not set (brew Ghidra needs it).
	env := os.Environ()
	if os.Getenv("JAVA_HOME") == "" {
		javaHome := findJavaHome(ghHome)
		if javaHome != "" {
			env = append(env, "JAVA_HOME="+javaHome)
		}
	}

	cmd := exec.Command(ghLauncher.cmd, append(ghLauncher.prefix, ghidraArgs...)...)
	cmd.Env = env
	cmd.Stdout = os.Stderr // Ghidra output goes to stderr.
	cmd.Stderr = os.Stderr

	if err := cmd.Run(); err != nil {
		return fmt.Errorf("analyzeHeadless failed: %w", err)
	}

	// 8. Report results.
	entries, _ := os.ReadDir(absDecompDir)
	cCount := 0
	for _, e := range entries {
		if strings.HasSuffix(e.Name(), ".c") {
			cCount++
		}
	}
	fmt.Fprintf(os.Stderr, "decompiled %d functions → %s\n", cCount, absDecompDir)

	return nil
}

// findGhidra locates the Ghidra installation and returns a launcher.
// Search order:
//  1. --ghidra-home flag
//  2. GHIDRA_HOME or UNFLUTTER_GHIDRA_HOME environment variable
//  3. analyzeHeadless in PATH
//  4. ghidraRun in PATH → derive installation directory
//  5. brew --prefix ghidra
func findGhidra(explicitHome string) (launcher ghidraLauncher, ghidraHome string, err error) {
	// 1. Explicit --ghidra-home.
	if explicitHome != "" {
		if l, home, ok := probeGhidraHome(explicitHome); ok {
			return l, home, nil
		}
		return ghidraLauncher{}, "", fmt.Errorf("analyzeHeadless not found in %s", explicitHome)
	}

	// 2. GHIDRA_HOME or UNFLUTTER_GHIDRA_HOME environment variable.
	for _, env := range []string{"GHIDRA_HOME", "UNFLUTTER_GHIDRA_HOME"} {
		if gh := os.Getenv(env); gh != "" {
			if l, home, ok := probeGhidraHome(gh); ok {
				return l, home, nil
			}
		}
	}

	// 3. analyzeHeadless in PATH.
	if ah, err := exec.LookPath("analyzeHeadless"); err == nil {
		home := filepath.Dir(filepath.Dir(ah))
		return ghidraLauncher{cmd: ah}, home, nil
	}

	// 4. ghidraRun in PATH → parse to find install dir.
	if gr, err := exec.LookPath("ghidraRun"); err == nil {
		home := deriveGhidraHome(gr)
		if home != "" {
			if l, h, ok := probeGhidraHome(home); ok {
				return l, h, nil
			}
		}
	}

	// 5. brew --prefix ghidra.
	if out, err := exec.Command("brew", "--prefix", "ghidra").Output(); err == nil {
		prefix := strings.TrimSpace(string(out))
		if l, home, ok := probeGhidraHome(prefix); ok {
			return l, home, nil
		}
		// Cellar layout: prefix/libexec is the real Ghidra home.
		if l, home, ok := probeGhidraHome(filepath.Join(prefix, "libexec")); ok {
			return l, home, nil
		}
	}

	return ghidraLauncher{}, "", fmt.Errorf(`Ghidra not found

Install Ghidra:
  brew install ghidra

Or set GHIDRA_HOME:
  export GHIDRA_HOME=/path/to/ghidra

Or pass --ghidra-home:
  unflutter decompile --ghidra-home /path/to/ghidra --in <dir>`)
}

// probeGhidraHome checks if a directory contains analyzeHeadless.
// Handles both direct layout (home/support/analyzeHeadless) and
// Caskroom layout (home/ghidra_*/support/analyzeHeadless).
// For Ghidra 12+ with pyghidraRun, returns a launcher that uses it
// so Python scripts work (PyGhidra replaces Jython).
func probeGhidraHome(home string) (launcher ghidraLauncher, ghidraHome string, ok bool) {
	// Direct: home/support/analyzeHeadless
	ah := filepath.Join(home, "support", "analyzeHeadless")
	if _, err := os.Stat(ah); err == nil {
		return makeLauncher(home, ah), home, true
	}
	// Caskroom: home/ghidra_*_PUBLIC/support/analyzeHeadless
	if subs, err := os.ReadDir(home); err == nil {
		for _, sub := range subs {
			if !sub.IsDir() {
				continue
			}
			subHome := filepath.Join(home, sub.Name())
			ah = filepath.Join(subHome, "support", "analyzeHeadless")
			if _, err := os.Stat(ah); err == nil {
				return makeLauncher(subHome, ah), subHome, true
			}
		}
	}
	return ghidraLauncher{}, "", false
}

// makeLauncher returns a ghidraLauncher for the given Ghidra home.
// If pyghidraRun exists (Ghidra 12+), uses it with -H flag so Python scripts work.
// Otherwise falls back to analyzeHeadless directly.
func makeLauncher(home, analyzeHeadless string) ghidraLauncher {
	pyghidra := filepath.Join(home, "support", "pyghidraRun")
	if _, err := os.Stat(pyghidra); err == nil {
		return ghidraLauncher{cmd: pyghidra, prefix: []string{"-H"}}
	}
	return ghidraLauncher{cmd: analyzeHeadless}
}

// deriveGhidraHome reads the ghidraRun shell script to find the real install path.
// Brew's ghidraRun wrapper contains: exec "/opt/homebrew/Cellar/ghidra/X.Y.Z/libexec/ghidraRun"
func deriveGhidraHome(ghidraRunPath string) string {
	data, err := os.ReadFile(ghidraRunPath)
	if err != nil {
		return ""
	}
	// Look for exec "..." pattern pointing to the real ghidraRun.
	lines := strings.Split(string(data), "\n")
	for _, line := range lines {
		line = strings.TrimSpace(line)
		// exec "/opt/homebrew/Cellar/ghidra/12.0.2/libexec/ghidraRun"
		if strings.Contains(line, "exec") && strings.Contains(line, "ghidraRun") {
			// Extract the quoted path.
			idx := strings.Index(line, `"`)
			if idx < 0 {
				continue
			}
			rest := line[idx+1:]
			end := strings.Index(rest, `"`)
			if end < 0 {
				continue
			}
			realPath := rest[:end]
			// ghidraRun is at <home>/ghidraRun, so home = dirname.
			home := filepath.Dir(realPath)
			if _, err := os.Stat(filepath.Join(home, "support")); err == nil {
				return home
			}
		}
	}
	return ""
}

// findScriptPath returns the path to the ghidra_scripts directory.
func findScriptPath() (string, error) {
	// Try relative to the binary.
	exe, _ := os.Executable()
	exeDir := filepath.Dir(exe)

	homeDir, _ := os.UserHomeDir()
	candidates := []string{
		filepath.Join(homeDir, ".unflutter", "ghidra_scripts"),
		filepath.Join(exeDir, "ghidra_scripts"),
		"ghidra_scripts",
		filepath.Join(exeDir, "..", "ghidra_scripts"),
	}

	for _, c := range candidates {
		abs, _ := filepath.Abs(c)
		if _, err := os.Stat(filepath.Join(abs, "unflutter_apply.py")); err == nil {
			return abs, nil
		}
	}

	return "", fmt.Errorf("cannot find ghidra_scripts/unflutter_apply.py; run from the unflutter project root")
}

// findJavaHome tries to locate a suitable JDK for Ghidra.
func findJavaHome(ghidraHome string) string {
	// Check if the ghidraRun wrapper sets JAVA_HOME.
	gr := filepath.Join(ghidraHome, "ghidraRun")
	if data, err := os.ReadFile(gr); err == nil {
		for _, line := range strings.Split(string(data), "\n") {
			if strings.Contains(line, "JAVA_HOME") && strings.Contains(line, ":-") {
				// JAVA_HOME="${JAVA_HOME:-/opt/homebrew/opt/openjdk@21/...}"
				idx := strings.Index(line, ":-")
				if idx >= 0 {
					rest := line[idx+2:]
					end := strings.IndexAny(rest, `}"`)
					if end > 0 {
						jh := rest[:end]
						if _, err := os.Stat(jh); err == nil {
							return jh
						}
					}
				}
			}
		}
	}

	// Common brew JDK paths.
	jdks := []string{
		"/opt/homebrew/opt/openjdk@21/libexec/openjdk.jdk/Contents/Home",
		"/opt/homebrew/opt/openjdk/libexec/openjdk.jdk/Contents/Home",
		"/usr/local/opt/openjdk@21/libexec/openjdk.jdk/Contents/Home",
	}
	for _, jh := range jdks {
		if _, err := os.Stat(jh); err == nil {
			return jh
		}
	}

	return ""
}

```

`cmd/unflutter/disasm.go`:

```go
package main

import (
	"flag"
	"fmt"

	"unflutter/internal/pipeline"
)

func cmdDisasm(args []string) error {
	fs := flag.NewFlagSet("disasm", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	outDir := fs.String("out", "", "output directory")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	limit := fs.Int("limit", 0, "max functions to disassemble (0 = all)")
	graph := fs.Bool("graph", false, "build lattice call graph and CFG (writes DOT files)")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *libapp == "" || *outDir == "" {
		return fmt.Errorf("--lib and --out are required")
	}

	_, err := pipeline.Run(pipeline.Opts{
		LibPath:  *libapp,
		OutDir:   *outDir,
		MaxSteps: *maxSteps,
		Limit:    *limit,
		Graph:    *graph,
		Quiet:    false,
	})
	return err
}

func qualifiedName(ownerName, funcName string, pcOffset uint32) string {
	return pipeline.QualifiedName(ownerName, funcName, pcOffset)
}

func sanitizeFilename(name string) string {
	return pipeline.SanitizeFilename(name)
}

```

`cmd/unflutter/disasm_test.go`:

```go
package main

import (
	"encoding/json"
	"os"
	"path/filepath"
	"testing"

	"unflutter/internal/disasm"
)

// sampleSpec describes expected thresholds for a sample.
type sampleSpec struct {
	name         string
	libapp       string
	minFunctions int
	minBLRPct    float64 // minimum BLR annotation percentage
}

var samples = []sampleSpec{
	{
		name:         "evil",
		libapp:       "samples/evil-patched.so",
		minFunctions: 1000,
		minBLRPct:    80.0,
	},
	{
		name:         "blutter",
		libapp:       "samples/blutter-lce.so",
		minFunctions: 1000,
		minBLRPct:    80.0,
	},
	{
		name:         "newandromo",
		libapp:       "samples/newandromo.so",
		minFunctions: 1000,
		minBLRPct:    80.0,
	},
}

// findProjectRoot walks up from cwd to find go.mod.
func findProjectRoot() string {
	dir, _ := os.Getwd()
	for {
		if _, err := os.Stat(filepath.Join(dir, "go.mod")); err == nil {
			return dir
		}
		parent := filepath.Dir(dir)
		if parent == dir {
			return ""
		}
		dir = parent
	}
}

func TestDisasmPipelineThresholds(t *testing.T) {
	root := findProjectRoot()
	if root == "" {
		t.Skip("project root not found")
	}

	for _, s := range samples {
		t.Run(s.name, func(t *testing.T) {
			libapp := filepath.Join(root, s.libapp)
			if _, err := os.Stat(libapp); err != nil {
				t.Skipf("sample not found: %s", libapp)
			}

			outDir := t.TempDir()
			err := cmdDisasm([]string{
				"--lib", libapp,
				"--out", outDir,
			})
			if err != nil {
				t.Fatalf("cmdDisasm: %v", err)
			}

			// Check functions.jsonl.
			funcsPath := filepath.Join(outDir, "functions.jsonl")
			funcCount := countJSONLLines(t, funcsPath)
			if funcCount < s.minFunctions {
				t.Errorf("functions: %d < %d minimum", funcCount, s.minFunctions)
			}

			// Check call_edges.jsonl BLR annotation rate.
			edgesPath := filepath.Join(outDir, "call_edges.jsonl")
			totalBLR, annotatedBLR := countBLRAnnotations(t, edgesPath)
			if totalBLR > 0 {
				pct := float64(annotatedBLR) / float64(totalBLR) * 100
				if pct < s.minBLRPct {
					t.Errorf("BLR annotation: %.1f%% < %.1f%% minimum (%d/%d)",
						pct, s.minBLRPct, annotatedBLR, totalBLR)
				}
				t.Logf("BLR: %d/%d (%.1f%%)", annotatedBLR, totalBLR, pct)
			}

			// Check unresolved_thr.jsonl exists.
			unresTHRPath := filepath.Join(outDir, "unresolved_thr.jsonl")
			unresTHRCount := countJSONLLines(t, unresTHRPath)
			t.Logf("functions=%d edges_total=%d blr=%d unres_thr=%d",
				funcCount, countJSONLLines(t, edgesPath), totalBLR, unresTHRCount)
		})
	}
}

func countJSONLLines(t *testing.T, path string) int {
	t.Helper()
	f, err := os.Open(path)
	if err != nil {
		t.Fatalf("open %s: %v", path, err)
	}
	defer f.Close()

	dec := json.NewDecoder(f)
	count := 0
	for dec.More() {
		var raw json.RawMessage
		if err := dec.Decode(&raw); err != nil {
			t.Fatalf("decode %s line %d: %v", path, count+1, err)
		}
		count++
	}
	return count
}

func countBLRAnnotations(t *testing.T, path string) (total, annotated int) {
	t.Helper()
	f, err := os.Open(path)
	if err != nil {
		t.Fatalf("open %s: %v", path, err)
	}
	defer f.Close()

	dec := json.NewDecoder(f)
	for dec.More() {
		var rec disasm.CallEdgeRecord
		if err := dec.Decode(&rec); err != nil {
			t.Fatalf("decode: %v", err)
		}
		if rec.Kind != "blr" {
			continue
		}
		total++
		if rec.Via != "" {
			annotated++
		}
	}
	return
}

```

`cmd/unflutter/dump.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"

	"unflutter/internal/dartfmt"
	"unflutter/internal/disasm"
	"unflutter/internal/elfx"
	"unflutter/internal/output"
	"unflutter/internal/snapshot"
)

func cmdDump(args []string) error {
	fs := flag.NewFlagSet("dump", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	outDir := fs.String("out", "", "output directory")
	_ = fs.String("profile", "", "override version profile (not yet implemented)")
	strict := fs.Bool("strict", false, "fail on first structural error")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")

	if err := fs.Parse(args); err != nil {
		return err
	}

	if *libapp == "" || *outDir == "" {
		return fmt.Errorf("--lib and --out are required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}
	if *strict {
		opts.Mode = dartfmt.ModeStrict
	}

	// Create output directory.
	if err := os.MkdirAll(*outDir, 0755); err != nil {
		return fmt.Errorf("mkdir: %w", err)
	}

	// Open ELF.
	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	// Extract snapshots.
	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	// Write snapshot.json.
	if err := output.WriteSnapshotJSON(*outDir, info); err != nil {
		return fmt.Errorf("write snapshot.json: %w", err)
	}
	fmt.Fprintf(os.Stderr, "wrote %s/snapshot.json\n", *outDir)

	// Generate placeholder symbols from instruction region.
	symbols := make(map[uint64]string)
	var symList []output.SymbolEntry

	// For now, generate sub_<addr> entries at the start of each region.
	if info.IsolateInstructions.VA != 0 {
		name := fmt.Sprintf("sub_%x", info.IsolateInstructions.VA)
		symbols[info.IsolateInstructions.VA] = name
		symList = append(symList, output.SymbolEntry{
			Address: info.IsolateInstructions.VA,
			Name:    name,
			Size:    info.IsolateInstructions.DataSize,
		})
	}
	if info.VmInstructions.VA != 0 {
		name := fmt.Sprintf("sub_%x", info.VmInstructions.VA)
		symbols[info.VmInstructions.VA] = name
		symList = append(symList, output.SymbolEntry{
			Address: info.VmInstructions.VA,
			Name:    name,
			Size:    info.VmInstructions.DataSize,
		})
	}

	// Write symbols.json.
	if err := output.WriteSymbolsJSON(*outDir, symList); err != nil {
		return fmt.Errorf("write symbols.json: %w", err)
	}
	fmt.Fprintf(os.Stderr, "wrote %s/symbols.json (%d entries)\n", *outDir, len(symList))

	lookup := disasm.PlaceholderLookup(symbols)

	// Extract actual code region from isolate instructions (skip Image + InstructionsSection headers).
	if len(info.IsolateInstructions.Data) > 0 {
		code, codeOff, payloadLen, err := snapshot.CodeRegion(info.IsolateInstructions.Data)
		if err != nil {
			fmt.Fprintf(os.Stderr, "warning: could not parse isolate instructions image header: %v\n", err)
			// Fall back to raw disassembly.
			code = info.IsolateInstructions.Data
			codeOff = 0
			payloadLen = uint64(len(code))
		}
		codeVA := info.IsolateInstructions.VA + codeOff
		fmt.Fprintf(os.Stderr, "disassembling isolate code (%d bytes, VA=0x%x, payload=%d)...\n",
			len(code), codeVA, payloadLen)
		insts := disasm.Disassemble(code, disasm.Options{
			BaseAddr: codeVA,
			MaxSteps: opts.EffectiveMaxSteps(),
			Symbols:  lookup,
		})
		if err := output.WriteASMSingle(*outDir, insts, lookup); err != nil {
			return fmt.Errorf("write asm.txt: %w", err)
		}
		fmt.Fprintf(os.Stderr, "wrote %s/asm.txt (%d instructions)\n", *outDir, len(insts))
	}

	// Extract code from VM instructions.
	if len(info.VmInstructions.Data) > 0 {
		code, codeOff, _, err := snapshot.CodeRegion(info.VmInstructions.Data)
		if err != nil {
			code = info.VmInstructions.Data
			codeOff = 0
		}
		codeVA := info.VmInstructions.VA + codeOff
		insts := disasm.Disassemble(code, disasm.Options{
			BaseAddr: codeVA,
			MaxSteps: opts.EffectiveMaxSteps(),
		})
		if err := output.WriteASM(*outDir, "vm_stubs", insts, lookup); err != nil {
			return fmt.Errorf("write asm/vm_stubs.txt: %w", err)
		}
		fmt.Fprintf(os.Stderr, "wrote %s/asm/vm_stubs.txt (%d instructions)\n", *outDir, len(insts))
	}

	if len(info.Diags) > 0 {
		fmt.Fprintf(os.Stderr, "\ndiagnostics: %d issues\n", len(info.Diags))
		for _, d := range info.Diags {
			fmt.Fprintf(os.Stderr, "  %s\n", d)
		}
	}

	return nil
}

```

`cmd/unflutter/find_libapp.go`:

```go
package main

import (
	"archive/zip"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sort"
	"strings"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

// FindResult is the output of find-libapp for one APK/zip.
type FindResult struct {
	APK        string          `json:"apk"`
	Found      bool            `json:"found"`
	Reason     string          `json:"reason"`
	Best       *FindCandidate  `json:"best,omitempty"`
	Candidates []FindCandidate `json:"candidates,omitempty"`
}

// FindCandidate is one .so file probed for Dart AOT indicators.
type FindCandidate struct {
	PathInAPK   string `json:"path_in_apk"`
	Hit         string `json:"hit"` // "symbols", "magic", "none"
	SHA256      string `json:"sha256"`
	Size        int64  `json:"size"`
	SnapHash    string `json:"snapshot_hash,omitempty"`
	DartVersion string `json:"dart_version,omitempty"`
}

func cmdFindLibapp(args []string) error {
	fs := flag.NewFlagSet("find-libapp", flag.ExitOnError)
	apk := fs.String("apk", "", "Path to APK/zip file")
	outDir := fs.String("out", "", "Output directory for find_libapp.json")
	if err := fs.Parse(args); err != nil {
		return err
	}
	if *apk == "" {
		return fmt.Errorf("--apk is required")
	}

	result, err := findLibappInZip(*apk)
	if err != nil {
		return err
	}

	data, err := json.MarshalIndent(result, "", "  ")
	if err != nil {
		return err
	}

	if *outDir != "" {
		if err := os.MkdirAll(*outDir, 0o755); err != nil {
			return err
		}
		base := strings.TrimSuffix(filepath.Base(*apk), filepath.Ext(*apk))
		outPath := filepath.Join(*outDir, base+"_find_libapp.json")
		if err := os.WriteFile(outPath, data, 0o644); err != nil {
			return err
		}
		fmt.Fprintf(os.Stderr, "wrote %s\n", outPath)
	} else {
		fmt.Println(string(data))
	}
	return nil
}

func findLibappInZip(zipPath string) (*FindResult, error) {
	zr, err := zip.OpenReader(zipPath)
	if err != nil {
		return nil, fmt.Errorf("open zip: %w", err)
	}
	defer zr.Close()

	result := &FindResult{APK: zipPath}

	// Collect all .so paths in lib/arm64-v8a/.
	var soFiles []*zip.File
	var hasNestedAPK bool
	for _, f := range zr.File {
		if strings.HasPrefix(f.Name, "lib/arm64-v8a/") && strings.HasSuffix(f.Name, ".so") {
			soFiles = append(soFiles, f)
		}
		if strings.HasSuffix(f.Name, ".apk") {
			hasNestedAPK = true
		}
	}

	// Probe direct .so files.
	for _, f := range soFiles {
		c, err := probeSOFile(f, f.Name)
		if err != nil {
			continue
		}
		result.Candidates = append(result.Candidates, *c)
	}

	// If no direct hits and nested APKs exist, probe those.
	if !hasAnyHit(result.Candidates) && hasNestedAPK {
		for _, f := range zr.File {
			if !strings.HasSuffix(f.Name, ".apk") {
				continue
			}
			nested, err := probeNestedAPK(f)
			if err != nil {
				continue
			}
			result.Candidates = append(result.Candidates, nested...)
		}
	}

	// Classify.
	classifyFindResult(result)
	return result, nil
}

func probeSOFile(f *zip.File, pathLabel string) (*FindCandidate, error) {
	rc, err := f.Open()
	if err != nil {
		return nil, err
	}
	defer rc.Close()

	tmp, err := os.CreateTemp("scratch", "probe-*.so")
	if err != nil {
		return nil, err
	}
	defer os.Remove(tmp.Name())

	n, err := io.Copy(tmp, rc)
	if err != nil {
		tmp.Close()
		return nil, err
	}
	tmp.Close()

	// Compute SHA256.
	h := sha256.New()
	data, err := os.ReadFile(tmp.Name())
	if err != nil {
		return nil, err
	}
	h.Write(data)
	sha := hex.EncodeToString(h.Sum(nil))

	c := &FindCandidate{
		PathInAPK: pathLabel,
		SHA256:    sha,
		Size:      n,
		Hit:       "none",
	}

	// Try ELF + snapshot extract (symbol-based detection).
	ef, err := elfx.Open(tmp.Name())
	if err != nil {
		// Not a valid ARM64 ELF — check for magic in raw data anyway.
		if off := snapshot.ProbeSnapshotMagic(data); off >= 0 {
			c.Hit = "magic"
		}
		return c, nil
	}
	defer ef.Close()

	opts := dartfmt.Options{Mode: dartfmt.ModeBestEffort}
	info, err := snapshot.Extract(ef, opts)
	if err == nil && info.VmHeader != nil && info.VmHeader.SnapshotHash != "" {
		c.Hit = "symbols"
		c.SnapHash = info.VmHeader.SnapshotHash
		if info.Version != nil {
			c.DartVersion = info.Version.DartVersion
		}
		return c, nil
	}

	// Symbols not found — try magic probe on loadable segments.
	segs := ef.LoadSegments()
	for _, seg := range segs {
		if seg.Filesz == 0 {
			continue
		}
		// Read first 4KB of each segment.
		sz := int(seg.Filesz)
		if sz > 4096 {
			sz = 4096
		}
		buf := make([]byte, sz)
		_, err := ef.ReadAt(buf, int64(seg.Offset))
		if err != nil {
			continue
		}
		if snapshot.ProbeSnapshotMagic(buf) >= 0 {
			c.Hit = "magic"
			return c, nil
		}
	}

	return c, nil
}

func probeNestedAPK(f *zip.File) ([]FindCandidate, error) {
	rc, err := f.Open()
	if err != nil {
		return nil, err
	}

	tmp, err := os.CreateTemp("scratch", "nested-*.apk")
	if err != nil {
		rc.Close()
		return nil, err
	}
	_, _ = io.Copy(tmp, rc)
	rc.Close()
	tmp.Close()
	defer os.Remove(tmp.Name())

	inner, err := zip.OpenReader(tmp.Name())
	if err != nil {
		return nil, err
	}
	defer inner.Close()

	var results []FindCandidate
	for _, inf := range inner.File {
		if strings.HasPrefix(inf.Name, "lib/arm64-v8a/") && strings.HasSuffix(inf.Name, ".so") {
			label := f.Name + "!" + inf.Name
			c, err := probeSOFile(inf, label)
			if err != nil {
				continue
			}
			results = append(results, *c)
		}
	}
	return results, nil
}

func hasAnyHit(candidates []FindCandidate) bool {
	for _, c := range candidates {
		if c.Hit != "none" {
			return true
		}
	}
	return false
}

func classifyFindResult(r *FindResult) {
	// Sort candidates: symbols first, then magic, then none.
	sort.Slice(r.Candidates, func(i, j int) bool {
		return hitPriority(r.Candidates[i].Hit) < hitPriority(r.Candidates[j].Hit)
	})

	for i := range r.Candidates {
		if r.Candidates[i].Hit != "none" {
			r.Found = true
			r.Best = &r.Candidates[i]
			switch r.Candidates[i].Hit {
			case "symbols":
				r.Reason = "MATCHED_SYMBOLS"
			case "magic":
				r.Reason = "MATCHED_MAGIC"
			}
			return
		}
	}

	// No hits.
	r.Found = false
	if len(r.Candidates) == 0 {
		// Check if the issue is split APK or no arm64.
		r.Reason = "NO_ARM64"
	} else {
		r.Reason = "NOT_FLUTTER"
	}
}

func hitPriority(hit string) int {
	switch hit {
	case "symbols":
		return 0
	case "magic":
		return 1
	default:
		return 2
	}
}

```

`cmd/unflutter/find_libapp_batch.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"
	"path/filepath"
	"sort"
	"strings"
)

func cmdFindLibappBatch(args []string) error {
	fs := flag.NewFlagSet("find-libapp-batch", flag.ExitOnError)
	dir := fs.String("dir", "samples/flutter", "Directory containing zip files")
	outDir := fs.String("out", "out/find-libapp", "Output directory")
	if err := fs.Parse(args); err != nil {
		return err
	}

	if err := os.MkdirAll(*outDir, 0o755); err != nil {
		return err
	}

	entries, err := os.ReadDir(*dir)
	if err != nil {
		return fmt.Errorf("readdir %s: %w", *dir, err)
	}

	type summary struct {
		Name   string
		Result *FindResult
		Error  string
	}

	var results []summary

	for _, e := range entries {
		if !strings.HasSuffix(e.Name(), ".zip") {
			continue
		}
		path := filepath.Join(*dir, e.Name())
		s := summary{Name: e.Name()}

		result, err := findLibappInZip(path)
		if err != nil {
			s.Error = err.Error()
		} else {
			s.Result = result
			// Write individual JSON.
			data, _ := json.MarshalIndent(result, "", "  ")
			base := strings.TrimSuffix(e.Name(), ".zip")
			outPath := filepath.Join(*outDir, base+"_find_libapp.json")
			os.WriteFile(outPath, data, 0o644)
		}
		results = append(results, s)
	}

	// Sort by name.
	sort.Slice(results, func(i, j int) bool {
		return results[i].Name < results[j].Name
	})

	// Generate no_libapp_report.md — only entries that were NOT found via standard libapp.so path.
	reportPath := filepath.Join(*outDir, "no_libapp_report.md")
	f, err := os.Create(reportPath)
	if err != nil {
		return err
	}
	defer f.Close()

	fmt.Fprintln(f, "# No libapp.so Report")
	fmt.Fprintln(f)
	fmt.Fprintln(f, "Samples where `lib/arm64-v8a/libapp.so` was not found at the standard path.")
	fmt.Fprintln(f)
	fmt.Fprintln(f, "| Sample | Reason | Best Match | Details |")
	fmt.Fprintln(f, "|--------|--------|------------|---------|")

	var noLibapp, found, notFlutter, noArm int
	for _, s := range results {
		if s.Error != "" {
			continue
		}
		if s.Result == nil {
			continue
		}
		// Check if the standard path was the best match.
		hasStandard := false
		if s.Result.Best != nil {
			p := s.Result.Best.PathInAPK
			hasStandard = p == "lib/arm64-v8a/libapp.so" ||
				strings.HasSuffix(p, "!lib/arm64-v8a/libapp.so")
		}
		if hasStandard {
			continue
		}

		noLibapp++
		name := strings.TrimSuffix(s.Name, ".zip")
		if len(name) > 30 {
			name = name[:27] + "..."
		}

		reason := s.Result.Reason
		bestMatch := "-"
		details := "-"

		if s.Result.Best != nil {
			bestMatch = s.Result.Best.PathInAPK
			if len(bestMatch) > 50 {
				bestMatch = "..." + bestMatch[len(bestMatch)-47:]
			}
			details = fmt.Sprintf("hit=%s sha=%s", s.Result.Best.Hit, s.Result.Best.SHA256[:12])
			if s.Result.Best.SnapHash != "" {
				details += " snap=" + s.Result.Best.SnapHash[:12]
			}
			found++
		} else {
			switch reason {
			case "NOT_FLUTTER":
				notFlutter++
				if len(s.Result.Candidates) > 0 {
					var names []string
					for _, c := range s.Result.Candidates {
						names = append(names, filepath.Base(c.PathInAPK))
					}
					details = fmt.Sprintf("%d .so files: %s", len(names), strings.Join(names, ", "))
				}
			case "NO_ARM64":
				noArm++
			}
		}

		fmt.Fprintf(f, "| %s | %s | %s | %s |\n", name, reason, bestMatch, details)
	}

	fmt.Fprintln(f)
	fmt.Fprintf(f, "**Summary:** %d samples without standard libapp.so path. ", noLibapp)
	fmt.Fprintf(f, "%d found (renamed), %d NOT_FLUTTER, %d NO_ARM64.\n", found, notFlutter, noArm)

	fmt.Fprintf(os.Stderr, "find-libapp-batch: %d total zips, %d without standard libapp.so\n", len(results), noLibapp)
	fmt.Fprintf(os.Stderr, "  FOUND (renamed): %d, NOT_FLUTTER: %d, NO_ARM64: %d\n", found, notFlutter, noArm)
	fmt.Fprintf(os.Stderr, "wrote %s\n", reportPath)

	return nil
}

```

`cmd/unflutter/flutter_meta.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/pipeline"
)

func cmdFlutterMeta(args []string) error {
	fs := flag.NewFlagSet("flutter-meta", flag.ExitOnError)
	inDir := fs.String("in", "", "input directory (disasm output)")
	outPath := fs.String("out", "", "output JSON file (default: <in>/flutter_meta.json)")
	decompAll := fs.Bool("decompile-all", false, "decompile ALL functions (default: signal functions only)")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inDir == "" {
		return fmt.Errorf("--in is required")
	}
	if *outPath == "" {
		*outPath = filepath.Join(*inDir, "flutter_meta.json")
	}

	_, err := pipeline.RunMetaStage(*inDir, *outPath, *decompAll, true, os.Stderr)
	return err
}

```

`cmd/unflutter/graph.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

type graphObject struct {
	Ref       int    `json:"ref"`
	CID       int    `json:"cid"`
	Kind      string `json:"kind"`
	Name      string `json:"name"`
	OwnerRef  int    `json:"owner_ref,omitempty"`
	OwnerName string `json:"owner_name,omitempty"`
}

type graphEdge struct {
	FromRef int    `json:"from_ref"`
	ToRef   int    `json:"to_ref"`
	Type    string `json:"type"`
}

type codeMapEntry struct {
	CodeRef      int    `json:"code_ref"`
	FunctionRef  int    `json:"function_ref"`
	FunctionName string `json:"function_name"`
	OwnerName    string `json:"owner_name,omitempty"`
}

func cmdGraph(args []string) error {
	fs := flag.NewFlagSet("graph", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	which := fs.String("which", "isolate", "which snapshot: vm, isolate, or both")
	outDir := fs.String("out", "", "output directory for JSONL files")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *libapp == "" {
		return fmt.Errorf("--lib is required")
	}
	if *outDir == "" {
		return fmt.Errorf("--out is required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}

	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	if info.Version != nil && info.Version.DartVersion != "" {
		fmt.Fprintf(os.Stderr, "Dart SDK version: %s\n", info.Version.DartVersion)
	}
	if info.Version != nil && !info.Version.Supported {
		return fmt.Errorf("HALT_UNSUPPORTED_VERSION: Dart %s (hash %s)", info.Version.DartVersion, info.VmHeader.SnapshotHash)
	}

	type target struct {
		name         string
		data         []byte
		snapshotSize int64
	}
	var targets []target
	switch *which {
	case "vm":
		targets = []target{{"VM", info.VmData.Data, info.VmHeader.TotalSize}}
	case "isolate":
		targets = []target{{"Isolate", info.IsolateData.Data, info.IsolateHeader.TotalSize}}
	default:
		targets = []target{
			{"VM", info.VmData.Data, info.VmHeader.TotalSize},
			{"Isolate", info.IsolateData.Data, info.IsolateHeader.TotalSize},
		}
	}

	// Parse all targets.
	type parsedTarget struct {
		name   string
		result *cluster.Result
	}
	var parsed []parsedTarget

	for _, t := range targets {
		if len(t.data) < 64 {
			fmt.Fprintf(os.Stderr, "%s: data too short (%d bytes)\n", t.name, len(t.data))
			continue
		}

		clusterStart, err := cluster.FindClusterDataStart(t.data)
		if err != nil {
			fmt.Fprintf(os.Stderr, "%s: %v\n", t.name, err)
			continue
		}

		isVM := t.name == "VM"
		result, err := cluster.ScanClusters(t.data, clusterStart, info.Version, isVM, opts)
		if err != nil {
			fmt.Fprintf(os.Stderr, "%s: scan error: %v\n", t.name, err)
			continue
		}

		if err := cluster.ReadFill(t.data, result, info.Version, isVM, t.snapshotSize); err != nil {
			fmt.Fprintf(os.Stderr, "%s: fill error: %v\n", t.name, err)
			continue
		}

		parsed = append(parsed, parsedTarget{name: t.name, result: result})
	}

	// Build combined ref→string map.
	refToStr := make(map[int]string)
	for _, pt := range parsed {
		for _, ps := range pt.result.Strings {
			refToStr[ps.RefID] = ps.Value
		}
	}

	// Build ref→NamedObject lookup.
	refToNamed := make(map[int]*cluster.NamedObject)
	for _, pt := range parsed {
		for i := range pt.result.Named {
			no := &pt.result.Named[i]
			refToNamed[no.RefID] = no
		}
	}

	// Resolve names: for each named object, resolve its name string.
	resolveName := func(no *cluster.NamedObject) string {
		if no.NameRefID >= 0 {
			if s, ok := refToStr[no.NameRefID]; ok {
				return s
			}
		}
		return ""
	}

	// Resolve owner name through the chain.
	resolveOwnerName := func(no *cluster.NamedObject) string {
		if no.OwnerRefID < 0 {
			return ""
		}
		if owner, ok := refToNamed[no.OwnerRefID]; ok {
			return resolveName(owner)
		}
		return ""
	}

	ct := info.Version.CIDs

	// Create output directory.
	if err := os.MkdirAll(*outDir, 0755); err != nil {
		return fmt.Errorf("mkdir %s: %w", *outDir, err)
	}

	// Write objects.jsonl.
	objectsPath := filepath.Join(*outDir, "objects.jsonl")
	objectsFile, err := os.Create(objectsPath)
	if err != nil {
		return fmt.Errorf("create %s: %w", objectsPath, err)
	}
	defer objectsFile.Close()

	enc := json.NewEncoder(objectsFile)
	enc.SetEscapeHTML(false)
	var objectCount int

	for _, pt := range parsed {
		for _, no := range pt.result.Named {
			kind := cluster.CidNameV(no.CID, ct)
			if kind == "" {
				kind = fmt.Sprintf("CID_%d", no.CID)
			}
			obj := graphObject{
				Ref:       no.RefID,
				CID:       no.CID,
				Kind:      kind,
				Name:      resolveName(&no),
				OwnerRef:  no.OwnerRefID,
				OwnerName: resolveOwnerName(&no),
			}
			if err := enc.Encode(obj); err != nil {
				return fmt.Errorf("write objects.jsonl: %w", err)
			}
			objectCount++
		}
	}

	// Write edges.jsonl.
	edgesPath := filepath.Join(*outDir, "edges.jsonl")
	edgesFile, err := os.Create(edgesPath)
	if err != nil {
		return fmt.Errorf("create %s: %w", edgesPath, err)
	}
	defer edgesFile.Close()

	edgeEnc := json.NewEncoder(edgesFile)
	edgeEnc.SetEscapeHTML(false)
	var edgeCount int

	for _, pt := range parsed {
		// Ownership edges from named objects.
		for _, no := range pt.result.Named {
			if no.OwnerRefID >= 0 {
				edge := graphEdge{
					FromRef: no.RefID,
					ToRef:   no.OwnerRefID,
					Type:    "owner",
				}
				if err := edgeEnc.Encode(edge); err != nil {
					return fmt.Errorf("write edges.jsonl: %w", err)
				}
				edgeCount++
			}
			// Name ref edge.
			if no.NameRefID >= 0 {
				edge := graphEdge{
					FromRef: no.RefID,
					ToRef:   no.NameRefID,
					Type:    "name",
				}
				if err := edgeEnc.Encode(edge); err != nil {
					return fmt.Errorf("write edges.jsonl: %w", err)
				}
				edgeCount++
			}
		}
		// Code→owner edges.
		for _, ce := range pt.result.Codes {
			if ce.OwnerRef > 0 {
				edge := graphEdge{
					FromRef: ce.RefID,
					ToRef:   ce.OwnerRef,
					Type:    "code_owner",
				}
				if err := edgeEnc.Encode(edge); err != nil {
					return fmt.Errorf("write edges.jsonl: %w", err)
				}
				edgeCount++
			}
		}
	}

	// Write code_map.jsonl.
	codeMapPath := filepath.Join(*outDir, "code_map.jsonl")
	codeMapFile, err := os.Create(codeMapPath)
	if err != nil {
		return fmt.Errorf("create %s: %w", codeMapPath, err)
	}
	defer codeMapFile.Close()

	codeEnc := json.NewEncoder(codeMapFile)
	codeEnc.SetEscapeHTML(false)
	var codeMapCount int

	for _, pt := range parsed {
		for _, ce := range pt.result.Codes {
			if ce.OwnerRef <= 0 {
				continue
			}
			owner, ok := refToNamed[ce.OwnerRef]
			if !ok {
				continue
			}
			funcName := resolveName(owner)
			ownerName := resolveOwnerName(owner)
			entry := codeMapEntry{
				CodeRef:      ce.RefID,
				FunctionRef:  ce.OwnerRef,
				FunctionName: funcName,
				OwnerName:    ownerName,
			}
			if err := codeEnc.Encode(entry); err != nil {
				return fmt.Errorf("write code_map.jsonl: %w", err)
			}
			codeMapCount++
		}
	}

	fmt.Fprintf(os.Stderr, "Wrote %d objects to %s\n", objectCount, objectsPath)
	fmt.Fprintf(os.Stderr, "Wrote %d edges to %s\n", edgeCount, edgesPath)
	fmt.Fprintf(os.Stderr, "Wrote %d code mappings to %s\n", codeMapCount, codeMapPath)

	return nil
}

```

`cmd/unflutter/ida.go`:

```go
package main

import (
	"fmt"
	"io/fs"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
)

// findPython locates a python3 binary that can import idapro.
// Search order: explicit flag, PATH candidates, conda base, IDA bundled.
func findPython(explicit string) (string, error) {
	if explicit != "" {
		if _, err := os.Stat(explicit); err == nil {
			return explicit, nil
		}
		return "", fmt.Errorf("python not found at %s", explicit)
	}

	// Candidates: PATH first, then conda base, then common IDA-adjacent locations.
	var candidates []string

	// PATH lookup.
	for _, name := range []string{"python3", "python"} {
		if p, err := exec.LookPath(name); err == nil {
			candidates = append(candidates, p)
		}
	}

	// Conda base environment.
	condaPaths := []string{
		"/opt/homebrew/Caskroom/miniconda/base/bin/python3",
		filepath.Join(os.Getenv("HOME"), "miniconda3", "bin", "python3"),
		filepath.Join(os.Getenv("HOME"), "anaconda3", "bin", "python3"),
		filepath.Join(os.Getenv("CONDA_PREFIX"), "bin", "python3"),
	}
	for _, p := range condaPaths {
		if p != "/bin/python3" { // skip if env var was empty
			candidates = append(candidates, p)
		}
	}

	// Test each candidate for idapro importability.
	for _, p := range candidates {
		if _, err := os.Stat(p); err != nil {
			continue
		}
		_, err := exec.Command(p, "-c", "import idapro").CombinedOutput()
		if err == nil {
			return p, nil
		}
	}

	return "", fmt.Errorf(`no python3 with idapro found

Install idapro into your Python:
  pip3 install /Applications/IDA*/Contents/MacOS/idalib/python
  python3 /Applications/IDA*/Contents/MacOS/idalib/python/py-activate-idalib.py -d /Applications/IDA*/Contents/MacOS

Or specify a python that has it:
  unflutter ida --python /path/to/python3 --in <dir>`)
}

// findIDAScript locates ida_scripts/unflutter_apply.py.
func findIDAScript() (string, error) {
	exe, _ := os.Executable()
	exeDir := filepath.Dir(exe)
	homeDir, _ := os.UserHomeDir()

	candidates := []string{
		filepath.Join(homeDir, ".unflutter", "ida_scripts", "unflutter_apply.py"),
		filepath.Join(exeDir, "ida_scripts", "unflutter_apply.py"),
		"ida_scripts/unflutter_apply.py",
		filepath.Join(exeDir, "..", "ida_scripts", "unflutter_apply.py"),
	}

	for _, c := range candidates {
		abs, _ := filepath.Abs(c)
		if _, err := os.Stat(abs); err == nil {
			return abs, nil
		}
	}

	return "", fmt.Errorf("cannot find ida_scripts/unflutter_apply.py; run from the unflutter project root or install with 'make install'")
}

// countDecompiledFiles counts .c files in a directory tree.
func countDecompiledFiles(dir string) int {
	count := 0
	filepath.WalkDir(dir, func(path string, d fs.DirEntry, err error) error {
		if err == nil && !d.IsDir() && strings.HasSuffix(d.Name(), ".c") {
			count++
		}
		return nil
	})
	return count
}

```

`cmd/unflutter/inventory.go`:

```go
package main

import (
	"archive/zip"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sort"
	"strings"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

// InventoryRow is one row of the corpus inventory JSONL.
type InventoryRow struct {
	SampleID       string `json:"sample_id"`
	APKPath        string `json:"apk_path"`
	ABI            string `json:"abi"`
	DeclaredLibapp bool   `json:"declared_libapp"`
	SnapshotHash   string `json:"snapshot_hash,omitempty"`
	DartVersion    string `json:"dart_version,omitempty"`
	Features       string `json:"features,omitempty"`
	Error          string `json:"error,omitempty"`
}

func cmdInventory(args []string) error {
	fs := flag.NewFlagSet("inventory", flag.ExitOnError)
	dir := fs.String("dir", "samples/flutter", "Directory containing zip files")
	outPath := fs.String("out", "", "Output JSONL file (default: stdout)")
	if err := fs.Parse(args); err != nil {
		return err
	}

	entries, err := os.ReadDir(*dir)
	if err != nil {
		return fmt.Errorf("readdir %s: %w", *dir, err)
	}

	var rows []InventoryRow
	for _, e := range entries {
		if !strings.HasSuffix(e.Name(), ".zip") {
			continue
		}
		path := filepath.Join(*dir, e.Name())
		row := InventoryRow{
			SampleID: strings.TrimSuffix(e.Name(), ".zip"),
			APKPath:  path,
			ABI:      "arm64-v8a",
		}

		libapp, err := inventoryExtractLibapp(path)
		if err != nil {
			row.DeclaredLibapp = false
			row.Error = err.Error()
			rows = append(rows, row)
			continue
		}
		row.DeclaredLibapp = true

		hash, dartVer, features, err := inventoryScanLibapp(libapp)
		os.Remove(libapp)
		if err != nil {
			row.Error = err.Error()
			rows = append(rows, row)
			continue
		}

		row.SnapshotHash = hash
		row.DartVersion = dartVer
		row.Features = features
		rows = append(rows, row)
	}

	// Stable sort by sample_id.
	sort.Slice(rows, func(i, j int) bool {
		return rows[i].SampleID < rows[j].SampleID
	})

	var w io.Writer = os.Stdout
	if *outPath != "" {
		if err := os.MkdirAll(filepath.Dir(*outPath), 0o755); err != nil {
			return err
		}
		f, err := os.Create(*outPath)
		if err != nil {
			return err
		}
		defer f.Close()
		w = f
	}

	enc := json.NewEncoder(w)
	enc.SetEscapeHTML(false)
	for _, row := range rows {
		if err := enc.Encode(row); err != nil {
			return err
		}
	}

	// Summary to stderr.
	var found, notFound, errCount int
	verCount := map[string]int{}
	hashCount := map[string]int{}
	for _, r := range rows {
		if r.Error != "" && !r.DeclaredLibapp {
			notFound++
			continue
		}
		if r.Error != "" {
			errCount++
			continue
		}
		found++
		if r.SnapshotHash != "" {
			hashCount[r.SnapshotHash]++
		}
		ver := r.DartVersion
		if ver == "" {
			ver = "unknown"
		}
		verCount[ver]++
	}

	fmt.Fprintf(os.Stderr, "inventory: %d zips, %d with libapp, %d no libapp, %d errors, %d unique hashes\n",
		len(rows), found, notFound, errCount, len(hashCount))
	type vc struct {
		ver   string
		count int
	}
	var vcs []vc
	for v, c := range verCount {
		vcs = append(vcs, vc{v, c})
	}
	sort.Slice(vcs, func(i, j int) bool { return vcs[i].ver < vcs[j].ver })
	for _, v := range vcs {
		fmt.Fprintf(os.Stderr, "  %-10s %d\n", v.ver, v.count)
	}
	return nil
}

// inventoryExtractLibapp finds and extracts lib/arm64-v8a/libapp.so from a zip.
func inventoryExtractLibapp(zipPath string) (string, error) {
	zr, err := zip.OpenReader(zipPath)
	if err != nil {
		return "", fmt.Errorf("open zip: %w", err)
	}
	defer zr.Close()

	// Direct libapp.so.
	for _, f := range zr.File {
		if f.Name == "lib/arm64-v8a/libapp.so" {
			return inventoryExtractFile(f)
		}
	}

	// Nested APKs.
	for _, f := range zr.File {
		if !strings.HasSuffix(f.Name, ".apk") {
			continue
		}
		rc, err := f.Open()
		if err != nil {
			continue
		}
		tmp, err := os.CreateTemp("scratch", "apk-*.apk")
		if err != nil {
			rc.Close()
			continue
		}
		_, _ = io.Copy(tmp, rc)
		rc.Close()
		tmp.Close()

		inner, err := zip.OpenReader(tmp.Name())
		if err != nil {
			os.Remove(tmp.Name())
			continue
		}

		var found string
		for _, inf := range inner.File {
			if inf.Name == "lib/arm64-v8a/libapp.so" {
				found, err = inventoryExtractFile(inf)
				break
			}
		}
		inner.Close()
		os.Remove(tmp.Name())

		if found != "" {
			return found, err
		}
	}

	return "", fmt.Errorf("no lib/arm64-v8a/libapp.so found")
}

func inventoryExtractFile(f *zip.File) (string, error) {
	rc, err := f.Open()
	if err != nil {
		return "", err
	}
	defer rc.Close()

	tmp, err := os.CreateTemp("scratch", "libapp-*.so")
	if err != nil {
		return "", err
	}
	if _, err := io.Copy(tmp, rc); err != nil {
		tmp.Close()
		os.Remove(tmp.Name())
		return "", err
	}
	tmp.Close()
	return tmp.Name(), nil
}

func inventoryScanLibapp(path string) (hash, dartVer, features string, err error) {
	ef, err := elfx.Open(path)
	if err != nil {
		return "", "", "", fmt.Errorf("open elf: %w", err)
	}
	defer ef.Close()

	opts := dartfmt.Options{Mode: dartfmt.ModeBestEffort}
	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return "", "", "", fmt.Errorf("extract: %w", err)
	}

	if info.VmHeader != nil {
		hash = info.VmHeader.SnapshotHash
		features = info.VmHeader.Features
	}
	if info.Version != nil {
		dartVer = info.Version.DartVersion
	}
	return hash, dartVer, features, nil
}

```

`cmd/unflutter/main.go`:

```go
package main

import (
	"fmt"
	"os"
	"strings"
)

func main() {
	if len(os.Args) < 2 {
		usage()
		os.Exit(1)
	}

	var err error
	cmd := os.Args[1]

	switch cmd {
	// --- Primary commands (new CLI) ---
	case "meta":
		err = cmdMeta(os.Args[2:])
	case "ghidra":
		err = cmdGhidra(os.Args[2:])
	case "ida":
		err = cmdIDA(os.Args[2:])
	case "doctor":
		err = cmdDoctor(os.Args[2:])
	case "find-libapp":
		err = cmdFindLibapp(os.Args[2:])
	case "parity":
		err = cmdParity(os.Args[2:])
	case "inventory":
		err = cmdInventory(os.Args[2:])
	case "_debug":
		err = cmdDebug(os.Args[2:])

	// --- Deprecated commands (shims with warnings) ---
	case "disasm":
		deprecationWarning("disasm", "unflutter <libapp.so>")
		err = cmdDisasm(os.Args[2:])
	case "signal":
		// "signal" with --in is the old form; without flags it's the new positional form.
		if hasFlag(os.Args[2:], "-in", "--in") {
			deprecationWarning("signal --in", "unflutter signal <libapp.so>")
			err = cmdSignal(os.Args[2:])
		} else {
			err = cmdSignalPipeline(os.Args[2:])
		}
	case "decompile":
		deprecationWarning("decompile", "unflutter ghidra <libapp.so>")
		err = cmdDecompile(os.Args[2:])
	case "flutter-meta", "ghidra-meta":
		deprecationWarning(cmd, "unflutter meta <libapp.so>")
		err = cmdFlutterMeta(os.Args[2:])
	case "scan":
		deprecationWarning("scan", "unflutter doctor <libapp.so> or unflutter _debug scan")
		err = cmdScan(os.Args[2:])
	case "dump":
		deprecationWarning("dump", "unflutter _debug dump")
		err = cmdDump(os.Args[2:])
	case "objects":
		deprecationWarning("objects", "unflutter _debug objects")
		err = cmdObjects(os.Args[2:])
	case "strings":
		deprecationWarning("strings", "unflutter _debug strings")
		err = cmdStrings(os.Args[2:])
	case "graph":
		deprecationWarning("graph", "unflutter _debug graph")
		err = cmdGraph(os.Args[2:])
	case "clusters":
		deprecationWarning("clusters", "unflutter _debug clusters")
		err = cmdClusters(os.Args[2:])
	case "render":
		deprecationWarning("render", "unflutter _debug render")
		err = cmdRender(os.Args[2:])
	case "thr-audit":
		deprecationWarning("thr-audit", "unflutter _debug thr-audit")
		err = cmdTHRAudit(os.Args[2:])
	case "thr-cluster":
		deprecationWarning("thr-cluster", "unflutter _debug thr-cluster")
		err = cmdTHRCluster(os.Args[2:])
	case "thr-classify":
		deprecationWarning("thr-classify", "unflutter _debug thr-classify")
		err = cmdTHRClassify(os.Args[2:])
	case "find-libapp-batch":
		deprecationWarning("find-libapp-batch", "unflutter _debug find-libapp-batch")
		err = cmdFindLibappBatch(os.Args[2:])
	case "dart2-buckets":
		deprecationWarning("dart2-buckets", "unflutter _debug dart2-buckets")
		err = cmdDart2Buckets(os.Args[2:])

	case "help", "-h", "--help":
		usage()
		os.Exit(0)

	default:
		// If the first arg is a file on disk, treat as "unflutter <libapp.so>".
		if resolvePositionalLib(cmd) != "" {
			err = cmdRun(os.Args[1:])
		} else if strings.HasPrefix(cmd, "-") {
			// Flags before file path: pass all args to cmdRun which will reorder.
			err = cmdRun(os.Args[1:])
		} else {
			fmt.Fprintf(os.Stderr, "unknown command: %s\n", cmd)
			usage()
			os.Exit(1)
		}
	}

	if err != nil {
		fmt.Fprintf(os.Stderr, "error: %v\n", err)
		os.Exit(1)
	}
}

func deprecationWarning(old, new string) {
	fmt.Fprintf(os.Stderr, "warning: '%s' is deprecated, use '%s' instead\n\n", old, new)
}

// hasFlag checks if any arg matches one of the given flag names.
func hasFlag(args []string, names ...string) bool {
	for _, a := range args {
		for _, n := range names {
			if a == n {
				return true
			}
		}
	}
	return false
}

func usage() {
	fmt.Fprintf(os.Stderr, `unflutter — Dart AOT snapshot analyzer

Usage:
  unflutter <libapp.so>                         Full analysis pipeline
  unflutter meta <libapp.so>                    Generate flutter_meta.json
  unflutter ghidra <libapp.so>                   Ghidra headless decompilation
  unflutter ida <libapp.so>                     IDA headless decompilation
  unflutter signal <libapp.so>                  Signal analysis
  unflutter doctor <libapp.so>                  Diagnostic scan
  unflutter find-libapp <apk>                   Find Dart library in APK
  unflutter parity <dir>                        Corpus parity report
  unflutter inventory <dir>                     Sample inventory
  unflutter _debug <cmd>                        Internal commands

Flags:
  --out <dir>         Output directory (default: <basename>.unflutter/)
  --quiet, -q         Suppress verbose output (verbose is default)
  --strict            Fail on structural errors
  --all               Include all functions (not just signal)
  --from <dir>        Reuse existing disasm output
  --k <n>             Signal context hops (default: 2)
  --graph             Build call graph and per-function CFGs
  --max-steps <n>     Global loop cap
`)
}

```

`cmd/unflutter/objects.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"

	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

type poolRecord struct {
	Index   int    `json:"index"`
	Offset  string `json:"offset"`
	Kind    string `json:"kind"`
	Display string `json:"display"`
	RefID   int    `json:"ref,omitempty"`
	Imm     int64  `json:"imm,omitempty"`
}

func cmdObjects(args []string) error {
	fs := flag.NewFlagSet("objects", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	jsonOut := fs.Bool("json", false, "output JSONL instead of text")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *libapp == "" {
		return fmt.Errorf("--lib is required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}

	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	if info.Version != nil && info.Version.DartVersion != "" {
		fmt.Fprintf(os.Stderr, "Dart SDK version: %s\n", info.Version.DartVersion)
	}
	if info.Version != nil && !info.Version.Supported {
		return fmt.Errorf("HALT_UNSUPPORTED_VERSION: Dart %s (hash %s)", info.Version.DartVersion, info.VmHeader.SnapshotHash)
	}

	// Parse isolate snapshot.
	data := info.IsolateData.Data
	if len(data) < 64 {
		return fmt.Errorf("isolate data too short (%d bytes)", len(data))
	}

	clusterStart, err := cluster.FindClusterDataStart(data)
	if err != nil {
		return fmt.Errorf("cluster start: %w", err)
	}

	result, err := cluster.ScanClusters(data, clusterStart, info.Version, false, opts)
	if err != nil {
		return fmt.Errorf("scan: %w", err)
	}

	if os.Getenv("DEFLUTTER_DEBUG_FILL") != "" {
		if err := cluster.DebugFillPositions(data, result, info.Version, false, os.Stderr); err != nil {
			return fmt.Errorf("fill debug: %w", err)
		}
	}
	if err := cluster.ReadFill(data, result, info.Version, false, info.IsolateHeader.TotalSize); err != nil {
		return fmt.Errorf("fill: %w", err)
	}

	// Parse VM snapshot for base object resolution (strings, names, CIDs).
	var vmResult *cluster.Result
	vmData := info.VmData.Data
	if len(vmData) >= 64 && info.VmHeader != nil {
		vmStart, err := cluster.FindClusterDataStart(vmData)
		if err == nil {
			vmRes, err := cluster.ScanClusters(vmData, vmStart, info.Version, true, opts)
			if err == nil {
				if err := cluster.ReadFillStrings(vmData, vmRes, info.Version, true, info.VmHeader.TotalSize); err == nil {
					// Also do full ReadFill for named objects.
					_ = cluster.ReadFill(vmData, vmRes, info.Version, true, info.VmHeader.TotalSize)
				}
				vmResult = vmRes
				fmt.Fprintf(os.Stderr, "vm snapshot: %d clusters, %d strings, %d named\n",
					len(vmRes.Clusters), len(vmRes.Strings), len(vmRes.Named))
			}
		}
	}

	// Resolve pool entries.
	pl := buildPoolLookups(result, info.Version.CIDs, vmResult)
	poolDisplay := resolvePoolDisplay(result.Pool, pl)

	fmt.Fprintf(os.Stderr, "pool: %d entries (%d resolved)\n", len(result.Pool), len(poolDisplay))

	// Output.
	if *jsonOut {
		enc := json.NewEncoder(os.Stdout)
		enc.SetEscapeHTML(false)
		for _, pe := range result.Pool {
			rec := poolRecord{
				Index:  pe.Index,
				Offset: fmt.Sprintf("0x%x", (pe.Index+2)*8),
				Kind:   poolKindString(pe.Kind),
			}
			if d, ok := poolDisplay[pe.Index]; ok {
				rec.Display = d
			}
			if pe.Kind == cluster.PoolTagged {
				rec.RefID = pe.RefID
			}
			if pe.Kind == cluster.PoolImmediate {
				rec.Imm = pe.Imm
			}
			if err := enc.Encode(rec); err != nil {
				return fmt.Errorf("write json: %w", err)
			}
		}
	} else {
		for _, pe := range result.Pool {
			offset := (pe.Index + 2) * 8
			display := poolDisplay[pe.Index]
			switch pe.Kind {
			case cluster.PoolTagged:
				if display != "" {
					fmt.Printf("[pp+0x%x] %s\n", offset, display)
				} else {
					fmt.Printf("[pp+0x%x] <ref:%d>\n", offset, pe.RefID)
				}
			case cluster.PoolImmediate:
				fmt.Printf("[pp+0x%x] IMM: 0x%x\n", offset, pe.Imm)
			case cluster.PoolNative:
				fmt.Printf("[pp+0x%x] Native\n", offset)
			case cluster.PoolEmpty:
				fmt.Printf("[pp+0x%x] Empty\n", offset)
			}
		}
	}

	return nil
}

func poolKindString(k cluster.PoolEntryKind) string {
	switch k {
	case cluster.PoolTagged:
		return "tagged"
	case cluster.PoolImmediate:
		return "immediate"
	case cluster.PoolNative:
		return "native"
	case cluster.PoolEmpty:
		return "empty"
	default:
		return fmt.Sprintf("unknown_%d", k)
	}
}

```

`cmd/unflutter/parity.go`:

```go
package main

import (
	"encoding/csv"
	"flag"
	"fmt"
	"os"
	"path/filepath"
	"sort"
	"strconv"
	"strings"

	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

type parityRow struct {
	SampleHash  string
	DartVersion string
	Supported   bool
	Status      string // OK, UNSUPPORTED, EXTRACT_FAIL, ALLOC_FAIL, FILL_FAIL
	Strings     int
	Named       int
	Codes       int
	CodeMap     int
	Clusters    int
	Error       string
}

func cmdParity(args []string) error {
	fs := flag.NewFlagSet("parity", flag.ExitOnError)
	samplesDir := fs.String("samples", "", "directory containing sample subdirs (each with libapp.so)")
	outDir := fs.String("out", "", "output directory for parity.csv and summary")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *samplesDir == "" || *outDir == "" {
		return fmt.Errorf("--samples and --out are required")
	}

	entries, err := os.ReadDir(*samplesDir)
	if err != nil {
		return fmt.Errorf("read samples dir: %w", err)
	}

	// Collect sample hashes that have libapp.so.
	var hashes []string
	for _, e := range entries {
		if !e.IsDir() {
			continue
		}
		libpath := filepath.Join(*samplesDir, e.Name(), "libapp.so")
		if _, err := os.Stat(libpath); err == nil {
			hashes = append(hashes, e.Name())
		}
	}
	sort.Strings(hashes)

	opts := dartfmt.Options{Mode: dartfmt.ModeBestEffort}

	var rows []parityRow
	for _, hash := range hashes {
		row := runParitySample(filepath.Join(*samplesDir, hash, "libapp.so"), hash, opts)
		rows = append(rows, row)
		fmt.Fprintf(os.Stderr, "%-34s %-8s %-12s strings=%-6d named=%-6d codes=%-6d codemap=%-6d\n",
			hash, row.DartVersion, row.Status, row.Strings, row.Named, row.Codes, row.CodeMap)
	}

	if err := os.MkdirAll(*outDir, 0755); err != nil {
		return fmt.Errorf("mkdir: %w", err)
	}

	// Write parity.csv.
	csvPath := filepath.Join(*outDir, "parity.csv")
	if err := writeParityCSV(csvPath, rows); err != nil {
		return err
	}
	fmt.Fprintf(os.Stderr, "\nWrote %s (%d rows)\n", csvPath, len(rows))

	// Write summary.
	summaryPath := filepath.Join(*outDir, "parity_summary.md")
	if err := writeParitySummary(summaryPath, rows); err != nil {
		return err
	}
	fmt.Fprintf(os.Stderr, "Wrote %s\n", summaryPath)

	return nil
}

func runParitySample(libpath, hash string, opts dartfmt.Options) parityRow {
	row := parityRow{SampleHash: hash}

	ef, err := elfx.Open(libpath)
	if err != nil {
		row.Status = "EXTRACT_FAIL"
		row.Error = err.Error()
		return row
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		row.Status = "EXTRACT_FAIL"
		row.Error = err.Error()
		return row
	}

	if info.Version != nil {
		row.DartVersion = info.Version.DartVersion
		row.Supported = info.Version.Supported
	}

	if !row.Supported {
		row.Status = "UNSUPPORTED"
		return row
	}

	// Run pipeline on isolate snapshot.
	data := info.IsolateData.Data
	if len(data) < 64 {
		row.Status = "EXTRACT_FAIL"
		row.Error = "isolate data too short"
		return row
	}

	clusterStart, err := cluster.FindClusterDataStart(data)
	if err != nil {
		row.Status = "ALLOC_FAIL"
		row.Error = err.Error()
		return row
	}

	result, err := cluster.ScanClusters(data, clusterStart, info.Version, false, opts)
	if err != nil {
		row.Status = "ALLOC_FAIL"
		row.Error = err.Error()
		return row
	}
	row.Clusters = len(result.Clusters)

	if err := cluster.ReadFill(data, result, info.Version, false, info.IsolateHeader.TotalSize); err != nil {
		row.Status = "FILL_FAIL"
		row.Error = err.Error()
		row.Strings = len(result.Strings)
		row.Named = len(result.Named)
		row.Codes = len(result.Codes)
		return row
	}

	row.Strings = len(result.Strings)
	row.Named = len(result.Named)
	row.Codes = len(result.Codes)

	// Count code→function mappings.
	refToNamed := make(map[int]bool, len(result.Named))
	for _, no := range result.Named {
		refToNamed[no.RefID] = true
	}
	for _, ce := range result.Codes {
		if ce.OwnerRef > 0 && refToNamed[ce.OwnerRef] {
			row.CodeMap++
		}
	}

	row.Status = "OK"
	return row
}

func writeParityCSV(path string, rows []parityRow) error {
	f, err := os.Create(path)
	if err != nil {
		return fmt.Errorf("create %s: %w", path, err)
	}
	defer f.Close()

	w := csv.NewWriter(f)
	defer w.Flush()

	header := []string{"sample_hash", "dart_version", "status", "clusters", "strings", "named", "codes", "code_map", "error"}
	if err := w.Write(header); err != nil {
		return err
	}

	for _, r := range rows {
		record := []string{
			r.SampleHash,
			r.DartVersion,
			r.Status,
			strconv.Itoa(r.Clusters),
			strconv.Itoa(r.Strings),
			strconv.Itoa(r.Named),
			strconv.Itoa(r.Codes),
			strconv.Itoa(r.CodeMap),
			r.Error,
		}
		if err := w.Write(record); err != nil {
			return err
		}
	}
	return nil
}

func writeParitySummary(path string, rows []parityRow) error {
	f, err := os.Create(path)
	if err != nil {
		return fmt.Errorf("create %s: %w", path, err)
	}
	defer f.Close()

	// Count by status.
	statusCounts := make(map[string]int)
	versionCounts := make(map[string]int)
	var totalStrings, totalNamed, totalCodes, totalCodeMap int
	for _, r := range rows {
		statusCounts[r.Status]++
		if r.DartVersion != "" {
			versionCounts[r.DartVersion]++
		}
		totalStrings += r.Strings
		totalNamed += r.Named
		totalCodes += r.Codes
		totalCodeMap += r.CodeMap
	}

	fmt.Fprintf(f, "# Parity Report\n\n")
	fmt.Fprintf(f, "Total samples: %d\n\n", len(rows))

	fmt.Fprintf(f, "## Status\n\n")
	fmt.Fprintf(f, "| Status | Count |\n|--------|-------|\n")
	for _, st := range []string{"OK", "UNSUPPORTED", "EXTRACT_FAIL", "ALLOC_FAIL", "FILL_FAIL"} {
		if c, ok := statusCounts[st]; ok {
			fmt.Fprintf(f, "| %s | %d |\n", st, c)
		}
	}

	fmt.Fprintf(f, "\n## Version Coverage\n\n")
	fmt.Fprintf(f, "| Version | Samples | Status |\n|---------|---------|--------|\n")
	var versions []string
	for v := range versionCounts {
		versions = append(versions, v)
	}
	sort.Strings(versions)
	for _, v := range versions {
		supported := "supported"
		for _, r := range rows {
			if r.DartVersion == v && !r.Supported {
				supported = "unsupported"
				break
			}
		}
		fmt.Fprintf(f, "| %s | %d | %s |\n", v, versionCounts[v], supported)
	}

	fmt.Fprintf(f, "\n## Totals (OK samples only)\n\n")
	fmt.Fprintf(f, "| Metric | Total |\n|--------|-------|\n")
	fmt.Fprintf(f, "| Strings | %d |\n", totalStrings)
	fmt.Fprintf(f, "| Named objects | %d |\n", totalNamed)
	fmt.Fprintf(f, "| Code entries | %d |\n", totalCodes)
	fmt.Fprintf(f, "| Code→function maps | %d |\n", totalCodeMap)

	// List failed samples.
	var failed []parityRow
	for _, r := range rows {
		if r.Status != "OK" && r.Status != "UNSUPPORTED" {
			failed = append(failed, r)
		}
	}
	if len(failed) > 0 {
		fmt.Fprintf(f, "\n## Failures\n\n")
		fmt.Fprintf(f, "| Hash | Version | Status | Error |\n|------|---------|--------|-------|\n")
		for _, r := range failed {
			errMsg := r.Error
			if len(errMsg) > 80 {
				errMsg = errMsg[:80] + "..."
			}
			errMsg = strings.ReplaceAll(errMsg, "|", "\\|")
			fmt.Fprintf(f, "| %s | %s | %s | %s |\n", r.SampleHash, r.DartVersion, r.Status, errMsg)
		}
	}

	// List unsupported samples.
	var unsupported []parityRow
	for _, r := range rows {
		if r.Status == "UNSUPPORTED" {
			unsupported = append(unsupported, r)
		}
	}
	if len(unsupported) > 0 {
		fmt.Fprintf(f, "\n## Unsupported Versions\n\n")
		fmt.Fprintf(f, "| Hash | Version |\n|------|--------|\n")
		for _, r := range unsupported {
			fmt.Fprintf(f, "| %s | %s |\n", r.SampleHash, r.DartVersion)
		}
	}

	return nil
}

```

`cmd/unflutter/pool.go`:

```go
package main

import (
	"unflutter/internal/cluster"
	"unflutter/internal/pipeline"
	"unflutter/internal/snapshot"
)

type poolLookups = pipeline.PoolLookups
func buildPoolLookups(result *cluster.Result, ct *snapshot.CIDTable, vmResult *cluster.Result) *poolLookups {
	return pipeline.BuildPoolLookups(result, ct, vmResult)
}

func resolvePoolDisplay(pool []cluster.PoolEntry, l *poolLookups) map[int]string {
	return pipeline.ResolvePoolDisplay(pool, l)
}

```

`cmd/unflutter/render.go`:

```go
package main

import (
	"encoding/binary"
	"flag"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"

	"unflutter/internal/disasm"
	"unflutter/internal/pipeline"
	"unflutter/internal/render"
)

func cmdRender(args []string) error {
	fs := flag.NewFlagSet("render", flag.ExitOnError)
	inDir := fs.String("in", "", "input directory (disasm output)")
	maxNodes := fs.Int("max-nodes", 0, "max function nodes in callgraph (0 = all)")
	title := fs.String("title", "", "title for callgraph and HTML (auto-detected from dir name)")
	noDot := fs.Bool("no-dot", true, "skip SVG generation (dot not required)")
	cfgFlag := fs.Bool("cfg", false, "generate per-function CFGs for reachable functions")
	asmDir := fs.String("asm", "", "directory with per-function .bin files (defaults to <in>/asm)")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inDir == "" {
		return fmt.Errorf("--in is required")
	}

	if *title == "" {
		*title = "unflutter"
	}
	if *asmDir == "" {
		*asmDir = filepath.Join(*inDir, "asm")
	}

	// Read functions.jsonl.
	funcs, err := readJSONL[disasm.FuncRecord](filepath.Join(*inDir, "functions.jsonl"))
	if err != nil {
		return fmt.Errorf("read functions.jsonl: %w", err)
	}
	fmt.Fprintf(os.Stderr, "read %d functions\n", len(funcs))

	// Read call_edges.jsonl.
	edges, err := readJSONL[disasm.CallEdgeRecord](filepath.Join(*inDir, "call_edges.jsonl"))
	if err != nil {
		return fmt.Errorf("read call_edges.jsonl: %w", err)
	}
	fmt.Fprintf(os.Stderr, "read %d call edges\n", len(edges))

	// Read unresolved_thr.jsonl (optional).
	unresTHRPath := filepath.Join(*inDir, "unresolved_thr.jsonl")
	var unresTHR []disasm.UnresolvedTHRRecord
	if _, err := os.Stat(unresTHRPath); err == nil {
		unresTHR, err = readJSONL[disasm.UnresolvedTHRRecord](unresTHRPath)
		if err != nil {
			return fmt.Errorf("read unresolved_thr.jsonl: %w", err)
		}
		fmt.Fprintf(os.Stderr, "read %d unresolved THR records\n", len(unresTHR))
	}

	// Create render output directory.
	renderDir := filepath.Join(*inDir, "render")
	if err := os.MkdirAll(renderDir, 0755); err != nil {
		return fmt.Errorf("mkdir render: %w", err)
	}

	// Compute stats.
	stats := render.ComputeStats(funcs, edges)

	// Compute reachability.
	entryPoints := render.FindEntryPoints(funcs, edges)
	reachable := render.ReachableSet(entryPoints, edges)
	fmt.Fprintf(os.Stderr, "entry points: %d, reachable functions: %d / %d\n",
		len(entryPoints), len(reachable), len(funcs))

	// Generate reachability DOT.
	reachDOT := render.ReachabilityDOT(funcs, edges, reachable, entryPoints,
		*title+" (reachable)", render.NASA)
	reachDotPath := filepath.Join(renderDir, "reachable.dot")
	if err := os.WriteFile(reachDotPath, []byte(reachDOT), 0644); err != nil {
		return fmt.Errorf("write reachable.dot: %w", err)
	}
	fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", reachDotPath, len(reachDOT))

	// Generate callgraph DOT.
	dot := render.CallgraphDOT(funcs, edges, *title, render.NASA, *maxNodes)
	dotPath := filepath.Join(renderDir, "callgraph.dot")
	if err := os.WriteFile(dotPath, []byte(dot), 0644); err != nil {
		return fmt.Errorf("write callgraph.dot: %w", err)
	}
	fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", dotPath, len(dot))

	// Generate classgraph DOT.
	classDOT := render.ClassgraphDOT(funcs, edges, *title+" (class level)", render.NASA, *maxNodes)
	classDotPath := filepath.Join(renderDir, "classgraph.dot")
	if err := os.WriteFile(classDotPath, []byte(classDOT), 0644); err != nil {
		return fmt.Errorf("write classgraph.dot: %w", err)
	}
	fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", classDotPath, len(classDOT))

	// Generate SVGs via graphviz dot.
	hasCallgraphSVG := false
	hasClassgraphSVG := false
	hasReachableSVG := false
	if !*noDot {
		svgPath := filepath.Join(renderDir, "callgraph.svg")
		if err := runDot(dotPath, svgPath, "svg"); err != nil {
			fmt.Fprintf(os.Stderr, "warning: callgraph SVG failed: %v (use --no-dot to skip)\n", err)
		} else {
			hasCallgraphSVG = true
			fi, _ := os.Stat(svgPath)
			fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", svgPath, fi.Size())
		}

		classSvgPath := filepath.Join(renderDir, "classgraph.svg")
		if err := runDot(classDotPath, classSvgPath, "svg"); err != nil {
			fmt.Fprintf(os.Stderr, "warning: classgraph SVG failed: %v\n", err)
		} else {
			hasClassgraphSVG = true
			fi, _ := os.Stat(classSvgPath)
			fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", classSvgPath, fi.Size())
		}

		reachSvgPath := filepath.Join(renderDir, "reachable.svg")
		if err := runDot(reachDotPath, reachSvgPath, "svg"); err != nil {
			fmt.Fprintf(os.Stderr, "warning: reachable SVG failed: %v\n", err)
		} else {
			hasReachableSVG = true
			fi, _ := os.Stat(reachSvgPath)
			fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", reachSvgPath, fi.Size())
		}
	}

	// Generate per-function CFGs if --cfg and asm directory exists.
	var cfgFuncs int
	if *cfgFlag {
		if _, err := os.Stat(*asmDir); err != nil {
			fmt.Fprintf(os.Stderr, "warning: --cfg requires asm directory at %s\n", *asmDir)
		} else {
			cfgDir := filepath.Join(renderDir, "cfg")
			if err := os.MkdirAll(cfgDir, 0755); err != nil {
				return fmt.Errorf("mkdir cfg: %w", err)
			}
			cfgFuncs, err = generateCFGs(funcs, reachable, *asmDir, cfgDir, !*noDot)
			if err != nil {
				return fmt.Errorf("generate CFGs: %w", err)
			}
			fmt.Fprintf(os.Stderr, "generated %d CFGs in %s\n", cfgFuncs, cfgDir)
		}
	}

	// Generate index.html.
	htmlPath := filepath.Join(renderDir, "index.html")
	htmlFile, err := os.Create(htmlPath)
	if err != nil {
		return fmt.Errorf("create index.html: %w", err)
	}
	render.WriteIndexHTML(htmlFile, stats, unresTHR, *title,
		hasCallgraphSVG, hasClassgraphSVG, hasReachableSVG,
		entryPoints, len(reachable), cfgFuncs)
	if err := htmlFile.Close(); err != nil {
		return fmt.Errorf("close index.html: %w", err)
	}
	fi, _ := os.Stat(htmlPath)
	fmt.Fprintf(os.Stderr, "wrote %s (%d bytes)\n", htmlPath, fi.Size())

	return nil
}

// generateCFGs builds per-function CFG DOTs (and optionally SVGs) for reachable functions.
// Returns the number of CFGs generated.
func generateCFGs(funcs []disasm.FuncRecord, reachable map[string]bool, asmDir, cfgDir string, genSVG bool) (int, error) {
	count := 0
	for _, f := range funcs {
		if !reachable[f.Name] {
			continue
		}
		if strings.HasPrefix(f.Name, "sub_") {
			continue
		}

		// Load raw instructions from .bin file (named by sanitizeFilename).
		safeName := sanitizeFilename(f.Name)
		binPath := filepath.Join(asmDir, safeName+".bin")
		data, err := os.ReadFile(binPath)
		if err != nil {
			continue // no .bin file for this function
		}
		if len(data) < 4 {
			continue
		}

		// Parse PC from function record.
		pc, err := strconv.ParseUint(strings.TrimPrefix(f.PC, "0x"), 16, 64)
		if err != nil {
			continue
		}

		// Decode instructions.
		insts := decodeRawInsts(data, pc)
		if len(insts) == 0 {
			continue
		}

		// Build CFG.
		cfg := disasm.BuildCFG(f.Name, insts)
		if len(cfg.Blocks) == 0 {
			continue
		}

		// Render DOT.
		dot := render.CFGDOT(cfg, render.NASA)
		dotPath := filepath.Join(cfgDir, safeName+".dot")
		if err := os.WriteFile(dotPath, []byte(dot), 0644); err != nil {
			return count, fmt.Errorf("write %s: %w", dotPath, err)
		}

		// Optional SVG.
		if genSVG {
			svgPath := filepath.Join(cfgDir, safeName+".svg")
			if err := runDot(dotPath, svgPath, "svg"); err != nil {
				// Non-fatal: skip SVG for this function.
				fmt.Fprintf(os.Stderr, "  warning: CFG SVG failed for %s: %v\n", f.Name, err)
			}
		}
		count++
	}
	return count, nil
}

// decodeRawInsts decodes ARM64 instructions from raw bytes.
// Minimal decoder: just addr + raw + a text representation.
func decodeRawInsts(data []byte, baseAddr uint64) []disasm.Inst {
	n := len(data) / 4
	insts := make([]disasm.Inst, 0, n)
	for i := 0; i < n; i++ {
		raw := binary.LittleEndian.Uint32(data[i*4:])
		addr := baseAddr + uint64(i*4)
		inst := disasm.Inst{
			Addr: addr,
			Raw:  raw,
			Size: 4,
			Text: fmt.Sprintf(".word 0x%08x", raw),
		}
		// Try to get a proper disassembly text.
		text := disasm.DisasmOne(raw, addr)
		if text != "" {
			inst.Text = text
		}
		insts = append(insts, inst)
	}
	return insts
}

// runDot invokes graphviz dot to produce the given format.
func runDot(dotPath, outPath, format string) error {
	cmd := exec.Command("dot", "-T"+format, "-o", outPath, dotPath)
	cmd.Stderr = os.Stderr
	return cmd.Run()
}

// readJSONL delegates to pipeline.ReadJSONL.
func readJSONL[T any](path string) ([]T, error) {
	return pipeline.ReadJSONL[T](path)
}

```

`cmd/unflutter/resolve.go`:

```go
package main

import (
	"os"
	"path/filepath"
	"strings"
)

// defaultOutDir computes the default output directory for a given input file.
// e.g., "libapp.so" → "libapp.unflutter/" in the same directory.
func defaultOutDir(libPath string) string {
	base := filepath.Base(libPath)
	name := strings.TrimSuffix(base, filepath.Ext(base))
	return filepath.Join(filepath.Dir(libPath), name+".unflutter")
}

// resolvePositionalLib resolves a positional argument as a path to a file.
// Returns the absolute path if the file exists, or empty string if not.
func resolvePositionalLib(arg string) string {
	if _, err := os.Stat(arg); err == nil {
		abs, _ := filepath.Abs(arg)
		return abs
	}
	return ""
}

// reorderPositionalArg handles the case where a positional file argument
// comes before flags (e.g. "libapp.so --verbose"). Go's flag package stops
// parsing at the first non-flag arg, so we move it to the end.
func reorderPositionalArg(args []string) []string {
	if len(args) == 0 || strings.HasPrefix(args[0], "-") {
		return args // already flags-first or empty
	}
	// First arg is non-flag (file path). Move it after all flags.
	reordered := make([]string, 0, len(args))
	reordered = append(reordered, args[1:]...)
	reordered = append(reordered, args[0])
	return reordered
}

```

`cmd/unflutter/scan.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

func cmdScan(args []string) error {
	fs := flag.NewFlagSet("scan", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	profile := fs.String("profile", "", "override version profile")
	strict := fs.Bool("strict", false, "fail on first structural error")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	jsonOut := fs.Bool("json", false, "output as JSON")

	if err := fs.Parse(args); err != nil {
		return err
	}

	if *libapp == "" {
		return fmt.Errorf("--lib is required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}
	if *strict {
		opts.Mode = dartfmt.ModeStrict
	}

	// Open and validate ELF.
	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	fmt.Fprintf(os.Stderr, "ELF: ARM64 shared object, %d bytes\n", ef.FileSize())

	// Print load segments.
	segs := ef.LoadSegments()
	fmt.Fprintf(os.Stderr, "PT_LOAD segments: %d\n", len(segs))
	for _, s := range segs {
		perm := ""
		if s.Flags&0x4 != 0 {
			perm += "R"
		}
		if s.Flags&0x2 != 0 {
			perm += "W"
		}
		if s.Flags&0x1 != 0 {
			perm += "X"
		}
		fmt.Fprintf(os.Stderr, "  VA=0x%08x Filesz=0x%08x Memsz=0x%08x %s\n",
			s.Vaddr, s.Filesz, s.Memsz, perm)
	}

	// Extract snapshots.
	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	if *jsonOut {
		enc := json.NewEncoder(os.Stdout)
		enc.SetIndent("", "  ")
		return enc.Encode(info)
	}

	// Text output.
	printRegion := func(r snapshot.Region) {
		fmt.Printf("  %-40s VA=0x%08x  FileOff=0x%08x  SymSize=0x%x\n",
			r.Name, r.VA, r.FileOffset, r.SymSize)
		if r.SHA256 != "" {
			fmt.Printf("    SHA256=%s  DataSize=%d\n", r.SHA256[:16]+"...", r.DataSize)
		}
	}

	fmt.Println("\nSnapshot Regions:")
	printRegion(info.VmData)
	printRegion(info.VmInstructions)
	printRegion(info.IsolateData)
	printRegion(info.IsolateInstructions)

	if info.VmHeader != nil {
		fmt.Printf("\nVM Snapshot Header:\n")
		fmt.Printf("  Kind:     %s\n", info.VmHeader.Kind)
		fmt.Printf("  Size:     %d (0x%x)\n", info.VmHeader.TotalSize, info.VmHeader.TotalSize)
		fmt.Printf("  Hash:     %s\n", info.VmHeader.SnapshotHash)
		fmt.Printf("  Features: %s\n", info.VmHeader.Features)

		prof := snapshot.DetectProfile(info.VmHeader)
		if *profile != "" {
			fmt.Printf("  Profile:  %s (overridden to %s)\n", prof.ID, *profile)
		} else {
			fmt.Printf("  Profile:  %s\n", prof.ID)
		}
		fmt.Printf("    CompressedPointers=%v NullSafety=%v\n",
			prof.CompressedPointers, prof.NullSafety)
	}

	if info.IsolateHeader != nil {
		fmt.Printf("\nIsolate Snapshot Header:\n")
		fmt.Printf("  Kind:     %s\n", info.IsolateHeader.Kind)
		fmt.Printf("  Size:     %d (0x%x)\n", info.IsolateHeader.TotalSize, info.IsolateHeader.TotalSize)
		fmt.Printf("  Hash:     %s\n", info.IsolateHeader.SnapshotHash)
		fmt.Printf("  Features: %s\n", info.IsolateHeader.Features)
	}

	// Parse instruction image headers for code region info.
	for _, r := range []struct {
		name string
		data []byte
		va   uint64
	}{
		{"VM Instructions", info.VmInstructions.Data, info.VmInstructions.VA},
		{"Isolate Instructions", info.IsolateInstructions.Data, info.IsolateInstructions.VA},
	} {
		if len(r.data) < 16 {
			continue
		}
		imgHdr, err := snapshot.ParseImageHeader(r.data)
		if err != nil {
			continue
		}
		sect, err := snapshot.ParseInstructionsSection(r.data, imgHdr.InstructionsSectionOffset)
		if err != nil {
			continue
		}
		fmt.Printf("\n%s Image:\n", r.name)
		fmt.Printf("  ImageSize=0x%x  InstrSectionOffset=0x%x\n",
			imgHdr.ImageSize, imgHdr.InstructionsSectionOffset)
		fmt.Printf("  PayloadLength=0x%x (%d bytes)\n", sect.PayloadLength, sect.PayloadLength)
		fmt.Printf("  RelocatedAddr=0x%x  CodeStart=VA 0x%x\n",
			sect.InstructionsRelocatedAddress, r.va+sect.CodeOffset)
	}

	if len(info.Diags) > 0 {
		fmt.Printf("\nDiagnostics (%d):\n", len(info.Diags))
		for _, d := range info.Diags {
			fmt.Printf("  %s\n", d)
		}
	}

	return nil
}

```

`cmd/unflutter/signal.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"

	"unflutter/internal/pipeline"
)

func cmdSignal(args []string) error {
	fs := flag.NewFlagSet("signal", flag.ExitOnError)
	inDir := fs.String("in", "", "input directory (disasm output)")
	k := fs.Int("k", 2, "context hops from signal functions")
	noAsm := fs.Bool("no-asm", false, "skip loading asm snippets")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inDir == "" {
		return fmt.Errorf("--in is required")
	}

	_, err := pipeline.RunSignalStage(*inDir, *k, *noAsm, false, os.Stderr)
	return err
}

```

`cmd/unflutter/strings.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"strings"

	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

func cmdStrings(args []string) error {
	fs := flag.NewFlagSet("strings", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	which := fs.String("which", "isolate", "which snapshot: vm, isolate, or both")
	maxLen := fs.Int("max-len", 200, "max display length per string (0 = unlimited)")
	names := fs.Bool("names", false, "extract and display named objects (Function, Class, Library, Script)")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *libapp == "" {
		return fmt.Errorf("--lib is required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}

	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	if info.Version != nil && info.Version.DartVersion != "" {
		fmt.Fprintf(os.Stderr, "Dart SDK version: %s\n", info.Version.DartVersion)
	}
	if info.Version != nil && !info.Version.Supported {
		return fmt.Errorf("HALT_UNSUPPORTED_VERSION: Dart %s (hash %s)", info.Version.DartVersion, info.VmHeader.SnapshotHash)
	}

	type target struct {
		name         string
		data         []byte
		snapshotSize int64
	}
	var targets []target
	switch {
	case *names:
		// Always parse both to build complete ref→string map.
		targets = []target{
			{"VM", info.VmData.Data, info.VmHeader.TotalSize},
			{"Isolate", info.IsolateData.Data, info.IsolateHeader.TotalSize},
		}
	case *which == "vm":
		targets = []target{{"VM", info.VmData.Data, info.VmHeader.TotalSize}}
	case *which == "isolate":
		targets = []target{{"Isolate", info.IsolateData.Data, info.IsolateHeader.TotalSize}}
	default:
		targets = []target{
			{"VM", info.VmData.Data, info.VmHeader.TotalSize},
			{"Isolate", info.IsolateData.Data, info.IsolateHeader.TotalSize},
		}
	}

	// When --names is set, build a combined ref→string map from all snapshots
	// so cross-snapshot refs (e.g., isolate name pointing to VM string) resolve.
	type parsedTarget struct {
		name   string
		result *cluster.Result
	}
	var parsed []parsedTarget

	for _, t := range targets {
		if len(t.data) < 64 {
			fmt.Fprintf(os.Stderr, "%s: data too short (%d bytes)\n", t.name, len(t.data))
			continue
		}

		clusterStart, err := cluster.FindClusterDataStart(t.data)
		if err != nil {
			fmt.Fprintf(os.Stderr, "%s: %v\n", t.name, err)
			continue
		}

		isVM := t.name == "VM"
		result, err := cluster.ScanClusters(t.data, clusterStart, info.Version, isVM, opts)
		if err != nil {
			fmt.Fprintf(os.Stderr, "%s: scan error: %v\n", t.name, err)
			continue
		}

		if *names {
			if err := cluster.ReadFill(t.data, result, info.Version, isVM, t.snapshotSize); err != nil {
				fmt.Fprintf(os.Stderr, "%s: fill error: %v\n", t.name, err)
				continue
			}
		} else {
			if err := cluster.ReadFillStrings(t.data, result, info.Version, isVM, t.snapshotSize); err != nil {
				fmt.Fprintf(os.Stderr, "%s: fill error: %v\n", t.name, err)
				continue
			}
		}

		parsed = append(parsed, parsedTarget{name: t.name, result: result})
	}

	// Build combined ref→string map across all snapshots.
	refToStr := make(map[int]string)
	if *names {
		for _, pt := range parsed {
			for _, ps := range pt.result.Strings {
				refToStr[ps.RefID] = ps.Value
			}
		}
		// Also build ref→named lookup for owner resolution.
		refToNamed := make(map[int]*cluster.NamedObject)
		for _, pt := range parsed {
			for i := range pt.result.Named {
				no := &pt.result.Named[i]
				refToNamed[no.RefID] = no
			}
		}
		// Resolve owner names through the named object chain.
		for _, pt := range parsed {
			for i := range pt.result.Named {
				no := &pt.result.Named[i]
				if no.OwnerRefID >= 0 {
					if owner, ok := refToNamed[no.OwnerRefID]; ok && owner.NameRefID >= 0 {
						if _, ok := refToStr[no.OwnerRefID]; !ok {
							// Store the owner's name string at the owner's ref ID.
							if ownerName, ok := refToStr[owner.NameRefID]; ok {
								refToStr[no.OwnerRefID] = ownerName
							}
						}
					}
				}
			}
		}
	}

	ct := info.Version.CIDs
	for _, pt := range parsed {
		fmt.Printf("%s Strings (%d):\n", pt.name, len(pt.result.Strings))
		for _, ps := range pt.result.Strings {
			display := ps.Value
			display = strings.ReplaceAll(display, "\n", "\\n")
			display = strings.ReplaceAll(display, "\r", "\\r")
			display = strings.ReplaceAll(display, "\t", "\\t")

			truncated := false
			if *maxLen > 0 && len(display) > *maxLen {
				display = display[:*maxLen]
				truncated = true
			}

			enc := "1b"
			if !ps.IsOneByte {
				enc = "2b"
			}

			suffix := ""
			if truncated {
				suffix = "..."
			}
			fmt.Printf("  [ref=%d] (%s) %q%s\n", ps.RefID, enc, display, suffix)
		}

		if *names && len(pt.result.Named) > 0 {
			fmt.Printf("\n%s Named Objects (%d):\n", pt.name, len(pt.result.Named))
			for _, no := range pt.result.Named {
				name := refToStr[no.NameRefID]
				if name == "" {
					name = fmt.Sprintf("<ref:%d>", no.NameRefID)
				}
				cidName := cluster.CidNameV(no.CID, ct)
				if cidName == "" {
					cidName = fmt.Sprintf("CID_%d", no.CID)
				}

				owner := ""
				if no.OwnerRefID >= 0 {
					if ownerName, ok := refToStr[no.OwnerRefID]; ok {
						owner = fmt.Sprintf(" owner=%q", ownerName)
					} else {
						owner = fmt.Sprintf(" owner=<ref:%d>", no.OwnerRefID)
					}
				}

				display := name
				if *maxLen > 0 && len(display) > *maxLen {
					display = display[:*maxLen] + "..."
				}
				fmt.Printf("  [ref=%d] %-20s %q%s\n", no.RefID, cidName, display, owner)
			}
		}
	}

	return nil
}

```

`cmd/unflutter/thr_audit.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"

	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/disasm"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

func cmdTHRAudit(args []string) error {
	fs := flag.NewFlagSet("thr-audit", flag.ExitOnError)
	libapp := fs.String("lib", "", "path to libapp.so")
	outPath := fs.String("out", "", "output JSONL path")
	maxSteps := fs.Int("max-steps", 0, "global loop cap")
	limit := fs.Int("limit", 0, "max functions to scan (0 = all)")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *libapp == "" || *outPath == "" {
		return fmt.Errorf("--lib and --out are required")
	}

	opts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: *maxSteps,
	}

	ef, err := elfx.Open(*libapp)
	if err != nil {
		return fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, opts)
	if err != nil {
		return fmt.Errorf("extract: %w", err)
	}

	dartVersion := ""
	if info.Version != nil {
		dartVersion = info.Version.DartVersion
	}
	fmt.Fprintf(os.Stderr, "Dart SDK version: %s\n", dartVersion)
	if info.Version != nil && !info.Version.Supported {
		return fmt.Errorf("HALT_UNSUPPORTED_VERSION: Dart %s (hash %s)", info.Version.DartVersion, info.VmHeader.SnapshotHash)
	}

	// Parse isolate snapshot clusters + fill.
	data := info.IsolateData.Data
	if len(data) < 64 {
		return fmt.Errorf("isolate data too short (%d bytes)", len(data))
	}

	clusterStart, err := cluster.FindClusterDataStart(data)
	if err != nil {
		return fmt.Errorf("cluster start: %w", err)
	}

	result, err := cluster.ScanClusters(data, clusterStart, info.Version, false, opts)
	if err != nil {
		return fmt.Errorf("scan: %w", err)
	}

	if err := cluster.ReadFill(data, result, info.Version, false, info.IsolateHeader.TotalSize); err != nil {
		return fmt.Errorf("fill: %w", err)
	}

	// Parse instructions table.
	table, err := cluster.ParseInstructionsTable(data, &result.Header, info.Version, info.IsolateHeader)
	if err != nil {
		return fmt.Errorf("instrtable: %w", err)
	}

	ranges, err := cluster.ResolveCodeRanges(result.Codes, table)
	if err != nil {
		return fmt.Errorf("code ranges: %w", err)
	}

	code, codeOff, payloadLen, err := snapshot.CodeRegion(info.IsolateInstructions.Data)
	if err != nil {
		return fmt.Errorf("code region: %w", err)
	}
	codeEndOffset := uint32(codeOff) + uint32(payloadLen)
	cluster.SetLastRangeSize(ranges, codeEndOffset)

	codeVA := info.IsolateInstructions.VA + codeOff

	// Build name lookup.
	refToStr := make(map[int]string)
	for _, ps := range result.Strings {
		refToStr[ps.RefID] = ps.Value
	}

	refToNamed := make(map[int]*cluster.NamedObject)
	for i := range result.Named {
		no := &result.Named[i]
		refToNamed[no.RefID] = no
	}

	resolveName := func(no *cluster.NamedObject) string {
		if no.NameRefID >= 0 {
			if s, ok := refToStr[no.NameRefID]; ok {
				return s
			}
		}
		return ""
	}

	resolveOwnerName := func(no *cluster.NamedObject) string {
		if no.OwnerRefID < 0 {
			return ""
		}
		if owner, ok := refToNamed[no.OwnerRefID]; ok {
			return resolveName(owner)
		}
		return ""
	}

	type codeInfo struct {
		funcName  string
		ownerName string
	}
	codeNames := make(map[int]codeInfo)
	for _, ce := range result.Codes {
		if ce.OwnerRef <= 0 {
			continue
		}
		owner, ok := refToNamed[ce.OwnerRef]
		if !ok {
			continue
		}
		codeNames[ce.RefID] = codeInfo{
			funcName:  resolveName(owner),
			ownerName: resolveOwnerName(owner),
		}
	}

	// Build symbol map.
	symbols := make(map[uint64]string)
	for _, r := range ranges {
		va := codeVA + uint64(r.PCOffset) - codeOff
		ci := codeNames[r.RefID]
		name := qualifiedName(ci.ownerName, ci.funcName, r.PCOffset)
		symbols[va] = name
	}
	lookup := disasm.PlaceholderLookup(symbols)

	// THR fields for resolved marking.
	thrFields := disasm.THRFields(dartVersion)

	// Open output.
	outFile, err := os.Create(*outPath)
	if err != nil {
		return fmt.Errorf("create output: %w", err)
	}
	defer outFile.Close()
	enc := json.NewEncoder(outFile)
	enc.SetEscapeHTML(false)

	// Derive sample name from libapp path.
	sample := *libapp

	n := len(ranges)
	if *limit > 0 && *limit < n {
		n = *limit
	}

	var totalAccesses, resolvedCount, unresolvedCount int

	for i := 0; i < n; i++ {
		r := &ranges[i]
		if r.Size == 0 {
			continue
		}

		funcStart := uint64(r.PCOffset) - codeOff
		funcEnd := funcStart + uint64(r.Size)
		if funcEnd > uint64(len(code)) {
			funcEnd = uint64(len(code))
		}
		if funcStart >= funcEnd {
			continue
		}
		funcCode := code[funcStart:funcEnd]
		funcVA := codeVA + funcStart

		ci := codeNames[r.RefID]
		funcName := qualifiedName(ci.ownerName, ci.funcName, r.PCOffset)

		insts := disasm.Disassemble(funcCode, disasm.Options{
			BaseAddr: funcVA,
			Symbols:  lookup,
		})

		accesses := disasm.ExtractTHRAccesses(insts, thrFields)
		if len(accesses) == 0 {
			continue
		}

		records := disasm.BuildAuditRecords(accesses, insts, sample, dartVersion, funcName)
		for _, rec := range records {
			if err := enc.Encode(rec); err != nil {
				return fmt.Errorf("write record: %w", err)
			}
			totalAccesses++
			if rec.Resolved {
				resolvedCount++
			} else {
				unresolvedCount++
			}
		}
	}

	fmt.Fprintf(os.Stderr, "THR accesses: %d total, %d resolved, %d unresolved\n",
		totalAccesses, resolvedCount, unresolvedCount)
	fmt.Fprintf(os.Stderr, "wrote %s\n", *outPath)

	return nil
}

```

`cmd/unflutter/thr_classify.go`:

```go
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/disasm"
)

func cmdTHRClassify(args []string) error {
	fs := flag.NewFlagSet("thr-classify", flag.ExitOnError)
	inputPath := fs.String("in", "", "input thr_loads.jsonl path")
	outDir := fs.String("out", "", "output directory")
	maxGap := fs.Int("max-gap", 0x18, "max gap between offsets before splitting bands")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inputPath == "" || *outDir == "" {
		return fmt.Errorf("--in and --out are required")
	}

	// Read audit records.
	f, err := os.Open(*inputPath)
	if err != nil {
		return fmt.Errorf("open input: %w", err)
	}
	defer f.Close()

	records, err := disasm.ReadAuditRecords(f)
	if err != nil {
		return fmt.Errorf("read records: %w", err)
	}

	// Cluster into bands.
	bands := disasm.ClusterBands(records, *maxGap)

	// Classify.
	classified := disasm.ClassifyRecords(records, bands)

	// Create output directory.
	if err := os.MkdirAll(*outDir, 0755); err != nil {
		return fmt.Errorf("mkdir: %w", err)
	}

	// Write classified.jsonl.
	classPath := filepath.Join(*outDir, "classified.jsonl")
	cf, err := os.Create(classPath)
	if err != nil {
		return fmt.Errorf("create classified: %w", err)
	}
	defer cf.Close()
	enc := json.NewEncoder(cf)
	enc.SetEscapeHTML(false)
	for _, cr := range classified {
		if err := enc.Encode(cr); err != nil {
			return fmt.Errorf("write classified: %w", err)
		}
	}

	// Build and print summary.
	summary := disasm.Summarize(classified)

	fmt.Fprintf(os.Stderr, "%s (Dart %s): %d unresolved\n",
		summary.Sample, summary.DartVersion, summary.Total)

	classes := []disasm.THRClass{
		disasm.ClassRuntimeEntrypoint,
		disasm.ClassObjectStoreCache,
		disasm.ClassIsolateGroupPtr,
		disasm.ClassUnknown,
	}
	for _, cls := range classes {
		count := summary.Counts[cls]
		pct := 0.0
		if summary.Total > 0 {
			pct = float64(count) / float64(summary.Total) * 100
		}
		fmt.Fprintf(os.Stderr, "  %-30s %4d (%5.1f%%)\n", cls, count, pct)
	}

	fmt.Fprintf(os.Stderr, "wrote %s\n", classPath)

	return nil
}

```

`cmd/unflutter/thr_cluster.go`:

```go
package main

import (
	"flag"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/disasm"
)

func cmdTHRCluster(args []string) error {
	fs := flag.NewFlagSet("thr-cluster", flag.ExitOnError)
	inputPath := fs.String("in", "", "input thr_loads.jsonl path")
	outDir := fs.String("out", "", "output directory for bands.json and bands.md")
	maxGap := fs.Int("max-gap", 0x18, "max gap between offsets before splitting bands")

	if err := fs.Parse(args); err != nil {
		return err
	}
	if *inputPath == "" || *outDir == "" {
		return fmt.Errorf("--in and --out are required")
	}

	// Read audit records.
	f, err := os.Open(*inputPath)
	if err != nil {
		return fmt.Errorf("open input: %w", err)
	}
	defer f.Close()

	records, err := disasm.ReadAuditRecords(f)
	if err != nil {
		return fmt.Errorf("read records: %w", err)
	}

	// Cluster into bands.
	br := disasm.ClusterBands(records, *maxGap)

	// Create output directory.
	if err := os.MkdirAll(*outDir, 0755); err != nil {
		return fmt.Errorf("mkdir: %w", err)
	}

	// Write bands.json.
	jsonPath := filepath.Join(*outDir, "bands.json")
	jf, err := os.Create(jsonPath)
	if err != nil {
		return fmt.Errorf("create json: %w", err)
	}
	defer jf.Close()
	if err := disasm.WriteBandsJSON(jf, br); err != nil {
		return fmt.Errorf("write json: %w", err)
	}

	// Write bands.md.
	mdPath := filepath.Join(*outDir, "bands.md")
	mf, err := os.Create(mdPath)
	if err != nil {
		return fmt.Errorf("create md: %w", err)
	}
	defer mf.Close()
	disasm.WriteBandsMD(mf, br)

	fmt.Fprintf(os.Stderr, "%s: %d bands from %d unresolved accesses\n",
		br.Sample, len(br.Bands), br.TotalUnresolved)
	fmt.Fprintf(os.Stderr, "wrote %s\n", jsonPath)
	fmt.Fprintf(os.Stderr, "wrote %s\n", mdPath)

	return nil
}

```

`ghidra_scripts/AARCH64_dart.cspec`:

```cspec
<?xml version="1.0" encoding="UTF-8"?>
<!-- AARCH64_dart.cspec — Dart AOT calling convention for ARM64
     Derived from AARCH64.cspec (standard ARM64 EABI).

     Dart AOT register conventions:
       X0-X7:  Parameter passing (standard ARM64)
       X15:    Dart shadow call stack / stack cache (NOT killed by calls)
       X21:    Dispatch table pointer (global, callee-saved)
       X26:    Thread pointer (THR) — global context, never modified
       X27:    Object pool pointer (PP) — per-function, callee-saved
       X28:    Heap base (compressed pointer decompression)
       X29:    Frame pointer
       X30:    Link register

     Key differences from standard AARCH64.cspec:
       - X15 moved from killedbycall to unaffected (Dart uses as stack cache)
       - All Dart runtime registers (X21, X26, X27, X28) remain unaffected
-->

<compiler_spec>
  <data_organization>
     <absolute_max_alignment value="0" />
     <machine_alignment value="4" />
     <default_alignment value="1" />
     <default_pointer_alignment value="8" />
     <pointer_size value="8" />
     <wchar_size value="4" />
     <short_size value="2" />
     <integer_size value="4" />
     <long_size value="8" />
     <long_long_size value="8" />
     <float_size value="4" />
     <double_size value="8" />
     <long_double_size value="8" />
     <size_alignment_map>
          <entry size="1" alignment="1" />
          <entry size="2" alignment="2" />
          <entry size="4" alignment="4" />
          <entry size="8" alignment="8" />
          <entry size="16" alignment="16"/>
     </size_alignment_map>
  </data_organization>

  <global>
    <range space="ram"/>
  </global>

  <stackpointer register="sp" space="ram"/>
  <funcptr align="4"/>

  <prefersplit style="inhalf">
    <register name="q0"/>
    <register name="q1"/>
    <register name="q2"/>
    <register name="q3"/>
    <register name="q4"/>
    <register name="q5"/>
    <register name="q6"/>
    <register name="q7"/>
    <register name="q8"/>
    <register name="q9"/>
    <register name="q10"/>
    <register name="q11"/>
    <register name="q12"/>
    <register name="q13"/>
    <register name="q14"/>
    <register name="q15"/>
    <register name="q16"/>
    <register name="q17"/>
    <register name="q18"/>
    <register name="q19"/>
    <register name="q20"/>
    <register name="q21"/>
    <register name="q22"/>
    <register name="q23"/>
    <register name="q24"/>
    <register name="q25"/>
    <register name="q26"/>
    <register name="q27"/>
    <register name="q28"/>
    <register name="q29"/>
    <register name="q30"/>
  </prefersplit>

  <default_proto>
    <prototype name="__dartcall" extrapop="0" stackshift="0">
      <input>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x0"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x1"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x2"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x3"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x4"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x5"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x6"/>
        </pentry>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x7"/>
        </pentry>
        <pentry minsize="1" maxsize="500" align="8">
          <addr offset="0" space="stack"/>
        </pentry>
      </input>
      <output>
        <pentry minsize="1" maxsize="8" extension="zero">
          <register name="x0"/>
        </pentry>
      </output>
      <unaffected>
        <!-- Dart shadow call stack — NOT killed by calls (unlike standard ARM64) -->
        <register name="x15"/>
        <!-- Standard callee-saved -->
        <register name="x19"/>
        <register name="x20"/>
        <!-- Dart dispatch table pointer -->
        <register name="x21"/>
        <register name="x22"/>
        <register name="x23"/>
        <register name="x24"/>
        <register name="x25"/>
        <!-- Dart thread pointer (THR) -->
        <register name="x26"/>
        <!-- Dart object pool pointer (PP) -->
        <register name="x27"/>
        <!-- Dart heap base (compressed pointer decompression) -->
        <register name="x28"/>
        <register name="x29"/>
        <register name="x30"/>
        <register name="sp"/>
        <!-- vectors -->
        <register name="d8"/>
        <register name="d9"/>
        <register name="d10"/>
        <register name="d11"/>
        <register name="d12"/>
        <register name="d13"/>
        <register name="d14"/>
        <register name="d15"/>
      </unaffected>
      <killedbycall>
        <register name="x8"/>
        <register name="x9"/>
        <register name="x10"/>
        <register name="x11"/>
        <register name="x12"/>
        <register name="x13"/>
        <register name="x14"/>
        <!-- X15 intentionally NOT here — Dart uses it as stack cache -->
        <register name="x16"/>
        <register name="x17"/>
        <register name="x18"/>
        <!-- vectors -->
        <register name="d16"/>
        <register name="d17"/>
        <register name="d18"/>
        <register name="d19"/>
        <register name="d20"/>
        <register name="d21"/>
        <register name="d22"/>
        <register name="d23"/>
        <register name="d24"/>
        <register name="d25"/>
        <register name="d26"/>
        <register name="d27"/>
        <register name="d28"/>
        <register name="d29"/>
        <register name="d30"/>
        <register name="d31"/>
      </killedbycall>
    </prototype>
  </default_proto>

  <callfixup name="PlaceHolderCallFixup">
    <target name="___NotARealFunctionName___"/>
    <pcode>
      <body><![CDATA[
            tmpptr:4 = 0;
      ]]></body>
    </pcode>
  </callfixup>

</compiler_spec>

```

`ghidra_scripts/unflutter_apply.py`:

```py
# -*- coding: utf-8 -*-
# unflutter_apply.py - Ghidra headless postScript
#
# Reads flutter_meta.json produced by `unflutter meta`, applies:
#   1. Function creation + renaming
#   2. Struct types for Dart classes + typed function signatures
#   3. EOL comments (THR fields, PP pool references)
#   4. Selective decompilation export for signal (focus) functions
#
# Usage (headless):
#   analyzeHeadless <project_dir> <project_name> \
#       -import <libapp.so> -overwrite \
#       -scriptPath <path_to_this_dir> \
#       -preScript unflutter_prescript.py \
#       -postScript unflutter_apply.py <flutter_meta.json> [<output_dir>]
#
# Script args:
#   arg[0]: path to flutter_meta.json (required)
#   arg[1]: output directory for decompiled .c files (optional)

import json
import os

from ghidra.program.model.symbol import SourceType
from ghidra.program.model.data import (
    Pointer64DataType, Pointer32DataType, PointerDataType,
    StructureDataType, CategoryPath, VoidDataType, LongDataType,
    IntegerDataType,
)
from ghidra.program.model.listing import ParameterImpl
from ghidra.program.model.listing import Function as GhidraFunction
from java.util import ArrayList
from ghidra.app.decompiler import DecompInterface

try:
    from ghidra.program.model.pcode import HighFunctionDBUtil
    HAS_HFDB_UTIL = True
except:
    HAS_HFDB_UTIL = False

try:
    from ghidra.program.model.data import DataTypeConflictHandler
    REPLACE_HANDLER = DataTypeConflictHandler.REPLACE_HANDLER
except:
    REPLACE_HANDLER = None


def resolve_meta_path(args):
    """Resolve flutter_meta.json path from script args or relative to this script."""
    if args and len(args) >= 1 and args[0]:
        return args[0]
    # Standalone mode: look for ../flutter_meta.json relative to this script.
    try:
        script_dir = os.path.dirname(os.path.abspath(sourceFile.getAbsolutePath()))
    except:
        script_dir = os.path.dirname(os.path.abspath(__file__))
    candidate = os.path.join(script_dir, "..", "flutter_meta.json")
    if os.path.exists(candidate):
        return candidate
    raise RuntimeError(
        "flutter_meta.json not found. Pass as script argument or place this script in <output>/ghidra/"
    )


def main():
    args = getScriptArgs()
    try:
        meta_path = resolve_meta_path(args)
    except RuntimeError as e:
        println("ERROR: %s" % str(e))
        return
    out_dir = args[1] if len(args) > 1 else None

    println("unflutter_apply: loading %s" % meta_path)

    with open(meta_path, "r") as f:
        meta = json.load(f)

    stats = {
        "functions": len(meta.get("functions", [])),
        "renamed": 0,
        "created": 0,
        "create_failed": 0,
        "labels": 0,
        "comments": 0,
        "comment_failed": 0,
        "decompiled": 0,
        "decompile_failed": 0,
    }

    fm = currentProgram.getFunctionManager()
    listing = currentProgram.getListing()
    symtab = currentProgram.getSymbolTable()

    # Detect image base: Ghidra rebases shared objects (typically +0x100000).
    mem = currentProgram.getMemory()
    image_base = currentProgram.getImageBase().getOffset()
    println("  image base: 0x%x" % image_base)

    # Determine pointer size from metadata (compressed pointers = 4 bytes).
    pointer_size = meta.get("pointer_size", 8)
    println("  pointer_size: %d" % pointer_size)

    # ptr_type = pointer to void (for return types, params — always 8 bytes in AArch64).
    # PointerDataType(VoidDataType()) renders as "void *" instead of "undefined *".
    ptr_type = PointerDataType(VoidDataType())

    # field_type = type used for Dart object fields inside structs.
    # With compressed pointers (4 bytes), fields are 32-bit pointers.
    # Without compression (8 bytes), fields are 64-bit pointers.
    if pointer_size == 4:
        field_type = Pointer32DataType()
    else:
        field_type = PointerDataType(VoidDataType())

    # Phase 1a: Force disassembly at all function addresses.
    # Ghidra's auto-analysis skips Dart AOT code (no standard prologues).
    println("Phase 1a: disassembling at %d addresses..." % stats["functions"])
    disasm_ok = 0
    disasm_fail = 0
    for entry in meta.get("functions", []):
        addr_int = int(entry["addr"], 16) + image_base
        addr = toAddr(addr_int)
        if listing.getInstructionAt(addr) is not None:
            disasm_ok += 1
            continue
        try:
            clearListing(addr)
            disassemble(addr)
            if listing.getInstructionAt(addr) is not None:
                disasm_ok += 1
            else:
                disasm_fail += 1
        except:
            disasm_fail += 1
    println("  disassembled=%d failed=%d" % (disasm_ok, disasm_fail))

    # Phase 1b: Create/rename functions.
    println("Phase 1b: creating/renaming %d functions..." % stats["functions"])
    for entry in meta.get("functions", []):
        addr_int = int(entry["addr"], 16) + image_base
        addr = toAddr(addr_int)
        name = entry["name"]

        fn = fm.getFunctionAt(addr)
        if fn is not None:
            try:
                fn.setName(name, SourceType.USER_DEFINED)
                stats["renamed"] += 1
            except:
                pass
            continue

        # Try to create function.
        try:
            fn = createFunction(addr, name)
            if fn is not None:
                stats["created"] += 1
                continue
        except:
            pass

        # Fallback: disassemble at the address, then try again.
        try:
            disassemble(addr)
            fn = createFunction(addr, name)
            if fn is not None:
                stats["created"] += 1
                continue
        except:
            pass

        # Last resort: create a label so the name appears.
        try:
            symtab.createLabel(addr, name, SourceType.USER_DEFINED)
            stats["labels"] += 1
        except:
            stats["create_failed"] += 1

    println("  created=%d renamed=%d labels=%d failed=%d" % (
        stats["created"], stats["renamed"], stats["labels"], stats["create_failed"]))

    # Verify: count how many functions exist now at our addresses.
    verify_count = 0
    for entry in meta.get("functions", []):
        addr = toAddr(int(entry["addr"], 16) + image_base)
        if fm.getFunctionAt(addr) is not None:
            verify_count += 1
    println("  verified: %d/%d addresses have functions" % (verify_count, stats["functions"]))

    # Phase 1c: Create struct types for Dart classes.
    # Must run BEFORE param application so typed 'this' pointers can reference structs.
    classes = meta.get("classes", [])
    struct_by_owner = {}  # class_name -> Ghidra DataType
    if classes:
        println("Phase 1c: creating %d class struct types..." % len(classes))
        dtm = currentProgram.getDataTypeManager()
        cat = CategoryPath("/DartClasses")
        struct_created = 0
        struct_failed = 0

        for cls in classes:
            try:
                cname = cls["class_name"]
                sname = "Dart_" + sanitize(cname)
                size = cls["instance_size"]
                if size <= 0:
                    continue
                fields = cls.get("fields", [])

                struct_dt = StructureDataType(cat, sname, size)
                for field in fields:
                    offset = field["byte_offset"]
                    fname = field["name"]
                    if offset >= 0 and offset + pointer_size <= size:
                        struct_dt.replaceAtOffset(offset, field_type, pointer_size, fname, "")

                resolved = dtm.addDataType(struct_dt, REPLACE_HANDLER)
                struct_by_owner[cname] = resolved
                struct_created += 1
            except Exception as e:
                struct_failed += 1
                if struct_failed <= 5:
                    println("  WARN: struct %s: %s" % (cls.get("class_name", "?"), str(e)[:80]))

        println("  structs created=%d failed=%d (lookup=%d)" % (struct_created, struct_failed, len(struct_by_owner)))
    else:
        println("Phase 1c: skipped (no class layouts)")

    # Phase 1c2: Create DartThread struct from THR fields.
    thr_fields = meta.get("thr_fields", [])
    if thr_fields:
        println("Phase 1c2: creating DartThread struct (%d fields)..." % len(thr_fields))
        dtm = currentProgram.getDataTypeManager()
        cat = CategoryPath("/DartClasses")
        try:
            # Find max offset to determine struct size.
            max_off = max(f["offset"] for f in thr_fields)
            thr_size = max_off + 8  # last field is a pointer
            thr_dt = StructureDataType(cat, "DartThread", thr_size)
            thr_placed = 0
            for tf in thr_fields:
                off = tf["offset"]
                tname = tf["name"]
                if off >= 0 and off + 8 <= thr_size:
                    thr_dt.replaceAtOffset(off, ptr_type, 8, tname, "")
                    thr_placed += 1
            dtm.addDataType(thr_dt, REPLACE_HANDLER)
            println("  DartThread: %d/%d fields placed (size=%d)" % (thr_placed, len(thr_fields), thr_size))
        except Exception as e:
            println("  WARN: DartThread creation failed: %s" % str(e)[:120])
    else:
        println("Phase 1c2: skipped (no THR fields)")

    # Prepare DartThread* type for register retyping in decompiler output.
    # When x26 is typed as DartThread*, the decompiler resolves
    # *(long *)(unaff_x26 + 0x38) → THR->stack_limit automatically.
    dart_thread_ptr_dt = None
    if thr_fields and HAS_HFDB_UTIL:
        dtm_check = currentProgram.getDataTypeManager()
        resolved = dtm_check.getDataType(CategoryPath("/DartClasses"), "DartThread")
        if resolved:
            dart_thread_ptr_dt = PointerDataType(resolved)
            println("  DartThread* ready for register retyping")

    # Phase 1d: Apply function signatures (typed parameters + return type).
    # For methods (functions with an owner class):
    #   - First param = this: Dart_OwnerClass* (typed pointer to owner struct)
    #   - Remaining params = generic pointers
    # For all functions:
    #   - Calling convention = __dartcall (registered by prescript via SpecExtension)
    #   - Return type = pointer (Dart functions return objects, not undefined)
    println("Phase 1d: applying function signatures...")
    sig_applied = 0
    sig_failed = 0
    ret_applied = 0
    this_typed = 0
    for entry in meta.get("functions", []):
        addr = toAddr(int(entry["addr"], 16) + image_base)
        fn = fm.getFunctionAt(addr)
        if fn is None:
            continue

        owner = entry.get("owner", "")
        pc = entry.get("param_count", 0)

        # Set calling convention to __dartcall (registered by prescript).
        # Must happen BEFORE replaceParameters to avoid "Unknown calling convention" warning.
        try:
            fn.setCallingConventionName("__dartcall")
        except:
            pass

        # Set return type to pointer (Dart returns objects, not undefined).
        try:
            fn.setReturnType(ptr_type, SourceType.USER_DEFINED)
            ret_applied += 1
        except:
            pass

        # Build parameter list (ArrayList for JPype/PyGhidra overload resolution).
        params = ArrayList()

        # Methods get typed 'this' as first parameter.
        # param_count excludes implicit 'this', so we add it separately.
        if owner:
            if owner in struct_by_owner:
                this_dt = PointerDataType(struct_by_owner[owner])
                this_typed += 1
            else:
                this_dt = ptr_type
            params.add(ParameterImpl("this", this_dt, currentProgram))

        # Explicit parameters.
        for i in range(pc):
            params.add(ParameterImpl("p%d" % i, ptr_type, currentProgram))

        if params.size() == 0:
            continue

        try:
            fn.replaceParameters(params,
                GhidraFunction.FunctionUpdateType.DYNAMIC_STORAGE_ALL_PARAMS,
                True, SourceType.USER_DEFINED)
            sig_applied += 1
        except Exception as e:
            sig_failed += 1
            if sig_failed <= 3:
                println("  WARN: replaceParameters failed for %s: %s" % (entry.get("name", "?"), str(e)[:120]))

    println("  signatures applied=%d failed=%d return_types=%d this_typed=%d" % (
        sig_applied, sig_failed, ret_applied, this_typed))

    # Phase 2: Set EOL comments.
    comment_entries = meta.get("comments", [])
    println("Phase 2: setting %d comments..." % len(comment_entries))
    for entry in comment_entries:
        addr_int = int(entry["addr"], 16) + image_base
        addr = toAddr(addr_int)
        text = entry["text"]
        try:
            setEOLComment(addr, text)
            stats["comments"] += 1
        except:
            stats["comment_failed"] += 1

    println("  set=%d failed=%d" % (stats["comments"], stats["comment_failed"]))

    # Phase 3: Selective decompilation.
    # Build addr → owner lookup for directory grouping.
    owner_by_addr = {}
    for entry in meta.get("functions", []):
        owner = entry.get("owner", "")
        if owner:
            owner_by_addr[entry["addr"]] = owner

    focus = meta.get("focus_functions", [])
    if out_dir and focus:
        println("Phase 3: decompiling %d focus functions..." % len(focus))
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)

        ifc = DecompInterface()
        ifc.openProgram(currentProgram)

        index = []
        not_found = 0
        for addr_str in focus:
            addr_int = int(addr_str, 16) + image_base
            addr = toAddr(addr_int)

            # Try exact match first, then containing.
            fn = fm.getFunctionAt(addr)
            if fn is None:
                fn = fm.getFunctionContaining(addr)

            if fn is None:
                not_found += 1
                if not_found <= 5:
                    println("  WARN: no function at %s" % addr_str)
                index.append({
                    "addr": addr_str,
                    "name": "unknown",
                    "file": None,
                    "decompile_ok": False,
                    "reason": "no_function",
                })
                stats["decompile_failed"] += 1
                continue

            fn_name = fn.getName()
            try:
                result = ifc.decompileFunction(fn, 60, monitor)
            except Exception as e:
                index.append({
                    "addr": addr_str,
                    "name": fn_name,
                    "file": None,
                    "decompile_ok": False,
                    "reason": str(e)[:100],
                })
                stats["decompile_failed"] += 1
                continue

            # Retype Dart registers for readable decompiler output:
            #   x26 → THR (DartThread*)  — resolves field accesses
            #   x27 → PP               — object pool pointer
            #   x28 → HEAP_BASE        — compressed pointer base
            #   x15 → SHADOW_SP        — Dart shadow call stack
            if result and result.decompileCompleted() and HAS_HFDB_UTIL:
                hfunc = result.getHighFunction()
                if hfunc:
                    retyped = _retype_dart_registers(
                        hfunc, dart_thread_ptr_dt, ptr_type)
                    if retyped:
                        try:
                            result = ifc.decompileFunction(fn, 60, monitor)
                        except:
                            pass

            if result and result.decompileCompleted():
                decomp = result.getDecompiledFunction()
                if decomp:
                    c_code = decomp.getC()
                    # Strip cosmetic warning from SpecExtension-registered CC.
                    # The native decompiler doesn't receive SpecExtension CCs,
                    # so it flags __dartcall as unknown. The CC works functionally.
                    c_code = c_code.replace(
                        "/* WARNING: Unknown calling convention -- yet parameter storage is locked */\n\n", "")
                    c_code = c_code.replace(
                        "/* WARNING: Unknown calling convention -- yet parameter storage is locked */\n", "")
                    safe_name = addr_str.replace("0x", "") + "_" + sanitize(fn_name)
                    # Use owner-based subdirectory if available.
                    owner = owner_by_addr.get(addr_str, "")
                    if owner:
                        sub_dir = os.path.join(out_dir, sanitize(owner))
                        if not os.path.exists(sub_dir):
                            os.makedirs(sub_dir)
                        out_file = os.path.join(sanitize(owner), safe_name + ".c")
                    else:
                        out_file = safe_name + ".c"
                    out_path = os.path.join(out_dir, out_file)
                    with open(out_path, "w") as cf:
                        cf.write(c_code)
                    index.append({
                        "addr": addr_str,
                        "name": fn_name,
                        "file": out_file,
                        "decompile_ok": True,
                    })
                    stats["decompiled"] += 1
                    continue

            reason = "decompile_incomplete"
            if result:
                err_msg = result.getErrorMessage()
                if err_msg:
                    reason = err_msg[:100]

            index.append({
                "addr": addr_str,
                "name": fn_name,
                "file": None,
                "decompile_ok": False,
                "reason": reason,
            })
            stats["decompile_failed"] += 1

        if not_found > 0:
            println("  %d focus functions not found" % not_found)

        ifc.dispose()

        # Write index.json.
        index_path = os.path.join(out_dir, "index.json")
        with open(index_path, "w") as idx:
            json.dump(index, idx, indent=2)
        println("  decompiled=%d failed=%d" % (stats["decompiled"], stats["decompile_failed"]))
    elif focus:
        println("Phase 3: skipped (no output directory specified)")
    else:
        println("Phase 3: skipped (no focus functions)")

    # Summary.
    println("UNFLUTTER_APPLY: functions=%d renamed=%d created=%d labels=%d comments=%d decompiled=%d failed=%d" % (
        stats["functions"],
        stats["renamed"],
        stats["created"],
        stats["labels"],
        stats["comments"],
        stats["decompiled"],
        stats["decompile_failed"],
    ))


def _retype_dart_registers(hfunc, dart_thread_ptr_dt, ptr_type):
    """Retype Dart-specific unaffected registers for readable decompiler output.

    Renames and types:
      x15 → SHADOW_SP   (long*)  Dart shadow call stack
      x21 → DT          (long)  dispatch table pointer
      x22 → DART_NULL   (long)  Dart null object
      x26 → THR         (DartThread*)  resolves struct field accesses
      x27 → PP          (long*)  object pool pointer (indexed)
      x28 → HEAP_BASE   (long)  compressed pointer base
      x29 → FP          (long)  frame pointer
      x30 → LR          (long)  link register / return address

    Also handles 32-bit subregister variants (w22, etc.) and Ghidra's
    internal register-space names (unaff_000040b4 = upper half of x22).

    Returns True if any symbols were retyped (caller should re-decompile).
    """
    long_type = LongDataType()
    int_type = IntegerDataType()  # 4 bytes — for w-regs and upper halves
    long_ptr_type = PointerDataType(long_type)  # long * — for stack/pool pointers

    # Map unaff_/in_ names to (readable_name, type).
    # None type = keep existing type.
    RENAMES = {
        # 64-bit registers — typed to eliminate undefined8
        "unaff_x15": ("SHADOW_SP",    long_ptr_type),  # Dart shadow stack
        "unaff_x21": ("DT",           long_type),
        "unaff_x22": ("DART_NULL",    long_type),
        "unaff_x26": ("THR",          dart_thread_ptr_dt),  # DartThread*
        "unaff_x27": ("PP",           long_ptr_type),  # pool pointer — indexed
        "unaff_x28": ("HEAP_BASE",    long_type),
        "unaff_x29": ("FP",           long_type),
        "unaff_x30": ("LR",           long_type),
        # 32-bit subregister variants (w-regs) — typed as int to eliminate undefined4
        "unaff_w15": ("SHADOW_SP",    int_type),
        "unaff_w21": ("DT",           int_type),
        "unaff_w22": ("DART_NULL",    int_type),
        "unaff_w26": ("THR",          int_type),
        "unaff_w27": ("PP",           int_type),
        "unaff_w28": ("HEAP_BASE",    int_type),
        "unaff_w29": ("FP",           int_type),
        "unaff_w30": ("LR",           int_type),
        # Upper 32-bit halves (Ghidra register-space offsets)
        # These are internal split-register names — type as int
        "unaff_000040b4":         ("DART_NULL_HI", int_type),   # upper x22
        "in_register_00004004":   ("x0_HI",        int_type),   # upper x0
        "in_register_0000400c":   ("x1_HI",        int_type),   # upper x1
        "in_register_00004014":   ("x2_HI",        int_type),   # upper x2
        "in_register_0000401c":   ("x3_HI",        int_type),   # upper x3
        "in_register_00004024":   ("x4_HI",        int_type),   # upper x4
        "in_register_0000402c":   ("x5_HI",        int_type),   # upper x5
        "in_register_00004034":   ("x6_HI",        int_type),   # upper x6
        "in_register_0000403c":   ("x7_HI",        int_type),   # upper x7
        # 32-bit parameter in-registers (w0-w7)
        "in_w0":  ("p0",    int_type),
        "in_w1":  ("p1",    int_type),
        "in_w2":  ("p2",    int_type),
        "in_w3":  ("p3",    int_type),
        "in_w4":  ("p4",    int_type),
        "in_w5":  ("p5",    int_type),
        "in_w6":  ("p6",    int_type),
        "in_w7":  ("p7",    int_type),
    }

    did_retype = False
    lsm = hfunc.getLocalSymbolMap()
    # Snapshot the iterator to avoid ConcurrentModificationException.
    symbols = list(lsm.getSymbols())
    for sym in symbols:
        entry = RENAMES.get(sym.getName())
        if entry is None:
            continue
        new_name, new_dt = entry
        try:
            dt = new_dt if new_dt else sym.getDataType()
            HighFunctionDBUtil.updateDBVariable(
                sym, new_name, dt, SourceType.USER_DEFINED)
            did_retype = True
        except:
            pass
    return did_retype


def sanitize(name):
    """Sanitize a function name for use as a filename."""
    out = []
    for ch in name:
        if ch.isalnum() or ch in ("_", "-", "."):
            out.append(ch)
        else:
            out.append("_")
    s = "".join(out)
    if len(s) > 120:
        s = s[:120]
    return s


main()

```

`ghidra_scripts/unflutter_prescript.py`:

```py
# -*- coding: utf-8 -*-
# unflutter_prescript.py - Ghidra headless preScript
#
# Configures analysis options before Ghidra auto-analysis runs.
# Dart AOT binaries have patterns that confuse standard analyzers:
#   - No standard ARM64 function prologues (Dart uses unchecked entry +0x18)
#   - BLR X21 dispatch table calls (not switch tables)
#   - Dense data sections interleaved with code
#
# Registers the __dartcall calling convention via SpecExtension and sets it
# as the program-wide default, so no modification of Ghidra installation
# files is needed.
#
# Usage:
#   analyzeHeadless ... -preScript unflutter_prescript.py -postScript unflutter_apply.py ...

from ghidra.program.database import SpecExtension

# Dart AOT calling convention for ARM64.
# Key difference from standard __cdecl:
#   - X15 in <unaffected> (Dart shadow call stack / stack cache)
#   - X21, X26 (THR), X27 (PP), X28 (heap base) all <unaffected>
DART_PROTO_XML = """\
<prototype name="__dartcall" extrapop="0" stackshift="0">
  <input>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x0"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x1"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x2"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x3"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x4"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x5"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x6"/></pentry>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x7"/></pentry>
    <pentry minsize="1" maxsize="500" align="8"><addr offset="0" space="stack"/></pentry>
  </input>
  <output>
    <pentry minsize="1" maxsize="8" extension="zero"><register name="x0"/></pentry>
  </output>
  <unaffected>
    <register name="x15"/>
    <register name="x19"/>
    <register name="x20"/>
    <register name="x21"/>
    <register name="x22"/>
    <register name="x23"/>
    <register name="x24"/>
    <register name="x25"/>
    <register name="x26"/>
    <register name="x27"/>
    <register name="x28"/>
    <register name="x29"/>
    <register name="x30"/>
    <register name="sp"/>
    <register name="d8"/>
    <register name="d9"/>
    <register name="d10"/>
    <register name="d11"/>
    <register name="d12"/>
    <register name="d13"/>
    <register name="d14"/>
    <register name="d15"/>
  </unaffected>
  <killedbycall>
    <register name="x8"/>
    <register name="x9"/>
    <register name="x10"/>
    <register name="x11"/>
    <register name="x12"/>
    <register name="x13"/>
    <register name="x14"/>
    <register name="x16"/>
    <register name="x17"/>
    <register name="x18"/>
    <register name="d16"/>
    <register name="d17"/>
    <register name="d18"/>
    <register name="d19"/>
    <register name="d20"/>
    <register name="d21"/>
    <register name="d22"/>
    <register name="d23"/>
    <register name="d24"/>
    <register name="d25"/>
    <register name="d26"/>
    <register name="d27"/>
    <register name="d28"/>
    <register name="d29"/>
    <register name="d30"/>
    <register name="d31"/>
  </killedbycall>
</prototype>
"""


def main():
    println("unflutter_prescript: configuring analysis for Dart AOT binary")

    # Step 1: Register __dartcall as a new calling convention via SpecExtension.
    try:
        spec_ext = SpecExtension(currentProgram)
        spec_ext.addReplaceCompilerSpecExtension(DART_PROTO_XML, monitor)
        println("  registered __dartcall calling convention")
    except Exception as e:
        println("  WARN: could not register __dartcall: %s" % str(e)[:120])

    # Step 2: Make __dartcall the program-wide default calling convention.
    # SpecExtension can't replace __cdecl (Ghidra blocks it), so we use
    # reflection to swap the defaultModel pointer. This ensures ALL call
    # targets (including unnamed stubs) use dart register classification,
    # eliminating extraout_x15 globally.
    try:
        cspec = currentProgram.getCompilerSpec()
        dartcall = cspec.getCallingConvention("__dartcall")
        if dartcall is not None:
            # BasicCompilerSpec has three prototype model fields that control
            # how the decompiler treats function calls:
            #   defaultModel     — default calling convention for new functions
            #   evalCurrentModel — prototype used to evaluate the current function
            #   evalCalledModel  — prototype used to evaluate CALLED functions
            # All three must point to __dartcall, otherwise the decompiler
            # will still use __cdecl (with X15 in killedbycall) for calls
            # to unknown targets, producing extraout_x15.
            base_class = cspec.getClass().getSuperclass()
            for field_name in ("defaultModel", "evalCurrentModel", "evalCalledModel"):
                f = base_class.getDeclaredField(field_name)
                f.setAccessible(True)
                f.set(cspec, dartcall)
            println("  set __dartcall as program default calling convention")
        else:
            println("  WARN: __dartcall not found after registration")
    except Exception as e:
        println("  WARN: could not set default CC: %s" % str(e)[:120])

    # Dart AOT doesn't use standard ARM64 prologues, so the aggressive
    # instruction finder creates false function starts in data regions.
    try:
        setAnalysisOption(currentProgram, "Aggressive Instruction Finder", "false")
        println("  disabled: Aggressive Instruction Finder")
    except Exception as e:
        println("  WARN: could not disable Aggressive Instruction Finder: %s" % str(e)[:60])

    # Dart functions don't follow standard non-return conventions.
    # The discovered non-returning analysis propagates incorrect assumptions.
    try:
        setAnalysisOption(currentProgram, "Non-Returning Functions - Discovered", "false")
        println("  disabled: Non-Returning Functions - Discovered")
    except Exception as e:
        println("  WARN: could not disable Non-Returning Functions - Discovered: %s" % str(e)[:60])

    println("unflutter_prescript: done")


main()

```

`go.mod`:

```mod
module unflutter

go 1.25.4

require (
	github.com/zboralski/lattice v0.1.0
	golang.org/x/arch v0.23.0
)

```

`go.sum`:

```sum
github.com/zboralski/lattice v0.1.0 h1:XUShKXaj9xL/RPx+a8ktFi/cJVNWYAHrEM5Z1BUuKD0=
github.com/zboralski/lattice v0.1.0/go.mod h1:NPS/ujKSnKORFtvgeynxz4U8uyyBkuD7voYnI2JwIMQ=
golang.org/x/arch v0.23.0 h1:lKF64A2jF6Zd8L0knGltUnegD62JMFBiCPBmQpToHhg=
golang.org/x/arch v0.23.0/go.mod h1:dNHoOeKiyja7GTvF9NJS1l3Z2yntpQNzgrjh1cU103A=

```

`ida_scripts/unflutter_apply.py`:

```py
# -*- coding: utf-8 -*-
"""unflutter_apply.py — IDA idalib script

Reads flutter_meta.json produced by `unflutter meta`, applies:
  1. All struct types (DartThread + Dart classes) via parse_decls — one shot
  2. Function creation + renaming
  3. Function signatures with typed this pointers referencing structs
  4. EOL comments (THR fields, PP pool refs, string refs)
  5. Hex-Rays decompilation of focus functions

Pattern follows IL2CppDumper: generate C header, parse_decls(), apply_type().

Usage:
  python3 unflutter_apply.py <libapp.so> <flutter_meta.json> [<output_dir>]

Requires:
  - IDA Pro with idalib (idapro Python package)
  - Hex-Rays decompiler for ARM64 (for decompilation phase)
"""

import json
import os
import sys
import time


def log(msg):
    sys.stderr.write(msg + "\n")
    sys.stderr.flush()


def sanitize(name):
    """Sanitize a name for use as C identifier or filename."""
    out = []
    for ch in name:
        if ch.isalnum() or ch == "_":
            out.append(ch)
        else:
            out.append("_")
    s = "".join(out)
    # C identifiers can't start with a digit.
    if s and s[0].isdigit():
        s = "_" + s
    return s[:120] if len(s) > 120 else s


def sanitize_filename(name):
    """Sanitize for filenames (allows dots and hyphens)."""
    out = []
    for ch in name:
        if ch.isalnum() or ch in ("_", "-", "."):
            out.append(ch)
        else:
            out.append("_")
    s = "".join(out)
    return s[:120] if len(s) > 120 else s


def resolve_meta_path(argv):
    """Resolve flutter_meta.json path from argv or relative to this script."""
    if len(argv) >= 3 and argv[2]:
        return argv[2]
    # Standalone mode: look for ../flutter_meta.json relative to this script.
    script_dir = os.path.dirname(os.path.abspath(__file__))
    candidate = os.path.join(script_dir, "..", "flutter_meta.json")
    if os.path.exists(candidate):
        return candidate
    return None


def main():
    if len(sys.argv) < 2:
        log("Usage: python3 unflutter_apply.py <libapp.so> [<flutter_meta.json>] [<output_dir>]")
        sys.exit(1)

    binary_path = sys.argv[1]
    meta_path = resolve_meta_path(sys.argv)
    out_dir = sys.argv[3] if len(sys.argv) > 3 else None

    if not os.path.exists(binary_path):
        log("ERROR: binary not found: %s" % binary_path)
        sys.exit(1)
    if meta_path is None or not os.path.exists(meta_path):
        log("ERROR: flutter_meta.json not found. Pass as argument or place script in <output>/ida/")
        sys.exit(1)

    log("unflutter_apply (IDA): loading %s" % meta_path)
    with open(meta_path, "r") as f:
        meta = json.load(f)

    # ---- Open database ----
    log("Opening binary in IDA: %s" % binary_path)
    import idapro
    idapro.enable_console_messages(False)

    result = idapro.open_database(binary_path, True)
    if result != 0:
        # Try fresh — delete stale database files.
        for ext in (".i64", ".idb", ".id0", ".id1", ".id2", ".nam", ".til"):
            p = binary_path + ext
            if os.path.exists(p):
                os.remove(p)
        result = idapro.open_database(binary_path, True)
        if result != 0:
            log("ERROR: failed to open database (code %d)" % result)
            sys.exit(1)
    log("  database opened")

    # ---- Import IDA modules (only after db is open) ----
    import ida_auto
    import ida_funcs
    import ida_typeinf
    import idautils
    import idc

    has_decompiler = False
    try:
        import ida_hexrays
        has_decompiler = ida_hexrays.init_hexrays_plugin()
    except Exception:
        pass
    log("  decompiler: %s" % ("yes" if has_decompiler else "no"))

    # ---- Wait for auto-analysis ----
    log("Waiting for auto-analysis...")
    t0 = time.time()
    ida_auto.auto_wait()
    log("  done (%.1fs)" % (time.time() - t0))

    pointer_size = meta.get("pointer_size", 8)
    log("  pointer_size: %d" % pointer_size)

    stats = {
        "functions": len(meta.get("functions", [])),
        "func_created": 0,
        "func_named": 0,
        "func_failed": 0,
        "sig_applied": 0,
        "sig_failed": 0,
        "comments": 0,
        "comment_failed": 0,
        "decompiled": 0,
        "decompile_failed": 0,
    }

    # ================================================================
    # Phase 1: Generate C header and parse all types at once
    # ================================================================
    # Like IL2CppDumper: build one big .h, parse_decls() in one shot.
    thr_fields = meta.get("thr_fields", [])
    classes = meta.get("classes", [])
    struct_names = {}  # dart class_name -> C struct name

    header_lines = []
    header_lines.append("// Auto-generated by unflutter for IDA")
    header_lines.append("")

    # DartThread struct.
    if thr_fields:
        header_lines.append(build_dart_thread_struct(thr_fields))
        header_lines.append("")

    # Dart class structs.
    for cls in classes:
        cname = cls.get("class_name", "")
        if not cname:
            continue
        sname = "Dart_" + sanitize(cname)
        size = cls.get("instance_size", 0)
        if size <= 0:
            continue
        fields = cls.get("fields", [])
        header_lines.append(build_class_struct(sname, size, fields, pointer_size))
        header_lines.append("")
        struct_names[cname] = sname

    header = "\n".join(header_lines)

    if header.strip():
        # Write header to disk for reference / debugging.
        header_path = os.path.splitext(meta_path)[0] + "_types.h"
        with open(header_path, "w") as hf:
            hf.write(header)
        log("Phase 1: wrote %s (%d bytes)" % (header_path, len(header)))

        # Parse all types in one shot (like IL2CppDumper's parse_decls).
        nerr = ida_typeinf.idc_parse_types(header, 0)
        if nerr == 0:
            type_count = 1 + len(struct_names)  # DartThread + classes
            log("  parsed %d struct types (0 errors)" % type_count)
        else:
            log("  WARN: %d parse errors (some structs may be missing)" % nerr)
    else:
        log("Phase 1: skipped (no types to create)")

    # ================================================================
    # Phase 2: Create/rename functions
    # ================================================================
    functions = meta.get("functions", [])
    log("Phase 2: creating/renaming %d functions..." % len(functions))
    for entry in functions:
        addr = int(entry["addr"], 16)
        name = entry["name"]
        size = entry.get("size", 0)

        # Ensure a function starts at exactly this address.
        # Dart has checked/unchecked entry points — IDA may merge them
        # into one function. Split if our addr is mid-function.
        fn = ida_funcs.get_func(addr)
        if fn is not None and fn.start_ea != addr:
            # Our address is inside a larger function — split it.
            ida_funcs.del_func(fn.start_ea)
            # Re-create the head portion.
            ida_funcs.add_func(fn.start_ea, addr)
            fn = None  # fall through to create our function

        if fn is None:
            end = addr + size if size > 0 else addr
            if ida_funcs.add_func(addr, end):
                stats["func_created"] += 1
            else:
                idc.create_insn(addr)
                if ida_funcs.add_func(addr, end):
                    stats["func_created"] += 1
                else:
                    stats["func_failed"] += 1

        # Set name (SN_NOWARN | SN_NOCHECK — same pattern as IL2CppDumper).
        flags = idc.SN_NOWARN | idc.SN_NOCHECK
        if not idc.set_name(addr, name, flags):
            fallback = "%s_%x" % (name, addr)
            idc.set_name(addr, fallback, flags)
        stats["func_named"] += 1

    log("  created=%d named=%d failed=%d" % (
        stats["func_created"], stats["func_named"], stats["func_failed"]))

    # Re-run analysis after function creation.
    log("  re-analyzing...")
    ida_auto.auto_wait()

    # ================================================================
    # Phase 3: Apply function signatures
    # ================================================================
    # Like IL2CppDumper: apply_type(addr, parse_decl(signature, 0), 1)
    log("Phase 3: applying function signatures...")
    for entry in functions:
        addr = int(entry["addr"], 16)
        owner = entry.get("owner", "")
        pc = entry.get("param_count", 0)
        name = entry["name"]

        proto = build_function_prototype(name, owner, pc, struct_names)
        if not proto:
            continue

        try:
            decl = idc.parse_decl(proto, 0)
            if decl:
                if idc.apply_type(addr, decl, 1) != False:
                    stats["sig_applied"] += 1
                else:
                    stats["sig_failed"] += 1
            else:
                stats["sig_failed"] += 1
        except Exception:
            stats["sig_failed"] += 1

    log("  applied=%d failed=%d" % (stats["sig_applied"], stats["sig_failed"]))

    # ================================================================
    # Phase 4: Set comments
    # ================================================================
    comments = meta.get("comments", [])
    log("Phase 4: setting %d comments..." % len(comments))
    for entry in comments:
        addr = int(entry["addr"], 16)
        text = entry["text"]
        try:
            # Repeatable comment (1) so it shows in decompiler too.
            idc.set_cmt(addr, text, 1)
            stats["comments"] += 1
        except Exception:
            stats["comment_failed"] += 1
    log("  set=%d failed=%d" % (stats["comments"], stats["comment_failed"]))

    # ================================================================
    # Phase 5: Decompile focus functions
    # ================================================================
    focus = meta.get("focus_functions", [])
    if out_dir and focus and has_decompiler:
        log("Phase 5: decompiling %d focus functions..." % len(focus))
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)

        name_by_addr = {}
        owner_by_addr = {}
        for entry in functions:
            a = entry["addr"]
            name_by_addr[a] = entry["name"]
            if entry.get("owner"):
                owner_by_addr[a] = entry["owner"]

        index = []
        for addr_str in focus:
            addr = int(addr_str, 16)
            fn = ida_funcs.get_func(addr)
            if fn is None:
                index.append({
                    "addr": addr_str,
                    "name": name_by_addr.get(addr_str, "unknown"),
                    "file": None,
                    "decompile_ok": False,
                    "reason": "no_function",
                })
                stats["decompile_failed"] += 1
                continue

            fn_name = idc.get_func_name(fn.start_ea)
            try:
                cfunc = ida_hexrays.decompile(fn.start_ea)
                if cfunc is None:
                    raise Exception("decompile returned None")

                # Retype Dart registers for readable output.
                # First pass: set names and types, save, re-decompile.
                # Second pass: re-apply names (re-decompile may reassign).
                if _retype_ida_registers(
                        cfunc, fn.start_ea, ida_hexrays, thr_fields):
                    cfunc = ida_hexrays.decompile(fn.start_ea)
                    if cfunc is None:
                        raise Exception("re-decompile returned None")
                    # Re-apply names on the fresh cfunc (types persist
                    # via save_user_lvars but names may need refreshing).
                    _retype_ida_registers(
                        cfunc, fn.start_ea, ida_hexrays, thr_fields)

                c_code = str(cfunc)

                safe_name = addr_str.replace("0x", "") + "_" + sanitize_filename(fn_name)
                owner = owner_by_addr.get(addr_str, "")
                if owner:
                    sub = sanitize_filename(owner)
                    sub_dir = os.path.join(out_dir, sub)
                    if not os.path.exists(sub_dir):
                        os.makedirs(sub_dir)
                    out_file = os.path.join(sub, safe_name + ".c")
                else:
                    out_file = safe_name + ".c"

                with open(os.path.join(out_dir, out_file), "w") as cf:
                    cf.write(c_code)

                index.append({
                    "addr": addr_str,
                    "name": fn_name,
                    "file": out_file,
                    "decompile_ok": True,
                })
                stats["decompiled"] += 1
            except Exception as e:
                index.append({
                    "addr": addr_str,
                    "name": fn_name,
                    "file": None,
                    "decompile_ok": False,
                    "reason": str(e)[:100],
                })
                stats["decompile_failed"] += 1

        with open(os.path.join(out_dir, "index.json"), "w") as idx:
            json.dump(index, idx, indent=2)
        log("  decompiled=%d failed=%d" % (stats["decompiled"], stats["decompile_failed"]))
    elif not has_decompiler:
        log("Phase 5: skipped (no Hex-Rays)")
    elif not out_dir:
        log("Phase 5: skipped (no output dir)")
    else:
        log("Phase 5: skipped (no focus functions)")

    # ================================================================
    # Save and close
    # ================================================================
    log("Saving database...")
    idapro.close_database(1)

    log("DONE: functions=%d created=%d named=%d structs=%d "
        "sigs=%d comments=%d decompiled=%d decomp_failed=%d" % (
            stats["functions"],
            stats["func_created"],
            stats["func_named"],
            len(struct_names) + (1 if thr_fields else 0),
            stats["sig_applied"],
            stats["comments"],
            stats["decompiled"],
            stats["decompile_failed"],
        ))


# ============================================================
# C header generation
# ============================================================

def build_dart_thread_struct(thr_fields):
    """Build DartThread struct as C declaration."""
    sorted_fields = sorted(thr_fields, key=lambda f: f["offset"])
    max_off = max(f["offset"] for f in sorted_fields)
    struct_size = max_off + 8

    lines = ["struct DartThread {"]
    prev_end = 0
    pad_idx = 0
    for f in sorted_fields:
        off = f["offset"]
        name = sanitize(f["name"])
        if off > prev_end:
            lines.append("  char _pad%d[%d];" % (pad_idx, off - prev_end))
            pad_idx += 1
        elif off < prev_end:
            continue  # overlapping, skip
        lines.append("  void* %s;" % name)
        prev_end = off + 8

    if prev_end < struct_size:
        lines.append("  char _pad_tail[%d];" % (struct_size - prev_end))

    lines.append("};")
    return "\n".join(lines)


def build_class_struct(sname, size, fields, pointer_size):
    """Build a Dart class struct as C declaration."""
    field_sz = pointer_size
    field_type = "int" if pointer_size == 4 else "void*"

    sorted_fields = sorted(fields, key=lambda f: f.get("byte_offset", 0))

    lines = ["struct %s {" % sname]
    prev_end = 0
    pad_idx = 0
    for f in sorted_fields:
        off = f.get("byte_offset", 0)
        fname = sanitize(f.get("name", "field_%x" % off))
        if off < prev_end:
            continue
        if off > prev_end:
            lines.append("  char _pad%d[%d];" % (pad_idx, off - prev_end))
            pad_idx += 1
        if off + field_sz <= size:
            lines.append("  %s %s;" % (field_type, fname))
            prev_end = off + field_sz
        else:
            prev_end = off

    if prev_end < size:
        lines.append("  char _pad_tail[%d];" % (size - prev_end))

    lines.append("};")
    return "\n".join(lines)


def build_function_prototype(name, owner, param_count, struct_names):
    """Build C function prototype. Returns None if no params to apply."""
    cname = sanitize(name)
    params = []

    if owner:
        if owner in struct_names:
            params.append("struct %s* this" % struct_names[owner])
        else:
            params.append("void* this")

    for i in range(param_count):
        params.append("void* p%d" % i)

    if not params:
        return "void* __fastcall %s(void);" % cname

    return "void* __fastcall %s(%s);" % (cname, ", ".join(params))


def _retype_ida_registers(cfunc, ea, ida_hexrays, has_thr_fields):
    """Rename and type Dart register variables in Hex-Rays decompilation.

    64-bit registers:
      x15 → SHADOW_SP (long*)   — indexed stack access: SHADOW_SP[-2]
      x21 → DT        (long)    — dispatch table
      x22 → DART_NULL (long)    — null sentinel
      x26 → THR       (DartThread*) — struct field resolution
      x27 → PP        (long*)   — indexed pool access: PP[8]
      x28 → HEAP_BASE (long)    — compressed pointer base
      x29 → FP        (long)    — frame pointer
      x30 → LR        (long)    — return address

    Also handles 32-bit subregister variants (w15, w22, etc.).

    Returns True if any symbols were retyped (caller should re-decompile).
    """
    import ida_typeinf

    # Build typed tinfo objects once.
    long_tinfo = ida_typeinf.tinfo_t()
    long_tinfo.create_simple_type(ida_typeinf.BTF_INT64)

    long_ptr_tinfo = ida_typeinf.tinfo_t()
    long_ptr_tinfo.create_ptr(long_tinfo)

    int_tinfo = ida_typeinf.tinfo_t()
    int_tinfo.create_simple_type(ida_typeinf.BTF_INT32)

    thr_ptr_tinfo = None
    if has_thr_fields:
        thr_tinfo = ida_typeinf.tinfo_t()
        if thr_tinfo.get_named_type(None, "DartThread"):
            thr_ptr_tinfo = ida_typeinf.tinfo_t()
            thr_ptr_tinfo.create_ptr(thr_tinfo)

    # Map register name → (display_name, tinfo or None).
    RENAMES = {
        # 64-bit
        "x15": ("SHADOW_SP", long_ptr_tinfo),
        "x21": ("DT",        long_tinfo),
        "x22": ("DART_NULL",  long_tinfo),
        "x26": ("THR",        thr_ptr_tinfo),
        "x27": ("PP",         long_ptr_tinfo),
        "x28": ("HEAP_BASE",  long_tinfo),
        "x29": ("FP",         long_tinfo),
        "x30": ("LR",         long_tinfo),
        # 32-bit subregisters
        "w15": ("SHADOW_SP",  int_tinfo),
        "w21": ("DT",         int_tinfo),
        "w22": ("DART_NULL",  int_tinfo),
        "w26": ("THR",        int_tinfo),
        "w27": ("PP",         int_tinfo),
        "w28": ("HEAP_BASE",  int_tinfo),
        "w29": ("FP",         int_tinfo),
        "w30": ("LR",         int_tinfo),
    }

    renamed = False
    try:
        for lvar in cfunc.lvars:
            loc = lvar.location
            if not loc.is_reg1():
                continue
            mreg = loc.reg1()
            try:
                reg_name = ida_hexrays.get_mreg_name(mreg, lvar.width)
            except Exception:
                continue
            if not reg_name:
                continue

            entry = RENAMES.get(reg_name)
            if entry is None:
                continue

            new_name, new_type = entry
            lvar.name = new_name
            if new_type is not None:
                lvar.set_lvar_type(new_type)
            renamed = True

        if renamed:
            cfunc.save_user_lvars()
    except Exception:
        pass

    return renamed


if __name__ == "__main__":
    main()

```

`internal/callgraph/callgraph.go`:

```go
package callgraph

import (
	"github.com/zboralski/lattice"
	"unflutter/internal/disasm"
)

// FuncInfo holds the data needed to build call graph and CFG for one function.
type FuncInfo struct {
	Name      string
	Insts     []disasm.Inst
	CallEdges []disasm.CallEdge
}

// BuildCallGraph constructs a lattice.Graph from disassembled functions.
// Each function becomes a node. Each resolved call edge becomes an edge.
// Unresolved BLR targets (no TargetName or Via) are skipped.
func BuildCallGraph(funcs []FuncInfo) *lattice.Graph {
	g := &lattice.Graph{}
	for _, f := range funcs {
		g.Nodes = append(g.Nodes, f.Name)
		for _, e := range f.CallEdges {
			callee := e.TargetName
			if callee == "" {
				callee = e.Via
			}
			if callee == "" {
				continue
			}
			g.Edges = append(g.Edges, lattice.Edge{
				Caller: f.Name,
				Callee: callee,
			})
		}
	}
	g.Dedup()
	return g
}

```

`internal/callgraph/cfg.go`:

```go
package callgraph

import (
	"fmt"
	"sort"

	"github.com/zboralski/lattice"
	"unflutter/internal/disasm"
)

// BuildCFG constructs a lattice.CFGGraph from disassembled functions.
// Each FuncInfo is converted to a lattice.FuncCFG via the existing
// disasm.BuildCFG (3-phase algorithm) then mapped to lattice types.
func BuildCFG(funcs []FuncInfo) *lattice.CFGGraph {
	cg := &lattice.CFGGraph{}
	for _, f := range funcs {
		dcfg := disasm.BuildCFG(f.Name, f.Insts)
		lcfg := convertFuncCFG(&dcfg, f.CallEdges)
		cg.Funcs = append(cg.Funcs, lcfg)
	}
	return cg
}

// BuildFuncCFG builds a single-function lattice.FuncCFG from instructions and call edges.
// Returns the FuncCFG and the number of basic blocks (for filtering trivial functions).
func BuildFuncCFG(name string, insts []disasm.Inst, edges []disasm.CallEdge) (*lattice.FuncCFG, int) {
	dcfg := disasm.BuildCFG(name, insts)
	lcfg := convertFuncCFG(&dcfg, edges)
	return lcfg, len(dcfg.Blocks)
}

// BuildSignalFuncCFG builds a FuncCFG for signal analysis. Only interesting calls
// (named functions, not sub_*/hex stubs) and string references are included.
// Blocks with no interesting content are pruned by the renderer.
func BuildSignalFuncCFG(name string, insts []disasm.Inst, edges []disasm.CallEdge, strRefs map[uint64]string) (*lattice.FuncCFG, int) {
	dcfg := disasm.BuildCFG(name, insts)
	lcfg := convertSignalFuncCFG(&dcfg, edges, strRefs)
	return lcfg, len(dcfg.Blocks)
}

// injectStringRefs adds string reference CallSite entries into the appropriate blocks.
func injectStringRefs(lcfg *lattice.FuncCFG, dcfg *disasm.FuncCFG, strRefs map[uint64]string) {
	if len(strRefs) == 0 {
		return
	}
	for bi, db := range dcfg.Blocks {
		added := false
		for idx := db.Start; idx < db.End && idx < len(dcfg.Insts); idx++ {
			pc := dcfg.Insts[idx].Addr
			if val, ok := strRefs[pc]; ok {
				if len(val) > 50 {
					val = val[:47] + "..."
				}
				lcfg.Blocks[bi].Calls = append(lcfg.Blocks[bi].Calls, lattice.CallSite{
					Offset: idx,
					Callee: fmt.Sprintf("%q", val),
				})
				added = true
			}
		}
		if added {
			sort.Slice(lcfg.Blocks[bi].Calls, func(i, j int) bool {
				return lcfg.Blocks[bi].Calls[i].Offset < lcfg.Blocks[bi].Calls[j].Offset
			})
		}
	}
}

// isInterestingCallee returns true if the callee name represents a real named
// function rather than VM internals, stubs, or dispatch noise.
func isInterestingCallee(name string) bool {
	if name == "" {
		return false
	}
	switch {
	case len(name) > 4 && name[:4] == "sub_": // unresolved address stubs
		return false
	case len(name) > 2 && name[0] == '0' && name[1] == 'x': // raw hex fallback
		return false
	case name == "dispatch_table" || name == "object_field": // VM dispatch noise
		return false
	case len(name) > 4 && name[:4] == "THR.": // thread-local runtime entries
		return false
	case len(name) > 3 && name[:3] == "PP[": // pool pointer stubs
		return false
	}
	return true
}

// convertSignalFuncCFG builds a single-block lattice.FuncCFG containing all
// interesting calls (named functions) and string references from the function.
// Each function becomes one node in the CFG showing its call/string summary.
func convertSignalFuncCFG(dcfg *disasm.FuncCFG, edges []disasm.CallEdge, strRefs map[uint64]string) *lattice.FuncCFG {
	edgeByPC := make(map[uint64]disasm.CallEdge, len(edges))
	for _, e := range edges {
		edgeByPC[e.FromPC] = e
	}

	// Collect all interesting calls and string refs across all blocks into one.
	seen := make(map[string]bool)
	var calls []lattice.CallSite
	seq := 0
	for _, db := range dcfg.Blocks {
		for idx := db.Start; idx < db.End && idx < len(dcfg.Insts); idx++ {
			pc := dcfg.Insts[idx].Addr

			if e, ok := edgeByPC[pc]; ok {
				callee := e.TargetName
				if callee == "" {
					callee = e.Via
				}
				if isInterestingCallee(callee) && !seen[callee] {
					seen[callee] = true
					calls = append(calls, lattice.CallSite{Offset: seq, Callee: callee})
					seq++
				}
			}

			if val, ok := strRefs[pc]; ok {
				if len(val) > 50 {
					val = val[:47] + "..."
				}
				label := fmt.Sprintf("%q", val)
				if !seen[label] {
					seen[label] = true
					calls = append(calls, lattice.CallSite{Offset: seq, Callee: label})
					seq++
				}
			}
		}
	}

	lcfg := &lattice.FuncCFG{Name: dcfg.Name}
	if len(calls) > 0 {
		lcfg.Blocks = append(lcfg.Blocks, &lattice.BasicBlock{
			ID:    0,
			Start: 0,
			End:   1,
			Term:  true,
			Calls: calls,
		})
	}
	return lcfg
}

// convertFuncCFG maps a disasm.FuncCFG to a lattice.FuncCFG.
// Call edges are mapped into blocks by matching instruction PCs.
func convertFuncCFG(dcfg *disasm.FuncCFG, edges []disasm.CallEdge) *lattice.FuncCFG {
	// Build PC → CallEdge map for O(1) lookup.
	edgeByPC := make(map[uint64]disasm.CallEdge, len(edges))
	for _, e := range edges {
		edgeByPC[e.FromPC] = e
	}

	lcfg := &lattice.FuncCFG{Name: dcfg.Name}
	for _, db := range dcfg.Blocks {
		lb := &lattice.BasicBlock{
			ID:    db.ID,
			Start: db.Start,
			End:   db.End,
			Term:  db.IsTerm,
		}

		// Convert successors.
		for _, ds := range db.Succs {
			lb.Succs = append(lb.Succs, lattice.Successor{
				BlockID: ds.BlockID,
				Cond:    ds.Cond,
			})
		}

		// Populate calls from edges that fall within this block's instruction range.
		for idx := db.Start; idx < db.End && idx < len(dcfg.Insts); idx++ {
			if e, ok := edgeByPC[dcfg.Insts[idx].Addr]; ok {
				callee := e.TargetName
				if callee == "" {
					callee = e.Via
				}
				if callee == "" {
					callee = fmt.Sprintf("0x%x", e.TargetPC)
				}
				lb.Calls = append(lb.Calls, lattice.CallSite{
					Offset: idx,
					Callee: callee,
				})
			}
		}

		lcfg.Blocks = append(lcfg.Blocks, lb)
	}
	return lcfg
}

```

`internal/callgraph/cfg_test.go`:

```go
package callgraph

import (
	"testing"

	"github.com/zboralski/lattice/render"
	"unflutter/internal/disasm"
)

func TestBuildCFG_DOTOutput(t *testing.T) {
	// Construct a small ARM64 function with branches and calls:
	//
	// entry (B0):
	//   0x1000: MOV X0, #0
	//   0x1004: BL  0x1100       ; call "Foo.bar"
	//   0x1008: CBZ X0, 0x1018   ; conditional → B2
	//
	// true path (B1):
	//   0x100C: MOV X1, #1
	//   0x1010: BL  0x1210       ; call "Baz.qux"
	//   0x1014: B   0x1020       ; jump → B3
	//
	// false path (B2):
	//   0x1018: BL  0x1318       ; call "Quux.run"
	//   0x101C: RET
	//
	// join (B3):
	//   0x1020: RET
	insts := []disasm.Inst{
		{Addr: 0x1000, Raw: 0xD2800000, Size: 4, Text: "MOV X0, #0"},     // MOV X0, #0
		{Addr: 0x1004, Raw: 0x94000040, Size: 4, Text: "BL 0x1104"},      // BL +0x100
		{Addr: 0x1008, Raw: 0xB4000080, Size: 4, Text: "CBZ X0, 0x1018"}, // CBZ X0, +0x10
		{Addr: 0x100C, Raw: 0xD2800021, Size: 4, Text: "MOV X1, #1"},     // MOV X1, #1
		{Addr: 0x1010, Raw: 0x94000080, Size: 4, Text: "BL 0x1210"},      // BL +0x200
		{Addr: 0x1014, Raw: 0x14000003, Size: 4, Text: "B 0x1020"},       // B +0xC
		{Addr: 0x1018, Raw: 0x940000C0, Size: 4, Text: "BL 0x1318"},      // BL +0x300
		{Addr: 0x101C, Raw: 0xD65F03C0, Size: 4, Text: "RET"},            // RET
		{Addr: 0x1020, Raw: 0xD65F03C0, Size: 4, Text: "RET"},            // RET
	}

	edges := []disasm.CallEdge{
		{FromPC: 0x1004, Kind: "bl", TargetPC: 0x1104, TargetName: "Foo.bar_a00"},
		{FromPC: 0x1010, Kind: "bl", TargetPC: 0x1210, TargetName: "Baz.qux_b00"},
		{FromPC: 0x1018, Kind: "bl", TargetPC: 0x1318, TargetName: "Quux.run_c00"},
	}

	funcs := []FuncInfo{
		{Name: "MyClass.myMethod_1000", Insts: insts, CallEdges: edges},
	}

	cfg := BuildCFG(funcs)

	// Verify structure.
	if len(cfg.Funcs) != 1 {
		t.Fatalf("expected 1 function, got %d", len(cfg.Funcs))
	}
	f := cfg.Funcs[0]
	if f.Name != "MyClass.myMethod_1000" {
		t.Errorf("func name = %q", f.Name)
	}
	// Expect 4 blocks: entry, true-path, false-path, join
	if len(f.Blocks) != 4 {
		t.Fatalf("expected 4 blocks, got %d", len(f.Blocks))
	}

	// B0: entry, has 1 call (Foo.bar), 2 successors (T→B1, F→B2)
	b0 := f.Blocks[0]
	if len(b0.Calls) != 1 || b0.Calls[0].Callee != "Foo.bar_a00" {
		t.Errorf("B0 calls = %+v", b0.Calls)
	}
	if len(b0.Succs) != 2 {
		t.Errorf("B0 succs = %+v", b0.Succs)
	}

	// B1: true path, has 1 call (Baz.qux), 1 unconditional successor
	b1 := f.Blocks[1]
	if len(b1.Calls) != 1 || b1.Calls[0].Callee != "Baz.qux_b00" {
		t.Errorf("B1 calls = %+v", b1.Calls)
	}

	// B2: false path, has 1 call (Quux.run), terminal (RET)
	b2 := f.Blocks[2]
	if len(b2.Calls) != 1 || b2.Calls[0].Callee != "Quux.run_c00" {
		t.Errorf("B2 calls = %+v", b2.Calls)
	}
	if !b2.Term {
		t.Error("B2 should be terminal")
	}

	// B3: join, terminal (RET)
	b3 := f.Blocks[3]
	if !b3.Term {
		t.Error("B3 should be terminal")
	}

	// Render DOT — verify it doesn't panic.
	dot := render.DOTCFG(cfg, "deflutter CFG example")
	if dot == "" {
		t.Error("expected non-empty DOT output")
	}
}

func TestBuildCallGraph_DOTOutput(t *testing.T) {
	funcs := []FuncInfo{
		{
			Name: "main_1000",
			CallEdges: []disasm.CallEdge{
				{FromPC: 0x1004, Kind: "bl", TargetPC: 0x2000, TargetName: "Foo.init_2000"},
				{FromPC: 0x1010, Kind: "bl", TargetPC: 0x3000, TargetName: "Bar.run_3000"},
			},
		},
		{
			Name: "Foo.init_2000",
			CallEdges: []disasm.CallEdge{
				{FromPC: 0x2008, Kind: "bl", TargetPC: 0x4000, TargetName: "Logger.log_4000"},
			},
		},
		{
			Name: "Bar.run_3000",
			CallEdges: []disasm.CallEdge{
				{FromPC: 0x3004, Kind: "bl", TargetPC: 0x4000, TargetName: "Logger.log_4000"},
				{FromPC: 0x3010, Kind: "blr", Reg: "X16", Via: "PP[42] Widget.build"},
			},
		},
		{
			Name: "Logger.log_4000",
		},
	}

	cg := BuildCallGraph(funcs)

	if len(cg.Nodes) != 4 {
		t.Errorf("expected 4 nodes, got %d", len(cg.Nodes))
	}

	dot := render.DOT(cg, "deflutter call graph example")
	if dot == "" {
		t.Error("expected non-empty DOT output")
	}
}

```

`internal/cli/color.go`:

```go
package cli

import "os"

// CRT neon palette from signal.html — BBS/Amiga aesthetic.
var (
	Green  = "\033[38;2;0;255;0m"
	Gold   = "\033[38;2;255;200;0m"
	Blue   = "\033[38;2;135;206;235m"
	Pink   = "\033[38;2;255;128;192m"
	Orange = "\033[38;2;255;128;0m"
	Red    = "\033[38;2;255;68;68m"
	Muted  = "\033[38;2;128;128;128m"
	White  = "\033[38;2;255;255;255m"
	Bold   = "\033[1m"
	Reset  = "\033[0m"
)

// DisableColor sets all color codes to empty strings.
func DisableColor() {
	Green = ""
	Gold = ""
	Blue = ""
	Pink = ""
	Orange = ""
	Red = ""
	Muted = ""
	White = ""
	Bold = ""
	Reset = ""
}

func init() {
	if os.Getenv("NO_COLOR") != "" {
		DisableColor()
		return
	}
	fi, err := os.Stderr.Stat()
	if err != nil || fi.Mode()&os.ModeCharDevice == 0 {
		DisableColor()
	}
}

```

`internal/cluster/cid.go`:

```go
// CID constants and tag decoding for Dart VM class IDs.
package cluster

import "unflutter/internal/snapshot"

// CID constants for Dart VM v3.9.2 (kept for backward compatibility and CidName).
const (
	CidIllegal                    = 0
	CidObject                     = 4
	CidClass                      = 5
	CidPatchClass                 = 6
	CidFunction                   = 7
	CidTypeParameters             = 8
	CidClosureData                = 9
	CidFfiTrampolineData          = 10
	CidField                      = 11
	CidScript                     = 12
	CidLibrary                    = 13
	CidNamespace                  = 14
	CidKernelProgramInfo          = 15
	CidWeakSerializationReference = 16
	CidWeakArray                  = 17
	CidCode                       = 18
	CidBytecode                   = 19
	CidInstructions               = 20
	CidInstructionsSection        = 21
	CidInstructionsTable          = 22
	CidObjectPool                 = 23
	CidPcDescriptors              = 24
	CidCodeSourceMap              = 25
	CidCompressedStackMaps        = 26
	CidLocalVarDescriptors        = 27
	CidExceptionHandlers          = 28
	CidContext                    = 29
	CidContextScope               = 30
	CidSentinel                   = 31
	CidSingleTargetCache          = 32
	CidMonomorphicSmiableCall     = 33
	CidCallSiteData               = 34
	CidUnlinkedCall               = 35
	CidICData                     = 36
	CidMegamorphicCache           = 37
	CidSubtypeTestCache           = 38
	CidLoadingUnit                = 39
	CidError                      = 40
	CidApiError                   = 41
	CidLanguageError              = 42
	CidUnhandledException         = 43
	CidUnwindError                = 44

	CidInstance              = 45
	CidLibraryPrefix         = 46
	CidTypeArguments         = 47
	CidAbstractType          = 48
	CidType                  = 49
	CidFunctionType          = 50
	CidRecordType            = 51
	CidTypeParameter         = 52
	CidFinalizerBase         = 53
	CidFinalizer             = 54
	CidNativeFinalizer       = 55
	CidFinalizerEntry        = 56
	CidClosure               = 57
	CidNumber                = 58
	CidInteger               = 59
	CidSmi                   = 60
	CidMint                  = 61
	CidDouble                = 62
	CidBool                  = 63
	CidFloat32x4             = 64
	CidInt32x4               = 65
	CidFloat64x2             = 66
	CidRecord                = 67
	CidTypedDataBase         = 68
	CidTypedData             = 69
	CidExternalTypedData     = 70
	CidTypedDataView         = 71
	CidPointer               = 72
	CidDynamicLibrary        = 73
	CidCapability            = 74
	CidReceivePort           = 75
	CidSendPort              = 76
	CidStackTrace            = 77
	CidSuspendState          = 78
	CidRegExp                = 79
	CidWeakProperty          = 80
	CidWeakReference         = 81
	CidMirrorReference       = 82
	CidFutureOr              = 83
	CidUserTag               = 84
	CidTransferableTypedData = 85

	CidMap      = 86
	CidConstMap = 87
	CidSet      = 88
	CidConstSet = 89

	CidArray               = 90
	CidImmutableArray      = 91
	CidGrowableObjectArray = 92

	CidString        = 93
	CidOneByteString = 94
	CidTwoByteString = 95
)

// Tag bit positions for v3.4.3+ object header tag encoding.
const (
	tagCanonicalBit = 1  // bit 1
	tagImmutableBit = 6  // bit 6
	tagClassIdShift = 12 // bits 12-31
	tagClassIdMask  = (1 << 20) - 1
)

// DecodeTags extracts CID, canonical, and immutable flags from v3.4.3+
// object header tag encoding. For old-style encoding, use DecodeTagsOld.
func DecodeTags(tags uint32) (cid int, isCanonical, isImmutable bool) {
	cid = int((tags >> tagClassIdShift) & tagClassIdMask)
	isCanonical = (tags>>tagCanonicalBit)&1 != 0
	isImmutable = (tags>>tagImmutableBit)&1 != 0
	return
}

// DecodeTagsOld extracts CID and canonical flag from v2.x / early v3.x
// cluster tags. Format: (cid << 1) | canonical, stored as uint64_t.
// The CID is masked to 32 bits to match Dart's (cid >> 1) & kMaxUint32.
func DecodeTagsOld(cidAndCanonical int64) (cid int, isCanonical bool) {
	cid = int(uint32(cidAndCanonical >> 1))
	isCanonical = cidAndCanonical&1 != 0
	return
}

// DecodeTagsV extracts CID, canonical, and immutable flags using the
// version profile's tag style.
func DecodeTagsV(tags uint32, classIdShift, classIdBits, canonicalBit uint, hasImmutable bool, immutableBit uint) (cid int, isCanonical, isImmutable bool) {
	mask := uint32((1 << classIdBits) - 1)
	cid = int((tags >> classIdShift) & mask)
	isCanonical = (tags>>canonicalBit)&1 != 0
	if hasImmutable {
		isImmutable = (tags>>immutableBit)&1 != 0
	}
	return
}

// AllocKind classifies how a cluster's alloc data should be parsed.
type AllocKind int

const (
	AllocSimple            AllocKind = iota // count = ReadUnsigned()
	AllocCanonicalSet                       // count + optional canonical set
	AllocString                             // count + per-string length + optional canonical set
	AllocMint                               // count + per-mint int64
	AllocArray                              // count + per-element length
	AllocWeakArray                          // count + per-element length
	AllocTypeArguments                      // count + per-item length + optional canonical set
	AllocClass                              // predefined_count + per-class cid + new_count
	AllocCode                               // count + per-code state_bits + deferred
	AllocObjectPool                         // count + per-pool length
	AllocROData                             // count + per-item offset + optional canonical set
	AllocExceptionHandlers                  // count + per-handler length
	AllocContext                            // count + per-context num_variables
	AllocContextScope                       // count + per-scope length
	AllocRecord                             // count + per-record num_fields
	AllocTypedData                          // count + per-item length
	AllocInstance                           // count + next_field_offset + instance_size
	AllocEmpty                              // no alloc data at all (WeakSerializationReference)
	AllocUnknown                            // unrecognized CID
)

// ClassifyAlloc determines the alloc kind for a CID given a CID table.
func ClassifyAlloc(cid int, ct *snapshot.CIDTable) AllocKind {
	switch cid {
	case ct.String, ct.OneByteString, ct.TwoByteString:
		return AllocString
	case ct.Mint:
		return AllocMint
	case ct.Double, ct.Float32x4, ct.Int32x4, ct.Float64x2:
		return AllocSimple
	case ct.Array, ct.ImmutableArray:
		return AllocArray
	case ct.WeakArray:
		if ct.WeakArray == 0 {
			return AllocUnknown
		}
		return AllocWeakArray
	case ct.TypeArguments:
		return AllocTypeArguments
	case ct.Type, ct.FunctionType, ct.TypeParameter:
		return AllocCanonicalSet
	case ct.Class:
		return AllocClass
	case ct.Code:
		return AllocCode
	case ct.ObjectPool:
		return AllocObjectPool
	case ct.PcDescriptors, ct.CodeSourceMap, ct.CompressedStackMaps:
		return AllocROData
	case ct.ExceptionHandlers:
		return AllocExceptionHandlers
	case ct.Context:
		return AllocContext
	case ct.ContextScope:
		return AllocContextScope
	case ct.Map, ct.ConstMap, ct.Set, ct.ConstSet:
		// Map/Set clusters use plain SerializationCluster, not
		// CanonicalSetSerializationCluster. Alloc is just count.
		return AllocSimple
	case ct.TypedData:
		return AllocTypedData
	case ct.TypedDataView, ct.ExternalTypedData:
		return AllocSimple
	case ct.GrowableObjectArray:
		return AllocSimple
	}

	// RecordType and Record may be 0 in v2.17.6.
	if ct.RecordType != 0 && cid == ct.RecordType {
		return AllocCanonicalSet
	}
	if ct.Record != 0 && cid == ct.Record {
		return AllocRecord
	}

	// WeakSerializationReference: exists only in Dart 2.x. Format varies by version:
	// - v2.10 (PreCanonicalSplit): AllocSimple (has count)
	// - v2.13+ (SplitCanonical/CidShift1): AllocEmpty (no alloc data at all)
	// Handled in skipAllocV which checks the version flags.
	if ct.WeakSerializationReference != 0 && cid == ct.WeakSerializationReference {
		return AllocEmpty
	}

	// Simple alloc types: just count = ReadUnsigned().
	simples := []int{
		ct.Function, ct.ClosureData, ct.Field, ct.Script, ct.Library,
		ct.Namespace, ct.KernelProgramInfo, ct.Closure,
		ct.UnlinkedCall, ct.ICData, ct.MegamorphicCache,
		ct.SubtypeTestCache, ct.LoadingUnit, ct.WeakProperty,
		ct.WeakReference, ct.LibraryPrefix, ct.LanguageError,
		ct.UnhandledException, ct.RegExp, ct.PatchClass,
		ct.FfiTrampolineData, ct.TypeParameters, ct.Sentinel, ct.SignatureData,
		ct.SingleTargetCache, ct.MonomorphicSmiableCall,
		ct.CallSiteData,
		ct.SendPort, ct.StackTrace, ct.Capability, ct.ReceivePort,
		ct.FutureOr, ct.TransferableTypedData, ct.UserTag,
	}
	if ct.SuspendState != 0 {
		simples = append(simples, ct.SuspendState)
	}
	if ct.TypeRef != 0 {
		simples = append(simples, ct.TypeRef)
	}
	for _, s := range simples {
		if s != 0 && cid == s {
			return AllocSimple
		}
	}

	// DeltaEncodedTypedData: CID = kNativePointer (1). Same alloc as TypedData.
	if ct.NativePointerCid != 0 && cid == ct.NativePointerCid {
		return AllocTypedData
	}

	// TypedData internal CIDs (kTypedDataInt8ArrayCid through kByteDataViewCid-1).
	// IsTypedDataClassId: cid in range AND (cid - base) % stride == 0.
	if ct.TypedDataInt8ArrayCid != 0 && ct.ByteDataViewCid != 0 &&
		cid >= ct.TypedDataInt8ArrayCid && cid < ct.ByteDataViewCid &&
		(cid-ct.TypedDataInt8ArrayCid)%ct.TypedDataCidStride == 0 {
		return AllocTypedData
	}

	// Instance: CID >= Instance and not otherwise matched.
	// App-defined classes (>= NumPredefinedCids) always use Instance alloc.
	// Predefined CIDs that reach here also use Instance alloc unless they
	// have their own serialization cluster (handled above or as special cases).
	if ct.Instance != 0 && cid >= ct.Instance {
		return AllocInstance
	}

	// Unrecognized predefined CIDs (e.g. SignatureData, RedirectionData, Bytecode
	// in v2.10.0 that were removed in later versions) default to AllocSimple.
	// All predefined types with non-simple alloc are matched above.
	if ct.NumPredefinedCids != 0 && cid > 0 && cid < ct.NumPredefinedCids {
		return AllocSimple
	}

	return AllocUnknown
}

// CidName returns a human-readable name for known v3.9.2 CIDs.
func CidName(cid int) string {
	return cidNameFromTable(cid, &snapshot.CIDTable{
		Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
		ClosureData: 9, Field: 11, Script: 12, Library: 13,
		Namespace: 14, Code: 18, ObjectPool: 23, PcDescriptors: 24,
		CodeSourceMap: 25, CompressedStackMaps: 26, ExceptionHandlers: 28,
		Context: 29, ContextScope: 30, UnlinkedCall: 35,
		ICData: 36, MegamorphicCache: 37, SubtypeTestCache: 38,
		LoadingUnit: 39, LanguageError: 42, UnhandledException: 43,
		Instance: 45, LibraryPrefix: 46, TypeArguments: 47,
		Type: 49, FunctionType: 50, RecordType: 51, TypeParameter: 52,
		Closure: 57, Mint: 61, Double: 62,
		GrowableObjectArray: 92, Record: 67,
		Array: 90, ImmutableArray: 91, WeakArray: 17,
		String: 93, OneByteString: 94, TwoByteString: 95,
		ConstMap: 87, ConstSet: 89, RegExp: 79,
		WeakProperty: 80, StackTrace: 77, SendPort: 76,
	})
}

// CidNameV returns a human-readable name for a CID using version-specific table.
func CidNameV(cid int, ct *snapshot.CIDTable) string {
	return cidNameFromTable(cid, ct)
}

// typedDataInternalNames maps TypedData type index to name.
var typedDataInternalNames = [14]string{
	"TypedDataInt8Array", "TypedDataUint8Array", "TypedDataUint8ClampedArray",
	"TypedDataInt16Array", "TypedDataUint16Array", "TypedDataInt32Array",
	"TypedDataUint32Array", "TypedDataInt64Array", "TypedDataUint64Array",
	"TypedDataFloat32Array", "TypedDataFloat64Array", "TypedDataFloat32x4Array",
	"TypedDataInt32x4Array", "TypedDataFloat64x2Array",
}

func typedDataInternalName(cid int, ct *snapshot.CIDTable) string {
	if ct.TypedDataCidStride == 0 {
		return ""
	}
	idx := (cid - ct.TypedDataInt8ArrayCid) / ct.TypedDataCidStride
	rem := (cid - ct.TypedDataInt8ArrayCid) % ct.TypedDataCidStride
	if idx < 0 || idx >= 14 {
		return ""
	}
	base := typedDataInternalNames[idx]
	switch rem {
	case 0:
		return base
	case 1:
		return base + "View"
	case 2:
		return "External" + base
	case 3:
		return "Unmodifiable" + base + "View"
	}
	return ""
}

func cidNameFromTable(cid int, ct *snapshot.CIDTable) string {
	switch {
	case cid == ct.Class:
		return "Class"
	case cid == ct.PatchClass:
		return "PatchClass"
	case cid == ct.Function:
		return "Function"
	case cid == ct.TypeParameters:
		return "TypeParameters"
	case cid == ct.ClosureData:
		return "ClosureData"
	case ct.SignatureData != 0 && cid == ct.SignatureData:
		return "SignatureData"
	case ct.FfiTrampolineData != 0 && cid == ct.FfiTrampolineData:
		return "FfiTrampolineData"
	case cid == ct.Field:
		return "Field"
	case cid == ct.Script:
		return "Script"
	case cid == ct.Library:
		return "Library"
	case cid == ct.Namespace:
		return "Namespace"
	case cid == ct.Code:
		return "Code"
	case cid == ct.ObjectPool:
		return "ObjectPool"
	case cid == ct.PcDescriptors:
		return "PcDescriptors"
	case cid == ct.CodeSourceMap:
		return "CodeSourceMap"
	case cid == ct.CompressedStackMaps:
		return "CompressedStackMaps"
	case cid == ct.ExceptionHandlers:
		return "ExceptionHandlers"
	case cid == ct.Context:
		return "Context"
	case cid == ct.ContextScope:
		return "ContextScope"
	case cid == ct.UnlinkedCall:
		return "UnlinkedCall"
	case cid == ct.ICData:
		return "ICData"
	case cid == ct.MegamorphicCache:
		return "MegamorphicCache"
	case cid == ct.SubtypeTestCache:
		return "SubtypeTestCache"
	case cid == ct.LoadingUnit:
		return "LoadingUnit"
	case cid == ct.LanguageError:
		return "LanguageError"
	case cid == ct.UnhandledException:
		return "UnhandledException"
	case cid == ct.Instance:
		return "Instance"
	case cid == ct.LibraryPrefix:
		return "LibraryPrefix"
	case cid == ct.TypeArguments:
		return "TypeArguments"
	case cid == ct.Type:
		return "Type"
	case cid == ct.FunctionType:
		return "FunctionType"
	case ct.RecordType != 0 && cid == ct.RecordType:
		return "RecordType"
	case ct.TypeRef != 0 && cid == ct.TypeRef:
		return "TypeRef"
	case cid == ct.TypeParameter:
		return "TypeParameter"
	case cid == ct.Closure:
		return "Closure"
	case cid == ct.Mint:
		return "Mint"
	case cid == ct.Double:
		return "Double"
	case cid == ct.GrowableObjectArray:
		return "GrowableObjectArray"
	case ct.Record != 0 && cid == ct.Record:
		return "Record"
	case cid == ct.Array:
		return "Array"
	case cid == ct.ImmutableArray:
		return "ImmutableArray"
	case ct.WeakArray != 0 && cid == ct.WeakArray:
		return "WeakArray"
	case cid == ct.String:
		return "String"
	case cid == ct.OneByteString:
		return "OneByteString"
	case cid == ct.TwoByteString:
		return "TwoByteString"
	case cid == ct.Map:
		return "Map"
	case cid == ct.ConstMap:
		return "ConstMap"
	case cid == ct.Set:
		return "Set"
	case cid == ct.ConstSet:
		return "ConstSet"
	case cid == ct.RegExp:
		return "RegExp"
	case cid == ct.WeakProperty:
		return "WeakProperty"
	case cid == ct.StackTrace:
		return "StackTrace"
	case cid == ct.SendPort:
		return "SendPort"
	case ct.NativePointerCid != 0 && cid == ct.NativePointerCid:
		return "DeltaEncodedTypedData"
	case ct.TypedDataInt8ArrayCid != 0 && ct.ByteDataViewCid != 0 &&
		cid >= ct.TypedDataInt8ArrayCid && cid < ct.ByteDataViewCid:
		return typedDataInternalName(cid, ct)
	default:
		return ""
	}
}

```

`internal/cluster/cluster.go`:

```go
// Package cluster parses Dart AOT clustered snapshot data to recover
// object references, string values, function names, and code mappings.
package cluster

import (
	"fmt"
	"os"

	"unflutter/internal/dartfmt"
	"unflutter/internal/snapshot"
)

var debugAlloc = os.Getenv("DEFLUTTER_DEBUG_ALLOC") != ""

// Header holds the clustered snapshot section header fields.
type Header struct {
	NumBaseObjects             int64
	NumObjects                 int64
	NumCanonicalClusters       int64 // v2.12-2.13 only (SplitCanonical); 0 otherwise
	NumClusters                int64
	InitialFieldTableLen       int64 // v2.x only; 0 for v3.x
	InstructionsTableLen       int64
	InstructionTableDataOffset int64
}

// ClusterMeta describes one cluster read from the alloc section.
type ClusterMeta struct {
	Index       int
	CID         int
	IsCanonical bool
	IsImmutable bool
	Count       int64 // number of objects allocated
	StartRef    int   // first ref index assigned during alloc
	StopRef     int   // one past last ref index
	StartOffset int   // byte offset where this cluster's tag was read
	EndOffset   int   // byte offset after this cluster's alloc data

	// Instance-specific: set only for AllocInstance clusters.
	// next_field_offset_in_words from alloc; used by fill parser
	// to determine how many pointer fields each instance has.
	NextFieldOffsetInWords int32

	// Code-specific: main (non-deferred) count from alloc.
	// In fill, main codes read ReadUnsigned(payload_info) + refs,
	// deferred codes read only refs.
	MainCount int64

	// Code-specific: set of discarded code indices (DiscardedBit set in state_bits).
	// v2.14+: discarded codes in fill skip all refs; only ReadInstructions is called.
	DiscardedCodes map[int64]bool

	// Per-object lengths from alloc, for variable-length fill clusters.
	// Set for Array, WeakArray, Context, TypeArguments, ExceptionHandlers,
	// TypedData, ObjectPool, ContextScope, Record.
	Lengths []int64

	// Class-specific: predefined class CIDs from alloc phase.
	PredefCIDs []int64
}

// ParsedString holds a recovered string value and its ref index.
type ParsedString struct {
	RefID     int
	Value     string
	IsOneByte bool
}

// CodeEntry holds a Code object's ref, owner ref, and instruction metadata.
type CodeEntry struct {
	RefID        int
	OwnerRef     int   // ref ID of the owning Function/Closure/FfiTrampolineData
	ClusterIndex int   // implicit instructions_index_ (main codes only; -1 for deferred)
	PayloadInfo  int64 // raw payload_info from fill (0 for deferred)
}

// PoolEntryKind distinguishes ObjectPool entry types.
type PoolEntryKind uint8

const (
	PoolTagged    PoolEntryKind = iota // tagged object ref
	PoolImmediate                      // raw int64
	PoolNative                         // native function (no snapshot data)
	PoolEmpty                          // non-snapshotable (v3.x behavior != 0)
)

// PoolEntry is one entry in the isolate ObjectPool.
type PoolEntry struct {
	Index int
	Kind  PoolEntryKind
	RefID int   // valid when Kind == PoolTagged
	Imm   int64 // valid when Kind == PoolImmediate
}

// Result holds all parsed cluster data.
type Result struct {
	Header     Header
	Clusters   []ClusterMeta
	Strings    []ParsedString
	Named      []NamedObject  // named objects extracted from fill (Function, Class, Library, etc.)
	FuncTypes  []FuncTypeInfo // FunctionType parameter counts extracted from fill
	Classes    []ClassInfo    // class layout data extracted from fill
	Fields     []FieldInfo    // field layout data extracted from fill
	Codes      []CodeEntry    // Code objects with owner refs, extracted from fill
	Pool       []PoolEntry    // ObjectPool entries extracted from fill
	MintValues map[int]int64  // Mint/Smi ref→int64 value from alloc phase
	FillStart  int            // byte offset where the fill section begins
	Diags      []dartfmt.Diag
}

// ScanClusters reads the clustered snapshot header and cluster tags from
// snapshot data. clusterStart is the offset within data where the clustered
// section begins (after the snapshot header's null-terminated features string).
// If profile is nil, the v3.x format is assumed. isVM indicates whether this
// is the VM snapshot (affects canonical set handling for strings).
func ScanClusters(data []byte, clusterStart int, profile *snapshot.VersionProfile, isVM bool, opts dartfmt.Options) (*Result, error) {
	if clusterStart >= len(data) {
		return nil, fmt.Errorf("cluster: start offset %d beyond data length %d", clusterStart, len(data))
	}
	if profile == nil {
		profile = snapshot.DetectVersion("")
	}

	s := dartfmt.NewStreamAt(data, clusterStart)
	maxSteps := opts.EffectiveMaxSteps()

	var diags dartfmt.Diags
	result := &Result{}

	// Read header values (count depends on version).
	// Header counts use WriteUnsigned in all versions (even 2.10/2.13).
	var err error
	result.Header.NumBaseObjects, err = s.ReadUnsigned()
	if err != nil {
		return nil, fmt.Errorf("cluster header: num_base_objects: %w", err)
	}
	result.Header.NumObjects, err = s.ReadUnsigned()
	if err != nil {
		return nil, fmt.Errorf("cluster header: num_objects: %w", err)
	}
	// Header field evolution:
	//   2.10      (HF=4): base, objects, clusters, field_table_len
	//   2.12-2.13 (HF=5, SplitCanonical): base, objects, canonical_clusters, clusters, field_table_len
	//   2.14-2.16 (HF=5): base, objects, clusters, field_table_len, instr_table_len
	//   2.17      (HF=6): base, objects, clusters, field_table_len, instr_table_len, instr_table_rodata
	//   2.18+     (HF=5): base, objects, clusters, instr_table_len, instr_table_rodata
	if profile.SplitCanonical {
		// v2.12-2.13: field 3 = num_canonical_clusters, field 4 = num_clusters
		result.Header.NumCanonicalClusters, err = s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("cluster header: num_canonical_clusters: %w", err)
		}
		result.Header.NumClusters, err = s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("cluster header: num_clusters: %w", err)
		}
	} else {
		result.Header.NumClusters, err = s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("cluster header: num_clusters: %w", err)
		}
	}
	if profile.FillRefUnsigned {
		result.Header.InitialFieldTableLen, err = s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("cluster header: initial_field_table_len: %w", err)
		}
	}
	if profile.HeaderFields >= 5 && !profile.SplitCanonical {
		result.Header.InstructionsTableLen, err = s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("cluster header: instructions_table_len: %w", err)
		}
	}
	if (profile.HeaderFields >= 6 || !profile.FillRefUnsigned) && !profile.SplitCanonical && !profile.PreCanonicalSplit {
		result.Header.InstructionTableDataOffset, err = s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("cluster header: instruction_table_data_offset: %w", err)
		}
	}

	// Total clusters = canonical + non-canonical for split format.
	nc := int(result.Header.NumCanonicalClusters + result.Header.NumClusters)
	if nc > maxSteps {
		return nil, fmt.Errorf("cluster: num_clusters %d exceeds max_steps %d", nc, maxSteps)
	}
	if debugAlloc {
		fmt.Fprintf(os.Stderr, "HEADER: base=%d objs=%d canonical=%d clusters=%d nc=%d field_table=%d instr_table=%d instr_offset=%d\n",
			result.Header.NumBaseObjects, result.Header.NumObjects,
			result.Header.NumCanonicalClusters, result.Header.NumClusters, nc,
			result.Header.InitialFieldTableLen, result.Header.InstructionsTableLen,
			result.Header.InstructionTableDataOffset)
	}

	// Read cluster tags from alloc section.
	result.Clusters = make([]ClusterMeta, 0, nc)
	ct := profile.CIDs
	nextRef := int(result.Header.NumBaseObjects) + 1
	for i := 0; i < nc; i++ {
		tagPos := s.Position()

		var cid int
		var canonical, immutable bool

		switch profile.Tags {
		case snapshot.TagStyleCidShift1:
			// v2.14+ / early v3.x: Read<uint64_t>((cid << 1) | canonical).
			cidAndCanonical, err := s.ReadTagged64()
			if err != nil {
				diags.Addf(uint64(tagPos), dartfmt.DiagTruncated,
					"cluster %d/%d: tags: %v", i, nc, err)
				break
			}
			cid, canonical = DecodeTagsOld(cidAndCanonical)
		case snapshot.TagStyleObjectHeader:
			// v3.4.3+: Read<uint32_t>(ClassIdTag | CanonicalBit | ImmutableBit).
			tags, err := s.ReadTagged32()
			if err != nil {
				diags.Addf(uint64(tagPos), dartfmt.DiagTruncated,
					"cluster %d/%d: tags: %v", i, nc, err)
				break
			}
			cid, canonical, immutable = DecodeTags(tags)
		case snapshot.TagStyleCidInt32:
			// v2.10-2.13: Read<int32_t>(cid). Signed VLE (endMarker=192), value = CID directly.
			// Canonical determined by cluster loop position (first NumCanonicalClusters are canonical).
			rawCid, err := s.ReadTagged64()
			if err != nil {
				diags.Addf(uint64(tagPos), dartfmt.DiagTruncated,
					"cluster %d/%d: tags: %v", i, nc, err)
				break
			}
			cid = int(rawCid)
			// In split-canonical format, clusters before NumCanonicalClusters are canonical.
			if profile.SplitCanonical {
				canonical = i < int(result.Header.NumCanonicalClusters)
			}
		}
		// Check if we broke out of the switch due to error.
		if s.Position() == tagPos {
			break
		}

		cm := ClusterMeta{
			Index:       i,
			CID:         cid,
			IsCanonical: canonical,
			IsImmutable: immutable,
			StartRef:    nextRef,
			StartOffset: tagPos,
		}

		// Skip alloc data for this cluster using version-aware CID dispatch.
		// Mint clusters are handled separately to capture ref→value mapping.
		var count int64
		var err error
		if ClassifyAlloc(cid, ct) == AllocMint {
			var mintVals []int64
			count, mintVals, err = readMintAlloc(s, profile.PreCanonicalSplit, maxSteps)
			if err == nil && result.MintValues == nil {
				result.MintValues = make(map[int]int64)
			}
			for j, v := range mintVals {
				result.MintValues[nextRef+j] = v
			}
		} else {
			count, err = skipAllocV(s, &cm, canonical, ct, isVM, profile, &diags, maxSteps)
		}
		if err != nil {
			name := CidNameV(cid, ct)
			if name == "" {
				name = fmt.Sprintf("CID_%d", cid)
			}
			if debugAlloc {
				ak := ClassifyAlloc(cid, ct)
				fmt.Fprintf(os.Stderr, "ALLOC[%3d] CID=%-4d %-24s kind=%-2d count=%-6d pos=0x%06x ERR: %v\n",
					i, cid, name, ak, count, s.Position(), err)
			}
			diags.Addf(uint64(s.Position()), dartfmt.DiagTruncated,
				"cluster %d (CID %d %s): alloc skip: %v", i, cid, name, err)
			cm.EndOffset = s.Position()
			cm.StopRef = nextRef + int(count)
			result.Clusters = append(result.Clusters, cm)
			break
		}
		cm.Count = count
		cm.StopRef = nextRef + int(count)
		cm.EndOffset = s.Position()
		nextRef = cm.StopRef
		result.Clusters = append(result.Clusters, cm)

		if debugAlloc {
			name := CidNameV(cid, ct)
			if name == "" {
				name = fmt.Sprintf("CID_%d", cid)
			}
			ak := ClassifyAlloc(cid, ct)
			fmt.Fprintf(os.Stderr, "ALLOC[%3d] CID=%-4d %-24s kind=%-2d count=%-6d tag=0x%06x end=0x%06x refs=%d-%d\n",
				i, cid, name, ak, count, cm.StartOffset, cm.EndOffset, cm.StartRef, cm.StopRef)
		}
	}

	result.FillStart = s.Position()
	if debugAlloc {
		fmt.Fprintf(os.Stderr, "ALLOC: nc=%d, FillStart=0x%06x totalRefs=%d expectedObjs=%d deficit=%d\n",
			nc, result.FillStart, nextRef-1, result.Header.NumObjects, result.Header.NumObjects-int64(nextRef-1))
	}
	result.Diags = diags.Items()
	return result, nil
}

// FindClusterDataStart returns the byte offset where clustered data begins
// within a snapshot data region. This is after: magic(4) + length(8) + kind(8) +
// hash(32) + features(null-terminated).
func FindClusterDataStart(data []byte) (int, error) {
	const minHeader = 0x35 // magic + length + kind + hash
	if len(data) < minHeader {
		return 0, fmt.Errorf("cluster: data too short (%d < %d)", len(data), minHeader)
	}

	// Features string starts at offset 0x34, null-terminated.
	featStart := 0x34
	for i := featStart; i < len(data); i++ {
		if data[i] == 0 {
			return i + 1, nil // byte after null terminator
		}
		if i-featStart > 1024 {
			return 0, fmt.Errorf("cluster: features string too long (no null terminator within 1024 bytes)")
		}
	}
	return 0, fmt.Errorf("cluster: unterminated features string")
}

// skipAllocV dispatches alloc skipping using version-aware CID classification.
// isVM indicates the VM snapshot, where String canonical sets are absent.
// cm is used to store extra metadata (e.g. NextFieldOffsetInWords for Instance clusters).
func skipAllocV(s *dartfmt.Stream, cm *ClusterMeta, isCanonical bool, ct *snapshot.CIDTable, isVM bool, profile *snapshot.VersionProfile, diags *dartfmt.Diags, maxSteps int) (int64, error) {
	cid := cm.CID
	kind := ClassifyAlloc(cid, ct)
	switch kind {
	case AllocSimple:
		return skipFixedAllocSimple(s, maxSteps)
	case AllocCanonicalSet:
		if profile.PreCanonicalSplit {
			// v2.10: Type and TypeParameter have internal canonical/non-canonical
			// split: two counts (canonical_count, non_canonical_count) with no
			// canonical set hash table data.
			return skipDualCountAlloc(s, maxSteps)
		}
		// In Dart 2.13 (SplitCanonical), BuildCanonicalSetFromLayout only writes
		// first_element for Type (kAllCanonicalObjectsAreIncludedIntoSet=false).
		// All other canonical set types have first_element hardcoded to 0 and NOT
		// in the stream. In 2.14+, first_element is always in the stream.
		readFirstElement := true
		if profile.SplitCanonical {
			readFirstElement = (cid == ct.Type)
		}
		return skipFixedWithCanonicalSet(s, isCanonical, readFirstElement, maxSteps)
	case AllocString:
		// In AOT without compressed-pointers, strings use ROData format:
		// count + per-item offset delta (not per-string length).
		// SplitCanonical (2.13) always uses ROData for strings.
		// For other versions, check CompressedPointers flag.
		if profile.SplitCanonical || !profile.CompressedPointers {
			// Only the abstract kStringCid has canonical set data in ROData.
			// OneByteString/TwoByteString via ROData have no canonical set,
			// even when the cluster is canonical (cid_ != kStringCid in C++).
			hasCanonicalSet := isCanonical && cid == ct.String
			// Pass cm to record offset deltas for later string extraction.
			return skipRODataAlloc(s, cm, hasCanonicalSet, !profile.SplitCanonical, maxSteps)
		}
		// VM snapshot strings never have canonical set data.
		return skipStringAlloc(s, isCanonical && !isVM, maxSteps)
	case AllocMint:
		// Handled in the alloc loop via readMintAlloc (captures ref→value mapping).
		// This path should not be reached.
		return 0, fmt.Errorf("AllocMint should be handled before skipAllocV")
	case AllocArray:
		return skipArrayAlloc(s, cm, maxSteps)
	case AllocWeakArray:
		return skipWeakArrayAlloc(s, cm, maxSteps)
	case AllocTypeArguments:
		// TypeArguments uses kAllCanonicalObjectsAreIncludedIntoSet=true.
		// In 2.13 (SplitCanonical), first_element is NOT in stream.
		// In 2.14+, first_element is always in stream.
		return skipTypeArgumentsAlloc(s, cm, isCanonical, !profile.SplitCanonical, maxSteps)
	case AllocClass:
		return skipClassAlloc(s, cm, ct, maxSteps)
	case AllocCode:
		// In Dart ≤2.13, Code alloc has no per-object state_bits (they are in fill).
		// In 2.14+, state_bits moved to alloc phase.
		stateBitsInAlloc := profile.Tags != snapshot.TagStyleCidInt32
		return skipCodeAlloc(s, cm, stateBitsInAlloc, maxSteps)
	case AllocObjectPool:
		return skipObjectPoolAlloc(s, cm, maxSteps)
	case AllocROData:
		// ROData for PcDescriptors/CodeSourceMap/CompressedStackMaps is never canonical,
		// so the readFirstElement value doesn't matter. Pass nil cm (no string extraction).
		return skipRODataAlloc(s, nil, isCanonical, !profile.SplitCanonical, maxSteps)
	case AllocExceptionHandlers:
		return skipExceptionHandlersAlloc(s, cm, maxSteps)
	case AllocContext:
		return skipContextAlloc(s, cm, maxSteps)
	case AllocContextScope:
		return skipContextScopeAlloc(s, cm, maxSteps)
	case AllocRecord:
		return skipRecordAlloc(s, cm, maxSteps)
	case AllocTypedData:
		return skipTypedDataAlloc(s, cm, maxSteps)
	case AllocInstance:
		return skipInstanceAllocV(s, cm, maxSteps)
	case AllocEmpty:
		// WeakSerializationReference in v2.13+: WriteAlloc writes only the CID tag,
		// ReadAlloc reads nothing. In v2.10 (PreCanonicalSplit), WSR has a count.
		if profile.PreCanonicalSplit {
			return skipFixedAllocSimple(s, maxSteps)
		}
		return 0, nil
	default:
		return 0, fmt.Errorf("unknown CID %d", cid)
	}
}

// skipDualCountAlloc handles v2.10 PreCanonicalSplit clusters (Type, TypeParameter)
// where canonical and non-canonical objects are counted separately within one cluster:
// canonical_count = ReadUnsigned(), non_canonical_count = ReadUnsigned().
// No canonical set hash table data.
func skipDualCountAlloc(s *dartfmt.Stream, maxSteps int) (int64, error) {
	canonical, err := s.ReadUnsigned()
	if err != nil {
		return 0, fmt.Errorf("canonical count: %w", err)
	}
	if canonical < 0 || int(canonical) > maxSteps {
		return 0, fmt.Errorf("canonical count %d out of range", canonical)
	}
	nonCanonical, err := s.ReadUnsigned()
	if err != nil {
		return canonical, fmt.Errorf("non-canonical count: %w", err)
	}
	if nonCanonical < 0 || int(nonCanonical) > maxSteps {
		return canonical, fmt.Errorf("non-canonical count %d out of range", nonCanonical)
	}
	return canonical + nonCanonical, nil
}

// skipFixedAllocSimple skips a cluster whose alloc is just: count = ReadUnsigned().
func skipFixedAllocSimple(s *dartfmt.Stream, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("count %d out of range", count)
	}
	return count, nil
}

// skipFixedWithCanonicalSet skips a fixed-size cluster that may have canonical set data.
// Used for Type, FunctionType, RecordType, TypeParameter, ConstMap, ConstSet.
// readFirstElement controls whether BuildCanonicalSetFromLayout reads first_element
// from the stream (true for ≥2.17, true only for Type in ≤2.16).
func skipFixedWithCanonicalSet(s *dartfmt.Stream, isCanonical bool, readFirstElement bool, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("count %d out of range", count)
	}
	if isCanonical {
		if err := skipCanonicalSet(s, int(count), readFirstElement, maxSteps); err != nil {
			return count, fmt.Errorf("canonical set: %w", err)
		}
	}
	return count, nil
}

// skipCanonicalSet reads the BuildCanonicalSetFromLayout data:
//
//	table_length: ReadUnsigned()
//	first_element: ReadUnsigned()   (only if readFirstElement is true)
//	for i in 0..(count - first_element): gap = ReadUnsigned()
//
// readFirstElement controls whether first_element is present in the stream.
// In Dart ≤2.16, only Type sets kAllCanonicalObjectsAreIncludedIntoSet=false,
// meaning first_element is written/read. All other types (TypeParameter,
// FunctionType, TypeArguments, etc.) use the default true, so first_element
// is hardcoded to 0 and NOT in the stream. In Dart ≥2.17, the format was
// simplified: first_element is always in the stream for all types.
func skipCanonicalSet(s *dartfmt.Stream, count int, readFirstElement bool, maxSteps int) error {
	// Table length (hash table backing array size).
	tableLen, err := s.ReadUnsigned()
	if err != nil {
		return fmt.Errorf("table_length: %w", err)
	}
	if tableLen < 0 || int(tableLen) > maxSteps*16 {
		return fmt.Errorf("table_length %d out of range", tableLen)
	}
	// first_element: number of objects that precede the first gap.
	// Only present in stream when readFirstElement is true.
	var firstElement int64
	if readFirstElement {
		firstElement, err = s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("first_element: %w", err)
		}
		if firstElement < 0 || int(firstElement) > count {
			return fmt.Errorf("first_element %d out of range (count=%d)", firstElement, count)
		}
	}
	// Number of gap values = count - first_element.
	numGaps := count - int(firstElement)
	for i := 0; i < numGaps; i++ {
		if _, err := s.ReadUnsigned(); err != nil {
			return fmt.Errorf("gap %d/%d: %w", i, numGaps, err)
		}
	}
	return nil
}

// skipStringAlloc skips String cluster alloc:
//
//	count + per-string encoded length + canonical set (if canonical).
func skipStringAlloc(s *dartfmt.Stream, isCanonical bool, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("string count %d out of range", count)
	}
	for i := int64(0); i < count; i++ {
		// Each string alloc reads: encoded = ReadUnsigned() (length<<1 | cid_flag)
		if _, err := s.ReadUnsigned(); err != nil {
			return count, fmt.Errorf("string %d/%d alloc: %w", i, count, err)
		}
	}
	if isCanonical {
		// String canonical sets in ≥2.17 always write first_element (kAllCanonical=true
		// but format always includes it). This path is only used for non-SplitCanonical (≥2.17).
		if err := skipCanonicalSet(s, int(count), true, maxSteps); err != nil {
			return count, fmt.Errorf("string canonical set: %w", err)
		}
	}
	return count, nil
}

// readMintAlloc reads Mint cluster alloc, capturing ref→value pairs.
//
// All versions: count + per-mint Read<int64_t>() value.
// v2.10 PreCanonicalSplit: per-mint also has Read<bool>(is_canonical) before value.
func readMintAlloc(s *dartfmt.Stream, preCanonicalSplit bool, maxSteps int) (int64, []int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, nil, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, nil, fmt.Errorf("mint count %d out of range", count)
	}
	// Each mint reads its value during alloc (to determine Smi vs heap Mint).
	values := make([]int64, count)
	for i := int64(0); i < count; i++ {
		if preCanonicalSplit {
			// v2.10: Read<bool>(is_canonical) = 1 raw byte.
			if _, err := s.ReadByte(); err != nil {
				return count, values, fmt.Errorf("mint %d/%d canonical: %w", i, count, err)
			}
		}
		v, err := s.ReadTagged64()
		if err != nil {
			return count, values, fmt.Errorf("mint %d/%d value: %w", i, count, err)
		}
		values[i] = v
	}
	return count, values, nil
}

// skipArrayAlloc skips Array/ImmutableArray alloc: count + per-element length.
func skipArrayAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("array count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("array %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipTypeArgumentsAlloc skips TypeArguments alloc:
//
//	count + per-item length + canonical set (if canonical).
//
// readFirstElement: whether canonical set has first_element in stream (≥2.17: true, ≤2.16: false).
func skipTypeArgumentsAlloc(s *dartfmt.Stream, cm *ClusterMeta, isCanonical bool, readFirstElement bool, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("type_arguments count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("type_arguments %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	if isCanonical {
		if err := skipCanonicalSet(s, int(count), readFirstElement, maxSteps); err != nil {
			return count, fmt.Errorf("type_arguments canonical set: %w", err)
		}
	}
	return count, nil
}

// skipClassAlloc skips Class alloc:
//
//	predefined_count + per-class ReadCid(), then new_count.
//
// Some Dart SDK builds (observed in Dart 3.5.1 / Flutter forks) write an extra
// WriteUnsigned(total_class_count) before the standard predefined_count field.
// We detect this by checking whether the first value exceeds NumPredefinedCids;
// if so, we consume it and read the next value as the actual predefined_count.
//
// Stores predefined count in cm.MainCount for fill-phase use.
func skipClassAlloc(s *dartfmt.Stream, cm *ClusterMeta, ct *snapshot.CIDTable, maxSteps int) (int64, error) {
	predefined, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	// Heuristic: predefined_count must be ≤ NumPredefinedCids (174 for v3.4.3+).
	// If the value is larger, it's an extra "total class count" prefix; skip it
	// and read the real predefined_count.
	if ct != nil && int(predefined) > ct.NumPredefinedCids {
		predefined, err = s.ReadUnsigned()
		if err != nil {
			return 0, err
		}
	}
	if predefined < 0 || int(predefined) > maxSteps {
		return 0, fmt.Errorf("predefined class count %d out of range", predefined)
	}
	cm.PredefCIDs = make([]int64, predefined)
	for i := int64(0); i < predefined; i++ {
		// ReadCid() = Read<int32_t>() with kEndByteMarker=192.
		cid, err := s.ReadTagged32()
		if err != nil {
			return 0, fmt.Errorf("predefined class %d/%d cid: %w", i, predefined, err)
		}
		cm.PredefCIDs[i] = int64(cid)
	}
	newCount, err := s.ReadUnsigned()
	if err != nil {
		return predefined, err
	}
	if newCount < 0 || int(newCount) > maxSteps {
		return predefined, fmt.Errorf("new class count %d out of range", newCount)
	}
	cm.MainCount = predefined
	return predefined + newCount, nil
}

// skipCodeAlloc skips Code cluster alloc.
//
// Format depends on Dart version:
//   - 2.14+: count + per-code state_bits(int32_t), deferred_count + per-deferred state_bits(int32_t)
//   - ≤2.13: count, deferred_count (no per-object data; state_bits read during fill)
func skipCodeAlloc(s *dartfmt.Stream, cm *ClusterMeta, stateBitsInAlloc bool, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("code count %d out of range", count)
	}
	if stateBitsInAlloc {
		for i := int64(0); i < count; i++ {
			sb, err := s.ReadTagged32()
			if err != nil {
				return count, fmt.Errorf("code %d/%d state_bits: %w", i, count, err)
			}
			// DiscardedBit is bit 3 of state_bits (Dart 2.14+).
			if (sb>>3)&1 != 0 {
				if cm.DiscardedCodes == nil {
					cm.DiscardedCodes = make(map[int64]bool)
				}
				cm.DiscardedCodes[i] = true
			}
		}
	}
	cm.MainCount = count
	// Deferred code section.
	deferred, err := s.ReadUnsigned()
	if err != nil {
		return count, fmt.Errorf("deferred code count: %w", err)
	}
	if deferred < 0 || int(deferred) > maxSteps {
		return count, fmt.Errorf("deferred code count %d out of range", deferred)
	}
	if stateBitsInAlloc {
		for i := int64(0); i < deferred; i++ {
			sb, err := s.ReadTagged32()
			if err != nil {
				return count + deferred, fmt.Errorf("deferred code %d/%d state_bits: %w", i, deferred, err)
			}
			// Deferred codes should not be discarded (Dart asserts this).
			if (sb>>3)&1 != 0 {
				if cm.DiscardedCodes == nil {
					cm.DiscardedCodes = make(map[int64]bool)
				}
				cm.DiscardedCodes[count+i] = true
			}
		}
	}
	return count + deferred, nil
}

// skipObjectPoolAlloc skips ObjectPool cluster alloc: count + per-pool length.
func skipObjectPoolAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("object_pool count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("object_pool %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipRODataAlloc skips ROData cluster alloc (used in AOT for PcDescriptors,
// CodeSourceMap, CompressedStackMaps, and sometimes String).
//
//	count + per-item ReadUnsigned() (running offset delta).
//	If CID is String and canonical, also reads canonical set data.
//
// readFirstElement: whether canonical set has first_element in stream.
// If cm is non-nil, records the offset deltas in cm.Lengths for later extraction.
func skipRODataAlloc(s *dartfmt.Stream, cm *ClusterMeta, isCanonical bool, readFirstElement bool, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("rodata count %d out of range", count)
	}
	if cm != nil {
		cm.Lengths = make([]int64, count)
	}
	for i := int64(0); i < count; i++ {
		delta, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("rodata %d/%d offset: %w", i, count, err)
		}
		if cm != nil {
			cm.Lengths[i] = delta
		}
	}
	// ROData canonical set is only for String CID, but we pass isCanonical
	// for safety — the caller knows the CID.
	if isCanonical {
		if err := skipCanonicalSet(s, int(count), readFirstElement, maxSteps); err != nil {
			return count, fmt.Errorf("rodata canonical set: %w", err)
		}
	}
	return count, nil
}

// skipExceptionHandlersAlloc skips ExceptionHandlers alloc: count + per-handler length.
func skipExceptionHandlersAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("exception_handlers count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("exception_handlers %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipContextAlloc skips Context cluster alloc: count + per-context num_variables.
func skipContextAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("context count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("context %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipContextScopeAlloc skips ContextScope cluster alloc: count + per-scope length.
func skipContextScopeAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("context_scope count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("context_scope %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipWeakArrayAlloc skips WeakArray cluster alloc: count + per-array length.
func skipWeakArrayAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("weak_array count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("weak_array %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipRecordAlloc skips Record cluster alloc: count + per-record num_fields.
func skipRecordAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("record count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("record %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipTypedDataAlloc skips TypedData cluster alloc: count + per-item length.
func skipTypedDataAlloc(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("typed_data count %d out of range", count)
	}
	cm.Lengths = make([]int64, count)
	for i := int64(0); i < count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return count, fmt.Errorf("typed_data %d/%d alloc: %w", i, count, err)
		}
		cm.Lengths[i] = length
	}
	return count, nil
}

// skipInstanceAllocV skips a generic Instance alloc and stores layout in cm:
//
//	count = ReadUnsigned()
//	next_field_offset = Read<int32_t>()
//	instance_size = Read<int32_t>()
func skipInstanceAllocV(s *dartfmt.Stream, cm *ClusterMeta, maxSteps int) (int64, error) {
	count, err := s.ReadUnsigned()
	if err != nil {
		return 0, err
	}
	if count < 0 || int(count) > maxSteps {
		return 0, fmt.Errorf("instance(%d) count %d out of range", cm.CID, count)
	}
	// Instance alloc reads two layout values using Read<int32_t>() (marker 192).
	nfo, err := s.ReadTagged32()
	if err != nil {
		return count, fmt.Errorf("instance(%d) next_field_offset: %w", cm.CID, err)
	}
	cm.NextFieldOffsetInWords = int32(nfo)
	if _, err := s.ReadTagged32(); err != nil {
		return count, fmt.Errorf("instance(%d) instance_size: %w", cm.CID, err)
	}
	return count, nil
}

```

`internal/cluster/cluster_test.go`:

```go
package cluster

import (
	"os"
	"path/filepath"
	"testing"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

func findSample(t *testing.T, name string) string {
	t.Helper()
	dir, _ := os.Getwd()
	for {
		p := filepath.Join(dir, "samples", name)
		if _, err := os.Stat(p); err == nil {
			return p
		}
		parent := filepath.Dir(dir)
		if parent == dir {
			t.Skipf("sample %s not found", name)
		}
		dir = parent
	}
}

func extractSnapshot(t *testing.T, name string) *snapshot.Info {
	t.Helper()
	path := findSample(t, name)
	ef, err := elfx.Open(path)
	if err != nil {
		t.Fatal(err)
	}
	t.Cleanup(func() { ef.Close() })

	info, err := snapshot.Extract(ef, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
	if err != nil {
		t.Fatal(err)
	}
	return info
}

func scanSnapshot(t *testing.T, info *snapshot.Info, data []byte, isVM bool) *Result {
	t.Helper()
	if len(data) < 64 {
		t.Fatal("data too short")
	}
	cs, err := FindClusterDataStart(data)
	if err != nil {
		t.Fatal(err)
	}
	result, err := ScanClusters(data, cs, info.Version, isVM, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
	if err != nil {
		t.Fatal(err)
	}
	return result
}

func TestScanClusters_EvilPatched_VM(t *testing.T) {
	info := extractSnapshot(t, "evil-patched.so")
	result := scanSnapshot(t, info, info.VmData.Data, true)

	if int64(len(result.Clusters)) != result.Header.NumClusters {
		t.Errorf("decoded %d clusters, want %d", len(result.Clusters), result.Header.NumClusters)
	}
	if result.Header.NumClusters != 6 {
		t.Errorf("NumClusters = %d, want 6", result.Header.NumClusters)
	}
}

func TestScanClusters_EvilPatched_Isolate(t *testing.T) {
	info := extractSnapshot(t, "evil-patched.so")
	result := scanSnapshot(t, info, info.IsolateData.Data, false)

	if int64(len(result.Clusters)) != result.Header.NumClusters {
		t.Errorf("decoded %d clusters, want %d", len(result.Clusters), result.Header.NumClusters)
	}
	if result.Header.NumClusters != 56 {
		t.Errorf("NumClusters = %d, want 56", result.Header.NumClusters)
	}

	// First cluster should be String (kStringCid, used for canonical string clusters).
	if result.Clusters[0].CID != info.Version.CIDs.String {
		t.Errorf("first cluster CID = %d, want String (%d)", result.Clusters[0].CID, info.Version.CIDs.String)
	}
}

func TestScanClusters_BlutterLce_VM(t *testing.T) {
	info := extractSnapshot(t, "blutter-lce.so")
	if info.Version == nil || info.Version.DartVersion != "2.17.6" {
		t.Fatalf("expected version 2.17.6, got %v", info.Version)
	}
	result := scanSnapshot(t, info, info.VmData.Data, true)

	if int64(len(result.Clusters)) != result.Header.NumClusters {
		t.Errorf("decoded %d clusters, want %d", len(result.Clusters), result.Header.NumClusters)
	}
	if result.Header.NumClusters != 6 {
		t.Errorf("NumClusters = %d, want 6", result.Header.NumClusters)
	}
}

func TestScanClusters_BlutterLce_Isolate(t *testing.T) {
	info := extractSnapshot(t, "blutter-lce.so")
	result := scanSnapshot(t, info, info.IsolateData.Data, false)

	if int64(len(result.Clusters)) != result.Header.NumClusters {
		t.Errorf("decoded %d clusters, want %d", len(result.Clusters), result.Header.NumClusters)
	}
	if result.Header.NumClusters != 341 {
		t.Errorf("NumClusters = %d, want 341", result.Header.NumClusters)
	}
}

func TestScanClusters_Newandromo_VM(t *testing.T) {
	info := extractSnapshot(t, "newandromo.so")
	result := scanSnapshot(t, info, info.VmData.Data, true)

	if int64(len(result.Clusters)) != result.Header.NumClusters {
		t.Errorf("decoded %d clusters, want %d", len(result.Clusters), result.Header.NumClusters)
	}
	if result.Header.NumClusters != 7 {
		t.Errorf("NumClusters = %d, want 7", result.Header.NumClusters)
	}
}

func TestScanClusters_Newandromo_Isolate(t *testing.T) {
	info := extractSnapshot(t, "newandromo.so")
	result := scanSnapshot(t, info, info.IsolateData.Data, false)

	if int64(len(result.Clusters)) != result.Header.NumClusters {
		t.Errorf("decoded %d clusters, want %d", len(result.Clusters), result.Header.NumClusters)
	}
	if result.Header.NumClusters != 655 {
		t.Errorf("NumClusters = %d, want 655", result.Header.NumClusters)
	}
}

func TestHeaderFieldCount_V2(t *testing.T) {
	info := extractSnapshot(t, "blutter-lce.so")
	if info.Version.HeaderFields != 6 {
		t.Errorf("HeaderFields = %d, want 6 for v2.17.6", info.Version.HeaderFields)
	}

	result := scanSnapshot(t, info, info.IsolateData.Data, false)
	if result.Header.InitialFieldTableLen == 0 {
		t.Error("InitialFieldTableLen should be nonzero for v2.17.6")
	}
}

func TestHeaderFieldCount_V3(t *testing.T) {
	info := extractSnapshot(t, "evil-patched.so")
	if info.Version.HeaderFields != 5 {
		t.Errorf("HeaderFields = %d, want 5 for v3.10.7", info.Version.HeaderFields)
	}

	result := scanSnapshot(t, info, info.IsolateData.Data, false)
	if result.Header.InitialFieldTableLen != 0 {
		t.Errorf("InitialFieldTableLen = %d, want 0 for v3.x", result.Header.InitialFieldTableLen)
	}
}

// TestPatchClassRefCount is a drift sentinel: pins the PatchClass ref count
// per format boundary. If the PreV32Format flag or specPatchClass logic changes,
// this fails before stream corruption can propagate to downstream clusters.
func TestPatchClassRefCount(t *testing.T) {
	tests := []struct {
		sample   string
		wantRefs int
	}{
		{"blutter-lce.so", 3},  // v2.17.6: PreV32Format=true → 3 refs
		{"newandromo.so", 3},   // v3.1.0:  PreV32Format=true → 3 refs
		{"evil-patched.so", 2}, // v3.10.7: PreV32Format=false → 2 refs
	}
	for _, tt := range tests {
		t.Run(tt.sample, func(t *testing.T) {
			info := extractSnapshot(t, tt.sample)
			patchCID := info.Version.CIDs.PatchClass
			spec := GetFillSpec(patchCID, &ClusterMeta{CID: patchCID}, info.Version)
			if spec.NumRefs != tt.wantRefs {
				t.Errorf("PatchClass NumRefs = %d, want %d (PreV32Format=%v)",
					spec.NumRefs, tt.wantRefs, info.Version.PreV32Format)
			}
		})
	}
}

// TestReadFill_AllSamples is the integration drift sentinel: full fill parsing
// must complete without error and produce exact string/named counts. Any ref
// count mismatch in ANY cluster propagates as stream drift and fails here.
func TestReadFill_AllSamples(t *testing.T) {
	tests := []struct {
		sample      string
		wantStrings int
		wantNamed   int
		wantCodes   int
	}{
		{"evil-patched.so", 2352, 2367, 1465},
		{"blutter-lce.so", 12314, 14883, 10113},
		{"newandromo.so", 24019, 12912, 4152},
	}
	for _, tt := range tests {
		t.Run(tt.sample, func(t *testing.T) {
			info := extractSnapshot(t, tt.sample)
			data := info.IsolateData.Data
			result := scanSnapshot(t, info, data, false)
			if err := ReadFill(data, result, info.Version, false, 0); err != nil {
				t.Fatalf("ReadFill: %v", err)
			}
			if len(result.Strings) != tt.wantStrings {
				t.Errorf("Strings = %d, want %d", len(result.Strings), tt.wantStrings)
			}
			if len(result.Named) != tt.wantNamed {
				t.Errorf("Named = %d, want %d", len(result.Named), tt.wantNamed)
			}
			if len(result.Codes) != tt.wantCodes {
				t.Errorf("Codes = %d, want %d", len(result.Codes), tt.wantCodes)
			}
		})
	}
}

func TestClassifyAlloc_TypedDataInternal(t *testing.T) {
	ct := &snapshot.CIDTable{
		TypedDataInt8ArrayCid: 112,
		ByteDataViewCid:       168,
		TypedDataCidStride:    4,
		NativePointerCid:      1,
		Instance:              45,
	}

	// TypedData internal CIDs should classify as AllocTypedData.
	for cid := 112; cid < 168; cid += 4 {
		kind := ClassifyAlloc(cid, ct)
		if kind != AllocTypedData {
			t.Errorf("CID %d: got %d, want AllocTypedData", cid, kind)
		}
	}

	// View CIDs (remainder 1) should NOT match TypedData, should fall to Instance.
	kind := ClassifyAlloc(113, ct)
	if kind != AllocInstance {
		t.Errorf("CID 113 (view): got %d, want AllocInstance", kind)
	}

	// DeltaEncodedTypedData (CID 1) should classify as AllocTypedData.
	kind = ClassifyAlloc(1, ct)
	if kind != AllocTypedData {
		t.Errorf("CID 1 (DeltaEncodedTypedData): got %d, want AllocTypedData", kind)
	}
}

func TestCidNameV_TypedDataInternal(t *testing.T) {
	ct := &snapshot.CIDTable{
		TypedDataInt8ArrayCid: 112,
		ByteDataViewCid:       168,
		TypedDataCidStride:    4,
		NativePointerCid:      1,
	}

	tests := []struct {
		cid  int
		want string
	}{
		{112, "TypedDataInt8Array"},
		{116, "TypedDataUint8Array"},
		{113, "TypedDataInt8ArrayView"},
		{114, "ExternalTypedDataInt8Array"},
		{115, "UnmodifiableTypedDataInt8ArrayView"},
		{1, "DeltaEncodedTypedData"},
	}

	for _, tt := range tests {
		got := CidNameV(tt.cid, ct)
		if got != tt.want {
			t.Errorf("CidNameV(%d) = %q, want %q", tt.cid, got, tt.want)
		}
	}
}

```

`internal/cluster/fill.go`:

```go
package cluster

import (
	"encoding/binary"
	"fmt"
	"io"
	"os"

	"unflutter/internal/dartfmt"
	"unflutter/internal/snapshot"
)

var debugFill = os.Getenv("DEFLUTTER_DEBUG_FILL") != ""

// NamedObject holds a named object extracted from the fill section.
type NamedObject struct {
	CID            int
	RefID          int
	NameRefID      int // ref ID pointing to name string (-1 if none)
	OwnerRefID     int // ref ID pointing to owner (-1 if none)
	SignatureRefID int // ref ID pointing to FunctionType signature (-1 if none)
}

// FuncTypeInfo holds parameter count data extracted from a FunctionType object.
type FuncTypeInfo struct {
	RefID       int
	NumFixed    int  // fixed parameters (excludes implicit 'this')
	NumOptional int  // optional parameters
	HasImplicit bool // true if instance method (has implicit 'this' parameter)
}

// ClassInfo holds class layout data extracted from a Class object's fill.
type ClassInfo struct {
	RefID        int
	NameRefID    int
	ClassID      int32
	InstanceSize int32
	NextFieldOff int32 // next_field_offset in bytes
	TypeArgsOff  int32 // type_arguments field offset in bytes
}

// FieldInfo holds field layout data extracted from a Field object's fill.
type FieldInfo struct {
	RefID      int
	NameRefID  int
	OwnerRefID int
	KindBits   int32
	HostOffset int32 // byte offset within instance; -1 for static fields
}

// readRef reads a fill-phase ref using the correct encoding for the version.
// ≤2.17 (fillRefUnsigned=true): ReadRef() → ReadUnsigned() (marker 128, little-endian).
// ≥2.18 (fillRefUnsigned=false): ReadRef() → ReadRefId() (big-endian, signed-byte).
func readRef(s *dartfmt.Stream, fillRefUnsigned bool) (int64, error) {
	if fillRefUnsigned {
		return s.ReadUnsigned()
	}
	return s.ReadRefId()
}

// DebugFillPositions iterates the fill section and prints the stream position
// before/after each cluster's fill to w. Used to diagnose fill drift.
func DebugFillPositions(data []byte, result *Result, profile *snapshot.VersionProfile, isVM bool, w io.Writer) error {
	if result.FillStart <= 0 || result.FillStart >= len(data) {
		return fmt.Errorf("fill: invalid start offset %d", result.FillStart)
	}
	s := dartfmt.NewStreamAt(data, result.FillStart)
	fillRefUnsigned := profile.FillRefUnsigned
	instrIdx := 0
	for i := range result.Clusters {
		cm := &result.Clusters[i]
		spec := GetFillSpec(cm.CID, cm, profile)
		startPos := s.Position()
		name := CidNameV(cm.CID, profile.CIDs)
		if name == "" {
			name = fmt.Sprintf("CID_%d", cm.CID)
		}
		err := fillOneCluster(s, cm, &spec, fillRefUnsigned, profile, &instrIdx, nil)
		endPos := s.Position()
		delta := endPos - startPos
		status := "OK"
		if err != nil {
			status = fmt.Sprintf("ERR: %v", err)
		}
		nfoStr := ""
		if cm.NextFieldOffsetInWords != 0 {
			nfoStr = fmt.Sprintf(" nfo=%d", cm.NextFieldOffsetInWords)
		}
		fmt.Fprintf(w, "FILL[%3d] CID=%-3d %-24s kind=%-2d count=%-5d start=0x%06x end=0x%06x delta=%-6d%s %s\n",
			i, cm.CID, name, spec.Kind, cm.Count, startPos, endPos, delta, nfoStr, status)
		if err != nil {
			return err
		}
	}
	return nil
}

// FillOneClusterExported is an exported wrapper around fillOneCluster for debug tools.
func FillOneClusterExported(s *dartfmt.Stream, cm *ClusterMeta, spec *FillSpec, fillRefUnsigned bool, profile *snapshot.VersionProfile, instrIdx *int) error {
	return fillOneCluster(s, cm, spec, fillRefUnsigned, profile, instrIdx, nil)
}

// dataImageObjStart computes the byte offset within data[] where ROData objects begin.
// snapshotSize is the TotalSize from the snapshot header.
// Returns 0 if ROData string extraction is not applicable.
func dataImageObjStart(dataLen int, snapshotSize int64, profile *snapshot.VersionProfile) int64 {
	if snapshotSize <= 0 || profile.CompressedPointers {
		return 0
	}
	var align int64
	if profile.TopLevelCid16 {
		align = 16
	} else {
		align = 64
	}
	diStart := (snapshotSize + align - 1) &^ (align - 1)
	objStart := diStart + align // skip image header
	if objStart >= int64(dataLen) {
		return 0
	}
	return objStart
}

// ReadFill parses the fill section of the snapshot, extracting strings
// and named objects. It processes ALL clusters in alloc order.
// snapshotSize is the TotalSize from the snapshot header (needed for ROData string extraction).
func ReadFill(data []byte, result *Result, profile *snapshot.VersionProfile, isVM bool, snapshotSize int64) error {
	if result.FillStart <= 0 || result.FillStart >= len(data) {
		return fmt.Errorf("fill: invalid start offset %d", result.FillStart)
	}

	s := dartfmt.NewStreamAt(data, result.FillStart)
	ct := profile.CIDs
	fillRefUnsigned := profile.FillRefUnsigned
	instrIdx := 0 // running instructions_index_ across Code clusters

	if debugFill {
		fmt.Fprintf(os.Stderr, "fill: %d clusters, fillStart=0x%x, dataLen=0x%x\n", len(result.Clusters), result.FillStart, len(data))
		for ci := range result.Clusters {
			cc := &result.Clusters[ci]
			name := CidNameV(cc.CID, ct)
			if name == "" {
				name = fmt.Sprintf("CID_%d", cc.CID)
			}
			fmt.Fprintf(os.Stderr, "  cluster[%d] CID=%d (%s) count=%d canonical=%v refs=%d..%d\n",
				ci, cc.CID, name, cc.Count, cc.IsCanonical, cc.StartRef, cc.StopRef)
		}
	}

	for i := range result.Clusters {
		cm := &result.Clusters[i]
		spec := GetFillSpec(cm.CID, cm, profile)
		fillPos := s.Position()
		if debugFill {
			fmt.Fprintf(os.Stderr, "fill[%d] CID=%d kind=%d count=%d pos=0x%x\n", i, cm.CID, spec.Kind, cm.Count, s.Position())
		}

		switch spec.Kind {
		case FillString:
			strings, err := readFillStrings(s, cm, profile.OldStringFormat, profile.CIDs)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (String CID %d): %w", i, cm.CID, err)
			}
			result.Strings = append(result.Strings, strings...)

		case FillNone, FillSentinel, FillInstructionsTable:
			// No fill data to read.

		case FillROData:
			// No fill data in the stream, but for string ROData clusters,
			// extract string data from the data image region.
			// In non-compressed-pointers mode, the abstract String cluster (ct.String)
			// holds deltas for ALL string objects (OneByteString + TwoByteString).
			// OneByteString/TwoByteString clusters are empty (count=0) or have wrong deltas.
			objStart := dataImageObjStart(len(data), snapshotSize, profile)
			if objStart > 0 && len(cm.Lengths) > 0 {
				// Only extract from the abstract String cluster, not from subclass clusters.
				if cm.CID == ct.String {
					strs := extractRODataStrings(data, cm, ct, objStart)
					result.Strings = append(result.Strings, strs...)
				}
			}

		case FillInlineBytes:
			if err := skipFillInlineBytes(s, cm); err != nil {
				return fmt.Errorf("fill: cluster %d (CID %d) pos=0x%x: %w", i, cm.CID, fillPos, err)
			}

		case FillRefs:
			named, funcTypes, fieldInfos, err := readFillRefs(s, cm, &spec, fillRefUnsigned)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (CID %d): %w", i, cm.CID, err)
			}
			result.Named = append(result.Named, named...)
			result.FuncTypes = append(result.FuncTypes, funcTypes...)
			result.Fields = append(result.Fields, fieldInfos...)

		case FillDouble:
			if err := skipFillDouble(s, cm, profile.PreCanonicalSplit); err != nil {
				return fmt.Errorf("fill: cluster %d (Double): %w", i, err)
			}

		case FillCode:
			codes, err := readFillCode(s, cm, profile.CIDs, fillRefUnsigned, instrIdx, profile.CodeNumRefs, profile.CodeTextOffsetDelta, profile.CodeStateBitsAfterRef, profile.CodeStateBitsAtEnd)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (Code): %w", i, err)
			}
			result.Codes = append(result.Codes, codes...)
			// Advance instrIdx by the number of main (non-deferred) codes.
			instrIdx += int(cm.MainCount)

		case FillObjectPool:
			pool, err := readFillObjectPool(s, cm, profile.OldPoolFormat, profile.PoolTypeSwapped, fillRefUnsigned)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (ObjectPool): %w", i, err)
			}
			result.Pool = append(result.Pool, pool...)

		case FillArray:
			if err := skipFillArray(s, cm, fillRefUnsigned, profile); err != nil {
				return fmt.Errorf("fill: cluster %d (Array): %w", i, err)
			}

		case FillWeakArray:
			if err := skipFillWeakArray(s, cm, fillRefUnsigned); err != nil {
				return fmt.Errorf("fill: cluster %d (WeakArray): %w", i, err)
			}

		case FillTypedData:
			if err := skipFillTypedData(s, cm, profile.CIDs, profile.PreCanonicalSplit); err != nil {
				return fmt.Errorf("fill: cluster %d (TypedData CID %d): %w", i, cm.CID, err)
			}

		case FillExceptionHandlers:
			if err := skipFillExceptionHandlers(s, cm, fillRefUnsigned); err != nil {
				return fmt.Errorf("fill: cluster %d (ExceptionHandlers) pos=0x%x: %w", i, fillPos, err)
			}

		case FillContext:
			if err := skipFillContext(s, cm, fillRefUnsigned); err != nil {
				return fmt.Errorf("fill: cluster %d (Context): %w", i, err)
			}

		case FillTypeArguments:
			if err := skipFillTypeArguments(s, cm, fillRefUnsigned, profile); err != nil {
				return fmt.Errorf("fill: cluster %d (TypeArguments): %w", i, err)
			}

		case FillClass:
			named, classInfos, err := readFillClass(s, cm, &spec, fillRefUnsigned, profile.TopLevelCid16, profile.ClassHasTokenPos)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (Class): %w", i, err)
			}
			result.Named = append(result.Named, named...)
			result.Classes = append(result.Classes, classInfos...)

		case FillField:
			named, fieldInfos, err := readFillField(s, cm, &spec, fillRefUnsigned)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (Field): %w", i, err)
			}
			result.Named = append(result.Named, named...)
			result.Fields = append(result.Fields, fieldInfos...)

		case FillInstance:
			if err := skipFillInstance(s, cm, fillRefUnsigned, profile.CompressedPointers, profile.PreCanonicalSplit); err != nil {
				return fmt.Errorf("fill: cluster %d (Instance CID %d): %w", i, cm.CID, err)
			}

		case FillRecord:
			if err := skipFillRecord(s, cm, fillRefUnsigned); err != nil {
				return fmt.Errorf("fill: cluster %d (Record): %w", i, err)
			}

		case FillContextScope:
			if err := skipFillContextScope(s, cm, fillRefUnsigned); err != nil {
				return fmt.Errorf("fill: cluster %d (ContextScope): %w", i, err)
			}

		default:
			return fmt.Errorf("fill: cluster %d (CID %d): unknown fill kind %d", i, cm.CID, spec.Kind)
		}
	}

	return nil
}

// fillOneCluster advances the stream past one cluster's fill data.
// Used by DebugFillPositions to track stream positions without collecting results.
// instrIdx is updated for Code clusters.
func fillOneCluster(s *dartfmt.Stream, cm *ClusterMeta, spec *FillSpec, fillRefUnsigned bool, profile *snapshot.VersionProfile, instrIdx *int, result *Result) error {
	switch spec.Kind {
	case FillString:
		strings, err := readFillStrings(s, cm, profile.OldStringFormat, profile.CIDs)
		if err != nil {
			return err
		}
		if result != nil {
			result.Strings = append(result.Strings, strings...)
		}
	case FillNone, FillSentinel, FillROData, FillInstructionsTable:
		// No fill data.
	case FillInlineBytes:
		return skipFillInlineBytes(s, cm)
	case FillRefs:
		_, _, _, err := readFillRefs(s, cm, spec, fillRefUnsigned)
		return err
	case FillDouble:
		return skipFillDouble(s, cm, profile.PreCanonicalSplit)
	case FillCode:
		_, err := readFillCode(s, cm, profile.CIDs, fillRefUnsigned, *instrIdx, profile.CodeNumRefs, profile.CodeTextOffsetDelta, profile.CodeStateBitsAfterRef, profile.CodeStateBitsAtEnd)
		*instrIdx += int(cm.MainCount)
		return err
	case FillObjectPool:
		_, err := readFillObjectPool(s, cm, profile.OldPoolFormat, profile.PoolTypeSwapped, fillRefUnsigned)
		return err
	case FillArray:
		return skipFillArray(s, cm, fillRefUnsigned, profile)
	case FillWeakArray:
		return skipFillWeakArray(s, cm, fillRefUnsigned)
	case FillTypedData:
		return skipFillTypedData(s, cm, profile.CIDs, profile.PreCanonicalSplit)
	case FillExceptionHandlers:
		return skipFillExceptionHandlers(s, cm, fillRefUnsigned)
	case FillContext:
		return skipFillContext(s, cm, fillRefUnsigned)
	case FillTypeArguments:
		return skipFillTypeArguments(s, cm, fillRefUnsigned, profile)
	case FillClass:
		_, _, err := readFillClass(s, cm, spec, fillRefUnsigned, profile.TopLevelCid16, profile.ClassHasTokenPos)
		return err
	case FillField:
		_, _, err := readFillField(s, cm, spec, fillRefUnsigned)
		return err
	case FillInstance:
		return skipFillInstance(s, cm, fillRefUnsigned, profile.CompressedPointers, profile.PreCanonicalSplit)
	case FillRecord:
		return skipFillRecord(s, cm, fillRefUnsigned)
	case FillContextScope:
		return skipFillContextScope(s, cm, fillRefUnsigned)
	default:
		return fmt.Errorf("unknown fill kind %d", spec.Kind)
	}
	return nil
}

// ReadFillStrings parses the Fill section of the snapshot to extract string
// values. It processes clusters in order, extracting strings from String
// clusters and skipping non-string clusters. Extracted strings are stored
// in result.Strings with their ref IDs for later correlation.
//
// Deprecated: Use ReadFill for full fill parsing including name extraction.
func ReadFillStrings(data []byte, result *Result, profile *snapshot.VersionProfile, isVM bool, snapshotSize int64) error {
	if result.FillStart <= 0 || result.FillStart >= len(data) {
		return fmt.Errorf("fill: invalid start offset %d", result.FillStart)
	}

	s := dartfmt.NewStreamAt(data, result.FillStart)
	ct := profile.CIDs

	for i := range result.Clusters {
		cm := &result.Clusters[i]
		kind := ClassifyAlloc(cm.CID, ct)

		if kind == AllocString {
			// ROData strings (non-compressed-pointers or SplitCanonical) have no fill data.
			// Extract string bytes from the data image region instead.
			if profile.SplitCanonical || !profile.CompressedPointers {
				objStart := dataImageObjStart(len(data), snapshotSize, profile)
				// Only extract from the abstract String cluster (ct.String), not subclass clusters.
				if objStart > 0 && len(cm.Lengths) > 0 && cm.CID == ct.String {
					strs := extractRODataStrings(data, cm, ct, objStart)
					result.Strings = append(result.Strings, strs...)
				}
				continue
			}
			strings, err := readFillStrings(s, cm, profile.OldStringFormat, profile.CIDs)
			if err != nil {
				return fmt.Errorf("fill: cluster %d (String): %w", i, err)
			}
			result.Strings = append(result.Strings, strings...)
		} else {
			break
		}
	}

	return nil
}

// readFillStrings reads the fill data for a String cluster.
// When oldFormat is true (≤2.14), length is plain ReadUnsigned and
// isTwoByte is determined by the cluster CID (ct.TwoByteString).
// When oldFormat is false (≥2.16), length is encoded as (length<<1)|flag.
func readFillStrings(s *dartfmt.Stream, cm *ClusterMeta, oldFormat bool, ct *snapshot.CIDTable) ([]ParsedString, error) {
	count := int(cm.Count)
	if count <= 0 {
		return nil, nil
	}

	// In old format, the CID determines one-byte vs two-byte for the entire cluster.
	cidIsTwoByte := oldFormat && ct != nil && cm.CID == ct.TwoByteString

	strings := make([]ParsedString, 0, count)
	ref := cm.StartRef

	for i := 0; i < count; i++ {
		encoded, err := s.ReadUnsigned()
		if err != nil {
			return strings, fmt.Errorf("string %d/%d encoded: %w", i, count, err)
		}

		var length int
		var isTwoByte bool
		if oldFormat {
			length = int(encoded)
			isTwoByte = cidIsTwoByte
		} else {
			length = int(encoded >> 1)
			isTwoByte = (encoded & 1) != 0
		}

		var value string
		if isTwoByte {
			nbytes := length * 2
			raw, err := s.ReadBytes(nbytes)
			if err != nil {
				return strings, fmt.Errorf("string %d/%d data (%d bytes): %w", i, count, nbytes, err)
			}
			runes := make([]rune, length)
			for j := 0; j < length; j++ {
				runes[j] = rune(uint16(raw[j*2]) | uint16(raw[j*2+1])<<8)
			}
			value = string(runes)
		} else {
			raw, err := s.ReadBytes(length)
			if err != nil {
				return strings, fmt.Errorf("string %d/%d data (%d bytes): %w", i, count, length, err)
			}
			value = string(raw)
		}

		strings = append(strings, ParsedString{
			RefID:     ref,
			Value:     value,
			IsOneByte: !isTwoByte,
		})
		ref++
	}

	return strings, nil
}

// extractRODataStrings reads string data from the data image for ROData string clusters.
// When strings use ROData format (non-compressed-pointers), the string bytes live
// in the data image region of the snapshot, not in the fill stream.
// The alloc phase recorded offset deltas in cm.Lengths.
// dataImageObjStart is the byte offset within data[] where ROData objects begin.
func extractRODataStrings(data []byte, cm *ClusterMeta, ct *snapshot.CIDTable, dataImageObjStart int64) []ParsedString {
	if len(cm.Lengths) == 0 || dataImageObjStart <= 0 {
		return nil
	}

	runningOffset := int64(0)
	ref := cm.StartRef
	var strings []ParsedString

	for i := 0; i < len(cm.Lengths); i++ {
		// First object is at offset 0, then we add deltas cumulatively.
		objPos := dataImageObjStart + runningOffset

		// Need at least 16 bytes for header (tags + length).
		if objPos+16 > int64(len(data)) {
			ref++
			continue
		}

		tags := binary.LittleEndian.Uint64(data[objPos : objPos+8])
		cid := int((tags >> 16) & 0xFFFF)

		// Check if this is a string object.
		isOneByte := cid == ct.OneByteString
		isTwoByte := ct.TwoByteString != 0 && cid == ct.TwoByteString

		if !isOneByte && !isTwoByte {
			// Non-string ROData object (TypeArguments, Array, etc.). Skip it.
			ref++
			// Still advance runningOffset to stay aligned.
			if i < len(cm.Lengths)-1 {
				runningOffset += cm.Lengths[i] << 5
			}
			continue
		}

		lenSmi := int64(binary.LittleEndian.Uint64(data[objPos+8 : objPos+16]))
		strLen := lenSmi >> 1 // Smi decode (kSmiTagShift=1 on arm64)

		if strLen < 0 || strLen > 1<<20 {
			// Implausible length — skip.
			strings = append(strings, ParsedString{RefID: ref, Value: "", IsOneByte: isOneByte})
			ref++
			continue
		}

		dataStart := objPos + 16 // oneByteStringHeaderSize
		var value string
		if isTwoByte {
			nbytes := strLen * 2
			if dataStart+nbytes > int64(len(data)) {
				strings = append(strings, ParsedString{RefID: ref, Value: "", IsOneByte: false})
				ref++
				continue
			}
			runes := make([]rune, strLen)
			for j := int64(0); j < strLen; j++ {
				off := dataStart + j*2
				runes[j] = rune(uint16(data[off]) | uint16(data[off+1])<<8)
			}
			value = string(runes)
		} else {
			if dataStart+strLen > int64(len(data)) {
				strings = append(strings, ParsedString{RefID: ref, Value: "", IsOneByte: true})
				ref++
				continue
			}
			value = string(data[dataStart : dataStart+strLen])
		}

		strings = append(strings, ParsedString{
			RefID:     ref,
			Value:     value,
			IsOneByte: isOneByte,
		})
		ref++
		// ROData object alignment is 32 bytes (2^5) in non-compressed-pointers mode.
		runningOffset += cm.Lengths[i] << 5
	}

	return strings
}

// readFillRefs reads fill data for a FillRefs cluster, extracting name/owner/signature refs.
// When spec.IsFuncType is true, also extracts packed_parameter_counts from scalars.
// When spec.IsField is true, also extracts kind_bits and host_offset from scalars.
func readFillRefs(s *dartfmt.Stream, cm *ClusterMeta, spec *FillSpec, fillRefUnsigned bool) ([]NamedObject, []FuncTypeInfo, []FieldInfo, error) {
	count := int(cm.Count)
	if count <= 0 {
		return nil, nil, nil, nil
	}

	hasName := spec.NameIdx >= 0
	var named []NamedObject
	if hasName {
		named = make([]NamedObject, 0, count)
	}

	var funcTypes []FuncTypeInfo
	if spec.IsFuncType {
		funcTypes = make([]FuncTypeInfo, 0, count)
	}

	var fields []FieldInfo
	if spec.IsField {
		fields = make([]FieldInfo, 0, count)
	}

	ref := cm.StartRef
	for i := 0; i < count; i++ {
		// v2.10: Read<bool>(is_canonical) — 1 raw byte before refs.
		if spec.LeadingBool {
			if _, err := s.ReadByte(); err != nil {
				return named, funcTypes, fields, fmt.Errorf("obj %d/%d is_canonical: %w", i, count, err)
			}
		}

		var nameRef, ownerRef, sigRef int
		nameRef = -1
		ownerRef = -1
		sigRef = -1

		// Read refs using version-appropriate encoding.
		for j := 0; j < spec.NumRefs; j++ {
			r, err := readRef(s, fillRefUnsigned)
			if err != nil {
				return named, funcTypes, fields, fmt.Errorf("obj %d/%d ref %d: %w", i, count, j, err)
			}
			if j == spec.NameIdx {
				nameRef = int(r)
			}
			if j == spec.OwnerIdx {
				ownerRef = int(r)
			}
			if spec.SignatureIdx > 0 && j == spec.SignatureIdx {
				sigRef = int(r)
			}
		}

		// Read scalars; extract type-specific data for FunctionType and Field clusters.
		var fieldKindBits int32
		for si, op := range spec.Scalars {
			if spec.IsFuncType && si == 1 {
				// packed_parameter_counts is OpTagged32 at scalar index 1.
				packed, err := s.ReadTagged32()
				if err != nil {
					return named, funcTypes, fields, fmt.Errorf("obj %d/%d packed_param_counts: %w", i, count, err)
				}
				hasImplicit := (packed & 1) != 0
				numFixed := int((packed >> 2) & 0x3FFF)
				numOptional := int((packed >> 16) & 0x3FFF)
				if hasImplicit && numFixed > 0 {
					numFixed-- // subtract implicit 'this'
				}
				funcTypes = append(funcTypes, FuncTypeInfo{
					RefID:       ref,
					NumFixed:    numFixed,
					NumOptional: numOptional,
					HasImplicit: hasImplicit,
				})
			} else if spec.IsField && si == 0 {
				// kind_bits is OpTagged32 at scalar index 0.
				kb, err := s.ReadTagged32()
				if err != nil {
					return named, funcTypes, fields, fmt.Errorf("obj %d/%d kind_bits: %w", i, count, err)
				}
				fieldKindBits = int32(kb)
			} else if spec.IsField && si == 1 {
				// host_offset_or_field_id is OpRefId at scalar index 1.
				hostOff, err := s.ReadRefId()
				if err != nil {
					return named, funcTypes, fields, fmt.Errorf("obj %d/%d host_offset: %w", i, count, err)
				}
				isStatic := (fieldKindBits>>1)&1 != 0
				offset := int32(hostOff)
				if isStatic {
					offset = -1
				}
				fields = append(fields, FieldInfo{
					RefID:      ref,
					NameRefID:  nameRef,
					OwnerRefID: ownerRef,
					KindBits:   fieldKindBits,
					HostOffset: offset,
				})
			} else {
				if err := skipScalar(s, op); err != nil {
					return named, funcTypes, fields, fmt.Errorf("obj %d/%d scalar: %w", i, count, err)
				}
			}
		}

		if hasName {
			named = append(named, NamedObject{
				CID:            cm.CID,
				RefID:          ref,
				NameRefID:      nameRef,
				OwnerRefID:     ownerRef,
				SignatureRefID: sigRef,
			})
		}
		ref++
	}

	return named, funcTypes, fields, nil
}

// skipScalar reads and discards one scalar value.
func skipScalar(s *dartfmt.Stream, op ScalarOp) error {
	switch op {
	case OpTagged32, OpUint16, OpInt16:
		// Read<int32_t/uint32_t/uint16_t/int16_t>: variable-length, marker 192.
		_, err := s.ReadTagged32()
		return err
	case OpTagged64:
		// Read<int64_t/double/uword>: variable-length, marker 192.
		_, err := s.ReadTagged64()
		return err
	case OpUnsigned:
		// ReadUnsigned: variable-length, marker 128.
		_, err := s.ReadUnsigned()
		return err
	case OpBool, OpUint8, OpInt8:
		// Read<uint8_t/int8_t/bool>: Raw<1,T> = 1 raw byte.
		_, err := s.ReadByte()
		return err
	case OpRefId:
		// ReadRef: big-endian signed-byte accumulation (trailing ref after scalars).
		_, err := s.ReadRefId()
		return err
	default:
		return fmt.Errorf("unknown scalar op %d", op)
	}
}

// readFillClass parses Class fill data with conditional bitmap read.
// Predefined classes (i < mainCount): bitmap always read.
// New classes (i >= mainCount): bitmap only if !IsTopLevelCid(class_id).
// ≤2.18: kTopLevelCidOffset = 1<<16. ≥2.19: kTopLevelCidOffset = 1<<20.
func readFillClass(s *dartfmt.Stream, cm *ClusterMeta, spec *FillSpec, fillRefUnsigned, topLevelCid16, classHasTokenPos bool) ([]NamedObject, []ClassInfo, error) {
	count := int(cm.Count)
	if count <= 0 {
		return nil, nil, nil
	}

	topLevelOffset := int64(1 << 20)
	if topLevelCid16 {
		topLevelOffset = 1 << 16
	}

	named := make([]NamedObject, 0, count)
	classes := make([]ClassInfo, 0, count)
	ref := cm.StartRef

	for i := 0; i < count; i++ {
		var nameRef int = -1

		// ReadFromTo: 13 refs.
		for j := 0; j < spec.NumRefs; j++ {
			r, err := readRef(s, fillRefUnsigned)
			if err != nil {
				return named, classes, fmt.Errorf("obj %d/%d ref %d/%d: %w", i, count, j, spec.NumRefs, err)
			}
			if j == spec.NameIdx {
				nameRef = int(r)
			}
		}

		// ReadCid (class_id) — Read<int32_t> = ReadTagged32.
		classID, err := s.ReadTagged32()
		if err != nil {
			return named, classes, fmt.Errorf("obj %d/%d class_id: %w", i, count, err)
		}

		// Read<int32_t>(instance_size) + Read<int32_t>(next_field_offset).
		instanceSize, err := s.ReadTagged32()
		if err != nil {
			return named, classes, fmt.Errorf("obj %d/%d instance_size: %w", i, count, err)
		}
		nextFieldOff, err := s.ReadTagged32()
		if err != nil {
			return named, classes, fmt.Errorf("obj %d/%d next_field_offset: %w", i, count, err)
		}
		// Read<int32_t>(type_args_offset).
		typeArgsOff, err := s.ReadTagged32()
		if err != nil {
			return named, classes, fmt.Errorf("obj %d/%d type_args_offset: %w", i, count, err)
		}
		// Read<int16_t>(num_type_arguments) — Read16 marker 192.
		if _, err := s.ReadTagged32(); err != nil {
			return named, classes, fmt.Errorf("obj %d/%d num_type_args: %w", i, count, err)
		}
		// Read<uint16_t>(num_native_fields) — Read16 marker 192.
		if _, err := s.ReadTagged32(); err != nil {
			return named, classes, fmt.Errorf("obj %d/%d num_native_fields: %w", i, count, err)
		}
		// v2.10/v2.13: ReadTokenPosition(token_pos) + ReadTokenPosition(end_token_pos).
		// These are Read<int32_t> each; not present in v2.14+ AOT.
		if classHasTokenPos {
			if _, err := s.ReadTagged32(); err != nil {
				return named, classes, fmt.Errorf("obj %d/%d token_pos: %w", i, count, err)
			}
			if _, err := s.ReadTagged32(); err != nil {
				return named, classes, fmt.Errorf("obj %d/%d end_token_pos: %w", i, count, err)
			}
		}
		// Read<uint32_t>(state_bits) — Read32 marker 192.
		if _, err := s.ReadTagged32(); err != nil {
			return named, classes, fmt.Errorf("obj %d/%d state_bits: %w", i, count, err)
		}

		// ReadUnsigned64 (bitmap) — conditional for new classes.
		isPredefined := int64(i) < cm.MainCount
		isTopLevel := int64(int32(classID)) >= topLevelOffset
		if isPredefined || !isTopLevel {
			if _, err := s.ReadUnsigned(); err != nil {
				return named, classes, fmt.Errorf("obj %d/%d bitmap: %w", i, count, err)
			}
		}

		named = append(named, NamedObject{
			CID:        cm.CID,
			RefID:      ref,
			NameRefID:  nameRef,
			OwnerRefID: -1,
		})
		classes = append(classes, ClassInfo{
			RefID:        ref,
			NameRefID:    nameRef,
			ClassID:      int32(classID),
			InstanceSize: int32(instanceSize),
			NextFieldOff: int32(nextFieldOff),
			TypeArgsOff:  int32(typeArgsOff),
		})
		ref++
	}
	return named, classes, nil
}

// readFillField parses v2.17.6 Field fill with conditional ReadUnsigned for static fields.
// v2.17.6 AOT: ReadFromTo(4 refs) + Read<uint16_t>(kind_bits) + ReadRef(value_or_offset) +
// [if static: ReadUnsigned(field_id)].
// kStaticBit = 1 in v2.17.6 kind_bits.
func readFillField(s *dartfmt.Stream, cm *ClusterMeta, spec *FillSpec, fillRefUnsigned bool) ([]NamedObject, []FieldInfo, error) {
	count := int(cm.Count)
	if count <= 0 {
		return nil, nil, nil
	}

	named := make([]NamedObject, 0, count)
	fields := make([]FieldInfo, 0, count)
	ref := cm.StartRef

	for i := 0; i < count; i++ {
		var nameRef, ownerRef int
		nameRef = -1
		ownerRef = -1

		// ReadFromTo: 4 refs (name, owner, type, initializer_function).
		for j := 0; j < spec.NumRefs; j++ {
			r, err := readRef(s, fillRefUnsigned)
			if err != nil {
				return named, fields, fmt.Errorf("field %d/%d ref %d: %w", i, count, j, err)
			}
			if j == spec.NameIdx {
				nameRef = int(r)
			}
			if j == spec.OwnerIdx {
				ownerRef = int(r)
			}
		}

		// Read<uint16_t>(kind_bits) — Read16(marker 192).
		kindBits, err := s.ReadTagged32()
		if err != nil {
			return named, fields, fmt.Errorf("field %d/%d kind_bits: %w", i, count, err)
		}

		// ReadRef(value_or_offset).
		valOrOff, err := readRef(s, fillRefUnsigned)
		if err != nil {
			return named, fields, fmt.Errorf("field %d/%d value_or_offset: %w", i, count, err)
		}

		// Conditional: if static field, read field_id.
		isStatic := (kindBits>>1)&1 != 0
		if isStatic {
			if _, err := s.ReadUnsigned(); err != nil {
				return named, fields, fmt.Errorf("field %d/%d field_id: %w", i, count, err)
			}
		}

		offset := int32(valOrOff)
		if isStatic {
			offset = -1
		}
		fields = append(fields, FieldInfo{
			RefID:      ref,
			NameRefID:  nameRef,
			OwnerRefID: ownerRef,
			KindBits:   int32(kindBits),
			HostOffset: offset,
		})

		named = append(named, NamedObject{
			CID:        cm.CID,
			RefID:      ref,
			NameRefID:  nameRef,
			OwnerRefID: ownerRef,
		})
		ref++
	}
	return named, fields, nil
}

// skipFillDouble skips Double fill.
// Read<double>() → Raw<8,double>::Read() → Read64(kEndByteMarker=192) = variable-length.
// v2.10: Read<bool>(is_canonical) before the double.
func skipFillDouble(s *dartfmt.Stream, cm *ClusterMeta, preCanonicalSplit bool) error {
	for i := int64(0); i < cm.Count; i++ {
		if preCanonicalSplit {
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("double %d/%d is_canonical: %w", i, cm.Count, err)
			}
		}
		if _, err := s.ReadTagged64(); err != nil {
			return fmt.Errorf("double %d/%d: %w", i, cm.Count, err)
		}
	}
	return nil
}

// readFillCode reads Code fill data, extracting owner refs and instruction metadata.
// AOT PRODUCT: ReadInstructions + N ReadRef per code.
// v2.16+: ReadInstructions = 1 ReadUnsigned (payload_info). 6 refs.
// v2.10-v2.15: ReadInstructions = 2 ReadUnsigned (text_offset_delta + payload_info). 7 refs.
// Deferred codes skip ReadInstructions (no stream read).
// Ref 0 = owner (Function/Closure/FfiTrampolineData).
// instrIdxBase is the running instructions_index_ counter from previous Code clusters.
//
// stateBitsAfterRef: 0 = no state_bits in fill (v2.10, v2.14+).
// N>0 = state_bits is read after first N refs (v2.13: N=1). DiscardedBit (bit 3)
// of state_bits determines whether remaining refs are skipped.
func readFillCode(s *dartfmt.Stream, cm *ClusterMeta, ct *snapshot.CIDTable, fillRefUnsigned bool, instrIdxBase int, codeNumRefs int, textOffsetDelta bool, stateBitsAfterRef int, stateBitsAtEnd bool) ([]CodeEntry, error) {
	numRefs := codeNumRefs
	if numRefs == 0 {
		numRefs = 6 // default: owner, exception_handlers, pc_descriptors, catch_entry, inlined_id_to_function, code_source_map
	}
	codes := make([]CodeEntry, 0, cm.Count)
	ref := cm.StartRef
	instrIdx := instrIdxBase
	discardedCount := 0
	for i := int64(0); i < cm.Count; i++ {
		var payloadInfo int64
		clusterIndex := -1
		traceCode := debugFill && i < 5

		// v2.14+: discarded status from alloc phase. v2.13: determined from state_bits below.
		discarded := cm.DiscardedCodes[i]

		posStart := s.Position()

		// Dump raw bytes for first 3, last 3, and codes near known failure points.
		if debugFill && (i < 3 || i >= cm.Count-3 || (i >= 21600 && i <= 21610)) {
			saved := s.Position()
			hexBytes, _ := s.ReadBytes(30)
			s.SetPosition(saved)
			fmt.Fprintf(os.Stderr, "  code[%d] RAW@0x%x: %x\n", i, posStart, hexBytes)
		}

		// Main (non-deferred) codes: ReadInstructions reads payload data.
		// v2.10-v2.15: ReadUnsigned(text_offset_delta) + ReadUnsigned(payload_info).
		//   v2.14+: discarded codes also read compressed_stackmaps(ReadRef) in ReadInstructions.
		// v2.16+: ReadUnsigned(payload_info) only.
		// Deferred codes: ReadInstructions does nothing (early return).
		if i < cm.MainCount {
			if textOffsetDelta {
				if _, err := s.ReadUnsigned(); err != nil {
					return codes, fmt.Errorf("code %d/%d text_offset_delta: %w", i, cm.Count, err)
				}
			}
			pi, err := s.ReadUnsigned()
			if err != nil {
				return codes, fmt.Errorf("code %d/%d payload_info: %w", i, cm.Count, err)
			}
			payloadInfo = pi
			clusterIndex = instrIdx
			instrIdx++

			// v2.14+: discarded codes read compressed_stackmaps ref inside ReadInstructions,
			// then return without reading any other refs or state_bits.
			if discarded && stateBitsAfterRef == 0 {
				if _, err := readRef(s, fillRefUnsigned); err != nil {
					return codes, fmt.Errorf("code %d/%d discarded compressed_stackmaps: %w", i, cm.Count, err)
				}
			}
		}

		// v2.13 (stateBitsAfterRef > 0): compressed_stackmaps → state_bits → [if discarded: stop] → 6 refs.
		// All codes read compressed_stackmaps and state_bits. DiscardedBit (bit 3) of state_bits
		// determines whether remaining refs are read. This is different from v2.14+ where
		// discarded status comes from the alloc phase.
		var ownerRef int
		if stateBitsAfterRef > 0 {
			// Read first N refs (before state_bits) — all codes, including discarded.
			for j := 0; j < stateBitsAfterRef; j++ {
				if _, err := readRef(s, fillRefUnsigned); err != nil {
					return codes, fmt.Errorf("code %d/%d ref %d: %w", i, cm.Count, j, err)
				}
			}
			// Read state_bits (Read<int32_t> VLE).
			sbPos := s.Position()
			sb, err := s.ReadTagged32()
			if err != nil {
				// Dump context for diagnosis.
				if debugFill {
					fmt.Fprintf(os.Stderr, "  code[%d] state_bits ERR at pos=0x%x (code start=0x%x)\n", i, sbPos, posStart)
					// Dump raw bytes from code start.
					saved := s.Position()
					s.SetPosition(posStart)
					hexBytes, _ := s.ReadBytes(40)
					s.SetPosition(saved)
					fmt.Fprintf(os.Stderr, "  hex@0x%x=%x\n", posStart, hexBytes)
				}
				return codes, fmt.Errorf("code %d/%d state_bits: %w", i, cm.Count, err)
			}
			if debugFill && (i%1000 == 0 || (i >= 21595 && i <= 21610)) {
				fmt.Fprintf(os.Stderr, "  code[%d] pos=0x%x sb=0x%x discarded=%v cumDisc=%d\n",
					i, posStart, sb, (sb>>3)&1 != 0, discardedCount)
			}
			// DiscardedBit = bit 3 of state_bits.
			discarded = (sb>>3)&1 != 0
			if discarded {
				discardedCount++
				if traceCode {
					fmt.Fprintf(os.Stderr, "  code[%d] pos=0x%x state_bits=0x%x DISCARDED\n", i, posStart, sb)
				}
				goto done
			}
			// Read remaining refs after state_bits.
			for j := stateBitsAfterRef; j < numRefs; j++ {
				r, err := readRef(s, fillRefUnsigned)
				if err != nil {
					return codes, fmt.Errorf("code %d/%d ref %d: %w", i, cm.Count, j, err)
				}
				// Owner is the first ref after state_bits (e.g., ref[1] for v2.13).
				if j == stateBitsAfterRef {
					ownerRef = int(r)
				}
			}
		} else if !discarded {
			// v2.10, v2.14+: read all refs in order (no interleaved state_bits).
			for j := 0; j < numRefs; j++ {
				r, err := readRef(s, fillRefUnsigned)
				if err != nil {
					return codes, fmt.Errorf("code %d/%d ref %d: %w", i, cm.Count, j, err)
				}
				if j == 0 {
					ownerRef = int(r)
				}
			}
		}

		// v2.10: state_bits_ = Read<int32_t>() after ALL refs, unconditionally (no discarded check).
		if stateBitsAtEnd {
			if _, err := s.ReadTagged32(); err != nil {
				return codes, fmt.Errorf("code %d/%d state_bits_at_end: %w", i, cm.Count, err)
			}
		}

	done:
		if traceCode {
			fmt.Fprintf(os.Stderr, "  code[%d] pos=0x%x total=%d discarded=%v\n",
				i, posStart, s.Position()-posStart, discarded)
		}
		if debugFill && (i < 5 || i >= cm.Count-3 || i == cm.MainCount-1 || i == cm.MainCount || i%5000 == 0) {
			fmt.Fprintf(os.Stderr, "  code[%d/%d] main=%d owner=%d discarded=%v endPos=0x%x\n", i, cm.Count, cm.MainCount, ownerRef, discarded, s.Position())
		}
		codes = append(codes, CodeEntry{
			RefID:        ref,
			OwnerRef:     ownerRef,
			ClusterIndex: clusterIndex,
			PayloadInfo:  payloadInfo,
		})
		ref++
	}
	if debugFill && discardedCount > 0 {
		fmt.Fprintf(os.Stderr, "  code: %d/%d discarded (from state_bits)\n", discardedCount, cm.Count)
	}
	return codes, nil
}

// readFillObjectPool reads ObjectPool fill data and captures entries.
// Per pool: ReadUnsigned(length) + length × (ReadByte(entry_bits) + type-dependent data).
//
// v2.17.6: TypeBits[0:7] (7 bits), PatchableBit[7].
//
//	0=kTaggedObject→ReadRef, 1=kImmediate→Read<intptr_t>, 2+=nothing.
//
// v3.x: TypeBits[0:4], PatchableBit[4], SnapshotBehaviorBits[5:8].
//
//	behavior 0: 0=kImmediate→Read<intptr_t>, 1=kTaggedObject→ReadRef, 2=kNativeFunction→nothing.
//	behavior 1,2,3: nothing.
func readFillObjectPool(s *dartfmt.Stream, cm *ClusterMeta, oldPoolFormat, poolTypeSwapped, fillRefUnsigned bool) ([]PoolEntry, error) {
	if debugFill {
		saved := s.Position()
		rawBytes, _ := s.ReadBytes(40)
		s.SetPosition(saved)
		fmt.Fprintf(os.Stderr, "  ObjectPool fill start @0x%x raw=%x\n", saved, rawBytes)
	}
	var entries []PoolEntry
	idx := 0
	for i := int64(0); i < cm.Count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return nil, fmt.Errorf("pool %d/%d length: %w", i, cm.Count, err)
		}
		for j := int64(0); j < length; j++ {
			entryBits, err := s.ReadByte()
			if err != nil {
				return nil, fmt.Errorf("pool %d entry %d bits: %w", i, j, err)
			}

			pe := PoolEntry{Index: idx}
			idx++

			if oldPoolFormat {
				// ≤3.2: TypeBits = entryBits & 0x7F (7 bits).
				typeBits := entryBits & 0x7F
				// v3.2 swapped kImmediate(0) and kTaggedObject(1). Normalize to pre-3.2 ordering.
				if poolTypeSwapped && typeBits <= 1 {
					typeBits ^= 1
				}
				switch typeBits {
				case 0: // kTaggedObject → ReadRef
					ref, err := readRef(s, fillRefUnsigned)
					if err != nil {
						return nil, fmt.Errorf("pool %d entry %d ref (bits=0x%02x pos=0x%x): %w", i, j, entryBits, s.Position(), err)
					}
					pe.Kind = PoolTagged
					pe.RefID = int(ref)
				case 1: // kImmediate → Read<intptr_t> = Read64
					imm, err := s.ReadTagged64()
					if err != nil {
						return nil, fmt.Errorf("pool %d entry %d imm (bits=0x%02x pos=0x%x): %w", i, j, entryBits, s.Position(), err)
					}
					pe.Kind = PoolImmediate
					pe.Imm = imm
				case 2, 3: // kNativeFunction, kNativeFunctionWrapper → nothing
					pe.Kind = PoolNative
				case 4: // kNativeEntryData → ReadRef (same as kTaggedObject)
					ref, err := readRef(s, fillRefUnsigned)
					if err != nil {
						return nil, fmt.Errorf("pool %d entry %d native_entry_data ref (bits=0x%02x pos=0x%x): %w", i, j, entryBits, s.Position(), err)
					}
					pe.Kind = PoolTagged
					pe.RefID = int(ref)
				default:
					return nil, fmt.Errorf("pool %d entry %d: unknown type %d (bits=0x%02x pos=0x%x)", i, j, typeBits, entryBits, s.Position())
				}
			} else {
				// v3.x: SnapshotBehaviorBits = entryBits >> 5 (3 bits).
				behaviorBits := entryBits >> 5
				typeBits := entryBits & 0x0F
				switch behaviorBits {
				case 0: // kSnapshotable
					switch typeBits {
					case 0: // kImmediate → Read<intptr_t>
						imm, err := s.ReadTagged64()
						if err != nil {
							return nil, fmt.Errorf("pool %d entry %d imm: %w", i, j, err)
						}
						pe.Kind = PoolImmediate
						pe.Imm = imm
					case 1: // kTaggedObject → ReadRef
						ref, err := readRef(s, fillRefUnsigned)
						if err != nil {
							return nil, fmt.Errorf("pool %d entry %d ref: %w", i, j, err)
						}
						pe.Kind = PoolTagged
						pe.RefID = int(ref)
					case 2: // kNativeFunction → nothing
						pe.Kind = PoolNative
					default:
						return nil, fmt.Errorf("pool %d entry %d: unknown type %d", i, j, typeBits)
					}
				case 1, 2, 3, 4: // kResetToBootstrapNative, kResetToSwitchableCallMissEntryPoint, kSetToZero, kResetToMegamorphicCallEntryPoint
					pe.Kind = PoolEmpty
				default:
					return nil, fmt.Errorf("pool %d entry %d: unknown snapshot behavior %d", i, j, behaviorBits)
				}
			}
			entries = append(entries, pe)
		}
	}
	return entries, nil
}

// skipFillInlineBytes skips clusters that store inline byte data.
// Per object: ReadUnsigned(length) + ReadBytes(length).
// Used for PcDescriptors, CodeSourceMap, CompressedStackMaps with compressed pointers.
func skipFillInlineBytes(s *dartfmt.Stream, cm *ClusterMeta) error {
	for i := int64(0); i < cm.Count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("inline_bytes %d/%d length: %w", i, cm.Count, err)
		}
		if err := s.Skip(int(length)); err != nil {
			return fmt.Errorf("inline_bytes %d/%d data (%d bytes): %w", i, cm.Count, length, err)
		}
	}
	return nil
}

// skipFillArray skips Array/ImmutableArray fill.
//
// New format (v2.16+):
//
//	Per object: ReadUnsigned(length) + ReadRef(type_args) + length × ReadRef(element).
//
// Old format (v2.13, v2.15 — OldArrayFill):
//
//	Per object: ReadRef(type_args) + N × ReadRef(element) where N = cm.Lengths[i] from alloc.
func skipFillArray(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool, profile *snapshot.VersionProfile) error {
	if profile.OldArrayFill {
		return skipFillArrayOld(s, cm, fillRefUnsigned)
	}
	for i := int64(0); i < cm.Count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("array %d/%d length: %w", i, cm.Count, err)
		}
		// v2.10: Read<bool>(is_canonical) after length.
		if profile.PreCanonicalSplit {
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("array %d is_canonical: %w", i, err)
			}
		}
		// ReadRef(type_arguments).
		if _, err := readRef(s, fillRefUnsigned); err != nil {
			return fmt.Errorf("array %d type_args: %w", i, err)
		}
		for j := int64(0); j < length; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("array %d elem %d/%d: %w", i, j, length, err)
			}
		}
	}
	return nil
}

// skipFillArrayOld handles the pre-v2.16 Array fill format.
// Per object: ReadRef(type_args) + N × ReadRef(element) where N = cm.Lengths[i] from alloc.
func skipFillArrayOld(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	for i := int64(0); i < cm.Count; i++ {
		allocLen := int64(0)
		if int(i) < len(cm.Lengths) {
			allocLen = cm.Lengths[i]
		}
		// ReadRef(type_arguments).
		if _, err := readRef(s, fillRefUnsigned); err != nil {
			return fmt.Errorf("array_old %d/%d type_args: %w", i, cm.Count, err)
		}
		for j := int64(0); j < allocLen; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("array_old %d elem %d/%d: %w", i, j, allocLen, err)
			}
		}
	}
	return nil
}

// skipFillWeakArray skips WeakArray fill.
// Per object: ReadUnsigned(length) + length × ReadRef(element).
func skipFillWeakArray(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	for i := int64(0); i < cm.Count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("weak_array %d/%d length: %w", i, cm.Count, err)
		}
		for j := int64(0); j < length; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("weak_array %d elem %d/%d: %w", i, j, length, err)
			}
		}
	}
	return nil
}

// skipFillTypedData skips TypedData fill.
// Per object: ReadUnsigned(length) + length × element_size raw bytes.
// v2.10: Read<bool>(is_canonical) after length.
func skipFillTypedData(s *dartfmt.Stream, cm *ClusterMeta, ct *snapshot.CIDTable, preCanonicalSplit bool) error {
	elemSize := typedDataElementSize(cm.CID, ct)
	for i := int64(0); i < cm.Count; i++ {
		// Fill reads: ReadUnsigned(length), then length * element_size raw bytes.
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("typed_data %d/%d length: %w", i, cm.Count, err)
		}
		if preCanonicalSplit {
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("typed_data %d is_canonical: %w", i, err)
			}
		}
		nbytes := int(length) * elemSize
		if err := s.Skip(nbytes); err != nil {
			return fmt.Errorf("typed_data %d/%d data (%d bytes): %w", i, cm.Count, nbytes, err)
		}
	}
	return nil
}

// skipFillExceptionHandlers skips ExceptionHandlers fill.
// v2.17.6: ReadUnsigned(length) directly.
// v3.x: ReadUnsigned(packed_fields), length = packed_fields >> 1 (AsyncHandlerBit at bit 0).
// Then: ReadRef(handled_types_data) + per-handler: Read<uint32_t>(pc_offset) +
// Read<int16_t>(outer_try_index) + Read<int8_t>(needs_stacktrace) +
// Read<int8_t>(has_catch_all) + Read<int8_t>(is_generated).
func skipFillExceptionHandlers(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	for i := int64(0); i < cm.Count; i++ {
		raw, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("exc_handlers %d length/packed: %w", i, err)
		}
		// v2.17.6: value IS the length. v3.x: length = packed_fields >> 1.
		length := raw
		if !fillRefUnsigned {
			length = raw >> 1
		}
		// ReadRef(handled_types_data).
		if _, err := readRef(s, fillRefUnsigned); err != nil {
			return fmt.Errorf("exc_handlers %d handled_types: %w", i, err)
		}
		for j := int64(0); j < length; j++ {
			// Read<uint32_t>(handler_pc_offset) — marker 192.
			if _, err := s.ReadTagged32(); err != nil {
				return fmt.Errorf("exc_handlers %d handler %d pc: %w", i, j, err)
			}
			// Read<int16_t>(outer_try_index) — marker 192 (Read16).
			if _, err := s.ReadTagged32(); err != nil {
				return fmt.Errorf("exc_handlers %d handler %d try_idx: %w", i, j, err)
			}
			// Read<int8_t>(needs_stacktrace) — Raw<1,T> = ReadByte.
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("exc_handlers %d handler %d stacktrace: %w", i, j, err)
			}
			// Read<int8_t>(has_catch_all) — Raw<1,T> = ReadByte.
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("exc_handlers %d handler %d catch_all: %w", i, j, err)
			}
			// Read<int8_t>(is_generated) — Raw<1,T> = ReadByte.
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("exc_handlers %d handler %d generated: %w", i, j, err)
			}
		}
	}
	return nil
}

// skipFillContext skips Context fill.
// Per object: ReadRef(parent) + num_variables × ReadRef(variable).
// skipFillContext skips Context fill.
// Per object: ReadUnsigned(length) + ReadRef(parent) + length × ReadRef(variable).
func skipFillContext(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	for i := int64(0); i < cm.Count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("context %d/%d length: %w", i, cm.Count, err)
		}
		// ReadRef(parent).
		if _, err := readRef(s, fillRefUnsigned); err != nil {
			return fmt.Errorf("context %d parent: %w", i, err)
		}
		for j := int64(0); j < length; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("context %d var %d/%d: %w", i, j, length, err)
			}
		}
	}
	return nil
}

// skipFillTypeArguments skips TypeArguments fill.
//
// New format (v2.14, v2.16+):
//
//	Per object: ReadUnsigned(length) + Read<int32_t>(hash) + ReadUnsigned(nullability) +
//	  ReadRef(instantiations) + length × ReadRef(type).
//
// Old format (v2.13, v2.15 — OldTypeArgsFill):
//
//	Per object: ReadRef(instantiations) + N × ReadRef(type) + Read<int32_t>(hash)
//	  where N = cm.Lengths[i] from alloc phase (no length/nullability in stream).
func skipFillTypeArguments(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool, profile *snapshot.VersionProfile) error {
	if profile.OldTypeArgsFill {
		return skipFillTypeArgumentsOld(s, cm, fillRefUnsigned)
	}
	if debugFill {
		pos := s.Position()
		peek, _ := s.ReadBytes(32)
		s.SetPosition(pos)
		fmt.Fprintf(os.Stderr, "  TypeArgs fill start pos=0x%x raw=%x\n", pos, peek)
		if len(cm.Lengths) > 0 {
			n := 5
			if len(cm.Lengths) < n {
				n = len(cm.Lengths)
			}
			fmt.Fprintf(os.Stderr, "  TypeArgs alloc lengths[0:%d]=%v\n", n, cm.Lengths[:n])
		}
	}
	for i := int64(0); i < cm.Count; i++ {
		itemPos := s.Position()
		// Fill reads length from stream (not from alloc).
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("type_args %d/%d length: %w", i, cm.Count, err)
		}
		if debugFill && (i < 3 || i >= 45 && i <= 50) {
			fmt.Fprintf(os.Stderr, "  typeargs[%d] pos=0x%x length=%d\n", i, itemPos, length)
		}
		// v2.10: Read<bool>(is_canonical) — 1 raw byte.
		if profile.PreCanonicalSplit {
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("type_args %d is_canonical: %w", i, err)
			}
		}
		// Read<int32_t>(hash) — marker 192.
		hash, err := s.ReadTagged32()
		if err != nil {
			return fmt.Errorf("type_args %d hash: %w", i, err)
		}
		// ReadUnsigned(nullability) — marker 128.
		nullab, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("type_args %d nullability: %w", i, err)
		}
		// ReadRef(instantiations).
		inst, err := readRef(s, fillRefUnsigned)
		if err != nil {
			return fmt.Errorf("type_args %d instantiations: %w", i, err)
		}
		if debugFill && i < 3 {
			fmt.Fprintf(os.Stderr, "    hash=%d nullab=%d inst=%d\n", hash, nullab, inst)
		}
		for j := int64(0); j < length; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("type_args %d type %d/%d: %w", i, j, length, err)
			}
		}
	}
	return nil
}

// skipFillTypeArgumentsOld handles the pre-v2.14 TypeArguments fill format.
// Per object: ReadRef(instantiations) + N × ReadRef(type) + Read<int32_t>(hash)
// where N = cm.Lengths[i] from the alloc phase.
func skipFillTypeArgumentsOld(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	for i := int64(0); i < cm.Count; i++ {
		allocLen := int64(1)
		if int(i) < len(cm.Lengths) {
			allocLen = cm.Lengths[i]
		}
		// ReadRef(instantiations).
		if _, err := readRef(s, fillRefUnsigned); err != nil {
			return fmt.Errorf("type_args_old %d/%d instantiations: %w", i, cm.Count, err)
		}
		// N × ReadRef(type) where N = alloc length.
		for j := int64(0); j < allocLen; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("type_args_old %d type %d/%d: %w", i, j, allocLen, err)
			}
		}
		// Read<int32_t>(hash).
		if _, err := s.ReadTagged32(); err != nil {
			return fmt.Errorf("type_args_old %d hash: %w", i, err)
		}
	}
	return nil
}

// skipFillInstance skips Instance fill.
// Format: ReadUnsigned64(unboxed_bitmap) ONCE, then per object:
//
//	for each field offset from header to next_field_offset:
//	  if unboxed: ReadWordWith32BitReads (2 × ReadTagged32)
//	  else: ReadRef (ReadRefId)
//
// header_words: 2 for compressed pointers (tags + hash = 2 × 4 bytes = 2 compressed words).
// header_words: 1 for uncompressed (tags = 1 × 8 bytes = 1 word).
func skipFillInstance(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned, compressedPointers, preCanonicalSplit bool) error {
	// v2.13+: ReadUnsigned64(unboxed_fields_bitmap) read once before all objects.
	// v2.10 (PreCanonicalSplit): bitmap from class table (not in stream); assume 0.
	var bitmap int64
	if !preCanonicalSplit {
		var err error
		bitmap, err = s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("instance(%d) bitmap: %w", cm.CID, err)
		}
	}

	nfo := int(cm.NextFieldOffsetInWords)
	if nfo <= 0 {
		return nil
	}
	// Compressed pointers: header = 2 compressed words (tags 4B + hash 4B).
	// Uncompressed: header = 1 word (tags 8B).
	headerWords := 1
	if compressedPointers {
		headerWords = 2
	}
	numFields := nfo - headerWords
	if numFields < 0 {
		numFields = 0
	}

	for i := int64(0); i < cm.Count; i++ {
		// v2.10: Read<bool>(is_canonical) per object — 1 raw byte.
		if preCanonicalSplit {
			if _, err := s.ReadByte(); err != nil {
				return fmt.Errorf("instance(%d) %d/%d is_canonical: %w", cm.CID, i, cm.Count, err)
			}
		}
		for j := 0; j < numFields; j++ {
			fieldWordIdx := headerWords + j
			isUnboxed := (bitmap>>uint(fieldWordIdx))&1 != 0
			if isUnboxed {
				// ReadWordWith32BitReads: 2 × Read<uint32_t> (marker 192).
				if _, err := s.ReadTagged32(); err != nil {
					return fmt.Errorf("instance(%d) %d/%d unboxed field %d lo: %w", cm.CID, i, cm.Count, j, err)
				}
				if _, err := s.ReadTagged32(); err != nil {
					return fmt.Errorf("instance(%d) %d/%d unboxed field %d hi: %w", cm.CID, i, cm.Count, j, err)
				}
			} else {
				if _, err := readRef(s, fillRefUnsigned); err != nil {
					return fmt.Errorf("instance(%d) %d/%d ref %d: %w", cm.CID, i, cm.Count, j, err)
				}
			}
		}
	}
	return nil
}

// skipFillRecord skips Record fill.
// Per object: ReadRef(shape) + num_fields × ReadRef(field).
// skipFillRecord skips Record fill.
// Per object: ReadUnsigned(shape) + num_fields × ReadRef(field).
// num_fields = RecordShape.NumFieldsBitField (lower 16 bits of shape).
func skipFillRecord(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	for i := int64(0); i < cm.Count; i++ {
		// Fill reads shape from stream; num_fields decoded from lower 16 bits.
		shape, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("record %d/%d shape: %w", i, cm.Count, err)
		}
		numFields := shape & 0xFFFF
		for j := int64(0); j < numFields; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("record %d field %d/%d: %w", i, j, numFields, err)
			}
		}
	}
	return nil
}

// skipFillContextScope skips ContextScope fill.
// Per scope: num_variables entries, each with multiple refs and scalars.
// ContextScope is non-AOT only (context_scope_ = null in AOT ClosureData).
// In practice this cluster type should not appear in AOT snapshots,
// but we handle it for completeness.
// skipFillContextScope skips ContextScope fill.
// ContextScope is non-AOT only. Should not appear in AOT PRODUCT snapshots.
// Per object: ReadUnsigned(length) + ReadByte(is_implicit) + ReadFromTo(scope, length).
// ReadFromTo reads all pointer fields per variable entry as ReadRef.
func skipFillContextScope(s *dartfmt.Stream, cm *ClusterMeta, fillRefUnsigned bool) error {
	// ContextScope shouldn't appear in AOT. If it does, we'll attempt to skip
	// using the known structure: ReadUnsigned(length) + ReadByte(is_implicit) +
	// then ReadFromTo which reads pointer fields per variable.
	// Each variable in ContextScope has ~7 pointer fields.
	const refsPerVariable = 7
	for i := int64(0); i < cm.Count; i++ {
		length, err := s.ReadUnsigned()
		if err != nil {
			return fmt.Errorf("context_scope %d/%d length: %w", i, cm.Count, err)
		}
		// Read<bool>(is_implicit) = ReadByte.
		if _, err := s.ReadByte(); err != nil {
			return fmt.Errorf("context_scope %d is_implicit: %w", i, err)
		}
		// ReadFromTo reads all pointer fields for this scope.
		// Each variable entry has ~7 pointer fields.
		totalRefs := int64(refsPerVariable) * length
		for j := int64(0); j < totalRefs; j++ {
			if _, err := readRef(s, fillRefUnsigned); err != nil {
				return fmt.Errorf("context_scope %d ref %d/%d: %w", i, j, totalRefs, err)
			}
		}
	}
	return nil
}

// typedDataElementSize returns the element size in bytes for a TypedData CID.
func typedDataElementSize(cid int, ct *snapshot.CIDTable) int {
	// DeltaEncodedTypedData (NativePointer) uses element size 1.
	if ct.NativePointerCid != 0 && cid == ct.NativePointerCid {
		return 1
	}

	// Generic TypedData CID (the base class) — element size 1.
	if cid == ct.TypedData {
		return 1
	}

	// Internal TypedData CIDs: stride-based lookup.
	if ct.TypedDataInt8ArrayCid == 0 || ct.TypedDataCidStride == 0 {
		return 1
	}
	idx := (cid - ct.TypedDataInt8ArrayCid) / ct.TypedDataCidStride
	// Element sizes by TypedData type index:
	// 0=Int8(1), 1=Uint8(1), 2=Uint8Clamped(1),
	// 3=Int16(2), 4=Uint16(2), 5=Int32(4), 6=Uint32(4),
	// 7=Int64(8), 8=Uint64(8), 9=Float32(4), 10=Float64(8),
	// 11=Float32x4(16), 12=Int32x4(16), 13=Float64x2(16)
	sizes := [14]int{1, 1, 1, 2, 2, 4, 4, 8, 8, 4, 8, 16, 16, 16}
	if idx >= 0 && idx < 14 {
		return sizes[idx]
	}
	return 1
}

```

`internal/cluster/fillspec.go`:

```go
// Fill format specifications for Dart AOT PRODUCT snapshot clusters.
//
// Each FillKind describes the sequence of reads per object in the fill section.
// The fill parser uses these to skip or extract data from each cluster.
package cluster

import "unflutter/internal/snapshot"

// FillKind classifies how a cluster's fill data should be parsed.
type FillKind int

const (
	// FillRefs reads N refs (ReadUnsigned each). N is fixed per CID.
	FillRefs FillKind = iota

	// FillString reads (length<<1|twobyte) + raw bytes. Already implemented.
	FillString

	// FillMint has no fill data (value read during alloc).
	FillNone

	// FillDouble reads one raw float64 (8 bytes LE).
	FillDouble

	// FillCode is custom: instructions + refs + scalars.
	FillCode

	// FillObjectPool is custom: per-entry type dispatch.
	FillObjectPool

	// FillArray reads type_args ref + N element refs (N from alloc).
	FillArray

	// FillWeakArray reads N element refs (N from alloc).
	FillWeakArray

	// FillTypedData reads length + raw bytes (length * element_size).
	FillTypedData

	// FillExceptionHandlers reads packed_fields + refs + per-handler scalars.
	FillExceptionHandlers

	// FillContext reads length + parent ref + N variable refs.
	FillContext

	// FillTypeArguments reads length + hash + nullability + instantiations ref + N type refs.
	FillTypeArguments

	// FillROData has no fill data (data lives in read-only image).
	FillROData

	// FillInstance reads N refs where N = (next_field_offset_in_words - header_words).
	FillInstance

	// FillRecord reads N+1 refs: shape ref + N field refs (N from alloc).
	FillRecord

	// FillContextScope is custom: per-scope variable-length data.
	FillContextScope

	// FillSentinel has no fill data.
	FillSentinel

	// FillInstructionsTable has no fill data (handled in alloc/image).
	FillInstructionsTable

	// FillClass is custom: per-object conditional bitmap read.
	FillClass

	// FillField is custom: v2.17.6 has conditional ReadUnsigned for static fields.
	FillField

	// FillInlineBytes reads ReadUnsigned(length) + ReadBytes(length) per object.
	// Used for PcDescriptors/CodeSourceMap/CompressedStackMaps with compressed pointers.
	FillInlineBytes

	// FillUnknown means we don't know the format.
	FillUnknown
)

// FillSpec describes how to parse one cluster's fill section.
type FillSpec struct {
	Kind         FillKind
	NumRefs      int // for FillRefs: number of ReadRef (ReadUnsigned) per object
	Scalars      []ScalarOp
	NameIdx      int  // index in refs of the "name" field (-1 = none)
	OwnerIdx     int  // index in refs of the "owner" field (-1 = none)
	SignatureIdx int  // index in refs of the "signature" field (-1 = none; used for Function→FunctionType link)
	LeadingBool  bool // v2.10: Read<bool>(is_canonical) before refs (1 raw byte per object)
	IsFuncType   bool // true for FunctionType clusters (extract packed_parameter_counts)
	IsField      bool // true for Field clusters (extract kind_bits + host_offset)
}

// ScalarOp describes one scalar read after the refs.
type ScalarOp int

const (
	OpTagged32 ScalarOp = iota // Read<int32_t/uint32_t>: variable-length, marker 192 (via ReadStream::Read32)
	OpTagged64                 // Read<int64_t/double/uword>: variable-length, marker 192 (via ReadStream::Read64)
	OpUnsigned                 // ReadUnsigned: variable-length, marker 128
	OpBool                     // Read<bool>: Raw<1,T> = ReadByte (1 raw byte)
	OpUint8                    // Read<uint8_t>: Raw<1,T> = ReadByte (1 raw byte)
	OpUint16                   // Read<uint16_t>: variable-length, marker 192 (via ReadStream::Read16)
	OpInt16                    // Read<int16_t>: variable-length, marker 192 (via ReadStream::Read16)
	OpInt8                     // Read<int8_t>: Raw<1,T> = ReadByte (1 raw byte)
	OpRefId                    // ReadRef: big-endian signed-byte accumulation (same as refs, but as trailing scalar)
)

// Fill specs for AOT PRODUCT clusters.
//
// Encoding in fill phase (Deserializer::Local):
//   Read<T>() for sizeof(T)==1: Raw<1,T>::Read() = ReadByte (1 raw byte)
//   Read<T>() for sizeof(T)==2: Raw<2,T>::Read() = Read16(kEndByteMarker=192)
//   Read<T>() for sizeof(T)==4: Raw<4,T>::Read() = Read32(kEndByteMarker=192)
//   Read<T>() for sizeof(T)==8: Raw<8,T>::Read() = Read64(kEndByteMarker=192)
//   ReadRef()  = ReadRefId() (big-endian signed-byte accumulation)
//   ReadUnsigned() = variable-length, marker 128

// specFunction returns FillSpec for Function clusters.
// v2.10:   7 refs + ReadRef(code) + Read<uint32_t>(packed_fields) + Read<uint32_t>(kind_tag)
// v2.13:   5 refs + ReadRef(code) + Read<uint32_t>(packed_fields) + Read<uint32_t>(kind_tag)
// v2.14-2.17: 4 refs + ReadUnsigned(code) + Read<uint32_t>(packed_fields) + Read<uint32_t>(kind_tag)
// v3.x:    4 refs + ReadUnsigned(code) + Read<uint32_t>(kind_tag)
func specFunction(fillRefUnsigned bool, numRefs int) FillSpec {
	if numRefs <= 0 {
		numRefs = 4 // default: name, owner, signature, data
	}
	scalars := []ScalarOp{OpUnsigned} // code_index (or code ref for ≤2.13)
	if fillRefUnsigned {
		scalars = append(scalars, OpTagged32) // packed_fields (v2.x only)
	}
	scalars = append(scalars, OpTagged32) // kind_tag
	return FillSpec{
		Kind:         FillRefs,
		NumRefs:      numRefs,
		Scalars:      scalars,
		NameIdx:      0,
		OwnerIdx:     1,
		SignatureIdx: 2, // Function refs: name(0), owner(1), signature(2), data(3)
	}
}

// specClass returns FillSpec for Class clusters (AOT PRODUCT).
// Custom handler needed because ReadUnsigned64(bitmap) is conditional:
// - Predefined classes: always read bitmap
// - New classes: only read bitmap if !IsTopLevelCid(class_id)
// v2.10: 16 refs (name through allocation_stub, no PRODUCT guards)
// v2.13: 15 refs (name through allocation_stub, no signature_function)
// v2.14+: 13 refs (name through invocation_dispatcher_cache, PRODUCT)
func specClass(numRefs int) FillSpec {
	if numRefs <= 0 {
		numRefs = 13
	}
	return FillSpec{
		Kind:     FillClass,
		NumRefs:  numRefs,
		NameIdx:  0,
		OwnerIdx: -1,
	}
}

func specPatchClass(preV32 bool) FillSpec {
	// ≤3.1: 3 refs (patched_class, origin_class, script). to_snapshot = &script_.
	// ≥3.2: 2 refs (wrapped_class, script). origin_class removed.
	nrefs := 2
	if preV32 {
		nrefs = 3
	}
	return FillSpec{Kind: FillRefs, NumRefs: nrefs, NameIdx: -1, OwnerIdx: -1}
}

func specClosureData(numRefs int) FillSpec {
	// AOT: context_scope=null (not read from stream).
	// v2.14+: parent_function, closure = 2 refs + ReadUnsigned(default_type_arguments_kind)
	// v2.13:  parent_function, closure, default_type_arguments = 3 refs + ReadUnsigned(default_type_arguments_kind)
	if numRefs == 0 {
		numRefs = 2
	}
	return FillSpec{
		Kind:     FillRefs,
		NumRefs:  numRefs,
		Scalars:  []ScalarOp{OpUnsigned},
		NameIdx:  -1,
		OwnerIdx: -1,
	}
}

func specField(fillRefUnsigned bool) FillSpec {
	if fillRefUnsigned {
		// v2.17.6 AOT: ReadFromTo = 4 refs + Read<uint16_t>(kind_bits) +
		// ReadRef(value_or_offset) + CONDITIONAL ReadUnsigned(field_id) for static fields.
		// Needs custom handler due to conditional read.
		return FillSpec{
			Kind:     FillField,
			NumRefs:  4, // name, owner, type, initializer_function
			NameIdx:  0,
			OwnerIdx: 1,
		}
	}
	// v3.10.7 AOT: ReadFromTo = 4 refs + Read<uint32_t>(kind_bits) + ReadRef(host_offset_or_field_id)
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 4, // name, owner, type, initializer_function
		Scalars: []ScalarOp{
			OpTagged32, // kind_bits (uint32)
			OpRefId,    // host_offset_or_field_id (ReadRef)
		},
		NameIdx:  0,
		OwnerIdx: 1,
		IsField:  true,
	}
}

func specScript(hasLineCol, hasFlags bool) FillSpec {
	// AOT: 1 ref (url). Then version-dependent scalars.
	// v2.14+:   kernel_script_index only.
	// v2.13:    line_offset + col_offset + kernel_script_index.
	// v2.10:    line_offset + col_offset + flags(uint8) + kernel_script_index.
	var scalars []ScalarOp
	if hasLineCol {
		scalars = append(scalars, OpTagged32, OpTagged32) // line_offset, col_offset
	}
	if hasFlags {
		scalars = append(scalars, OpUint8) // flags
	}
	scalars = append(scalars, OpTagged32) // kernel_script_index
	return FillSpec{
		Kind:     FillRefs,
		NumRefs:  1, // url
		Scalars:  scalars,
		NameIdx:  0, // url is the "name"
		OwnerIdx: -1,
	}
}

func specLibrary() FillSpec {
	// AOT: 10 refs (name through exports). Then scalars.
	// kernel_library_index NOT read in AOT.
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 10, // name through exports
		Scalars: []ScalarOp{
			OpTagged32, // index (int32_t)
			OpTagged32, // num_imports (uint16_t via Read16)
			OpInt8,     // load_state (int8_t → ReadByte)
			OpUint8,    // flags (uint8_t → ReadByte)
		},
		NameIdx:  0,
		OwnerIdx: -1,
	}
}

func specNamespace() FillSpec {
	// AOT: 1 ref (target only). No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 1, NameIdx: -1, OwnerIdx: -1}
}

func specClosure() FillSpec {
	// ReadFromTo = 6 refs. No scalars in AOT PRODUCT.
	return FillSpec{Kind: FillRefs, NumRefs: 6, NameIdx: -1, OwnerIdx: -1}
}

func specUnlinkedCall() FillSpec {
	// ReadFromTo = 2 refs (target_name, args_descriptor). Read<bool>(can_patch).
	return FillSpec{
		Kind:     FillRefs,
		NumRefs:  2,
		Scalars:  []ScalarOp{OpBool},
		NameIdx:  0, // target_name
		OwnerIdx: -1,
	}
}

func specSubtypeTestCache(fillRefUnsigned, noSTCScalars bool) FillSpec {
	// v2.17.6: ReadRef(cache) only. No scalars.
	// v3.0.x: ReadRef(cache) only. No scalars (num_inputs/num_occupied not yet added).
	// v3.1.0+: ReadRef(cache) + Read<uint32_t>(num_inputs) + Read<uint32_t>(num_occupied).
	var scalars []ScalarOp
	if !fillRefUnsigned && !noSTCScalars {
		scalars = []ScalarOp{OpTagged32, OpTagged32}
	}
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 1,
		Scalars: scalars,
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specLoadingUnit() FillSpec {
	// ReadRef(parent) + Read<int32_t>(id).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 1,
		Scalars: []ScalarOp{OpTagged32},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specType(fillRefUnsigned, oldTypeScalars, typeClassIdIsRef, typeHasTokenPos bool, numRefs int) FillSpec {
	// v3.x:       ReadFromTo = 3 refs (type_test_stub, hash, arguments). ReadUnsigned(flags).
	// v2.17-2.19: ReadFromTo = 3 refs. ReadUnsigned(type_class_id) + Read<uint8_t>(combined).
	// v2.14-2.15: ReadFromTo = 3 refs (type_class_id, arguments, hash). Read<uint8_t>(combined).
	// v2.13:      ReadFromTo = 4 refs (type_test_stub, type_class_id, arguments, hash). Read<uint8_t>(combined).
	// v2.10:      ReadFromTo = 5 refs (type_test_stub, type_class_id, arguments, hash, signature).
	//             ReadTokenPosition(token_pos) + Read<uint8_t>(combined).
	if numRefs == 0 {
		numRefs = 3
	}
	var scalars []ScalarOp
	if typeClassIdIsRef && typeHasTokenPos {
		// v2.10: type_class_id in ReadFromTo + token_pos(int32) + combined(uint8)
		scalars = []ScalarOp{OpTagged32, OpUint8}
	} else if typeClassIdIsRef {
		// v2.13-v2.15: type_class_id is a pointer in ReadFromTo, only combined scalar.
		scalars = []ScalarOp{OpUint8}
	} else if oldTypeScalars {
		// v2.17/v2.18: type_class_id(Unsigned) + combined(uint8)
		scalars = []ScalarOp{OpUnsigned, OpUint8}
	} else {
		// v3.x: flags(Unsigned) only
		scalars = []ScalarOp{OpUnsigned}
	}
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: numRefs,
		Scalars: scalars,
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specFunctionType(numRefs int, oldScalars bool) FillSpec {
	// v2.17+/v3.x: ReadFromTo = 6 refs. Read<uint8_t>(combined) + Read<uint32_t>(packed_parameter_counts) + Read<uint16_t>(packed_type_parameter_counts).
	// v2.14-2.15:  ReadFromTo = 5 refs (no type_test_stub). Same 3 scalars.
	// v2.13:       ReadFromTo = 6 refs. Read<uint8_t>(combined) + Read<uint32_t>(packed_fields). Only 2 scalars.
	if numRefs == 0 {
		numRefs = 6
	}
	scalars := []ScalarOp{OpUint8, OpTagged32, OpTagged32}
	if oldScalars {
		// v2.13: only combined + packed_fields (no packed_type_parameter_counts)
		scalars = []ScalarOp{OpUint8, OpTagged32}
	}
	return FillSpec{
		Kind:       FillRefs,
		NumRefs:    numRefs,
		Scalars:    scalars,
		NameIdx:    -1,
		OwnerIdx:   -1,
		IsFuncType: true,
	}
}

func specRecordType() FillSpec {
	// ReadFromTo: type_test_stub, hash, shape, field_types = 4 refs.
	// shape is COMPRESSED_SMI_FIELD (compressed pointer, included in ReadFromTo).
	// Read<uint8_t>(flags).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 4,
		Scalars: []ScalarOp{OpUint8},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specTypeParameter(hasParamClassId, typeParamByteScalars, typeParamWideScalars, typeHasTokenPos bool, numRefs int) FillSpec {
	// v3.1.0+: ReadFromTo = 3 refs (type_test_stub, hash, owner).
	//   Read<uint16_t>(base) + Read<uint16_t>(index) + Read<uint8_t>(flags)
	// v3.0.x: ReadFromTo = 3 refs (type_test_stub, hash, bound).
	//   Read<int32_t>(parameterized_class_id) + Read<uint16_t>(base) + Read<uint16_t>(index) + Read<uint8_t>(flags)
	// v2.17-v2.19: ReadFromTo = 3 refs (type_test_stub, hash, bound).
	//   Read<int32_t>(parameterized_class_id) + Read<uint8_t>(base) + Read<uint8_t>(index) + Read<uint8_t>(combined)
	// v2.14-v2.15: ReadFromTo = 2 refs (hash, bound). Same scalars as v2.17.
	// v2.13: ReadFromTo = 5 refs (type_test_stub, name, hash, bound, default_argument).
	//   Read<int32_t>(parameterized_class_id) + Read<uint16_t>(base) + Read<uint16_t>(index) + Read<uint8_t>(combined)
	// v2.10: ReadFromTo = 5 refs (type_test_stub, name, hash, bound, parameterized_function).
	//   Read<int32_t>(parameterized_class_id) + ReadTokenPosition(token_pos) + Read<int16_t>(index) + Read<uint8_t>(combined)
	if numRefs == 0 {
		numRefs = 3
	}
	var scalars []ScalarOp
	switch {
	case typeHasTokenPos:
		// v2.10: parameterized_class_id(int32) + token_pos(int32) + index(int16) + combined(uint8)
		scalars = []ScalarOp{OpTagged32, OpTagged32, OpInt16, OpUint8}
	case typeParamWideScalars:
		// v2.13: parameterized_class_id(int32) + base(uint16) + index(uint16) + combined(uint8)
		scalars = []ScalarOp{OpTagged32, OpTagged32, OpTagged32, OpUint8}
	case hasParamClassId && typeParamByteScalars:
		// v2.14-v2.19: parameterized_class_id(int32) + base(uint8) + index(uint8) + combined(uint8)
		scalars = []ScalarOp{OpTagged32, OpUint8, OpUint8, OpUint8}
	case hasParamClassId:
		// v3.0.x: parameterized_class_id(int32) + base(uint16) + index(uint16) + flags(uint8)
		scalars = []ScalarOp{OpTagged32, OpTagged32, OpTagged32, OpUint8}
	default:
		// v3.1.0+: base(uint16) + index(uint16) + flags(uint8)
		scalars = []ScalarOp{OpTagged32, OpTagged32, OpUint8}
	}
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: numRefs,
		Scalars: scalars,
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specTypeRef(numRefs int) FillSpec {
	// v2.17.6: ReadFromTo = 2 refs (type_test_stub, type). No scalars.
	// v2.14-v2.15: ReadFromTo = 1 ref (type only, no type_test_stub).
	// v2.13: ReadFromTo = 2 refs (type_test_stub, type).
	if numRefs == 0 {
		numRefs = 2
	}
	return FillSpec{Kind: FillRefs, NumRefs: numRefs, NameIdx: -1, OwnerIdx: -1}
}

func specGrowableObjectArray() FillSpec {
	// ReadFromTo = 3 refs (type_arguments, length, data). No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 3, NameIdx: -1, OwnerIdx: -1}
}

func specMap() FillSpec {
	// Map/ConstMap: ReadFromTo(to_snapshot) = 5 refs.
	// Fields: type_arguments, hash_mask, data, used_data, deleted_keys.
	// Field "index" is NOT serialized (null-initialized via to_snapshot()).
	return FillSpec{Kind: FillRefs, NumRefs: 5, NameIdx: -1, OwnerIdx: -1}
}

func specSet() FillSpec {
	// Set/ConstSet: ReadFromTo(to_snapshot) = 5 refs.
	// Fields: type_arguments, hash_mask, data, used_data, deleted_keys.
	// Field "index" is NOT serialized (null-initialized via to_snapshot()).
	// Same layout as Map — both inherit UntaggedLinkedHashBase.
	return FillSpec{Kind: FillRefs, NumRefs: 5, NameIdx: -1, OwnerIdx: -1}
}

func specRegExp(hasExternalFields bool) FillSpec {
	// ≤3.3.0: ReadFromTo = 10 refs (capture_name_map, pattern, one_byte, two_byte,
	//   external_one_byte, external_two_byte, one_byte_sticky, two_byte_sticky,
	//   external_one_byte_sticky, external_two_byte_sticky).
	// ≥3.4.3: ReadFromTo = 6 refs (external_* fields removed).
	// Scalars: Read<int32_t>(num_one_byte_registers) + Read<int32_t>(num_two_byte_registers) + Read<int8_t>(type_flags).
	numRefs := 6
	if hasExternalFields {
		numRefs = 10
	}
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: numRefs,
		Scalars: []ScalarOp{OpTagged32, OpTagged32, OpInt8},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specWeakProperty() FillSpec {
	// ReadFromTo = 2 refs (key, value). No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 2, NameIdx: -1, OwnerIdx: -1}
}

func specWeakReference() FillSpec {
	// ReadFromTo = 2 refs (target, type_arguments). No scalars in AOT.
	return FillSpec{Kind: FillRefs, NumRefs: 2, NameIdx: -1, OwnerIdx: -1}
}

func specLibraryPrefix() FillSpec {
	// AOT: to_snapshot(kFullAOT) = &imports_. ReadFromTo = 2 refs (name, imports).
	// importer NOT serialized in AOT.
	// Read<uint16_t>(num_imports) + Read<bool>(is_deferred_load).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 2,
		Scalars: []ScalarOp{OpTagged32, OpBool},
		NameIdx: 0, OwnerIdx: -1,
	}
}

func specLanguageError() FillSpec {
	// ReadFromTo = 4 refs (previous_error, script, message, formatted_message).
	// ReadTokenPosition = Read<int32_t>(token_pos).
	// Read<bool>(report_after_token).
	// Read<int8_t>(kind).
	// All scalar reads are unconditional (no DART_PRECOMPILED_RUNTIME guard).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 4,
		Scalars: []ScalarOp{OpTagged32, OpBool, OpInt8},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specUnhandledException() FillSpec {
	// ReadFromTo = 2 refs (exception, stacktrace). No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 2, NameIdx: -1, OwnerIdx: -1}
}

func specICData() FillSpec {
	// AOT PRODUCT: ReadFromTo reads CallSiteData fields + ICData entries.
	// CallSiteData: target_name, args_descriptor; ICData: entries = 3 refs total.
	// deopt_id is NOT_IN_PRECOMPILED (skipped in AOT).
	// Read<int32_t>(state_bits) only.
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 3,
		Scalars: []ScalarOp{OpTagged32},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specMegamorphicCache() FillSpec {
	// ReadFromTo reads CallSiteData (target_name, args_descriptor) + MegamorphicCache (buckets, mask) = 4 refs.
	// Read<int32_t>(filled_entry_count).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 4,
		Scalars: []ScalarOp{OpTagged32},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specSingleTargetCache() FillSpec {
	// ReadFromTo: target = 1 ref.
	// Read<uword>(lower_limit) + Read<uword>(upper_limit). uword = 8 bytes on arm64.
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 1,
		Scalars: []ScalarOp{OpTagged64, OpTagged64},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specKernelProgramInfo() FillSpec {
	// ReadFromTo only. to_snapshot → &constants_table_.
	// Fields: kernel_component, string_offsets, string_data, canonical_names,
	//         metadata_payloads, metadata_mappings, scripts, constants, constants_table = 9 refs.
	// No scalars (ReadFill only does ReadFromTo).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 9,
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specFfiTrampolineData(fillRefUnsigned, noFfiKind bool) FillSpec {
	// ReadFromTo: signature_type, c_signature, callback_target, callback_exceptional_return = 4 refs.
	// v2.17.6: ReadUnsigned(callback_id) only. No ffi_function_kind.
	// v3.0.x: Read<int32_t>(callback_id) only. ffi_function_kind not yet added.
	// v3.1.0+: Read<int32_t>(callback_id) + Read<uint8_t>(ffi_function_kind).
	var scalars []ScalarOp
	switch {
	case fillRefUnsigned:
		scalars = []ScalarOp{OpUnsigned}
	case noFfiKind:
		scalars = []ScalarOp{OpTagged32}
	default:
		scalars = []ScalarOp{OpTagged32, OpUint8}
	}
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 4,
		Scalars: scalars,
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specSignatureData() FillSpec {
	// v2.10 only. ReadFromTo: parent_function, signature_type = 2 refs.
	return FillSpec{Kind: FillRefs, NumRefs: 2, NameIdx: -1, OwnerIdx: -1}
}

func specTypeParameters() FillSpec {
	// ReadFromTo: names, flags, bounds, defaults = 4 refs. No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 4, NameIdx: -1, OwnerIdx: -1}
}

func specMonomorphicSmiableCall() FillSpec {
	// Read<uword>(expected_cid) + Read<uword>(entry_point).
	// No refs in fill. uword = 8 bytes on arm64 → Read64(marker 192).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 0,
		Scalars: []ScalarOp{OpTagged64, OpTagged64},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specTypedDataView() FillSpec {
	// ReadFromTo: typed_data, offset_in_bytes, length = 3 refs. No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 3, NameIdx: -1, OwnerIdx: -1}
}

func specExternalTypedData() FillSpec {
	// ReadFromTo: length = 1 ref. Read raw data pointer handling.
	// Actually in AOT, ExternalTypedData not typically serialized. Treat as simple refs.
	return FillSpec{Kind: FillRefs, NumRefs: 1, NameIdx: -1, OwnerIdx: -1}
}

func specStackTrace() FillSpec {
	// ReadFromTo = 2 refs. No scalars in AOT PRODUCT.
	return FillSpec{Kind: FillRefs, NumRefs: 2, NameIdx: -1, OwnerIdx: -1}
}

func specSendPort() FillSpec {
	// SendPort: ReadRef(id) + ReadUnsigned(origin_id).
	// Actually: no ReadFromTo, custom: Read<Dart_Port>(id) + Read<Dart_Port>(origin_id) = 2 × ReadTagged64.
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 0,
		Scalars: []ScalarOp{OpTagged64, OpTagged64},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specCapability() FillSpec {
	// Read<uint64_t>(id) = ReadTagged64.
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 0,
		Scalars: []ScalarOp{OpTagged64},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specReceivePort() FillSpec {
	// AOT: ReadRef(send_port) + Read<Dart_Port>(id) = 1 ref + Tagged64.
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 1,
		Scalars: []ScalarOp{OpTagged64},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specSuspendState() FillSpec {
	// AOT: ReadFromTo = 2 refs (then_callback, error_callback).
	// Read<int32_t>(frame_size).
	return FillSpec{
		Kind:    FillRefs,
		NumRefs: 2,
		Scalars: []ScalarOp{OpTagged32},
		NameIdx: -1, OwnerIdx: -1,
	}
}

func specTransferableTypedData() FillSpec {
	// No fill data in AOT typically. Treat as 0 refs.
	return FillSpec{Kind: FillNone, NameIdx: -1, OwnerIdx: -1}
}

func specUserTag() FillSpec {
	// ReadFromTo = 1 ref (label). Read<uword>(tag). uword = 8 bytes on arm64.
	return FillSpec{
		Kind:     FillRefs,
		NumRefs:  1,
		Scalars:  []ScalarOp{OpTagged64},
		NameIdx:  0, // label
		OwnerIdx: -1,
	}
}

func specFutureOr() FillSpec {
	// ReadFromTo = 2 refs (type_test_stub, type_arguments). No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 2, NameIdx: -1, OwnerIdx: -1}
}

func specWeakSerializationReference() FillSpec {
	// ReadRef(target) = 1 ref. No scalars.
	return FillSpec{Kind: FillRefs, NumRefs: 1, NameIdx: -1, OwnerIdx: -1}
}

// GetFillSpec returns the fill format for a cluster, dispatching by CID.
// Takes the full VersionProfile to access CIDs, version, and compressed pointer flag.
func GetFillSpec(cid int, cm *ClusterMeta, profile *snapshot.VersionProfile) FillSpec {
	ct := profile.CIDs
	fillRefUnsigned := profile.FillRefUnsigned
	preV32 := profile.PreV32Format
	switch {
	case cid == ct.Function:
		return specFunction(fillRefUnsigned, profile.FuncNumRefs)
	case cid == ct.Class:
		return specClass(profile.ClassNumRefs)
	case cid == ct.PatchClass:
		return specPatchClass(preV32)
	case cid == ct.ClosureData:
		return specClosureData(profile.ClosureDataNumRefs)
	case cid == ct.Field:
		return specField(fillRefUnsigned)
	case cid == ct.Script:
		return specScript(profile.ScriptHasLineCol, profile.ScriptHasFlags)
	case cid == ct.Library:
		return specLibrary()
	case cid == ct.Namespace:
		return specNamespace()
	case cid == ct.Closure:
		s := specClosure()
		if profile.PreCanonicalSplit {
			s.LeadingBool = true
		}
		return s
	case cid == ct.UnlinkedCall:
		return specUnlinkedCall()
	case cid == ct.SubtypeTestCache:
		return specSubtypeTestCache(fillRefUnsigned, profile.HasTypeParamClassId)
	case cid == ct.LoadingUnit:
		return specLoadingUnit()
	case cid == ct.Type:
		return specType(fillRefUnsigned, profile.OldTypeScalars, profile.TypeClassIdIsRef, profile.TypeHasTokenPos, profile.TypeNumRefs)
	case cid == ct.FunctionType:
		return specFunctionType(profile.FuncTypeNumRefs, profile.FuncTypeOldScalars)
	case ct.RecordType != 0 && cid == ct.RecordType:
		return specRecordType()
	case cid == ct.TypeParameter:
		return specTypeParameter(profile.HasTypeParamClassId, profile.TypeParamByteScalars, profile.TypeParamWideScalars, profile.TypeHasTokenPos, profile.TypeParamNumRefs)
	case ct.TypeRef != 0 && cid == ct.TypeRef:
		return specTypeRef(profile.TypeRefNumRefs)
	case cid == ct.GrowableObjectArray:
		s := specGrowableObjectArray()
		if profile.PreCanonicalSplit {
			s.LeadingBool = true
		}
		return s
	case cid == ct.Map, cid == ct.ConstMap:
		s := specMap()
		if profile.PreCanonicalSplit {
			s.LeadingBool = true
		}
		return s
	case cid == ct.Set, cid == ct.ConstSet:
		s := specSet()
		if profile.PreCanonicalSplit {
			s.LeadingBool = true
		}
		return s
	case cid == ct.RegExp:
		// ≤3.3.0 (CidShift1): 10 refs (external_* fields present).
		// ≥3.4.3 (ObjectHeader): 6 refs (external_* fields removed).
		hasExternal := profile.Tags == snapshot.TagStyleCidShift1
		return specRegExp(hasExternal)
	case cid == ct.WeakProperty:
		return specWeakProperty()
	case ct.WeakReference != 0 && cid == ct.WeakReference:
		return specWeakReference()
	case cid == ct.LibraryPrefix:
		return specLibraryPrefix()
	case cid == ct.LanguageError:
		return specLanguageError()
	case cid == ct.UnhandledException:
		return specUnhandledException()
	case cid == ct.ICData:
		return specICData()
	case cid == ct.MegamorphicCache:
		return specMegamorphicCache()
	case cid == ct.SingleTargetCache:
		return specSingleTargetCache()
	case ct.MonomorphicSmiableCall != 0 && cid == ct.MonomorphicSmiableCall:
		return specMonomorphicSmiableCall()
	case cid == ct.KernelProgramInfo:
		return specKernelProgramInfo()
	case ct.FfiTrampolineData != 0 && cid == ct.FfiTrampolineData:
		return specFfiTrampolineData(fillRefUnsigned, profile.HasTypeParamClassId)
	case ct.SignatureData != 0 && cid == ct.SignatureData:
		return specSignatureData()
	case ct.TypeParameters != 0 && cid == ct.TypeParameters:
		return specTypeParameters()
	case cid == ct.TypedDataView:
		s := specTypedDataView()
		if profile.PreCanonicalSplit {
			s.LeadingBool = true
		}
		return s
	case cid == ct.ExternalTypedData:
		return specExternalTypedData()
	case cid == ct.StackTrace:
		return specStackTrace()
	case cid == ct.SendPort:
		return specSendPort()
	case ct.Capability != 0 && cid == ct.Capability:
		return specCapability()
	case ct.ReceivePort != 0 && cid == ct.ReceivePort:
		return specReceivePort()
	case ct.SuspendState != 0 && cid == ct.SuspendState:
		return specSuspendState()
	case ct.TransferableTypedData != 0 && cid == ct.TransferableTypedData:
		return specTransferableTypedData()
	case ct.UserTag != 0 && cid == ct.UserTag:
		return specUserTag()
	case ct.FutureOr != 0 && cid == ct.FutureOr:
		return specFutureOr()
	case ct.WeakSerializationReference != 0 && cid == ct.WeakSerializationReference:
		return specWeakSerializationReference()
	case ct.Sentinel != 0 && cid == ct.Sentinel:
		return FillSpec{Kind: FillSentinel, NameIdx: -1, OwnerIdx: -1}

	// Special fill formats (not FillRefs)
	case cid == ct.String, cid == ct.OneByteString, cid == ct.TwoByteString:
		// In AOT without compressed pointers (or SplitCanonical/2.13), strings use
		// ROData format: alloc embeds the data inline, fill has nothing.
		// With compressed pointers, strings have per-string fill data.
		if profile.SplitCanonical || !profile.CompressedPointers {
			return FillSpec{Kind: FillROData, NameIdx: -1, OwnerIdx: -1}
		}
		return FillSpec{Kind: FillString, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Mint:
		return FillSpec{Kind: FillNone, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Double:
		return FillSpec{Kind: FillDouble, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Float32x4:
		return FillSpec{Kind: FillRefs, NumRefs: 0,
			Scalars: []ScalarOp{OpTagged32, OpTagged32, OpTagged32, OpTagged32},
			NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Int32x4:
		return FillSpec{Kind: FillRefs, NumRefs: 0,
			Scalars: []ScalarOp{OpTagged32, OpTagged32, OpTagged32, OpTagged32},
			NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Float64x2:
		return FillSpec{Kind: FillRefs, NumRefs: 0,
			Scalars: []ScalarOp{OpTagged64, OpTagged64},
			NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Code:
		return FillSpec{Kind: FillCode, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.ObjectPool:
		return FillSpec{Kind: FillObjectPool, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Array, cid == ct.ImmutableArray:
		return FillSpec{Kind: FillArray, NameIdx: -1, OwnerIdx: -1}
	case ct.WeakArray != 0 && cid == ct.WeakArray:
		return FillSpec{Kind: FillWeakArray, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.TypeArguments:
		return FillSpec{Kind: FillTypeArguments, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.ExceptionHandlers:
		return FillSpec{Kind: FillExceptionHandlers, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.Context:
		return FillSpec{Kind: FillContext, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.ContextScope:
		return FillSpec{Kind: FillContextScope, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.PcDescriptors, cid == ct.CodeSourceMap, cid == ct.CompressedStackMaps:
		// With compressed pointers, these use individual clusters with inline data:
		// ReadUnsigned(length) + ReadBytes(length) per object.
		// Without compressed pointers, they use ROData (no fill).
		if profile.CompressedPointers {
			return FillSpec{Kind: FillInlineBytes, NameIdx: -1, OwnerIdx: -1}
		}
		return FillSpec{Kind: FillROData, NameIdx: -1, OwnerIdx: -1}
	case cid == ct.TypedData:
		return FillSpec{Kind: FillTypedData, NameIdx: -1, OwnerIdx: -1}
	case ct.Record != 0 && cid == ct.Record:
		return FillSpec{Kind: FillRecord, NameIdx: -1, OwnerIdx: -1}
	}

	// TypedData internal CIDs.
	if ct.TypedDataInt8ArrayCid != 0 && ct.ByteDataViewCid != 0 &&
		cid >= ct.TypedDataInt8ArrayCid && cid < ct.ByteDataViewCid {
		rem := (cid - ct.TypedDataInt8ArrayCid) % ct.TypedDataCidStride
		if rem == 0 {
			// Internal TypedData: same as TypedData fill.
			return FillSpec{Kind: FillTypedData, NameIdx: -1, OwnerIdx: -1}
		}
		if rem == 1 {
			// TypedDataView: 3 refs (typed_data, offset_in_bytes, length).
			return specTypedDataView()
		}
		// External or UnmodifiableView: treat as simple refs.
		return specExternalTypedData()
	}

	// DeltaEncodedTypedData (NativePointer CID).
	if ct.NativePointerCid != 0 && cid == ct.NativePointerCid {
		return FillSpec{Kind: FillTypedData, NameIdx: -1, OwnerIdx: -1}
	}

	// Instance subclasses (CID >= Instance).
	if ct.Instance != 0 && cid >= ct.Instance {
		return FillSpec{Kind: FillInstance, NameIdx: -1, OwnerIdx: -1}
	}

	return FillSpec{Kind: FillUnknown, NameIdx: -1, OwnerIdx: -1}
}

// v210FillLeadingBool lists CIDs that have Read<bool>(is_canonical) per object in v2.10.
// In v2.13+, canonical status moved to the cluster level (stamp_canonical parameter).
func v210FillLeadingBool(cid int, ct *snapshot.CIDTable) bool {
	switch cid {
	case ct.Closure, ct.GrowableObjectArray:
		return true
	}
	// Map/ConstMap, Set/ConstSet — these are LinkedHashMap/LinkedHashSet in v2.10.
	if cid == ct.Map || cid == ct.ConstMap {
		return true
	}
	return false
}

```

`internal/cluster/instrtable.go`:

```go
package cluster

import (
	"encoding/binary"
	"fmt"
	"sort"

	"unflutter/internal/snapshot"
)

// InstructionsTable holds the parsed InstructionsTable rodata from the data image.
type InstructionsTable struct {
	Length             uint32 // total number of table entries (stubs + code)
	FirstEntryWithCode uint32 // index of first entry that maps to a Code object
	Entries            []InstrTableEntry
}

// InstrTableEntry is one entry in the InstructionsTable.
type InstrTableEntry struct {
	PCOffset       uint32 // offset from instructions image base
	StackMapOffset uint32
}

// CodeRange describes one Code object's instruction region.
type CodeRange struct {
	RefID    int
	OwnerRef int
	Index    int    // ClusterIndex (slot relative to first_entry_with_code)
	PCOffset uint32 // from instructions image base
	Size     uint32 // bytes
}

// dataImageAlignment returns the data image alignment for a version.
// Dart ≤2.18 uses kMaxObjectAlignment=16; Dart ≥2.19 uses kObjectStartAlignment=64.
func dataImageAlignment(profile *snapshot.VersionProfile) int64 {
	if profile.TopLevelCid16 {
		return 16
	}
	return 64
}

// oneByteStringHeaderSize is the size of a OneByteString object header in the
// image. On arm64, WriteROData writes tags (8 bytes) + length (8 bytes via
// WriteTargetWord) = 16 bytes before the payload data.
const oneByteStringHeaderSize = 16

// instrTableDataHeaderSize is sizeof(UntaggedInstructionsTable::Data):
// {canon_offset u32, length u32, first_entry_with_code u32, padding u32}.
const instrTableDataHeaderSize = 16

// ParseInstructionsTable reads the InstructionsTable rodata from the isolate
// snapshot data. It locates the data image, finds the OneByteString object at
// InstructionTableDataOffset, skips its header, and parses the Data header
// and DataEntry array.
func ParseInstructionsTable(data []byte, hdr *Header, profile *snapshot.VersionProfile, isoHeader *snapshot.Header) (*InstructionsTable, error) {
	if hdr.InstructionTableDataOffset == 0 {
		return nil, fmt.Errorf("instrtable: no instruction table data offset")
	}

	align := dataImageAlignment(profile)
	diStart := roundUp(isoHeader.TotalSize, align)
	tableObjOff := diStart + hdr.InstructionTableDataOffset

	// Minimum: oneByteStringHeader + Data header + 0 entries
	minSize := tableObjOff + oneByteStringHeaderSize + instrTableDataHeaderSize
	if int64(len(data)) < minSize {
		return nil, fmt.Errorf("instrtable: data too short for table at offset %d (need %d, have %d)",
			tableObjOff, minSize, len(data))
	}

	// Skip OneByteString header to reach Data payload.
	payloadOff := int(tableObjOff) + oneByteStringHeaderSize

	// Read Data header: {canon_offset u32, length u32, first_entry_with_code u32, padding u32}
	length := binary.LittleEndian.Uint32(data[payloadOff+4 : payloadOff+8])
	firstCode := binary.LittleEndian.Uint32(data[payloadOff+8 : payloadOff+12])

	if length == 0 {
		return &InstructionsTable{}, nil
	}
	if firstCode > length {
		return nil, fmt.Errorf("instrtable: first_entry_with_code %d > length %d", firstCode, length)
	}

	// Read DataEntry array.
	entriesOff := payloadOff + instrTableDataHeaderSize
	entryBytes := int(length) * 8
	if entriesOff+entryBytes > len(data) {
		return nil, fmt.Errorf("instrtable: data too short for %d entries (need %d, have %d)",
			length, entriesOff+entryBytes, len(data))
	}

	entries := make([]InstrTableEntry, length)
	for i := range entries {
		off := entriesOff + i*8
		entries[i] = InstrTableEntry{
			PCOffset:       binary.LittleEndian.Uint32(data[off : off+4]),
			StackMapOffset: binary.LittleEndian.Uint32(data[off+4 : off+8]),
		}
	}

	return &InstructionsTable{
		Length:             length,
		FirstEntryWithCode: firstCode,
		Entries:            entries,
	}, nil
}

// ResolveCodeRanges maps each CodeEntry to its instruction byte range using the
// InstructionsTable. Returns sorted CodeRange slices (by PCOffset).
func ResolveCodeRanges(codes []CodeEntry, table *InstructionsTable) ([]CodeRange, error) {
	if table == nil || len(table.Entries) == 0 {
		return nil, nil
	}

	// Collect pc_offsets for all main codes.
	var ranges []CodeRange
	for i := range codes {
		c := &codes[i]
		if c.ClusterIndex < 0 {
			continue
		}
		slot := int(table.FirstEntryWithCode) + c.ClusterIndex
		if slot < 0 || slot >= len(table.Entries) {
			return nil, fmt.Errorf("instrtable: code ref %d index %d maps to slot %d (table has %d entries)",
				c.RefID, c.ClusterIndex, slot, len(table.Entries))
		}
		ranges = append(ranges, CodeRange{
			RefID:    c.RefID,
			OwnerRef: c.OwnerRef,
			Index:    c.ClusterIndex,
			PCOffset: table.Entries[slot].PCOffset,
		})
	}

	// Sort by PCOffset.
	sort.Slice(ranges, func(i, j int) bool {
		return ranges[i].PCOffset < ranges[j].PCOffset
	})

	// Compute sizes by diffing adjacent offsets.
	for i := 0; i < len(ranges)-1; i++ {
		ranges[i].Size = ranges[i+1].PCOffset - ranges[i].PCOffset
	}
	// Last range: size unknown from table alone; caller must provide code region end.

	return ranges, nil
}

// ResolveStubRanges creates CodeRange entries for stub/trampoline entries in
// the instructions table (indices 0 through FirstEntryWithCode-1). These
// entries have valid PCOffsets but are not associated with snapshot Code objects.
// RefID is set to -1 to distinguish them from code-object ranges.
func ResolveStubRanges(table *InstructionsTable) []CodeRange {
	if table == nil || table.FirstEntryWithCode == 0 {
		return nil
	}

	ranges := make([]CodeRange, 0, int(table.FirstEntryWithCode))
	for i := 0; i < int(table.FirstEntryWithCode); i++ {
		ranges = append(ranges, CodeRange{
			RefID:    -1,
			OwnerRef: -1,
			Index:    i,
			PCOffset: table.Entries[i].PCOffset,
		})
	}

	// Sort by PCOffset.
	sort.Slice(ranges, func(i, j int) bool {
		return ranges[i].PCOffset < ranges[j].PCOffset
	})

	// Compute sizes by diffing adjacent offsets.
	for i := 0; i < len(ranges)-1; i++ {
		ranges[i].Size = ranges[i+1].PCOffset - ranges[i].PCOffset
	}
	// Last stub: size set by caller (either first code entry or code region end).

	return ranges
}

// MergeRanges merges stub and code ranges into a single sorted slice.
// Sizes are recomputed from adjacent entries after merge. The caller must
// call SetLastRangeSize on the result.
func MergeRanges(stubs, codes []CodeRange) []CodeRange {
	all := make([]CodeRange, 0, len(stubs)+len(codes))
	all = append(all, stubs...)
	all = append(all, codes...)

	sort.Slice(all, func(i, j int) bool {
		return all[i].PCOffset < all[j].PCOffset
	})

	// Recompute sizes from sorted order.
	for i := 0; i < len(all)-1; i++ {
		all[i].Size = all[i+1].PCOffset - all[i].PCOffset
	}
	// Last entry: size 0 until caller sets it.
	if len(all) > 0 {
		all[len(all)-1].Size = 0
	}

	return all
}

// SetLastRangeSize sets the size of the last CodeRange based on the total
// code region end offset. codeEndOffset is relative to the instructions image base.
func SetLastRangeSize(ranges []CodeRange, codeEndOffset uint32) {
	if len(ranges) == 0 {
		return
	}
	last := &ranges[len(ranges)-1]
	if codeEndOffset > last.PCOffset {
		last.Size = codeEndOffset - last.PCOffset
	}
}

func roundUp(v, align int64) int64 {
	return (v + align - 1) &^ (align - 1)
}

```

`internal/cluster/instrtable_test.go`:

```go
package cluster

import (
	"testing"
)

func TestInstructionsTable_AllSamples(t *testing.T) {
	tests := []struct {
		sample        string
		wantLength    uint32
		wantFirstCode uint32
		wantMainCodes int
	}{
		{"evil-patched.so", 1465, 0, 1465},
		{"blutter-lce.so", 10113, 0, 10113},
		{"newandromo.so", 21627, 17475, 4152},
	}
	for _, tt := range tests {
		t.Run(tt.sample, func(t *testing.T) {
			info := extractSnapshot(t, tt.sample)
			data := info.IsolateData.Data
			result := scanSnapshot(t, info, data, false)
			if err := ReadFill(data, result, info.Version, false, 0); err != nil {
				t.Fatalf("ReadFill: %v", err)
			}

			table, err := ParseInstructionsTable(data, &result.Header, info.Version, info.IsolateHeader)
			if err != nil {
				t.Fatalf("ParseInstructionsTable: %v", err)
			}

			if table.Length != tt.wantLength {
				t.Errorf("Length = %d, want %d", table.Length, tt.wantLength)
			}
			if table.FirstEntryWithCode != tt.wantFirstCode {
				t.Errorf("FirstEntryWithCode = %d, want %d", table.FirstEntryWithCode, tt.wantFirstCode)
			}

			// Verify entry count matches.
			if int(table.Length) != len(table.Entries) {
				t.Errorf("len(Entries) = %d, want %d", len(table.Entries), table.Length)
			}

			// Verify code entry count.
			codeEntries := int(table.Length) - int(table.FirstEntryWithCode)
			if codeEntries != tt.wantMainCodes {
				t.Errorf("code entries = %d, want %d", codeEntries, tt.wantMainCodes)
			}

			// Verify first code entry has non-zero PCOffset.
			if table.FirstEntryWithCode < table.Length {
				first := table.Entries[table.FirstEntryWithCode]
				if first.PCOffset == 0 {
					t.Error("first code entry has PCOffset=0")
				}
			}

			// Resolve code ranges.
			ranges, err := ResolveCodeRanges(result.Codes, table)
			if err != nil {
				t.Fatalf("ResolveCodeRanges: %v", err)
			}
			if len(ranges) != tt.wantMainCodes {
				t.Errorf("len(ranges) = %d, want %d", len(ranges), tt.wantMainCodes)
			}

			// All ranges except last should have non-zero size.
			for i := 0; i < len(ranges)-1; i++ {
				if ranges[i].Size == 0 {
					t.Errorf("range[%d] (ref %d) has size 0", i, ranges[i].RefID)
					break
				}
			}

			// Ranges should be sorted by PCOffset.
			for i := 1; i < len(ranges); i++ {
				if ranges[i].PCOffset <= ranges[i-1].PCOffset {
					t.Errorf("ranges not sorted: [%d].PCOffset=%d <= [%d].PCOffset=%d",
						i, ranges[i].PCOffset, i-1, ranges[i-1].PCOffset)
					break
				}
			}
		})
	}
}

```

`internal/cluster/trace.go`:

```go
package cluster

import (
	"fmt"
	"io"

	"unflutter/internal/dartfmt"
)

// TraceEntry records one read operation with its byte offset range and value.
type TraceEntry struct {
	Frame    string
	Label    string
	StartOff int
	EndOff   int
	Value    int64
}

// TracingStream wraps a dartfmt.Stream with offset tracking and frame context.
type TracingStream struct {
	*dartfmt.Stream
	entries []TraceEntry
	frames  []string
	marks   [16]int
	markIdx int
	enabled bool
}

// NewTracingStream wraps a stream with tracing. If enabled is false,
// read methods delegate directly with no overhead.
func NewTracingStream(s *dartfmt.Stream, enabled bool) *TracingStream {
	return &TracingStream{Stream: s, enabled: enabled}
}

// PushFrame pushes a logical context frame (e.g. "cluster[3]/String/alloc").
func (ts *TracingStream) PushFrame(label string) {
	if !ts.enabled {
		return
	}
	ts.frames = append(ts.frames, label)
}

// PopFrame removes the top frame.
func (ts *TracingStream) PopFrame() {
	if !ts.enabled || len(ts.frames) == 0 {
		return
	}
	ts.frames = ts.frames[:len(ts.frames)-1]
}

// Mark records the current position in a ring buffer for debugging.
func (ts *TracingStream) Mark() {
	if !ts.enabled {
		return
	}
	ts.marks[ts.markIdx%len(ts.marks)] = ts.Position()
	ts.markIdx++
}

func (ts *TracingStream) frame() string {
	if len(ts.frames) == 0 {
		return ""
	}
	return ts.frames[len(ts.frames)-1]
}

// ReadUnsignedT reads an unsigned value and records a trace entry.
func (ts *TracingStream) ReadUnsignedT(label string) (int64, error) {
	if !ts.enabled {
		return ts.Stream.ReadUnsigned()
	}
	start := ts.Position()
	v, err := ts.Stream.ReadUnsigned()
	if err != nil {
		return v, err
	}
	ts.entries = append(ts.entries, TraceEntry{
		Frame:    ts.frame(),
		Label:    label,
		StartOff: start,
		EndOff:   ts.Position(),
		Value:    v,
	})
	return v, nil
}

// ReadTagged32T reads a tagged uint32 and records a trace entry.
func (ts *TracingStream) ReadTagged32T(label string) (uint32, error) {
	if !ts.enabled {
		return ts.Stream.ReadTagged32()
	}
	start := ts.Position()
	v, err := ts.Stream.ReadTagged32()
	if err != nil {
		return v, err
	}
	ts.entries = append(ts.entries, TraceEntry{
		Frame:    ts.frame(),
		Label:    label,
		StartOff: start,
		EndOff:   ts.Position(),
		Value:    int64(v),
	})
	return v, nil
}

// ReadTagged64T reads a tagged int64 and records a trace entry.
func (ts *TracingStream) ReadTagged64T(label string) (int64, error) {
	if !ts.enabled {
		return ts.Stream.ReadTagged64()
	}
	start := ts.Position()
	v, err := ts.Stream.ReadTagged64()
	if err != nil {
		return v, err
	}
	ts.entries = append(ts.entries, TraceEntry{
		Frame:    ts.frame(),
		Label:    label,
		StartOff: start,
		EndOff:   ts.Position(),
		Value:    v,
	})
	return v, nil
}

// Entries returns all recorded trace entries.
func (ts *TracingStream) Entries() []TraceEntry {
	return ts.entries
}

// RecentMarks returns the most recent mark positions (up to 16).
func (ts *TracingStream) RecentMarks() []int {
	n := ts.markIdx
	if n > len(ts.marks) {
		n = len(ts.marks)
	}
	out := make([]int, n)
	for i := 0; i < n; i++ {
		idx := (ts.markIdx - n + i) % len(ts.marks)
		out[i] = ts.marks[idx]
	}
	return out
}

// DumpTrace writes all entries to w in a human-readable format.
func (ts *TracingStream) DumpTrace(w io.Writer) {
	for _, e := range ts.entries {
		frame := e.Frame
		if frame != "" {
			frame += "/"
		}
		fmt.Fprintf(w, "  0x%06x..0x%06x  %s%s = %d (0x%x)\n",
			e.StartOff, e.EndOff, frame, e.Label, e.Value, e.Value)
	}
}

```

`internal/dartfmt/diag.go`:

```go
// Package dartfmt provides shared types and diagnostics for Dart snapshot parsing.
package dartfmt

import "fmt"

// DiagKind classifies a diagnostic message.
type DiagKind string

const (
	DiagTruncated  DiagKind = "truncated"
	DiagInvalid    DiagKind = "invalid"
	DiagUnknownTag DiagKind = "unknown_tag"
	DiagOverflow   DiagKind = "overflow"
	DiagClamped    DiagKind = "clamped"
)

// Diag records a non-fatal issue encountered during parsing.
type Diag struct {
	Offset uint64   `json:"offset"`
	Kind   DiagKind `json:"kind"`
	Msg    string   `json:"msg"`
}

func (d Diag) String() string {
	return fmt.Sprintf("[%s] 0x%x: %s", d.Kind, d.Offset, d.Msg)
}

// Diags accumulates diagnostics.
type Diags struct {
	items []Diag
}

func (d *Diags) Add(offset uint64, kind DiagKind, msg string) {
	d.items = append(d.items, Diag{Offset: offset, Kind: kind, Msg: msg})
}

func (d *Diags) Addf(offset uint64, kind DiagKind, format string, args ...any) {
	d.items = append(d.items, Diag{Offset: offset, Kind: kind, Msg: fmt.Sprintf(format, args...)})
}

func (d *Diags) Items() []Diag { return d.items }
func (d *Diags) Len() int      { return len(d.items) }

// Mode controls error handling behavior.
type Mode int

const (
	ModeStrict     Mode = iota // first structural error returns error
	ModeBestEffort             // continue with placeholders, accumulate diags
)

// Options controls parsing behavior across packages.
type Options struct {
	Mode     Mode
	MaxSteps int // global loop cap; 0 = use default
	MaxBytes int // output size cap; 0 = unlimited
}

// DefaultMaxSteps is the global default loop cap.
const DefaultMaxSteps = 10_000_000

func (o Options) EffectiveMaxSteps() int {
	if o.MaxSteps > 0 {
		return o.MaxSteps
	}
	return DefaultMaxSteps
}

```

`internal/dartfmt/stream.go`:

```go
// Dart snapshot data stream reader.
// Implements the custom variable-length integer encodings used by the Dart VM.
package dartfmt

import (
	"encoding/binary"
	"errors"
	"fmt"
)

var (
	ErrStreamEOF     = errors.New("stream: unexpected end of data")
	ErrStreamOverrun = errors.New("stream: value too large")
)

// Stream reads Dart snapshot data using the VM's encoding conventions.
type Stream struct {
	data []byte
	pos  int
	end  int
}

// NewStream creates a stream over the given data.
func NewStream(data []byte) *Stream {
	return &Stream{data: data, pos: 0, end: len(data)}
}

// NewStreamAt creates a stream starting at offset within data.
func NewStreamAt(data []byte, offset int) *Stream {
	if offset > len(data) {
		offset = len(data)
	}
	return &Stream{data: data, pos: offset, end: len(data)}
}

// Position returns the current read position.
func (s *Stream) Position() int { return s.pos }

// SetPosition sets the read position.
func (s *Stream) SetPosition(pos int) {
	if pos > s.end {
		pos = s.end
	}
	s.pos = pos
}

// Remaining returns bytes left to read.
func (s *Stream) Remaining() int { return s.end - s.pos }

// ReadByte reads a single byte.
func (s *Stream) ReadByte() (byte, error) {
	if s.pos >= s.end {
		return 0, ErrStreamEOF
	}
	b := s.data[s.pos]
	s.pos++
	return b, nil
}

// ReadBytes reads n bytes into a new slice.
func (s *Stream) ReadBytes(n int) ([]byte, error) {
	if s.pos+n > s.end {
		return nil, ErrStreamEOF
	}
	out := make([]byte, n)
	copy(out, s.data[s.pos:s.pos+n])
	s.pos += n
	return out, nil
}

// ReadUint8 reads a uint8.
func (s *Stream) ReadUint8() (uint8, error) {
	return s.ReadByte()
}

// ReadUint16 reads a little-endian uint16.
func (s *Stream) ReadUint16() (uint16, error) {
	if s.pos+2 > s.end {
		return 0, ErrStreamEOF
	}
	v := binary.LittleEndian.Uint16(s.data[s.pos:])
	s.pos += 2
	return v, nil
}

// ReadUint32 reads a little-endian uint32.
func (s *Stream) ReadUint32() (uint32, error) {
	if s.pos+4 > s.end {
		return 0, ErrStreamEOF
	}
	v := binary.LittleEndian.Uint32(s.data[s.pos:])
	s.pos += 4
	return v, nil
}

// ReadUint64 reads a little-endian uint64.
func (s *Stream) ReadUint64() (uint64, error) {
	if s.pos+8 > s.end {
		return 0, ErrStreamEOF
	}
	v := binary.LittleEndian.Uint64(s.data[s.pos:])
	s.pos += 8
	return v, nil
}

// ReadInt32 reads a little-endian int32.
func (s *Stream) ReadInt32() (int32, error) {
	v, err := s.ReadUint32()
	return int32(v), err
}

// Dart variable-length integer encoding constants.
const (
	dataBitsPerByte        = 7
	byteMask               = (1 << dataBitsPerByte) - 1 // 0x7f
	maxUnsignedDataPerByte = byteMask                   // 127

	// ReadUnsigned end marker: final byte encodes 7 unsigned bits (0-127).
	endUnsignedByteMarker = 255 - maxUnsignedDataPerByte // 128

	// Read<T> (signed) end marker: final byte encodes 7 signed bits (-64..63).
	// Used by Read<uint32_t> for cluster tags.
	minDataPerByte = -(1 << (dataBitsPerByte - 1)) // -64
	maxDataPerByte = (^byte(0x40)) & byteMask      // 63
	endByteMarker  = 255 - maxDataPerByte          // 192
)

// ReadUnsigned reads a Dart-encoded unsigned variable-length integer.
//
// Encoding: each byte carries 7 bits of data in little-endian order.
// If byte > 127: it's the last byte; value contribution = byte - 128.
// If byte <= 127: it's a data byte; 7 bits contribute to the value.
func (s *Stream) ReadUnsigned() (int64, error) {
	b, err := s.ReadByte()
	if err != nil {
		return 0, err
	}
	if b > maxUnsignedDataPerByte {
		return int64(b) - endUnsignedByteMarker, nil
	}

	var r int64
	var shift uint
	for {
		r |= int64(b) << shift
		shift += dataBitsPerByte
		b, err = s.ReadByte()
		if err != nil {
			return 0, err
		}
		if b > maxUnsignedDataPerByte {
			r |= int64(b-endUnsignedByteMarker) << shift
			return r, nil
		}
		if shift >= 63 {
			return 0, ErrStreamOverrun
		}
	}
}

// ReadTagged32 reads a Dart-encoded uint32 using the signed variable-length
// encoding (kEndByteMarker = 192). Used for cluster tags and Read<int32_t>.
//
// Same structure as ReadUnsigned but the terminator byte subtracts 192 instead
// of 128, giving a 7-bit signed range (-64..63) for the final contribution.
func (s *Stream) ReadTagged32() (uint32, error) {
	b, err := s.ReadByte()
	if err != nil {
		return 0, err
	}
	if b > maxUnsignedDataPerByte {
		return uint32(b) - uint32(endByteMarker), nil
	}

	var r uint32
	var shift uint
	for {
		r |= uint32(b) << shift
		shift += dataBitsPerByte
		b, err = s.ReadByte()
		if err != nil {
			return 0, err
		}
		if b > maxUnsignedDataPerByte {
			r |= (uint32(b) - uint32(endByteMarker)) << shift
			return r, nil
		}
		if shift >= 28 {
			return 0, ErrStreamOverrun
		}
	}
}

// ReadTagged64 reads a Dart-encoded int64 using the signed variable-length
// encoding (kEndByteMarker = 192). Used for Read<int64_t> (e.g. Mint values).
func (s *Stream) ReadTagged64() (int64, error) {
	b, err := s.ReadByte()
	if err != nil {
		return 0, err
	}
	if b > maxUnsignedDataPerByte {
		return int64(b) - int64(endByteMarker), nil
	}

	var r int64
	var shift uint
	for {
		r |= int64(b) << shift
		shift += dataBitsPerByte
		b, err = s.ReadByte()
		if err != nil {
			return 0, err
		}
		if b > maxUnsignedDataPerByte {
			r |= (int64(b) - int64(endByteMarker)) << shift
			return r, nil
		}
		if shift >= 63 {
			return 0, ErrStreamOverrun
		}
	}
}

// ReadRefId reads a Dart reference ID using the optimized big-endian encoding.
//
// Uses signed bytes with big-endian accumulation:
//
//	result = byte + (result << 7)
//
// Terminates when byte < 0 (bit 7 set, interpreted as signed).
// Final result = accumulated + 128.
func (s *Stream) ReadRefId() (int64, error) {
	var result int64
	for i := 0; i < 5; i++ { // max 4 stages + safety
		if s.pos >= s.end {
			return 0, ErrStreamEOF
		}
		// Read as signed int8.
		b := int8(s.data[s.pos])
		s.pos++
		result = int64(b) + (result << 7)
		if b < 0 {
			return result + 128, nil
		}
	}
	return 0, ErrStreamOverrun
}

// ReadCString reads a null-terminated string.
func (s *Stream) ReadCString() (string, error) {
	start := s.pos
	for s.pos < s.end {
		if s.data[s.pos] == 0 {
			str := string(s.data[start:s.pos])
			s.pos++ // skip null terminator
			return str, nil
		}
		s.pos++
	}
	return "", fmt.Errorf("stream: unterminated string at offset %d", start)
}

// Align advances position to the next alignment boundary.
func (s *Stream) Align(alignment int) {
	if alignment <= 0 {
		return
	}
	rem := s.pos % alignment
	if rem != 0 {
		s.pos += alignment - rem
	}
	if s.pos > s.end {
		s.pos = s.end
	}
}

// Skip advances the position by n bytes.
func (s *Stream) Skip(n int) error {
	if s.pos+n > s.end {
		return ErrStreamEOF
	}
	s.pos += n
	return nil
}

```

`internal/dartfmt/stream_test.go`:

```go
package dartfmt

import (
	"testing"
)

func TestReadUnsigned_SingleByte(t *testing.T) {
	// Single-byte encoding: byte > 127 means terminal.
	// Value = byte - 128.
	tests := []struct {
		in   byte
		want int64
	}{
		{128, 0},   // 128 - 128 = 0
		{129, 1},   // 129 - 128 = 1
		{255, 127}, // 255 - 128 = 127
	}
	for _, tt := range tests {
		s := NewStream([]byte{tt.in})
		got, err := s.ReadUnsigned()
		if err != nil {
			t.Errorf("ReadUnsigned(%d): %v", tt.in, err)
			continue
		}
		if got != tt.want {
			t.Errorf("ReadUnsigned(%d) = %d, want %d", tt.in, got, tt.want)
		}
	}
}

func TestReadUnsigned_MultiByte(t *testing.T) {
	// Multi-byte: data bytes (<=127) carry 7 bits each, terminal (>127) ends.
	// Example: [5, 128+3] = 5 | (3 << 7) = 5 + 384 = 389
	tests := []struct {
		in   []byte
		want int64
	}{
		{[]byte{0, 128}, 0},       // 0 | (0 << 7) = 0
		{[]byte{1, 128}, 1},       // 1 | (0 << 7) = 1
		{[]byte{5, 131}, 389},     // 5 | (3 << 7) = 5 + 384
		{[]byte{127, 128}, 127},   // 127 | (0 << 7)
		{[]byte{127, 255}, 16383}, // 127 | (127 << 7) = 127 + 16256
		{[]byte{0, 0, 128}, 0},    // three bytes, value 0
		{[]byte{1, 1, 128}, 129},  // 1 | (1 << 7) | (0 << 14) = 1 + 128
	}
	for _, tt := range tests {
		s := NewStream(tt.in)
		got, err := s.ReadUnsigned()
		if err != nil {
			t.Errorf("ReadUnsigned(%v): %v", tt.in, err)
			continue
		}
		if got != tt.want {
			t.Errorf("ReadUnsigned(%v) = %d, want %d", tt.in, got, tt.want)
		}
	}
}

func TestReadUnsigned_EOF(t *testing.T) {
	s := NewStream([]byte{})
	_, err := s.ReadUnsigned()
	if err != ErrStreamEOF {
		t.Errorf("expected EOF, got %v", err)
	}

	// Data byte with no terminator.
	s = NewStream([]byte{5})
	_, err = s.ReadUnsigned()
	if err != ErrStreamEOF {
		t.Errorf("expected EOF for unterminated, got %v", err)
	}
}

func TestReadTagged32_SingleByte(t *testing.T) {
	// Terminal byte > 127: value = byte - 192.
	// Range: 128→(128-192)=wraps, 192→0, 255→63.
	// Actually for uint32: 192→0, 255→63, 128→(128-192) wraps to 0xFFFFFF80...
	// But stored as uint32, so 128-192 = -64 → 0xFFFFFFC0.
	tests := []struct {
		in   byte
		want uint32
	}{
		{192, 0},
		{193, 1},
		{255, 63},
	}
	for _, tt := range tests {
		s := NewStream([]byte{tt.in})
		got, err := s.ReadTagged32()
		if err != nil {
			t.Errorf("ReadTagged32(%d): %v", tt.in, err)
			continue
		}
		if got != tt.want {
			t.Errorf("ReadTagged32(%d) = %d, want %d", tt.in, got, tt.want)
		}
	}
}

func TestReadTagged32_MultiByte(t *testing.T) {
	// Data bytes (<=127) carry 7 bits, terminal (>127) subtracts 192.
	tests := []struct {
		in   []byte
		want uint32
	}{
		{[]byte{0, 192}, 0},   // 0 | (0 << 7)
		{[]byte{1, 192}, 1},   // 1 | (0 << 7)
		{[]byte{5, 195}, 389}, // 5 | (3 << 7) = 5 + 384
	}
	for _, tt := range tests {
		s := NewStream(tt.in)
		got, err := s.ReadTagged32()
		if err != nil {
			t.Errorf("ReadTagged32(%v): %v", tt.in, err)
			continue
		}
		if got != tt.want {
			t.Errorf("ReadTagged32(%v) = %d, want %d", tt.in, got, tt.want)
		}
	}
}

func TestReadTagged64_SingleByte(t *testing.T) {
	tests := []struct {
		in   byte
		want int64
	}{
		{192, 0},
		{193, 1},
		{255, 63},
		// Negative: 128-192 = -64
		{128, -64},
		{191, -1},
	}
	for _, tt := range tests {
		s := NewStream([]byte{tt.in})
		got, err := s.ReadTagged64()
		if err != nil {
			t.Errorf("ReadTagged64(%d): %v", tt.in, err)
			continue
		}
		if got != tt.want {
			t.Errorf("ReadTagged64(%d) = %d, want %d", tt.in, got, tt.want)
		}
	}
}

func TestReadRefId_SingleByte(t *testing.T) {
	// Signed byte < 0 (bit 7 set) terminates immediately.
	// result = int8(byte) + 128
	tests := []struct {
		in   byte
		want int64
	}{
		{0x80, 0},   // int8(0x80) = -128, + 128 = 0
		{0xFF, 127}, // int8(0xFF) = -1, + 128 = 127
	}
	for _, tt := range tests {
		s := NewStream([]byte{tt.in})
		got, err := s.ReadRefId()
		if err != nil {
			t.Errorf("ReadRefId(%d): %v", tt.in, err)
			continue
		}
		if got != tt.want {
			t.Errorf("ReadRefId(0x%02x) = %d, want %d", tt.in, got, tt.want)
		}
	}
}

func TestReadRefId_MultiByte(t *testing.T) {
	// Non-negative bytes accumulate: result = byte + (result << 7).
	// First byte 1, second byte 0x80: result = 1, then (1<<7) + int8(0x80) = 128 + (-128) = 0, + 128 = 128.
	s := NewStream([]byte{1, 0x80})
	got, err := s.ReadRefId()
	if err != nil {
		t.Fatalf("ReadRefId: %v", err)
	}
	if got != 128 {
		t.Errorf("ReadRefId([1, 0x80]) = %d, want 128", got)
	}
}

func TestReadCString(t *testing.T) {
	s := NewStream([]byte("hello\x00world\x00"))
	got, err := s.ReadCString()
	if err != nil {
		t.Fatalf("ReadCString: %v", err)
	}
	if got != "hello" {
		t.Errorf("got %q, want %q", got, "hello")
	}
	got, err = s.ReadCString()
	if err != nil {
		t.Fatalf("ReadCString: %v", err)
	}
	if got != "world" {
		t.Errorf("got %q, want %q", got, "world")
	}
}

func TestStreamPosition(t *testing.T) {
	s := NewStreamAt([]byte{0, 0, 0, 0, 128}, 3)
	if s.Position() != 3 {
		t.Errorf("position = %d, want 3", s.Position())
	}
	if s.Remaining() != 2 {
		t.Errorf("remaining = %d, want 2", s.Remaining())
	}
	v, err := s.ReadUnsigned()
	if err != nil {
		t.Fatal(err)
	}
	if v != 0 {
		t.Errorf("ReadUnsigned = %d, want 0", v)
	}
}

```

`internal/disasm/annotate.go`:

```go
package disasm

import "fmt"

// Annotator returns an optional inline comment for an instruction.
// Empty string means no annotation. Receives the full Inst for access
// to both raw encoding and address.
type Annotator func(inst Inst) string

// ARM64 register numbers for Dart AOT.
const (
	regPP  = 27 // X27 = object pool pointer
	regTHR = 26 // X26 = thread pointer
)

// isLDR64UnsignedOffset returns true if the raw 32-bit ARM64 instruction is
// LDR Xt, [Xn, #imm] (64-bit, unsigned offset). Returns the base register
// number and the byte offset.
//
// Encoding: size=11 | 111 | V=0 | 01 | opc=01 | imm12 | Rn | Rt
// Mask: 0xFFC00000, Value: 0xF9400000
func isLDR64UnsignedOffset(raw uint32) (baseReg int, byteOffset int, ok bool) {
	if raw&0xFFC00000 != 0xF9400000 {
		return 0, 0, false
	}
	rn := int((raw >> 5) & 0x1F)
	imm12 := int((raw >> 10) & 0xFFF)
	return rn, imm12 << 3, true // scaled by 8 for 64-bit
}

// isADD64Immediate returns true if the raw instruction is ADD Xd, Xn, #imm
// (64-bit). Returns dest reg, source reg, and the effective immediate value
// (with shift applied).
//
// Encoding: sf=1 | op=0 | S=0 | 100010 | sh | imm12 | Rn | Rd
// Mask: 0x7F800000, Value: 0x11000000 (with sf=1 → 0x91000000)
func isADD64Immediate(raw uint32) (rd, rn int, immValue int, ok bool) {
	if raw&0xFF000000 != 0x91000000 {
		return 0, 0, 0, false
	}
	rd = int(raw & 0x1F)
	rn = int((raw >> 5) & 0x1F)
	imm12 := int((raw >> 10) & 0xFFF)
	shift := int((raw >> 22) & 0x3)
	if shift == 1 {
		immValue = imm12 << 12
	} else {
		immValue = imm12
	}
	return rd, rn, immValue, true
}

// IsLDR64UnsignedOffsetExported is the exported version of isLDR64UnsignedOffset
// for use outside the disasm package (e.g. extracting string refs in cmd/).
func IsLDR64UnsignedOffsetExported(raw uint32) (baseReg int, byteOffset int, ok bool) {
	return isLDR64UnsignedOffset(raw)
}

// PPAnnotator annotates LDR Xt, [X27, #imm] instructions with pool entry info.
// pool maps pool index → display string.
func PPAnnotator(pool map[int]string) Annotator {
	return func(inst Inst) string {
		baseReg, byteOff, ok := isLDR64UnsignedOffset(inst.Raw)
		if !ok || baseReg != regPP {
			return ""
		}
		idx := byteOff / 8
		if s, found := pool[idx]; found {
			return fmt.Sprintf("PP[%d] %s", idx, s)
		}
		return fmt.Sprintf("PP[%d]", idx)
	}
}

// THRAnnotator annotates LDR Xt, [X26, #imm] instructions with thread offset.
// If fields is non-nil, resolved field names are included.
func THRAnnotator(fields map[int]string) Annotator {
	return func(inst Inst) string {
		baseReg, byteOff, ok := isLDR64UnsignedOffset(inst.Raw)
		if !ok || baseReg != regTHR {
			return ""
		}
		if fields != nil {
			if name, found := fields[byteOff]; found {
				return fmt.Sprintf("THR.%s", name)
			}
		}
		return fmt.Sprintf("THR+0x%x", byteOff)
	}
}

// THRContextAnnotator pre-computes THR annotations for an instruction stream,
// including classification labels for unresolved offsets using instruction context.
// It handles LDR64, LDR32, STR64, and STR32 on X26.
// Replaces the simple THRAnnotator when full context is available.
func THRContextAnnotator(insts []Inst, fields map[int]string) Annotator {
	anns := make(map[uint64]string)

	for i, inst := range insts {
		raw := inst.Raw
		var byteOff int
		var isStore bool
		var width int
		detected := false

		// LDR X64 [X26, #imm]
		if base, off, ok := isLDR64UnsignedOffset(raw); ok && base == regTHR {
			byteOff, width = off, 8
			detected = true
		}
		// LDR W32 [X26, #imm]
		if !detected {
			if base, off, _, ok := isLDR32UnsignedOffset(raw); ok && base == regTHR {
				byteOff, width = off, 4
				detected = true
			}
		}
		// STR X64 [X26, #imm]
		if !detected {
			if base, off, _, ok := isSTR64UnsignedOffset(raw); ok && base == regTHR {
				byteOff, width = off, 8
				isStore = true
				detected = true
			}
		}
		// STR W32 [X26, #imm]
		if !detected {
			if base, off, _, ok := isSTR32UnsignedOffset(raw); ok && base == regTHR {
				byteOff, width = off, 4
				isStore = true
				detected = true
			}
		}

		if !detected {
			continue
		}

		// Resolved?
		if fields != nil {
			if name, found := fields[byteOff]; found {
				anns[inst.Addr] = fmt.Sprintf("THR.%s", name)
				continue
			}
		}

		// Unresolved — classify from context.
		rec := buildContextRecord(insts, i, byteOff, isStore, width)
		cls := classifyFromContext(rec)

		label := thrAnnotationLabel(byteOff, isStore, width, cls)
		anns[inst.Addr] = label
	}

	return func(inst Inst) string {
		if s, ok := anns[inst.Addr]; ok {
			return s
		}
		return ""
	}
}

// buildContextRecord constructs a THRAuditRecord from instruction context
// for classification. Only the fields needed by classifyFromContext are populated.
func buildContextRecord(insts []Inst, idx, byteOff int, isStore bool, width int) THRAuditRecord {
	var ctx []string
	for d := -2; d <= 2; d++ {
		j := idx + d
		if j >= 0 && j < len(insts) {
			prefix := "  "
			if d == 0 {
				prefix = "> "
			}
			ctx = append(ctx, fmt.Sprintf("%s0x%x: %s", prefix, insts[j].Addr, insts[j].Text))
		}
	}

	return THRAuditRecord{
		THROffset: fmt.Sprintf("0x%x", byteOff),
		Insn:      insts[idx].Text,
		IsStore:   isStore,
		Width:     width,
		Context:   ctx,
	}
}

// thrAnnotationLabel builds the disasm annotation string for an unresolved THR access.
func thrAnnotationLabel(byteOff int, isStore bool, width int, cls THRClass) string {
	var classTag string
	switch cls {
	case ClassRuntimeEntrypoint:
		classTag = "RUNTIME_ENTRY"
	case ClassObjectStoreCache:
		classTag = "OBJSTORE"
	case ClassIsolateGroupPtr:
		classTag = "ISO_GROUP"
	default:
		classTag = "UNKNOWN"
	}

	op := "LDR"
	if isStore {
		op = "STR"
	}
	wStr := ""
	if width == 4 {
		wStr = "w32 "
	}

	return fmt.Sprintf("THR+0x%x %s%s[%s]", byteOff, wStr, op, classTag)
}

// PeepholeState tracks state for multi-instruction annotation patterns.
type PeepholeState struct {
	pool      map[int]string
	prevRaw   uint32
	prevValid bool
}

// NewPeepholeState creates a peephole annotator for ADD+LDR PP patterns.
func NewPeepholeState(pool map[int]string) *PeepholeState {
	return &PeepholeState{pool: pool}
}

// Reset clears the peephole state. Call between functions.
func (p *PeepholeState) Reset() {
	p.prevValid = false
}

// Annotate checks for ADD Xd, X27, #upper followed by LDR Xt, [Xd, #lower].
// Call this for each instruction in sequence. Returns annotation for the
// current instruction (may annotate the LDR in a two-instruction sequence).
func (p *PeepholeState) Annotate(inst Inst) string {
	defer func() {
		p.prevRaw = inst.Raw
		p.prevValid = true
	}()

	if !p.prevValid {
		return ""
	}

	// Check if previous was ADD Xd, X27, #upper
	addRd, addRn, addImm, addOK := isADD64Immediate(p.prevRaw)
	if !addOK || addRn != regPP {
		return ""
	}

	// Check if current is LDR Xt, [Xd, #lower] where Xd matches ADD dest
	baseReg, ldrOff, ldrOK := isLDR64UnsignedOffset(inst.Raw)
	if !ldrOK || baseReg != addRd {
		return ""
	}

	combined := addImm + ldrOff
	idx := combined / 8
	if s, found := p.pool[idx]; found {
		return fmt.Sprintf("PP[%d] %s", idx, s)
	}
	return fmt.Sprintf("PP[%d]", idx)
}

```

`internal/disasm/annotate_test.go`:

```go
package disasm

import (
	"encoding/binary"
	"testing"
)

func TestIsLDR64UnsignedOffset(t *testing.T) {
	tests := []struct {
		name       string
		raw        uint32
		wantBase   int
		wantOffset int
		wantOK     bool
	}{
		// LDR X0, [X27, #0x120] → base=27, offset=0x120, idx=36
		// Encoding: 0xF9400000 | (imm12 << 10) | (Rn << 5) | Rt
		// imm12 = 0x120/8 = 0x24, Rn=27, Rt=0
		{"PP_load_0x120", 0xF9400000 | (0x24 << 10) | (27 << 5) | 0, 27, 0x120, true},

		// LDR X16, [X26, #72] → base=26, offset=72
		// imm12 = 72/8 = 9, Rn=26, Rt=16
		{"THR_load_72", 0xF9400000 | (9 << 10) | (26 << 5) | 16, 26, 72, true},

		// LDR X0, [X29, #64] → base=29 (frame pointer, not PP/THR)
		{"FP_load", 0xF9400000 | (8 << 10) | (29 << 5) | 0, 29, 64, true},

		// Not an LDR (STR instruction)
		{"not_LDR", 0xF9000000, 0, 0, false},

		// ADD instruction
		{"ADD_not_LDR", 0x91000000, 0, 0, false},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			base, off, ok := isLDR64UnsignedOffset(tt.raw)
			if ok != tt.wantOK {
				t.Fatalf("ok = %v, want %v", ok, tt.wantOK)
			}
			if !ok {
				return
			}
			if base != tt.wantBase {
				t.Errorf("base = %d, want %d", base, tt.wantBase)
			}
			if off != tt.wantOffset {
				t.Errorf("offset = %d, want %d", off, tt.wantOffset)
			}
		})
	}
}

func TestIsADD64Immediate(t *testing.T) {
	tests := []struct {
		name    string
		raw     uint32
		wantRd  int
		wantRn  int
		wantImm int
		wantOK  bool
	}{
		// ADD X0, X27, #0x1000 (shift=1, imm12=1)
		// Encoding: 0x91000000 | (1<<22) | (1<<10) | (27<<5) | 0
		{"ADD_PP_shift12", 0x91000000 | (1 << 22) | (1 << 10) | (27 << 5) | 0, 0, 27, 0x1000, true},

		// ADD X5, X27, #0x10 (shift=0, imm12=0x10)
		{"ADD_PP_noshift", 0x91000000 | (0x10 << 10) | (27 << 5) | 5, 5, 27, 0x10, true},

		// SUB instruction (not ADD)
		{"SUB_not_ADD", 0xD1000000, 0, 0, 0, false},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			rd, rn, imm, ok := isADD64Immediate(tt.raw)
			if ok != tt.wantOK {
				t.Fatalf("ok = %v, want %v", ok, tt.wantOK)
			}
			if !ok {
				return
			}
			if rd != tt.wantRd {
				t.Errorf("rd = %d, want %d", rd, tt.wantRd)
			}
			if rn != tt.wantRn {
				t.Errorf("rn = %d, want %d", rn, tt.wantRn)
			}
			if imm != tt.wantImm {
				t.Errorf("imm = 0x%x, want 0x%x", imm, tt.wantImm)
			}
		})
	}
}

func TestPPAnnotator(t *testing.T) {
	pool := map[int]string{
		36: `"hello world"`,
	}
	ann := PPAnnotator(pool)

	// LDR X0, [X27, #0x120] → PP[36] "hello world"
	raw := uint32(0xF9400000 | (0x24 << 10) | (27 << 5) | 0)
	got := ann(Inst{Raw: raw})
	want := `PP[36] "hello world"`
	if got != want {
		t.Errorf("PPAnnotator = %q, want %q", got, want)
	}

	// LDR X0, [X27, #0x128] → PP[37] (unknown index)
	raw2 := uint32(0xF9400000 | (0x25 << 10) | (27 << 5) | 0)
	got2 := ann(Inst{Raw: raw2})
	if got2 != "PP[37]" {
		t.Errorf("PPAnnotator unknown = %q, want %q", got2, "PP[37]")
	}

	// LDR from non-PP register → empty
	rawFP := uint32(0xF9400000 | (8 << 10) | (29 << 5) | 0)
	if got := ann(Inst{Raw: rawFP}); got != "" {
		t.Errorf("PPAnnotator non-PP = %q, want empty", got)
	}
}

func TestTHRAnnotator(t *testing.T) {
	ann := THRAnnotator(nil)

	// LDR X16, [X26, #72] → THR+0x48
	raw := uint32(0xF9400000 | (9 << 10) | (26 << 5) | 16)
	got := ann(Inst{Raw: raw})
	if got != "THR+0x48" {
		t.Errorf("THRAnnotator = %q, want %q", got, "THR+0x48")
	}

	// With field map.
	fields := map[int]string{0x48: "stack_limit"}
	annFields := THRAnnotator(fields)
	got = annFields(Inst{Raw: raw})
	if got != "THR.stack_limit" {
		t.Errorf("THRAnnotator with fields = %q, want %q", got, "THR.stack_limit")
	}
}

func TestPeepholeState(t *testing.T) {
	pool := map[int]string{
		0x800: `"large pool string"`,
	}
	ps := NewPeepholeState(pool)

	// ADD X0, X27, #0x4000 (shift=1, imm12=4)
	addRaw := uint32(0x91000000 | (1 << 22) | (4 << 10) | (27 << 5) | 0)
	got := ps.Annotate(Inst{Raw: addRaw})
	if got != "" {
		t.Errorf("ADD alone should not annotate, got %q", got)
	}

	// LDR X1, [X0, #0] → combined offset = 0x4000, idx = 0x800
	ldrRaw := uint32(0xF9400000 | (0 << 10) | (0 << 5) | 1)
	got = ps.Annotate(Inst{Raw: ldrRaw})
	want := `PP[2048] "large pool string"`
	if got != want {
		t.Errorf("peephole = %q, want %q", got, want)
	}
}

// TestPPAnnotator_RealBytes tests on actual ARM64 machine code bytes
// (little-endian encoding as it would appear in a binary).
func TestPPAnnotator_RealBytes(t *testing.T) {
	pool := map[int]string{9: "stack_limit"}

	// LDR X16, [X26, #72] = 0xF9402750 in LE: 50 27 40 f9
	var buf [4]byte
	buf[0], buf[1], buf[2], buf[3] = 0x50, 0x27, 0x40, 0xf9
	raw := binary.LittleEndian.Uint32(buf[:])

	thr := THRAnnotator(nil)
	got := thr(Inst{Raw: raw})
	if got != "THR+0x48" {
		t.Errorf("THR from real bytes = %q, want %q", got, "THR+0x48")
	}

	pp := PPAnnotator(pool)
	got = pp(Inst{Raw: raw})
	if got != "" {
		t.Errorf("PP from THR load should be empty, got %q", got)
	}
}

```

`internal/disasm/branch.go`:

```go
package disasm

// ARM64 branch instruction detection from raw 32-bit encoding.
// These functions identify basic-block terminators and extract branch targets.

// BranchInfo describes a decoded branch instruction.
type BranchInfo struct {
	Target uint64 // absolute target address (0 if RET)
	Cond   bool   // true if conditional (has fallthrough)
	IsRet  bool   // true if RET
}

// DecodeBranch attempts to decode a branch instruction from raw encoding at the given PC.
// Returns nil if the instruction is not a branch/ret.
func DecodeBranch(raw uint32, pc uint64) *BranchInfo {
	// RET (0xD65F03C0 exactly, or RET Xn = 0xD65F0000 | Rn<<5)
	if raw&0xFFFFFC1F == 0xD65F0000 {
		return &BranchInfo{IsRet: true}
	}

	// B (unconditional): 000101 imm26
	if raw&0xFC000000 == 0x14000000 {
		imm26 := raw & 0x03FFFFFF
		offset := signExtend(imm26, 26) * 4
		return &BranchInfo{Target: uint64(int64(pc) + int64(offset))}
	}

	// B.cond: 01010100 imm19 0 cond
	if raw&0xFF000010 == 0x54000000 {
		imm19 := (raw >> 5) & 0x7FFFF
		offset := signExtend(imm19, 19) * 4
		return &BranchInfo{Target: uint64(int64(pc) + int64(offset)), Cond: true}
	}

	// CBZ: 0 sf 110100 imm19 Rt
	if raw&0x7F000000 == 0x34000000 {
		imm19 := (raw >> 5) & 0x7FFFF
		offset := signExtend(imm19, 19) * 4
		return &BranchInfo{Target: uint64(int64(pc) + int64(offset)), Cond: true}
	}

	// CBNZ: 0 sf 110101 imm19 Rt
	if raw&0x7F000000 == 0x35000000 {
		imm19 := (raw >> 5) & 0x7FFFF
		offset := signExtend(imm19, 19) * 4
		return &BranchInfo{Target: uint64(int64(pc) + int64(offset)), Cond: true}
	}

	// TBZ: 0 b5 110110 b40 imm14 Rt
	if raw&0x7F000000 == 0x36000000 {
		imm14 := (raw >> 5) & 0x3FFF
		offset := signExtend(imm14, 14) * 4
		return &BranchInfo{Target: uint64(int64(pc) + int64(offset)), Cond: true}
	}

	// TBNZ: 0 b5 110111 b40 imm14 Rt
	if raw&0x7F000000 == 0x37000000 {
		imm14 := (raw >> 5) & 0x3FFF
		offset := signExtend(imm14, 14) * 4
		return &BranchInfo{Target: uint64(int64(pc) + int64(offset)), Cond: true}
	}

	return nil
}

// signExtend sign-extends a value from the given bit width to int32.
func signExtend(val uint32, bits int) int32 {
	sign := uint32(1) << (bits - 1)
	mask := sign - 1
	if val&sign != 0 {
		return int32(val | ^mask) // negative
	}
	return int32(val & mask)
}

// IsBranchTerminator returns true if the instruction terminates a basic block.
// This includes all branches (B, B.cond, CBZ, CBNZ, TBZ, TBNZ, RET) but NOT BL/BLR
// (calls return to the next instruction).
func IsBranchTerminator(raw uint32) bool {
	return DecodeBranch(raw, 0) != nil
}

```

`internal/disasm/branch_test.go`:

```go
package disasm

import "testing"

func TestDecodeBranch_RET(t *testing.T) {
	// RET (X30) = 0xD65F03C0
	bi := DecodeBranch(0xD65F03C0, 0x1000)
	if bi == nil {
		t.Fatal("expected RET")
	}
	if !bi.IsRet {
		t.Error("expected IsRet=true")
	}
}

func TestDecodeBranch_B(t *testing.T) {
	// B #0x100 at PC=0x1000 → target=0x1100
	// imm26 = 0x100/4 = 0x40
	raw := uint32(0x14000000 | 0x40)
	bi := DecodeBranch(raw, 0x1000)
	if bi == nil {
		t.Fatal("expected B")
	}
	if bi.Target != 0x1100 {
		t.Errorf("target = 0x%x, want 0x1100", bi.Target)
	}
	if bi.Cond {
		t.Error("B should not be conditional")
	}
}

func TestDecodeBranch_B_Negative(t *testing.T) {
	// B #-0x10 at PC=0x1000 → target=0xFF0
	// imm26 = -4 (offset = -0x10 / 4 = -4), encoded as 0x03FFFFFC
	raw := uint32(0x14000000 | (0x03FFFFFF - 3)) // -4 in 26-bit two's complement
	bi := DecodeBranch(raw, 0x1000)
	if bi == nil {
		t.Fatal("expected B")
	}
	if bi.Target != 0x0FF0 {
		t.Errorf("target = 0x%x, want 0xFF0", bi.Target)
	}
}

func TestDecodeBranch_Bcond(t *testing.T) {
	// B.EQ #0x20 at PC=0x2000 → target=0x2020
	// imm19 = 0x20/4 = 8, cond = 0 (EQ)
	raw := uint32(0x54000000 | (8 << 5) | 0) // B.EQ
	bi := DecodeBranch(raw, 0x2000)
	if bi == nil {
		t.Fatal("expected B.cond")
	}
	if bi.Target != 0x2020 {
		t.Errorf("target = 0x%x, want 0x2020", bi.Target)
	}
	if !bi.Cond {
		t.Error("B.cond should be conditional")
	}
}

func TestDecodeBranch_CBZ(t *testing.T) {
	// CBZ X0, #0x40 at PC=0x3000 → target=0x3040
	// imm19 = 0x40/4 = 0x10, sf=1 (64-bit), Rt=0
	raw := uint32(0xB4000000 | (0x10 << 5) | 0) // CBZ X0
	bi := DecodeBranch(raw, 0x3000)
	if bi == nil {
		t.Fatal("expected CBZ")
	}
	if bi.Target != 0x3040 {
		t.Errorf("target = 0x%x, want 0x3040", bi.Target)
	}
	if !bi.Cond {
		t.Error("CBZ should be conditional")
	}
}

func TestDecodeBranch_TBZ(t *testing.T) {
	// TBZ W0, #0, #0x10 at PC=0x4000 → target=0x4010
	// imm14 = 0x10/4 = 4
	raw := uint32(0x36000000 | (4 << 5) | 0) // TBZ
	bi := DecodeBranch(raw, 0x4000)
	if bi == nil {
		t.Fatal("expected TBZ")
	}
	if bi.Target != 0x4010 {
		t.Errorf("target = 0x%x, want 0x4010", bi.Target)
	}
	if !bi.Cond {
		t.Error("TBZ should be conditional")
	}
}

func TestDecodeBranch_NotBranch(t *testing.T) {
	// ADD X0, X1, X2 = 0x8B020020
	bi := DecodeBranch(0x8B020020, 0x1000)
	if bi != nil {
		t.Error("ADD should not be a branch")
	}

	// BL is NOT a basic-block terminator (it's a call)
	bl := uint32(0x94000000 | 0x100)
	bi = DecodeBranch(bl, 0x1000)
	if bi != nil {
		t.Error("BL should not be detected as branch terminator")
	}
}

func TestSignExtend(t *testing.T) {
	tests := []struct {
		val  uint32
		bits int
		want int32
	}{
		{0x04, 19, 4},       // positive
		{0x7FFFF, 19, -1},   // -1 in 19-bit
		{0x3FFF, 14, -1},    // -1 in 14-bit
		{0x2000, 14, -8192}, // MSB set in 14-bit
	}
	for _, tc := range tests {
		got := signExtend(tc.val, tc.bits)
		if got != tc.want {
			t.Errorf("signExtend(0x%x, %d) = %d, want %d", tc.val, tc.bits, got, tc.want)
		}
	}
}

```

`internal/disasm/calledge.go`:

```go
package disasm

import "fmt"

const regDT = 21 // X21 = dispatch table register

// CallEdge represents a call site extracted from disassembly.
type CallEdge struct {
	FromPC     uint64 `json:"from_pc"`
	Kind       string `json:"kind"`                // "bl" or "blr"
	TargetPC   uint64 `json:"target_pc,omitempty"` // resolved VA for bl
	TargetName string `json:"target_name,omitempty"`
	Reg        string `json:"reg,omitempty"` // register for blr (e.g. "X16")
	Via        string `json:"via,omitempty"` // provenance: "THR.AllocateArray_ep", "PP[36] foo", ""
}

// RegDef records the last definition of a register within the W=8 window.
type RegDef struct {
	Annotation string // e.g. "THR.AllocateArray_ep" or "PP[36] foo"
	Age        int    // instructions since definition
}

// RegTracker tracks last-def provenance for GP registers X0-X30.
// Window size W=8: definitions older than W instructions are expired.
type RegTracker struct {
	defs [31]RegDef // X0..X30
	w    int
}

// NewRegTracker creates a tracker with the given window size.
func NewRegTracker(w int) *RegTracker {
	return &RegTracker{w: w}
}

// Reset clears all tracked definitions. Call between functions.
func (rt *RegTracker) Reset() {
	for i := range rt.defs {
		rt.defs[i] = RegDef{}
	}
}

// Tick ages all definitions by 1 and expires those beyond the window.
func (rt *RegTracker) Tick() {
	for i := range rt.defs {
		if rt.defs[i].Annotation != "" {
			rt.defs[i].Age++
			if rt.defs[i].Age > rt.w {
				rt.defs[i] = RegDef{}
			}
		}
	}
}

// Define records that register rd was defined with the given annotation.
func (rt *RegTracker) Define(rd int, annotation string) {
	if rd < 0 || rd > 30 {
		return
	}
	rt.defs[rd] = RegDef{Annotation: annotation, Age: 0}
}

// Lookup returns the annotation for register rd, or "" if expired/unknown.
func (rt *RegTracker) Lookup(rd int) string {
	if rd < 0 || rd > 30 {
		return ""
	}
	return rt.defs[rd].Annotation
}

// Kill clears the definition for a register (e.g. when overwritten by a
// non-annotated instruction).
func (rt *RegTracker) Kill(rd int) {
	if rd < 0 || rd > 30 {
		return
	}
	rt.defs[rd] = RegDef{}
}

// isBL detects ARM64 BL (branch with link) instructions.
// Encoding: 1 | 00101 | imm26
// Mask: 0xFC000000, Value: 0x94000000
// Returns the target address (sign-extended imm26 * 4 + PC).
func isBL(raw uint32, pc uint64) (target uint64, ok bool) {
	if raw&0xFC000000 != 0x94000000 {
		return 0, false
	}
	imm26 := int32(raw & 0x03FFFFFF)
	// Sign extend from 26 bits.
	if imm26&(1<<25) != 0 {
		imm26 |= ^int32(0x03FFFFFF)
	}
	target = uint64(int64(pc) + int64(imm26)*4)
	return target, true
}

// isBLR detects ARM64 BLR (branch with link to register) instructions.
// Encoding: 1101011 | 0 | 0 | 01 | 11111 | 0000 | 0 | 0 | Rn | 00000
// Mask: 0xFFFFFC1F, Value: 0xD63F0000
// Returns the register number.
func isBLR(raw uint32) (rn int, ok bool) {
	if raw&0xFFFFFC1F != 0xD63F0000 {
		return 0, false
	}
	rn = int((raw >> 5) & 0x1F)
	return rn, true
}

// dstRegOfInst returns the destination register of a data-processing or load
// instruction, or -1 if not detected. Used by the register tracker to know
// which register an annotated instruction defines.
func dstRegOfInst(raw uint32) int {
	// LDR X64 unsigned offset
	if raw&0xFFC00000 == 0xF9400000 {
		return int(raw & 0x1F)
	}
	// LDR W32 unsigned offset
	if raw&0xFFC00000 == 0xB9400000 {
		return int(raw & 0x1F)
	}
	// LDUR X64 (unscaled offset): size=11|111|V=0|00|opc=01|imm9|00|Rn|Rt
	// Mask: 0xFFE00C00, Value: 0xF8400000
	if raw&0xFFE00C00 == 0xF8400000 {
		return int(raw & 0x1F)
	}
	// LDUR W32 (unscaled offset): size=10|111|V=0|00|opc=01|imm9|00|Rn|Rt
	if raw&0xFFE00C00 == 0xB8400000 {
		return int(raw & 0x1F)
	}
	// LDR X64 register offset: size=11|111|V=0|01|opc=01|1|Rm|option|S|10|Rn|Rt
	// Mask: 0xFFE00C00, Value: 0xF8600800
	if raw&0xFFE00C00 == 0xF8600800 {
		return int(raw & 0x1F)
	}
	// ADD X64 immediate
	if raw&0xFF000000 == 0x91000000 {
		return int(raw & 0x1F)
	}
	// SUB X64 immediate
	if raw&0xFF000000 == 0xD1000000 {
		return int(raw & 0x1F)
	}
	// MOV (alias of ORR Rd, XZR, Rm) - wide: MOVZ/MOVK/MOVN
	if raw&0xFF800000 == 0xD2800000 || // MOVZ X
		raw&0xFF800000 == 0xF2800000 || // MOVK X
		raw&0xFF800000 == 0x92800000 { // MOVN X
		return int(raw & 0x1F)
	}
	// UBFX/UBFM (bit field extract): sf=1|opc=10|100110|N=1|...
	if raw&0xFF800000 == 0xD3000000 {
		return int(raw & 0x1F)
	}
	return -1
}

// isLDRRegExtended detects LDR Xt, [Xn, Xm, LSL #3] (64-bit register offset).
// Returns base, index register, and destination register.
func isLDRRegExtended(raw uint32) (base, rm, rt int, ok bool) {
	// Encoding: 11|111|V=0|01|opc=01|1|Rm|option|S|10|Rn|Rt
	// We match: 0xFFE00C00 == 0xF8600800
	if raw&0xFFE00C00 != 0xF8600800 {
		return 0, 0, 0, false
	}
	rt = int(raw & 0x1F)
	base = int((raw >> 5) & 0x1F)
	rm = int((raw >> 16) & 0x1F)
	return base, rm, rt, true
}

// isLDUR64 detects LDUR Xt, [Xn, #imm9] (64-bit unscaled immediate).
func isLDUR64(raw uint32) (base, rt int, ok bool) {
	if raw&0xFFE00C00 != 0xF8400000 {
		return 0, 0, false
	}
	rt = int(raw & 0x1F)
	base = int((raw >> 5) & 0x1F)
	return base, rt, true
}

// ExtractCallEdges scans instructions for BL and BLR call sites.
// Uses register tracking with window W to resolve BLR targets.
// annotators are run per-instruction to populate the register tracker.
// symbols resolves BL target addresses to names.
func ExtractCallEdges(insts []Inst, symbols SymbolLookup, annotators []Annotator, w int) []CallEdge {
	rt := NewRegTracker(w)
	var edges []CallEdge

	for _, inst := range insts {
		// Check for BL first.
		if target, ok := isBL(inst.Raw, inst.Addr); ok {
			e := CallEdge{
				FromPC:   inst.Addr,
				Kind:     "bl",
				TargetPC: target,
			}
			if symbols != nil {
				if name, found := symbols(target); found {
					e.TargetName = name
				}
			}
			edges = append(edges, e)
			rt.Tick()
			continue
		}

		// Check for BLR.
		if rn, ok := isBLR(inst.Raw); ok {
			via := rt.Lookup(rn)
			e := CallEdge{
				FromPC: inst.Addr,
				Kind:   "blr",
				Reg:    fmt.Sprintf("X%d", rn),
				Via:    via,
			}
			edges = append(edges, e)
			rt.Tick()
			continue
		}

		// Check for dispatch table load: LDR Xn, [X21, Xm, LSL #3].
		if base, _, dstR, ok := isLDRRegExtended(inst.Raw); ok && base == regDT {
			rt.Tick()
			rt.Define(dstR, "dispatch_table")
			continue
		}

		// Check for object field load via LDUR: LDUR Xn, [Xm, #imm].
		// These are compressed pointer dereferences (vtable/closure calls).
		if _, dstR, ok := isLDUR64(inst.Raw); ok {
			rt.Tick()
			rt.Define(dstR, "object_field")
			continue
		}

		// Run annotators to check if this instruction defines a register
		// with a known provenance (PP load, THR load).
		var annotation string
		for _, ann := range annotators {
			if s := ann(inst); s != "" {
				annotation = s
				break
			}
		}

		if annotation != "" {
			rd := dstRegOfInst(inst.Raw)
			if rd >= 0 {
				rt.Tick()
				rt.Define(rd, annotation)
				continue
			}
		}

		// Non-annotated instruction: kill the destination register if it's
		// a load or data-processing instruction.
		rd := dstRegOfInst(inst.Raw)
		if rd >= 0 {
			rt.Kill(rd)
		}
		rt.Tick()
	}

	return edges
}

```

`internal/disasm/calledge_test.go`:

```go
package disasm

import (
	"testing"
)

func TestIsBL(t *testing.T) {
	// BL #0x1234 at PC=0x1000:
	// imm26 = 0x1234/4 = 0x48D, encoding: 0x94000000 | 0x48D = 0x9400048D
	raw := uint32(0x9400048D)
	target, ok := isBL(raw, 0x1000)
	if !ok {
		t.Fatal("isBL failed to detect BL")
	}
	want := uint64(0x1000 + 0x48D*4)
	if target != want {
		t.Errorf("isBL target = 0x%x, want 0x%x", target, want)
	}

	// Negative offset: BL #-8 at PC=0x2000.
	// imm26 = -2 (signed), encoded as 0x03FFFFFE
	raw = 0x94000000 | 0x03FFFFFE
	target, ok = isBL(raw, 0x2000)
	if !ok {
		t.Fatal("isBL failed for negative offset")
	}
	want = uint64(0x2000 - 8)
	if target != want {
		t.Errorf("isBL negative = 0x%x, want 0x%x", target, want)
	}

	// Non-BL instruction should not match.
	_, ok = isBL(0xD503201F, 0) // NOP
	if ok {
		t.Error("isBL matched NOP")
	}
}

func TestIsBLR(t *testing.T) {
	// BLR X16: 1101 0110 0011 1111 0000 00 10000 00000 = 0xD63F0200
	raw := uint32(0xD63F0200)
	rn, ok := isBLR(raw)
	if !ok {
		t.Fatal("isBLR failed")
	}
	if rn != 16 {
		t.Errorf("isBLR rn = %d, want 16", rn)
	}

	// BLR X30: 0xD63F03C0
	rn, ok = isBLR(0xD63F03C0)
	if !ok {
		t.Fatal("isBLR X30 failed")
	}
	if rn != 30 {
		t.Errorf("isBLR rn = %d, want 30", rn)
	}

	// Non-BLR.
	_, ok = isBLR(0xD503201F)
	if ok {
		t.Error("isBLR matched NOP")
	}
}

func TestRegTracker(t *testing.T) {
	rt := NewRegTracker(3) // W=3

	rt.Define(5, "THR.foo_ep")
	if got := rt.Lookup(5); got != "THR.foo_ep" {
		t.Errorf("after define: got %q", got)
	}

	// Age 1, 2, 3: still valid.
	rt.Tick()
	rt.Tick()
	rt.Tick()
	if got := rt.Lookup(5); got != "THR.foo_ep" {
		t.Errorf("at age 3: got %q", got)
	}

	// Age 4: expired.
	rt.Tick()
	if got := rt.Lookup(5); got != "" {
		t.Errorf("at age 4: got %q, want empty", got)
	}
}

func TestRegTrackerKill(t *testing.T) {
	rt := NewRegTracker(8)
	rt.Define(10, "PP[5] hello")
	rt.Kill(10)
	if got := rt.Lookup(10); got != "" {
		t.Errorf("after kill: got %q", got)
	}
}

func TestExtractCallEdges_BL(t *testing.T) {
	// Build instructions: NOP, BL +8, NOP
	insts := []Inst{
		{Addr: 0x1000, Raw: 0xD503201F, Text: "NOP"},
		{Addr: 0x1004, Raw: 0x94000002, Text: "BL .+8"}, // target = 0x1004 + 2*4 = 0x100C
		{Addr: 0x1008, Raw: 0xD503201F, Text: "NOP"},
	}

	symbols := PlaceholderLookup(map[uint64]string{
		0x100C: "target_func",
	})

	edges := ExtractCallEdges(insts, symbols, nil, 8)
	if len(edges) != 1 {
		t.Fatalf("got %d edges, want 1", len(edges))
	}
	e := edges[0]
	if e.Kind != "bl" {
		t.Errorf("kind = %q", e.Kind)
	}
	if e.TargetPC != 0x100C {
		t.Errorf("target = 0x%x, want 0x100C", e.TargetPC)
	}
	if e.TargetName != "target_func" {
		t.Errorf("name = %q", e.TargetName)
	}
}

func TestExtractCallEdges_BLR_WithProvenance(t *testing.T) {
	// Simulate: LDR X16, [X26,#0x2e8] (THR.AllocateArray_ep), then BLR X16.
	thrLDR := uint32(0xF9417350) // LDR X16, [X26,#0x2e8]
	blrX16 := uint32(0xD63F0200) // BLR X16

	insts := []Inst{
		{Addr: 0x1000, Raw: thrLDR, Text: "LDR X16, [X26,#744]"},
		{Addr: 0x1004, Raw: blrX16, Text: "BLR X16"},
	}

	thrFields := THRFields("3.10.7")
	thrAnn := THRContextAnnotator(insts, thrFields)

	edges := ExtractCallEdges(insts, nil, []Annotator{thrAnn}, 8)
	if len(edges) != 1 {
		t.Fatalf("got %d edges, want 1", len(edges))
	}
	e := edges[0]
	if e.Kind != "blr" {
		t.Errorf("kind = %q", e.Kind)
	}
	if e.Reg != "X16" {
		t.Errorf("reg = %q", e.Reg)
	}
	if e.Via == "" {
		t.Error("via is empty, expected THR annotation")
	}
	t.Logf("via = %q", e.Via)
}

```

`internal/disasm/cfg.go`:

```go
package disasm

import "sort"

// BasicBlock represents a sequence of instructions with a single entry point.
type BasicBlock struct {
	ID      int
	Start   int    // index into FuncCFG.Insts (inclusive)
	End     int    // index into FuncCFG.Insts (exclusive)
	Succs   []Succ // successor edges
	IsEntry bool
	IsTerm  bool // ends with RET or unconditional branch out of function
}

// Succ describes a control-flow successor edge.
type Succ struct {
	BlockID int
	Cond    string // "" = unconditional, "T" = taken/true, "F" = fallthrough/false
}

// FuncCFG is a per-function control flow graph.
type FuncCFG struct {
	Name   string
	Blocks []BasicBlock
	Insts  []Inst
}

// BuildCFG constructs a control flow graph from a function's instruction stream.
// The algorithm:
//  1. Find block leaders: index 0, branch targets, instructions after terminators.
//  2. Partition instructions into blocks by leaders.
//  3. Compute successor edges from each block's last instruction.
func BuildCFG(name string, insts []Inst) FuncCFG {
	if len(insts) == 0 {
		return FuncCFG{Name: name, Insts: insts}
	}

	funcStart := insts[0].Addr
	funcEnd := insts[len(insts)-1].Addr + 4

	// Map address → instruction index for branch target resolution.
	addrToIdx := make(map[uint64]int, len(insts))
	for i, inst := range insts {
		addrToIdx[inst.Addr] = i
	}

	// Pass 1: Identify block leaders.
	leaders := make(map[int]bool)
	leaders[0] = true // entry point is always a leader

	for i, inst := range insts {
		bi := DecodeBranch(inst.Raw, inst.Addr)
		if bi == nil {
			continue
		}
		// Instruction after a terminator is a leader (if it exists).
		if i+1 < len(insts) {
			leaders[i+1] = true
		}
		// Branch target within this function is a leader.
		if !bi.IsRet && bi.Target >= funcStart && bi.Target < funcEnd {
			if idx, ok := addrToIdx[bi.Target]; ok {
				leaders[idx] = true
			}
		}
	}

	// Sort leaders for partitioning.
	sorted := make([]int, 0, len(leaders))
	for idx := range leaders {
		sorted = append(sorted, idx)
	}
	sort.Ints(sorted)

	// Pass 2: Partition into blocks.
	blocks := make([]BasicBlock, len(sorted))
	leaderToBlock := make(map[int]int, len(sorted))
	for i, start := range sorted {
		end := len(insts) // last block extends to end
		if i+1 < len(sorted) {
			end = sorted[i+1]
		}
		blocks[i] = BasicBlock{
			ID:      i,
			Start:   start,
			End:     end,
			IsEntry: start == 0,
		}
		leaderToBlock[start] = i
	}

	// Pass 3: Compute successors.
	for i := range blocks {
		blk := &blocks[i]
		if blk.End <= blk.Start {
			continue
		}
		lastInst := insts[blk.End-1]
		bi := DecodeBranch(lastInst.Raw, lastInst.Addr)

		if bi == nil {
			// Not a branch — fallthrough to next block.
			if nextBlk, ok := leaderToBlock[blk.End]; ok {
				blk.Succs = append(blk.Succs, Succ{BlockID: nextBlk})
			}
			continue
		}

		if bi.IsRet {
			blk.IsTerm = true
			continue
		}

		// Resolve branch target to a block.
		targetBlockID := -1
		if bi.Target >= funcStart && bi.Target < funcEnd {
			if idx, ok := addrToIdx[bi.Target]; ok {
				if bid, ok := leaderToBlock[idx]; ok {
					targetBlockID = bid
				}
			}
		}

		if bi.Cond {
			// Conditional: taken (T) goes to target, fallthrough (F) goes to next.
			if targetBlockID >= 0 {
				blk.Succs = append(blk.Succs, Succ{BlockID: targetBlockID, Cond: "T"})
			}
			if nextBlk, ok := leaderToBlock[blk.End]; ok {
				blk.Succs = append(blk.Succs, Succ{BlockID: nextBlk, Cond: "F"})
			}
		} else {
			// Unconditional branch.
			if targetBlockID >= 0 {
				blk.Succs = append(blk.Succs, Succ{BlockID: targetBlockID})
			} else {
				// Branch outside function — terminal.
				blk.IsTerm = true
			}
		}
	}

	return FuncCFG{
		Name:   name,
		Blocks: blocks,
		Insts:  insts,
	}
}

```

`internal/disasm/cfg_test.go`:

```go
package disasm

import "testing"

// makeInst creates a synthetic Inst at the given address with raw encoding.
func makeInst(addr uint64, raw uint32) Inst {
	return Inst{Addr: addr, Raw: raw, Size: 4}
}

func TestBuildCFG_Linear(t *testing.T) {
	// Three NOPs — no branches → one block.
	insts := []Inst{
		makeInst(0x1000, 0xD503201F), // NOP
		makeInst(0x1004, 0xD503201F), // NOP
		makeInst(0x1008, 0xD65F03C0), // RET
	}
	cfg := BuildCFG("linear", insts)
	if len(cfg.Blocks) != 1 {
		t.Fatalf("blocks = %d, want 1", len(cfg.Blocks))
	}
	blk := cfg.Blocks[0]
	if blk.Start != 0 || blk.End != 3 {
		t.Errorf("block range = [%d,%d), want [0,3)", blk.Start, blk.End)
	}
	if !blk.IsTerm {
		t.Error("block should be terminal (RET)")
	}
	if len(blk.Succs) != 0 {
		t.Errorf("succs = %d, want 0", len(blk.Succs))
	}
}

func TestBuildCFG_ConditionalBranch(t *testing.T) {
	// B.EQ to +0x10 (forward to addr 0x1010), then fallthrough.
	//   0x1000: B.EQ #0x10  → target 0x1010
	//   0x1004: NOP          (fallthrough)
	//   0x1008: RET
	//   0x100C: NOP
	//   0x1010: RET          (branch target)
	beq := uint32(0x54000000 | (4 << 5)) // imm19 = 4 → offset = 0x10
	insts := []Inst{
		makeInst(0x1000, beq),        // B.EQ → 0x1010
		makeInst(0x1004, 0xD503201F), // NOP
		makeInst(0x1008, 0xD65F03C0), // RET
		makeInst(0x100C, 0xD503201F), // NOP
		makeInst(0x1010, 0xD65F03C0), // RET (branch target)
	}
	cfg := BuildCFG("cond", insts)

	// Leaders: 0 (entry), 1 (after B.EQ), 3 (after RET at idx 2), 4 (target 0x1010)
	// Block 0: insts[0:1] = B.EQ
	// Block 1: insts[1:3] = NOP, RET
	// Block 2: insts[3:4] = NOP (dead code after RET)
	// Block 3: insts[4:5] = RET (branch target)

	if len(cfg.Blocks) != 4 {
		t.Fatalf("blocks = %d, want 4", len(cfg.Blocks))
	}

	// Block 0 should have T and F successors.
	b0 := cfg.Blocks[0]
	if len(b0.Succs) != 2 {
		t.Fatalf("block 0 succs = %d, want 2", len(b0.Succs))
	}
	// T should point to block 3 (target 0x1010), F to block 1 (fallthrough).
	var hasT, hasF bool
	for _, s := range b0.Succs {
		if s.Cond == "T" && s.BlockID == 3 {
			hasT = true
		}
		if s.Cond == "F" && s.BlockID == 1 {
			hasF = true
		}
	}
	if !hasT {
		t.Errorf("block 0 missing T→block3, succs=%+v", b0.Succs)
	}
	if !hasF {
		t.Errorf("block 0 missing F→block1, succs=%+v", b0.Succs)
	}

	// Block 1 should be terminal (contains RET).
	b1 := cfg.Blocks[1]
	if !b1.IsTerm {
		t.Error("block 1 should be terminal (RET)")
	}

	// Block 3 should be terminal.
	b3 := cfg.Blocks[3]
	if !b3.IsTerm {
		t.Error("block 3 should be terminal (RET)")
	}
}

func TestBuildCFG_UnconditionalBranch(t *testing.T) {
	// B to +0x8 (skip one instruction).
	//   0x2000: B #0x8     → target 0x2008
	//   0x2004: NOP         (dead code)
	//   0x2008: RET         (branch target)
	b := uint32(0x14000000 | 2) // imm26=2 → offset=8
	insts := []Inst{
		makeInst(0x2000, b),          // B → 0x2008
		makeInst(0x2004, 0xD503201F), // NOP
		makeInst(0x2008, 0xD65F03C0), // RET
	}
	cfg := BuildCFG("uncond", insts)

	// Leaders: 0 (entry), 1 (after B), 2 (target of B)
	if len(cfg.Blocks) != 3 {
		t.Fatalf("blocks = %d, want 3", len(cfg.Blocks))
	}

	// Block 0 has one unconditional successor → block 2.
	b0 := cfg.Blocks[0]
	if len(b0.Succs) != 1 {
		t.Fatalf("block 0 succs = %d, want 1", len(b0.Succs))
	}
	if b0.Succs[0].BlockID != 2 || b0.Succs[0].Cond != "" {
		t.Errorf("block 0 succ = {%d, %q}, want {2, \"\"}", b0.Succs[0].BlockID, b0.Succs[0].Cond)
	}
}

func TestBuildCFG_Empty(t *testing.T) {
	cfg := BuildCFG("empty", nil)
	if len(cfg.Blocks) != 0 {
		t.Errorf("blocks = %d, want 0", len(cfg.Blocks))
	}
}

```

`internal/disasm/disasm.go`:

```go
// Package disasm provides ARM64 disassembly for Dart AOT code regions.
package disasm

import (
	"encoding/binary"
	"fmt"
	"strings"

	"golang.org/x/arch/arm64/arm64asm"
)

// Inst is a decoded ARM64 instruction with address and raw bytes.
type Inst struct {
	Addr     uint64
	Raw      uint32
	Size     int // always 4 for ARM64
	Mnemonic string
	Operands string
	Text     string // full disassembly line
}

// SymbolLookup resolves an address to a symbolic name. Returns ("", false) if unknown.
type SymbolLookup func(addr uint64) (name string, ok bool)

// Options controls disassembly behavior.
type Options struct {
	BaseAddr uint64       // VA of the first byte in Data
	MaxSteps int          // maximum instructions to decode; 0 = 10M
	Symbols  SymbolLookup // optional symbol resolver
}

const defaultMaxSteps = 10_000_000

func (o Options) effectiveMax() int {
	if o.MaxSteps > 0 {
		return o.MaxSteps
	}
	return defaultMaxSteps
}

// Disassemble decodes ARM64 instructions from a byte region.
// Returns decoded instructions up to MaxSteps or end of data.
func Disassemble(data []byte, opts Options) []Inst {
	maxSteps := opts.effectiveMax()
	n := len(data) / 4
	if n > maxSteps {
		n = maxSteps
	}

	result := make([]Inst, 0, n)
	for i := 0; i < n; i++ {
		off := i * 4
		if off+4 > len(data) {
			break
		}
		raw := binary.LittleEndian.Uint32(data[off : off+4])
		addr := opts.BaseAddr + uint64(off)

		inst, err := arm64asm.Decode(data[off : off+4])
		var mnemonic, operands, text string
		if err != nil {
			mnemonic = ".word"
			operands = fmt.Sprintf("0x%08x", raw)
			text = fmt.Sprintf(".word 0x%08x", raw)
		} else {
			text = inst.String()
			// Split into mnemonic and operands.
			parts := strings.SplitN(text, " ", 2)
			mnemonic = parts[0]
			if len(parts) > 1 {
				operands = parts[1]
			}
		}

		result = append(result, Inst{
			Addr:     addr,
			Raw:      raw,
			Size:     4,
			Mnemonic: mnemonic,
			Operands: operands,
			Text:     text,
		})
	}
	return result
}

// Format renders a slice of instructions as stable text output.
// Each line: <addr>  <hex bytes>  <disasm>  ; <comments>
// Annotators are checked in order; first non-empty result is used.
func Format(insts []Inst, lookup SymbolLookup, annotators ...Annotator) string {
	var b strings.Builder
	for _, inst := range insts {
		// Address.
		fmt.Fprintf(&b, "0x%08x  ", inst.Addr)
		// Raw bytes (little-endian hex).
		fmt.Fprintf(&b, "%02x %02x %02x %02x  ",
			byte(inst.Raw), byte(inst.Raw>>8), byte(inst.Raw>>16), byte(inst.Raw>>24))
		// Disassembly.
		b.WriteString(inst.Text)
		// Symbol comment.
		commented := false
		if lookup != nil {
			if name, ok := lookup(inst.Addr); ok {
				fmt.Fprintf(&b, "  ; <%s>", name)
				commented = true
			}
		}
		// Instruction annotators (PP loads, THR loads, etc).
		if !commented {
			for _, ann := range annotators {
				if s := ann(inst); s != "" {
					fmt.Fprintf(&b, "  ; %s", s)
					break
				}
			}
		}
		b.WriteByte('\n')
	}
	return b.String()
}

// DisasmOne decodes a single ARM64 instruction from its raw encoding.
// Returns the disassembly text, or "" if decoding fails.
func DisasmOne(raw uint32, addr uint64) string {
	buf := make([]byte, 4)
	binary.LittleEndian.PutUint32(buf, raw)
	inst, err := arm64asm.Decode(buf)
	if err != nil {
		return ""
	}
	return inst.String()
}

// PlaceholderLookup returns a SymbolLookup that generates sub_<hexaddr> names
// for a set of known function entry points.
func PlaceholderLookup(entryPoints map[uint64]string) SymbolLookup {
	return func(addr uint64) (string, bool) {
		if name, ok := entryPoints[addr]; ok {
			return name, true
		}
		return "", false
	}
}

```

`internal/disasm/disasm_test.go`:

```go
package disasm

import (
	"encoding/binary"
	"strings"
	"testing"
)

func TestDisassembleNOP(t *testing.T) {
	// ARM64 NOP = 0xd503201f
	data := make([]byte, 8)
	binary.LittleEndian.PutUint32(data[0:4], 0xd503201f)
	binary.LittleEndian.PutUint32(data[4:8], 0xd503201f)

	insts := Disassemble(data, Options{BaseAddr: 0x1000})
	if len(insts) != 2 {
		t.Fatalf("got %d instructions, want 2", len(insts))
	}
	if insts[0].Addr != 0x1000 {
		t.Errorf("addr[0] = 0x%x, want 0x1000", insts[0].Addr)
	}
	if insts[1].Addr != 0x1004 {
		t.Errorf("addr[1] = 0x%x, want 0x1004", insts[1].Addr)
	}
	if !strings.Contains(strings.ToLower(insts[0].Text), "nop") {
		t.Errorf("expected NOP, got: %s", insts[0].Text)
	}
}

func TestDisassembleMaxSteps(t *testing.T) {
	// 100 NOPs but max 10.
	data := make([]byte, 400)
	for i := 0; i < 100; i++ {
		binary.LittleEndian.PutUint32(data[i*4:], 0xd503201f)
	}

	insts := Disassemble(data, Options{MaxSteps: 10})
	if len(insts) != 10 {
		t.Fatalf("got %d instructions, want 10", len(insts))
	}
}

func TestDisassembleEmpty(t *testing.T) {
	insts := Disassemble(nil, Options{})
	if len(insts) != 0 {
		t.Fatalf("got %d instructions for nil data", len(insts))
	}
}

func TestDisassembleShort(t *testing.T) {
	// Less than 4 bytes.
	insts := Disassemble([]byte{0x01, 0x02}, Options{})
	if len(insts) != 0 {
		t.Fatalf("got %d instructions for 2 bytes", len(insts))
	}
}

func TestFormat(t *testing.T) {
	data := make([]byte, 4)
	binary.LittleEndian.PutUint32(data, 0xd503201f)
	insts := Disassemble(data, Options{BaseAddr: 0x1000})

	syms := map[uint64]string{0x1000: "nop_func"}
	text := Format(insts, PlaceholderLookup(syms))
	if !strings.Contains(text, "0x00001000") {
		t.Errorf("missing address in output: %s", text)
	}
	if !strings.Contains(text, "<nop_func>") {
		t.Errorf("missing symbol in output: %s", text)
	}
}

func TestFormatDeterministic(t *testing.T) {
	data := make([]byte, 20)
	for i := 0; i < 5; i++ {
		binary.LittleEndian.PutUint32(data[i*4:], 0xd503201f)
	}
	insts := Disassemble(data, Options{BaseAddr: 0x2000})
	out1 := Format(insts, nil)
	out2 := Format(insts, nil)
	if out1 != out2 {
		t.Error("non-deterministic output")
	}
}

```

`internal/disasm/pipeline.go`:

```go
package disasm

// FuncRecord is one line in functions.jsonl.
type FuncRecord struct {
	PC         string `json:"pc"`
	Size       int    `json:"size"`
	Name       string `json:"name"`
	Owner      string `json:"owner,omitempty"`
	ParamCount int    `json:"param_count,omitempty"`
}

// CallEdgeRecord is one line in call_edges.jsonl.
type CallEdgeRecord struct {
	FromFunc string `json:"from_func"`
	FromPC   string `json:"from_pc"`
	Kind     string `json:"kind"`             // "bl" or "blr"
	Target   string `json:"target,omitempty"` // resolved name or "0x..." for bl
	Reg      string `json:"reg,omitempty"`    // "X16" etc for blr
	Via      string `json:"via,omitempty"`    // provenance for blr
}

// UnresolvedTHRRecord is one line in unresolved_thr.jsonl.
type UnresolvedTHRRecord struct {
	FuncName  string `json:"func_name"`
	PC        string `json:"pc"`
	THROffset string `json:"thr_offset"`
	Width     int    `json:"width"`
	IsStore   bool   `json:"is_store,omitempty"`
	Class     string `json:"class"` // RUNTIME_ENTRY, OBJSTORE, ISO_GROUP, UNKNOWN
}

// StringRefRecord is one line in string_refs.jsonl.
type StringRefRecord struct {
	Func    string `json:"func"`
	PC      string `json:"pc"`
	Kind    string `json:"kind"` // "PP" or "PP_peep"
	PoolIdx int    `json:"pool_idx"`
	Value   string `json:"value"` // raw string value (unquoted)
}

```

`internal/disasm/thraudit.go`:

```go
package disasm

import "fmt"

// THRAccess describes a single THR-relative memory access in the instruction stream.
type THRAccess struct {
	PC        uint64 `json:"pc"`
	InsnText  string `json:"insn"`
	THROffset int    `json:"thr_offset"`
	IsStore   bool   `json:"is_store"`
	DstReg    int    `json:"dst_reg,omitempty"` // for loads
	SrcReg    int    `json:"src_reg,omitempty"` // for stores
	Width     int    `json:"width"`             // 4 or 8
	Resolved  bool   `json:"resolved"`          // whether THRFields has a name for this offset
}

// isLDR32UnsignedOffset detects LDR Wt, [Xn, #imm] (32-bit unsigned offset).
// Encoding: size=10 | 111 | V=0 | 01 | opc=01 | imm12 | Rn | Rt
// Mask: 0xFFC00000, Value: 0xB9400000
func isLDR32UnsignedOffset(raw uint32) (baseReg int, byteOffset int, dstReg int, ok bool) {
	if raw&0xFFC00000 != 0xB9400000 {
		return 0, 0, 0, false
	}
	rn := int((raw >> 5) & 0x1F)
	rt := int(raw & 0x1F)
	imm12 := int((raw >> 10) & 0xFFF)
	return rn, imm12 << 2, rt, true // scaled by 4 for 32-bit
}

// isSTR64UnsignedOffset detects STR Xt, [Xn, #imm] (64-bit unsigned offset).
// Encoding: size=11 | 111 | V=0 | 01 | opc=00 | imm12 | Rn | Rt
// Mask: 0xFFC00000, Value: 0xF9000000
func isSTR64UnsignedOffset(raw uint32) (baseReg int, byteOffset int, srcReg int, ok bool) {
	if raw&0xFFC00000 != 0xF9000000 {
		return 0, 0, 0, false
	}
	rn := int((raw >> 5) & 0x1F)
	rt := int(raw & 0x1F)
	imm12 := int((raw >> 10) & 0xFFF)
	return rn, imm12 << 3, rt, true
}

// isSTR32UnsignedOffset detects STR Wt, [Xn, #imm] (32-bit unsigned offset).
// Encoding: size=10 | 111 | V=0 | 01 | opc=00 | imm12 | Rn | Rt
// Mask: 0xFFC00000, Value: 0xB9000000
func isSTR32UnsignedOffset(raw uint32) (baseReg int, byteOffset int, srcReg int, ok bool) {
	if raw&0xFFC00000 != 0xB9000000 {
		return 0, 0, 0, false
	}
	rn := int((raw >> 5) & 0x1F)
	rt := int(raw & 0x1F)
	imm12 := int((raw >> 10) & 0xFFF)
	return rn, imm12 << 2, rt, true
}

// ExtractTHRAccesses scans decoded instructions for THR-relative memory operations.
// Returns all THR accesses found. fields is optional (for marking resolved).
func ExtractTHRAccesses(insts []Inst, fields map[int]string) []THRAccess {
	var result []THRAccess
	for _, inst := range insts {
		raw := inst.Raw

		// LDR X64 [X26, #imm]
		if base, off, ok := isLDR64UnsignedOffset(raw); ok && base == regTHR {
			dst := int(raw & 0x1F)
			_, resolved := fields[off]
			result = append(result, THRAccess{
				PC:        inst.Addr,
				InsnText:  inst.Text,
				THROffset: off,
				DstReg:    dst,
				Width:     8,
				Resolved:  resolved,
			})
			continue
		}

		// LDR W32 [X26, #imm]
		if base, off, dst, ok := isLDR32UnsignedOffset(raw); ok && base == regTHR {
			_, resolved := fields[off]
			result = append(result, THRAccess{
				PC:        inst.Addr,
				InsnText:  inst.Text,
				THROffset: off,
				DstReg:    dst,
				Width:     4,
				Resolved:  resolved,
			})
			continue
		}

		// STR X64 [X26, #imm]
		if base, off, src, ok := isSTR64UnsignedOffset(raw); ok && base == regTHR {
			_, resolved := fields[off]
			result = append(result, THRAccess{
				PC:        inst.Addr,
				InsnText:  inst.Text,
				THROffset: off,
				IsStore:   true,
				SrcReg:    src,
				Width:     8,
				Resolved:  resolved,
			})
			continue
		}

		// STR W32 [X26, #imm]
		if base, off, src, ok := isSTR32UnsignedOffset(raw); ok && base == regTHR {
			_, resolved := fields[off]
			result = append(result, THRAccess{
				PC:        inst.Addr,
				InsnText:  inst.Text,
				THROffset: off,
				IsStore:   true,
				SrcReg:    src,
				Width:     4,
				Resolved:  resolved,
			})
			continue
		}
	}
	return result
}

// THRAuditRecord is a JSONL output record for thr-audit.
type THRAuditRecord struct {
	Sample      string   `json:"sample"`
	DartVersion string   `json:"dart_version"`
	PC          string   `json:"pc"`
	Insn        string   `json:"insn"`
	THROffset   string   `json:"thr_offset"`
	IsStore     bool     `json:"is_store"`
	DstReg      int      `json:"dst_reg,omitempty"`
	SrcReg      int      `json:"src_reg,omitempty"`
	Width       int      `json:"width"`
	FuncName    string   `json:"func_name"`
	Resolved    bool     `json:"resolved"`
	Context     []string `json:"context"`
}

// BuildAuditRecords converts THRAccess entries into audit records with context.
func BuildAuditRecords(accesses []THRAccess, allInsts []Inst, sample, dartVersion, funcName string) []THRAuditRecord {
	// Build PC→index map for context lookup.
	pcIdx := make(map[uint64]int, len(allInsts))
	for i, inst := range allInsts {
		pcIdx[inst.Addr] = i
	}

	records := make([]THRAuditRecord, 0, len(accesses))
	for _, a := range accesses {
		// Build context: prev 2, current, next 2
		var ctx []string
		if idx, ok := pcIdx[a.PC]; ok {
			for d := -2; d <= 2; d++ {
				j := idx + d
				if j >= 0 && j < len(allInsts) {
					prefix := "  "
					if d == 0 {
						prefix = "> "
					}
					ctx = append(ctx, fmt.Sprintf("%s0x%x: %s", prefix, allInsts[j].Addr, allInsts[j].Text))
				}
			}
		}

		rec := THRAuditRecord{
			Sample:      sample,
			DartVersion: dartVersion,
			PC:          fmt.Sprintf("0x%x", a.PC),
			Insn:        a.InsnText,
			THROffset:   fmt.Sprintf("0x%x", a.THROffset),
			IsStore:     a.IsStore,
			Width:       a.Width,
			FuncName:    funcName,
			Resolved:    a.Resolved,
			Context:     ctx,
		}
		if a.IsStore {
			rec.SrcReg = a.SrcReg
		} else {
			rec.DstReg = a.DstReg
		}
		records = append(records, rec)
	}
	return records
}

```

`internal/disasm/thrclassify.go`:

```go
package disasm

import (
	"encoding/json"
	"fmt"
	"io"
	"sort"
	"strings"
)

// Band represents a contiguous group of unresolved THR offsets.
type Band struct {
	ID      int          `json:"id"`
	MinOff  int          `json:"min_offset"`
	MaxOff  int          `json:"max_offset"`
	Count   int          `json:"count"`
	Offsets []BandOffset `json:"offsets"`
}

// BandOffset is a single offset within a band, with frequency.
type BandOffset struct {
	Offset int `json:"offset"`
	Freq   int `json:"freq"`
}

// BandResult holds clustering output for one sample.
type BandResult struct {
	Sample          string `json:"sample"`
	DartVersion     string `json:"dart_version"`
	TotalUnresolved int    `json:"total_unresolved"`
	Bands           []Band `json:"bands"`
}

// ClusterBands groups unresolved THR audit records into bands.
// Split threshold: gap > maxGap between consecutive unique offsets.
func ClusterBands(records []THRAuditRecord, maxGap int) BandResult {
	// Filter unresolved only.
	var unresolved []THRAuditRecord
	sample := ""
	dartVersion := ""
	for _, r := range records {
		if r.Resolved {
			continue
		}
		unresolved = append(unresolved, r)
		if sample == "" {
			sample = r.Sample
			dartVersion = r.DartVersion
		}
	}

	if len(unresolved) == 0 {
		return BandResult{Sample: sample, DartVersion: dartVersion}
	}

	// Count frequency per offset.
	freqMap := make(map[int]int)
	for _, r := range unresolved {
		off := parseTHROffset(r.THROffset)
		freqMap[off]++
	}

	// Sort unique offsets.
	offsets := make([]int, 0, len(freqMap))
	for off := range freqMap {
		offsets = append(offsets, off)
	}
	sort.Ints(offsets)

	// Split into bands by gap.
	var bands []Band
	bandID := 0
	bandStart := 0

	for i := 1; i <= len(offsets); i++ {
		split := i == len(offsets)
		if !split {
			gap := offsets[i] - offsets[i-1]
			if gap > maxGap {
				split = true
			}
		}
		if split {
			bandOffsets := make([]BandOffset, 0, i-bandStart)
			totalCount := 0
			for j := bandStart; j < i; j++ {
				f := freqMap[offsets[j]]
				bandOffsets = append(bandOffsets, BandOffset{Offset: offsets[j], Freq: f})
				totalCount += f
			}
			bands = append(bands, Band{
				ID:      bandID,
				MinOff:  offsets[bandStart],
				MaxOff:  offsets[i-1],
				Count:   totalCount,
				Offsets: bandOffsets,
			})
			bandID++
			bandStart = i
		}
	}

	return BandResult{
		Sample:          sample,
		DartVersion:     dartVersion,
		TotalUnresolved: len(unresolved),
		Bands:           bands,
	}
}

// WriteBandsJSON writes the band result as JSON.
func WriteBandsJSON(w io.Writer, br BandResult) error {
	enc := json.NewEncoder(w)
	enc.SetIndent("", "  ")
	enc.SetEscapeHTML(false)
	return enc.Encode(br)
}

// WriteBandsMD writes the band result as a markdown table.
func WriteBandsMD(w io.Writer, br BandResult) {
	fmt.Fprintf(w, "# THR Unresolved Bands: %s (Dart %s)\n\n", br.Sample, br.DartVersion)
	fmt.Fprintf(w, "Total unresolved: %d\n\n", br.TotalUnresolved)

	fmt.Fprintln(w, "| Band | Range | Slots | Count | Top Offsets |")
	fmt.Fprintln(w, "|------|-------|-------|-------|-------------|")

	for _, b := range br.Bands {
		slots := (b.MaxOff-b.MinOff)/8 + 1
		topOffsets := topN(b.Offsets, 10)
		fmt.Fprintf(w, "| %d | 0x%03x–0x%03x | %d | %d | %s |\n",
			b.ID, b.MinOff, b.MaxOff, slots, b.Count, topOffsets)
	}
	fmt.Fprintln(w)
}

// topN returns a formatted string of the top N offsets by frequency.
func topN(offsets []BandOffset, n int) string {
	sorted := make([]BandOffset, len(offsets))
	copy(sorted, offsets)
	sort.Slice(sorted, func(i, j int) bool {
		return sorted[i].Freq > sorted[j].Freq
	})
	if len(sorted) > n {
		sorted = sorted[:n]
	}
	var parts []string
	for _, bo := range sorted {
		parts = append(parts, fmt.Sprintf("0x%x(%d)", bo.Offset, bo.Freq))
	}
	return strings.Join(parts, " ")
}

// parseTHROffset parses "0x2f0" to int.
func parseTHROffset(s string) int {
	var v int
	fmt.Sscanf(s, "0x%x", &v)
	return v
}

// THRClass is a heuristic classification for an unresolved THR access.
type THRClass string

const (
	ClassRuntimeEntrypoint THRClass = "RUNTIME_ENTRYPOINT_ARRAY"
	ClassObjectStoreCache  THRClass = "OBJECTSTORE_OR_CACHE"
	ClassIsolateGroupPtr   THRClass = "ISOLATE_OR_GROUP_PTR"
	ClassUnknown           THRClass = "UNKNOWN"
)

// ClassifiedRecord is a classified THR audit record.
type ClassifiedRecord struct {
	THRAuditRecord
	BandID int      `json:"band_id"`
	Class  THRClass `json:"class"`
}

// ClassifySummary holds per-class counts for one sample.
type ClassifySummary struct {
	Sample      string           `json:"sample"`
	DartVersion string           `json:"dart_version"`
	Total       int              `json:"total"`
	Counts      map[THRClass]int `json:"counts"`
}

// ClassifyRecords classifies unresolved THR audit records using heuristics
// on the surrounding instruction context.
func ClassifyRecords(records []THRAuditRecord, bands BandResult) []ClassifiedRecord {
	// Build offset→bandID map.
	offsetBand := make(map[int]int)
	for _, b := range bands.Bands {
		for _, bo := range b.Offsets {
			offsetBand[bo.Offset] = b.ID
		}
	}

	var result []ClassifiedRecord
	for _, r := range records {
		if r.Resolved {
			continue
		}
		off := parseTHROffset(r.THROffset)
		bandID := offsetBand[off]

		cls := classifyFromContext(r)

		result = append(result, ClassifiedRecord{
			THRAuditRecord: r,
			BandID:         bandID,
			Class:          cls,
		})
	}
	return result
}

// classifyFromContext applies heuristic rules to the instruction context.
func classifyFromContext(r THRAuditRecord) THRClass {
	// Rule 0: STR to THR → RUNTIME_ENTRYPOINT_ARRAY (vm_tag update pattern).
	// Pattern: LDR X16, [X26, #entry] → STR X16, [X26, #vm_tag] → BLR X16
	if r.IsStore {
		return ClassRuntimeEntrypoint
	}

	// Find the current instruction index in context.
	curIdx := -1
	for i, line := range r.Context {
		if strings.HasPrefix(line, "> ") {
			curIdx = i
			break
		}
	}
	if curIdx < 0 {
		return ClassUnknown
	}

	// Get next 1-2 context lines.
	var next1, next2 string
	if curIdx+1 < len(r.Context) {
		next1 = strings.TrimPrefix(r.Context[curIdx+1], "  ")
	}
	if curIdx+2 < len(r.Context) {
		next2 = strings.TrimPrefix(r.Context[curIdx+2], "  ")
	}

	// Extract the destination register from the current LDR instruction.
	dstReg := extractDstReg(r.Insn)

	// Rule 1: LDR Xn → BLR Xn (direct call through entry point).
	if dstReg != "" && containsBLR(next1, dstReg) {
		return ClassRuntimeEntrypoint
	}

	// Rule 2: LDR Xn → STR Xn, [X26, ...] → BLR Xn
	// (save entry point to vm_tag, then call).
	if dstReg != "" && isSTRtoTHR(next1, dstReg) && containsBLR(next2, dstReg) {
		return ClassRuntimeEntrypoint
	}

	// Rule 3: LDR X5 → MOV X4 → LDR X30, [X26, ...]
	// (runtime entry argument passing pattern: load target, set argc, load call stub).
	if dstReg == "X5" && strings.Contains(next1, "MOV X4,") {
		if strings.Contains(next2, "LDR X30, [X26,") {
			return ClassRuntimeEntrypoint
		}
	}

	// Rule 4: LDR X30 → STP ..., [X15] → BL
	// (load return address from THR, push to Dart stack, call).
	if dstReg == "X30" && strings.Contains(next1, "STP") && strings.Contains(next1, "[X15") {
		if strings.Contains(next2, "BL ") {
			return ClassIsolateGroupPtr
		}
	}

	// Rule 5: LDR X9 → BLR X10 (stack overflow check pattern).
	// Context: LDR X10, [X26, #resolved] + LDR X9, [X26, #unresolved] → BLR X10
	if dstReg == "X9" && containsBLR(next1, "X10") {
		return ClassRuntimeEntrypoint
	}

	// Rule 6: LDR Xn → STUR/STR to object (not X26 base).
	// Value stored into an object field → OBJECTSTORE_OR_CACHE.
	if dstReg != "" && isStoreToObject(next1, dstReg) {
		return ClassObjectStoreCache
	}

	// Rule 7: LDR Xn → CMP Wn/Xn (type CID check or sentinel comparison).
	// The loaded value is a cached constant used for type checks.
	if dstReg != "" && isCMPwithReg(next1, dstReg) {
		return ClassObjectStoreCache
	}

	// Rule 8: LDR X0 → LDR X0, [X0, #imm] (pointer chase through THR).
	// Loads a struct pointer from THR, then dereferences a field.
	if dstReg != "" && isDerefSameReg(next1, dstReg) {
		return ClassIsolateGroupPtr
	}

	// Rule 9: LDR Xn → B (unconditional branch).
	// Load cached constant from THR in a conditional path, then branch past alternative.
	if strings.Contains(next1, "B .+") && !strings.Contains(next1, "BL ") && !strings.Contains(next1, "BLR ") {
		return ClassObjectStoreCache
	}

	return ClassUnknown
}

// extractDstReg extracts the destination register from an LDR instruction text.
// E.g., "LDR X16, [X26,#1824]" → "X16"
func extractDstReg(insn string) string {
	insn = strings.TrimSpace(insn)
	if !strings.HasPrefix(insn, "LDR ") {
		return ""
	}
	parts := strings.SplitN(insn[4:], ",", 2)
	if len(parts) == 0 {
		return ""
	}
	return strings.TrimSpace(parts[0])
}

// containsBLR checks if an instruction line contains BLR with the given register.
func containsBLR(line, reg string) bool {
	return strings.Contains(line, "BLR "+reg)
}

// isSTRtoTHR checks if an instruction stores the given register to THR.
func isSTRtoTHR(line, reg string) bool {
	return strings.Contains(line, "STR "+reg+", [X26,")
}

// isStoreToObject checks if an instruction stores the register to a non-THR address.
func isStoreToObject(line, reg string) bool {
	// Match STUR Wn/Xn or STR Wn/Xn where the register number matches.
	regNum := strings.TrimPrefix(reg, "X")
	wReg := "W" + regNum
	if strings.Contains(line, "STUR "+wReg+",") || strings.Contains(line, "STUR "+reg+",") {
		if !strings.Contains(line, "[X26,") {
			return true
		}
	}
	if strings.Contains(line, "STR "+wReg+",") || strings.Contains(line, "STR "+reg+",") {
		if !strings.Contains(line, "[X26,") {
			return true
		}
	}
	return false
}

// isCMPwithReg checks if the instruction is a CMP using the given register
// (or its W-form equivalent).
func isCMPwithReg(line, reg string) bool {
	regNum := strings.TrimPrefix(reg, "X")
	wReg := "W" + regNum
	return strings.Contains(line, "CMP "+wReg+",") ||
		strings.Contains(line, "CMP "+reg+",") ||
		strings.Contains(line, ", "+wReg) && strings.Contains(line, "CMP")
}

// isDerefSameReg checks if the instruction loads from the same register
// (e.g., LDR X0, [X0, #imm]).
func isDerefSameReg(line, reg string) bool {
	return strings.Contains(line, "LDR "+reg+", ["+reg+",")
}

// Summarize builds a ClassifySummary from classified records.
func Summarize(records []ClassifiedRecord) ClassifySummary {
	if len(records) == 0 {
		return ClassifySummary{}
	}
	counts := make(map[THRClass]int)
	for _, r := range records {
		counts[r.Class]++
	}
	return ClassifySummary{
		Sample:      records[0].Sample,
		DartVersion: records[0].DartVersion,
		Total:       len(records),
		Counts:      counts,
	}
}

// ReadAuditRecords reads THRAuditRecord JSONL from a reader.
func ReadAuditRecords(r io.Reader) ([]THRAuditRecord, error) {
	dec := json.NewDecoder(r)
	var records []THRAuditRecord
	for dec.More() {
		var rec THRAuditRecord
		if err := dec.Decode(&rec); err != nil {
			return records, fmt.Errorf("decode: %w", err)
		}
		records = append(records, rec)
	}
	return records, nil
}

```

`internal/disasm/thrclassify_test.go`:

```go
package disasm

import (
	"os"
	"path/filepath"
	"testing"
)

// fixtureDir returns the path to thr_audit fixture JSONL files.
// These are generated by `go run ./cmd/unflutter thr-audit` on the three samples.
func fixtureDir() string {
	// Walk up from test dir to find scratch/thr_audit/
	dir, _ := os.Getwd()
	for {
		candidate := filepath.Join(dir, "scratch", "thr_audit")
		if fi, err := os.Stat(candidate); err == nil && fi.IsDir() {
			return candidate
		}
		parent := filepath.Dir(dir)
		if parent == dir {
			return ""
		}
		dir = parent
	}
}

type fixtureSpec struct {
	name    string
	jsonl   string
	version string

	// Expected classification counts.
	wantTotal              int
	wantRuntimeEntrypoint  int
	wantObjectStoreCache   int
	wantIsolateGroupPtr    int
	wantUnknown            int
	wantBandsMax           int // band count must not exceed this
	want100PctRuntimeEntry bool
}

var fixtures = []fixtureSpec{
	{
		name:                   "evil",
		jsonl:                  "evil_thr_loads.jsonl",
		version:                "3.10.7",
		wantTotal:              110,
		wantRuntimeEntrypoint:  91,
		wantObjectStoreCache:   14,
		wantIsolateGroupPtr:    5,
		wantUnknown:            0,
		wantBandsMax:           11, // currently 9, allow +2
		want100PctRuntimeEntry: false,
	},
	{
		name:                   "newandromo",
		jsonl:                  "newandromo_thr_loads.jsonl",
		version:                "3.1.0",
		wantTotal:              194,
		wantRuntimeEntrypoint:  143,
		wantObjectStoreCache:   6,
		wantIsolateGroupPtr:    45,
		wantUnknown:            0,
		wantBandsMax:           14, // currently 12, allow +2
		want100PctRuntimeEntry: false,
	},
	{
		name:                   "blutter",
		jsonl:                  "blutter_thr_loads.jsonl",
		version:                "2.17.6",
		wantTotal:              148,
		wantRuntimeEntrypoint:  148,
		wantObjectStoreCache:   0,
		wantIsolateGroupPtr:    0,
		wantUnknown:            0,
		wantBandsMax:           10, // currently 8, allow +2
		want100PctRuntimeEntry: true,
	},
}

func TestClassifyRegression(t *testing.T) {
	dir := fixtureDir()
	if dir == "" {
		t.Skip("scratch/thr_audit/ not found — run thr-audit first")
	}

	for _, fx := range fixtures {
		t.Run(fx.name, func(t *testing.T) {
			path := filepath.Join(dir, fx.jsonl)
			f, err := os.Open(path)
			if err != nil {
				t.Skipf("fixture not found: %v", err)
			}
			defer f.Close()

			records, err := ReadAuditRecords(f)
			if err != nil {
				t.Fatalf("read records: %v", err)
			}

			bands := ClusterBands(records, 0x18)
			classified := ClassifyRecords(records, bands)
			summary := Summarize(classified)

			// Gate: UNKNOWN must be 0.
			if got := summary.Counts[ClassUnknown]; got != fx.wantUnknown {
				t.Errorf("UNKNOWN = %d, want %d", got, fx.wantUnknown)
			}

			// Gate: total unresolved must match.
			if summary.Total != fx.wantTotal {
				t.Errorf("total = %d, want %d", summary.Total, fx.wantTotal)
			}

			// Gate: class counts must match exactly.
			if got := summary.Counts[ClassRuntimeEntrypoint]; got != fx.wantRuntimeEntrypoint {
				t.Errorf("RUNTIME_ENTRYPOINT = %d, want %d", got, fx.wantRuntimeEntrypoint)
			}
			if got := summary.Counts[ClassObjectStoreCache]; got != fx.wantObjectStoreCache {
				t.Errorf("OBJECTSTORE_OR_CACHE = %d, want %d", got, fx.wantObjectStoreCache)
			}
			if got := summary.Counts[ClassIsolateGroupPtr]; got != fx.wantIsolateGroupPtr {
				t.Errorf("ISOLATE_OR_GROUP_PTR = %d, want %d", got, fx.wantIsolateGroupPtr)
			}

			// Gate: blutter must be 100% RUNTIME_ENTRYPOINT.
			if fx.want100PctRuntimeEntry {
				if summary.Counts[ClassRuntimeEntrypoint] != summary.Total {
					t.Errorf("expected 100%% RUNTIME_ENTRYPOINT, got %d/%d",
						summary.Counts[ClassRuntimeEntrypoint], summary.Total)
				}
			}

			// Gate: band count must not increase beyond threshold.
			if len(bands.Bands) > fx.wantBandsMax {
				t.Errorf("band count = %d, exceeds max %d", len(bands.Bands), fx.wantBandsMax)
			}
		})
	}
}

```

`internal/disasm/thrfields.go`:

```go
package disasm

// THR field name tables for ARM64 + compressed pointers (PRODUCT AOT builds).
// Extracted from dartsdk/v*/runtime/vm/compiler/runtime_offsets_extracted.h
// (AOT + PRODUCT + TARGET_ARCH_ARM64 + DART_COMPRESSED_POINTERS sections).
//
// Each map: byte offset → short field name.

// THRFields returns the Thread offset→name map for a given Dart version string.
// Returns nil if no table is available (annotations fall back to THR+0xNN).
func THRFields(dartVersion string) map[int]string {
	switch dartVersion {
	case "2.17.6":
		return thrV217
	case "3.0.5", "3.1.0", "3.2.5", "3.3.0":
		return thrV325
	case "3.4.3", "3.5.0":
		return thrV343
	case "3.6.2", "3.7.0":
		return thrV362
	case "3.8.1":
		return thrV381
	case "3.9.2":
		return thrV392
	case "3.10.7":
		return thrV3107
	}
	return nil
}

// v2.17.6: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v2.17.6/runtime/vm/compiler/runtime_offsets_extracted.h:16818-17478
var thrV217 = map[int]string{
	0x20:  "top_resource",
	0x38:  "stack_limit",
	0x40:  "write_barrier_mask",
	0x48:  "heap_base",
	0x50:  "isolate",
	0x58:  "dispatch_table_array",
	0x60:  "top",
	0x68:  "end",
	0x70:  "saved_stack_limit",
	0x78:  "stack_overflow_flags",
	0x80:  "field_table_values",
	0x90:  "top_exit_frame_info",
	0x98:  "store_buffer_block",
	0xa0:  "marking_stack_block",
	0xb0:  "vm_tag",
	0xb8:  "unboxed_int64_runtime_arg",
	0xc0:  "unboxed_double_runtime_arg",
	0xc8:  "object_null",
	0xd0:  "bool_true",
	0xd8:  "bool_false",
	0xe0:  "fix_callers_target_code",
	0xe8:  "fix_allocation_stub_code",
	0xf0:  "invoke_dart_code_stub",
	0xf8:  "call_to_runtime_stub",
	0x100: "late_init_error_nofpu_stub",
	0x108: "late_init_error_fpu_stub",
	0x110: "null_error_nofpu_stub",
	0x118: "null_error_fpu_stub",
	0x120: "null_arg_error_nofpu_stub",
	0x128: "null_arg_error_fpu_stub",
	0x130: "null_cast_error_nofpu_stub",
	0x138: "null_cast_error_fpu_stub",
	0x140: "range_error_nofpu_stub",
	0x148: "range_error_fpu_stub",
	0x150: "allocate_mint_fpu_stub",
	0x158: "allocate_mint_nofpu_stub",
	0x160: "allocate_object_stub",
	0x168: "allocate_object_parameterized_stub",
	0x170: "allocate_object_slow_stub",
	0x178: "stack_overflow_nofpu_stub",
	0x180: "stack_overflow_fpu_stub",
	0x188: "switchable_call_miss_stub",
	0x1a8: "optimize_stub",
	0x1b0: "deoptimize_stub",
	0x1b8: "lazy_deopt_from_return_stub",
	0x1c0: "lazy_deopt_from_throw_stub",
	0x1c8: "slow_type_test_stub",
	0x1d0: "lazy_specialize_type_test_stub",
	0x1d8: "enter_safepoint_stub",
	0x1e0: "exit_safepoint_stub",
	0x1e8: "exit_safepoint_ignore_unwind_stub",
	0x1f0: "call_native_through_safepoint_stub",
	0x1f8: "write_barrier_ep",
	0x200: "array_write_barrier_ep",
	0x208: "call_to_runtime_ep",
	0x210: "allocate_mint_fpu_ep",
	0x218: "allocate_mint_nofpu_ep",
	0x220: "allocate_object_ep",
	0x228: "allocate_object_parameterized_ep",
	0x230: "allocate_object_slow_ep",
	0x238: "stack_overflow_nofpu_ep",
	0x240: "stack_overflow_fpu_ep",
	0x248: "megamorphic_call_checked_entry",
	0x250: "switchable_call_miss_entry",
	0x258: "optimize_ep",
	0x260: "deoptimize_ep",
	0x268: "call_native_through_safepoint_ep",
	0x270: "jump_to_frame_ep",
	0x278: "slow_type_test_ep",
	0x280: "bootstrap_native_wrapper_ep",
	0x288: "no_scope_native_wrapper_ep",
	0x290: "auto_scope_native_wrapper_ep",
	0x298: "predefined_symbols_address",
	0x2a8: "double_negate_address",
	0x2b0: "double_abs_address",
	0x2b8: "float_not_address",
	0x2c0: "float_negate_address",
	0x2c8: "float_absolute_address",
	0x2d0: "float_zerow_address",
	0x2d8: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x588: "wb_wrapper_R0",
	0x590: "wb_wrapper_R1",
	0x598: "wb_wrapper_R2",
	0x5a0: "wb_wrapper_R3",
	0x5a8: "wb_wrapper_R4",
	0x5b0: "wb_wrapper_R5",
	0x5b8: "wb_wrapper_R6",
	0x5c0: "wb_wrapper_R7",
	0x5c8: "wb_wrapper_R8",
	0x5d0: "wb_wrapper_R9",
	0x5d8: "wb_wrapper_R10",
	0x5e0: "wb_wrapper_R11",
	0x5e8: "wb_wrapper_R12",
	0x5f0: "wb_wrapper_R13",
	0x5f8: "wb_wrapper_R14",
	0x600: "wb_wrapper_R19",
	0x608: "wb_wrapper_R20",
	0x610: "wb_wrapper_R23",
	0x618: "wb_wrapper_R24",
	0x620: "active_exception",
	0x628: "active_stacktrace",
	0x630: "global_object_pool",
	0x638: "resume_pc",
	0x640: "saved_shadow_call_stack",
	0x648: "execution_state",
	0x650: "safepoint_state",
	0x658: "callback_code",
	0x660: "callback_stack_return",
	0x668: "exit_through_ffi",
	0x670: "api_top_scope",
	0x678: "double_truncate_round_supported",
	0x680: "random",
	0x688: "tsan_utils",
	0x698: "dart_stream",
	0x6a0: "isolate_group",
}

// v3.2.5: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v3.2.5/runtime/vm/compiler/runtime_offsets_extracted.h:20107-20870
// Also covers v3.1.0 (closest available SDK) and v3.3.0.
var thrV325 = map[int]string{
	0x20:  "top_resource",
	0x38:  "stack_limit",
	0x40:  "write_barrier_mask",
	0x48:  "heap_base",
	0x50:  "top",
	0x58:  "end",
	0x60:  "dispatch_table_array",
	0x68:  "field_table_values",
	0x70:  "object_null",
	0x78:  "bool_true",
	0x80:  "bool_false",
	0x88:  "empty_array",
	0x90:  "dynamic_type",
	0x98:  "fix_callers_target_code",
	0xa0:  "fix_allocation_stub_code",
	0xa8:  "invoke_dart_code_stub",
	0xb0:  "call_to_runtime_stub",
	0xb8:  "late_init_error_nofpu_stub",
	0xc0:  "late_init_error_fpu_stub",
	0xc8:  "null_error_nofpu_stub",
	0xd0:  "null_error_fpu_stub",
	0xd8:  "null_arg_error_nofpu_stub",
	0xe0:  "null_arg_error_fpu_stub",
	0xe8:  "null_cast_error_nofpu_stub",
	0xf0:  "null_cast_error_fpu_stub",
	0xf8:  "range_error_nofpu_stub",
	0x100: "range_error_fpu_stub",
	0x108: "write_error_nofpu_stub",
	0x110: "write_error_fpu_stub",
	0x118: "allocate_mint_fpu_stub",
	0x120: "allocate_mint_nofpu_stub",
	0x128: "allocate_object_stub",
	0x130: "allocate_object_parameterized_stub",
	0x138: "allocate_object_slow_stub",
	0x140: "async_exception_handler_stub",
	0x148: "resume_stub",
	0x150: "return_async_stub",
	0x158: "return_async_not_future_stub",
	0x160: "return_async_star_stub",
	0x168: "stack_overflow_nofpu_stub",
	0x170: "stack_overflow_fpu_stub",
	0x178: "switchable_call_miss_stub",
	0x198: "optimize_stub",
	0x1a0: "deoptimize_stub",
	0x1a8: "lazy_deopt_from_return_stub",
	0x1b0: "lazy_deopt_from_throw_stub",
	0x1b8: "slow_type_test_stub",
	0x1c0: "lazy_specialize_type_test_stub",
	0x1c8: "enter_safepoint_stub",
	0x1d0: "exit_safepoint_stub",
	0x1d8: "exit_safepoint_ignore_unwind_stub",
	0x1e0: "call_native_through_safepoint_stub",
	0x1e8: "write_barrier_ep",
	0x1f0: "array_write_barrier_ep",
	0x1f8: "call_to_runtime_ep",
	0x200: "allocate_mint_fpu_ep",
	0x208: "allocate_mint_nofpu_ep",
	0x210: "allocate_object_ep",
	0x218: "allocate_object_parameterized_ep",
	0x220: "allocate_object_slow_ep",
	0x228: "stack_overflow_nofpu_ep",
	0x230: "stack_overflow_fpu_ep",
	0x238: "megamorphic_call_checked_entry",
	0x240: "switchable_call_miss_entry",
	0x248: "optimize_ep",
	0x250: "deoptimize_ep",
	0x258: "call_native_through_safepoint_ep",
	0x260: "jump_to_frame_ep",
	0x268: "slow_type_test_ep",
	0x270: "bootstrap_native_wrapper_ep",
	0x278: "no_scope_native_wrapper_ep",
	0x280: "auto_scope_native_wrapper_ep",
	0x288: "predefined_symbols_address",
	0x298: "double_negate_address",
	0x2a0: "double_abs_address",
	0x2a8: "float_not_address",
	0x2b0: "float_negate_address",
	0x2b8: "float_absolute_address",
	0x2c0: "float_zerow_address",
	0x2c8: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x5e8: "wb_wrapper_R0",
	0x5f0: "wb_wrapper_R1",
	0x5f8: "wb_wrapper_R2",
	0x600: "wb_wrapper_R3",
	0x608: "wb_wrapper_R4",
	0x610: "wb_wrapper_R5",
	0x618: "wb_wrapper_R6",
	0x620: "wb_wrapper_R7",
	0x628: "wb_wrapper_R8",
	0x630: "wb_wrapper_R9",
	0x638: "wb_wrapper_R10",
	0x640: "wb_wrapper_R11",
	0x648: "wb_wrapper_R12",
	0x650: "wb_wrapper_R13",
	0x658: "wb_wrapper_R14",
	0x660: "wb_wrapper_R19",
	0x668: "wb_wrapper_R20",
	0x670: "wb_wrapper_R23",
	0x678: "wb_wrapper_R24",
	0x680: "wb_wrapper_R25",
	// High offsets (>0x680):
	0x688: "suspend_state_init_async_ep",
	0x690: "suspend_state_await_ep",
	0x698: "suspend_state_await_type_check_ep",
	0x6a0: "suspend_state_return_async_ep",
	0x6a8: "suspend_state_return_async_not_future_ep",
	0x6b0: "suspend_state_init_async_star_ep",
	0x6b8: "suspend_state_yield_async_star_ep",
	0x6c0: "suspend_state_return_async_star_ep",
	0x6c8: "suspend_state_init_sync_star_ep",
	0x6d0: "suspend_state_suspend_sync_star_ep",
	0x6d8: "suspend_state_handle_exception_ep",
	0x6e0: "isolate",
	0x6e8: "isolate_group",
	0x6f0: "saved_stack_limit",
	0x6f8: "stack_overflow_flags",
	0x700: "top_exit_frame_info",
	0x708: "store_buffer_block",
	0x710: "marking_stack_block",
	0x718: "deferred_marking_stack_block",
	0x720: "vm_tag",
	0x728: "unboxed_runtime_arg",
	0x738: "active_exception",
	0x740: "active_stacktrace",
	0x748: "global_object_pool",
	0x750: "resume_pc",
	0x758: "saved_shadow_call_stack",
	0x760: "execution_state",
	0x768: "safepoint_state",
	0x770: "exit_through_ffi",
	0x778: "api_top_scope",
	0x780: "double_truncate_round_supported",
	0x788: "next_task_id",
	0x790: "random",
	0x798: "tsan_utils",
	0x7b0: "dart_stream",
	0x7b8: "service_extension_stream",
}

// v3.4.3: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v3.4.3/runtime/vm/compiler/runtime_offsets_extracted.h:9204-9904
// Also covers v3.5.0.
// Delta from v3.2.5: +8 shift from fix_callers_target_code onward (RangeErrorUnboxedInt64 added).
var thrV343 = map[int]string{
	0x20:  "top_resource",
	0x38:  "stack_limit",
	0x40:  "write_barrier_mask",
	0x48:  "heap_base",
	0x50:  "top",
	0x58:  "end",
	0x60:  "dispatch_table_array",
	0x68:  "field_table_values",
	0x70:  "object_null",
	0x78:  "bool_true",
	0x80:  "bool_false",
	0x88:  "empty_array",
	0x90:  "empty_type_arguments",
	0x98:  "dynamic_type",
	0xa0:  "fix_callers_target_code",
	0xa8:  "fix_allocation_stub_code",
	0xb0:  "invoke_dart_code_stub",
	0xb8:  "call_to_runtime_stub",
	0xc0:  "late_init_error_nofpu_stub",
	0xc8:  "late_init_error_fpu_stub",
	0xd0:  "null_error_nofpu_stub",
	0xd8:  "null_error_fpu_stub",
	0xe0:  "null_arg_error_nofpu_stub",
	0xe8:  "null_arg_error_fpu_stub",
	0xf0:  "null_cast_error_nofpu_stub",
	0xf8:  "null_cast_error_fpu_stub",
	0x100: "range_error_nofpu_stub",
	0x108: "range_error_fpu_stub",
	0x110: "write_error_nofpu_stub",
	0x118: "write_error_fpu_stub",
	0x120: "allocate_mint_fpu_stub",
	0x128: "allocate_mint_nofpu_stub",
	0x130: "allocate_object_stub",
	0x138: "allocate_object_parameterized_stub",
	0x140: "allocate_object_slow_stub",
	0x148: "async_exception_handler_stub",
	0x150: "resume_stub",
	0x158: "return_async_stub",
	0x160: "return_async_not_future_stub",
	0x168: "return_async_star_stub",
	0x170: "stack_overflow_nofpu_stub",
	0x178: "stack_overflow_fpu_stub",
	0x180: "switchable_call_miss_stub",
	0x1a0: "optimize_stub",
	0x1a8: "deoptimize_stub",
	0x1b0: "lazy_deopt_from_return_stub",
	0x1b8: "lazy_deopt_from_throw_stub",
	0x1c0: "slow_type_test_stub",
	0x1c8: "lazy_specialize_type_test_stub",
	0x1d0: "enter_safepoint_stub",
	0x1d8: "exit_safepoint_stub",
	0x1e0: "exit_safepoint_ignore_unwind_stub",
	0x1e8: "call_native_through_safepoint_stub",
	0x1f0: "write_barrier_ep",
	0x1f8: "array_write_barrier_ep",
	0x200: "call_to_runtime_ep",
	0x208: "allocate_mint_fpu_ep",
	0x210: "allocate_mint_nofpu_ep",
	0x218: "allocate_object_ep",
	0x220: "allocate_object_parameterized_ep",
	0x228: "allocate_object_slow_ep",
	0x230: "stack_overflow_nofpu_ep",
	0x238: "stack_overflow_fpu_ep",
	0x240: "megamorphic_call_checked_entry",
	0x248: "switchable_call_miss_entry",
	0x250: "optimize_ep",
	0x258: "deoptimize_ep",
	0x260: "call_native_through_safepoint_ep",
	0x268: "jump_to_frame_ep",
	0x270: "slow_type_test_ep",
	0x278: "bootstrap_native_wrapper_ep",
	0x280: "no_scope_native_wrapper_ep",
	0x288: "auto_scope_native_wrapper_ep",
	0x290: "predefined_symbols_address",
	0x2a0: "double_negate_address",
	0x2a8: "double_abs_address",
	0x2b0: "float_not_address",
	0x2b8: "float_negate_address",
	0x2c0: "float_absolute_address",
	0x2c8: "float_zerow_address",
	0x2d0: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x5f8: "wb_wrapper_R0",
	0x600: "wb_wrapper_R1",
	0x608: "wb_wrapper_R2",
	0x610: "wb_wrapper_R3",
	0x618: "wb_wrapper_R4",
	0x620: "wb_wrapper_R5",
	0x628: "wb_wrapper_R6",
	0x630: "wb_wrapper_R7",
	0x638: "wb_wrapper_R8",
	0x640: "wb_wrapper_R9",
	0x648: "wb_wrapper_R10",
	0x650: "wb_wrapper_R11",
	0x658: "wb_wrapper_R12",
	0x660: "wb_wrapper_R13",
	0x668: "wb_wrapper_R14",
	0x670: "wb_wrapper_R19",
	0x678: "wb_wrapper_R20",
	0x680: "wb_wrapper_R23",
	0x688: "wb_wrapper_R24",
	0x690: "wb_wrapper_R25",
	// High offsets (>0x690):
	0x698: "suspend_state_init_async_ep",
	0x6a0: "suspend_state_await_ep",
	0x6a8: "suspend_state_await_type_check_ep",
	0x6b0: "suspend_state_return_async_ep",
	0x6b8: "suspend_state_return_async_not_future_ep",
	0x6c0: "suspend_state_init_async_star_ep",
	0x6c8: "suspend_state_yield_async_star_ep",
	0x6d0: "suspend_state_return_async_star_ep",
	0x6d8: "suspend_state_init_sync_star_ep",
	0x6e0: "suspend_state_suspend_sync_star_ep",
	0x6e8: "suspend_state_handle_exception_ep",
	0x6f0: "isolate",
	0x6f8: "isolate_group",
	0x700: "saved_stack_limit",
	0x708: "stack_overflow_flags",
	0x710: "top_exit_frame_info",
	0x718: "store_buffer_block",
	0x720: "marking_stack_block",
	0x730: "vm_tag",
	0x738: "unboxed_runtime_arg",
	0x748: "active_exception",
	0x750: "active_stacktrace",
	0x758: "global_object_pool",
	0x760: "resume_pc",
	0x768: "saved_shadow_call_stack",
	0x770: "execution_state",
	0x778: "safepoint_state",
	0x780: "exit_through_ffi",
	0x788: "api_top_scope",
	0x790: "double_truncate_round_supported",
	0x798: "next_task_id",
	0x7a0: "random",
	0x7a8: "tsan_utils",
	0x7c0: "dart_stream",
	0x7c8: "service_extension_stream",
}

// v3.6.2: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v3.6.2/runtime/vm/compiler/runtime_offsets_extracted.h:20318-21100
// Also covers v3.7.0.
// Delta from v3.4.3: shared_field_table_values added, invoke_dart_code_from_bytecode_stub added,
// resume_interpreter_ep + interpret_call_ep added, marking_stack split into old/new.
var thrV362 = map[int]string{
	0x20:  "top_resource",
	0x38:  "stack_limit",
	0x40:  "write_barrier_mask",
	0x48:  "heap_base",
	0x50:  "top",
	0x58:  "end",
	0x60:  "dispatch_table_array",
	0x68:  "field_table_values",
	0x70:  "shared_field_table_values",
	0x78:  "object_null",
	0x80:  "bool_true",
	0x88:  "bool_false",
	0x90:  "empty_array",
	0x98:  "empty_type_arguments",
	0xa0:  "dynamic_type",
	0xa8:  "fix_callers_target_code",
	0xb0:  "fix_allocation_stub_code",
	0xb8:  "invoke_dart_code_stub",
	0xc0:  "invoke_dart_code_from_bytecode_stub",
	0xc8:  "call_to_runtime_stub",
	0xd0:  "late_init_error_nofpu_stub",
	0xd8:  "late_init_error_fpu_stub",
	0xe0:  "null_error_nofpu_stub",
	0xe8:  "null_error_fpu_stub",
	0xf0:  "null_arg_error_nofpu_stub",
	0xf8:  "null_arg_error_fpu_stub",
	0x100: "null_cast_error_nofpu_stub",
	0x108: "null_cast_error_fpu_stub",
	0x110: "range_error_nofpu_stub",
	0x118: "range_error_fpu_stub",
	0x120: "write_error_nofpu_stub",
	0x128: "write_error_fpu_stub",
	0x130: "allocate_mint_fpu_stub",
	0x138: "allocate_mint_nofpu_stub",
	0x140: "allocate_object_stub",
	0x148: "allocate_object_parameterized_stub",
	0x150: "allocate_object_slow_stub",
	0x158: "async_exception_handler_stub",
	0x160: "resume_stub",
	0x168: "return_async_stub",
	0x170: "return_async_not_future_stub",
	0x178: "return_async_star_stub",
	0x180: "stack_overflow_nofpu_stub",
	0x188: "stack_overflow_fpu_stub",
	0x190: "switchable_call_miss_stub",
	0x1a8: "optimize_stub",
	0x1b0: "deoptimize_stub",
	0x1b8: "lazy_deopt_from_return_stub",
	0x1c0: "lazy_deopt_from_throw_stub",
	0x1c8: "slow_type_test_stub",
	0x1d0: "lazy_specialize_type_test_stub",
	0x1d8: "enter_safepoint_stub",
	0x1e0: "exit_safepoint_stub",
	0x1e8: "exit_safepoint_ignore_unwind_stub",
	0x1f0: "call_native_through_safepoint_stub",
	0x1f8: "write_barrier_ep",
	0x200: "array_write_barrier_ep",
	0x208: "call_to_runtime_ep",
	0x210: "allocate_mint_fpu_ep",
	0x218: "allocate_mint_nofpu_ep",
	0x220: "allocate_object_ep",
	0x228: "allocate_object_parameterized_ep",
	0x230: "allocate_object_slow_ep",
	0x238: "stack_overflow_nofpu_ep",
	0x240: "stack_overflow_fpu_ep",
	0x248: "megamorphic_call_checked_entry",
	0x250: "switchable_call_miss_entry",
	0x258: "optimize_ep",
	0x260: "deoptimize_ep",
	0x268: "call_native_through_safepoint_ep",
	0x270: "jump_to_frame_ep",
	0x278: "slow_type_test_ep",
	0x280: "resume_interpreter_ep",
	0x288: "bootstrap_native_wrapper_ep",
	0x290: "no_scope_native_wrapper_ep",
	0x298: "auto_scope_native_wrapper_ep",
	0x2a0: "interpret_call_ep",
	0x2a8: "predefined_symbols_address",
	0x2b8: "double_negate_address",
	0x2c0: "double_abs_address",
	0x2c8: "float_not_address",
	0x2d0: "float_negate_address",
	0x2d8: "float_absolute_address",
	0x2e0: "float_zerow_address",
	0x2e8: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x660: "wb_wrapper_R0",
	0x668: "wb_wrapper_R1",
	0x670: "wb_wrapper_R2",
	0x678: "wb_wrapper_R3",
	0x680: "wb_wrapper_R4",
	0x688: "wb_wrapper_R5",
	0x690: "wb_wrapper_R6",
	0x698: "wb_wrapper_R7",
	0x6a0: "wb_wrapper_R8",
	0x6a8: "wb_wrapper_R9",
	0x6b0: "wb_wrapper_R10",
	0x6b8: "wb_wrapper_R11",
	0x6c0: "wb_wrapper_R12",
	0x6c8: "wb_wrapper_R13",
	0x6d0: "wb_wrapper_R14",
	0x6d8: "wb_wrapper_R19",
	0x6e0: "wb_wrapper_R20",
	0x6e8: "wb_wrapper_R23",
	0x6f0: "wb_wrapper_R24",
	0x6f8: "wb_wrapper_R25",
	// High offsets (>0x6f8):
	0x700: "suspend_state_init_async_ep",
	0x708: "suspend_state_await_ep",
	0x710: "suspend_state_await_type_check_ep",
	0x718: "suspend_state_return_async_ep",
	0x720: "suspend_state_return_async_not_future_ep",
	0x728: "suspend_state_init_async_star_ep",
	0x730: "suspend_state_yield_async_star_ep",
	0x738: "suspend_state_return_async_star_ep",
	0x740: "suspend_state_init_sync_star_ep",
	0x748: "suspend_state_suspend_sync_star_ep",
	0x750: "suspend_state_handle_exception_ep",
	0x758: "isolate",
	0x760: "isolate_group",
	0x768: "saved_stack_limit",
	0x770: "stack_overflow_flags",
	0x778: "top_exit_frame_info",
	0x780: "store_buffer_block",
	0x788: "old_marking_stack_block",
	0x790: "new_marking_stack_block",
	0x7a0: "vm_tag",
	0x7a8: "unboxed_runtime_arg",
	0x7b8: "active_exception",
	0x7c0: "active_stacktrace",
	0x7c8: "global_object_pool",
	0x7d0: "resume_pc",
	0x7d8: "saved_shadow_call_stack",
	0x7e0: "execution_state",
	0x7e8: "safepoint_state",
	0x7f0: "exit_through_ffi",
	0x7f8: "api_top_scope",
	0x800: "double_truncate_round_supported",
	0x808: "next_task_id",
	0x810: "random",
	0x818: "tsan_utils",
	0x830: "dart_stream",
	0x838: "service_extension_stream",
}

// v3.8.1: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v3.8.1/runtime/vm/compiler/runtime_offsets_extracted.h:9347-9900
// Delta from v3.6.2: exit_safepoint_ignore_unwind_stub removed (shifts all ep offsets by -8),
// RememberCard and ExitSafepointIgnoreUnwindInProgress removed from LEAF list.
var thrV381 = map[int]string{
	0x20:  "top_resource",
	0x38:  "stack_limit",
	0x40:  "write_barrier_mask",
	0x48:  "heap_base",
	0x50:  "top",
	0x58:  "end",
	0x60:  "dispatch_table_array",
	0x68:  "field_table_values",
	0x70:  "shared_field_table_values",
	0x78:  "object_null",
	0x80:  "bool_true",
	0x88:  "bool_false",
	0x90:  "empty_array",
	0x98:  "empty_type_arguments",
	0xa0:  "dynamic_type",
	0xa8:  "fix_callers_target_code",
	0xb0:  "fix_allocation_stub_code",
	0xb8:  "invoke_dart_code_stub",
	0xc0:  "invoke_dart_code_from_bytecode_stub",
	0xc8:  "call_to_runtime_stub",
	0xd0:  "late_init_error_nofpu_stub",
	0xd8:  "late_init_error_fpu_stub",
	0xe0:  "null_error_nofpu_stub",
	0xe8:  "null_error_fpu_stub",
	0xf0:  "null_arg_error_nofpu_stub",
	0xf8:  "null_arg_error_fpu_stub",
	0x100: "null_cast_error_nofpu_stub",
	0x108: "null_cast_error_fpu_stub",
	0x110: "range_error_nofpu_stub",
	0x118: "range_error_fpu_stub",
	0x120: "write_error_nofpu_stub",
	0x128: "write_error_fpu_stub",
	0x130: "allocate_mint_fpu_stub",
	0x138: "allocate_mint_nofpu_stub",
	0x140: "allocate_object_stub",
	0x148: "allocate_object_parameterized_stub",
	0x150: "allocate_object_slow_stub",
	0x158: "async_exception_handler_stub",
	0x160: "resume_stub",
	0x168: "return_async_stub",
	0x170: "return_async_not_future_stub",
	0x178: "return_async_star_stub",
	0x180: "stack_overflow_nofpu_stub",
	0x188: "stack_overflow_fpu_stub",
	0x190: "switchable_call_miss_stub",
	0x1a8: "optimize_stub",
	0x1b0: "deoptimize_stub",
	0x1b8: "lazy_deopt_from_return_stub",
	0x1c0: "lazy_deopt_from_throw_stub",
	0x1c8: "slow_type_test_stub",
	0x1d0: "lazy_specialize_type_test_stub",
	0x1d8: "enter_safepoint_stub",
	0x1e0: "exit_safepoint_stub",
	0x1e8: "call_native_through_safepoint_stub",
	0x1f0: "write_barrier_ep",
	0x1f8: "array_write_barrier_ep",
	0x200: "call_to_runtime_ep",
	0x208: "allocate_mint_fpu_ep",
	0x210: "allocate_mint_nofpu_ep",
	0x218: "allocate_object_ep",
	0x220: "allocate_object_parameterized_ep",
	0x228: "allocate_object_slow_ep",
	0x230: "stack_overflow_nofpu_ep",
	0x238: "stack_overflow_fpu_ep",
	0x240: "megamorphic_call_checked_entry",
	0x248: "switchable_call_miss_entry",
	0x250: "optimize_ep",
	0x258: "deoptimize_ep",
	0x260: "call_native_through_safepoint_ep",
	0x268: "jump_to_frame_ep",
	0x270: "slow_type_test_ep",
	0x278: "resume_interpreter_ep",
	0x280: "bootstrap_native_wrapper_ep",
	0x288: "no_scope_native_wrapper_ep",
	0x290: "auto_scope_native_wrapper_ep",
	0x298: "interpret_call_ep",
	0x2a0: "predefined_symbols_address",
	0x2b0: "double_negate_address",
	0x2b8: "double_abs_address",
	0x2c0: "float_not_address",
	0x2c8: "float_negate_address",
	0x2d0: "float_absolute_address",
	0x2d8: "float_zerow_address",
	0x2e0: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x648: "wb_wrapper_R0",
	0x650: "wb_wrapper_R1",
	0x658: "wb_wrapper_R2",
	0x660: "wb_wrapper_R3",
	0x668: "wb_wrapper_R4",
	0x670: "wb_wrapper_R5",
	0x678: "wb_wrapper_R6",
	0x680: "wb_wrapper_R7",
	0x688: "wb_wrapper_R8",
	0x690: "wb_wrapper_R9",
	0x698: "wb_wrapper_R10",
	0x6a0: "wb_wrapper_R11",
	0x6a8: "wb_wrapper_R12",
	0x6b0: "wb_wrapper_R13",
	0x6b8: "wb_wrapper_R14",
	0x6c0: "wb_wrapper_R19",
	0x6c8: "wb_wrapper_R20",
	0x6d0: "wb_wrapper_R23",
	0x6d8: "wb_wrapper_R24",
	0x6e0: "wb_wrapper_R25",
	// High offsets (>0x6e0):
	0x6e8: "suspend_state_init_async_ep",
	0x6f0: "suspend_state_await_ep",
	0x6f8: "suspend_state_await_type_check_ep",
	0x700: "suspend_state_return_async_ep",
	0x708: "suspend_state_return_async_not_future_ep",
	0x710: "suspend_state_init_async_star_ep",
	0x718: "suspend_state_yield_async_star_ep",
	0x720: "suspend_state_return_async_star_ep",
	0x728: "suspend_state_init_sync_star_ep",
	0x730: "suspend_state_suspend_sync_star_ep",
	0x738: "suspend_state_handle_exception_ep",
	0x740: "isolate",
	0x748: "isolate_group",
	0x750: "saved_stack_limit",
	0x758: "stack_overflow_flags",
	0x760: "top_exit_frame_info",
	0x768: "store_buffer_block",
	0x770: "old_marking_stack_block",
	0x778: "new_marking_stack_block",
	0x788: "vm_tag",
	0x790: "unboxed_runtime_arg",
	0x7a0: "active_exception",
	0x7a8: "active_stacktrace",
	0x7b0: "global_object_pool",
	0x7b8: "resume_pc",
	0x7c0: "saved_shadow_call_stack",
	0x7c8: "execution_state",
	0x7d0: "safepoint_state",
	0x7d8: "exit_through_ffi",
	0x7e0: "api_top_scope",
	0x7e8: "double_truncate_round_supported",
	0x7f0: "next_task_id",
	0x7f8: "random",
	0x800: "tsan_utils",
	0x818: "dart_stream",
	0x820: "service_extension_stream",
}

// v3.9.2: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v3.9.2/runtime/vm/compiler/runtime_offsets_extracted.h:20369-21163
// Delta from v3.8.1: -TraceICCall, +StaticFieldAccessedWithoutIsolateError,
// +ThrowIfValueCantBeShared, +ConvertToInstanceTypeArguments, +ResolveExternalCall,
// +InitializeSharedField. AllocateArray_ep shifts to 0x2f0, wb_wrappers to 0x678.
var thrV392 = map[int]string{
	0x20:  "top_resource",
	0x38:  "stack_limit",
	0x40:  "write_barrier_mask",
	0x48:  "heap_base",
	0x50:  "top",
	0x58:  "end",
	0x60:  "dispatch_table_array",
	0x68:  "field_table_values",
	0x70:  "shared_field_table_values",
	0x78:  "object_null",
	0x80:  "bool_true",
	0x88:  "bool_false",
	0x90:  "empty_array",
	0x98:  "empty_type_arguments",
	0xa0:  "dynamic_type",
	0xa8:  "fix_callers_target_code",
	0xb0:  "fix_allocation_stub_code",
	0xb8:  "invoke_dart_code_stub",
	0xc0:  "invoke_dart_code_from_bytecode_stub",
	0xc8:  "call_to_runtime_stub",
	0xd0:  "late_init_error_nofpu_stub",
	0xd8:  "late_init_error_fpu_stub",
	0xe0:  "null_error_nofpu_stub",
	0xe8:  "null_error_fpu_stub",
	0xf0:  "null_arg_error_nofpu_stub",
	0xf8:  "null_arg_error_fpu_stub",
	0x100: "null_cast_error_nofpu_stub",
	0x108: "null_cast_error_fpu_stub",
	0x110: "range_error_nofpu_stub",
	0x118: "range_error_fpu_stub",
	0x120: "write_error_nofpu_stub",
	0x128: "write_error_fpu_stub",
	0x130: "field_access_error_nofpu_stub",
	0x138: "field_access_error_fpu_stub",
	0x140: "allocate_mint_fpu_stub",
	0x148: "allocate_mint_nofpu_stub",
	0x150: "allocate_object_stub",
	0x158: "allocate_object_parameterized_stub",
	0x160: "allocate_object_slow_stub",
	0x168: "async_exception_handler_stub",
	0x170: "resume_stub",
	0x178: "return_async_stub",
	0x180: "return_async_not_future_stub",
	0x188: "return_async_star_stub",
	0x190: "stack_overflow_nofpu_stub",
	0x198: "stack_overflow_fpu_stub",
	0x1a0: "switchable_call_miss_stub",
	0x1b8: "optimize_stub",
	0x1c0: "deoptimize_stub",
	0x1c8: "lazy_deopt_from_return_stub",
	0x1d0: "lazy_deopt_from_throw_stub",
	0x1d8: "slow_type_test_stub",
	0x1e0: "lazy_specialize_type_test_stub",
	0x1e8: "enter_safepoint_stub",
	0x1f0: "exit_safepoint_stub",
	0x1f8: "call_native_through_safepoint_stub",
	0x200: "write_barrier_ep",
	0x208: "array_write_barrier_ep",
	0x210: "call_to_runtime_ep",
	0x218: "allocate_mint_fpu_ep",
	0x220: "allocate_mint_nofpu_ep",
	0x228: "allocate_object_ep",
	0x230: "allocate_object_parameterized_ep",
	0x238: "allocate_object_slow_ep",
	0x240: "stack_overflow_nofpu_ep",
	0x248: "stack_overflow_fpu_ep",
	0x250: "megamorphic_call_checked_entry",
	0x258: "switchable_call_miss_entry",
	0x260: "optimize_ep",
	0x268: "deoptimize_ep",
	0x270: "call_native_through_safepoint_ep",
	0x278: "jump_to_frame_ep",
	0x280: "slow_type_test_ep",
	0x288: "resume_interpreter_ep",
	0x290: "bootstrap_native_wrapper_ep",
	0x298: "no_scope_native_wrapper_ep",
	0x2a0: "auto_scope_native_wrapper_ep",
	0x2a8: "interpret_call_ep",
	0x2b0: "predefined_symbols_address",
	0x2c0: "double_negate_address",
	0x2c8: "double_abs_address",
	0x2d0: "float_not_address",
	0x2d8: "float_negate_address",
	0x2e0: "float_absolute_address",
	0x2e8: "float_zerow_address",
	0x2f0: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x678: "wb_wrapper_R0",
	0x680: "wb_wrapper_R1",
	0x688: "wb_wrapper_R2",
	0x690: "wb_wrapper_R3",
	0x698: "wb_wrapper_R4",
	0x6a0: "wb_wrapper_R5",
	0x6a8: "wb_wrapper_R6",
	0x6b0: "wb_wrapper_R7",
	0x6b8: "wb_wrapper_R8",
	0x6c0: "wb_wrapper_R9",
	0x6c8: "wb_wrapper_R10",
	0x6d0: "wb_wrapper_R11",
	0x6d8: "wb_wrapper_R12",
	0x6e0: "wb_wrapper_R13",
	0x6e8: "wb_wrapper_R14",
	0x6f0: "wb_wrapper_R19",
	0x6f8: "wb_wrapper_R20",
	0x700: "wb_wrapper_R23",
	0x708: "wb_wrapper_R24",
	0x710: "wb_wrapper_R25",
	// Suspend state entry points
	0x718: "suspend_state_init_async_ep",
	0x720: "suspend_state_await_ep",
	0x728: "suspend_state_await_type_check_ep",
	0x730: "suspend_state_return_async_ep",
	0x738: "suspend_state_return_async_not_future_ep",
	0x740: "suspend_state_init_async_star_ep",
	0x748: "suspend_state_yield_async_star_ep",
	0x750: "suspend_state_return_async_star_ep",
	0x758: "suspend_state_init_sync_star_ep",
	0x760: "suspend_state_suspend_sync_star_ep",
	0x768: "suspend_state_handle_exception_ep",
	// High offsets
	0x770: "isolate",
	0x778: "isolate_group",
	0x780: "saved_stack_limit",
	0x788: "stack_overflow_flags",
	0x790: "top_exit_frame_info",
	0x798: "store_buffer_block",
	0x7a0: "old_marking_stack_block",
	0x7a8: "new_marking_stack_block",
	0x7b8: "vm_tag",
	0x7c0: "unboxed_runtime_arg",
	0x7d0: "active_exception",
	0x7d8: "active_stacktrace",
	0x7e0: "global_object_pool",
	0x7e8: "resume_pc",
	0x7f0: "saved_shadow_call_stack",
	0x7f8: "execution_state",
	0x800: "safepoint_state",
	0x808: "exit_through_ffi",
	0x810: "api_top_scope",
	0x818: "double_truncate_round_supported",
	0x820: "next_task_id",
	0x828: "random",
	0x830: "tsan_utils",
	0x850: "dart_stream",
	0x858: "service_extension_stream",
}

// v3.10.7: PRODUCT AOT + ARM64 + DART_COMPRESSED_POINTERS
// Source: dartsdk/v3.10.7/runtime/vm/compiler/runtime_offsets_extracted.h:20210-21000
var thrV3107 = map[int]string{
	0x20:  "top_resource",
	0x48:  "stack_limit",
	0x50:  "write_barrier_mask",
	0x58:  "heap_base",
	0x60:  "top",
	0x68:  "end",
	0x70:  "dispatch_table_array",
	0x78:  "field_table_values",
	0x80:  "shared_field_table_values",
	0x88:  "object_null",
	0x90:  "bool_true",
	0x98:  "bool_false",
	0xa0:  "empty_array",
	0xa8:  "empty_type_arguments",
	0xb0:  "dynamic_type",
	0xb8:  "fix_callers_target_code",
	0xc0:  "fix_allocation_stub_code",
	0xc8:  "invoke_dart_code_stub",
	0xd0:  "invoke_dart_code_from_bytecode_stub",
	0xd8:  "call_to_runtime_stub",
	0xe0:  "late_init_error_nofpu_stub",
	0xe8:  "late_init_error_fpu_stub",
	0xf0:  "null_error_nofpu_stub",
	0xf8:  "null_error_fpu_stub",
	0x100: "null_arg_error_nofpu_stub",
	0x108: "null_arg_error_fpu_stub",
	0x110: "null_cast_error_nofpu_stub",
	0x118: "null_cast_error_fpu_stub",
	0x120: "range_error_nofpu_stub",
	0x128: "range_error_fpu_stub",
	0x130: "write_error_nofpu_stub",
	0x138: "write_error_fpu_stub",
	0x140: "field_access_error_nofpu_stub",
	0x148: "field_access_error_fpu_stub",
	0x150: "allocate_mint_fpu_stub",
	0x158: "allocate_mint_nofpu_stub",
	0x160: "async_exception_handler_stub",
	0x168: "resume_stub",
	0x170: "return_async_stub",
	0x178: "return_async_not_future_stub",
	0x180: "return_async_star_stub",
	0x188: "stack_overflow_nofpu_stub",
	0x190: "stack_overflow_fpu_stub",
	0x198: "switchable_call_miss_stub",
	0x1b0: "optimize_stub",
	0x1b8: "deoptimize_stub",
	0x1c0: "lazy_deopt_from_return_stub",
	0x1c8: "lazy_deopt_from_throw_stub",
	0x1d0: "slow_type_test_stub",
	0x1d8: "lazy_specialize_type_test_stub",
	0x1e0: "enter_safepoint_stub",
	0x1e8: "exit_safepoint_stub",
	0x1f0: "call_native_through_safepoint_stub",
	0x1f8: "write_barrier_ep",
	0x200: "array_write_barrier_ep",
	0x208: "call_to_runtime_ep",
	0x210: "allocate_mint_fpu_ep",
	0x218: "allocate_mint_nofpu_ep",
	0x220: "allocate_object_ep",
	0x228: "allocate_object_parameterized_ep",
	0x230: "allocate_object_slow_ep",
	0x238: "stack_overflow_nofpu_ep",
	0x240: "stack_overflow_fpu_ep",
	0x248: "megamorphic_call_checked_entry",
	0x250: "switchable_call_miss_entry",
	0x258: "optimize_ep",
	0x260: "deoptimize_ep",
	0x268: "call_native_through_safepoint_ep",
	0x270: "jump_to_frame_ep",
	0x278: "slow_type_test_ep",
	0x280: "resume_interpreter_ep",
	0x288: "bootstrap_native_wrapper_ep",
	0x290: "no_scope_native_wrapper_ep",
	0x298: "auto_scope_native_wrapper_ep",
	0x2a0: "interpret_call_ep",
	0x2a8: "predefined_symbols_address",
	0x2b8: "double_negate_address",
	0x2c0: "double_abs_address",
	0x2c8: "float_not_address",
	0x2d0: "float_negate_address",
	0x2d8: "float_absolute_address",
	0x2e0: "float_zerow_address",
	0x2e8: "AllocateArray_ep",
	// write_barrier_wrappers[R0..R25]
	0x570: "wb_wrapper_R0",
	0x578: "wb_wrapper_R1",
	0x580: "wb_wrapper_R2",
	0x588: "wb_wrapper_R3",
	0x590: "wb_wrapper_R4",
	0x598: "wb_wrapper_R5",
	0x5a0: "wb_wrapper_R6",
	0x5a8: "wb_wrapper_R7",
	0x5b0: "wb_wrapper_R8",
	0x5b8: "wb_wrapper_R9",
	0x5c0: "wb_wrapper_R10",
	0x5c8: "wb_wrapper_R11",
	0x5d0: "wb_wrapper_R12",
	0x5d8: "wb_wrapper_R13",
	0x5e0: "wb_wrapper_R14",
	0x5e8: "wb_wrapper_R19",
	0x5f0: "wb_wrapper_R20",
	0x5f8: "wb_wrapper_R23",
	0x600: "wb_wrapper_R24",
	0x608: "wb_wrapper_R25",
	// High offsets (>0x610):
	0x610: "suspend_state_init_async_ep",
	0x618: "suspend_state_await_ep",
	0x620: "suspend_state_await_type_check_ep",
	0x628: "suspend_state_return_async_ep",
	0x630: "suspend_state_return_async_not_future_ep",
	0x638: "suspend_state_init_async_star_ep",
	0x640: "suspend_state_yield_async_star_ep",
	0x648: "suspend_state_return_async_star_ep",
	0x650: "suspend_state_init_sync_star_ep",
	0x658: "suspend_state_suspend_sync_star_ep",
	0x660: "suspend_state_handle_exception_ep",
	0x668: "isolate",
	0x670: "isolate_group",
	0x678: "saved_stack_limit",
	0x680: "stack_overflow_flags",
	0x688: "top_exit_frame_info",
	0x690: "store_buffer_block",
	0x698: "old_marking_stack_block",
	0x6a0: "new_marking_stack_block",
	0x6b0: "vm_tag",
	0x6b8: "active_exception",
	0x6c0: "active_stacktrace",
	0x6c8: "global_object_pool",
	0x6d0: "resume_pc",
	0x6d8: "saved_shadow_call_stack",
	0x6e0: "execution_state",
	0x6e8: "safepoint_state",
	0x6f0: "exit_through_ffi",
	0x888: "api_top_scope",
	0x890: "double_truncate_round_supported",
	0x898: "unboxed_runtime_arg",
	0x8a8: "next_task_id",
	0x8b0: "random",
	0x8b8: "tsan_utils",
	0x8c8: "user_tag",
	0x8d0: "current_tag",
	0x8d8: "default_tag",
	0x8f0: "dart_stream",
	0x8f8: "service_extension_stream",
}

// Runtime entry point names by version, ordered as in runtime_entry_list.h.
// Each entry occupies 8 bytes (one uword) in the Thread struct.
// Offset = AllocateArray_ep + index*8.
// RUNTIME_ENTRY_LIST entries come first, then LEAF_RUNTIME_ENTRY_LIST entries.

// v2.17.6: 55 RUNTIME + 31 LEAF = 86 entries from 0x2d8 to 0x588 (exclusive).
var runtimeEntriesV217 = []string{
	// RUNTIME_ENTRY_LIST (55)
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "BoxDouble",
	"BreakpointRuntimeHandler", "SingleStepHandler", "CloneContext",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck", "NonBoolTypeError",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue",
	"OptimizeInvokedFunction", "TraceICCall", "PatchStaticCall",
	"RangeError", "NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "StackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "SwitchableCallMiss", "NotLoaded",
	// LEAF_RUNTIME_ENTRY_LIST (31)
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "MarkingStackBlockProcess", "RememberCard",
	"EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint", "ExitSafepointIgnoreUnwindInProgress",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"TsanLoadAcquire", "TsanStoreRelease",
}

// v3.2.5: 64 RUNTIME + 36 LEAF = 100 entries from 0x2c8 to 0x5e8 (exclusive).
// Also used for v3.1.0 (closest available SDK).
var runtimeEntriesV325 = []string{
	// RUNTIME_ENTRY_LIST (64)
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "AllocateRecord", "AllocateSmallRecord",
	"AllocateSuspendState", "BoxDouble", "BoxFloat32x4", "BoxFloat64x2",
	"BreakpointRuntimeHandler", "SingleStepHandler",
	"CloneContext", "CloneSuspendState",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck", "NonBoolTypeError",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue",
	"OptimizeInvokedFunction", "TraceICCall", "PatchStaticCall",
	"RangeError", "WriteError",
	"NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "InterruptOrStackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "ResumeFrame", "SwitchableCallMiss", "NotLoaded",
	"FfiAsyncCallbackSend",
	// LEAF_RUNTIME_ENTRY_LIST (36)
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "MarkingStackBlockProcess", "RememberCard",
	"EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint", "ExitSafepointIgnoreUnwindInProgress",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"PropagateError", "MsanUnpoison", "MsanUnpoisonParam",
	"TsanLoadAcquire", "TsanStoreRelease",
	"TryDoubleAsInteger", "MemoryMove",
}

// v3.4.3: 65 RUNTIME + 36 LEAF = 101 entries from 0x2d0 to 0x5f8 (exclusive).
// Also used for v3.5.0.
// Delta from v3.2.5: +RangeErrorUnboxedInt64, +WriteError replaces old position.
var runtimeEntriesV343 = []string{
	// RUNTIME_ENTRY_LIST (65)
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "AllocateRecord", "AllocateSmallRecord",
	"AllocateSuspendState", "BoxDouble", "BoxFloat32x4", "BoxFloat64x2",
	"BreakpointRuntimeHandler", "SingleStepHandler",
	"CloneContext", "CloneSuspendState",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck", "NonBoolTypeError",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue",
	"OptimizeInvokedFunction", "TraceICCall", "PatchStaticCall",
	"RangeError", "RangeErrorUnboxedInt64", "WriteError",
	"NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "InterruptOrStackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "ResumeFrame", "SwitchableCallMiss", "NotLoaded",
	"FfiAsyncCallbackSend",
	// LEAF_RUNTIME_ENTRY_LIST (36)
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "MarkingStackBlockProcess", "RememberCard",
	"EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint", "ExitSafepointIgnoreUnwindInProgress",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"PropagateError", "MsanUnpoison", "MsanUnpoisonParam",
	"TsanLoadAcquire", "TsanStoreRelease",
	"TryDoubleAsInteger", "MemoryMove",
}

// v3.6.2: 73 RUNTIME + 38 LEAF = 111 entries from 0x2e8 to 0x660 (exclusive).
// Also used for v3.7.0.
// Delta from v3.4.3: -NonBoolTypeError, +LateFieldAlreadyInitializedError,
// +8 new entries at end. LEAF: MarkingStackBlockProcess split into Old+New, +LibcFmod.
var runtimeEntriesV362 = []string{
	// RUNTIME_ENTRY_LIST (73)
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "AllocateRecord", "AllocateSmallRecord",
	"AllocateSuspendState", "BoxDouble", "BoxFloat32x4", "BoxFloat64x2",
	"BreakpointRuntimeHandler", "SingleStepHandler",
	"CloneContext", "CloneSuspendState",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue",
	"OptimizeInvokedFunction", "TraceICCall", "PatchStaticCall",
	"RangeError", "RangeErrorUnboxedInt64", "WriteError",
	"NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "InterruptOrStackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"LateFieldAlreadyInitializedError",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "ResumeFrame", "SwitchableCallMiss", "NotLoaded",
	"FfiAsyncCallbackSend",
	"AllocateSubtypeTestCache", "GetFieldForDispatch",
	"AdjustArgumentsDesciptorForImplicitClosure",
	"ClosureArgumentsValid", "ResolveCallFunction",
	"InterpretedInstanceCallMissHandler",
	"InvokeNoSuchMethod", "ResumeInterpreter",
	// LEAF_RUNTIME_ENTRY_LIST (38)
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "OldMarkingStackBlockProcess", "NewMarkingStackBlockProcess",
	"RememberCard", "EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFmod",
	"LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint", "ExitSafepointIgnoreUnwindInProgress",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"PropagateError", "MsanUnpoison", "MsanUnpoisonParam",
	"TsanLoadAcquire", "TsanStoreRelease",
	"TryDoubleAsInteger", "MemoryMove",
}

// v3.8.1: 73 RUNTIME + 36 LEAF = 109 entries from 0x2e0 to 0x648 (exclusive).
// Delta from v3.6.2: -RememberCard, -ExitSafepointIgnoreUnwindInProgress from LEAF.
// exit_safepoint_ignore_unwind_stub removed → all ep offsets shift -8.
var runtimeEntriesV381 = []string{
	// RUNTIME_ENTRY_LIST (73) — identical to v3.6.2
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "AllocateRecord", "AllocateSmallRecord",
	"AllocateSuspendState", "BoxDouble", "BoxFloat32x4", "BoxFloat64x2",
	"BreakpointRuntimeHandler", "SingleStepHandler",
	"CloneContext", "CloneSuspendState",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue",
	"OptimizeInvokedFunction", "TraceICCall", "PatchStaticCall",
	"RangeError", "RangeErrorUnboxedInt64", "WriteError",
	"NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "InterruptOrStackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"LateFieldAlreadyInitializedError",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "ResumeFrame", "SwitchableCallMiss", "NotLoaded",
	"FfiAsyncCallbackSend",
	"AllocateSubtypeTestCache", "GetFieldForDispatch",
	"AdjustArgumentsDesciptorForImplicitClosure",
	"ClosureArgumentsValid", "ResolveCallFunction",
	"InterpretedInstanceCallMissHandler",
	"InvokeNoSuchMethod", "ResumeInterpreter",
	// LEAF_RUNTIME_ENTRY_LIST (36) — RememberCard and ExitSafepointIgnoreUnwindInProgress removed
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "OldMarkingStackBlockProcess", "NewMarkingStackBlockProcess",
	"EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFmod",
	"LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"PropagateError", "MsanUnpoison", "MsanUnpoisonParam",
	"TsanLoadAcquire", "TsanStoreRelease",
	"TryDoubleAsInteger", "MemoryMove",
}

// v3.9.2: 77 RUNTIME + 36 LEAF = 113 entries from 0x2f0 to 0x678 (exclusive).
// Delta from v3.8.1: -TraceICCall, +StaticFieldAccessedWithoutIsolateError,
// +ThrowIfValueCantBeShared, +ConvertToInstanceTypeArguments, +ResolveExternalCall,
// +InitializeSharedField. LEAF identical to v3.8.1.
var runtimeEntriesV392 = []string{
	// RUNTIME_ENTRY_LIST (77)
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "AllocateRecord", "AllocateSmallRecord",
	"AllocateSuspendState", "BoxDouble", "BoxFloat32x4", "BoxFloat64x2",
	"BreakpointRuntimeHandler", "SingleStepHandler",
	"CloneContext", "CloneSuspendState",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue",
	"OptimizeInvokedFunction", "PatchStaticCall",
	"RangeError", "RangeErrorUnboxedInt64", "WriteError",
	"NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "InterruptOrStackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"StaticFieldAccessedWithoutIsolateError", "ThrowIfValueCantBeShared",
	"LateFieldAlreadyInitializedError",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "ResumeFrame", "SwitchableCallMiss", "NotLoaded",
	"FfiAsyncCallbackSend",
	"AllocateSubtypeTestCache", "GetFieldForDispatch",
	"AdjustArgumentsDesciptorForImplicitClosure",
	"ConvertToInstanceTypeArguments",
	"ClosureArgumentsValid", "ResolveCallFunction", "ResolveExternalCall",
	"InterpretedInstanceCallMissHandler",
	"InvokeNoSuchMethod", "ResumeInterpreter", "InitializeSharedField",
	// LEAF_RUNTIME_ENTRY_LIST (36) — identical to v3.8.1
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "OldMarkingStackBlockProcess", "NewMarkingStackBlockProcess",
	"EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFmod",
	"LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"PropagateError", "MsanUnpoison", "MsanUnpoisonParam",
	"TsanLoadAcquire", "TsanStoreRelease",
	"TryDoubleAsInteger", "MemoryMove",
}

// v3.10.7: 81 RUNTIME entries from 0x2e8 to 0x570 (exclusive). No LEAF in block.
var runtimeEntriesV3107 = []string{
	// RUNTIME_ENTRY_LIST (81)
	"AllocateArray", "AllocateMint", "AllocateDouble", "AllocateFloat32x4",
	"AllocateFloat64x2", "AllocateInt32x4", "AllocateTypedData", "AllocateClosure",
	"AllocateContext", "AllocateObject", "AllocateRecord", "AllocateSmallRecord",
	"AllocateSuspendState", "BoxDouble", "BoxFloat32x4", "BoxFloat64x2",
	"BreakpointRuntimeHandler", "SingleStepHandler", "ResumptionBreakpointHandler",
	"CloneContext", "CloneSuspendState",
	"DoubleToInteger", "FixCallersTarget", "FixCallersTargetMonomorphic",
	"FixAllocationStubTarget", "InlineCacheMissHandlerOneArg", "InlineCacheMissHandlerTwoArgs",
	"StaticCallMissHandlerOneArg", "StaticCallMissHandlerTwoArgs",
	"Instanceof", "SubtypeCheck", "TypeCheck",
	"InstantiateType", "InstantiateTypeArguments",
	"NoSuchMethodFromCallStub", "NoSuchMethodFromPrologue", "NoSuchMethodError",
	"OptimizeInvokedFunction", "PatchStaticCall",
	"RangeError", "RangeErrorUnboxedInt64", "WriteError",
	"NullError", "NullErrorWithSelector", "NullCastError",
	"ArgumentNullError", "DispatchTableNullError", "ArgumentError",
	"ArgumentErrorUnboxedInt64", "IntegerDivisionByZeroException",
	"ReThrow", "InterruptOrStackOverflow", "Throw",
	"DeoptimizeMaterialize", "RewindPostDeopt", "UpdateFieldCid",
	"InitInstanceField", "InitStaticField",
	"StaticFieldAccessedWithoutIsolateError", "ThrowIfValueCantBeShared",
	"LateFieldAlreadyInitializedError",
	"LateFieldAssignedDuringInitializationError", "LateFieldNotInitializedError",
	"CompileFunction", "ResumeFrame", "SwitchableCallMiss", "NotLoaded",
	"FfiAsyncCallbackSend", "AllocateSubtypeTestCache", "GetFieldForDispatch",
	"AdjustArgumentsDescriptorForImplicitClosure", "ConvertToInstanceTypeArguments",
	"ClosureArgumentsValid", "ResolveCallFunction", "ResolveExternalCall",
	"FfiCall", "CheckFunctionArgumentTypes",
	"InterpretedInstanceCallMissHandler",
	"InvokeNoSuchMethod", "ResumeInterpreter", "InitializeSharedField",
}

// v3.10.7: 50 LEAF entries stored in separate block at 0x6f8 (after exit_through_ffi at 0x6f0).
// In v3.10.7, LEAF entries moved from the main runtime entry block to their own block.
// Source: dartsdk/v3.10.7/runtime/vm/thread.h:1512-1514 (LEAF_RUNTIME_ENTRY_LIST(DECLARE_MEMBERS))
var leafEntriesV3107 = []string{
	"DeoptimizeCopyFrame", "DeoptimizeFillFrame",
	"StoreBufferBlockProcess", "OldMarkingStackBlockProcess", "NewMarkingStackBlockProcess",
	"EnsureRememberedAndMarkingDeferred",
	"LibcPow", "DartModulo", "LibcFmod",
	"LibcFloor", "LibcCeil", "LibcTrunc", "LibcRound",
	"LibcCos", "LibcSin", "LibcTan", "LibcAcos", "LibcAsin", "LibcAtan",
	"LibcAtan2", "LibcExp", "LibcLog",
	"CaseInsensitiveCompareUCS2", "CaseInsensitiveCompareUTF16",
	"EnterSafepoint", "ExitSafepoint",
	"EnterHandleScope", "ExitHandleScope", "AllocateHandle",
	"PropagateError", "MsanUnpoison", "MsanUnpoisonParam",
	"TsanAtomic32Load", "TsanAtomic32Store", "TsanAtomic64Load", "TsanAtomic64Store",
	"TsanRead1", "TsanRead2", "TsanRead4", "TsanRead8", "TsanRead16",
	"TsanWrite1", "TsanWrite2", "TsanWrite4", "TsanWrite8", "TsanWrite16",
	"TsanFuncEntry", "TsanFuncExit",
	"TryDoubleAsInteger", "MemoryMove",
}

func init() {
	mergeRuntimeEntries(thrV217, 0x2d8, runtimeEntriesV217)
	mergeRuntimeEntries(thrV325, 0x2c8, runtimeEntriesV325)
	mergeRuntimeEntries(thrV343, 0x2d0, runtimeEntriesV343)
	mergeRuntimeEntries(thrV362, 0x2e8, runtimeEntriesV362)
	mergeRuntimeEntries(thrV381, 0x2e0, runtimeEntriesV381)
	mergeRuntimeEntries(thrV392, 0x2f0, runtimeEntriesV392)
	mergeRuntimeEntries(thrV3107, 0x2e8, runtimeEntriesV3107)
	mergeRuntimeEntries(thrV3107, 0x6f8, leafEntriesV3107) // LEAF block after exit_through_ffi
}

// mergeRuntimeEntries adds computed runtime entry point names to a THR field map.
// base is the offset of the first entry (AllocateArray). Each subsequent entry is +8.
func mergeRuntimeEntries(m map[int]string, base int, names []string) {
	for i, name := range names {
		off := base + i*8
		if _, exists := m[off]; !exists {
			m[off] = name + "_ep"
		}
	}
}

```

`internal/disasm/thrfields_test.go`:

```go
package disasm

import (
	"fmt"
	"testing"
)

func TestRuntimeEntryMerge(t *testing.T) {
	fields := THRFields("3.10.7")

	// Check a few runtime entry offsets.
	checks := []struct {
		off  int
		want string
	}{
		{0x2e8, "AllocateArray_ep"},
		{0x2f0, "AllocateMint_ep"},
		{0x2f8, "AllocateDouble_ep"},
		{0x468, "ArgumentErrorUnboxedInt64_ep"},
		{0x470, "IntegerDivisionByZeroException_ep"},
		{0x478, "ReThrow_ep"},
		{0x568, "InitializeSharedField_ep"},
	}
	for _, c := range checks {
		t.Run(fmt.Sprintf("0x%x", c.off), func(t *testing.T) {
			got, ok := fields[c.off]
			if !ok {
				t.Fatalf("offset 0x%x not in map", c.off)
			}
			if got != c.want {
				t.Errorf("0x%x = %q, want %q", c.off, got, c.want)
			}
		})
	}

	// Verify static entries not overwritten.
	if got := fields[0x48]; got != "stack_limit" {
		t.Errorf("stack_limit = %q", got)
	}

	t.Logf("Total v3.10.7 entries: %d", len(fields))
}

func TestRuntimeEntryV217Merge(t *testing.T) {
	fields := THRFields("2.17.6")

	// v2.17.6 base 0x2d8 = AllocateArray
	checks := []struct {
		off  int
		want string
	}{
		{0x2d8, "AllocateArray_ep"},
		{0x2e0, "AllocateMint_ep"},
		{0x488, "NotLoaded_ep"},
		// LEAF entries
		{0x490, "DeoptimizeCopyFrame_ep"},
		{0x580, "TsanStoreRelease_ep"},
	}
	for _, c := range checks {
		t.Run(fmt.Sprintf("0x%x", c.off), func(t *testing.T) {
			got, ok := fields[c.off]
			if !ok {
				t.Fatalf("offset 0x%x not in map", c.off)
			}
			if got != c.want {
				t.Errorf("0x%x = %q, want %q", c.off, got, c.want)
			}
		})
	}

	t.Logf("Total v2.17.6 entries: %d", len(fields))
}

func TestTHRContextAnnotator_RuntimeEntry(t *testing.T) {
	fields := THRFields("3.10.7")

	// LDR X5, [X26,#1128] → 0x468 → ArgumentErrorUnboxedInt64_ep
	// Raw encoding: 45 37 42 f9 = 0xf9423745
	raw := uint32(0xf9423745)

	insts := []Inst{
		{Addr: 0x1000, Raw: 0xd503201f, Text: "NOP"}, // padding
		{Addr: 0x1004, Raw: raw, Text: "LDR X5, [X26,#1128]"},
		{Addr: 0x1008, Raw: 0xd503201f, Text: "NOP"}, // padding
	}

	ann := THRContextAnnotator(insts, fields)
	got := ann(insts[1])
	want := "THR.ArgumentErrorUnboxedInt64_ep"
	if got != want {
		t.Errorf("THRContextAnnotator(0x468) = %q, want %q", got, want)
	}
}

```

`internal/elfx/elfx.go`:

```go
// Package elfx provides ELF loading helpers for Dart AOT libapp.so files.
package elfx

import (
	"debug/elf"
	"encoding/binary"
	"errors"
	"fmt"
	"io"
	"os"
)

var (
	ErrNotELF       = errors.New("elfx: not an ELF file")
	ErrNotARM64     = errors.New("elfx: not ARM64 (EM_AARCH64)")
	ErrNotShared    = errors.New("elfx: not a shared object")
	ErrNot64Bit     = errors.New("elfx: not 64-bit ELF")
	ErrNoSymbol     = errors.New("elfx: symbol not found")
	ErrNoSegment    = errors.New("elfx: no PT_LOAD segment covers address")
	ErrSymbolNoSize = errors.New("elfx: symbol has zero size")
)

// File wraps a debug/elf.File with convenience methods for Dart AOT analysis.
type File struct {
	ELF  *elf.File
	raw  io.ReaderAt
	size int64
}

// Open opens an ELF file and validates it is an ARM64 shared object.
func Open(path string) (*File, error) {
	f, err := os.Open(path)
	if err != nil {
		return nil, fmt.Errorf("elfx: open: %w", err)
	}

	info, err := f.Stat()
	if err != nil {
		f.Close()
		return nil, fmt.Errorf("elfx: stat: %w", err)
	}

	ef, err := elf.NewFile(f)
	if err != nil {
		f.Close()
		return nil, fmt.Errorf("%w: %v", ErrNotELF, err)
	}

	if ef.Class != elf.ELFCLASS64 {
		ef.Close()
		return nil, ErrNot64Bit
	}
	if ef.Machine != elf.EM_AARCH64 {
		ef.Close()
		return nil, ErrNotARM64
	}
	if ef.Type != elf.ET_DYN {
		ef.Close()
		return nil, ErrNotShared
	}

	return &File{ELF: ef, raw: f, size: info.Size()}, nil
}

// Close releases resources.
func (f *File) Close() error {
	return f.ELF.Close()
}

// FileSize returns the size of the underlying file.
func (f *File) FileSize() int64 { return f.size }

// Symbol looks up a dynamic symbol by exact name.
// Returns the symbol's virtual address and size.
func (f *File) Symbol(name string) (addr, size uint64, err error) {
	syms, err := f.ELF.DynamicSymbols()
	if err != nil {
		return 0, 0, fmt.Errorf("elfx: dynsym: %w", err)
	}
	for _, s := range syms {
		if s.Name == name {
			return s.Value, s.Size, nil
		}
	}
	return 0, 0, fmt.Errorf("%w: %s", ErrNoSymbol, name)
}

// VAToFileOffset converts a virtual address to a file offset using PT_LOAD segments.
func (f *File) VAToFileOffset(va uint64) (uint64, error) {
	for _, p := range f.ELF.Progs {
		if p.Type != elf.PT_LOAD {
			continue
		}
		if va >= p.Vaddr && va < p.Vaddr+p.Memsz {
			offset := va - p.Vaddr + p.Off
			if offset >= uint64(f.size) {
				return 0, fmt.Errorf("elfx: VA 0x%x maps to offset 0x%x beyond file size 0x%x", va, offset, f.size)
			}
			return offset, nil
		}
	}
	return 0, fmt.Errorf("%w: VA 0x%x", ErrNoSegment, va)
}

// ReadAt reads bytes from the underlying file at the given file offset.
func (f *File) ReadAt(buf []byte, off int64) (int, error) {
	return f.raw.ReadAt(buf, off)
}

// ReadBytesAtVA reads n bytes starting at the given virtual address.
func (f *File) ReadBytesAtVA(va uint64, n int) ([]byte, error) {
	off, err := f.VAToFileOffset(va)
	if err != nil {
		return nil, err
	}
	// Clamp to file size.
	avail := f.size - int64(off)
	if avail <= 0 {
		return nil, fmt.Errorf("elfx: offset 0x%x at or past end of file", off)
	}
	if int64(n) > avail {
		n = int(avail)
	}
	buf := make([]byte, n)
	_, err = f.raw.ReadAt(buf, int64(off))
	if err != nil && !errors.Is(err, io.EOF) {
		return nil, fmt.Errorf("elfx: read at 0x%x: %w", off, err)
	}
	return buf, nil
}

// SegmentInfo describes a PT_LOAD segment.
type SegmentInfo struct {
	Vaddr  uint64
	Memsz  uint64
	Filesz uint64
	Offset uint64
	Flags  elf.ProgFlag
}

// LoadSegments returns all PT_LOAD segments.
func (f *File) LoadSegments() []SegmentInfo {
	var segs []SegmentInfo
	for _, p := range f.ELF.Progs {
		if p.Type != elf.PT_LOAD {
			continue
		}
		segs = append(segs, SegmentInfo{
			Vaddr:  p.Vaddr,
			Memsz:  p.Memsz,
			Filesz: p.Filesz,
			Offset: p.Off,
			Flags:  p.Flags,
		})
	}
	return segs
}

// ByteOrder returns the ELF byte order.
func (f *File) ByteOrder() binary.ByteOrder {
	return f.ELF.ByteOrder
}

```

`internal/elfx/elfx_test.go`:

```go
package elfx

import (
	"os"
	"path/filepath"
	"testing"
)

func findSample(t *testing.T, name string) string {
	t.Helper()
	// Walk up to find samples/ directory.
	dir, _ := os.Getwd()
	for {
		p := filepath.Join(dir, "samples", name)
		if _, err := os.Stat(p); err == nil {
			return p
		}
		parent := filepath.Dir(dir)
		if parent == dir {
			t.Skipf("sample %s not found", name)
		}
		dir = parent
	}
}

func TestOpenValid(t *testing.T) {
	path := findSample(t, "blutter-lce.so")
	ef, err := Open(path)
	if err != nil {
		t.Fatal(err)
	}
	defer ef.Close()

	if ef.FileSize() == 0 {
		t.Error("file size is 0")
	}
}

func TestOpenRejectsNonELF(t *testing.T) {
	// Create a temp file with garbage data.
	tmp := filepath.Join(t.TempDir(), "notelf")
	if err := os.WriteFile(tmp, []byte("not an ELF file at all"), 0644); err != nil {
		t.Fatal(err)
	}
	_, err := Open(tmp)
	if err == nil {
		t.Fatal("expected error for non-ELF file")
	}
}

func TestSymbolLookup(t *testing.T) {
	path := findSample(t, "blutter-lce.so")
	ef, err := Open(path)
	if err != nil {
		t.Fatal(err)
	}
	defer ef.Close()

	va, size, err := ef.Symbol("_kDartVmSnapshotData")
	if err != nil {
		t.Fatal(err)
	}
	if va == 0 {
		t.Error("VA is 0")
	}
	if size == 0 {
		t.Error("size is 0")
	}
}

func TestSymbolNotFound(t *testing.T) {
	path := findSample(t, "blutter-lce.so")
	ef, err := Open(path)
	if err != nil {
		t.Fatal(err)
	}
	defer ef.Close()

	_, _, err = ef.Symbol("_kNonExistentSymbol")
	if err == nil {
		t.Fatal("expected error for missing symbol")
	}
}

func TestVAToFileOffset(t *testing.T) {
	path := findSample(t, "blutter-lce.so")
	ef, err := Open(path)
	if err != nil {
		t.Fatal(err)
	}
	defer ef.Close()

	// The first PT_LOAD segment typically has vaddr=0 and offset=0,
	// so VA should equal file offset for addresses in that segment.
	va, _, err := ef.Symbol("_kDartVmSnapshotData")
	if err != nil {
		t.Fatal(err)
	}
	off, err := ef.VAToFileOffset(va)
	if err != nil {
		t.Fatal(err)
	}
	// For this sample, VA == file offset (first segment).
	if off != va {
		t.Logf("VA=0x%x FileOff=0x%x (different, which may be valid for non-zero-based segments)", va, off)
	}
}

func TestVAToFileOffsetInvalid(t *testing.T) {
	path := findSample(t, "blutter-lce.so")
	ef, err := Open(path)
	if err != nil {
		t.Fatal(err)
	}
	defer ef.Close()

	_, err = ef.VAToFileOffset(0xDEADBEEFDEADBEEF)
	if err == nil {
		t.Fatal("expected error for invalid VA")
	}
}

func TestLoadSegments(t *testing.T) {
	path := findSample(t, "blutter-lce.so")
	ef, err := Open(path)
	if err != nil {
		t.Fatal(err)
	}
	defer ef.Close()

	segs := ef.LoadSegments()
	if len(segs) == 0 {
		t.Fatal("no PT_LOAD segments")
	}
	for _, s := range segs {
		if s.Filesz == 0 && s.Memsz == 0 {
			t.Error("segment with zero size")
		}
	}
}

func FuzzELFOpen(f *testing.F) {
	// Seed with a valid ELF header prefix and garbage.
	f.Add([]byte("\x7fELF\x02\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00"))
	f.Add([]byte("not an elf at all"))
	f.Add([]byte{})

	f.Fuzz(func(t *testing.T, data []byte) {
		tmp := filepath.Join(t.TempDir(), "fuzz.so")
		if err := os.WriteFile(tmp, data, 0644); err != nil {
			t.Fatal(err)
		}
		ef, err := Open(tmp)
		if err != nil {
			return // expected
		}
		// If it opens, exercise the API.
		ef.FileSize()
		ef.LoadSegments()
		ef.Symbol("_kDartVmSnapshotData")
		ef.VAToFileOffset(0)
		ef.Close()
	})
}

```

`internal/output/output.go`:

```go
// Package output writes unflutter analysis results to files.
package output

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"

	"unflutter/internal/disasm"
	"unflutter/internal/snapshot"
)

// WriteSnapshotJSON writes snapshot metadata to snapshot.json.
func WriteSnapshotJSON(dir string, info *snapshot.Info) error {
	return writeJSON(filepath.Join(dir, "snapshot.json"), info)
}

// SymbolEntry represents a named code address.
type SymbolEntry struct {
	Address uint64 `json:"address"`
	Name    string `json:"name"`
	Size    uint64 `json:"size,omitempty"`
}

// WriteSymbolsJSON writes symbols to symbols.json.
func WriteSymbolsJSON(dir string, symbols []SymbolEntry) error {
	return writeJSON(filepath.Join(dir, "symbols.json"), symbols)
}

// WriteASM writes disassembled instructions to asm/<name>.txt.
// name may contain path separators (e.g., "OwnerClass/func_hex") for directory grouping.
func WriteASM(dir string, name string, insts []disasm.Inst, lookup disasm.SymbolLookup, annotators ...disasm.Annotator) error {
	path := filepath.Join(dir, "asm", name+".txt")
	if err := os.MkdirAll(filepath.Dir(path), 0755); err != nil {
		return fmt.Errorf("output: mkdir asm: %w", err)
	}

	text := disasm.Format(insts, lookup, annotators...)
	return os.WriteFile(path, []byte(text), 0644)
}

// WriteASMSingle writes all instructions to a single asm.txt file.
func WriteASMSingle(dir string, insts []disasm.Inst, lookup disasm.SymbolLookup, annotators ...disasm.Annotator) error {
	path := filepath.Join(dir, "asm.txt")
	text := disasm.Format(insts, lookup, annotators...)
	return os.WriteFile(path, []byte(text), 0644)
}

// WriteBin writes raw instruction bytes to asm/<name>.bin for CFG construction.
// name may contain path separators (e.g., "OwnerClass/func_hex") for directory grouping.
func WriteBin(dir string, name string, data []byte) error {
	path := filepath.Join(dir, "asm", name+".bin")
	if err := os.MkdirAll(filepath.Dir(path), 0755); err != nil {
		return fmt.Errorf("output: mkdir asm: %w", err)
	}
	return os.WriteFile(path, data, 0644)
}

func writeJSON(path string, v any) error {
	f, err := os.Create(path)
	if err != nil {
		return fmt.Errorf("output: create %s: %w", path, err)
	}
	defer f.Close()

	enc := json.NewEncoder(f)
	enc.SetIndent("", "  ")
	if err := enc.Encode(v); err != nil {
		return fmt.Errorf("output: encode %s: %w", path, err)
	}
	return nil
}

```

`internal/pipeline/disasm_stage.go`:

```go
package pipeline

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strconv"
	"strings"

	"github.com/zboralski/lattice"
	"github.com/zboralski/lattice/render"
	"unflutter/internal/callgraph"
	"unflutter/internal/cli"
	"unflutter/internal/cluster"
	"unflutter/internal/disasm"
	"unflutter/internal/output"
	"unflutter/internal/snapshot"
)

// DisasmResult holds summary stats from the disassembly stage.
type DisasmResult struct {
	Written        int
	TotalEdges     int
	TotalBLR       int
	BLRAnnotated   int
	BLRUnannotated int
	TotalUnresTHR  int
	TotalStringRefs int
	CFGCount       int
}

// RunDisasmStage executes the per-function disassembly loop.
func RunDisasmStage(
	opts *Opts,
	pl *PoolLookups,
	poolDisplay map[int]string,
	clResult *cluster.Result,
	ranges []cluster.CodeRange,
	code []byte,
	codeOff uint64,
	codeVA uint64,
	thrFields map[int]string,
	info *snapshot.Info,
) (*DisasmResult, error) {
	// Build symbol map for cross-references during disassembly.
	symbols := make(map[uint64]string)
	for _, r := range ranges {
		va := codeVA + uint64(r.PCOffset) - codeOff
		if r.RefID >= 0 {
			symbols[va] = QualifiedCodeName(r.RefID, pl, r.PCOffset)
		} else {
			symbols[va] = fmt.Sprintf("stub_%x", r.PCOffset)
		}
	}
	lookup := disasm.PlaceholderLookup(symbols)

	ppAnn := disasm.PPAnnotator(poolDisplay)
	peephole := disasm.NewPeepholeState(poolDisplay)

	opts.stagef("disasm", "%s%d%s functions, pool %s%d%s entries (%d resolved)",
		cli.Gold, len(ranges), cli.Reset, cli.Gold, len(clResult.Pool), cli.Reset, len(poolDisplay))

	// Create output directories.
	asmDir := filepath.Join(opts.OutDir, "asm")
	if err := os.MkdirAll(asmDir, 0755); err != nil {
		return nil, fmt.Errorf("mkdir asm: %w", err)
	}
	cfgDir := filepath.Join(opts.OutDir, "cfg")
	if opts.Graph {
		if err := os.MkdirAll(cfgDir, 0755); err != nil {
			return nil, fmt.Errorf("mkdir cfg: %w", err)
		}
	}

	// Limit function count.
	n := len(ranges)
	if opts.Limit > 0 && opts.Limit < n {
		n = opts.Limit
	}

	// Open all output files.
	indexFile, err := os.Create(filepath.Join(opts.OutDir, "index.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("create index: %w", err)
	}
	defer indexFile.Close()
	enc := json.NewEncoder(indexFile)
	enc.SetEscapeHTML(false)

	funcsFile, err := os.Create(filepath.Join(opts.OutDir, "functions.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("create functions.jsonl: %w", err)
	}
	defer funcsFile.Close()
	funcsEnc := json.NewEncoder(funcsFile)
	funcsEnc.SetEscapeHTML(false)

	edgesFile, err := os.Create(filepath.Join(opts.OutDir, "call_edges.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("create call_edges.jsonl: %w", err)
	}
	defer edgesFile.Close()
	edgesEnc := json.NewEncoder(edgesFile)
	edgesEnc.SetEscapeHTML(false)

	unresTHRFile, err := os.Create(filepath.Join(opts.OutDir, "unresolved_thr.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("create unresolved_thr.jsonl: %w", err)
	}
	defer unresTHRFile.Close()
	unresTHREnc := json.NewEncoder(unresTHRFile)
	unresTHREnc.SetEscapeHTML(false)

	stringRefsFile, err := os.Create(filepath.Join(opts.OutDir, "string_refs.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("create string_refs.jsonl: %w", err)
	}
	defer stringRefsFile.Close()
	stringRefsEnc := json.NewEncoder(stringRefsFile)
	stringRefsEnc.SetEscapeHTML(false)

	dr := &DisasmResult{}
	var funcInfos []callgraph.FuncInfo

	for i := 0; i < n; i++ {
		r := &ranges[i]
		if r.Size == 0 {
			continue
		}

		// Slice code bytes for this function.
		funcStart := uint64(r.PCOffset) - codeOff
		funcEnd := funcStart + uint64(r.Size)
		if funcEnd > uint64(len(code)) {
			funcEnd = uint64(len(code))
		}
		if funcStart >= funcEnd {
			continue
		}
		funcCode := code[funcStart:funcEnd]
		funcVA := codeVA + funcStart

		// Resolve name.
		var funcName, ownerName, name string
		if r.RefID >= 0 {
			ci := pl.CodeNames[r.RefID]
			funcName = ci.FuncName
			ownerName = ci.OwnerName
			name = QualifiedName(ownerName, funcName, r.PCOffset)
		} else {
			funcName = fmt.Sprintf("stub_%x", r.PCOffset)
			name = funcName
		}

		// Disassemble.
		peephole.Reset()
		insts := disasm.Disassemble(funcCode, disasm.Options{
			BaseAddr: funcVA,
			Symbols:  lookup,
		})

		// Build per-function annotators.
		thrCtxAnn := disasm.THRContextAnnotator(insts, thrFields)
		annotators := []disasm.Annotator{ppAnn, thrCtxAnn, peephole.Annotate}

		// Write asm file.
		filename := FuncRelPath(ownerName, funcName, r.PCOffset)
		if err := output.WriteASM(opts.OutDir, filename, insts, lookup, annotators...); err != nil {
			return nil, fmt.Errorf("write asm %s: %w", filename, err)
		}

		// Write raw bytes for CFG construction.
		if err := output.WriteBin(opts.OutDir, filename, funcCode); err != nil {
			return nil, fmt.Errorf("write bin %s: %w", filename, err)
		}

		// Write index entry.
		entry := DisasmIndexEntry{
			Name:      funcName,
			OwnerName: ownerName,
			RefID:     r.RefID,
			OwnerRef:  r.OwnerRef,
			PCOffset:  r.PCOffset,
			Size:      r.Size,
			File:      filepath.ToSlash(filepath.Join("asm", filename+".txt")),
		}
		if err := enc.Encode(entry); err != nil {
			return nil, fmt.Errorf("write index: %w", err)
		}

		// Emit functions.jsonl entry.
		var paramCount int
		if r.RefID >= 0 {
			paramCount = pl.CodeNames[r.RefID].ParamCount
		}
		funcRec := disasm.FuncRecord{
			PC:         fmt.Sprintf("0x%x", funcVA),
			Size:       int(r.Size),
			Name:       name,
			Owner:      ownerName,
			ParamCount: paramCount,
		}
		if err := funcsEnc.Encode(funcRec); err != nil {
			return nil, fmt.Errorf("write functions.jsonl: %w", err)
		}

		// Extract call edges.
		edges := disasm.ExtractCallEdges(insts, lookup, annotators, 8)
		for _, e := range edges {
			rec := disasm.CallEdgeRecord{
				FromFunc: name,
				FromPC:   fmt.Sprintf("0x%x", e.FromPC),
				Kind:     e.Kind,
				Reg:      e.Reg,
				Via:      e.Via,
			}
			if e.Kind == "bl" {
				if e.TargetName != "" {
					rec.Target = e.TargetName
				} else {
					rec.Target = fmt.Sprintf("0x%x", e.TargetPC)
				}
			}
			if err := edgesEnc.Encode(rec); err != nil {
				return nil, fmt.Errorf("write call_edges.jsonl: %w", err)
			}
			dr.TotalEdges++
			if e.Kind == "blr" {
				dr.TotalBLR++
				if e.Via != "" {
					dr.BLRAnnotated++
				} else {
					dr.BLRUnannotated++
				}
			}
		}

		// Build per-function CFG DOT and accumulate for call graph.
		if opts.Graph {
			lcfg, nblocks := callgraph.BuildFuncCFG(name, insts, edges)
			if nblocks > 1 {
				g := &lattice.CFGGraph{Funcs: []*lattice.FuncCFG{lcfg}}
				dot := render.DOTCFG(g, name)
				dotPath := filepath.Join(cfgDir, filename+".dot")
				if err := os.MkdirAll(filepath.Dir(dotPath), 0755); err != nil {
					return nil, fmt.Errorf("mkdir cfg: %w", err)
				}
				if err := os.WriteFile(dotPath, []byte(dot), 0644); err != nil {
					return nil, fmt.Errorf("write cfg dot %s: %w", filename, err)
				}
				dr.CFGCount++
			}
			funcInfos = append(funcInfos, callgraph.FuncInfo{
				Name:      name,
				CallEdges: edges,
			})
		}

		// Extract string references from PP loads.
		stringRefs := ExtractStringRefs(insts, poolDisplay, name)
		for _, sr := range stringRefs {
			if err := stringRefsEnc.Encode(sr); err != nil {
				return nil, fmt.Errorf("write string_refs.jsonl: %w", err)
			}
			dr.TotalStringRefs++
		}

		// Extract unresolved THR accesses.
		thrAccesses := disasm.ExtractTHRAccesses(insts, thrFields)
		for _, a := range thrAccesses {
			if a.Resolved {
				continue
			}
			rec := disasm.UnresolvedTHRRecord{
				FuncName:  name,
				PC:        fmt.Sprintf("0x%x", a.PC),
				THROffset: fmt.Sprintf("0x%x", a.THROffset),
				Width:     a.Width,
				IsStore:   a.IsStore,
				Class:     "UNKNOWN",
			}
			if ann := thrCtxAnn(disasm.Inst{Addr: a.PC, Raw: 0}); ann != "" {
				switch {
				case strings.Contains(ann, "RUNTIME_ENTRY"):
					rec.Class = "RUNTIME_ENTRY"
				case strings.Contains(ann, "OBJSTORE"):
					rec.Class = "OBJSTORE"
				case strings.Contains(ann, "ISO_GROUP"):
					rec.Class = "ISO_GROUP"
				case strings.HasPrefix(ann, "THR."):
					continue
				}
			}
			if err := unresTHREnc.Encode(rec); err != nil {
				return nil, fmt.Errorf("write unresolved_thr.jsonl: %w", err)
			}
			dr.TotalUnresTHR++
		}

		dr.Written++
	}

	opts.logf("  %sfunctions:%s %d -> %s%s%s\n", cli.Muted, cli.Reset, dr.Written, cli.Blue, asmDir, cli.Reset)
	opts.logf("  %scall edges:%s %d (%d BLR: %d annotated, %d unannotated)\n",
		cli.Muted, cli.Reset, dr.TotalEdges, dr.TotalBLR, dr.BLRAnnotated, dr.BLRUnannotated)
	opts.logf("  %sstring refs:%s %d\n", cli.Muted, cli.Reset, dr.TotalStringRefs)
	if dr.TotalBLR > 0 {
		pct := float64(dr.BLRAnnotated) / float64(dr.TotalBLR) * 100
		opts.logf("  %sBLR annotation:%s %.1f%%\n", cli.Muted, cli.Reset, pct)
	}

	// Build call graph.
	if opts.Graph && len(funcInfos) > 0 {
		cg := callgraph.BuildCallGraph(funcInfos)
		cgDOT := render.DOT(cg, "callgraph")
		cgPath := filepath.Join(opts.OutDir, "callgraph.dot")
		if err := os.WriteFile(cgPath, []byte(cgDOT), 0644); err != nil {
			return nil, fmt.Errorf("write callgraph.dot: %w", err)
		}
		opts.logf("  %scallgraph:%s %d nodes, %d edges -> %s%s%s\n",
			cli.Muted, cli.Reset, len(cg.Nodes), len(cg.Edges), cli.Blue, cgPath, cli.Reset)
		opts.logf("  %sCFG DOTs:%s %d -> %s%s%s\n", cli.Muted, cli.Reset, dr.CFGCount, cli.Blue, cfgDir, cli.Reset)
	}

	return dr, nil
}

// ExtractStringRefs scans instructions for PP loads that resolve to string values.
func ExtractStringRefs(insts []disasm.Inst, poolDisplay map[int]string, funcName string) []disasm.StringRefRecord {
	var refs []disasm.StringRefRecord
	peep := disasm.NewPeepholeState(poolDisplay)

	for _, inst := range insts {
		// Check single-instruction PP load: LDR Xt, [X27, #imm]
		if baseReg, byteOff, ok := disasm.IsLDR64UnsignedOffsetExported(inst.Raw); ok && baseReg == 27 {
			idx := byteOff / 8
			if s, found := poolDisplay[idx]; found && len(s) > 0 && s[0] == '"' {
				val, err := strconv.Unquote(s)
				if err == nil {
					refs = append(refs, disasm.StringRefRecord{
						Func:    funcName,
						PC:      fmt.Sprintf("0x%x", inst.Addr),
						Kind:    "PP",
						PoolIdx: idx,
						Value:   val,
					})
				}
			}
		}

		// Check two-instruction peephole: ADD Xd, X27, #upper + LDR Xt, [Xd, #lower]
		ann := peep.Annotate(inst)
		if ann != "" && strings.HasPrefix(ann, "PP[") {
			closeBracket := strings.IndexByte(ann, ']')
			if closeBracket > 3 {
				idxStr := ann[3:closeBracket]
				idx, err := strconv.Atoi(idxStr)
				if err == nil {
					rest := strings.TrimSpace(ann[closeBracket+1:])
					if len(rest) > 0 && rest[0] == '"' {
						val, err := strconv.Unquote(rest)
						if err == nil {
							refs = append(refs, disasm.StringRefRecord{
								Func:    funcName,
								PC:      fmt.Sprintf("0x%x", inst.Addr),
								Kind:    "PP_peep",
								PoolIdx: idx,
								Value:   val,
							})
						}
					}
				}
			}
		}
	}
	return refs
}

```

`internal/pipeline/helpers.go`:

```go
package pipeline

import (
	"bufio"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strconv"
	"strings"

	"unflutter/internal/cluster"
	"unflutter/internal/snapshot"
)

// CodeNameInfo holds resolved function and owner names for a code ref.
type CodeNameInfo struct {
	FuncName   string
	OwnerName  string
	ParamCount int // total visible parameters (fixed + optional, excluding implicit 'this')
}

// PoolLookups holds the lookup maps needed for pool entry resolution.
type PoolLookups struct {
	RefToStr       map[int]string
	RefToNamed     map[int]*cluster.NamedObject
	RefCID         map[int]int
	CodeRefDisplay map[int]string
	CodeNames      map[int]CodeNameInfo
	VmRefToStr     map[int]string // VM snapshot strings by ref ID
	VmRefCID       map[int]int    // VM snapshot CID by ref ID
	VmRefToNamed   map[int]*cluster.NamedObject
	CT             *snapshot.CIDTable
	BaseObjLimit   int
}

// BuildPoolLookups builds the lookup maps from a fill result.
// vmResult is optional — if non-nil, VM snapshot strings/names are used to resolve base object refs.
func BuildPoolLookups(result *cluster.Result, ct *snapshot.CIDTable, vmResult *cluster.Result) *PoolLookups {
	l := &PoolLookups{
		RefToStr:       make(map[int]string),
		RefToNamed:     make(map[int]*cluster.NamedObject),
		RefCID:         make(map[int]int),
		CodeRefDisplay: make(map[int]string),
		VmRefToStr:     make(map[int]string),
		VmRefCID:       make(map[int]int),
		VmRefToNamed:   make(map[int]*cluster.NamedObject),
		CT:             ct,
		BaseObjLimit:   int(result.Header.NumBaseObjects) + 1,
	}

	for _, ps := range result.Strings {
		l.RefToStr[ps.RefID] = ps.Value
	}
	for i := range result.Named {
		no := &result.Named[i]
		l.RefToNamed[no.RefID] = no
	}
	for _, cm := range result.Clusters {
		for ref := cm.StartRef; ref < cm.StopRef; ref++ {
			l.RefCID[ref] = cm.CID
		}
	}

	// Populate VM lookups from VM snapshot result.
	if vmResult != nil {
		for _, ps := range vmResult.Strings {
			l.VmRefToStr[ps.RefID] = ps.Value
		}
		for i := range vmResult.Named {
			no := &vmResult.Named[i]
			l.VmRefToNamed[no.RefID] = no
		}
		for _, cm := range vmResult.Clusters {
			for ref := cm.StartRef; ref < cm.StopRef; ref++ {
				l.VmRefCID[ref] = cm.CID
			}
		}
	}

	// Build FunctionType ref→info lookup for parameter count resolution.
	funcTypeByRef := make(map[int]*cluster.FuncTypeInfo, len(result.FuncTypes))
	for i := range result.FuncTypes {
		ft := &result.FuncTypes[i]
		funcTypeByRef[ft.RefID] = ft
	}

	// Build code ref→name.
	l.CodeNames = make(map[int]CodeNameInfo)
	for _, ce := range result.Codes {
		if ce.OwnerRef <= 0 {
			continue
		}
		owner, ok := l.RefToNamed[ce.OwnerRef]
		if !ok {
			continue
		}
		ci := CodeNameInfo{
			FuncName:  l.ResolveName(owner),
			OwnerName: l.ResolveOwnerName(owner),
		}
		// Follow Function→FunctionType chain for parameter count.
		if owner.SignatureRefID > 0 {
			if ft, ok := funcTypeByRef[owner.SignatureRefID]; ok {
				ci.ParamCount = ft.NumFixed + ft.NumOptional
			}
		}
		l.CodeNames[ce.RefID] = ci
	}
	for _, ce := range result.Codes {
		ci := l.CodeNames[ce.RefID]
		if ci.FuncName != "" {
			if ci.OwnerName != "" {
				l.CodeRefDisplay[ce.RefID] = ci.OwnerName + "." + ci.FuncName
			} else {
				l.CodeRefDisplay[ce.RefID] = ci.FuncName
			}
		}
	}

	return l
}

func (l *PoolLookups) ResolveName(no *cluster.NamedObject) string {
	if no.NameRefID >= 0 {
		if s, ok := l.RefToStr[no.NameRefID]; ok {
			return s
		}
	}
	return ""
}

func (l *PoolLookups) ResolveVMName(no *cluster.NamedObject) string {
	if no.NameRefID >= 0 {
		if s, ok := l.VmRefToStr[no.NameRefID]; ok {
			return s
		}
	}
	return ""
}

func (l *PoolLookups) ResolveOwnerName(no *cluster.NamedObject) string {
	if no.OwnerRefID < 0 {
		return ""
	}
	if owner, ok := l.RefToNamed[no.OwnerRefID]; ok {
		return l.ResolveName(owner)
	}
	return ""
}

// QualifiedCodeName returns "Owner.Func_hexaddr" for a code refID using PoolLookups.
func QualifiedCodeName(refID int, pl *PoolLookups, pcOffset uint32) string {
	ci := pl.CodeNames[refID]
	return QualifiedName(ci.OwnerName, ci.FuncName, pcOffset)
}

// ResolvePoolDisplay builds a map from pool entry index to display string.
func ResolvePoolDisplay(pool []cluster.PoolEntry, l *PoolLookups) map[int]string {
	display := make(map[int]string, len(pool))
	for _, pe := range pool {
		switch pe.Kind {
		case cluster.PoolTagged:
			if s, ok := l.RefToStr[pe.RefID]; ok {
				display[pe.Index] = fmt.Sprintf("%q", s)
			} else if no, ok := l.RefToNamed[pe.RefID]; ok {
				name := l.ResolveName(no)
				if name != "" {
					display[pe.Index] = name
				} else {
					display[pe.Index] = fmt.Sprintf("<%s>", cluster.CidNameV(no.CID, l.CT))
				}
			} else if fn, ok := l.CodeRefDisplay[pe.RefID]; ok {
				display[pe.Index] = fn
			} else if cidNum, ok := l.RefCID[pe.RefID]; ok {
				cidName := cluster.CidNameV(cidNum, l.CT)
				if cidName != "" {
					display[pe.Index] = fmt.Sprintf("<%s>", cidName)
				} else {
					display[pe.Index] = fmt.Sprintf("<Instance_%d>", cidNum)
				}
			} else if pe.RefID == 1 {
				display[pe.Index] = "null"
			} else if pe.RefID > 0 && pe.RefID < l.BaseObjLimit {
				// Try resolving from VM snapshot lookups.
				if s, ok := l.VmRefToStr[pe.RefID]; ok {
					display[pe.Index] = fmt.Sprintf("%q", s)
				} else if no, ok := l.VmRefToNamed[pe.RefID]; ok {
					name := l.ResolveVMName(no)
					if name != "" {
						display[pe.Index] = name
					} else {
						display[pe.Index] = fmt.Sprintf("<vm:%s>", cluster.CidNameV(no.CID, l.CT))
					}
				} else if cidNum, ok := l.VmRefCID[pe.RefID]; ok {
					cidName := cluster.CidNameV(cidNum, l.CT)
					if cidName != "" {
						display[pe.Index] = fmt.Sprintf("<vm:%s>", cidName)
					} else {
						display[pe.Index] = fmt.Sprintf("<vm:%d>", pe.RefID)
					}
				} else {
					display[pe.Index] = fmt.Sprintf("<vm:%d>", pe.RefID)
				}
			} else {
				display[pe.Index] = fmt.Sprintf("<ref:%d>", pe.RefID)
			}
		case cluster.PoolImmediate:
			display[pe.Index] = fmt.Sprintf("0x%x", pe.Imm)
		}
	}
	return display
}

// DartClassLayout is a resolved class definition ready for export.
type DartClassLayout struct {
	ClassName    string            `json:"class_name"`
	ClassID      int32             `json:"class_id"`
	InstanceSize int32             `json:"instance_size"`
	Fields       []DartFieldLayout `json:"fields"`
}

// DartFieldLayout is one field in a DartClassLayout.
type DartFieldLayout struct {
	Name       string `json:"name"`
	ByteOffset int32  `json:"byte_offset"`
}

// BuildClassLayouts joins ClassInfo + FieldInfo + string lookups into class layouts.
func BuildClassLayouts(result *cluster.Result, pl *PoolLookups, compressedPtrs bool) []DartClassLayout {
	var wordSize int32 = 8
	if compressedPtrs {
		wordSize = 4
	}

	classByRef := make(map[int]*cluster.ClassInfo, len(result.Classes))
	for i := range result.Classes {
		ci := &result.Classes[i]
		classByRef[ci.RefID] = ci
	}

	type resolvedField struct {
		nameRefID  int
		byteOffset int32
	}
	fieldsByOwner := make(map[int][]resolvedField)
	for _, fi := range result.Fields {
		if fi.OwnerRefID <= 0 || fi.HostOffset < 0 {
			continue
		}
		offsetRef := int(fi.HostOffset)
		wordOff, ok := result.MintValues[offsetRef]
		if !ok {
			continue
		}
		fieldsByOwner[fi.OwnerRefID] = append(fieldsByOwner[fi.OwnerRefID], resolvedField{
			nameRefID:  fi.NameRefID,
			byteOffset: int32(wordOff) * wordSize,
		})
	}

	var layouts []DartClassLayout
	for _, ci := range result.Classes {
		if ci.InstanceSize <= 0 {
			continue
		}
		className := ""
		if ci.NameRefID >= 0 {
			if s, ok := pl.RefToStr[ci.NameRefID]; ok {
				className = s
			}
		}
		if className == "" {
			continue
		}

		layout := DartClassLayout{
			ClassName:    className,
			ClassID:      ci.ClassID,
			InstanceSize: ci.InstanceSize * wordSize,
		}

		if rfs, ok := fieldsByOwner[ci.RefID]; ok {
			for _, rf := range rfs {
				fieldName := ""
				if rf.nameRefID >= 0 {
					if s, ok := pl.RefToStr[rf.nameRefID]; ok {
						fieldName = s
					}
				}
				if fieldName == "" {
					fieldName = fmt.Sprintf("field_0x%x", rf.byteOffset)
				}
				layout.Fields = append(layout.Fields, DartFieldLayout{
					Name:       fieldName,
					ByteOffset: rf.byteOffset,
				})
			}
		} else {
			byteSize := ci.InstanceSize * wordSize
			for off := wordSize; off+wordSize <= byteSize; off += wordSize {
				layout.Fields = append(layout.Fields, DartFieldLayout{
					Name:       fmt.Sprintf("f_0x%x", off),
					ByteOffset: off,
				})
			}
		}

		sort.Slice(layout.Fields, func(i, j int) bool {
			return layout.Fields[i].ByteOffset < layout.Fields[j].ByteOffset
		})

		layouts = append(layouts, layout)
	}
	return layouts
}

// QualifiedName builds "Owner.FuncName_hexaddr" like blutter.
func QualifiedName(ownerName, funcName string, pcOffset uint32) string {
	suffix := fmt.Sprintf("_%x", pcOffset)
	if funcName == "" {
		return "sub" + suffix
	}
	if ownerName != "" {
		return ownerName + "." + funcName + suffix
	}
	return funcName + suffix
}

// SanitizeFilename makes a string safe for use as a filename.
func SanitizeFilename(name string) string {
	r := strings.NewReplacer(
		"/", "_",
		"\\", "_",
		":", "_",
		"*", "_",
		"?", "_",
		"\"", "_",
		"<", "_",
		">", "_",
		"|", "_",
		" ", "_",
	)
	s := r.Replace(name)
	if len(s) > 200 {
		s = s[:200]
	}
	return s
}

// FuncRelPath returns a relative path like "OwnerClass/funcName_hex" for functions
// with an owner, or "funcName_hex" for ownerless functions.
func FuncRelPath(ownerName, funcName string, pcOffset uint32) string {
	suffix := fmt.Sprintf("_%x", pcOffset)
	var fpart string
	if funcName == "" {
		fpart = "sub" + suffix
	} else {
		fpart = SanitizeFilename(funcName + suffix)
	}
	if ownerName != "" {
		return SanitizeFilename(ownerName) + "/" + fpart
	}
	return fpart
}

// FuncRelPathFromQualified reconstructs the relative path from a qualified name
// and its owner. Used by post-disasm commands (signal, decompile).
func FuncRelPathFromQualified(qualifiedName, owner string) string {
	if owner != "" {
		prefix := owner + "."
		funcPart := qualifiedName
		if strings.HasPrefix(qualifiedName, prefix) {
			funcPart = qualifiedName[len(prefix):]
		}
		return SanitizeFilename(owner) + "/" + SanitizeFilename(funcPart)
	}
	return SanitizeFilename(qualifiedName)
}

// ReadJSONL reads a JSONL file into a slice of T.
func ReadJSONL[T any](path string) ([]T, error) {
	f, err := os.Open(path)
	if err != nil {
		return nil, err
	}
	defer f.Close()

	var records []T
	dec := json.NewDecoder(f)
	for dec.More() {
		var rec T
		if err := dec.Decode(&rec); err != nil {
			return records, fmt.Errorf("line %d: %w", len(records)+1, err)
		}
		records = append(records, rec)
	}

	return records, nil
}

// DisasmIndexEntry is the per-function index record written to index.jsonl.
type DisasmIndexEntry struct {
	Name      string `json:"name"`
	OwnerName string `json:"owner_name,omitempty"`
	RefID     int    `json:"ref_id"`
	OwnerRef  int    `json:"owner_ref,omitempty"`
	PCOffset  uint32 `json:"pc_offset"`
	Size      uint32 `json:"size"`
	File      string `json:"file"`
}

// DartMetaJSON is the structure written to dart_meta.json.
type DartMetaJSON struct {
	DartVersion        string             `json:"dart_version"`
	CompressedPointers bool               `json:"compressed_pointers"`
	PointerSize        int                `json:"pointer_size"`
	THRFields          []DartMetaTHRField `json:"thr_fields"`
}

// DartMetaTHRField is a THR field entry for dart_meta.json.
type DartMetaTHRField struct {
	Offset int    `json:"offset"`
	Name   string `json:"name"`
}

// WriteDartMeta writes dart_meta.json with snapshot metadata.
func WriteDartMeta(outDir, dartVersion string, compressed bool, ptrSize int, thrFields map[int]string) error {
	fields := make([]DartMetaTHRField, 0, len(thrFields))
	for off, name := range thrFields {
		fields = append(fields, DartMetaTHRField{Offset: off, Name: name})
	}
	sort.Slice(fields, func(i, j int) bool { return fields[i].Offset < fields[j].Offset })

	meta := DartMetaJSON{
		DartVersion:        dartVersion,
		CompressedPointers: compressed,
		PointerSize:        ptrSize,
		THRFields:          fields,
	}

	f, err := os.Create(filepath.Join(outDir, "dart_meta.json"))
	if err != nil {
		return err
	}
	enc := json.NewEncoder(f)
	enc.SetIndent("", "  ")
	if err := enc.Encode(meta); err != nil {
		f.Close()
		return err
	}
	return f.Close()
}

// NormalizeHexAddr strips leading zeros: "0x000652e4" → "0x652e4".
func NormalizeHexAddr(s string) string {
	if !strings.HasPrefix(s, "0x") && !strings.HasPrefix(s, "0X") {
		return s
	}
	v, err := strconv.ParseUint(s[2:], 16, 64)
	if err != nil {
		return s
	}
	return fmt.Sprintf("0x%x", v)
}

// ParseHexAddr parses "0x..." hex address strings. Returns 0 on failure.
func ParseHexAddr(s string) uint64 {
	s = strings.TrimPrefix(s, "0x")
	v, _ := strconv.ParseUint(s, 16, 64)
	return v
}

// AsmCommentRe matches annotated asm lines: address + instruction + "; comment"
var AsmCommentRe = regexp.MustCompile(`^(0x[0-9a-fA-F]+)\s+.*;\s+(.+)$`)

// ExtractAsmComments parses all .txt files in asmDir for instruction-level annotations.
func ExtractAsmComments(asmDir string) ([]FlutterMetaComment, error) {
	entries, err := os.ReadDir(asmDir)
	if err != nil {
		return nil, err
	}

	var comments []FlutterMetaComment
	seen := make(map[string]bool)

	for _, entry := range entries {
		if entry.IsDir() || !strings.HasSuffix(entry.Name(), ".txt") {
			continue
		}
		path := filepath.Join(asmDir, entry.Name())
		fc, err := extractFileComments(path, seen)
		if err != nil {
			continue
		}
		comments = append(comments, fc...)
	}

	return comments, nil
}

func extractFileComments(path string, seen map[string]bool) ([]FlutterMetaComment, error) {
	f, err := os.Open(path)
	if err != nil {
		return nil, err
	}
	defer f.Close()

	var comments []FlutterMetaComment
	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		line := scanner.Text()
		m := AsmCommentRe.FindStringSubmatch(line)
		if m == nil {
			continue
		}
		addr := NormalizeHexAddr(m[1])
		text := strings.TrimSpace(m[2])

		if strings.HasPrefix(text, "<") && strings.HasSuffix(text, ">") {
			continue
		}

		if seen[addr] {
			continue
		}
		seen[addr] = true

		comments = append(comments, FlutterMetaComment{
			Addr: addr,
			Text: text,
		})
	}

	return comments, scanner.Err()
}

// IsInterestingCallee returns true if the callee name represents a real named
// function rather than VM internals, stubs, or dispatch noise.
func IsInterestingCallee(name string) bool {
	if name == "" {
		return false
	}
	switch {
	case len(name) > 4 && name[:4] == "sub_":
		return false
	case len(name) > 2 && name[0] == '0' && name[1] == 'x':
		return false
	case name == "dispatch_table" || name == "object_field":
		return false
	case len(name) > 4 && name[:4] == "THR.":
		return false
	case len(name) > 3 && name[:3] == "PP[":
		return false
	}
	return true
}

// FlutterMetaComment is a comment entry for flutter_meta.json.
type FlutterMetaComment struct {
	Addr string `json:"addr"`
	Text string `json:"text"`
}

```

`internal/pipeline/meta_stage.go`:

```go
package pipeline

import (
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"

	"unflutter/internal/cli"
	"unflutter/internal/disasm"
	"unflutter/internal/signal"
)

// FlutterMetaFunc is a function entry in flutter_meta.json.
type FlutterMetaFunc struct {
	Addr       string `json:"addr"`
	Name       string `json:"name"`
	Size       int    `json:"size"`
	Owner      string `json:"owner,omitempty"`
	ParamCount int    `json:"param_count,omitempty"`
}

// FlutterMetaTHRField is a THR (thread) struct field.
type FlutterMetaTHRField struct {
	Offset int    `json:"offset"`
	Name   string `json:"name"`
}

// FlutterMetaJSON is the top-level flutter_meta.json structure.
type FlutterMetaJSON struct {
	Version        string                `json:"version"`
	DartVersion    string                `json:"dart_version,omitempty"`
	PointerSize    int                   `json:"pointer_size,omitempty"`
	Functions      []FlutterMetaFunc     `json:"functions"`
	Comments       []FlutterMetaComment  `json:"comments"`
	FocusFunctions []string              `json:"focus_functions,omitempty"`
	Classes        []DartClassLayout     `json:"classes,omitempty"`
	THRFields      []FlutterMetaTHRField `json:"thr_fields,omitempty"`
}

// RunMetaStage generates flutter_meta.json from existing disasm output.
func RunMetaStage(inDir, outPath string, decompAll bool, quiet bool, log io.Writer) (string, error) {
	if log == nil {
		log = os.Stderr
	}
	logf := func(format string, args ...interface{}) {
		if !quiet {
			fmt.Fprintf(log, format, args...)
		}
	}
	stagef := func(name string, format string, args ...interface{}) {
		if !quiet {
			detail := fmt.Sprintf(format, args...)
			fmt.Fprintf(log, "\n%s%s%s %s\n", cli.Pink, name, cli.Reset, detail)
		}
	}

	if outPath == "" {
		outPath = filepath.Join(inDir, "flutter_meta.json")
	}

	// 1. Read functions.jsonl.
	funcs, err := ReadJSONL[disasm.FuncRecord](filepath.Join(inDir, "functions.jsonl"))
	if err != nil {
		return "", fmt.Errorf("read functions.jsonl: %w", err)
	}
	stagef("meta", "%s%d%s functions", cli.Gold, len(funcs), cli.Reset)

	metaFuncs := make([]FlutterMetaFunc, len(funcs))
	for i, f := range funcs {
		metaFuncs[i] = FlutterMetaFunc{
			Addr:       f.PC,
			Name:       f.Name,
			Size:       f.Size,
			Owner:      f.Owner,
			ParamCount: f.ParamCount,
		}
	}

	// 2. Determine which functions to decompile.
	var focusFuncs []string
	if decompAll {
		for _, f := range funcs {
			focusFuncs = append(focusFuncs, f.PC)
		}
		logf("  %sfocus:%s ALL %d functions\n", cli.Muted, cli.Reset, len(focusFuncs))
	} else {
		sgPath := filepath.Join(inDir, "signal_graph.json")
		if data, err := os.ReadFile(sgPath); err == nil {
			var sg signal.SignalGraph
			if err := json.Unmarshal(data, &sg); err == nil {
				for _, sf := range sg.Funcs {
					if sf.Role == "signal" {
						focusFuncs = append(focusFuncs, sf.PC)
					}
				}
			}
		}
		logf("  %sfocus:%s %d signal functions %s(use --all for everything)%s\n",
			cli.Muted, cli.Reset, len(focusFuncs), cli.Muted, cli.Reset)
	}

	// 2b. Read dart_meta.json for pointer size and THR fields.
	var pointerSize int
	var dartVersion string
	var thrFields []FlutterMetaTHRField
	dmPath := filepath.Join(inDir, "dart_meta.json")
	if dmData, err := os.ReadFile(dmPath); err == nil {
		var dm struct {
			DartVersion string `json:"dart_version"`
			PointerSize int    `json:"pointer_size"`
			THRFields   []struct {
				Offset int    `json:"offset"`
				Name   string `json:"name"`
			} `json:"thr_fields"`
		}
		if err := json.Unmarshal(dmData, &dm); err == nil {
			dartVersion = dm.DartVersion
			pointerSize = dm.PointerSize
			for _, f := range dm.THRFields {
				thrFields = append(thrFields, FlutterMetaTHRField{Offset: f.Offset, Name: f.Name})
			}
			logf("  %sdart:%s %s  %sptr_size:%s %d  %sthr_fields:%s %d\n",
				cli.Muted, cli.Reset, dartVersion, cli.Muted, cli.Reset, pointerSize, cli.Muted, cli.Reset, len(thrFields))
		}
	} else {
		logf("  %s! dart_meta.json: %v (ptr_size defaults to 8)%s\n", cli.Red, err, cli.Reset)
		pointerSize = 8
	}

	// 2c. Read class layouts.
	classLayouts, err := ReadJSONL[DartClassLayout](filepath.Join(inDir, "classes.jsonl"))
	if err != nil {
		logf("  %s! classes.jsonl: %v%s\n", cli.Red, err, cli.Reset)
		classLayouts = nil
	} else {
		logf("  %sclasses:%s %d layouts\n", cli.Muted, cli.Reset, len(classLayouts))
	}

	// 3. Extract comments from asm/*.txt files.
	asmDir := filepath.Join(inDir, "asm")
	comments, err := ExtractAsmComments(asmDir)
	if err != nil {
		logf("  %s! asm comments: %v%s\n", cli.Red, err, cli.Reset)
		comments = nil
	}
	logf("  %scomments:%s %d from asm files\n", cli.Muted, cli.Reset, len(comments))

	// 3b. Merge string references as comments.
	stringRefs, err := ReadJSONL[disasm.StringRefRecord](filepath.Join(inDir, "string_refs.jsonl"))
	if err != nil {
		logf("  %s! string_refs.jsonl: %v%s\n", cli.Red, err, cli.Reset)
	} else {
		seen := make(map[string]bool, len(comments))
		for _, c := range comments {
			seen[c.Addr] = true
		}
		strAdded := 0
		for _, sr := range stringRefs {
			addr := NormalizeHexAddr(sr.PC)
			if seen[addr] {
				continue
			}
			seen[addr] = true
			val := sr.Value
			if len(val) > 80 {
				val = val[:77] + "..."
			}
			comments = append(comments, FlutterMetaComment{
				Addr: addr,
				Text: fmt.Sprintf("str: %q", val),
			})
			strAdded++
		}
		logf("  %sstring refs:%s +%d comments\n", cli.Muted, cli.Reset, strAdded)
	}

	// 4. Write flutter_meta.json.
	meta := FlutterMetaJSON{
		Version:        "1",
		DartVersion:    dartVersion,
		PointerSize:    pointerSize,
		Functions:      metaFuncs,
		Comments:       comments,
		FocusFunctions: focusFuncs,
		Classes:        classLayouts,
		THRFields:      thrFields,
	}

	f, err := os.Create(outPath)
	if err != nil {
		return "", fmt.Errorf("create output: %w", err)
	}
	enc := json.NewEncoder(f)
	enc.SetIndent("", "  ")
	if err := enc.Encode(meta); err != nil {
		f.Close()
		return "", fmt.Errorf("write json: %w", err)
	}
	if err := f.Close(); err != nil {
		return "", fmt.Errorf("close output: %w", err)
	}

	fi, _ := os.Stat(outPath)
	logf("  %s->%s %s%s%s (%d bytes)\n", cli.Muted, cli.Reset, cli.Blue, outPath, cli.Reset, fi.Size())

	return outPath, nil
}

```

`internal/pipeline/pipeline.go`:

```go
package pipeline

import (
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"

	"unflutter/internal/cli"
	"unflutter/internal/cluster"
	"unflutter/internal/dartfmt"
	"unflutter/internal/disasm"
	"unflutter/internal/elfx"
	"unflutter/internal/snapshot"
)

// Opts controls pipeline execution.
type Opts struct {
	LibPath   string // path to libapp.so
	OutDir    string // output directory
	FromDir   string // reuse existing disasm output (skip ELF/disasm)
	Strict    bool
	MaxSteps  int
	Limit     int  // max functions (0=all)
	Graph     bool // build callgraph DOTs
	Signal    bool // run signal analysis
	SignalK   int  // signal context hops (default 2)
	Meta      bool // produce flutter_meta.json
	DecompAll bool // all functions vs signal-only in focus list
	Quiet     bool // suppress verbose output (verbose is default)
	Log       io.Writer // stderr by default
}

// Result holds pipeline summary information.
type Result struct {
	OutDir      string
	LibPath     string // absolute
	DartVersion string
	PointerSize int
	FuncCount   int
	ClassCount  int
	SignalCount int
	MetaPath    string // empty if Meta=false
	Diags       []string
}

func (o *Opts) log() io.Writer {
	if o.Log != nil {
		return o.Log
	}
	return os.Stderr
}

func (o *Opts) logf(format string, args ...interface{}) {
	if !o.Quiet {
		fmt.Fprintf(o.log(), format, args...)
	}
}

func (o *Opts) stagef(name string, format string, args ...interface{}) {
	if o.Quiet {
		return
	}
	detail := fmt.Sprintf(format, args...)
	fmt.Fprintf(o.log(), "\n%s%s%s %s\n", cli.Pink, name, cli.Reset, detail)
}

// Run executes the full analysis pipeline.
func Run(opts Opts) (*Result, error) {
	if opts.SignalK <= 0 {
		opts.SignalK = 2
	}

	result := &Result{
		OutDir:  opts.OutDir,
		LibPath: opts.LibPath,
	}

	// If FromDir is set, skip ELF parsing and disassembly.
	if opts.FromDir != "" {
		return runFromExisting(&opts, result)
	}

	// Step 1: ELF open + snapshot extract.
	fmtOpts := dartfmt.Options{
		Mode:     dartfmt.ModeBestEffort,
		MaxSteps: opts.MaxSteps,
	}
	if opts.Strict {
		fmtOpts.Mode = dartfmt.ModeStrict
	}

	ef, err := elfx.Open(opts.LibPath)
	if err != nil {
		return nil, fmt.Errorf("open: %w", err)
	}
	defer ef.Close()

	info, err := snapshot.Extract(ef, fmtOpts)
	if err != nil {
		return nil, fmt.Errorf("extract: %w", err)
	}

	if info.Version != nil && info.Version.DartVersion != "" {
		opts.stagef("elf", "Dart SDK %s%s%s", cli.Gold, info.Version.DartVersion, cli.Reset)
		result.DartVersion = info.Version.DartVersion
	}
	if info.Version != nil && !info.Version.Supported {
		return nil, fmt.Errorf("HALT_UNSUPPORTED_VERSION: Dart %s (hash %s)", info.Version.DartVersion, info.VmHeader.SnapshotHash)
	}

	// Step 2: Parse isolate snapshot clusters + fill.
	data := info.IsolateData.Data
	if len(data) < 64 {
		return nil, fmt.Errorf("isolate data too short (%d bytes)", len(data))
	}

	clusterStart, err := cluster.FindClusterDataStart(data)
	if err != nil {
		return nil, fmt.Errorf("cluster start: %w", err)
	}

	clResult, err := cluster.ScanClusters(data, clusterStart, info.Version, false, fmtOpts)
	if err != nil {
		return nil, fmt.Errorf("scan: %w", err)
	}

	if err := cluster.ReadFill(data, clResult, info.Version, false, info.IsolateHeader.TotalSize); err != nil {
		return nil, fmt.Errorf("fill: %w", err)
	}

	// Step 3: Parse instructions table + resolve code ranges.
	table, err := cluster.ParseInstructionsTable(data, &clResult.Header, info.Version, info.IsolateHeader)
	if err != nil {
		return nil, fmt.Errorf("instrtable: %w", err)
	}

	codeRanges, err := cluster.ResolveCodeRanges(clResult.Codes, table)
	if err != nil {
		return nil, fmt.Errorf("code ranges: %w", err)
	}

	stubRanges := cluster.ResolveStubRanges(table)
	ranges := cluster.MergeRanges(stubRanges, codeRanges)

	code, codeOff, payloadLen, err := snapshot.CodeRegion(info.IsolateInstructions.Data)
	if err != nil {
		return nil, fmt.Errorf("code region: %w", err)
	}
	codeEndOffset := uint32(codeOff) + uint32(payloadLen)
	cluster.SetLastRangeSize(ranges, codeEndOffset)

	codeVA := info.IsolateInstructions.VA + codeOff

	opts.stagef("code", "%s%d%s bytes at VA %s0x%x%s",
		cli.Gold, payloadLen, cli.Reset, cli.Blue, codeVA, cli.Reset)
	opts.logf("  %sinstructions:%s %d entries (%d stubs + %d code)\n",
		cli.Muted, cli.Reset, table.Length, table.FirstEntryWithCode, int(table.Length)-int(table.FirstEntryWithCode))
	opts.logf("  %sranges:%s %d (%d stubs + %d code)\n",
		cli.Muted, cli.Reset, len(ranges), len(stubRanges), len(codeRanges))

	// Create output directory.
	if err := os.MkdirAll(opts.OutDir, 0755); err != nil {
		return nil, fmt.Errorf("mkdir output: %w", err)
	}

	// Build name lookups and pool display map.
	pl := BuildPoolLookups(clResult, info.Version.CIDs, nil)
	poolDisplay := ResolvePoolDisplay(clResult.Pool, pl)

	// Build and write class layouts.
	classLayouts := BuildClassLayouts(clResult, pl, info.Version.CompressedPointers)
	if len(classLayouts) > 0 {
		classesPath := filepath.Join(opts.OutDir, "classes.jsonl")
		classesFile, err := os.Create(classesPath)
		if err != nil {
			return nil, fmt.Errorf("create classes.jsonl: %w", err)
		}
		classesEnc := json.NewEncoder(classesFile)
		classesEnc.SetEscapeHTML(false)
		for i := range classLayouts {
			if err := classesEnc.Encode(&classLayouts[i]); err != nil {
				classesFile.Close()
				return nil, fmt.Errorf("write classes.jsonl: %w", err)
			}
		}
		classesFile.Close()
		opts.logf("  %sclasses:%s %d layouts\n", cli.Muted, cli.Reset, len(classLayouts))
	}
	result.ClassCount = len(classLayouts)

	// Write dart_meta.json.
	thrFields := disasm.THRFields(info.Version.DartVersion)
	ptrSize := 8
	if info.Version.CompressedPointers {
		ptrSize = 4
	}
	result.PointerSize = ptrSize
	if err := WriteDartMeta(opts.OutDir, info.Version.DartVersion, info.Version.CompressedPointers, ptrSize, thrFields); err != nil {
		return nil, fmt.Errorf("write dart_meta.json: %w", err)
	}

	// Step 4: Per-function disassembly.
	disasmResult, err := RunDisasmStage(&opts, pl, poolDisplay, clResult, ranges, code, codeOff, codeVA, thrFields, info)
	if err != nil {
		return nil, err
	}
	result.FuncCount = disasmResult.Written

	// Step 5: Signal analysis (if enabled).
	if opts.Signal {
		sigResult, err := RunSignalStage(opts.OutDir, opts.SignalK, false, opts.Quiet, opts.log())
		if err != nil {
			return nil, fmt.Errorf("signal: %w", err)
		}
		result.SignalCount = sigResult.SignalCount
	}

	// Step 6: Flutter-meta generation (if enabled).
	if opts.Meta {
		metaPath, err := RunMetaStage(opts.OutDir, "", opts.DecompAll, opts.Quiet, opts.log())
		if err != nil {
			return nil, fmt.Errorf("meta: %w", err)
		}
		result.MetaPath = metaPath
	}

	return result, nil
}

// runFromExisting runs signal/meta stages using pre-existing disasm output.
func runFromExisting(opts *Opts, result *Result) (*Result, error) {
	// Validate required files exist.
	for _, f := range []string{"functions.jsonl", "call_edges.jsonl"} {
		if _, err := os.Stat(filepath.Join(opts.FromDir, f)); err != nil {
			return nil, fmt.Errorf("--from dir missing %s: %w", f, err)
		}
	}

	outDir := opts.FromDir
	if opts.OutDir != "" {
		outDir = opts.OutDir
	}
	result.OutDir = outDir

	// Count existing functions.
	funcs, err := ReadJSONL[disasm.FuncRecord](filepath.Join(opts.FromDir, "functions.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("read functions.jsonl: %w", err)
	}
	result.FuncCount = len(funcs)

	if opts.Signal {
		sigResult, err := RunSignalStage(opts.FromDir, opts.SignalK, false, opts.Quiet, opts.log())
		if err != nil {
			return nil, fmt.Errorf("signal: %w", err)
		}
		result.SignalCount = sigResult.SignalCount
	}

	if opts.Meta {
		metaPath, err := RunMetaStage(opts.FromDir, "", opts.DecompAll, opts.Quiet, opts.log())
		if err != nil {
			return nil, fmt.Errorf("meta: %w", err)
		}
		result.MetaPath = metaPath
	}

	return result, nil
}

```

`internal/pipeline/signal_stage.go`:

```go
package pipeline

import (
	"encoding/json"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"strings"

	"unflutter/internal/cli"
	"unflutter/internal/disasm"
	"unflutter/internal/render"
	"unflutter/internal/signal"
)

// SignalResult holds summary stats from the signal stage.
type SignalResult struct {
	SignalCount  int
	ContextCount int
	EdgeCount    int
}

// RunSignalStage runs the signal analysis on existing disasm output.
func RunSignalStage(inDir string, k int, noAsm bool, quiet bool, log io.Writer) (*SignalResult, error) {
	if log == nil {
		log = os.Stderr
	}
	logf := func(format string, args ...interface{}) {
		if !quiet {
			fmt.Fprintf(log, format, args...)
		}
	}
	stagef := func(name string, format string, args ...interface{}) {
		if !quiet {
			detail := fmt.Sprintf(format, args...)
			fmt.Fprintf(log, "\n%s%s%s %s\n", cli.Pink, name, cli.Reset, detail)
		}
	}

	// Read functions.jsonl.
	funcs, err := ReadJSONL[disasm.FuncRecord](filepath.Join(inDir, "functions.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("read functions.jsonl: %w", err)
	}

	// Read call_edges.jsonl.
	edges, err := ReadJSONL[disasm.CallEdgeRecord](filepath.Join(inDir, "call_edges.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("read call_edges.jsonl: %w", err)
	}

	// Read string_refs.jsonl.
	stringRefs, err := ReadJSONL[disasm.StringRefRecord](filepath.Join(inDir, "string_refs.jsonl"))
	if err != nil {
		return nil, fmt.Errorf("read string_refs.jsonl: %w", err)
	}

	// Compute entry points.
	entryList := render.FindEntryPoints(funcs, edges)
	entrySet := make(map[string]bool, len(entryList))
	for _, ep := range entryList {
		entrySet[ep] = true
	}

	// Build signal graph.
	g := signal.BuildSignalGraph(funcs, edges, stringRefs, k, entrySet)
	stagef("signal", "%s%d%s signal + %s%d%s context, %s%d%s edges",
		cli.Gold, g.Stats.SignalFuncs, cli.Reset,
		cli.Gold, g.Stats.ContextFuncs, cli.Reset,
		cli.Gold, g.Stats.TotalEdges, cli.Reset)
	for cat, count := range g.Stats.Categories {
		logf("  %s%s:%s %d\n", cli.Muted, cat, cli.Reset, count)
	}

	// Load asm snippets.
	const contextAsmLines = 30
	asmSnippets := make(map[string]string)
	if !noAsm {
		asmDir := filepath.Join(inDir, "asm")
		for _, sf := range g.Funcs {
			if sf.Role == "" {
				continue
			}
			relPath := FuncRelPathFromQualified(sf.Name, sf.Owner)
			path := filepath.Join(asmDir, relPath+".txt")
			data, err := os.ReadFile(path)
			if err != nil {
				flatPath := filepath.Join(asmDir, SanitizeFilename(sf.Name)+".txt")
				data, err = os.ReadFile(flatPath)
				if err != nil {
					continue
				}
			}
			s := strings.TrimRight(string(data), "\n")
			if sf.Role == "context" {
				lines := strings.SplitN(s, "\n", contextAsmLines+1)
				if len(lines) > contextAsmLines {
					s = strings.Join(lines[:contextAsmLines], "\n") + "\n[... truncated]"
				}
			}
			asmSnippets[sf.Name] = s
		}
		logf("  %sasm snippets:%s %d\n", cli.Muted, cli.Reset, len(asmSnippets))
	}

	// Write signal_graph.json.
	outPath := filepath.Join(inDir, "signal.html")
	jsonPath := filepath.Join(inDir, "signal_graph.json")
	jsonFile, err := os.Create(jsonPath)
	if err != nil {
		return nil, fmt.Errorf("create signal_graph.json: %w", err)
	}
	enc := json.NewEncoder(jsonFile)
	enc.SetIndent("", "  ")
	if err := enc.Encode(g); err != nil {
		jsonFile.Close()
		return nil, fmt.Errorf("write signal_graph.json: %w", err)
	}
	jsonFile.Close()
	fi, _ := os.Stat(jsonPath)
	logf("  %s->%s %s%s%s (%d bytes)\n", cli.Muted, cli.Reset, cli.Blue, jsonPath, cli.Reset, fi.Size())

	// Write signal.html.
	htmlFile, err := os.Create(outPath)
	if err != nil {
		return nil, fmt.Errorf("create signal.html: %w", err)
	}
	title := "unflutter"
	digest := filepath.Base(filepath.Dir(inDir))
	filename := inDir
	if metaBytes, err := os.ReadFile(filepath.Join(filepath.Dir(inDir), "meta.json")); err == nil {
		var meta struct {
			Hash   string `json:"hash"`
			Source string `json:"source"`
		}
		if json.Unmarshal(metaBytes, &meta) == nil {
			if meta.Hash != "" {
				digest = meta.Hash
			}
			if meta.Source != "" {
				filename = filepath.Base(meta.Source)
			}
		}
	}
	render.WriteSignalHTML(htmlFile, g, title, filename, digest, asmSnippets)
	if err := htmlFile.Close(); err != nil {
		return nil, fmt.Errorf("close signal.html: %w", err)
	}
	fi, _ = os.Stat(outPath)
	logf("  %s->%s %s%s%s (%d bytes)\n", cli.Muted, cli.Reset, cli.Blue, outPath, cli.Reset, fi.Size())

	// Write signal.dot.
	dotPath := filepath.Join(inDir, "signal.dot")
	dotContent := render.SignalDOT(g, title, render.NASA)
	if err := os.WriteFile(dotPath, []byte(dotContent), 0644); err != nil {
		return nil, fmt.Errorf("write signal.dot: %w", err)
	}
	fi, _ = os.Stat(dotPath)
	logf("  %s->%s %s%s%s (%d bytes)\n", cli.Muted, cli.Reset, cli.Blue, dotPath, cli.Reset, fi.Size())

	// Build connected signal CFG.
	if !noAsm {
		content := BuildSignalContent(g, inDir, funcs, edges)
		if len(content) > 0 {
			cfgTitle := "signal CFG"
			if title != "" {
				cfgTitle = title + " — signal CFG"
			}
			cfgDOT := render.SignalCFGDOT(g, content, cfgTitle, render.NASA)
			cfgPath := filepath.Join(inDir, "signal_cfg.dot")
			if err := os.WriteFile(cfgPath, []byte(cfgDOT), 0644); err != nil {
				return nil, fmt.Errorf("write signal_cfg.dot: %w", err)
			}
			fi, _ = os.Stat(cfgPath)
			logf("  %s->%s %s%s%s (%d functions, %d bytes)\n",
				cli.Muted, cli.Reset, cli.Blue, cfgPath, cli.Reset, len(content), fi.Size())
		}
	}

	// Render SVG via dot if available.
	dotBin, err := exec.LookPath("dot")
	if err != nil {
		logf("  %s!%s dot not found — install Graphviz for SVG: %sbrew install graphviz%s\n",
			cli.Red, cli.Reset, cli.Gold, cli.Reset)
	} else {
		dotFiles := []string{dotPath}
		cfgDotPath := filepath.Join(inDir, "signal_cfg.dot")
		if _, statErr := os.Stat(cfgDotPath); statErr == nil {
			dotFiles = append(dotFiles, cfgDotPath)
		}
		for _, df := range dotFiles {
			svgPath := strings.TrimSuffix(df, ".dot") + ".svg"
			cmd := exec.Command(dotBin, "-Tsvg", "-o", svgPath, df)
			if out, err := cmd.CombinedOutput(); err != nil {
				logf("  %s!%s dot render failed for %s: %v\n%s\n", cli.Red, cli.Reset, filepath.Base(df), err, out)
			} else {
				fi, _ = os.Stat(svgPath)
				logf("  %s->%s %s%s%s (%d bytes)\n", cli.Muted, cli.Reset, cli.Blue, svgPath, cli.Reset, fi.Size())
			}
		}
	}

	return &SignalResult{
		SignalCount:  g.Stats.SignalFuncs,
		ContextCount: g.Stats.ContextFuncs,
		EdgeCount:    g.Stats.TotalEdges,
	}, nil
}

// BuildSignalContent re-disassembles signal functions from bin files and extracts
// interesting calls and string refs for each function.
func BuildSignalContent(
	g *signal.SignalGraph,
	inDir string,
	funcs []disasm.FuncRecord,
	edgeRecords []disasm.CallEdgeRecord,
) map[string]*render.SignalFuncContent {
	edgesByFunc := make(map[string][]disasm.CallEdge)
	for _, er := range edgeRecords {
		pc := ParseHexAddr(er.FromPC)
		ce := disasm.CallEdge{
			FromPC:     pc,
			Kind:       er.Kind,
			TargetName: er.Target,
			TargetPC:   ParseHexAddr(er.Target),
			Via:        er.Via,
		}
		edgesByFunc[er.FromFunc] = append(edgesByFunc[er.FromFunc], ce)
	}

	funcByName := make(map[string]disasm.FuncRecord, len(funcs))
	for _, f := range funcs {
		funcByName[f.Name] = f
	}

	asmDir := filepath.Join(inDir, "asm")
	result := make(map[string]*render.SignalFuncContent)

	for _, sf := range g.Funcs {
		if sf.Role != "signal" {
			continue
		}
		fr, ok := funcByName[sf.Name]
		if !ok {
			continue
		}

		relPath := FuncRelPathFromQualified(sf.Name, sf.Owner)
		binPath := filepath.Join(asmDir, relPath+".bin")
		data, err := os.ReadFile(binPath)
		if err != nil {
			binPath = filepath.Join(asmDir, SanitizeFilename(sf.Name)+".bin")
			data, err = os.ReadFile(binPath)
		}
		if err != nil || len(data) < 4 {
			continue
		}

		baseAddr := ParseHexAddr(fr.PC)
		if baseAddr == 0 {
			continue
		}

		insts := disasm.Disassemble(data, disasm.Options{BaseAddr: baseAddr})
		if len(insts) == 0 {
			continue
		}

		funcEdges := edgesByFunc[sf.Name]
		edgeByPC := make(map[uint64]disasm.CallEdge, len(funcEdges))
		for _, e := range funcEdges {
			edgeByPC[e.FromPC] = e
		}
		seenCalls := make(map[string]bool)
		var calls []string
		for _, inst := range insts {
			if e, ok := edgeByPC[inst.Addr]; ok {
				callee := e.TargetName
				if callee == "" {
					callee = e.Via
				}
				if IsInterestingCallee(callee) && !seenCalls[callee] {
					seenCalls[callee] = true
					calls = append(calls, callee)
				}
			}
		}

		seenStrs := make(map[string]bool)
		var strs []render.ClassifiedString
		for _, sr := range sf.StringRefs {
			if seenStrs[sr.Value] {
				continue
			}
			seenStrs[sr.Value] = true
			cat := ""
			if len(sr.Categories) > 0 {
				cat = sr.Categories[0]
			}
			strs = append(strs, render.ClassifiedString{Value: sr.Value, Category: cat})
		}

		if len(calls) > 0 || len(strs) > 0 {
			result[sf.Name] = &render.SignalFuncContent{
				Calls:   calls,
				Strings: strs,
			}
		}
	}

	return result
}

```

`internal/render/callgraph.go`:

```go
package render

import (
	"fmt"
	"strings"

	"unflutter/internal/disasm"
)

// Provenance categories extracted from CallEdgeRecord.Via.
const (
	ProvTHR        = "thr"
	ProvPP         = "pp"
	ProvDispatch   = "dispatch_table"
	ProvObject     = "object_field"
	ProvDirect     = "direct"
	ProvUnresolved = "unresolved"
)

// ClassifyEdgeProv returns the provenance category for a call edge.
func ClassifyEdgeProv(e disasm.CallEdgeRecord) string {
	if e.Kind == "bl" {
		return ProvDirect
	}
	switch {
	case strings.HasPrefix(e.Via, "THR."):
		return ProvTHR
	case strings.HasPrefix(e.Via, "PP["):
		return ProvPP
	case e.Via == "dispatch_table":
		return ProvDispatch
	case e.Via == "object_field":
		return ProvObject
	case e.Via == "":
		return ProvUnresolved
	default:
		return ProvUnresolved
	}
}

// edgeColor returns the DOT color for an edge provenance category.
func edgeColor(prov string, t Theme) string {
	switch prov {
	case ProvTHR:
		return t.EdgeTHR
	case ProvPP:
		return t.EdgePP
	case ProvDispatch:
		return t.EdgeDispatch
	case ProvObject:
		return t.EdgeObject
	case ProvDirect:
		return t.EdgeDirect
	case ProvUnresolved:
		return t.EdgeUnresolved
	default:
		return t.EdgeDirect
	}
}

// edgeStyle returns dot style attributes for provenance.
func edgeStyle(prov string) string {
	switch prov {
	case ProvDispatch:
		return "dotted"
	case ProvObject:
		return "dotted"
	case ProvUnresolved:
		return "dashed"
	default:
		return "solid"
	}
}

// CallgraphDOT renders a callgraph from functions and call edges as DOT.
// Only edges between known functions are rendered (internal edges).
// External targets (stubs, runtime) are shown as plaintext nodes.
// maxNodes limits the number of function nodes rendered (0 = all).
func CallgraphDOT(funcs []disasm.FuncRecord, edges []disasm.CallEdgeRecord, title string, t Theme, maxNodes int) string {
	// Build set of known function names.
	funcSet := make(map[string]bool, len(funcs))
	for _, f := range funcs {
		funcSet[f.Name] = true
	}

	// Deduplicate edges: caller→callee→prov.
	type edgeKey struct {
		from, to, prov string
	}
	type edgeVal struct {
		count int
		via   string
	}
	dedupEdges := make(map[edgeKey]*edgeVal)

	for _, e := range edges {
		prov := ClassifyEdgeProv(e)
		var target string
		if e.Kind == "bl" {
			target = e.Target
		} else {
			// For BLR, target is unresolvable — group by "from → via" label.
			target = e.Via
			if target == "" {
				target = "unresolved_blr"
			}
		}
		if target == "" {
			continue
		}
		k := edgeKey{e.FromFunc, target, prov}
		if v, ok := dedupEdges[k]; ok {
			v.count++
		} else {
			dedupEdges[k] = &edgeVal{count: 1, via: e.Via}
		}
	}

	// Identify referenced nodes (callers + callees).
	refNodes := make(map[string]bool)
	for k := range dedupEdges {
		refNodes[k.from] = true
		refNodes[k.to] = true
	}

	// Filter to functions that participate in edges.
	var renderFuncs []disasm.FuncRecord
	for _, f := range funcs {
		if refNodes[f.Name] {
			renderFuncs = append(renderFuncs, f)
		}
	}
	if maxNodes > 0 && len(renderFuncs) > maxNodes {
		renderFuncs = renderFuncs[:maxNodes]
		// Rebuild funcSet to only include rendered functions.
		funcSet = make(map[string]bool, len(renderFuncs))
		for _, f := range renderFuncs {
			funcSet[f.Name] = true
		}
	}

	// Collect external nodes (targets not in funcSet, reachable from rendered funcs).
	externalNodes := make(map[string]bool)
	for k := range dedupEdges {
		if !funcSet[k.from] {
			continue // edge from non-rendered function — skip entirely
		}
		if !funcSet[k.to] {
			externalNodes[k.to] = true
		}
	}

	// Group rendered functions by owner for clustering.
	ownerFuncs := make(map[string][]disasm.FuncRecord)
	var noOwner []disasm.FuncRecord
	for _, f := range renderFuncs {
		if f.Owner != "" {
			ownerFuncs[f.Owner] = append(ownerFuncs[f.Owner], f)
		} else {
			noOwner = append(noOwner, f)
		}
	}

	var b strings.Builder
	b.WriteString("digraph callgraph {\n")
	b.WriteString("  rankdir=LR;\n")
	b.WriteString("  compound=true;\n")
	b.WriteString("  splines=true;\n")
	b.WriteString("  nodesep=0.4;\n")
	b.WriteString("  ranksep=0.6;\n")
	fmt.Fprintf(&b, "  bgcolor=%q;\n", t.Background)
	fmt.Fprintf(&b, "  node [shape=rect, style=filled, fillcolor=%q, color=%q, penwidth=0.5, fontname=\"Helvetica Neue,Helvetica,Arial\", fontsize=9, fontcolor=%q, height=0.3, margin=\"0.12,0.06\"];\n",
		t.NodeFill, t.NodeBorder, t.TextColor)
	fmt.Fprintf(&b, "  edge [penwidth=0.5, arrowsize=0.5, arrowhead=vee];\n")
	if title != "" {
		fmt.Fprintf(&b, "  labelloc=t;\n  labeljust=l;\n")
		fmt.Fprintf(&b, "  label=<<font face=\"Helvetica Neue,Helvetica\" point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.TextColor, dotEscape(title))
	}
	b.WriteByte('\n')

	// Render clustered function nodes (grouped by owner).
	for owner, funcsInOwner := range ownerFuncs {
		if len(funcsInOwner) < 2 {
			// Singletons go at top level.
			noOwner = append(noOwner, funcsInOwner...)
			continue
		}
		clusterID := "cluster_" + dotID(owner)
		ownerLabel := stripOwnerHash(owner)
		fmt.Fprintf(&b, "  subgraph %s {\n", clusterID)
		fmt.Fprintf(&b, "    label=<<font point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.ClusterLabel, dotEscape(ownerLabel))
		fmt.Fprintf(&b, "    style=dotted; color=%q; penwidth=0.3;\n", t.ClusterBorder)
		for _, f := range funcsInOwner {
			id := dotID(f.Name)
			// Inside a cluster, strip owner prefix for shorter labels.
			label := stripMethodName(f.Name, owner)
			label = truncLabel(label, 50)
			if strings.HasPrefix(f.Name, "sub_") {
				fmt.Fprintf(&b, "    %s [label=%q, fillcolor=%q];\n", id, label, t.StubFill)
			} else {
				fmt.Fprintf(&b, "    %s [label=%q];\n", id, label)
			}
		}
		fmt.Fprintf(&b, "  }\n")
	}

	// Render unclustered nodes (no owner or singletons).
	for _, f := range noOwner {
		id := dotID(f.Name)
		label := truncLabel(f.Name, 60)
		if strings.HasPrefix(f.Name, "sub_") {
			fmt.Fprintf(&b, "  %s [label=%q, fillcolor=%q];\n", id, label, t.StubFill)
		} else {
			fmt.Fprintf(&b, "  %s [label=%q];\n", id, label)
		}
	}
	b.WriteByte('\n')

	// Render external nodes.
	for name := range externalNodes {
		id := dotID(name)
		label := truncLabel(name, 50)
		fmt.Fprintf(&b, "  %s [label=%q, shape=plaintext, style=\"\", fillcolor=none, fontcolor=%q, fontsize=8];\n",
			id, label, t.ExternalText)
	}
	b.WriteByte('\n')

	// Render edges.
	for k, v := range dedupEdges {
		if !funcSet[k.from] && !externalNodes[k.from] {
			continue
		}
		fromID := dotID(k.from)
		toID := dotID(k.to)
		color := edgeColor(k.prov, t)
		style := edgeStyle(k.prov)

		attrs := fmt.Sprintf("color=%q, style=%q", color, style)
		if v.count > 1 {
			attrs += fmt.Sprintf(", penwidth=%.1f", 0.5+float64(v.count)*0.1)
			if v.count > 2 {
				attrs += fmt.Sprintf(", label=<<font point-size=\"7\" color=\"%s\">%dx</font>>", color, v.count)
			}
		}
		fmt.Fprintf(&b, "  %s -> %s [%s];\n", fromID, toID, attrs)
	}

	b.WriteString("}\n")
	return b.String()
}

// CallgraphStats computes summary statistics from edges.
type CallgraphStats struct {
	TotalFunctions int
	TotalEdges     int
	BLEdges        int
	BLREdges       int
	BLRAnnotated   int
	UniqueOwners   int
	ProvCounts     map[string]int
	TopCallers     []NameCount // sorted desc
	TopCallees     []NameCount // sorted desc
	TopOwners      []NameCount // sorted desc by method count
}

// NameCount pairs a name with a count.
type NameCount struct {
	Name  string
	Count int
}

// ComputeStats computes callgraph statistics from JSONL data.
func ComputeStats(funcs []disasm.FuncRecord, edges []disasm.CallEdgeRecord) CallgraphStats {
	stats := CallgraphStats{
		TotalFunctions: len(funcs),
		TotalEdges:     len(edges),
		ProvCounts:     make(map[string]int),
	}

	callerCount := make(map[string]int)
	calleeCount := make(map[string]int)

	for _, e := range edges {
		prov := ClassifyEdgeProv(e)
		stats.ProvCounts[prov]++

		callerCount[e.FromFunc]++
		if e.Kind == "bl" {
			stats.BLEdges++
			if e.Target != "" {
				calleeCount[e.Target]++
			}
		} else {
			stats.BLREdges++
			if e.Via != "" {
				stats.BLRAnnotated++
			}
		}
	}

	// Count methods per owner class.
	ownerCount := make(map[string]int)
	for _, f := range funcs {
		if f.Owner != "" {
			ownerCount[f.Owner]++
		}
	}
	stats.UniqueOwners = len(ownerCount)

	stats.TopCallers = topNMap(callerCount, 20)
	stats.TopCallees = topNMap(calleeCount, 20)
	stats.TopOwners = topNMap(ownerCount, 30)
	return stats
}

// topNMap returns the top N entries from a map, sorted descending.
func topNMap(m map[string]int, n int) []NameCount {
	entries := make([]NameCount, 0, len(m))
	for name, count := range m {
		entries = append(entries, NameCount{name, count})
	}
	// Sort descending by count.
	for i := 0; i < len(entries); i++ {
		for j := i + 1; j < len(entries); j++ {
			if entries[j].Count > entries[i].Count {
				entries[i], entries[j] = entries[j], entries[i]
			}
		}
	}
	if len(entries) > n {
		entries = entries[:n]
	}
	return entries
}

```

`internal/render/cfg.go`:

```go
package render

import (
	"fmt"
	"strings"

	"unflutter/internal/disasm"
)

// CFGDOT renders a per-function basic-block CFG as DOT.
// Each basic block is a node; edges represent control flow.
// Entry block is highlighted. Conditional edges use T/F colors.
func CFGDOT(cfg disasm.FuncCFG, t Theme) string {
	if len(cfg.Blocks) == 0 {
		return ""
	}

	var b strings.Builder
	b.WriteString("digraph cfg {\n")
	b.WriteString("  rankdir=TB;\n")
	b.WriteString("  nodesep=0.3;\n")
	b.WriteString("  ranksep=0.4;\n")
	fmt.Fprintf(&b, "  bgcolor=%q;\n", t.Background)
	fmt.Fprintf(&b, "  node [shape=rect, style=filled, fillcolor=%q, color=%q, penwidth=0.5, fontname=\"Courier,monospace\", fontsize=8, fontcolor=%q, margin=\"0.08,0.04\"];\n",
		t.NodeFill, t.NodeBorder, t.TextColor)
	fmt.Fprintf(&b, "  edge [penwidth=0.7, arrowsize=0.5, arrowhead=vee];\n")
	fmt.Fprintf(&b, "  labelloc=t;\n  labeljust=l;\n")
	fmt.Fprintf(&b, "  label=<<font face=\"Helvetica Neue,Helvetica\" point-size=\"9\" color=\"%s\">%s</font>>;\n",
		t.TextColor, dotEscape(cfg.Name))
	b.WriteByte('\n')

	// Render blocks as nodes.
	for _, blk := range cfg.Blocks {
		id := fmt.Sprintf("bb%d", blk.ID)

		// Build label: one line per instruction.
		var lines []string
		end := blk.End
		if end > len(cfg.Insts) {
			end = len(cfg.Insts)
		}
		for i := blk.Start; i < end; i++ {
			inst := cfg.Insts[i]
			line := fmt.Sprintf("0x%x: %s", inst.Addr, inst.Text)
			lines = append(lines, dotEscape(line))
		}
		// Truncate long blocks.
		if len(lines) > 12 {
			kept := append(lines[:5], fmt.Sprintf("... (%d more)", len(lines)-10))
			lines = append(kept, lines[len(lines)-5:]...)
		}

		label := strings.Join(lines, "<br align=\"left\"/>")
		label += "<br align=\"left\"/>"

		attrs := ""
		if blk.IsEntry {
			attrs = fmt.Sprintf(", penwidth=1.5, color=%q", t.EdgeTHR)
		}
		if blk.IsTerm {
			attrs += fmt.Sprintf(", fillcolor=%q", t.StubFill)
		}
		fmt.Fprintf(&b, "  %s [label=<%s>%s];\n", id, label, attrs)
	}
	b.WriteByte('\n')

	// Render edges.
	for _, blk := range cfg.Blocks {
		from := fmt.Sprintf("bb%d", blk.ID)
		for _, s := range blk.Succs {
			to := fmt.Sprintf("bb%d", s.BlockID)
			switch s.Cond {
			case "T":
				fmt.Fprintf(&b, "  %s -> %s [color=%q, label=<<font point-size=\"7\" color=\"%s\">T</font>>];\n",
					from, to, t.EdgeTHR, t.EdgeTHR)
			case "F":
				fmt.Fprintf(&b, "  %s -> %s [color=%q, label=<<font point-size=\"7\" color=\"%s\">F</font>>];\n",
					from, to, t.EdgeUnresolved, t.EdgeUnresolved)
			default:
				fmt.Fprintf(&b, "  %s -> %s [color=%q];\n", from, to, t.EdgeDirect)
			}
		}
	}

	b.WriteString("}\n")
	return b.String()
}

```

`internal/render/classgraph.go`:

```go
package render

import (
	"fmt"
	"math"
	"sort"
	"strings"

	"unflutter/internal/disasm"
)

// stripOwnerHash removes the @hash suffix from Dart owner names.
// "_Future@5048458" → "_Future", "PlatformDispatcher" → "PlatformDispatcher".
func stripOwnerHash(s string) string {
	if i := strings.LastIndex(s, "@"); i > 0 {
		return s[:i]
	}
	return s
}

// ClassgraphDOT renders a class-level callgraph where each owner class is one node
// and edges represent aggregated inter-class calls. maxNodes limits rendered classes
// (0 = all). Functions without an owner are grouped under "(unowned)".
func ClassgraphDOT(funcs []disasm.FuncRecord, edges []disasm.CallEdgeRecord, title string, t Theme, maxNodes int) string {
	const unowned = "(unowned)"

	// Map function name → owner.
	funcOwner := make(map[string]string, len(funcs))
	ownerMethodCount := make(map[string]int)
	for _, f := range funcs {
		owner := f.Owner
		if owner == "" {
			owner = unowned
		}
		funcOwner[f.Name] = owner
		ownerMethodCount[owner]++
	}

	// Aggregate inter-class edges.
	type classEdge struct {
		from, to string
	}
	classCounts := make(map[classEdge]int)
	for _, e := range edges {
		srcOwner := funcOwner[e.FromFunc]
		if srcOwner == "" {
			srcOwner = unowned
		}

		// For BL edges, resolve target owner.
		var dstOwner string
		if e.Kind == "bl" && e.Target != "" {
			dstOwner = funcOwner[e.Target]
			if dstOwner == "" {
				dstOwner = unowned
			}
		} else {
			continue // BLR edges don't have named targets for class mapping
		}

		if srcOwner == dstOwner {
			continue // skip intra-class calls
		}
		classCounts[classEdge{srcOwner, dstOwner}]++
	}

	// Collect all classes involved in inter-class edges.
	classInvolvement := make(map[string]int) // total edges touching this class
	for ce, count := range classCounts {
		classInvolvement[ce.from] += count
		classInvolvement[ce.to] += count
	}

	// Rank classes by involvement for maxNodes limit.
	type rankedClass struct {
		name        string
		involvement int
	}
	ranked := make([]rankedClass, 0, len(classInvolvement))
	for name, inv := range classInvolvement {
		ranked = append(ranked, rankedClass{name, inv})
	}
	sort.Slice(ranked, func(i, j int) bool {
		return ranked[i].involvement > ranked[j].involvement
	})

	renderSet := make(map[string]bool)
	limit := len(ranked)
	if maxNodes > 0 && limit > maxNodes {
		limit = maxNodes
	}
	for _, rc := range ranked[:limit] {
		renderSet[rc.name] = true
	}

	// Build DOT.
	var b strings.Builder
	b.WriteString("digraph classgraph {\n")
	b.WriteString("  rankdir=LR;\n")
	b.WriteString("  splines=true;\n")
	b.WriteString("  nodesep=0.5;\n")
	b.WriteString("  ranksep=0.8;\n")
	fmt.Fprintf(&b, "  bgcolor=%q;\n", t.Background)
	fmt.Fprintf(&b, "  node [shape=rect, style=\"filled,rounded\", fillcolor=%q, color=%q, penwidth=0.5, fontname=\"Helvetica Neue,Helvetica,Arial\", fontsize=10, fontcolor=%q, height=0.4, margin=\"0.15,0.08\"];\n",
		t.NodeFill, t.NodeBorder, t.TextColor)
	fmt.Fprintf(&b, "  edge [penwidth=0.5, arrowsize=0.5, arrowhead=vee, color=%q];\n", t.EdgeDirect)
	if title != "" {
		fmt.Fprintf(&b, "  labelloc=t;\n  labeljust=l;\n")
		fmt.Fprintf(&b, "  label=<<font face=\"Helvetica Neue,Helvetica\" point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.TextColor, dotEscape(title))
	}
	b.WriteByte('\n')

	// Render class nodes.
	maxMethods := 1
	for name := range renderSet {
		if c := ownerMethodCount[name]; c > maxMethods {
			maxMethods = c
		}
	}
	for _, rc := range ranked[:limit] {
		name := rc.name
		id := dotID(name)
		label := stripOwnerHash(name)
		methods := ownerMethodCount[name]

		// Scale node height by method count (log scale).
		height := 0.4 + 0.3*math.Log2(float64(methods)+1)/math.Log2(float64(maxMethods)+1)

		// Subtitle with method count.
		htmlLabel := fmt.Sprintf("<<font point-size=\"10\">%s</font><br/><font point-size=\"7\" color=\"%s\">%d methods</font>>",
			dotEscape(label), t.ExternalText, methods)

		if name == unowned {
			fmt.Fprintf(&b, "  %s [label=%s, fillcolor=%q, height=%.2f];\n",
				id, htmlLabel, t.StubFill, height)
		} else {
			fmt.Fprintf(&b, "  %s [label=%s, height=%.2f];\n",
				id, htmlLabel, height)
		}
	}
	b.WriteByte('\n')

	// Render inter-class edges.
	maxEdgeCount := 1
	for ce := range classCounts {
		if !renderSet[ce.from] || !renderSet[ce.to] {
			continue
		}
		if c := classCounts[classEdge{ce.from, ce.to}]; c > maxEdgeCount {
			maxEdgeCount = c
		}
	}

	for ce, count := range classCounts {
		if !renderSet[ce.from] || !renderSet[ce.to] {
			continue
		}
		fromID := dotID(ce.from)
		toID := dotID(ce.to)

		pw := 0.5 + 2.0*math.Log2(float64(count)+1)/math.Log2(float64(maxEdgeCount)+1)
		attrs := fmt.Sprintf("penwidth=%.1f", pw)
		if count > 1 {
			attrs += fmt.Sprintf(", label=<<font point-size=\"7\" color=\"%s\">%d</font>>",
				t.ExternalText, count)
		}
		fmt.Fprintf(&b, "  %s -> %s [%s];\n", fromID, toID, attrs)
	}

	b.WriteString("}\n")
	return b.String()
}

```

`internal/render/helpers.go`:

```go
// Package render produces Graphviz DOT and HTML output from unflutter JSONL.
package render

import (
	"fmt"
	"strings"
)

// dotEscape escapes a string for use in DOT HTML labels.
func dotEscape(s string) string {
	s = strings.ReplaceAll(s, "&", "&amp;")
	s = strings.ReplaceAll(s, "<", "&lt;")
	s = strings.ReplaceAll(s, ">", "&gt;")
	s = strings.ReplaceAll(s, "\"", "&quot;")
	return s
}

// dotID creates a safe DOT identifier from a function name.
func dotID(name string) string {
	var b strings.Builder
	b.WriteString("n_")
	for _, c := range name {
		if (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') || c == '_' {
			b.WriteRune(c)
		} else {
			fmt.Fprintf(&b, "_%04x", c)
		}
	}
	return b.String()
}

// stripMethodName removes the owner prefix from a fully qualified function name.
// "Owner.methodName_1234" → "methodName_1234". Returns the original if no match.
func stripMethodName(funcName, owner string) string {
	prefix := owner + "."
	if strings.HasPrefix(funcName, prefix) {
		return funcName[len(prefix):]
	}
	return funcName
}

// truncLabel shortens a label to maxLen, appending "..." if truncated.
func truncLabel(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	return s[:maxLen-3] + "..."
}

```

`internal/render/html.go`:

```go
package render

import (
	"fmt"
	"io"
	"sort"
	"strings"

	"unflutter/internal/disasm"
)

// WriteIndexHTML writes a small HTML page summarizing the disasm output.
func WriteIndexHTML(w io.Writer, stats CallgraphStats, unresTHR []disasm.UnresolvedTHRRecord, title string,
	hasCallgraphSVG, hasClassgraphSVG, hasReachableSVG bool,
	entryPoints []string, reachableCount int, cfgCount int) {

	blrPct := 0.0
	if stats.BLREdges > 0 {
		blrPct = float64(stats.BLRAnnotated) / float64(stats.BLREdges) * 100
	}

	fmt.Fprintf(w, `<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>%s</title>
<style>
body { font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; font-size: 14px; color: #1A1A1A; background: #F5F5F5; margin: 2em; max-width: 900px; }
h1 { font-size: 18px; font-weight: 600; margin-bottom: 0.5em; }
h2 { font-size: 14px; font-weight: 600; margin-top: 1.5em; border-bottom: 1px solid #ddd; padding-bottom: 4px; }
table { border-collapse: collapse; margin: 0.5em 0; }
th, td { text-align: left; padding: 3px 12px 3px 0; font-size: 13px; }
th { font-weight: 600; }
td.num { text-align: right; font-variant-numeric: tabular-nums; }
.prov { display: inline-block; width: 10px; height: 10px; border-radius: 2px; margin-right: 4px; vertical-align: middle; }
a { color: #0B3D91; }
.bar { height: 8px; border-radius: 2px; display: inline-block; vertical-align: middle; }
.mbar { height: 6px; border-radius: 2px; display: inline-block; vertical-align: middle; background: #0B3D91; }
.ep { font-family: "Courier New", monospace; font-size: 12px; }
</style>
</head>
<body>
`, htmlEscape(title))

	fmt.Fprintf(w, "<h1>%s</h1>\n", htmlEscape(title))

	// Summary table.
	fmt.Fprintln(w, "<h2>Summary</h2>")
	fmt.Fprintln(w, "<table>")
	fmt.Fprintf(w, "<tr><td>Functions</td><td class=\"num\">%d</td></tr>\n", stats.TotalFunctions)
	fmt.Fprintf(w, "<tr><td>Owner classes</td><td class=\"num\">%d</td></tr>\n", stats.UniqueOwners)
	fmt.Fprintf(w, "<tr><td>Total edges</td><td class=\"num\">%d</td></tr>\n", stats.TotalEdges)
	fmt.Fprintf(w, "<tr><td>BL (direct)</td><td class=\"num\">%d</td></tr>\n", stats.BLEdges)
	fmt.Fprintf(w, "<tr><td>BLR (indirect)</td><td class=\"num\">%d</td></tr>\n", stats.BLREdges)
	fmt.Fprintf(w, "<tr><td>BLR annotated</td><td class=\"num\">%d (%.1f%%)</td></tr>\n", stats.BLRAnnotated, blrPct)
	fmt.Fprintf(w, "<tr><td>Entry points</td><td class=\"num\">%d</td></tr>\n", len(entryPoints))
	fmt.Fprintf(w, "<tr><td>Reachable functions</td><td class=\"num\">%d</td></tr>\n", reachableCount)
	fmt.Fprintf(w, "<tr><td>Unresolved THR</td><td class=\"num\">%d</td></tr>\n", len(unresTHR))
	if cfgCount > 0 {
		fmt.Fprintf(w, "<tr><td>CFGs generated</td><td class=\"num\">%d</td></tr>\n", cfgCount)
	}
	fmt.Fprintln(w, "</table>")

	// Provenance breakdown.
	fmt.Fprintln(w, "<h2>Edge Provenance</h2>")
	fmt.Fprintln(w, "<table>")
	fmt.Fprintln(w, "<tr><th></th><th>Category</th><th>Count</th><th></th></tr>")
	provOrder := []string{ProvDirect, ProvTHR, ProvPP, ProvDispatch, ProvObject, ProvUnresolved}
	provLabels := map[string]string{
		ProvDirect:     "BL direct",
		ProvTHR:        "THR (runtime entry)",
		ProvPP:         "PP (object pool)",
		ProvDispatch:   "Dispatch table",
		ProvObject:     "Object field",
		ProvUnresolved: "Unresolved",
	}
	nasa := NASA
	provColors := map[string]string{
		ProvDirect:     nasa.EdgeDirect,
		ProvTHR:        nasa.EdgeTHR,
		ProvPP:         nasa.EdgePP,
		ProvDispatch:   nasa.EdgeDispatch,
		ProvObject:     nasa.EdgeObject,
		ProvUnresolved: nasa.EdgeUnresolved,
	}
	for _, prov := range provOrder {
		count := stats.ProvCounts[prov]
		if count == 0 {
			continue
		}
		color := provColors[prov]
		barW := 0
		if stats.TotalEdges > 0 {
			barW = count * 200 / stats.TotalEdges
			if barW < 2 {
				barW = 2
			}
		}
		fmt.Fprintf(w, "<tr><td><span class=\"prov\" style=\"background:%s\"></span></td><td>%s</td><td class=\"num\">%d</td><td><span class=\"bar\" style=\"width:%dpx;background:%s\"></span></td></tr>\n",
			color, provLabels[prov], count, barW, color)
	}
	fmt.Fprintln(w, "</table>")

	// Graphs — only link SVGs (dot files can't be opened in a browser).
	fmt.Fprintln(w, "<h2>Graphs</h2>")
	fmt.Fprint(w, "<p>")
	var links []string
	if hasReachableSVG {
		links = append(links, `<a href="reachable.svg">Reachable call tree</a>`)
	}
	if hasClassgraphSVG {
		links = append(links, `<a href="classgraph.svg">Class-level graph</a>`)
	}
	if hasCallgraphSVG {
		links = append(links, `<a href="callgraph.svg">Function-level graph</a>`)
	}
	if cfgCount > 0 {
		links = append(links, `<a href="cfg/">Per-function CFGs</a>`)
	}
	if len(links) == 0 {
		fmt.Fprint(w, `<span style="color:#9E9E9E">Run without --no-dot to generate SVGs</span>`)
	} else {
		for i, link := range links {
			if i > 0 {
				fmt.Fprint(w, " | ")
			}
			fmt.Fprint(w, link)
		}
	}
	fmt.Fprintln(w, "</p>")

	// Entry points.
	if len(entryPoints) > 0 {
		fmt.Fprintln(w, "<h2>Entry Points</h2>")
		fmt.Fprintf(w, "<p>%d functions with no incoming BL edges (roots of the call tree):</p>\n", len(entryPoints))
		fmt.Fprintln(w, "<table>")
		fmt.Fprintln(w, "<tr><th>Function</th></tr>")
		limit := 50
		if len(entryPoints) < limit {
			limit = len(entryPoints)
		}
		for _, ep := range entryPoints[:limit] {
			cfgLink := ""
			if cfgCount > 0 {
				safe := safeFuncNameHTML(ep)
				cfgLink = fmt.Sprintf(` <a href="cfg/%s.svg" style="font-size:11px">[cfg]</a>`, safe)
			}
			fmt.Fprintf(w, "<tr><td class=\"ep\">%s%s</td></tr>\n", htmlEscape(ep), cfgLink)
		}
		if len(entryPoints) > limit {
			fmt.Fprintf(w, "<tr><td>... and %d more</td></tr>\n", len(entryPoints)-limit)
		}
		fmt.Fprintln(w, "</table>")
	}

	// Top classes by method count.
	if len(stats.TopOwners) > 0 {
		fmt.Fprintln(w, "<h2>Top Classes</h2>")
		fmt.Fprintln(w, "<table>")
		fmt.Fprintln(w, "<tr><th>Class</th><th>Methods</th><th></th></tr>")
		limit := 20
		if len(stats.TopOwners) < limit {
			limit = len(stats.TopOwners)
		}
		maxCount := stats.TopOwners[0].Count
		for _, nc := range stats.TopOwners[:limit] {
			barW := nc.Count * 120 / maxCount
			if barW < 2 {
				barW = 2
			}
			fmt.Fprintf(w, "<tr><td>%s</td><td class=\"num\">%d</td><td><span class=\"mbar\" style=\"width:%dpx\"></span></td></tr>\n",
				htmlEscape(stripOwnerHash(nc.Name)), nc.Count, barW)
		}
		fmt.Fprintln(w, "</table>")
	}

	// Top callers.
	if len(stats.TopCallers) > 0 {
		fmt.Fprintln(w, "<h2>Top Callers</h2>")
		fmt.Fprintln(w, "<table>")
		fmt.Fprintln(w, "<tr><th>Function</th><th>Outgoing</th></tr>")
		limit := 15
		if len(stats.TopCallers) < limit {
			limit = len(stats.TopCallers)
		}
		for _, nc := range stats.TopCallers[:limit] {
			fmt.Fprintf(w, "<tr><td>%s</td><td class=\"num\">%d</td></tr>\n", htmlEscape(nc.Name), nc.Count)
		}
		fmt.Fprintln(w, "</table>")
	}

	// Top callees.
	if len(stats.TopCallees) > 0 {
		fmt.Fprintln(w, "<h2>Top Callees</h2>")
		fmt.Fprintln(w, "<table>")
		fmt.Fprintln(w, "<tr><th>Function</th><th>Incoming</th></tr>")
		limit := 15
		if len(stats.TopCallees) < limit {
			limit = len(stats.TopCallees)
		}
		for _, nc := range stats.TopCallees[:limit] {
			fmt.Fprintf(w, "<tr><td>%s</td><td class=\"num\">%d</td></tr>\n", htmlEscape(nc.Name), nc.Count)
		}
		fmt.Fprintln(w, "</table>")
	}

	// Unresolved THR summary.
	if len(unresTHR) > 0 {
		fmt.Fprintln(w, "<h2>Unresolved THR Accesses</h2>")
		// Group by offset.
		type offInfo struct {
			offset string
			class  string
			count  int
		}
		offMap := make(map[string]*offInfo)
		for _, r := range unresTHR {
			if oi, ok := offMap[r.THROffset]; ok {
				oi.count++
			} else {
				offMap[r.THROffset] = &offInfo{r.THROffset, r.Class, 1}
			}
		}
		// Sort by offset for stable output.
		offSlice := make([]*offInfo, 0, len(offMap))
		for _, oi := range offMap {
			offSlice = append(offSlice, oi)
		}
		sort.Slice(offSlice, func(i, j int) bool {
			return offSlice[i].offset < offSlice[j].offset
		})
		fmt.Fprintln(w, "<table>")
		fmt.Fprintln(w, "<tr><th>Offset</th><th>Class</th><th>Count</th></tr>")
		for _, oi := range offSlice {
			fmt.Fprintf(w, "<tr><td>%s</td><td>%s</td><td class=\"num\">%d</td></tr>\n",
				htmlEscape(oi.offset), htmlEscape(oi.class), oi.count)
		}
		fmt.Fprintln(w, "</table>")
	}

	fmt.Fprintln(w, "</body></html>")
}

func htmlEscape(s string) string {
	s = strings.ReplaceAll(s, "&", "&amp;")
	s = strings.ReplaceAll(s, "<", "&lt;")
	s = strings.ReplaceAll(s, ">", "&gt;")
	s = strings.ReplaceAll(s, "\"", "&quot;")
	return s
}

// safeFuncNameHTML converts a function name to a safe filename.
// Must match sanitizeFilename in cmd/unflutter/disasm.go.
func safeFuncNameHTML(name string) string {
	r := strings.NewReplacer(
		"/", "_",
		"\\", "_",
		":", "_",
		"*", "_",
		"?", "_",
		"\"", "_",
		"<", "_",
		">", "_",
		"|", "_",
		" ", "_",
	)
	s := r.Replace(name)
	if len(s) > 200 {
		s = s[:200]
	}
	return s
}

```

`internal/render/reachability.go`:

```go
package render

import (
	"fmt"
	"sort"
	"strings"

	"unflutter/internal/disasm"
)

// FindEntryPoints returns functions that have no incoming BL edges.
// Runtime stubs (sub_*) are excluded since they're callees, not true entry points.
func FindEntryPoints(funcs []disasm.FuncRecord, edges []disasm.CallEdgeRecord) []string {
	// Collect all named BL targets.
	blTargets := make(map[string]bool)
	for _, e := range edges {
		if e.Kind == "bl" && e.Target != "" {
			blTargets[e.Target] = true
		}
	}

	// Functions not targeted by any BL = entry points.
	var entries []string
	for _, f := range funcs {
		if strings.HasPrefix(f.Name, "sub_") {
			continue // runtime stubs are not meaningful entry points
		}
		if !blTargets[f.Name] {
			entries = append(entries, f.Name)
		}
	}
	sort.Strings(entries)
	return entries
}

// ReachableSet performs BFS from entry points following BL edges
// and returns the set of all reachable function names.
func ReachableSet(entryPoints []string, edges []disasm.CallEdgeRecord) map[string]bool {
	// Build adjacency list from BL edges.
	adj := make(map[string][]string)
	for _, e := range edges {
		if e.Kind == "bl" && e.Target != "" {
			adj[e.FromFunc] = append(adj[e.FromFunc], e.Target)
		}
	}

	reachable := make(map[string]bool)
	queue := make([]string, 0, len(entryPoints))
	for _, ep := range entryPoints {
		if !reachable[ep] {
			reachable[ep] = true
			queue = append(queue, ep)
		}
	}

	for len(queue) > 0 {
		fn := queue[0]
		queue = queue[1:]
		for _, target := range adj[fn] {
			if !reachable[target] {
				reachable[target] = true
				queue = append(queue, target)
			}
		}
	}
	return reachable
}

// ReachabilityDOT renders a callgraph filtered to the reachable set.
// Entry points are highlighted. Only BL edges between reachable functions are shown.
func ReachabilityDOT(funcs []disasm.FuncRecord, edges []disasm.CallEdgeRecord, reachable map[string]bool, entryPoints []string, title string, t Theme) string {
	entrySet := make(map[string]bool, len(entryPoints))
	for _, ep := range entryPoints {
		entrySet[ep] = true
	}

	// Build func name→owner map.
	funcOwner := make(map[string]string, len(funcs))
	for _, f := range funcs {
		funcOwner[f.Name] = f.Owner
	}

	// Deduplicate BL edges within reachable set.
	type edgeKey struct{ from, to string }
	edgeCount := make(map[edgeKey]int)
	for _, e := range edges {
		if e.Kind != "bl" || e.Target == "" {
			continue
		}
		if !reachable[e.FromFunc] || !reachable[e.Target] {
			continue
		}
		edgeCount[edgeKey{e.FromFunc, e.Target}]++
	}

	// Collect referenced nodes.
	refNodes := make(map[string]bool)
	for k := range edgeCount {
		refNodes[k.from] = true
		refNodes[k.to] = true
	}
	// Also include entry points even if they have no edges.
	for _, ep := range entryPoints {
		refNodes[ep] = true
	}

	// Group by owner for clustering.
	ownerFuncs := make(map[string][]string)
	var noOwner []string
	for name := range refNodes {
		owner := funcOwner[name]
		if owner != "" {
			ownerFuncs[owner] = append(ownerFuncs[owner], name)
		} else {
			noOwner = append(noOwner, name)
		}
	}

	var b strings.Builder
	b.WriteString("digraph reachable {\n")
	b.WriteString("  rankdir=LR;\n")
	b.WriteString("  compound=true;\n")
	b.WriteString("  splines=true;\n")
	b.WriteString("  nodesep=0.4;\n")
	b.WriteString("  ranksep=0.6;\n")
	fmt.Fprintf(&b, "  bgcolor=%q;\n", t.Background)
	fmt.Fprintf(&b, "  node [shape=rect, style=filled, fillcolor=%q, color=%q, penwidth=0.5, fontname=\"Helvetica Neue,Helvetica,Arial\", fontsize=9, fontcolor=%q, height=0.3, margin=\"0.12,0.06\"];\n",
		t.NodeFill, t.NodeBorder, t.TextColor)
	fmt.Fprintf(&b, "  edge [penwidth=0.5, arrowsize=0.5, arrowhead=vee, color=%q];\n", t.EdgeDirect)
	if title != "" {
		fmt.Fprintf(&b, "  labelloc=t;\n  labeljust=l;\n")
		fmt.Fprintf(&b, "  label=<<font face=\"Helvetica Neue,Helvetica\" point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.TextColor, dotEscape(title))
	}
	b.WriteByte('\n')

	writeNode := func(name string) {
		id := dotID(name)
		label := truncLabel(name, 50)
		if entrySet[name] {
			fmt.Fprintf(&b, "    %s [label=%q, penwidth=1.5, color=%q];\n", id, label, t.EdgeTHR)
		} else {
			fmt.Fprintf(&b, "    %s [label=%q];\n", id, label)
		}
	}

	// Clustered nodes.
	for owner, names := range ownerFuncs {
		if len(names) < 2 {
			noOwner = append(noOwner, names...)
			continue
		}
		sort.Strings(names)
		clusterID := "cluster_" + dotID(owner)
		fmt.Fprintf(&b, "  subgraph %s {\n", clusterID)
		fmt.Fprintf(&b, "    label=<<font point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.ClusterLabel, dotEscape(stripOwnerHash(owner)))
		fmt.Fprintf(&b, "    style=dotted; color=%q; penwidth=0.3;\n", t.ClusterBorder)
		for _, name := range names {
			writeNode(name)
		}
		b.WriteString("  }\n")
	}
	sort.Strings(noOwner)
	for _, name := range noOwner {
		b.WriteString("  ")
		writeNode(name)
	}
	b.WriteByte('\n')

	// Edges.
	for k, count := range edgeCount {
		fromID := dotID(k.from)
		toID := dotID(k.to)
		attrs := fmt.Sprintf("color=%q", t.EdgeDirect)
		if count > 1 {
			attrs += fmt.Sprintf(", penwidth=%.1f", 0.5+float64(count)*0.1)
		}
		fmt.Fprintf(&b, "  %s -> %s [%s];\n", fromID, toID, attrs)
	}

	b.WriteString("}\n")
	return b.String()
}

```

`internal/render/signal_cfg_dot.go`:

```go
package render

import (
	"fmt"
	"sort"
	"strings"

	"unflutter/internal/signal"
)

// ClassifiedString is a string ref with its signal category for rendering.
type ClassifiedString struct {
	Value    string
	Category string // primary category (e.g. "encryption", "auth", "url")
}

// SignalFuncContent holds the interesting calls and string refs for one signal function,
// collected by re-disassembly from bin files.
type SignalFuncContent struct {
	Calls   []string           // deduplicated callee names
	Strings []ClassifiedString // deduplicated classified string refs
}

// SignalCFGDOT renders a connected signal graph where each signal function is a node
// showing its interesting calls and string refs, and edges show how signal functions
// call each other (both directly and through intermediate context functions).
func SignalCFGDOT(g *signal.SignalGraph, content map[string]*SignalFuncContent, title string, t Theme) string {
	// Index functions.
	type funcInfo struct {
		severity   string
		categories []string
		owner      string
	}
	funcMap := make(map[string]*funcInfo, len(g.Funcs))
	signalSet := make(map[string]bool)
	for _, f := range g.Funcs {
		funcMap[f.Name] = &funcInfo{
			severity:   f.Severity,
			categories: f.Categories,
			owner:      f.Owner,
		}
		if f.Role == "signal" {
			signalSet[f.Name] = true
		}
	}

	// Build forward adjacency from all edges (BL only) for path finding.
	fwd := make(map[string][]string)
	for _, e := range g.Edges {
		if e.Kind == "bl" && e.To != "" {
			fwd[e.From] = append(fwd[e.From], e.To)
		}
	}

	// Find direct signal→signal edges (BL and BLR).
	type edgeInfo struct {
		from, to string
		kind     string // "bl" or "blr"
		via      string
	}
	var signalEdges []edgeInfo
	edgeSeen := make(map[[2]string]bool)

	for _, e := range g.Edges {
		if e.To == "" {
			continue
		}
		from, to := e.From, e.To
		if !signalSet[from] || !signalSet[to] {
			continue
		}
		key := [2]string{from, to}
		if edgeSeen[key] {
			continue
		}
		edgeSeen[key] = true
		signalEdges = append(signalEdges, edgeInfo{from, to, e.Kind, e.Via})
	}

	// BFS from each signal function through context nodes to find signal→signal reachability.
	// This captures indirect paths: signal_A → context → context → signal_B.
	for src := range signalSet {
		visited := map[string]bool{src: true}
		queue := []string{src}
		for len(queue) > 0 {
			cur := queue[0]
			queue = queue[1:]
			for _, next := range fwd[cur] {
				if visited[next] {
					continue
				}
				visited[next] = true
				if signalSet[next] {
					// Found a path from src to next signal function.
					key := [2]string{src, next}
					if !edgeSeen[key] {
						edgeSeen[key] = true
						signalEdges = append(signalEdges, edgeInfo{src, next, "bl", ""})
					}
					// Don't continue BFS through signal nodes (they're their own roots).
				} else {
					// Context/other node — keep searching through it.
					queue = append(queue, next)
				}
			}
		}
	}

	// Only render signal functions that have content or edges.
	hasEdge := make(map[string]bool)
	for _, e := range signalEdges {
		hasEdge[e.from] = true
		hasEdge[e.to] = true
	}
	activeSignal := make(map[string]bool)
	for name := range signalSet {
		if hasEdge[name] {
			activeSignal[name] = true
			continue
		}
		if c, ok := content[name]; ok && (len(c.Calls) > 0 || len(c.Strings) > 0) {
			activeSignal[name] = true
		}
	}

	// Render DOT.
	var b strings.Builder
	b.WriteString("digraph signal_cfg {\n")
	b.WriteString("  rankdir=LR;\n")
	b.WriteString("  compound=true;\n")
	b.WriteString("  splines=true;\n")
	b.WriteString("  nodesep=0.4;\n")
	b.WriteString("  ranksep=0.6;\n")
	fmt.Fprintf(&b, "  bgcolor=%q;\n", t.Background)
	fmt.Fprintf(&b, "  node [shape=plaintext, fontname=\"Helvetica Neue,Helvetica,Arial\", fontsize=9, fontcolor=%q];\n", t.TextColor)
	fmt.Fprintf(&b, "  edge [penwidth=0.7, arrowsize=0.5, arrowhead=vee, color=%q];\n", t.EdgeDirect)
	if title != "" {
		fmt.Fprintf(&b, "  labelloc=t; labeljust=l;\n")
		fmt.Fprintf(&b, "  label=<<font face=\"Helvetica Neue,Helvetica\" point-size=\"9\" color=\"%s\">%s</font>>;\n",
			t.TextColor, dotEscape(title))
	}
	b.WriteByte('\n')

	// Group by owner for clustering.
	ownerNodes := make(map[string][]string)
	var noOwner []string
	for name := range activeSignal {
		fi := funcMap[name]
		if fi != nil && fi.owner != "" {
			ownerNodes[fi.owner] = append(ownerNodes[fi.owner], name)
		} else {
			noOwner = append(noOwner, name)
		}
	}

	writeNode := func(name string) {
		fi := funcMap[name]
		id := dotID(name)
		label := truncLabel(name, 45)

		// Pick border/header color by severity.
		borderColor := "#1565C0" // blue (low/default)
		headerBG := "#E3F2FD"
		if fi != nil {
			switch fi.severity {
			case "high":
				borderColor = "#C62828"
				headerBG = "#FCE4EC"
			case "medium":
				borderColor = "#E65100"
				headerBG = "#FFF3E0"
			}
		}

		// Build HTML table label.
		var tbl strings.Builder
		tbl.WriteString("<<TABLE BORDER=\"1\" CELLBORDER=\"0\" CELLSPACING=\"0\" CELLPADDING=\"3\"")
		fmt.Fprintf(&tbl, " COLOR=%q BGCOLOR=\"white\"", borderColor)
		tbl.WriteString(">\n")

		// Header: function name + categories.
		fmt.Fprintf(&tbl, "    <TR><TD BGCOLOR=%q ALIGN=\"LEFT\"><FONT POINT-SIZE=\"9\" COLOR=%q><B>%s</B></FONT>",
			headerBG, borderColor, dotEscape(label))
		if fi != nil && len(fi.categories) > 0 {
			cats := strings.Join(fi.categories, ", ")
			if len(cats) > 35 {
				cats = cats[:35] + "..."
			}
			fmt.Fprintf(&tbl, "<BR/><FONT POINT-SIZE=\"7\" COLOR=\"#757575\">%s</FONT>", dotEscape(cats))
		}
		tbl.WriteString("</TD></TR>\n")

		// Calls section.
		c := content[name]
		if c != nil && len(c.Calls) > 0 {
			tbl.WriteString("    <HR/>\n")
			maxCalls := 8
			for i, callee := range c.Calls {
				if i >= maxCalls {
					fmt.Fprintf(&tbl, "    <TR><TD ALIGN=\"LEFT\"><FONT POINT-SIZE=\"7\" COLOR=\"#757575\">+%d more calls</FONT></TD></TR>\n",
						len(c.Calls)-maxCalls)
					break
				}
				cl := callee
				if len(cl) > 45 {
					cl = cl[:42] + "..."
				}
				icon := "&#x2192;" // →
				fmt.Fprintf(&tbl, "    <TR><TD ALIGN=\"LEFT\"><FONT POINT-SIZE=\"7\" FACE=\"monospace\" COLOR=\"#424242\">%s %s</FONT></TD></TR>\n",
					icon, dotEscape(cl))
			}
		}

		// Strings section — classified with category colors.
		if c != nil && len(c.Strings) > 0 {
			tbl.WriteString("    <HR/>\n")
			maxStrs := 5
			for i, s := range c.Strings {
				if i >= maxStrs {
					fmt.Fprintf(&tbl, "    <TR><TD ALIGN=\"LEFT\"><FONT POINT-SIZE=\"7\" COLOR=\"#757575\">+%d more strings</FONT></TD></TR>\n",
						len(c.Strings)-maxStrs)
					break
				}
				sv := s.Value
				if len(sv) > 50 {
					sv = sv[:47] + "..."
				}
				color := strCategoryColor(s.Category)
				catLabel := ""
				if s.Category != "" {
					catLabel = " [" + s.Category + "]"
				}
				fmt.Fprintf(&tbl, "    <TR><TD ALIGN=\"LEFT\"><FONT POINT-SIZE=\"7\" FACE=\"Courier\" COLOR=%q>\"%s\"%s</FONT></TD></TR>\n",
					color, dotEscape(sv), dotEscape(catLabel))
			}
		}

		tbl.WriteString("  </TABLE>>")
		fmt.Fprintf(&b, "    %s [label=%s];\n", id, tbl.String())
	}

	// Render clusters.
	for owner, names := range ownerNodes {
		if len(names) < 2 {
			noOwner = append(noOwner, names...)
			continue
		}
		sort.Strings(names)
		clusterID := "cluster_" + dotID(owner)
		fmt.Fprintf(&b, "  subgraph %s {\n", clusterID)
		fmt.Fprintf(&b, "    label=<<font point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.ClusterLabel, dotEscape(stripOwnerHash(owner)))
		fmt.Fprintf(&b, "    style=dotted; color=%q; penwidth=0.3;\n", t.ClusterBorder)
		for _, name := range names {
			writeNode(name)
		}
		b.WriteString("  }\n")
	}
	sort.Strings(noOwner)
	for _, name := range noOwner {
		b.WriteString("  ")
		writeNode(name)
	}
	b.WriteByte('\n')

	// Render edges.
	for _, e := range signalEdges {
		fromID := dotID(e.from)
		toID := dotID(e.to)
		if e.kind == "blr" {
			attrs := fmt.Sprintf("style=dashed, color=%q, penwidth=0.5", t.EdgePP)
			if e.via != "" {
				via := e.via
				if len(via) > 20 {
					via = via[:20]
				}
				attrs += fmt.Sprintf(", label=%q, fontsize=7, fontcolor=%q", via, t.ClusterLabel)
			}
			fmt.Fprintf(&b, "  %s -> %s [%s];\n", fromID, toID, attrs)
		} else {
			fmt.Fprintf(&b, "  %s -> %s [color=%q];\n", fromID, toID, t.EdgeDirect)
		}
	}

	b.WriteString("}\n")
	return b.String()
}

// strCategoryColor returns a DOT color for a signal string category.
func strCategoryColor(cat string) string {
	switch cat {
	case "crypto", "encryption":
		return "#C62828" // red
	case "auth":
		return "#AD1457" // dark pink
	case "url", "host":
		return "#0B3D91" // blue
	case "cloaking", "sim", "sms", "contacts":
		return "#C62828" // red
	case "device", "location":
		return "#E65100" // orange
	default:
		return "#C2185B" // pink
	}
}

```

`internal/render/signal_dot.go`:

```go
package render

import (
	"fmt"
	"sort"
	"strings"

	"unflutter/internal/signal"
)

// SignalDOT renders a focused callgraph showing paths from entry points to signal functions.
// Uses forward BFS from entry points, traces shortest paths to each reachable signal function,
// includes all intermediate nodes. Signal functions show their referenced strings as leaf nodes.
// BLR (indirect call) edges between path nodes are shown with dashed lines.
func SignalDOT(g *signal.SignalGraph, title string, t Theme) string {
	// Index functions and collect string refs.
	type funcInfo struct {
		role       string
		severity   string
		isEntry    bool
		categories []string
		owner      string
		stringRefs []signal.ClassifiedStringRef
	}
	funcMap := make(map[string]*funcInfo, len(g.Funcs))
	for _, f := range g.Funcs {
		funcMap[f.Name] = &funcInfo{
			role:       f.Role,
			severity:   f.Severity,
			isEntry:    f.IsEntryPoint,
			categories: f.Categories,
			owner:      f.Owner,
			stringRefs: f.StringRefs,
		}
	}

	// Build BL and BLR adjacency.
	fwd := make(map[string][]string)       // BL only
	blrEdges := make(map[[2]string]string) // [from,to] → via label
	for _, e := range g.Edges {
		if e.To == "" {
			continue
		}
		if e.Kind == "bl" {
			fwd[e.From] = append(fwd[e.From], e.To)
		} else if e.Kind == "blr" {
			key := [2]string{e.From, e.To}
			if _, ok := blrEdges[key]; !ok {
				blrEdges[key] = e.Via
			}
		}
	}

	// Find high+medium severity signal functions.
	signalSet := make(map[string]bool)
	for _, f := range g.Funcs {
		if f.Role == "signal" && (f.Severity == "high" || f.Severity == "medium") {
			signalSet[f.Name] = true
		}
	}
	if len(signalSet) == 0 {
		for _, f := range g.Funcs {
			if f.Role == "signal" {
				signalSet[f.Name] = true
			}
		}
	}

	// Build reverse adjacency to find true roots (no BL callers).
	hasCaller := make(map[string]bool)
	for _, e := range g.Edges {
		if e.Kind == "bl" && e.To != "" {
			hasCaller[e.To] = true
		}
	}

	// Forward BFS from all root functions (no incoming BL edges).
	parent := make(map[string]string) // child → parent
	dist := make(map[string]int)
	maxDist := 8

	type bfsItem struct {
		name string
		d    int
	}
	var queue []bfsItem
	for _, f := range g.Funcs {
		if !hasCaller[f.Name] {
			if _, ok := dist[f.Name]; !ok {
				dist[f.Name] = 0
				queue = append(queue, bfsItem{f.Name, 0})
			}
		}
	}
	for len(queue) > 0 {
		item := queue[0]
		queue = queue[1:]
		if item.d >= maxDist {
			continue
		}
		for _, next := range fwd[item.name] {
			if _, ok := dist[next]; !ok {
				dist[next] = item.d + 1
				parent[next] = item.name
				queue = append(queue, bfsItem{next, item.d + 1})
			}
		}
	}

	// For each reachable signal function, trace back to the entry point.
	pathNodes := make(map[string]bool)
	pathEdges := make(map[[2]string]bool)
	for name := range signalSet {
		if _, ok := dist[name]; !ok {
			continue // unreachable from any entry point
		}
		cur := name
		for cur != "" {
			pathNodes[cur] = true
			p, ok := parent[cur]
			if !ok {
				break // reached an entry point (no parent)
			}
			pathEdges[[2]string{p, cur}] = true
			cur = p
		}
	}

	// Also add direct edges between signal functions for intra-signal structure.
	for _, e := range g.Edges {
		if e.Kind == "bl" && signalSet[e.From] && signalSet[e.To] {
			pathNodes[e.From] = true
			pathNodes[e.To] = true
			pathEdges[[2]string{e.From, e.To}] = true
		}
	}

	// Include signal functions that are roots (no callers).
	for name := range signalSet {
		if !hasCaller[name] {
			pathNodes[name] = true
		}
	}

	// If no paths found (signal funcs unreachable from entry points),
	// just show signal funcs and their 1-hop neighbors.
	if len(pathEdges) == 0 {
		for name := range signalSet {
			pathNodes[name] = true
			for _, callee := range fwd[name] {
				pathNodes[callee] = true
				pathEdges[[2]string{name, callee}] = true
			}
		}
	}

	// Prune long chains: collapse intermediate nodes that are neither
	// entry points nor signal functions and have exactly 1 in + 1 out edge.
	for changed := true; changed; {
		changed = false
		for name := range pathNodes {
			fi := funcMap[name]
			if fi == nil {
				continue
			}
			if !hasCaller[name] || signalSet[name] || fi.role == "signal" {
				continue
			}
			var ins, outs [][2]string
			for e := range pathEdges {
				if e[1] == name {
					ins = append(ins, e)
				}
				if e[0] == name {
					outs = append(outs, e)
				}
			}
			if len(ins) == 1 && len(outs) == 1 {
				from := ins[0][0]
				to := outs[0][1]
				delete(pathEdges, ins[0])
				delete(pathEdges, outs[0])
				pathEdges[[2]string{from, to}] = true
				delete(pathNodes, name)
				changed = true
			}
		}
	}

	// Collect BLR edges between path nodes.
	type blrEdge struct {
		from, to, via string
	}
	var pathBLR []blrEdge
	for key, via := range blrEdges {
		if pathNodes[key[0]] && pathNodes[key[1]] && key[0] != key[1] {
			// Skip if a BL edge already exists for this pair.
			if !pathEdges[key] {
				pathBLR = append(pathBLR, blrEdge{key[0], key[1], via})
			}
		}
	}

	// Collect string ref nodes for signal functions in the path.
	// Deduplicate by value per function, cap at 5 strings per function.
	type strNode struct {
		id    string // unique DOT id
		label string
		cat   string // primary category
	}
	const maxStrPerFunc = 5
	var strNodes []strNode
	strEdges := make(map[[2]string]bool) // func DOT id → str DOT id
	strIdx := 0
	for name := range pathNodes {
		fi := funcMap[name]
		if fi == nil || !signalSet[name] || len(fi.stringRefs) == 0 {
			continue
		}
		seen := make(map[string]bool)
		count := 0
		for _, sr := range fi.stringRefs {
			if seen[sr.Value] || count >= maxStrPerFunc {
				continue
			}
			seen[sr.Value] = true
			count++
			sid := fmt.Sprintf("str_%d", strIdx)
			strIdx++
			label := sr.Value
			if len(label) > 60 {
				label = label[:57] + "..."
			}
			cat := ""
			if len(sr.Categories) > 0 {
				cat = sr.Categories[0]
			}
			strNodes = append(strNodes, strNode{id: sid, label: label, cat: cat})
			strEdges[[2]string{dotID(name), sid}] = true
		}
		if len(fi.stringRefs) > maxStrPerFunc && count == maxStrPerFunc {
			sid := fmt.Sprintf("str_%d", strIdx)
			strIdx++
			more := len(fi.stringRefs) - maxStrPerFunc
			strNodes = append(strNodes, strNode{id: sid, label: fmt.Sprintf("+%d more", more)})
			strEdges[[2]string{dotID(name), sid}] = true
		}
	}

	// Render DOT.
	var b strings.Builder
	b.WriteString("digraph signal {\n")
	b.WriteString("  rankdir=LR;\n")
	b.WriteString("  compound=true;\n")
	b.WriteString("  splines=true;\n")
	b.WriteString("  nodesep=0.3;\n")
	b.WriteString("  ranksep=0.5;\n")
	fmt.Fprintf(&b, "  bgcolor=%q;\n", t.Background)
	fmt.Fprintf(&b, "  node [shape=rect, style=filled, fillcolor=%q, color=%q, penwidth=0.5, fontname=\"Helvetica Neue,Helvetica,Arial\", fontsize=9, fontcolor=%q, height=0.3, margin=\"0.10,0.05\"];\n",
		t.NodeFill, t.NodeBorder, t.TextColor)
	fmt.Fprintf(&b, "  edge [penwidth=0.6, arrowsize=0.5, arrowhead=vee, color=%q];\n", t.EdgeDirect)
	if title != "" {
		fmt.Fprintf(&b, "  labelloc=t; labeljust=l;\n")
		fmt.Fprintf(&b, "  label=<<font face=\"Helvetica Neue,Helvetica\" point-size=\"9\" color=\"%s\">%s</font>>;\n",
			t.TextColor, dotEscape(title))
	}
	b.WriteByte('\n')

	// Group by owner for clustering.
	ownerNodes := make(map[string][]string)
	var noOwner []string
	for name := range pathNodes {
		fi := funcMap[name]
		if fi != nil && fi.owner != "" {
			ownerNodes[fi.owner] = append(ownerNodes[fi.owner], name)
		} else {
			noOwner = append(noOwner, name)
		}
	}

	writeNode := func(name string) {
		fi := funcMap[name]
		id := dotID(name)
		label := truncLabel(name, 40)
		attrs := ""

		if signalSet[name] {
			switch fi.severity {
			case "high":
				attrs = `, fillcolor="#FCE4EC", color="#C62828", penwidth=1.5, fontcolor="#C62828"`
			case "medium":
				attrs = `, fillcolor="#FFF3E0", color="#E65100", penwidth=1.2, fontcolor="#E65100"`
			default:
				attrs = `, fillcolor="#E3F2FD", color="#1565C0", penwidth=1.0`
			}
			if len(fi.categories) > 0 {
				cats := strings.Join(fi.categories, ",")
				if len(cats) > 30 {
					cats = cats[:30] + "..."
				}
				label += "\\n" + cats
			}
		} else if !hasCaller[name] {
			attrs = fmt.Sprintf(`, fillcolor="#E8F5E9", color="%s", penwidth=1.2`, t.EdgeTHR)
		} else {
			// Intermediate context node.
			attrs = `, fillcolor="#F5F5F5", color="#BDBDBD", fontcolor="#757575"`
		}

		fmt.Fprintf(&b, "    %s [label=%q%s];\n", id, label, attrs)
	}

	for owner, names := range ownerNodes {
		if len(names) < 2 {
			noOwner = append(noOwner, names...)
			continue
		}
		sort.Strings(names)
		clusterID := "cluster_" + dotID(owner)
		fmt.Fprintf(&b, "  subgraph %s {\n", clusterID)
		fmt.Fprintf(&b, "    label=<<font point-size=\"8\" color=\"%s\">%s</font>>;\n",
			t.ClusterLabel, dotEscape(stripOwnerHash(owner)))
		fmt.Fprintf(&b, "    style=dotted; color=%q; penwidth=0.3;\n", t.ClusterBorder)
		for _, name := range names {
			writeNode(name)
		}
		b.WriteString("  }\n")
	}
	sort.Strings(noOwner)
	for _, name := range noOwner {
		b.WriteString("  ")
		writeNode(name)
	}
	b.WriteByte('\n')

	// String literal nodes.
	if len(strNodes) > 0 {
		b.WriteString("  // String literals\n")
		for _, sn := range strNodes {
			color := "#C2185B" // pink
			switch sn.cat {
			case "crypto", "encryption":
				color = "#C62828" // red
			case "auth":
				color = "#AD1457" // dark pink
			case "url", "host":
				color = "#0B3D91" // blue
			case "cloaking", "sim", "sms", "contacts":
				color = "#C62828" // red
			}
			fmt.Fprintf(&b, "  %s [shape=rect, style=\"filled,rounded\", fillcolor=\"#FFF8E1\", color=%q, penwidth=0.3, fontsize=7, fontcolor=%q, fontname=\"Courier,monospace\", margin=\"0.06,0.03\", height=0.2, label=%q];\n",
				sn.id, color, color, sn.label)
		}
		b.WriteByte('\n')
	}

	// BL edges (direct calls).
	for edge := range pathEdges {
		fromID := dotID(edge[0])
		toID := dotID(edge[1])
		attrs := fmt.Sprintf("color=%q", t.EdgeDirect)
		if signalSet[edge[1]] {
			attrs = fmt.Sprintf("color=%q, penwidth=1.0", t.EdgeTHR)
		}
		fmt.Fprintf(&b, "  %s -> %s [%s];\n", fromID, toID, attrs)
	}

	// BLR edges (indirect calls) — dashed.
	for _, e := range pathBLR {
		fromID := dotID(e.from)
		toID := dotID(e.to)
		via := e.via
		if len(via) > 20 {
			via = via[:20]
		}
		attrs := fmt.Sprintf("style=dashed, color=%q, penwidth=0.5", t.EdgePP)
		if via != "" {
			attrs += fmt.Sprintf(", label=%q, fontsize=7, fontcolor=%q", via, t.ClusterLabel)
		}
		fmt.Fprintf(&b, "  %s -> %s [%s];\n", fromID, toID, attrs)
	}

	// String ref edges — dotted, thin.
	for edge := range strEdges {
		fmt.Fprintf(&b, "  %s -> %s [style=dotted, arrowsize=0.3, penwidth=0.4, color=\"#C2185B\"];\n",
			edge[0], edge[1])
	}

	b.WriteString("}\n")
	return b.String()
}

```

`internal/render/signal_html.go`:

```go
package render

import (
	"bytes"
	"compress/gzip"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"

	"unflutter/internal/signal"
)

// gzipBase64 gzip-compresses data and returns the base64-encoded result.
func gzipBase64(data []byte) string {
	var buf bytes.Buffer
	gz, err := gzip.NewWriterLevel(&buf, gzip.BestCompression)
	if err != nil {
		return base64.StdEncoding.EncodeToString(data) // fallback: uncompressed
	}
	if _, err := gz.Write(data); err != nil {
		return base64.StdEncoding.EncodeToString(data)
	}
	if err := gz.Close(); err != nil {
		return base64.StdEncoding.EncodeToString(data)
	}
	return base64.StdEncoding.EncodeToString(buf.Bytes())
}

// WriteSignalHTML writes a self-contained HTML page for the signal graph.
// asmSnippets maps function name → first N lines of annotated disasm.
func WriteSignalHTML(w io.Writer, g *signal.SignalGraph, title, filename, digest string, asmSnippets map[string]string) {
	graphJSON, err := json.Marshal(g)
	if err != nil {
		fmt.Fprintf(w, "<html><body>error marshaling signal graph: %v</body></html>", err)
		return
	}

	fmt.Fprintf(w, `<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>%s — Signal Graph</title>
<style>
:root {
  /* Surfaces */
  --bg: #000000; --bg2: #0a0a0a; --surface: #141414; --border: #222;
  /* Text hierarchy: bright > text > muted */
  --bright: #ffffff; --text: #c0c0c0; --muted: #808080;
  /* Semantic */
  --blue: #87CEEB; --pink: #FF80C0; --gold: #FFC800;
  --orange: #FF8000; --green: #00FF00; --red: #ff4444;
  /* Aliases */
  --link: var(--blue);
  /* Type scale: 3 sizes only */
  --fs: 14px; --fs-sm: 12px; --fs-xs: 10px;
  /* Spacing: 4px base unit */
  --sp-1: 4px; --sp-2: 8px; --sp-3: 16px; --sp-4: 24px;
  /* Font */
  --mono: "SF Mono","Fira Code","Consolas","Liberation Mono",monospace;
}
* { box-sizing: border-box; margin: 0; padding: 0; }
body { font-family: var(--mono); font-size: var(--fs); line-height: 1.5; color: var(--text); background: var(--bg); padding: var(--sp-3) var(--sp-4); }
a { color: var(--link); text-decoration: none; }
a:hover { color: var(--bright); }

/* --- Page header --- */
h1 { font-size: var(--fs); font-weight: 600; color: var(--bright); margin-bottom: var(--sp-1); }
.file-info { font-size: var(--fs-sm); color: var(--muted); margin-bottom: var(--sp-3); }
.file-info .digest { margin-left: var(--sp-2); opacity: 0.6; }

/* --- Stats bar --- */
.stats { display: flex; gap: var(--sp-4); font-size: var(--fs-sm); color: var(--muted); margin-bottom: var(--sp-3); }
.stats b { color: var(--bright); font-weight: 400; }

/* --- Toolbar (search + scope + view) --- */
.toolbar { display: flex; gap: var(--sp-3); flex-wrap: wrap; align-items: center; margin-bottom: var(--sp-3); }
.search-box input { width: 480px; max-width: 100%%; padding: var(--sp-1) var(--sp-2); font: inherit; font-size: var(--fs-sm); border: 1px solid var(--border); background: var(--bg2); color: var(--text); border-radius: 3px; }
.search-box input:focus { outline: none; border-color: var(--link); }
.search-box input::placeholder { color: var(--muted); }
.btn { display: inline-block; padding: var(--sp-1) 10px; cursor: pointer; font: inherit; font-size: var(--fs-sm); border: 1px solid var(--border); background: var(--bg2); color: var(--muted); border-radius: 3px; }
.btn:hover { color: var(--text); background: var(--surface); }
.btn.active { color: var(--bright); background: var(--surface); border-color: var(--link); }
.btn-group { display: flex; gap: 1px; }

/* --- Category tags --- */
.cats-bar { display: flex; gap: 6px; flex-wrap: wrap; margin-bottom: var(--sp-2); }
.cat-tag { display: inline-block; padding: 2px 8px; font-size: var(--fs-xs); cursor: pointer; background: var(--surface); border-radius: 4px; border: 1px solid var(--border); }
.cat-tag:hover { border-color: var(--muted); }
.cat-tag.active { color: var(--bright); border-color: var(--bright); }
.cat-url { color: var(--blue); }
.cat-host { color: var(--orange); }
.cat-encryption { color: var(--red); }
.cat-auth { color: var(--pink); }
.cat-net { color: var(--green); }
.cat-file { color: var(--gold); }
.cat-base64 { color: var(--orange); }
.cat-thr { color: var(--blue); }
.cat-sim { color: var(--red); }
.cat-sms { color: var(--red); }
.cat-contacts { color: var(--pink); }
.cat-location { color: var(--orange); }
.cat-device { color: var(--gold); }
.cat-cloaking { color: var(--red); }
.cat-data { color: var(--pink); }
.cat-camera { color: var(--green); }
.cat-webview { color: var(--orange); }
.cat-blockchain { color: var(--gold); }
.cat-gambling { color: var(--red); }

/* --- Count --- */
#count { font-size: var(--fs-sm); color: var(--muted); margin-bottom: var(--sp-2); }

/* --- Class groups --- */
.class-group { margin-bottom: var(--sp-1); }
.class-header { padding: var(--sp-1) var(--sp-2); cursor: pointer; display: flex; align-items: center; gap: var(--sp-2); color: var(--gold); border-radius: 3px; }
.class-header:hover { background: var(--surface); }
.class-header .arrow { font-size: var(--fs-sm); transition: transform 0.15s; color: var(--muted); }
.class-group.collapsed .class-body { display: none; }
.class-group.collapsed .arrow { transform: rotate(-90deg); }
.class-count { font-size: var(--fs-sm); color: var(--muted); margin-left: auto; }

/* --- Function cards --- */
.card { margin-bottom: var(--sp-4); }
.card.context { opacity: 0.5; }
.card.other { opacity: 0.3; }
.card.revealed { opacity: 1 !important; background: rgba(255,200,0,0.05); }
.card-header { padding: var(--sp-1) 0; cursor: pointer; display: flex; align-items: center; gap: var(--sp-2); }
.card-header:hover .func-name { color: var(--bright); }
.func-name { color: var(--gold); word-break: break-all; }
.owner-name { font-size: var(--fs-sm); color: var(--muted); }
.sev-badge { font-size: var(--fs-sm); font-weight: 600; padding: 1px 6px; text-transform: uppercase; letter-spacing: 0.5px; border-radius: 3px; }
.sev-badge.high { background: rgba(241,76,76,0.15); color: var(--red); }
.sev-badge.medium { background: rgba(255,128,0,0.15); color: var(--orange); }
.sev-badge.ep { background: rgba(0,255,0,0.1); color: var(--green); }
.card-tags { display: flex; gap: var(--sp-1); flex-wrap: wrap; margin-left: auto; }
.asm-link { font-size: var(--fs-sm); color: var(--link); margin-left: 6px; opacity: 0.6; }
.asm-link:hover { opacity: 1; }
.card-body { display: none; padding: var(--sp-1) 0 var(--sp-2) 0; }
.card.open .card-body { display: block; }

/* --- String refs inside cards --- */
.str-ref { padding: 2px 0; word-break: break-all; line-height: 1.6; }
.str-val { color: var(--pink); }
.str-pc { font-size: var(--fs-sm); color: var(--muted); cursor: pointer; }
.str-pc:hover { color: var(--link); }

/* --- Content box (one class for all content blocks) --- */
.cbox { margin-bottom: var(--sp-2); color: var(--bright); }
.cbox .section-label { font-size: var(--fs-sm); text-transform: uppercase; letter-spacing: 0.5px; margin-bottom: var(--sp-1); position: relative; z-index: 2; }
.cbox.asm { line-height: 1.5; white-space: pre-wrap; word-break: break-all; max-height: 260px; overflow: hidden; cursor: pointer; position: relative; }
.cbox.asm::before { content: ""; position: absolute; top: 0; left: 0; right: 0; height: 40px; background: linear-gradient(rgba(0,0,0,1), rgba(0,0,0,0.85) 40%%, rgba(0,0,0,0)); pointer-events: none; z-index: 1; }
.cbox.asm::after { content: ""; position: absolute; bottom: 0; left: 0; right: 0; height: 40px; background: linear-gradient(rgba(0,0,0,0), rgba(0,0,0,0.85) 60%%, rgba(0,0,0,1)); pointer-events: none; }
.cbox.asm.expanded { max-height: none; }
.cbox.asm.expanded::before, .cbox.asm.expanded::after { display: none; }
.neighbor-list { line-height: 1.8; display: flex; flex-wrap: wrap; gap: var(--sp-1) var(--sp-2); }
.neighbor-list a { color: var(--muted); }
.neighbor-list a:hover { color: var(--link); }
.neighbor-list a.nb-high { color: var(--red); }
.neighbor-list a.nb-med { color: var(--orange); }
.neighbor-list a.nb-sig { color: var(--link); }
.backtrace { line-height: 1.8; }
.backtrace-line { white-space: nowrap; overflow: hidden; text-overflow: ellipsis; }
.backtrace-line a { color: var(--muted); }
.backtrace-line a:hover { color: var(--link); }
.backtrace-line a.nb-high { color: var(--red); }
.backtrace-line a.nb-med { color: var(--orange); }
.backtrace-line a.nb-sig { color: var(--link); }
.bt-arrow { color: #646464; }
.a-addr { color: var(--gold); }
.a-bytes { color: var(--muted); }
.a-instr { color: var(--bright); }
.a-reg { color: var(--blue); }
.a-imm { color: var(--pink); }
.a-comment { color: var(--bright); }
.a-str { color: var(--pink); }
.a-pp { color: var(--blue); }
.a-thr { color: var(--pink); }
.a-name { color: var(--gold); }
.a-arrows { user-select: none; }
.hidden { display: none; }

/* --- Signals table (inside cards) --- */
.sig-table { border-collapse: collapse; }
.sig-table td { padding: 2px 12px 2px 0; vertical-align: top; line-height: 1.5; }
.sig-table .sig-pc { white-space: nowrap; vertical-align: top; }
.sig-table .sig-pc a { color: var(--gold); }
.sig-table .sig-pc a:hover { color: var(--bright); }
.sig-table .sig-pc .sig-cat { display: block; font-size: var(--fs-xs); line-height: 1.2; }
.sig-table .sig-val { color: var(--bright); word-break: break-all; }
.sig-table .sig-decoded { display: block; color: var(--muted); font-size: var(--fs-sm); margin-top: 1px; }

/* --- Strings view table --- */
.str-table { width: 100%%; border-collapse: collapse; }
.str-table th { text-align: left; padding: var(--sp-1) 10px; font-size: var(--fs-sm); font-weight: 400; color: var(--muted); text-transform: uppercase; letter-spacing: 0.5px; position: sticky; top: 0; cursor: pointer; user-select: none; border-bottom: 1px solid var(--border); background: var(--bg); }
.str-table th:hover { color: var(--text); }
.str-table td { padding: var(--sp-1) 10px; border-bottom: 1px solid var(--border); vertical-align: top; line-height: 1.6; }
.str-table tr:hover { background: var(--surface); }
.str-table td.str-val-cell { color: var(--pink); word-break: break-all; max-width: 500px; }
.str-table td.str-func-cell { max-width: 300px; word-break: break-all; }
.str-table td.str-func-cell a { color: var(--gold); }
.str-table td.str-func-cell a:hover { color: var(--bright); }
.str-table td.str-cat-cell { white-space: nowrap; }
.str-table td.str-pc-cell { color: var(--gold); white-space: nowrap; }
.str-cat-row td { font-weight: 600; padding: var(--sp-3) 10px var(--sp-1) !important; border-bottom: none; color: var(--gold); }
</style>
</head>
<body>
<h1>%s</h1>
<div class="file-info">%s<span class="digest">%s</span> <a href="signal.svg">signal graph</a></div>
`, htmlEscape(title), htmlEscape(title), htmlEscape(filename), htmlEscape(digest))

	// Stats bar.
	fmt.Fprintf(w, `<div class="stats">
<span><b>%d</b> signal</span>
<span><b>%d</b> context</span>
<span><b>%d</b> total</span>
<span><b>%d</b> strings</span>
<span><b>%d</b> edges</span>
</div>
`, g.Stats.SignalFuncs, g.Stats.ContextFuncs,
		g.Stats.TotalFuncs,
		g.Stats.StringRefCount, g.Stats.TotalEdges)

	// Toolbar.
	fmt.Fprint(w, `<div class="toolbar">
<div class="search-box"><input id="search" type="text" placeholder="Search functions or strings..." oninput="filterAll()"></div>
<div class="btn-group">
  <span class="btn role-signal active" onclick="setScope('signal')">Signal</span>
  <span class="btn role-context" onclick="setScope('context')">+Context</span>
  <span class="btn role-all" onclick="setScope('all')">All</span>
</div>
<div class="btn-group">
  <span class="btn active" data-view="class" onclick="setView('class')">By Class</span>
  <span class="btn" data-view="flat" onclick="setView('flat')">Flat</span>
  <span class="btn" data-view="strings" onclick="setView('strings')">Strings</span>
</div>
</div>
`)

	// Category filter bar.
	fmt.Fprint(w, `<div class="cats-bar" id="catbar"></div>
<div id="count"></div>
`)

	// Boot log (terminal-style progress).
	fmt.Fprint(w, `<div id="boot-log" style="font-size:var(--fs-sm);color:var(--muted);line-height:1.8;padding:var(--sp-2) 0;white-space:pre"></div>
`)

	// Cards container.
	fmt.Fprint(w, `<div id="cards"></div>
`)

	// Embed gzip+base64 data blobs.
	asmJSON, _ := json.Marshal(asmSnippets)
	gzGraph := gzipBase64(graphJSON)
	gzAsm := gzipBase64(asmJSON)
	fmt.Fprintf(w, `<script>
const _GZ_G = "%s";
const _GZ_ASM = "%s";
`, gzGraph, gzAsm)

	// JS logic: decompress blobs with progress, then run app.
	fmt.Fprint(w, `
const _t0 = performance.now();
const _log = document.getElementById("boot-log");
function _emit(msg) {
  const t = ((performance.now() - _t0) / 1000).toFixed(1);
  _log.textContent += t + "s  " + msg + "\n";
}

async function _decompress(b64) {
  const bin = Uint8Array.from(atob(b64), c => c.charCodeAt(0));
  const ds = new DecompressionStream("gzip");
  const writer = ds.writable.getWriter();
  writer.write(bin);
  writer.close();
  const chunks = [];
  const reader = ds.readable.getReader();
  for (;;) {
    const {done, value} = await reader.read();
    if (done) break;
    chunks.push(value);
  }
  const blob = new Blob(chunks);
  return JSON.parse(await blob.text());
}

let G, ASM;
(async () => {
  const _frame = () => new Promise(r => requestAnimationFrame(r));
  _emit("decompressing graph data (" + (_GZ_G.length / 1024 | 0) + " KB)..."); await _frame();
  G = await _decompress(_GZ_G);
  _emit("decompressing asm data (" + (_GZ_ASM.length / 1024 | 0) + " KB)..."); await _frame();
  ASM = await _decompress(_GZ_ASM);
  _emit("loaded " + G.funcs.length + " functions, " + G.edges.length + " edges, " + Object.keys(ASM).length + " asm snippets"); await _frame();
  _emit("building indices..."); await _frame();
  _boot();
})();

function _boot() {
// Build neighbor index from ALL edges.
const callers = {}, callees = {};
G.edges.forEach(e => {
  if (e.kind === "bl" && e.to) {
    if (!callees[e.from]) callees[e.from] = [];
    callees[e.from].push(e.to);
    if (!callers[e.to]) callers[e.to] = [];
    callers[e.to].push(e.from);
  }
});

// Build name→index map for fast lookup.
const nameIdx = {};
G.funcs.forEach((f, i) => { nameIdx[f.name] = i; });

let activeCat = null;
let scope = "signal"; // "signal", "context", "all"
let viewMode = "class";
const revealed = new Set(); // manually revealed function names

function catClass(c) { return "cat-tag cat-" + c; }

function renderCatBar() {
  const bar = document.getElementById("catbar");
  const cats = Object.entries(G.stats.categories || {}).sort((a,b) => b[1]-a[1]);
  bar.innerHTML = cats.map(([c, n]) =>
    '<span class="' + catClass(c) + '" data-cat="' + c + '" onclick="toggleCat(\'' + c + '\')">' + c + '</span>'
  ).join("");
}

function toggleCat(c) {
  activeCat = activeCat === c ? null : c;
  document.querySelectorAll("#catbar .cat-tag").forEach(el => {
    el.classList.toggle("active", el.dataset.cat === activeCat);
  });
  filterAll();
}

function setScope(s) {
  scope = s;
  document.querySelectorAll(".btn.role-signal,.btn.role-context,.btn.role-all").forEach(el => {
    el.classList.remove("active");
    if (s === "signal" && el.classList.contains("role-signal")) el.classList.add("active");
    if (s === "context" && el.classList.contains("role-context")) el.classList.add("active");
    if (s === "all" && el.classList.contains("role-all")) el.classList.add("active");
  });
  filterAll();
}

function setView(v) {
  viewMode = v;
  document.querySelectorAll(".btn[data-view]").forEach(el => {
    el.classList.toggle("active", el.dataset.view === v);
  });
  renderCards();
  filterAll();
}

function fmtName(name) {
  // Uppercase hex in sub_ names for consistency.
  if (/^sub_[0-9a-f]+$/.test(name)) return "sub_" + name.substring(4).toUpperCase();
  // Uppercase hex suffix after last underscore in named functions (e.g. "Foo.bar_1a2b3c").
  return name.replace(/_([0-9a-f]{4,})$/i, function(m, h) { return "_" + h.toUpperCase(); });
}

function neighborClass(name) {
  const idx = nameIdx[name];
  if (idx === undefined) return "";
  const f = G.funcs[idx];
  if (!f) return "";
  if (f.severity === "high") return " nb-high";
  if (f.severity === "medium") return " nb-med";
  if (f.role === "signal") return " nb-sig";
  return "";
}

function renderNeighborList(names) {
  if (names.length === 0) return "";
  return names.map(n =>
    '<a class="' + neighborClass(n) + '" href="#" onclick="revealAndScroll(\'' + esc(n) + '\');return false">' + esc(fmtName(n)) + '</a>'
  ).join("");
}

// Walk callers backwards up to maxDepth, return array of chains (each is an array of names, root first).
function getBacktraces(name, maxDepth) {
  const traces = [];
  function walk(cur, chain, visited) {
    const cls = callers[cur] || [];
    if (chain.length >= maxDepth || cls.length === 0) {
      traces.push(chain.slice());
      return;
    }
    // Limit fan-out: only follow first 3 callers per level to keep output bounded.
    const limit = Math.min(cls.length, 3);
    for (let i = 0; i < limit; i++) {
      const c = cls[i];
      if (visited.has(c)) {
        traces.push([c + " (cycle)", ...chain]);
        continue;
      }
      visited.add(c);
      walk(c, [c, ...chain], visited);
      visited.delete(c);
    }
    if (cls.length > limit) {
      traces.push(["... +" + (cls.length - limit) + " more", ...chain]);
    }
  }
  const cls = callers[name] || [];
  if (cls.length === 0) return [];
  const visited = new Set([name]);
  cls.forEach(c => {
    visited.add(c);
    walk(c, [c], visited);
    visited.delete(c);
  });
  return traces;
}

function renderBacktraces(name) {
  const traces = getBacktraces(name, 4);
  if (traces.length === 0) return "";
  // Separate single-node traces (no chain) from real chains.
  const singles = [];
  const chains = [];
  traces.forEach(chain => {
    if (chain.length <= 1) singles.push(chain[0] || "");
    else chains.push(chain);
  });
  let html = '<div class="backtrace">';
  // Render singles as a compact inline list.
  if (singles.length > 0) {
    html += '<div class="backtrace-line">';
    html += singles.map(n => {
      return '<a class="' + neighborClass(n) + '" href="#" onclick="revealAndScroll(\'' + esc(n) + '\');return false">' + esc(fmtName(n)) + '</a>';
    }).join(', ');
    html += '</div>';
  }
  // Render chains as before, one per line.
  chains.forEach(chain => {
    html += '<div class="backtrace-line">';
    html += chain.map(n => {
      if (n.startsWith("...")) return '<span class="bt-arrow">' + esc(n) + '</span>';
      return '<a class="' + neighborClass(n) + '" href="#" onclick="revealAndScroll(\'' + esc(n) + '\');return false">' + esc(fmtName(n)) + '</a>';
    }).join('<span class="bt-arrow"> \u2192 </span>');
    html += '</div>';
  });
  html += '</div>';
  return html;
}

function renderCard(f, i) {
  const cats = (f.categories || []).map(c => '<span class="' + catClass(c) + '">' + c + '</span>').join("");
  const role = f.role || "";
  const isSignal = role === "signal";
  let cls = "card";
  if (isSignal) cls += " open"; // signal cards expanded by default
  if (role === "context") cls += " context";
  if (role === "") cls += " other";
  let html = '<div class="' + cls + '" id="card-' + i + '" data-name="' + esc(f.name) + '" data-role="' + role + '" data-sev="' + (f.severity||"") + '" data-cats="' + (f.categories||[]).join(",") + '" data-strings="' + esc((f.string_refs||[]).map(r=>r.value).join("|")) + '" data-owner="' + esc(f.owner||"") + '">';
  html += '<div class="card-header" onclick="toggle(' + i + ')">';
  if (f.is_entry_point) html += '<span class="sev-badge ep">EP</span>';
  if (f.severity === "high") html += '<span class="sev-badge high">HIGH</span>';
  else if (f.severity === "medium") html += '<span class="sev-badge medium">MED</span>';
  html += '<span class="func-name">' + esc(fmtName(f.name)) + '</span>';
  if (ASM[f.name]) html += '<a class="asm-link" href="asm/' + encodeURIComponent(f.name) + '.txt" target="_blank" onclick="event.stopPropagation()">asm</a>';
  if (f.owner) html += ' <span class="owner-name">' + esc(fmtName(f.owner)) + '</span>';
  html += '<div class="card-tags">' + cats + '</div>';
  html += '</div>';
  html += '<div class="card-body">';

  // 1. Signals (no title, before asm).
  if (f.string_refs && f.string_refs.length > 0) {
    const seen = {};
    f.string_refs.forEach(r => {
      if (seen[r.value]) { seen[r.value].count++; return; }
      seen[r.value] = {r: r, count: 1};
    });
    const rows = Object.values(seen);
    html += '<div class="cbox"><table class="sig-table">';
    rows.forEach(({r, count}) => {
      const strCats = r.categories || [];
      const primary = strCats[0] || "";
      const colorCls = primary ? "cat-" + primary : "";
      const pcDisp = r.pc.startsWith("0x") ? r.pc.substring(2).toUpperCase() : r.pc;
      html += '<tr>';
      html += '<td class="sig-pc"><a href="#" onclick="scrollAsm(' + i + ',\'' + r.pc + '\');return false">' + pcDisp + '</a>';
      if (primary) html += '<span class="sig-cat ' + colorCls + '">' + primary + '</span>';
      html += '</td>';
      html += '<td class="sig-val">"' + esc(r.value) + '"';
      if (count > 1) html += ' <span class="owner-name">\u00d7' + count + '</span>';
      if (strCats.includes("base64")) {
        try { const d = atob(r.value); if (d.length > 0 && /^[\x20-\x7e\r\n\t]+$/.test(d)) html += '<span class="sig-decoded">\u2192 ' + esc(d) + '</span>'; } catch(e) {}
      }
      html += '</td>';
      html += '</tr>';
    });
    html += '</table></div>';
  }

  // 2. ASM.
  if (ASM[f.name]) {
    html += '<div class="cbox asm" onclick="this.classList.toggle(\'expanded\')"><div class="section-label">Disasm</div>' + colorizeAsm(ASM[f.name]) + '</div>';
  }

  // 3. Callers + Callees (each in own box).
  const cl = callers[f.name] || [];
  const ce = callees[f.name] || [];
  if (cl.length > 0) {
    html += '<div class="cbox">';
    html += '<div class="section-label">' + (cl.length === 1 ? 'Caller' : 'Callers') + '</div>';
    html += renderBacktraces(f.name);
    html += '</div>';
  }
  if (ce.length > 0) {
    html += '<div class="cbox">';
    html += '<div class="section-label">' + (ce.length === 1 ? 'Callee' : 'Callees') + '</div>';
    html += '<div class="neighbor-list">' + renderNeighborList(ce) + '</div>';
    html += '</div>';
  }

  html += '</div></div>';
  return html;
}

// Build flat list of all string refs with func metadata for Strings view.
const allStringRefs = [];
G.funcs.forEach((f, i) => {
  if (!f.string_refs) return;
  f.string_refs.forEach(r => {
    const strCats = r.categories || f.categories || [];
    allStringRefs.push({
      value: r.value,
      pc: r.pc,
      poolIdx: r.pool_idx,
      funcName: f.name,
      funcIdx: i,
      owner: f.owner || "",
      role: f.role || "",
      severity: f.severity || "",
      categories: strCats
    });
  });
});

let stringSortCol = "cat";
let stringSortAsc = true;

function renderStrings() {
  const container = document.getElementById("cards");
  const q = document.getElementById("search").value.toLowerCase();

  // Filter strings.
  let filtered = allStringRefs.filter(s => {
    if (scope === "signal" && s.role !== "signal") return false;
    if (scope === "context" && s.role !== "signal" && s.role !== "context") return false;
    if (q && !s.value.toLowerCase().includes(q) && !s.funcName.toLowerCase().includes(q)) return false;
    if (activeCat && !s.categories.includes(activeCat)) return false;
    return true;
  });

  // Group by category.
  const catGroups = {};
  const catOrder = [];
  filtered.forEach(s => {
    const cat = (s.categories && s.categories.length > 0) ? s.categories[0] : "(uncategorized)";
    if (!catGroups[cat]) { catGroups[cat] = []; catOrder.push(cat); }
    catGroups[cat].push(s);
  });
  const sevOrder = {"high": 0, "medium": 1, "low": 2, "": 3};
  catOrder.sort((a, b) => {
    const sa = catGroups[a][0] ? (sevOrder[catGroups[a][0].severity] || 3) : 3;
    const sb = catGroups[b][0] ? (sevOrder[catGroups[b][0].severity] || 3) : 3;
    if (sa !== sb) return sa - sb;
    return a < b ? -1 : 1;
  });

  // Sort within each group.
  const cmp = (a, b) => {
    let va, vb;
    if (stringSortCol === "value") { va = a.value; vb = b.value; }
    else if (stringSortCol === "func") { va = a.funcName; vb = b.funcName; }
    else if (stringSortCol === "pc") { va = a.pc; vb = b.pc; }
    else { va = a.value; vb = b.value; }
    if (va < vb) return stringSortAsc ? -1 : 1;
    if (va > vb) return stringSortAsc ? 1 : -1;
    return 0;
  };
  for (const cat in catGroups) catGroups[cat].sort(cmp);

  if (filtered.length === 0) {
    container.innerHTML = '<div class="owner-name" style="padding:20px">No strings match the current filter.</div>';
    document.getElementById("count").textContent = "0 / " + allStringRefs.length + " strings shown";
    return;
  }

  // Single table, category headers as spanning rows.
  let html = '<table class="str-table"><thead><tr>';
  html += '<th onclick="sortStrings(\'pc\')" style="width:10%">Address' + sortArrow("pc") + '</th>';
  html += '<th onclick="sortStrings(\'value\')" style="width:52%">Value' + sortArrow("value") + '</th>';
  html += '<th onclick="sortStrings(\'func\')" style="width:38%">Function' + sortArrow("func") + '</th>';
  html += '</tr></thead><tbody>';

  catOrder.forEach(cat => {
    const items = catGroups[cat];
    html += '<tr class="str-cat-row"><td colspan="3"><span class="' + catClass(cat) + '">' + cat + '</span> <span class="owner-name">' + items.length + '</span></td></tr>';
    items.forEach(s => {
      const addr = s.pc.startsWith("0x") ? s.pc.substring(2).toUpperCase() : s.pc;
      html += '<tr>';
      html += '<td class="str-pc-cell">' + addr + '</td>';
      html += '<td class="str-val-cell">"' + esc(s.value) + '"</td>';
      html += '<td class="str-func-cell"><a href="#" onclick="setView(\'class\');revealAndScroll(\'' + esc(s.funcName) + '\');return false">' + esc(fmtName(s.funcName)) + '</a></td>';
      html += '</tr>';
    });
  });

  html += '</tbody></table>';
  container.innerHTML = html;
  document.getElementById("count").textContent = filtered.length + " / " + allStringRefs.length + " strings shown";
}

function sortArrow(col) {
  if (stringSortCol !== col) return "";
  return stringSortAsc ? " &#9650;" : " &#9660;";
}

function sortStrings(col) {
  if (stringSortCol === col) stringSortAsc = !stringSortAsc;
  else { stringSortCol = col; stringSortAsc = true; }
  renderStrings();
}

function renderCards() {
  const container = document.getElementById("cards");
  if (viewMode === "strings") {
    renderStrings();
    return;
  }
  if (viewMode === "flat") {
    let html = "";
    G.funcs.forEach((f, i) => { html += renderCard(f, i); });
    container.innerHTML = html;
  } else {
    const groups = {};
    const order = [];
    G.funcs.forEach((f, i) => {
      const owner = f.owner || "(no class)";
      if (!groups[owner]) { groups[owner] = []; order.push(owner); }
      groups[owner].push({f, i});
    });
    let html = "";
    order.forEach(owner => {
      const items = groups[owner];
      // Start groups collapsed if they contain no signal funcs.
      const hasSignal = items.some(({f}) => f.role === "signal");
      const collapsed = hasSignal ? "" : " collapsed";
      html += '<div class="class-group' + collapsed + '" data-owner="' + esc(owner) + '">';
      html += '<div class="class-header" onclick="toggleGroup(this.parentNode)">';
      html += '<span class="arrow">&#9660;</span> ' + esc(fmtName(owner));
      html += '<span class="class-count">' + items.length + '</span>';
      html += '</div>';
      html += '<div class="class-body">';
      items.forEach(({f, i}) => { html += renderCard(f, i); });
      html += '</div></div>';
    });
    container.innerHTML = html;
  }
}

function toggleGroup(el) {
  el.classList.toggle("collapsed");
}

function toggle(i) {
  document.getElementById("card-" + i).classList.toggle("open");
}

function scrollAsm(cardIdx, pc) {
  const card = document.getElementById("card-" + cardIdx);
  if (!card) return;
  card.classList.add("open");
  const asm = card.querySelector(".cbox.asm");
  if (!asm) return;
  asm.classList.add("expanded");
  const text = asm.textContent;
  const lines = text.split("\n");
  const lineHeight = 15;
  for (let li = 0; li < lines.length; li++) {
    if (lines[li].includes(pc)) {
      asm.scrollTop = Math.max(0, li * lineHeight - 60);
      const pre = asm.innerHTML;
      const escaped = esc(lines[li]);
      asm.innerHTML = pre.replace(escaped, '<span style="background:rgba(255,200,0,0.15)">' + escaped + '</span>');
      setTimeout(() => { asm.innerHTML = pre; }, 2000);
      return;
    }
  }
}

// Reveal a function (even if filtered out) and scroll to it.
function revealAndScroll(name) {
  revealed.add(name);
  const idx = nameIdx[name];
  if (idx === undefined) return;
  const card = document.getElementById("card-" + idx);
  if (!card) return;
  // Unhide card and parent group.
  card.classList.remove("hidden");
  card.classList.add("open", "revealed");
  const group = card.closest(".class-group");
  if (group) {
    group.classList.remove("collapsed", "hidden");
  }
  card.scrollIntoView({behavior: "smooth", block: "center"});
  setTimeout(() => card.classList.remove("revealed"), 3000);
}

function matchesFilter(c) {
  const q = document.getElementById("search").value.toLowerCase();
  const name = c.dataset.name.toLowerCase();
  const strings = (c.dataset.strings || "").toLowerCase();
  const cats = c.dataset.cats || "";
  const role = c.dataset.role || "";

  // Scope filter: signal = signal only, context = signal+context, all = everything.
  // Revealed functions always pass.
  if (!revealed.has(c.dataset.name)) {
    if (scope === "signal" && role !== "signal") return false;
    if (scope === "context" && role !== "signal" && role !== "context") return false;
  }

  // Text search.
  if (q && !name.includes(q) && !strings.includes(q)) return false;

  // Category filter.
  if (activeCat && !cats.includes(activeCat)) return false;

  return true;
}

function filterAll() {
  if (viewMode === "strings") {
    renderStrings();
    return;
  }
  const cards = document.querySelectorAll(".card");
  let shown = 0;
  cards.forEach(c => {
    const vis = matchesFilter(c);
    c.classList.toggle("hidden", !vis);
    if (vis) shown++;
  });
  // Update group counts and hide empty groups.
  document.querySelectorAll(".class-group").forEach(g => {
    const visible = g.querySelectorAll(".card:not(.hidden)").length;
    const countEl = g.querySelector(".class-count");
    if (countEl) countEl.textContent = visible;
    g.classList.toggle("hidden", visible === 0);
  });
  document.getElementById("count").textContent = shown + " / " + cards.length + " functions";
}

function esc(s) {
  if (!s) return "";
  return s.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;").replace(/"/g,"&quot;").replace(/'/g,"&#39;");
}

function colorizeLine(s) {
  const m = s.match(/^(0x[0-9a-fA-F]+)(  )([0-9a-f]{2} [0-9a-f]{2} [0-9a-f]{2} [0-9a-f]{2})(  )(.*)$/);
  if (!m) return s;
  const addr = '<span class="a-addr">' + m[1].substring(2).replace(/^0+/, "").toUpperCase() + '</span>';
  const bytes = '<span class="a-bytes">' + m[3].replace(/ /g, "").toUpperCase() + '</span>';
  let rest = m[5];
  // Split instruction from comment at first ";"
  let instr = rest, comment = "";
  const ci = rest.indexOf(";");
  if (ci >= 0) { instr = rest.substring(0, ci); comment = rest.substring(ci); }
  // Pad instruction to fixed column so annotations align.
  const instrPlain = instr.replace(/&amp;/g,"&").replace(/&lt;/g,"<").replace(/&gt;/g,">").replace(/&quot;/g,'"');
  const padLen = 32;
  const pad = instrPlain.length < padLen ? " ".repeat(padLen - instrPlain.length) : " ";
  instr = instr.replace(/\b(X[0-9]{1,2}|W[0-9]{1,2}|SP|X30|XZR|WZR|X29|X28|X27|X26|X15)\b/g, '<span class="a-reg">$1</span>');
  instr = instr.replace(/(#-?0x[0-9a-fA-F]+|#-?[0-9]+)\b/g, '<span class="a-imm">$1</span>');
  instr = '<span class="a-instr">' + instr + '</span>';
  if (comment) {
    comment = comment.replace(/(&quot;[^&]*?&quot;)/g, '<span class="a-str">$1</span>');
    comment = comment.replace(/(PP\[\d+\])/g, '<span class="a-pp">$1</span>');
    comment = comment.replace(/(THR\.[a-zA-Z_]+)/g, '<span class="a-thr">$1</span>');
    comment = comment.replace(/(&lt;[^&]+?&gt;)/g, '<span class="a-name">$1</span>');
    comment = '<span class="a-comment">' + comment + '</span>';
  }
  return addr + m[2] + bytes + m[4] + instr + (comment ? pad + comment : "");
}

const arrowColors = ["#444", "#555", "#666", "#777"];

function colorizeAsm(raw) {
  const lines = raw.split("\n");
  // Pass 1: parse addresses.
  const addrs = [];
  const addrToIdx = {};
  lines.forEach((line, i) => {
    const m = line.match(/^(0x[0-9a-fA-F]+)/);
    const a = m ? parseInt(m[1], 16) : null;
    addrs.push(a);
    if (a !== null) addrToIdx[a] = i;
  });
  // Pass 2: detect intra-function branches (B/B.cond/CBZ/CBNZ/TBZ/TBNZ, NOT BL/BLR).
  const branches = [];
  lines.forEach((line, i) => {
    if (addrs[i] === null) return;
    // Extract instruction after "0xADDR  HH HH HH HH  "
    const parts = line.match(/^0x[0-9a-fA-F]+  [0-9a-f]{2} [0-9a-f]{2} [0-9a-f]{2} [0-9a-f]{2}  (.+)$/);
    if (!parts) return;
    const inst = parts[1].split(";")[0].trim();
    // Match branch but NOT BL/BLR (function calls).
    if (/^BL[R ]?\b/.test(inst)) return;
    if (!/^(B|B\.\w+|CBZ|CBNZ|TBZ|TBNZ)\b/.test(inst)) return;
    const tm = inst.match(/\.\+(0x[0-9a-fA-F]+)/);
    if (!tm) return;
    const off = parseInt(tm[1], 16);
    // Skip huge offsets (inter-function, wrapping negative).
    if (off > 0x10000) return;
    const target = addrs[i] + off;
    if (addrToIdx[target] !== undefined) {
      branches.push({ from: i, to: addrToIdx[target] });
    }
  });
  if (branches.length === 0) {
    return lines.map(l => colorizeLine(esc(l))).join("\n");
  }
  // Assign columns (greedy non-overlapping, shorter spans first).
  branches.sort((a, b) => Math.abs(a.to - a.from) - Math.abs(b.to - b.from));
  const maxCols = 4;
  branches.forEach(br => {
    const lo = Math.min(br.from, br.to), hi = Math.max(br.from, br.to);
    for (let c = 0; c < maxCols; c++) {
      const ok = branches.every(o => {
        if (o === br || o.col === undefined || o.col !== c) return true;
        const oLo = Math.min(o.from, o.to), oHi = Math.max(o.from, o.to);
        return hi < oLo || lo > oHi;
      });
      if (ok) { br.col = c; break; }
    }
    if (br.col === undefined) br.col = 0;
  });
  const totalCols = Math.max(...branches.map(b => b.col)) + 1;
  // Build margin grid.
  const grid = lines.map(() => new Array(totalCols).fill(" "));
  const gridColor = lines.map(() => new Array(totalCols).fill(0));
  branches.forEach((br, bi) => {
    const lo = Math.min(br.from, br.to), hi = Math.max(br.from, br.to);
    const c = br.col;
    for (let i = lo; i <= hi; i++) { grid[i][c] = "\u2502"; gridColor[i][c] = c; }
    if (br.from < br.to) { grid[br.from][c] = "\u252c"; grid[br.to][c] = "\u2514"; }
    else { grid[br.from][c] = "\u2534"; grid[br.to][c] = "\u250c"; }
  });
  // Render.
  return lines.map((line, i) => {
    let margin = "";
    for (let c = 0; c < totalCols; c++) {
      const ch = grid[i][c];
      const color = arrowColors[gridColor[i][c] % arrowColors.length];
      if (ch !== " ") margin += '<span style="color:' + color + '">' + ch + '</span>';
      else margin += " ";
    }
    return '<span class="a-arrows">' + margin + '</span>' + colorizeLine(esc(line));
  }).join("\n");
}

// Expose handlers for inline onclick attributes.
window.setScope = setScope;
window.setView = setView;
window.toggleCat = toggleCat;
window.toggle = toggle;
window.toggleGroup = toggleGroup;
window.filterAll = filterAll;
window.scrollAsm = scrollAsm;
window.revealAndScroll = revealAndScroll;
window.sortStrings = sortStrings;

_emit("rendering " + G.funcs.length + " cards...");
renderCatBar();
renderCards();
filterAll();
_emit("ready.");
_log.style.transition = "opacity 2s";
setTimeout(() => { _log.style.opacity = "0"; setTimeout(() => _log.remove(), 2000); }, 3000);
} // end _boot
</script>
</body>
</html>
`)
}

```

`internal/render/theme.go`:

```go
package render

// Theme holds colors for callgraph rendering.
type Theme struct {
	Background string
	NodeFill   string
	NodeBorder string
	TextColor  string

	// Edge colors by provenance category.
	EdgeTHR        string // THR.* runtime entry calls
	EdgePP         string // PP[n] pool-loaded calls
	EdgeDispatch   string // dispatch_table (virtual calls)
	EdgeObject     string // object_field (vtable/closure)
	EdgeDirect     string // BL direct calls
	EdgeUnresolved string // unannotated BLR

	// Node accents.
	StubFill     string // runtime stubs (sub_xxx)
	ExternalText string // external / unresolved targets

	// Cluster styling.
	ClusterBorder string // subgraph cluster border
	ClusterLabel  string // subgraph cluster label text
}

// NASA is the NASA/Bauhaus theme: geometric, monochrome, sparse color.
var NASA = Theme{
	Background: "#F5F5F5",
	NodeFill:   "white",
	NodeBorder: "#1A1A1A",
	TextColor:  "#1A1A1A",

	EdgeTHR:        "#0B3D91", // NASA blue
	EdgePP:         "#00695C", // teal
	EdgeDispatch:   "#9E9E9E", // gray
	EdgeObject:     "#E65100", // deep orange
	EdgeDirect:     "#424242", // dark gray
	EdgeUnresolved: "#FC3D21", // NASA red

	StubFill:     "#ECEFF1", // blue-gray 50
	ExternalText: "#9E9E9E",

	ClusterBorder: "#BDBDBD",
	ClusterLabel:  "#757575",
}

```

`internal/signal/classify.go`:

```go
package signal

import (
	"math"
	"regexp"
	"strings"
)

// Categories for string signal classification.
const (
	CatURL        = "url"
	CatHost       = "host"
	CatEncryption = "encryption"
	CatAuth       = "auth"
	CatNet        = "net"
	CatFileExt    = "file"
	CatBase64Key  = "base64"

	// Suspicious mobile behavior categories.
	CatSIM         = "sim"         // SIM card, IMEI, carrier, MCC/MNC
	CatSMS         = "sms"         // SMS read/send
	CatContacts    = "contacts"    // Contact list access
	CatLocation    = "location"    // GPS, geolocation, geofence
	CatDeviceInfo  = "device"      // Device ID, fingerprinting
	CatCloaking    = "cloaking"    // Keyword/locale gating, redirect tricks
	CatDataCollect = "data"        // Bulk data harvesting
	CatCamera      = "camera"      // Camera access
	CatWebView     = "webview"     // WebView loadUrl, evaluateJavascript, JS bridge
	CatBlockchain  = "blockchain"  // Wallet, mnemonic, seed phrase, blockchain, NFT
	CatGambling    = "gambling"    // Betting, casino, slots, lottery, poker
	CatAttribution = "attribution" // Install referrer, campaign, organic, SDK tracking
)

var (
	reURL       = regexp.MustCompile(`(?i)(https?|wss?|ftp)://`)
	reIPLiteral = regexp.MustCompile(`\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b`)
	reBase64    = regexp.MustCompile(`^[A-Za-z0-9+/=]{16,}$`)

	// Crypto keywords that are safe for substring matching (long enough, no false positives).
	cryptoKeywords = []string{
		"encrypt", "decrypt", "cipher", "ciphertext",
		"xxtea", "xorcipher", "xordecrypt", "xorencrypt", "xorkey",
		"pbkdf", "argon2", "bcrypt", "scrypt",
		"signature", "digest",
		"hmacsha", "chacha", "blowfish", "twofish",
		"nonce", "saltvalue",
	}

	// Short crypto words need word-boundary matching to avoid false positives
	// ("rsa" in "Traversal", "tea" in "instead", "md5" in random strings).
	reCryptoShort = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(aes|rsa|ecdsa|ecdh|hmac|sha1|sha256|sha512|md5|cbc|ecb|gcm|pkcs|xor|rc4|3des|salt|iv)([^a-zA-Z]|$)`)

	// Auth patterns use word boundaries to avoid camelCase false positives
	// like "brieflyShowPassword" (Flutter UI setting).
	reAuth = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(oauth|jwt|bearer|credential|passwd|apikey|api_key|api-key|authorization|authenticate)([^a-zA-Z]|$)`)

	// These require standalone match (not embedded in camelCase).
	reAuthStandalone = regexp.MustCompile(`(?i)(^|[^a-z])(password|token|secret|login)([^a-z]|$)`)

	netKeywords = []string{
		"socket", "connect", "dns", "proxy", "redirect",
	}

	httpMethods = []string{"GET", "POST", "PUT", "DELETE", "PATCH", "HEAD", "OPTIONS"}

	signalExtensions = []string{
		".dex", ".so", ".apk", ".aab", ".ipa",
		".zip", ".tar", ".gz",
		".json", ".xml", ".yaml", ".yml",
		".db", ".sqlite",
		".key", ".pem", ".cert", ".crt", ".p12", ".jks",
		".js", ".lua", ".py",
	}

	// SIM / telephony patterns.
	// Use case-sensitive camelCase-aware matching via classifyContains.
	// All keyword lists use normalized form: lowercase, no separators.
	// normalizeForMatch strips _, -, space, . before matching.

	simKeywords = []string{
		"simcard", "checksim", "imei", "imsi",
		"telephon", "subscriberid", "getline1", "simoperator",
		"simcountry", "simserial",
	}

	smsKeywords = []string{
		"smslog", "sendsms", "readsms", "smsmanager",
	}
	// "sms" alone is too short for containsKeyword (matches inside other words).
	// Handled via regex below.
	reSMS = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(sms|mms)([^a-zA-Z]|$)`)

	contactKeywords = []string{
		"contactlist", "addressbook", "calllog", "readcontacts",
		"contactaddress", "phonenumber",
	}

	locationKeywords = []string{
		"geolocation", "geofence", "latitude", "longitude",
		"currentlocation", "locationservice", "requestlocation",
		"enablelocation", "locationexception", "locationpermission",
		"lastknownlocation", "fusedlocation", "geopoint",
		"locationcallback", "locationlistener", "locationmanager",
		"locationrequest", "isenablelocation",
	}
	// "gps" needs word-boundary matching (would match inside longer words).
	reLocationShort = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(gps)([^a-zA-Z]|$)`)

	deviceInfoKeywords = []string{
		"deviceid", "androidid", "getdevice", "deviceinfo",
		"devicefingerprint", "devicemodel", "deviceattributes",
		"installreferrer", "installerstore",
		"packageinfo", "getpackageinfo", "packagename",
		"getinstalledpackages", "packagemanager",
		"applicationinfo", "getapplicationinfo",
	}

	cloakingKeywords = []string{
		"checkkeyword", "keywordcheck", "keywordmismatch",
		"isallowed", "checkandlaunch", "checkredirect",
		"cloak", "appcountry",
		// Locale / timezone / timing checks
		"checklanguage", "checklocale", "checktimezone",
		"getdefaultlocale", "systemlocale", "devicelanguage",
		"timedelay", "scheduletask", "setinterval",
	}

	reDataCollect = regexp.MustCompile(`(?i)(data.?collect|mobile.?data|send.?all.?mobile|collect.?data|harvest|bulk.?data|scrape|exfiltrat)`)

	cameraKeywords = []string{
		"camerapermission", "cameraopen", "getavailablecameras",
		"takepicture", "recordvideo",
	}

	walletKeywords = []string{
		// Mnemonic / seed phrase
		"mnemonic", "seedphrase", "bip39", "bip44", "bip32",
		"recoveryphrase", "backupphrase", "secretphrase",
		"wordlist", "passphrase", "derivepath",
		// Wallet core
		"privatek", "publickey", "keystore", "keychain",
		"hdwallet", "coldwallet", "hotwallet",
		"walletconnect", "walletaddress", "walletbalance",
		"walletprovider", "walletadapter",
		// Chains & tokens (long enough for substring match)
		"blockchain", "smartcontract",
		"ethereum", "solana", "bitcoin", "binance", "polygon",
		"tether", "usdc", "usdt",
		"erc20", "bep20", "trc20",
		// Wallets / services
		"metamask", "trustwallet", "phantom", "coinbase",
		"uniswap", "pancakeswap", "opensea",
		// Web3 (long enough for substring match)
		"gasprice", "gaslimit", "gasfee",
		// NFT
		"nftmint", "nftmarket", "tokenuri", "tokenmeta",
	}
	reWallet = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(wallet|mnemonic|seed.?phrase|private.?key|web3|dapp|nft|defi|swap|stake|airdrop|bitcoin|ether|crypto.?currency|token.?transfer)([^a-zA-Z]|$)`)

	gamblingKeywords = []string{
		// Casino / slots
		"casino", "slotmachine", "roulette", "blackjack",
		"jackpot", "spinwheel", "freespin",
		// Betting / wager
		"sportsbet", "placebet", "betslip", "oddscalc",
		"bookmaker", "bookie", "handicap",
		// Lottery
		"lottery", "lotto", "lucknumber", "drawresult",
		// Poker / card games
		"pokerroom", "pokertable", "texasholdem",
		// Money flow
		"placewager", "payout", "cashout",
		"topup", "recharge",
	}
	reGambling = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(bet|wager|casino|slot|gamble|lottery|lotto|poker|roulette|jackpot|withdraw|deposit|reward|bonus|payout|cashout|spin)([^a-zA-Z]|$)`)

	attributionKeywords = []string{
		// Install attribution
		"installreferrer", "installattribution", "installsource",
		"googleplayinstallreferrer",
		// Campaign / conversion tracking
		"campaigndata", "campaignattribution", "campaigntracking",
		"conversiondata", "conversionvalue", "conversiontracking",
		"deferreddeeplink",
		// Attribution SDK names (long enough for substring match)
		"appsflyerlib", "appsflyerdata", "appsflyerconv",
		"branchmetrics", "branchuniversalobj",
		"kochavatracker", "kochavaevent",
		"singularsdk", "tenjinsdk", "airbridgesdk",
		"adjustattribution", "adjustsession", "adjustevent", "adjustconfig",
		"adjustdevice", "getadid",
	}
	reAttribution = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(referrer|organic|campaign|attribution|appsflyer|kochava|utm_source|utm_medium|utm_campaign|utm_content|utm_term|install_referrer|ad_id|adid|gclid|fbclid)([^a-zA-Z]|$)`)

	webviewKeywords = []string{
		// WebView core
		"loadurl", "loaddata", "loadrequest",
		"evaluatejavascript", "addjavascriptinterface",
		"javascriptchannel", "webviewclient", "webviewcontroller",
		"webchromeclient", "inappwebview", "inappbrowser",
		"shouldoverrideurlloading", "shouldinterceptrequest",
		"webmessagelistener", "onpagestarted", "onpagefinished",
		// Chrome / custom tabs
		"customtab", "opencustomtab", "chrometab", "chromeclient",
		// Intent / deep linking
		"startactivity", "intentfilter", "deeplink", "applink",
		"launchurl", "canlaunch", "urlscheme",
		// Java bridge / JNI
		"javabridge", "jsbridge", "nativebridge",
		"javascriptinterface", "postmessage",
		// Cookies
		"cookiemanager", "setcookie", "getcookie", "clearcookie",
		"cookiejar", "cookiestore",
	}
	reWebView = regexp.MustCompile(`(?i)(^|[^a-zA-Z])(webview|loadurl|cookie|intent|jsbridge)([^a-zA-Z]|$)`)
)

// ClassifyString returns the set of signal categories matching the value.
// Returns nil if the string carries no signal.
func ClassifyString(value string) []string {
	if len(value) < 2 {
		return nil
	}

	var cats []string
	lower := strings.ToLower(value)

	// URL
	if reURL.MatchString(value) {
		cats = append(cats, CatURL)
	}

	// Host (IP literal)
	if reIPLiteral.MatchString(value) {
		cats = append(cats, CatHost)
	}

	// Crypto: keyword substring match + word-boundary regex for short words.
	if containsKeyword(value, cryptoKeywords) || reCryptoShort.MatchString(value) {
		cats = append(cats, CatEncryption)
	}

	// Auth (word-boundary matching to avoid camelCase false positives).
	if reAuth.MatchString(value) || reAuthStandalone.MatchString(value) {
		cats = append(cats, CatAuth)
	}

	// Net (HTTP methods or network keywords)
	for _, m := range httpMethods {
		if value == m {
			cats = append(cats, CatNet)
			break
		}
	}
	if !containsCat(cats, CatNet) {
		for _, w := range netKeywords {
			if strings.Contains(lower, w) {
				cats = append(cats, CatNet)
				break
			}
		}
	}

	// File extension
	for _, ext := range signalExtensions {
		if strings.HasSuffix(lower, ext) || strings.Contains(lower, ext+" ") || strings.Contains(lower, ext+",") {
			cats = append(cats, CatFileExt)
			break
		}
	}

	// Base64/hex key (high-entropy, standalone).
	// Exclude camelCase identifiers which match the character set but aren't keys.
	trimmed := strings.TrimSpace(value)
	if reBase64.MatchString(trimmed) && entropy(value) > 3.5 && !isCamelCase(trimmed) {
		cats = append(cats, CatBase64Key)
	}

	// SIM / telephony
	if containsKeyword(value, simKeywords) {
		cats = append(cats, CatSIM)
	}

	// SMS
	if containsKeyword(value, smsKeywords) || reSMS.MatchString(value) {
		cats = append(cats, CatSMS)
	}

	// Contacts
	if containsKeyword(value, contactKeywords) {
		cats = append(cats, CatContacts)
	}

	// Location / GPS
	if containsKeyword(value, locationKeywords) || reLocationShort.MatchString(value) {
		cats = append(cats, CatLocation)
	}

	// Device info / fingerprinting
	if containsKeyword(value, deviceInfoKeywords) {
		cats = append(cats, CatDeviceInfo)
	}

	// Cloaking
	if containsKeyword(value, cloakingKeywords) {
		cats = append(cats, CatCloaking)
	}

	// Data collection
	if reDataCollect.MatchString(value) {
		cats = append(cats, CatDataCollect)
	}

	// Camera
	if containsKeyword(value, cameraKeywords) {
		cats = append(cats, CatCamera)
	}

	// WebView
	if containsKeyword(value, webviewKeywords) || reWebView.MatchString(value) {
		cats = append(cats, CatWebView)
	}

	// Crypto wallet / blockchain
	if containsKeyword(value, walletKeywords) || reWallet.MatchString(value) {
		cats = append(cats, CatBlockchain)
	}

	// Gambling
	if containsKeyword(value, gamblingKeywords) || reGambling.MatchString(value) {
		cats = append(cats, CatGambling)
	}

	// Attribution / install tracking
	if containsKeyword(value, attributionKeywords) || reAttribution.MatchString(value) {
		cats = append(cats, CatAttribution)
	}

	return cats
}

// IsMundaneTHR returns true for THR field names that represent allocations,
// write barriers, or type checks — noise in the signal graph.
func IsMundaneTHR(name string) bool {
	lower := strings.ToLower(name)
	mundanePatterns := []string{
		"allocate",
		"write_barrier",
		"store_buffer",
		"type_test",
		"subtype_check",
		"call_to_runtime_ep",
		"stack_overflow",
		"null_error",
		"range_error",
		"throw_",
		"deoptimize",
		"megamorphic_call",
		"switchable_call",
		"monomorphic_",
		"lazy_deopt",
		"re_",
		"safepoint",
	}
	for _, p := range mundanePatterns {
		if strings.Contains(lower, p) {
			// Exception: call_native_through_safepoint_ep is interesting (FFI/JNI).
			if strings.Contains(lower, "native") {
				return false
			}
			return true
		}
	}
	return false
}

// Severity levels for signal categories.
const (
	SeverityHigh   = "high"
	SeverityMedium = "medium"
	SeverityLow    = "low"
)

// CategorySeverity returns the severity level for a category.
func CategorySeverity(cat string) string {
	switch cat {
	case CatEncryption, CatAuth, CatSIM, CatSMS, CatContacts, CatCloaking, CatDataCollect, CatWebView, CatBlockchain, CatGambling:
		return SeverityHigh
	case CatURL, CatHost, CatBase64Key, CatLocation, CatDeviceInfo, CatCamera, CatAttribution:
		return SeverityMedium
	case CatNet, CatFileExt, "thr":
		return SeverityLow
	default:
		return SeverityLow
	}
}

// MaxSeverity returns the highest severity from a list of categories.
func MaxSeverity(categories []string) string {
	best := ""
	for _, c := range categories {
		s := CategorySeverity(c)
		if s == SeverityHigh {
			return SeverityHigh
		}
		if s == SeverityMedium {
			best = SeverityMedium
		} else if best == "" {
			best = SeverityLow
		}
	}
	if best == "" {
		return SeverityLow
	}
	return best
}

// isCamelCase returns true if the string looks like a camelCase/PascalCase identifier.
// It checks for lowercase-to-uppercase transitions (e.g. "checkSimCard").
func isCamelCase(s string) bool {
	for i := 1; i < len(s); i++ {
		if s[i-1] >= 'a' && s[i-1] <= 'z' && s[i] >= 'A' && s[i] <= 'Z' {
			return true
		}
	}
	return false
}

// normalizeForMatch strips underscores, hyphens, spaces, and dots from a
// lowercased string. This lets "checkSimCard", "check_sim_card", and
// "check sim card" all match the keyword "checksimcard".
func normalizeForMatch(s string) string {
	lower := strings.ToLower(s)
	var b strings.Builder
	b.Grow(len(lower))
	for i := 0; i < len(lower); i++ {
		c := lower[i]
		if c != '_' && c != '-' && c != ' ' && c != '.' {
			b.WriteByte(c)
		}
	}
	return b.String()
}

// containsKeyword checks if the normalized value contains any keyword.
// Keywords should be lowercase with no separators (e.g. "checksimcard").
func containsKeyword(value string, keywords []string) bool {
	norm := normalizeForMatch(value)
	for _, kw := range keywords {
		if strings.Contains(norm, kw) {
			return true
		}
	}
	return false
}

func containsCat(cats []string, cat string) bool {
	for _, c := range cats {
		if c == cat {
			return true
		}
	}
	return false
}

// entropy computes Shannon entropy of a string in bits per character.
func entropy(s string) float64 {
	if len(s) == 0 {
		return 0
	}
	freq := make(map[byte]int)
	for i := 0; i < len(s); i++ {
		freq[s[i]]++
	}
	n := float64(len(s))
	var ent float64
	for _, count := range freq {
		p := float64(count) / n
		if p > 0 {
			ent -= p * math.Log2(p)
		}
	}
	return ent
}

```

`internal/signal/classify_test.go`:

```go
package signal

import "testing"

func TestClassifyURL(t *testing.T) {
	cats := ClassifyString("https://api.icloseli.com/oauth/accessToken")
	if !containsCat(cats, CatURL) {
		t.Errorf("expected url category, got %v", cats)
	}
	if !containsCat(cats, CatAuth) {
		t.Errorf("expected auth category for oauth/accessToken, got %v", cats)
	}
}

func TestClassifyCrypto(t *testing.T) {
	for _, s := range []string{
		"AES/CBC/PKCS7PADDING", "sha256", "HMAC-SHA1", "encrypt",
		"xor cipher", "XOR decrypt key", "encryptAndStoreSecretToken",
		"Ciphertext:", "Nonce must have 12 bytes",
		"PartnerVerify_CHMACSHA256", "SALT",
		"RSA", "rsa_public_key",
	} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatEncryption) {
			t.Errorf("expected crypto category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyCryptoFalsePositives(t *testing.T) {
	for _, s := range []string{
		"skipTraversal",
		"TraversalEdgeBehavior.",
		"FocusTraversalPolicy",
		"SliverSafeArea",
		"set:_indexOrNext@1026248",
		"get:descendantsAreTraversable",
	} {
		cats := ClassifyString(s)
		if containsCat(cats, CatEncryption) {
			t.Errorf("should NOT be crypto: %q, got %v", s, cats)
		}
	}
}

func TestClassifyAuth(t *testing.T) {
	for _, s := range []string{"password", "Bearer token", "jwt", "apikey", "Authorization"} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatAuth) {
			t.Errorf("expected auth category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyNet(t *testing.T) {
	cats := ClassifyString("GET")
	if !containsCat(cats, CatNet) {
		t.Errorf("expected net category for GET, got %v", cats)
	}
	cats = ClassifyString("socket connection")
	if !containsCat(cats, CatNet) {
		t.Errorf("expected net category for socket, got %v", cats)
	}
}

func TestClassifyFileExt(t *testing.T) {
	cats := ClassifyString("classes.dex")
	if !containsCat(cats, CatFileExt) {
		t.Errorf("expected file_ext for classes.dex, got %v", cats)
	}
	cats = ClassifyString("data.json")
	if !containsCat(cats, CatFileExt) {
		t.Errorf("expected file_ext for data.json, got %v", cats)
	}
}

func TestClassifyBase64Key(t *testing.T) {
	cats := ClassifyString("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/==")
	if !containsCat(cats, CatBase64Key) {
		t.Errorf("expected base64_key, got %v", cats)
	}
}

func TestClassifyAuthFalsePositive(t *testing.T) {
	// Flutter framework camelCase identifiers should not trigger auth.
	for _, s := range []string{"brieflyShowPassword", "nativeSpellCheckServiceDefined", "platformBrightness"} {
		cats := ClassifyString(s)
		if containsCat(cats, CatAuth) {
			t.Errorf("should NOT be auth: %q, got %v", s, cats)
		}
	}
}

func TestClassifyMundane(t *testing.T) {
	// Normal runtime error strings should not be classified.
	cats := ClassifyString("Index out of range")
	if len(cats) != 0 {
		t.Errorf("expected no categories for mundane string, got %v", cats)
	}
}

func TestClassifyIP(t *testing.T) {
	cats := ClassifyString("192.168.1.1:8080")
	if !containsCat(cats, CatHost) {
		t.Errorf("expected host category for IP literal, got %v", cats)
	}
}

func TestClassifySIM(t *testing.T) {
	for _, s := range []string{"checkSimCard", "SIM card check failed:", "IMEI", "sim_operator"} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatSIM) {
			t.Errorf("expected sim category for %q, got %v", s, cats)
		}
	}
	// "similar" should NOT trigger sim
	cats := ClassifyString("similar results")
	if containsCat(cats, CatSIM) {
		t.Errorf("'similar' should NOT be sim, got %v", cats)
	}
}

func TestClassifySMS(t *testing.T) {
	for _, s := range []string{`{"type": "sms", "description" : "SMS log"}`, "send_sms", "SmsManager"} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatSMS) {
			t.Errorf("expected sms category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyContacts(t *testing.T) {
	for _, s := range []string{"ContactAddressModel", "/customer/contactAddress?contractId=", "read_contacts", "call_log"} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatContacts) {
			t.Errorf("expected contacts category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyLocation(t *testing.T) {
	for _, s := range []string{
		"RequestCurrentLocation error",
		"geolocationEnabled",
		"geofence",
		"enableLocation",
		"IsEnableLocationService",
		"LocationException",
		"lastKnownLocation",
		"fusedLocationProvider",
		"GPS coordinates",
		"GeolocationPermissionsCallback",
		"[MobileDataCollector] RequestCurrentLocation error => ",
		"[MobileDataCollector] IsEnableLocationService error => ",
		"requestCurrentLocationSimple",
	} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatLocation) {
			t.Errorf("expected location category for %q, got %v", s, cats)
		}
	}
	// Framework noise should NOT match.
	for _, s := range []string{
		"layout ( location = 0 ) out vec4 oColor;",
		"FloatingActionButtonLocation.endFloat",
		"get:localPosition",
		"TextPosition(offset: ",
		"ScrollPositionAlignmentPolicy.",
	} {
		cats := ClassifyString(s)
		if containsCat(cats, CatLocation) {
			t.Errorf("should NOT be location: %q, got %v", s, cats)
		}
	}
}

func TestClassifyDeviceInfo(t *testing.T) {
	for _, s := range []string{"Device ID", "getDeviceID", "device_id", "installReferrer", "installerStore"} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatDeviceInfo) {
			t.Errorf("expected device category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyCloaking(t *testing.T) {
	for _, s := range []string{
		"Keyword check failed: ",
		"Keyword mismatch: expected ",
		"checkKeywords",
		"is_allowed",
		"checkAndLaunchRedirect",
		"app_country",
	} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatCloaking) {
			t.Errorf("expected cloaking category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyDataCollect(t *testing.T) {
	for _, s := range []string{
		"[MobileDataCollector] SendAllMobileData",
		"StartMobileDataCollectionEvent",
		"Collect data fail",
	} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatDataCollect) {
			t.Errorf("expected data category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyCamera(t *testing.T) {
	for _, s := range []string{"camera_permission", "CAMERA_OPEN_FAILED", "getAvailableCameras"} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatCamera) {
			t.Errorf("expected camera category for %q, got %v", s, cats)
		}
	}
}

func TestClassifyAttribution(t *testing.T) {
	for _, s := range []string{
		"utm_medium=organic",
		"utm_source=(not20%set)&utm_medium=(not20%set)",
		"getAdjustDeviceID",
		"install_referrer",
		"referrer data",
		"campaign_id=123",
		"AppsFlyer conversion",
		"adjustConfig params",
		"kochava tracker init",
	} {
		cats := ClassifyString(s)
		if !containsCat(cats, CatAttribution) {
			t.Errorf("expected attribution category for %q, got %v", s, cats)
		}
	}
	// False positives: generic words that happen to appear.
	for _, s := range []string{
		"callbackParameters",
		"partnerParameters",
		"flutter4.38.1",
		"addSessionCallbackParameter",
	} {
		cats := ClassifyString(s)
		if containsCat(cats, CatAttribution) {
			t.Errorf("should NOT be attribution: %q, got %v", s, cats)
		}
	}
}

func TestIsMundaneTHR(t *testing.T) {
	mundane := []string{
		"AllocateArray_ep",
		"AllocateObject_ep",
		"write_barrier_entry_point",
		"store_buffer_ep",
		"type_test_stub",
		"subtype_check_ep",
		"call_to_runtime_ep",
	}
	for _, name := range mundane {
		if !IsMundaneTHR(name) {
			t.Errorf("expected %q to be mundane", name)
		}
	}

	interesting := []string{
		"call_native_through_safepoint_ep",
		"active_exception_ep",
	}
	for _, name := range interesting {
		if IsMundaneTHR(name) {
			t.Errorf("expected %q to NOT be mundane", name)
		}
	}
}

```

`internal/signal/graph.go`:

```go
package signal

import (
	"sort"
	"strings"

	"unflutter/internal/disasm"
)

// ClassifiedStringRef is a string reference with its signal categories.
type ClassifiedStringRef struct {
	Func       string   `json:"func"`
	PC         string   `json:"pc"`
	Kind       string   `json:"kind"`
	PoolIdx    int      `json:"pool_idx"`
	Value      string   `json:"value"`
	Categories []string `json:"categories,omitempty"`
}

// SignalFunc is a function in the signal graph.
type SignalFunc struct {
	Name         string                `json:"name"`
	Owner        string                `json:"owner,omitempty"`
	PC           string                `json:"pc"`
	Size         int                   `json:"size"`
	StringRefs   []ClassifiedStringRef `json:"string_refs,omitempty"`
	Categories   []string              `json:"categories"`
	Severity     string                `json:"severity"` // "high", "medium", "low"
	Role         string                `json:"role"`     // "signal", "context", ""
	IsEntryPoint bool                  `json:"is_entry_point,omitempty"`
}

// SignalEdge is an edge in the signal graph.
type SignalEdge struct {
	From string `json:"from"`
	To   string `json:"to"`
	Kind string `json:"kind"` // "bl", "blr"
	Via  string `json:"via,omitempty"`
}

// SignalGraph is the complete signal graph.
type SignalGraph struct {
	Funcs []SignalFunc `json:"funcs"`
	Edges []SignalEdge `json:"edges"`
	Stats SignalStats  `json:"stats"`
}

// SignalStats holds summary statistics.
type SignalStats struct {
	TotalFuncs     int            `json:"total_funcs"`
	SignalFuncs    int            `json:"signal_funcs"`
	ContextFuncs   int            `json:"context_funcs"`
	TotalEdges     int            `json:"total_edges"`
	StringRefCount int            `json:"string_ref_count"`
	Categories     map[string]int `json:"categories"`
}

// BuildSignalGraph constructs a signal graph from disasm artifacts.
// k = number of context hops from each signal function.
// entryPoints is the set of functions with no incoming BL edges (may be nil).
func BuildSignalGraph(
	funcs []disasm.FuncRecord,
	edges []disasm.CallEdgeRecord,
	stringRefs []disasm.StringRefRecord,
	k int,
	entryPoints map[string]bool,
) *SignalGraph {
	// Index functions by name.
	funcByName := make(map[string]*disasm.FuncRecord, len(funcs))
	for i := range funcs {
		funcByName[funcs[i].Name] = &funcs[i]
	}

	// Group string refs by function and classify each string individually.
	type funcSignal struct {
		refs       []ClassifiedStringRef
		categories map[string]bool
	}
	funcSignals := make(map[string]*funcSignal)

	catCounts := make(map[string]int)

	for _, sr := range stringRefs {
		cats := ClassifyString(sr.Value)
		if len(cats) == 0 {
			continue
		}
		fs, ok := funcSignals[sr.Func]
		if !ok {
			fs = &funcSignal{categories: make(map[string]bool)}
			funcSignals[sr.Func] = fs
		}
		csr := ClassifiedStringRef{
			Func:       sr.Func,
			PC:         sr.PC,
			Kind:       sr.Kind,
			PoolIdx:    sr.PoolIdx,
			Value:      sr.Value,
			Categories: cats,
		}
		fs.refs = append(fs.refs, csr)
		for _, c := range cats {
			if !fs.categories[c] {
				fs.categories[c] = true
				catCounts[c]++
			}
		}
	}

	// Also mark functions with non-mundane THR calls.
	for _, e := range edges {
		if e.Kind != "blr" || e.Via == "" {
			continue
		}
		if !strings.HasPrefix(e.Via, "THR.") {
			continue
		}
		thrName := e.Via[4:]
		if IsMundaneTHR(thrName) {
			continue
		}
		// Mark the calling function as signal.
		if _, ok := funcSignals[e.FromFunc]; !ok {
			funcSignals[e.FromFunc] = &funcSignal{categories: make(map[string]bool)}
		}
		funcSignals[e.FromFunc].categories["thr"] = true
	}

	// Signal function set.
	signalSet := make(map[string]bool, len(funcSignals))
	for name := range funcSignals {
		signalSet[name] = true
	}

	// Build bidirectional adjacency for BFS context expansion.
	fwd := make(map[string][]string) // caller → callees
	rev := make(map[string][]string) // callee → callers
	for _, e := range edges {
		if e.Kind == "bl" && e.Target != "" {
			fwd[e.FromFunc] = append(fwd[e.FromFunc], e.Target)
			rev[e.Target] = append(rev[e.Target], e.FromFunc)
		}
	}

	// BFS k hops from signal functions.
	contextSet := make(map[string]bool)
	visited := make(map[string]bool)
	type queueItem struct {
		name  string
		depth int
	}
	var queue []queueItem
	for name := range signalSet {
		visited[name] = true
		queue = append(queue, queueItem{name, 0})
	}
	for len(queue) > 0 {
		item := queue[0]
		queue = queue[1:]
		if item.depth >= k {
			continue
		}
		// Forward neighbors.
		for _, next := range fwd[item.name] {
			if !visited[next] {
				visited[next] = true
				contextSet[next] = true
				queue = append(queue, queueItem{next, item.depth + 1})
			}
		}
		// Reverse neighbors.
		for _, prev := range rev[item.name] {
			if !visited[prev] {
				visited[prev] = true
				contextSet[prev] = true
				queue = append(queue, queueItem{prev, item.depth + 1})
			}
		}
	}

	// Build ALL funcs with role annotations.
	var allFuncs []SignalFunc
	for _, f := range funcs {
		sf := SignalFunc{
			Name:         f.Name,
			Owner:        f.Owner,
			PC:           f.PC,
			Size:         f.Size,
			IsEntryPoint: entryPoints[f.Name],
		}
		if signalSet[f.Name] {
			sf.Role = "signal"
		} else if contextSet[f.Name] {
			sf.Role = "context"
		}
		if fs, ok := funcSignals[f.Name]; ok {
			sf.StringRefs = fs.refs
			for c := range fs.categories {
				sf.Categories = append(sf.Categories, c)
			}
			sort.Strings(sf.Categories)
			sf.Severity = MaxSeverity(sf.Categories)
		}
		allFuncs = append(allFuncs, sf)
	}

	// Sort: signal → context → other.
	// Within signal: entry points first, then severity, then category count.
	roleOrd := map[string]int{"signal": 0, "context": 1, "": 2}
	sevOrd := map[string]int{"high": 0, "medium": 1, "low": 2, "": 3}
	sort.Slice(allFuncs, func(i, j int) bool {
		si, sj := &allFuncs[i], &allFuncs[j]
		if si.Role != sj.Role {
			return roleOrd[si.Role] < roleOrd[sj.Role]
		}
		if si.Role == "signal" && si.IsEntryPoint != sj.IsEntryPoint {
			return si.IsEntryPoint
		}
		if si.Severity != sj.Severity {
			return sevOrd[si.Severity] < sevOrd[sj.Severity]
		}
		if len(si.Categories) != len(sj.Categories) {
			return len(si.Categories) > len(sj.Categories)
		}
		return si.Name < sj.Name
	})

	// Include ALL BL edges (deduped), plus non-mundane BLR edges.
	var allEdges []SignalEdge
	seen := make(map[string]bool)
	for _, e := range edges {
		var to string
		if e.Kind == "bl" {
			if e.Target == "" {
				continue
			}
			to = e.Target
		} else if e.Kind == "blr" {
			if e.Via == "" {
				continue
			}
			// Skip mundane THR.
			if strings.HasPrefix(e.Via, "THR.") && IsMundaneTHR(e.Via[4:]) {
				continue
			}
			to = e.Via
		} else {
			continue
		}

		key := e.FromFunc + "|" + to + "|" + e.Kind
		if seen[key] {
			continue
		}
		seen[key] = true

		se := SignalEdge{From: e.FromFunc, To: to, Kind: e.Kind}
		if e.Kind == "blr" {
			se.Via = e.Via
		}
		allEdges = append(allEdges, se)
	}

	return &SignalGraph{
		Funcs: allFuncs,
		Edges: allEdges,
		Stats: SignalStats{
			TotalFuncs:     len(funcs),
			SignalFuncs:    len(signalSet),
			ContextFuncs:   len(contextSet),
			TotalEdges:     len(allEdges),
			StringRefCount: len(stringRefs),
			Categories:     catCounts,
		},
	}
}

```

`internal/snapshot/image.go`:

```go
// Image header and InstructionsSection parsing for Dart AOT instruction snapshots.
package snapshot

import (
	"encoding/binary"
	"errors"
	"fmt"
)

// ImageHeader represents the header at the start of a Dart AOT instructions image.
// Layout (arm64, 64-bit words):
//
//	+0x00: ImageSize (uword) — total size of image including header
//	+0x08: InstructionsSectionOffset (uword) — offset from image start to InstructionsSection object
type ImageHeader struct {
	ImageSize                 uint64
	InstructionsSectionOffset uint64
}

// InstructionsSection represents the InstructionsSection heap object.
// Layout (arm64):
//
//	+0x00: tags_ (uword) — object header tag
//	+0x08: payload_length_ (uword) — instruction bytes that follow
//	+0x10: bss_offset_ (int64) — offset to BSS section
//	+0x18: instructions_relocated_address_ (uword)
//	+0x20: build_id_offset_ (int64)
//	+0x28: data[] — actual machine code starts here
type InstructionsSection struct {
	Tags                         uint64
	PayloadLength                uint64
	BSSOffset                    int64
	InstructionsRelocatedAddress uint64
	BuildIDOffset                int64
	CodeOffset                   uint64 // file offset where actual code begins (computed)
}

const (
	imageHeaderSize           = 16 // 2 * 8 bytes (arm64)
	instructionsSectionFields = 40 // 5 * 8 bytes (tag + 4 fields)
)

// ParseImageHeader reads the Image header from raw instruction section bytes.
func ParseImageHeader(data []byte) (*ImageHeader, error) {
	if len(data) < imageHeaderSize {
		return nil, errors.New("image: data too short for header")
	}
	return &ImageHeader{
		ImageSize:                 binary.LittleEndian.Uint64(data[0:8]),
		InstructionsSectionOffset: binary.LittleEndian.Uint64(data[8:16]),
	}, nil
}

// ParseInstructionsSection reads the InstructionsSection object from raw bytes.
// offset is the byte offset within the image where the object starts.
func ParseInstructionsSection(data []byte, offset uint64) (*InstructionsSection, error) {
	end := offset + instructionsSectionFields
	if uint64(len(data)) < end {
		return nil, fmt.Errorf("image: data too short for InstructionsSection at 0x%x", offset)
	}

	d := data[offset:]
	return &InstructionsSection{
		Tags:                         binary.LittleEndian.Uint64(d[0:8]),
		PayloadLength:                binary.LittleEndian.Uint64(d[8:16]),
		BSSOffset:                    int64(binary.LittleEndian.Uint64(d[16:24])),
		InstructionsRelocatedAddress: binary.LittleEndian.Uint64(d[24:32]),
		BuildIDOffset:                int64(binary.LittleEndian.Uint64(d[32:40])),
		CodeOffset:                   offset + instructionsSectionFields,
	}, nil
}

// CodeRegion extracts the actual machine code bytes from an instruction image.
// Returns the code bytes, their VA offset from the image start, and the payload length.
func CodeRegion(imageData []byte) (code []byte, codeOffsetInImage uint64, payloadLen uint64, err error) {
	hdr, err := ParseImageHeader(imageData)
	if err != nil {
		return nil, 0, 0, err
	}

	sect, err := ParseInstructionsSection(imageData, hdr.InstructionsSectionOffset)
	if err != nil {
		return nil, 0, 0, err
	}

	codeStart := sect.CodeOffset
	codeEnd := codeStart + sect.PayloadLength
	if codeEnd > uint64(len(imageData)) {
		// Clamp to available data.
		codeEnd = uint64(len(imageData))
	}
	if codeStart >= codeEnd {
		return nil, codeStart, 0, nil
	}

	return imageData[codeStart:codeEnd], codeStart, sect.PayloadLength, nil
}

```

`internal/snapshot/probe.go`:

```go
package snapshot

import "bytes"

// ProbeSnapshotMagic scans data for the Dart snapshot magic bytes (0xf5f5dcdc).
// Returns the byte offset of the first occurrence, or -1 if not found.
func ProbeSnapshotMagic(data []byte) int {
	return bytes.Index(data, snapshotMagic[:])
}

```

`internal/snapshot/profile.go`:

```go
// Profile definitions for Dart AOT snapshot format variations.
package snapshot

// ProfileID identifies a specific Dart AOT snapshot format profile.
type ProfileID string

const (
	ProfileAndroidARM64CompressedPtrs ProfileID = "android-arm64-compressedptrs"
	ProfileAndroidARM64NoCompress     ProfileID = "android-arm64-nocompress"
	ProfileUnknown                    ProfileID = "unknown"
)

// Profile holds per-version constants for snapshot layout parsing.
type Profile struct {
	ID                 ProfileID `json:"id"`
	CompressedPointers bool      `json:"compressed_pointers"`
	NullSafety         bool      `json:"null_safety"`
	TaggedPointerShift int       `json:"tagged_pointer_shift"` // typically 1
	ObjectAlignment    int       `json:"object_alignment"`     // typically 8 or 16
}

// DetectProfile guesses a profile from snapshot header features.
func DetectProfile(hdr *Header) Profile {
	if hdr == nil {
		return Profile{ID: ProfileUnknown}
	}

	p := Profile{
		ID:                 ProfileUnknown,
		TaggedPointerShift: 1,
		ObjectAlignment:    8,
	}

	features := hdr.FeatureList()
	for _, f := range features {
		switch f {
		case "compressed-pointers":
			p.CompressedPointers = true
		case "null-safety":
			p.NullSafety = true
		case "no-null-safety":
			p.NullSafety = false
		}
	}

	hasARM64 := false
	hasAndroid := false
	for _, f := range features {
		switch f {
		case "arm64", "arm64-sysv":
			hasARM64 = true
		case "android":
			hasAndroid = true
		}
	}

	if hasARM64 || hasAndroid {
		if p.CompressedPointers {
			p.ID = ProfileAndroidARM64CompressedPtrs
		} else {
			p.ID = ProfileAndroidARM64NoCompress
		}
	}

	return p
}

```

`internal/snapshot/snapshot.go`:

```go
// Package snapshot locates and extracts Dart snapshot regions from libapp.so.
package snapshot

import (
	"crypto/sha256"
	"encoding/hex"
	"errors"
	"fmt"
	"strings"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
)

// Well-known symbol names for Dart AOT snapshots.
const (
	SymVmSnapshotData              = "_kDartVmSnapshotData"
	SymVmSnapshotInstructions      = "_kDartVmSnapshotInstructions"
	SymIsolateSnapshotData         = "_kDartIsolateSnapshotData"
	SymIsolateSnapshotInstructions = "_kDartIsolateSnapshotInstructions"
	SymSnapshotBuildID             = "_kDartSnapshotBuildId"
)

// snapshotMagic is the 4-byte magic at the start of a Dart snapshot data blob.
var snapshotMagic = [4]byte{0xf5, 0xf5, 0xdc, 0xdc}

// Region describes one snapshot region extracted from libapp.so.
type Region struct {
	Name       string `json:"name"`
	VA         uint64 `json:"va"`
	FileOffset uint64 `json:"file_offset"`
	SymSize    uint64 `json:"sym_size"`  // from ELF symbol; 0 if unknown
	DataSize   uint64 `json:"data_size"` // from snapshot header; 0 if not parsed
	SHA256     string `json:"sha256"`    // hex; empty if data not extracted
	Data       []byte `json:"-"`         // raw bytes; not serialized
}

// SnapshotKind identifies the snapshot type.
type SnapshotKind int64

const (
	KindFull    SnapshotKind = 0
	KindCore    SnapshotKind = 1
	KindFullJIT SnapshotKind = 2
	KindFullAOT SnapshotKind = 3
)

func (k SnapshotKind) String() string {
	switch k {
	case KindFull:
		return "Full"
	case KindCore:
		return "FullCore"
	case KindFullJIT:
		return "FullJIT"
	case KindFullAOT:
		return "FullAOT"
	default:
		return fmt.Sprintf("Unknown(%d)", k)
	}
}

// Header holds parsed fields from a Dart snapshot data header.
// Layout:
//
//	+0x00: magic   int32  (0xdcdcf5f5)
//	+0x04: length  int64  (excludes magic; total = stored + 4)
//	+0x0c: kind    int64  (0=Full, 1=Core, 2=FullJIT, 3=FullAOT)
//	+0x14: version hash (32 ASCII hex chars)
//	+0x34: features (null-terminated string)
type Header struct {
	Magic        [4]byte      `json:"-"`
	Length       int64        `json:"length"` // stored length (excludes magic)
	TotalSize    int64        `json:"size"`   // length + 4
	Kind         SnapshotKind `json:"kind"`
	SnapshotHash string       `json:"snapshot_hash"` // 32 hex chars at offset 0x14
	Features     string       `json:"features"`      // null-terminated at offset 0x34
}

// FeatureList returns the features as a sorted slice.
func (h *Header) FeatureList() []string {
	if h.Features == "" {
		return nil
	}
	return strings.Split(h.Features, " ")
}

// HasFeature checks if a specific feature is present.
func (h *Header) HasFeature(name string) bool {
	for _, f := range h.FeatureList() {
		if f == name {
			return true
		}
	}
	return false
}

// Info aggregates all extracted snapshot information.
type Info struct {
	VmData              Region          `json:"vm_data"`
	VmInstructions      Region          `json:"vm_instructions"`
	IsolateData         Region          `json:"isolate_data"`
	IsolateInstructions Region          `json:"isolate_instructions"`
	VmHeader            *Header         `json:"vm_header,omitempty"`
	IsolateHeader       *Header         `json:"isolate_header,omitempty"`
	Version             *VersionProfile `json:"version,omitempty"`
	Diags               []dartfmt.Diag  `json:"diagnostics,omitempty"`
}

// Extract locates and reads snapshot regions from an opened ELF file.
func Extract(ef *elfx.File, opts dartfmt.Options) (*Info, error) {
	var diags dartfmt.Diags
	info := &Info{}

	// Resolve all four snapshot symbols.
	type symTarget struct {
		name   string
		region *Region
	}
	targets := []symTarget{
		{SymVmSnapshotData, &info.VmData},
		{SymVmSnapshotInstructions, &info.VmInstructions},
		{SymIsolateSnapshotData, &info.IsolateData},
		{SymIsolateSnapshotInstructions, &info.IsolateInstructions},
	}

	for _, t := range targets {
		t.region.Name = t.name
		va, size, err := ef.Symbol(t.name)
		if err != nil {
			if opts.Mode == dartfmt.ModeStrict {
				return nil, fmt.Errorf("snapshot: %w", err)
			}
			diags.Add(0, dartfmt.DiagInvalid, fmt.Sprintf("symbol %s not found: %v", t.name, err))
			continue
		}
		t.region.VA = va
		t.region.SymSize = size

		off, err := ef.VAToFileOffset(va)
		if err != nil {
			if opts.Mode == dartfmt.ModeStrict {
				return nil, fmt.Errorf("snapshot: VA mapping for %s: %w", t.name, err)
			}
			diags.Add(va, dartfmt.DiagInvalid, fmt.Sprintf("VA 0x%x for %s: %v", va, t.name, err))
			continue
		}
		t.region.FileOffset = off

		// Read region data. Use symbol size if available, else cap at a reasonable max.
		readSize := size
		if readSize == 0 {
			// For instruction regions, symbol size is often 0. We'll read a
			// capped amount; the actual size comes from header parsing or
			// region boundary analysis later.
			readSize = capRegionSize(ef, va)
		}
		if readSize > 0 {
			data, err := ef.ReadBytesAtVA(va, int(readSize))
			if err != nil {
				if opts.Mode == dartfmt.ModeStrict {
					return nil, fmt.Errorf("snapshot: read %s: %w", t.name, err)
				}
				diags.Add(va, dartfmt.DiagTruncated, fmt.Sprintf("read %s: %v", t.name, err))
			} else {
				t.region.Data = data
				t.region.DataSize = uint64(len(data))
				h := sha256.Sum256(data)
				t.region.SHA256 = hex.EncodeToString(h[:])
			}
		}
	}

	// Parse headers from snapshot data regions.
	if len(info.VmData.Data) >= 64 {
		hdr, err := parseHeader(info.VmData.Data)
		if err != nil {
			diags.Add(info.VmData.VA, dartfmt.DiagInvalid, fmt.Sprintf("vm header: %v", err))
		} else {
			info.VmHeader = hdr
		}
	}
	if len(info.IsolateData.Data) >= 64 {
		hdr, err := parseHeader(info.IsolateData.Data)
		if err != nil {
			diags.Add(info.IsolateData.VA, dartfmt.DiagInvalid, fmt.Sprintf("isolate header: %v", err))
		} else {
			info.IsolateHeader = hdr
		}
	}

	// Detect Dart SDK version from snapshot hash.
	if info.VmHeader != nil && info.VmHeader.SnapshotHash != "" {
		info.Version = DetectVersion(info.VmHeader.SnapshotHash)

		// For unknown hashes, probe the VM data to determine tag style.
		if info.Version != nil && info.Version.DartVersion == "" && info.VmData.Data != nil {
			if cs, err := findClusterDataStart(info.VmData.Data); err == nil {
				info.Version = ProbeTagStyle(info.VmData.Data, cs)
			}
		}
	}

	// Propagate compressed pointers flag from features to version profile.
	if info.Version != nil {
		if (info.IsolateHeader != nil && info.IsolateHeader.HasFeature("compressed-pointers")) ||
			(info.VmHeader != nil && info.VmHeader.HasFeature("compressed-pointers")) {
			info.Version.CompressedPointers = true
		}
	}

	info.Diags = diags.Items()
	return info, nil
}

// findClusterDataStart returns the byte offset where clustered data begins
// within a snapshot data region. Duplicated from cluster package to avoid
// circular imports.
func findClusterDataStart(data []byte) (int, error) {
	const minHeader = 0x35
	if len(data) < minHeader {
		return 0, fmt.Errorf("data too short (%d < %d)", len(data), minHeader)
	}
	featStart := 0x34
	for i := featStart; i < len(data); i++ {
		if data[i] == 0 {
			return i + 1, nil
		}
		if i-featStart > 1024 {
			return 0, fmt.Errorf("features string too long")
		}
	}
	return 0, fmt.Errorf("unterminated features string")
}

// capRegionSize computes a bounded read size for a region whose symbol has size 0.
// Uses the gap to the next known VA or the segment end.
func capRegionSize(ef *elfx.File, va uint64) uint64 {
	const maxCap = 256 * 1024 * 1024 // 256 MiB hard cap

	// Find the PT_LOAD segment containing this VA and use its end as bound.
	for _, seg := range ef.LoadSegments() {
		if va >= seg.Vaddr && va < seg.Vaddr+seg.Filesz {
			remaining := seg.Vaddr + seg.Filesz - va
			if remaining > maxCap {
				remaining = maxCap
			}
			return remaining
		}
	}
	return 0
}

// Snapshot data header layout (observed from Dart AOT snapshots):
//
//	+0x00: magic       [4]byte  {0xf5, 0xf5, 0xdc, 0xdc}
//	+0x04: size        uint32   (little-endian, blob size)
//	+0x08: padding     [8]byte  (zeros + kind field)
//	+0x10: padding     [4]byte  (zeros)
//	+0x14: hash        [32]byte (ASCII hex, snapshot version hash)
//	+0x34: features    []byte   (null-terminated, space-separated)
const (
	headerMinSize  = 0x35 // minimum to read magic + size + hash
	hashOffset     = 0x14
	hashLen        = 32
	featuresOffset = 0x34
)

// parseHeader extracts structured fields from a Dart snapshot data blob header.
func parseHeader(data []byte) (*Header, error) {
	if len(data) < headerMinSize {
		return nil, errors.New("header too short")
	}
	var h Header
	copy(h.Magic[:], data[:4])
	if h.Magic != snapshotMagic {
		return nil, fmt.Errorf("bad magic: %x (want %x)", h.Magic, snapshotMagic)
	}

	// Bytes 4-11: length (int64 LE, excludes magic).
	h.Length = int64(data[4]) | int64(data[5])<<8 | int64(data[6])<<16 | int64(data[7])<<24 |
		int64(data[8])<<32 | int64(data[9])<<40 | int64(data[10])<<48 | int64(data[11])<<56
	h.TotalSize = h.Length + 4 // add magic size

	// Bytes 12-19: kind (int64 LE).
	kind := int64(data[12]) | int64(data[13])<<8 | int64(data[14])<<16 | int64(data[15])<<24 |
		int64(data[16])<<32 | int64(data[17])<<40 | int64(data[18])<<48 | int64(data[19])<<56
	h.Kind = SnapshotKind(kind)

	// Offset 0x14: 32-char hex snapshot version hash.
	if len(data) >= hashOffset+hashLen {
		hashBytes := data[hashOffset : hashOffset+hashLen]
		validHex := true
		for _, b := range hashBytes {
			if !((b >= '0' && b <= '9') || (b >= 'a' && b <= 'f')) {
				validHex = false
				break
			}
		}
		if validHex {
			h.SnapshotHash = string(hashBytes)
		}
	}

	// Offset 0x34: null-terminated features string.
	if len(data) > featuresOffset {
		featEnd := featuresOffset
		for featEnd < len(data) && data[featEnd] != 0 {
			featEnd++
			if featEnd-featuresOffset > 1024 { // sanity cap
				break
			}
		}
		if featEnd > featuresOffset {
			h.Features = string(data[featuresOffset:featEnd])
		}
	}

	return &h, nil
}

```

`internal/snapshot/snapshot_test.go`:

```go
package snapshot

import (
	"os"
	"path/filepath"
	"testing"

	"unflutter/internal/dartfmt"
	"unflutter/internal/elfx"
)

func findSample(t *testing.T, name string) string {
	t.Helper()
	dir, _ := os.Getwd()
	for {
		p := filepath.Join(dir, "samples", name)
		if _, err := os.Stat(p); err == nil {
			return p
		}
		parent := filepath.Dir(dir)
		if parent == dir {
			t.Skipf("sample %s not found", name)
		}
		dir = parent
	}
}

func openSample(t *testing.T, name string) *elfx.File {
	t.Helper()
	path := findSample(t, name)
	ef, err := elfx.Open(path)
	if err != nil {
		t.Fatal(err)
	}
	t.Cleanup(func() { ef.Close() })
	return ef
}

func TestExtractBlutterLCE(t *testing.T) {
	ef := openSample(t, "blutter-lce.so")
	info, err := Extract(ef, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
	if err != nil {
		t.Fatal(err)
	}

	// Verify all four regions found.
	if info.VmData.VA == 0 {
		t.Error("VmData VA is 0")
	}
	if info.VmInstructions.VA == 0 {
		t.Error("VmInstructions VA is 0")
	}
	if info.IsolateData.VA == 0 {
		t.Error("IsolateData VA is 0")
	}
	if info.IsolateInstructions.VA == 0 {
		t.Error("IsolateInstructions VA is 0")
	}

	// Verify headers parsed.
	if info.VmHeader == nil {
		t.Fatal("VmHeader is nil")
	}
	if info.VmHeader.SnapshotHash == "" {
		t.Error("VmHeader hash is empty")
	}
	if info.VmHeader.SnapshotHash != "1441d6b13b8623fa7fbf61433abebd31" {
		t.Errorf("unexpected hash: %s", info.VmHeader.SnapshotHash)
	}
	if info.VmHeader.Features == "" {
		t.Error("VmHeader features is empty")
	}

	// Verify SHA256 computed.
	if info.VmData.SHA256 == "" {
		t.Error("VmData SHA256 is empty")
	}
}

func TestExtractNewandromo(t *testing.T) {
	ef := openSample(t, "newandromo.so")
	info, err := Extract(ef, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
	if err != nil {
		t.Fatal(err)
	}

	if info.VmHeader == nil {
		t.Fatal("VmHeader is nil")
	}
	if info.VmHeader.SnapshotHash != "7dbbeeb8ef7b91338640dca3927636de" {
		t.Errorf("unexpected hash: %s", info.VmHeader.SnapshotHash)
	}
	if !info.VmHeader.HasFeature("null-safety") {
		t.Error("expected null-safety feature")
	}
	if !info.VmHeader.HasFeature("compressed-pointers") {
		t.Error("expected compressed-pointers feature")
	}
}

func TestExtractEvilPatched(t *testing.T) {
	ef := openSample(t, "evil-patched.so")
	info, err := Extract(ef, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
	if err != nil {
		t.Fatal(err)
	}

	if info.VmHeader == nil {
		t.Fatal("VmHeader is nil")
	}
	if info.VmHeader.SnapshotHash != "1ce86630892e2dca9a8543fdb8ed8e22" {
		t.Errorf("unexpected hash: %s", info.VmHeader.SnapshotHash)
	}
}

func TestDetectProfile(t *testing.T) {
	tests := []struct {
		name     string
		features string
		wantID   ProfileID
		wantCP   bool
		wantNS   bool
	}{
		{
			name:     "compressed with null safety",
			features: "arm64 android compressed-pointers null-safety",
			wantID:   ProfileAndroidARM64CompressedPtrs,
			wantCP:   true,
			wantNS:   true,
		},
		{
			name:     "compressed without null safety",
			features: "arm64-sysv compressed-pointers no-null-safety",
			wantID:   ProfileAndroidARM64CompressedPtrs,
			wantCP:   true,
			wantNS:   false,
		},
		{
			name:     "no compression",
			features: "arm64 android",
			wantID:   ProfileAndroidARM64NoCompress,
			wantCP:   false,
			wantNS:   false,
		},
		{
			name:     "nil header",
			features: "",
			wantID:   ProfileUnknown,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			var hdr *Header
			if tt.features != "" {
				hdr = &Header{Features: tt.features}
			}
			p := DetectProfile(hdr)
			if p.ID != tt.wantID {
				t.Errorf("ID: got %s, want %s", p.ID, tt.wantID)
			}
			if p.CompressedPointers != tt.wantCP {
				t.Errorf("CompressedPointers: got %v, want %v", p.CompressedPointers, tt.wantCP)
			}
			if p.NullSafety != tt.wantNS {
				t.Errorf("NullSafety: got %v, want %v", p.NullSafety, tt.wantNS)
			}
		})
	}
}

// TestVersionProfileFlags pins the format flag cross-product per sample.
// If a hash→profile mapping changes or flags are swapped, this fails.
func TestVersionProfileFlags(t *testing.T) {
	tests := []struct {
		sample         string
		wantVersion    string
		wantHeaderFlds int
		wantFillRefUns bool
		wantPreV32     bool
	}{
		{"blutter-lce.so", "2.17.6", 6, true, true},
		{"newandromo.so", "3.1.0", 5, false, true},
		{"evil-patched.so", "3.10.7", 5, false, false},
	}
	for _, tt := range tests {
		t.Run(tt.sample, func(t *testing.T) {
			ef := openSample(t, tt.sample)
			info, err := Extract(ef, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
			if err != nil {
				t.Fatal(err)
			}
			if info.Version.DartVersion != tt.wantVersion {
				t.Errorf("DartVersion = %q, want %q", info.Version.DartVersion, tt.wantVersion)
			}
			if info.Version.HeaderFields != tt.wantHeaderFlds {
				t.Errorf("HeaderFields = %d, want %d", info.Version.HeaderFields, tt.wantHeaderFlds)
			}
			if info.Version.FillRefUnsigned != tt.wantFillRefUns {
				t.Errorf("FillRefUnsigned = %v, want %v", info.Version.FillRefUnsigned, tt.wantFillRefUns)
			}
			if info.Version.PreV32Format != tt.wantPreV32 {
				t.Errorf("PreV32Format = %v, want %v", info.Version.PreV32Format, tt.wantPreV32)
			}
		})
	}
}

func TestParseHeader(t *testing.T) {
	// Construct a minimal valid header.
	data := make([]byte, 256)
	copy(data[0:4], []byte{0xf5, 0xf5, 0xdc, 0xdc})
	data[4] = 0x10 // size = 16
	copy(data[0x14:0x34], []byte("abcdef0123456789abcdef0123456789"))
	copy(data[0x34:], []byte("arm64 android compressed-pointers\x00"))

	h, err := parseHeader(data)
	if err != nil {
		t.Fatal(err)
	}
	if h.SnapshotHash != "abcdef0123456789abcdef0123456789" {
		t.Errorf("hash: %s", h.SnapshotHash)
	}
	if h.Features != "arm64 android compressed-pointers" {
		t.Errorf("features: %s", h.Features)
	}
}

func TestParseHeaderBadMagic(t *testing.T) {
	data := make([]byte, 64)
	_, err := parseHeader(data)
	if err == nil {
		t.Fatal("expected error for bad magic")
	}
}

func TestParseHeaderTooShort(t *testing.T) {
	_, err := parseHeader([]byte{0xf5, 0xf5, 0xdc, 0xdc})
	if err == nil {
		t.Fatal("expected error for short data")
	}
}

func FuzzExtract(f *testing.F) {
	f.Add([]byte("\x7fELF\x02\x01\x01\x00"))
	f.Add([]byte{})

	f.Fuzz(func(t *testing.T, data []byte) {
		tmp := filepath.Join(t.TempDir(), "fuzz.so")
		if err := os.WriteFile(tmp, data, 0644); err != nil {
			t.Fatal(err)
		}
		ef, err := elfx.Open(tmp)
		if err != nil {
			return
		}
		defer ef.Close()
		// Must not panic.
		Extract(ef, dartfmt.Options{Mode: dartfmt.ModeBestEffort})
	})
}

```

`internal/snapshot/version.go`:

```go
// Version detection for Dart AOT snapshot format variations.
package snapshot

// TagStyle identifies how cluster tags are encoded in the snapshot.
type TagStyle int

const (
	// TagStyleCidShift1 is the v2.14+ / early v3.x format:
	//   Write<uint64_t>((cid << 1) | canonical)
	// Used in Dart 2.14.0 through 3.2.5.
	TagStyleCidShift1 TagStyle = iota

	// TagStyleObjectHeader is the v3.4.3+ format:
	//   Write<uint32_t>(ClassIdTag::encode(cid) | CanonicalBit | ImmutableBit)
	// CID at bits 12-31, canonical at bit 1, immutable at bit 6.
	TagStyleObjectHeader

	// TagStyleCidInt32 is the v2.10-2.13 format:
	//   Write<int32_t>(cid)
	// Raw 32-bit CID, no canonical bit (canonical is passed separately or
	// determined by which cluster loop we're in).
	TagStyleCidInt32
)

// VersionProfile holds format parameters that differ across Dart SDK versions.
type VersionProfile struct {
	DartVersion           string   // e.g. "2.17.6", "3.10.7", "" if unknown
	Supported             bool     // true if full parsing is available (CID table + format flags)
	HeaderFields          int      // clustered snapshot header field count (5 or 6)
	Tags                  TagStyle // how cluster tags are encoded
	CIDs                  *CIDTable
	CompressedPointers    bool // true if snapshot uses compressed pointers (from features string)
	FillRefUnsigned       bool // ≤2.17: ReadRef() = ReadUnsigned(); Function has packed_fields
	PreV32Format          bool // ≤3.1: PatchClass has 3 refs; ObjectPool uses v2 type bits
	HasTypeParamClassId   bool // ≤3.0: TypeParameter has parameterized_class_id scalar
	TypeParamByteScalars  bool // ≤2.19: TypeParameter base_/index_ are Write<uint8_t> not Write<uint16_t>
	OldTypeScalars        bool // ≤2.18: Type fill has type_class_id_(unsigned)+combined(uint8) instead of flags(unsigned)
	TopLevelCid16         bool // ≤2.18: kTopLevelCidOffset = 1<<16 (vs 1<<20 in ≥2.19)
	OldPoolFormat         bool // ≤3.2: ObjectPool uses 7-bit TypeBits (no SnapshotBehavior)
	PoolTypeSwapped       bool // ≥3.2: ObjectPool kImmediate=0,kTaggedObject=1 (was swapped in 3.2.0)
	OldStringFormat       bool // ≤2.14: separate OneByteString/TwoByteString clusters with plain length (no <<1|flag)
	OldTypeArgsFill       bool // 2.15: TypeArguments fill = inst+N*type+hash (no length/nullability in stream)
	OldArrayFill          bool // 2.15: Array fill = type_args+N*ref (no length in stream, N from alloc)
	SplitCanonical        bool // 2.12-2.13: header has separate num_canonical_clusters + num_clusters
	PreCanonicalSplit     bool // ≤2.10: no canonical/non-canonical distinction at all (single cluster loop, no canonical bit)
	ClassNumRefs          int  // Class pointer field count override. 0 = default (13). v2.10=16, v2.13=15.
	ClassHasTokenPos      bool // Class fill includes ReadTokenPosition(token_pos) + ReadTokenPosition(end_token_pos)
	FuncNumRefs           int  // Function pointer field count override. 0 = default (4). v2.10=7, v2.13=5.
	TypeNumRefs           int  // Type fill ref count override. 0 = default (3). v2.13=4.
	TypeClassIdIsRef      bool // Type: type_class_id is a pointer in ReadFromTo, not scalar. v2.13-v2.15.
	FuncTypeNumRefs       int  // FunctionType fill ref count override. 0 = default (6). v2.13=6 (different scalars).
	FuncTypeOldScalars    bool // FunctionType v2.13: 2 scalars (uint8+uint32) not 3.
	TypeParamNumRefs      int  // TypeParameter fill ref count override. 0 = default (3). v2.13=5, v2.14/v2.15=2.
	TypeParamWideScalars  bool // TypeParameter v2.13: base/index use Read<uint16_t> not Read<uint8_t>.
	TypeRefNumRefs        int  // TypeRef fill ref count override. 0 = default (2). v2.14/v2.15=1.
	CodeNumRefs           int  // Code fill ref count override. 0 = default (6). v2.10-v2.15=7 (includes compressed_stackmaps).
	CodeTextOffsetDelta   bool // Code ReadInstructions reads extra ReadUnsigned (text_offset_delta). v2.10-v2.15.
	CodeStateBitsAfterRef int  // Code state_bits_ position in fill: 0=not in fill (v2.14+), N=read after first N refs. v2.13=1 (1 ref → state_bits → 6 refs).
	CodeStateBitsAtEnd    bool // Code state_bits_ Read<int32_t> after ALL refs (no discarded check). v2.10.
	ClosureDataNumRefs    int  // ClosureData ref count override. 0 = default (2). v2.13=3 (includes default_type_arguments).
	TypeHasTokenPos       bool // Type/TypeParameter fill has ReadTokenPosition scalar. v2.10 only.
	ScriptHasLineCol      bool // Script fill has line_offset + col_offset scalars before kernel_script_index. v2.10, v2.13.
	ScriptHasFlags        bool // Script fill has flags (uint8) scalar between col_offset and kernel_script_index. v2.10 only.
}

// CIDTable maps predefined type names to class IDs for a specific Dart version.
// Only types with non-trivial alloc behavior need entries.
type CIDTable struct {
	String                     int
	OneByteString              int
	TwoByteString              int
	Mint                       int
	Double                     int
	Float32x4                  int
	Int32x4                    int
	Float64x2                  int
	Array                      int
	ImmutableArray             int
	WeakArray                  int
	TypeArguments              int
	Type                       int
	FunctionType               int
	RecordType                 int // 0 if not present (v2.17.6)
	TypeParameter              int
	Class                      int
	Function                   int
	ClosureData                int
	SignatureData              int // 0 if not present (v2.10 only, removed in v2.13)
	Field                      int
	Script                     int
	Library                    int
	Namespace                  int
	KernelProgramInfo          int
	Code                       int
	ObjectPool                 int
	PcDescriptors              int
	CodeSourceMap              int
	CompressedStackMaps        int
	ExceptionHandlers          int
	Context                    int
	ContextScope               int
	UnlinkedCall               int
	ICData                     int
	MegamorphicCache           int
	SubtypeTestCache           int
	LoadingUnit                int
	Closure                    int
	GrowableObjectArray        int
	Map                        int
	ConstMap                   int
	Set                        int
	ConstSet                   int
	WeakProperty               int
	WeakReference              int
	RegExp                     int
	Record                     int // 0 if not present (v2.17.6)
	TypedData                  int
	TypedDataView              int
	ExternalTypedData          int
	Instance                   int
	Sentinel                   int
	SingleTargetCache          int
	MonomorphicSmiableCall     int
	CallSiteData               int
	WeakSerializationReference int
	LanguageError              int
	UnhandledException         int
	PatchClass                 int
	FfiTrampolineData          int
	TypeParameters             int
	LibraryPrefix              int
	SendPort                   int
	StackTrace                 int
	SuspendState               int // 0 if not present (v2.17.6)
	TypeRef                    int // 0 if not present (removed in v3.x)
	Capability                 int
	ReceivePort                int
	FutureOr                   int
	TransferableTypedData      int
	UserTag                    int

	// TypedData internal CID range. CIDs from TypedDataInt8ArrayCid to
	// ByteDataViewCid-1 are internal typed data classes (stride = TypedDataCidStride).
	// IsTypedDataClassId(cid) = cid >= TypedDataInt8ArrayCid &&
	//   cid < ByteDataViewCid && (cid - TypedDataInt8ArrayCid) % TypedDataCidStride == 0
	TypedDataInt8ArrayCid int // first internal TypedData CID
	ByteDataViewCid       int // end marker (exclusive)
	TypedDataCidStride    int // 3 for v2.17.6, 4 for v3.x

	// DeltaEncodedTypedData pseudo-CID (kNativePointer = 1 in all versions).
	NativePointerCid int

	// NumPredefinedCids is the count of VM-internal class IDs. CIDs >= this
	// value are app-defined Instance subclasses. CIDs < this that aren't
	// explicitly handled should default to AllocSimple, NOT AllocInstance.
	NumPredefinedCids int
}

// Known snapshot hashes mapped to Dart SDK versions.
// Sources: blutter precompiled SDKs + reFlutter enginehash.csv.
var knownHashes = map[string]string{
	// Dart 2.17.x (Flutter 2.17.0 stable + betas)
	"1441d6b13b8623fa7fbf61433abebd31": "2.17.6", // Flutter 2.17.0.stable
	"a0cb0c928b23bc17a26e062b351dc44d": "2.17.6", // Flutter 2.17.0-182.2.beta
	"ded6ef11c73fdc638d6ff6d3ad22a67b": "2.17.6", // Flutter 2.17.0-69.2.beta
	// Dart 3.0.x (Flutter 3.10.x)
	"90b56a561f70cd55e972cb49b79b3d8b": "3.0.5", // Flutter 3.10.4
	"aa64af18e7d086041ac127cc4bc50c5e": "3.0.5", // Flutter 3.10.0 (approximate)
	// Dart 3.1.x (Flutter 3.13.x)
	"7dbbeeb8ef7b91338640dca3927636de": "3.1.0", // Flutter 3.13.9
	// Dart 3.2.x (Flutter 3.16.x)
	"f71c76320d35b65f1164dbaa6d95fe09": "3.2.5", // Flutter 3.16.0
	// Dart 3.3.x (Flutter 3.19.x)
	"ee1eb666c76a5cb7746faf39d0b97547": "3.3.0", // Flutter 3.19.0
	// Dart 3.4.x (Flutter 3.22.x)
	"d20a1be77c3d3c41b2a5accaee1ce549": "3.4.3", // Flutter 3.22.0
	// Dart 3.5.x (Flutter 3.24.x)
	"80a49c7111088100a233b2ae788e1f48": "3.5.0", // Flutter 3.24.0
	"cda356e9bae476c70de33809fd92e009": "3.5.0", // Dart 3.5.1 (from blutter SDK v3.5.1/runtime/vm/version.cc)
	"2858c2c0920495f00b9bce9edf6a8cd9": "3.6.2", // CIDs match v3.6.2 (Mint=61, String=93), likely Dart 3.6.0-dev or 3.5.x+1
	// Dart 3.6.x (Flutter 3.27.x)
	"f956f595844a2f845a55707faaaa51e4": "3.6.2", // Flutter 3.27.1
	// Dart 3.7.x (Flutter 3.29.x)
	"d91c0e6f35f0eb2e44124e8f42aa44a7": "3.7.0", // Flutter 3.29.3
	// Dart 3.8.x (Flutter 3.32.x)
	"830f4f59e7969c70b595182826435c19": "3.8.1", // Flutter 3.32.0
	// Dart 3.9.x (Flutter 3.35.x)
	"97ff04a728735e6b6b098bdf983faaba": "3.9.2", // Flutter 3.35.1
	// Dart 3.10.x (Flutter 3.38.x)
	"1ce86630892e2dca9a8543fdb8ed8e22": "3.10.7", // Flutter 3.38.4

	// Dart 2.14-2.19 (supported with CID tables)
	"9cf77f4405212c45daf608e1cd646852": "2.14.0", // Flutter 2.5.0
	"659a72e41e3276e882709901c27de33d": "2.14.0", // Flutter 2.4.0
	"f10776149bf76be288def3c2ca73bdc1": "2.15.0", // Flutter 2.6.0-5.2.pre (NativePointer inserted, CIDs shifted +1 from v2.14)
	"24d9d411c2f90c8fbe8907f99e89d4b0": "2.15.0", // Flutter 2.7.0-3.0.pre
	"d56742caf7b3b3f4bd2df93a9bbb5503": "2.16.0", // Flutter 2.16.0-134.1.beta
	"3318fe66091c0ffbb64faec39976cb7d": "2.16.0", // Flutter 2.16.0-80.1.beta
	"adf563436d12ba0d50ea5beb7f3be1bb": "2.16.0", // Flutter 2.8.0-3.1.pre
	"b0e899ec5a90e4661501f0b69e9dd70f": "2.18.0", // Flutter 3.3.0-0.1.pre
	"b6d0a1f034d158b0d37b51d559379697": "2.18.0", // Flutter 3.3.10
	"8e50e448b241be23b9e990094f4dca39": "2.18.0", // Flutter 2.18.0.165
	"6a9b5a03a7e784a4558b10c769f188d9": "2.18.0", // Flutter 2.18.0.44
	"adb4292f3ec25074ca70abcd2d5c7251": "2.19.0", // Flutter 3.7.12
	"501ef5cbd64ca70b6b42672346af6a8a": "2.19.0", // Flutter 3.7.0

	// Dart 3.0-3.1 additional hashes
	"36b0375d284ee2af0d0fffc6e6e48fde": "3.0.5", // Flutter 3.11.0-0.1.pre
	"16ad76edd19b537bf6ea64fdd31977a7": "3.0.5", // Flutter 3.12.0

	// Dart 2.10-2.13 (supported with CID tables, int32 tag format)
	"8ee4ef7a67df9845fba331734198a953": "2.10.0", // Flutter 1.22.6
	"e4a09dbf2bb120fe4674e0576617a0dc": "2.13.0", // Flutter 2.2.0
	"34f6eec64e9371856eaaa278ccf56538": "2.13.0", // Flutter 2.2.0-10.1.pre
	"7a5b240780941844bae88eca5dbaa7b8": "2.13.0", // Flutter 2.3.0
}

// CID tables generated from dartsdk/v*/runtime/vm/class_id.h.
// Only versions with different CID numbering need separate tables.

// v2.10.0 CIDs: pre-FunctionType split, has Bytecode/SignatureData/RedirectionData/ParameterTypeCheck/WASM.
// No TypeParameters, no Sentinel, no InstructionsTable, no FunctionType, no WeakReference,
// no SuspendState, no Record, no RecordType, no LinkedHashSet, no NativePointer. TypedData stride 3.
// Tag format: raw int32 CID. Single cluster loop (no canonical split).
var cidsV210 = CIDTable{
	Class: 4, PatchClass: 5, Function: 6,
	ClosureData: 7, SignatureData: 8, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 77,
	// No TypeParameters in v2.10
	Code: 16, ObjectPool: 20, PcDescriptors: 21, CodeSourceMap: 22,
	CompressedStackMaps: 23, ExceptionHandlers: 25, Context: 26,
	ContextScope: 27, SingleTargetCache: 29, UnlinkedCall: 30,
	MonomorphicSmiableCall: 31, CallSiteData: 32,
	ICData: 33, MegamorphicCache: 34, SubtypeTestCache: 35,
	LoadingUnit: 36, LanguageError: 39, UnhandledException: 40,
	Instance: 42, LibraryPrefix: 43, TypeArguments: 44,
	Type: 46, TypeRef: 47, TypeParameter: 48,
	// No FunctionType in v2.10 (FunctionType was added in 2.13)
	Closure: 49, Mint: 53, Double: 54,
	GrowableObjectArray: 56,
	Float32x4:           57, Int32x4: 58, Float64x2: 59,
	TypedData: 61, ExternalTypedData: 62, TypedDataView: 63,
	Capability: 66, ReceivePort: 67, SendPort: 68,
	StackTrace: 69, RegExp: 70, WeakProperty: 71,
	FutureOr: 74, UserTag: 75, TransferableTypedData: 76,
	// v2.10 has LinkedHashMap only (no Set, no Immutable variants)
	Map:   73,
	Array: 78, ImmutableArray: 79,
	String: 80, OneByteString: 81, TwoByteString: 82,
	// TypedData internals: stride 3 (no UnmodifiableView)
	TypedDataInt8ArrayCid: 108, ByteDataViewCid: 150, TypedDataCidStride: 3,
	NumPredefinedCids: 156,
}

// v2.13.0 CIDs: adds FunctionType, removes SignatureData/RedirectionData/Bytecode/ParameterTypeCheck/WASM.
// No TypeParameters, no Sentinel, no WeakReference, no SuspendState, no Record, no RecordType.
// No LinkedHashSet. No NativePointer. TypedData stride 3.
// Tag format: raw int32 CID. Split canonical/non-canonical cluster loops.
var cidsV213 = CIDTable{
	Class: 4, PatchClass: 5, Function: 6,
	ClosureData: 7, FfiTrampolineData: 8, Field: 9, Script: 10,
	Library: 11, Namespace: 12, KernelProgramInfo: 13,
	WeakSerializationReference: 14,
	// No TypeParameters in v2.13
	Code: 15, ObjectPool: 18, PcDescriptors: 19, CodeSourceMap: 20,
	CompressedStackMaps: 21, ExceptionHandlers: 23, Context: 24,
	ContextScope: 25, SingleTargetCache: 26, UnlinkedCall: 27,
	MonomorphicSmiableCall: 28, CallSiteData: 29,
	ICData: 30, MegamorphicCache: 31, SubtypeTestCache: 32,
	LoadingUnit: 33, LanguageError: 36, UnhandledException: 37,
	Instance: 39, LibraryPrefix: 40, TypeArguments: 41,
	Type: 43, FunctionType: 44, TypeRef: 45, TypeParameter: 46,
	Closure: 47, Mint: 51, Double: 52,
	GrowableObjectArray: 54,
	Float32x4:           55, Int32x4: 56, Float64x2: 57,
	TypedData: 59, ExternalTypedData: 60, TypedDataView: 61,
	Capability: 64, ReceivePort: 65, SendPort: 66,
	StackTrace: 67, RegExp: 68, WeakProperty: 69,
	FutureOr: 72, UserTag: 73, TransferableTypedData: 74,
	// v2.13 has LinkedHashMap only (no Set, no Immutable variants)
	Map:   71,
	Array: 75, ImmutableArray: 76,
	String: 77, OneByteString: 78, TwoByteString: 79,
	// TypedData internals: stride 3 (no UnmodifiableView)
	TypedDataInt8ArrayCid: 100, ByteDataViewCid: 142, TypedDataCidStride: 3,
	NumPredefinedCids: 148,
}

// v2.14.0 CIDs: adds TypeParameters, InstructionsTable, Sentinel, LinkedHashSet
// vs 2.13.0. No WeakArray, WeakReference, SuspendState, Record, RecordType.
// No ImmutableLinkedHashMap/Set (ConstMap/ConstSet). No NativePointer. TypedData stride 3.
var cidsV214 = CIDTable{
	Class: 4, PatchClass: 5, Function: 6, TypeParameters: 7,
	ClosureData: 8, FfiTrampolineData: 9, Field: 10, Script: 11,
	Library: 12, Namespace: 13, KernelProgramInfo: 14,
	WeakSerializationReference: 15,
	// No WeakArray in v2.14
	Code: 16, ObjectPool: 20, PcDescriptors: 21, CodeSourceMap: 22,
	CompressedStackMaps: 23, ExceptionHandlers: 25, Context: 26,
	ContextScope: 27, Sentinel: 28, SingleTargetCache: 29,
	UnlinkedCall: 30, MonomorphicSmiableCall: 31, CallSiteData: 32,
	ICData: 33, MegamorphicCache: 34, SubtypeTestCache: 35,
	LoadingUnit: 36, LanguageError: 39, UnhandledException: 40,
	Instance: 42, LibraryPrefix: 43, TypeArguments: 44,
	Type: 46, FunctionType: 47, TypeRef: 48, TypeParameter: 49,
	Closure: 50, Mint: 54, Double: 55,
	Float32x4: 58, Int32x4: 59, Float64x2: 60,
	TypedData: 62, ExternalTypedData: 63, TypedDataView: 64,
	Capability: 67, ReceivePort: 68, SendPort: 69,
	StackTrace: 70, RegExp: 71, WeakProperty: 72,
	FutureOr: 74, UserTag: 75, TransferableTypedData: 76,
	// v2.14 has LinkedHashMap/Set but no Immutable variants
	Map: 77, Set: 78,
	Array: 79, ImmutableArray: 80, GrowableObjectArray: 57,
	String: 81, OneByteString: 82, TwoByteString: 83,
	// TypedData internals: stride 3 (no UnmodifiableView)
	TypedDataInt8ArrayCid: 104, ByteDataViewCid: 146, TypedDataCidStride: 3,
	NumPredefinedCids: 152,
}

// v2.15.0 CIDs: NativePointer(1) inserted at CID 1, and GrowableObjectArray
// moved from CLASS_LIST_INSTANCE_SINGLETONS to CLASS_LIST_ARRAYS (after ImmutableArray).
// Net effect: Class..Bool get +1 shift (NativePointer), Float32x4..TransferableTypedData
// get +0 (NativePointer +1, GOA removal -1), Map/Set/Array/ImmutableArray get +0,
// GOA moves from CID 57 to CID 81, String and beyond get +1.
// No ImmutableLinkedHashMap/Set (those were added in v2.16).
// Hash f10776149bf76be288def3c2ca73bdc1 (Flutter 2.6.0-5.2.pre) uses this layout.
var cidsV215 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16,
	// No WeakArray in v2.15
	Code: 17, ObjectPool: 21, PcDescriptors: 22, CodeSourceMap: 23,
	CompressedStackMaps: 24, ExceptionHandlers: 26, Context: 27,
	ContextScope: 28, Sentinel: 29, SingleTargetCache: 30,
	UnlinkedCall: 31, MonomorphicSmiableCall: 32, CallSiteData: 33,
	ICData: 34, MegamorphicCache: 35, SubtypeTestCache: 36,
	LoadingUnit: 37, LanguageError: 40, UnhandledException: 41,
	Instance: 43, LibraryPrefix: 44, TypeArguments: 45,
	Type: 47, FunctionType: 48, TypeRef: 49, TypeParameter: 50,
	Closure: 51, Mint: 55, Double: 56,
	// v2.15 pre-release: NativePointer(CID 1) inserts +1 for Class..Bool,
	// but GrowableObjectArray moved from INSTANCE_SINGLETONS to ARRAYS group
	// (after ImmutableArray), so classes from Float32x4..TransferableTypedData
	// get net +0 shift (+1 NativePointer, -1 GOA removal).
	// Map/Set/Array/ImmutableArray also net +0. GOA moves to CID 81.
	// String and beyond get +1 (NativePointer +1, GOA removal -1, GOA insertion +1).
	Float32x4: 58, Int32x4: 59, Float64x2: 60,
	TypedData: 62, ExternalTypedData: 63, TypedDataView: 64,
	Capability: 67, ReceivePort: 68, SendPort: 69,
	StackTrace: 70, RegExp: 71, WeakProperty: 72,
	FutureOr: 74, UserTag: 75, TransferableTypedData: 76,
	// v2.15 pre-release: LinkedHashMap/Set only (no Immutable variants)
	Map: 77, Set: 78,
	Array: 79, ImmutableArray: 80, GrowableObjectArray: 81,
	String: 82, OneByteString: 83, TwoByteString: 84,
	// TypedData internals: stride 3 (no UnmodifiableView)
	TypedDataInt8ArrayCid: 105, ByteDataViewCid: 147, TypedDataCidStride: 3,
	NativePointerCid: 1, NumPredefinedCids: 153,
}

// v2.16.0 CIDs: adds NativePointer(1), ImmutableLinkedHashMap/Set (ConstMap/ConstSet),
// FfiBool, GrowableObjectArray moved to arrays group. TypedData stride 3.
var cidsV216 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16,
	// No WeakArray in v2.16
	Code: 17, ObjectPool: 21, PcDescriptors: 22, CodeSourceMap: 23,
	CompressedStackMaps: 24, ExceptionHandlers: 26, Context: 27,
	ContextScope: 28, Sentinel: 29, SingleTargetCache: 30,
	UnlinkedCall: 31, MonomorphicSmiableCall: 32, CallSiteData: 33,
	ICData: 34, MegamorphicCache: 35, SubtypeTestCache: 36,
	LoadingUnit: 37, LanguageError: 40, UnhandledException: 41,
	Instance: 43, LibraryPrefix: 44, TypeArguments: 45,
	Type: 47, FunctionType: 48, TypeRef: 49, TypeParameter: 50,
	Closure: 51, Mint: 55, Double: 56,
	Float32x4: 58, Int32x4: 59, Float64x2: 60,
	TypedData: 62, ExternalTypedData: 63, TypedDataView: 64,
	Capability: 67, ReceivePort: 68, SendPort: 69,
	StackTrace: 70, RegExp: 71, WeakProperty: 72,
	FutureOr: 74, UserTag: 75, TransferableTypedData: 76,
	// v2.16 has LinkedHashMap + ImmutableLinkedHashMap, LinkedHashSet + ImmutableLinkedHashSet
	Map: 77, ConstMap: 78, Set: 79, ConstSet: 80,
	Array: 81, ImmutableArray: 82, GrowableObjectArray: 83,
	String: 84, OneByteString: 85, TwoByteString: 86,
	// TypedData internals: stride 3 (no UnmodifiableView)
	TypedDataInt8ArrayCid: 106, ByteDataViewCid: 148, TypedDataCidStride: 3,
	NativePointerCid: 1, NumPredefinedCids: 154,
}

var cidsV217 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16,
	// WeakArray not present in v2.17.6 CLASS_LIST_INTERNAL_ONLY
	Code: 17, ObjectPool: 21, PcDescriptors: 22, CodeSourceMap: 23,
	CompressedStackMaps: 24, ExceptionHandlers: 26, Context: 27,
	ContextScope: 28, Sentinel: 29, SingleTargetCache: 30,
	UnlinkedCall: 31, MonomorphicSmiableCall: 32, CallSiteData: 33,
	ICData: 34, MegamorphicCache: 35, SubtypeTestCache: 36,
	LoadingUnit: 37, LanguageError: 40, UnhandledException: 41,
	Instance: 43, LibraryPrefix: 44, TypeArguments: 45,
	Type: 47, FunctionType: 52, TypeParameter: 54,
	TypeRef: 53,
	Closure: 55, Mint: 59, Double: 60,
	Float32x4: 62, Int32x4: 63, Float64x2: 64,
	TypedData: 66, ExternalTypedData: 67, TypedDataView: 68,
	Capability: 71, ReceivePort: 72, SendPort: 73,
	StackTrace: 74, RegExp: 75, WeakProperty: 76, WeakReference: 77,
	FutureOr: 79, UserTag: 80, TransferableTypedData: 81,
	// v2.17.6 uses LinkedHashMap/LinkedHashSet instead of Map/Set
	Map: 82, ConstMap: 83, Set: 84, ConstSet: 85,
	Array: 86, ImmutableArray: 87, GrowableObjectArray: 88,
	String: 89, OneByteString: 90, TwoByteString: 91,
	// TypedData internals: stride 3 (no UnmodifiableView in v2.17.6)
	TypedDataInt8ArrayCid: 110, ByteDataViewCid: 152, TypedDataCidStride: 3,
	NativePointerCid: 1, NumPredefinedCids: 158,
}

// v2.18.0 CIDs: identical to v2.17.6 except SuspendState added after StackTrace,
// shifting RegExp and all subsequent CIDs by +1. No WeakArray. TypedData stride 3.
var cidsV218 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16,
	// No WeakArray in v2.18
	Code: 17, ObjectPool: 21, PcDescriptors: 22, CodeSourceMap: 23,
	CompressedStackMaps: 24, ExceptionHandlers: 26, Context: 27,
	ContextScope: 28, Sentinel: 29, SingleTargetCache: 30,
	UnlinkedCall: 31, MonomorphicSmiableCall: 32, CallSiteData: 33,
	ICData: 34, MegamorphicCache: 35, SubtypeTestCache: 36,
	LoadingUnit: 37, LanguageError: 40, UnhandledException: 41,
	Instance: 43, LibraryPrefix: 44, TypeArguments: 45,
	Type: 47, FunctionType: 52, TypeParameter: 54,
	TypeRef: 53,
	Closure: 55, Mint: 59, Double: 60,
	Float32x4: 62, Int32x4: 63, Float64x2: 64,
	TypedData: 66, ExternalTypedData: 67, TypedDataView: 68,
	Capability: 71, ReceivePort: 72, SendPort: 73,
	StackTrace: 74, SuspendState: 75, RegExp: 76,
	WeakProperty: 77, WeakReference: 78,
	FutureOr: 80, UserTag: 81, TransferableTypedData: 82,
	// v2.18 uses LinkedHashMap/LinkedHashSet
	Map: 83, ConstMap: 84, Set: 85, ConstSet: 86,
	Array: 87, ImmutableArray: 88, GrowableObjectArray: 89,
	String: 90, OneByteString: 91, TwoByteString: 92,
	// TypedData internals: stride 3 (no UnmodifiableView in v2.18)
	TypedDataInt8ArrayCid: 111, ByteDataViewCid: 153, TypedDataCidStride: 3,
	NativePointerCid: 1, NumPredefinedCids: 159,
}

// v2.19.0 CIDs: structurally identical to v3.0.5 but without WeakArray,
// so all CIDs from Code onward are offset by -1 compared to cidsV305.
// Adds RecordType, Record. TypedData stride 4 (with UnmodifiableView).
var cidsV219 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16,
	// No WeakArray in v2.19
	Code: 17, ObjectPool: 21, PcDescriptors: 22, CodeSourceMap: 23,
	CompressedStackMaps: 24, ExceptionHandlers: 26, Context: 27,
	ContextScope: 28, Sentinel: 29, SingleTargetCache: 30,
	UnlinkedCall: 31, MonomorphicSmiableCall: 32, CallSiteData: 33,
	ICData: 34, MegamorphicCache: 35, SubtypeTestCache: 36,
	LoadingUnit: 37, LanguageError: 40, UnhandledException: 41,
	Instance: 43, LibraryPrefix: 44, TypeArguments: 45,
	Type: 47, FunctionType: 48, RecordType: 49, TypeRef: 50, TypeParameter: 51,
	Closure: 56, Mint: 60, Double: 61,
	Float32x4: 63, Int32x4: 64, Float64x2: 65, Record: 66,
	TypedData: 68, ExternalTypedData: 69, TypedDataView: 70,
	Capability: 73, ReceivePort: 74, SendPort: 75,
	StackTrace: 76, SuspendState: 77, RegExp: 78,
	WeakProperty: 79, WeakReference: 80,
	FutureOr: 82, UserTag: 83, TransferableTypedData: 84,
	Map: 85, ConstMap: 86, Set: 87, ConstSet: 88,
	Array: 89, ImmutableArray: 90, GrowableObjectArray: 91,
	String: 92, OneByteString: 93, TwoByteString: 94,
	TypedDataInt8ArrayCid: 113, ByteDataViewCid: 169, TypedDataCidStride: 4,
	NativePointerCid: 1, NumPredefinedCids: 176,
}

// v3.0.5 CIDs: same layout as v3.2.5 except TypeRef still present (between
// RecordType and TypeParameter). This shifts TypeParameter and all subsequent
// CIDs by +1 compared to v3.1.0+.
var cidsV305 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16, WeakArray: 17,
	Code: 18, ObjectPool: 22, PcDescriptors: 23, CodeSourceMap: 24,
	CompressedStackMaps: 25, ExceptionHandlers: 27, Context: 28,
	ContextScope: 29, Sentinel: 30, SingleTargetCache: 31,
	UnlinkedCall: 32, MonomorphicSmiableCall: 33, CallSiteData: 34,
	ICData: 35, MegamorphicCache: 36, SubtypeTestCache: 37,
	LoadingUnit: 38, LanguageError: 41, UnhandledException: 42,
	Instance: 44, LibraryPrefix: 45, TypeArguments: 46,
	Type: 48, FunctionType: 49, RecordType: 50, TypeRef: 51, TypeParameter: 52,
	Closure: 57, Mint: 61, Double: 62,
	Float32x4: 64, Int32x4: 65, Float64x2: 66, Record: 67,
	TypedData: 69, ExternalTypedData: 70, TypedDataView: 71,
	Capability: 74, ReceivePort: 75, SendPort: 76,
	StackTrace: 77, SuspendState: 78, RegExp: 79,
	WeakProperty: 80, WeakReference: 81,
	FutureOr: 83, UserTag: 84, TransferableTypedData: 85,
	Map: 86, ConstMap: 87, Set: 88, ConstSet: 89,
	Array: 90, ImmutableArray: 91, GrowableObjectArray: 92,
	String: 93, OneByteString: 94, TwoByteString: 95,
	TypedDataInt8ArrayCid: 114, ByteDataViewCid: 170, TypedDataCidStride: 4,
	NativePointerCid: 1, NumPredefinedCids: 177,
}

var cidsV325 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16, WeakArray: 17,
	Code: 18, ObjectPool: 22, PcDescriptors: 23, CodeSourceMap: 24,
	CompressedStackMaps: 25, ExceptionHandlers: 27, Context: 28,
	ContextScope: 29, Sentinel: 30, SingleTargetCache: 31,
	UnlinkedCall: 32, MonomorphicSmiableCall: 33, CallSiteData: 34,
	ICData: 35, MegamorphicCache: 36, SubtypeTestCache: 37,
	LoadingUnit: 38, LanguageError: 41, UnhandledException: 42,
	Instance: 44, LibraryPrefix: 45, TypeArguments: 46,
	Type: 48, FunctionType: 49, RecordType: 50, TypeParameter: 51,
	Closure: 56, Mint: 60, Double: 61,
	Float32x4: 63, Int32x4: 64, Float64x2: 65, Record: 66,
	TypedData: 68, ExternalTypedData: 69, TypedDataView: 70,
	Capability: 73, ReceivePort: 74, SendPort: 75,
	StackTrace: 76, SuspendState: 77, RegExp: 78,
	WeakProperty: 79, WeakReference: 80,
	FutureOr: 82, UserTag: 83, TransferableTypedData: 84,
	Map: 85, ConstMap: 86, Set: 87, ConstSet: 88,
	Array: 89, ImmutableArray: 90, GrowableObjectArray: 91,
	String: 92, OneByteString: 93, TwoByteString: 94,
	TypedDataInt8ArrayCid: 113, ByteDataViewCid: 169, TypedDataCidStride: 4,
	NativePointerCid: 1, NumPredefinedCids: 176,
}

// v3.4.3 CIDs: same as v3.2.5 except Bytecode removed (no Bytecode CID 19),
// all CIDs after Code shift by -1 compared to v3.9.2 (which has Bytecode at 19).
var cidsV343 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16, WeakArray: 17,
	Code: 18, ObjectPool: 22, PcDescriptors: 23, CodeSourceMap: 24,
	CompressedStackMaps: 25, ExceptionHandlers: 27, Context: 28,
	ContextScope: 29, Sentinel: 30, SingleTargetCache: 31,
	UnlinkedCall: 32, MonomorphicSmiableCall: 33, CallSiteData: 34,
	ICData: 35, MegamorphicCache: 36, SubtypeTestCache: 37,
	LoadingUnit: 38, LanguageError: 41, UnhandledException: 42,
	Instance: 44, LibraryPrefix: 45, TypeArguments: 46,
	Type: 48, FunctionType: 49, RecordType: 50, TypeParameter: 51,
	Closure: 56, Mint: 60, Double: 61,
	Float32x4: 63, Int32x4: 64, Float64x2: 65, Record: 66,
	TypedData: 68, ExternalTypedData: 69, TypedDataView: 70,
	Capability: 73, ReceivePort: 74, SendPort: 75,
	StackTrace: 76, SuspendState: 77, RegExp: 78,
	WeakProperty: 79, WeakReference: 80,
	FutureOr: 82, UserTag: 83, TransferableTypedData: 84,
	Map: 85, ConstMap: 86, Set: 87, ConstSet: 88,
	Array: 89, ImmutableArray: 90, GrowableObjectArray: 91,
	String: 92, OneByteString: 93, TwoByteString: 94,
	TypedDataInt8ArrayCid: 111, ByteDataViewCid: 167, TypedDataCidStride: 4,
	NativePointerCid: 1, NumPredefinedCids: 174,
}

// v3.6.2 through v3.8.1: nearly identical to v3.9.2 except for
// UnlinkedCall/MonomorphicSmiableCall/CallSiteData ordering.
var cidsV362 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16, WeakArray: 17,
	Code: 18, ObjectPool: 23, PcDescriptors: 24, CodeSourceMap: 25,
	CompressedStackMaps: 26, ExceptionHandlers: 28, Context: 29,
	ContextScope: 30, Sentinel: 31, SingleTargetCache: 32,
	UnlinkedCall: 33, MonomorphicSmiableCall: 34, CallSiteData: 35,
	ICData: 36, MegamorphicCache: 37, SubtypeTestCache: 38,
	LoadingUnit: 39, LanguageError: 42, UnhandledException: 43,
	Instance: 45, LibraryPrefix: 46, TypeArguments: 47,
	Type: 49, FunctionType: 50, RecordType: 51, TypeParameter: 52,
	Closure: 57, Mint: 61, Double: 62,
	Float32x4: 64, Int32x4: 65, Float64x2: 66, Record: 67,
	TypedData: 69, ExternalTypedData: 70, TypedDataView: 71,
	Capability: 74, ReceivePort: 75, SendPort: 76,
	StackTrace: 77, SuspendState: 78, RegExp: 79,
	WeakProperty: 80, WeakReference: 81,
	FutureOr: 83, UserTag: 84, TransferableTypedData: 85,
	Map: 86, ConstMap: 87, Set: 88, ConstSet: 89,
	Array: 90, ImmutableArray: 91, GrowableObjectArray: 92,
	String: 93, OneByteString: 94, TwoByteString: 95,
	TypedDataInt8ArrayCid: 112, ByteDataViewCid: 168, TypedDataCidStride: 4,
	NativePointerCid: 1, NumPredefinedCids: 175,
}

// v3.9.2 and v3.10.7: the CID table currently hardcoded in cid.go.
var cidsV392 = CIDTable{
	Class: 5, PatchClass: 6, Function: 7, TypeParameters: 8,
	ClosureData: 9, FfiTrampolineData: 10, Field: 11, Script: 12,
	Library: 13, Namespace: 14, KernelProgramInfo: 15,
	WeakSerializationReference: 16, WeakArray: 17,
	Code: 18, ObjectPool: 23, PcDescriptors: 24, CodeSourceMap: 25,
	CompressedStackMaps: 26, ExceptionHandlers: 28, Context: 29,
	ContextScope: 30, Sentinel: 31, SingleTargetCache: 32,
	UnlinkedCall: 35, MonomorphicSmiableCall: 33, CallSiteData: 34,
	ICData: 36, MegamorphicCache: 37, SubtypeTestCache: 38,
	LoadingUnit: 39, LanguageError: 42, UnhandledException: 43,
	Instance: 45, LibraryPrefix: 46, TypeArguments: 47,
	Type: 49, FunctionType: 50, RecordType: 51, TypeParameter: 52,
	Closure: 57, Mint: 61, Double: 62,
	Float32x4: 64, Int32x4: 65, Float64x2: 66, Record: 67,
	TypedData: 69, ExternalTypedData: 70, TypedDataView: 71,
	Capability: 74, ReceivePort: 75, SendPort: 76,
	StackTrace: 77, SuspendState: 78, RegExp: 79,
	WeakProperty: 80, WeakReference: 81,
	FutureOr: 83, UserTag: 84, TransferableTypedData: 85,
	Map: 86, ConstMap: 87, Set: 88, ConstSet: 89,
	Array: 90, ImmutableArray: 91, GrowableObjectArray: 92,
	String: 93, OneByteString: 94, TwoByteString: 95,
	TypedDataInt8ArrayCid: 112, ByteDataViewCid: 168, TypedDataCidStride: 4,
	NativePointerCid: 1, NumPredefinedCids: 175,
}

var versionProfiles = map[string]*VersionProfile{
	"2.10.0": {DartVersion: "2.10.0", Supported: true, HeaderFields: 4, Tags: TagStyleCidInt32, CIDs: &cidsV210, FillRefUnsigned: true, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true, OldStringFormat: true, PreCanonicalSplit: true, ClassNumRefs: 16, ClassHasTokenPos: true, FuncNumRefs: 7, TypeNumRefs: 5, TypeClassIdIsRef: true, TypeHasTokenPos: true, TypeParamNumRefs: 5, CodeNumRefs: 7, CodeTextOffsetDelta: true, CodeStateBitsAtEnd: true, ScriptHasLineCol: true, ScriptHasFlags: true},
	"2.13.0": {DartVersion: "2.13.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidInt32, CIDs: &cidsV213, FillRefUnsigned: true, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true, OldStringFormat: true, SplitCanonical: true, ClassNumRefs: 15, ClassHasTokenPos: true, FuncNumRefs: 5, TypeNumRefs: 4, TypeClassIdIsRef: true, FuncTypeOldScalars: true, TypeParamNumRefs: 5, TypeParamWideScalars: true, CodeNumRefs: 7, CodeTextOffsetDelta: true, CodeStateBitsAfterRef: 1, ClosureDataNumRefs: 3, ScriptHasLineCol: true},
	"2.14.0": {DartVersion: "2.14.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV214, FillRefUnsigned: true, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true, OldStringFormat: true, TypeClassIdIsRef: true, TypeNumRefs: 4, CodeNumRefs: 7, CodeTextOffsetDelta: true, FuncTypeNumRefs: 6, TypeParamNumRefs: 3, TypeRefNumRefs: 2},
	"2.15.0": {DartVersion: "2.15.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV215, FillRefUnsigned: true, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true, OldStringFormat: true, TypeClassIdIsRef: true, TypeNumRefs: 4, CodeNumRefs: 7, CodeTextOffsetDelta: true, FuncTypeNumRefs: 6, TypeParamNumRefs: 3, TypeRefNumRefs: 2},
	"2.16.0": {DartVersion: "2.16.0", Supported: true, HeaderFields: 6, Tags: TagStyleCidShift1, CIDs: &cidsV216, FillRefUnsigned: true, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true},
	"2.17.6": {DartVersion: "2.17.6", Supported: true, HeaderFields: 6, Tags: TagStyleCidShift1, CIDs: &cidsV217, FillRefUnsigned: true, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true},
	"2.18.0": {DartVersion: "2.18.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV218, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldTypeScalars: true, TopLevelCid16: true, OldPoolFormat: true},
	"2.19.0": {DartVersion: "2.19.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV219, PreV32Format: true, HasTypeParamClassId: true, TypeParamByteScalars: true, OldPoolFormat: true},
	"3.0.5":  {DartVersion: "3.0.5", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV305, PreV32Format: true, HasTypeParamClassId: true, OldPoolFormat: true},
	"3.1.0":  {DartVersion: "3.1.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV325, PreV32Format: true, OldPoolFormat: true},
	"3.2.5":  {DartVersion: "3.2.5", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV325, OldPoolFormat: true, PoolTypeSwapped: true},
	"3.3.0":  {DartVersion: "3.3.0", Supported: true, HeaderFields: 5, Tags: TagStyleCidShift1, CIDs: &cidsV325},
	"3.4.3":  {DartVersion: "3.4.3", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV343},
	"3.5.0":  {DartVersion: "3.5.0", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV343},
	"3.6.2":  {DartVersion: "3.6.2", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV362},
	"3.7.0":  {DartVersion: "3.7.0", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV362},
	"3.8.1":  {DartVersion: "3.8.1", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV362},
	"3.9.2":  {DartVersion: "3.9.2", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV392},
	"3.10.7": {DartVersion: "3.10.7", Supported: true, HeaderFields: 5, Tags: TagStyleObjectHeader, CIDs: &cidsV392},
}

// DetectVersion returns a VersionProfile for the given snapshot hash.
// For supported versions, returns a full profile with Supported=true.
// For known but unsupported versions (e.g. Dart 2.x without CID tables),
// returns a minimal profile with Supported=false.
// For completely unknown hashes, returns a v3.9.2 fallback with empty DartVersion.
func DetectVersion(hash string) *VersionProfile {
	version := knownHashes[hash]
	if version == "" {
		// Unknown hash. Return v3.9.2 profile with empty DartVersion
		// so caller can probe the actual tag style.
		p := *versionProfiles["3.9.2"]
		p.DartVersion = ""
		return &p
	}
	p, ok := versionProfiles[version]
	if !ok {
		// Known version but no profile — known but unsupported.
		return &VersionProfile{
			DartVersion: version,
			Supported:   false,
		}
	}
	return p
}

// ProbeTagStyle reads the first cluster tag using both tag styles and returns
// the profile that produces a valid CID. clusterStart is the byte offset
// where clustered data begins. This is used for unknown snapshot hashes.
func ProbeTagStyle(data []byte, clusterStart int) *VersionProfile {
	// Try each candidate profile and check first-cluster CID plausibility.
	candidates := []*VersionProfile{
		versionProfiles["3.9.2"],  // TagStyleObjectHeader, 5 fields
		versionProfiles["3.2.5"],  // TagStyleCidShift1, 5 fields
		versionProfiles["2.17.6"], // TagStyleCidShift1, 6 fields
		versionProfiles["2.13.0"], // TagStyleCidInt32, 5 fields (split canonical)
		versionProfiles["2.10.0"], // TagStyleCidInt32, 4 fields (no canonical split)
	}

	for _, prof := range candidates {
		cid := probeFirstCID(data, clusterStart, prof)
		if cid > 0 && cid < 200 {
			// Valid-looking CID. Confirm it maps to a known type.
			p := *prof
			p.DartVersion = ""
			return &p
		}
	}
	// Fallback to latest.
	p := *versionProfiles["3.9.2"]
	return &p
}

// probeFirstCID reads the header and first cluster tag, returning the CID.
// Returns -1 on any error.
func probeFirstCID(data []byte, clusterStart int, prof *VersionProfile) int {
	if clusterStart >= len(data)-20 {
		return -1
	}

	// Use a minimal stream reader to skip header fields and read the tag.
	pos := clusterStart

	// Skip header fields using inline VLE decoding.
	// Both ReadUnsigned (endMarker=128) and ReadTagged64 (endMarker=192)
	// use the same terminal condition: byte > 127. They differ only in
	// value decoding, which we don't need here.
	for i := 0; i < prof.HeaderFields; i++ {
		for pos < len(data) {
			b := data[pos]
			pos++
			if b > 127 { // terminal byte
				break
			}
		}
	}

	if pos >= len(data)-4 {
		return -1
	}

	// Decode tag based on tag style.
	switch prof.Tags {
	case TagStyleCidShift1:
		// ReadTagged64: read until byte > 127, subtract 192.
		var val int64
		var shift uint
		for pos < len(data) {
			b := data[pos]
			pos++
			if b > 127 {
				val |= int64(int(b)-192) << shift
				break
			}
			val |= int64(b) << shift
			shift += 7
		}
		cid := int(val >> 1)
		return cid

	case TagStyleObjectHeader:
		// ReadTagged32: read until byte > 127, subtract 192.
		var val int32
		var shift uint
		for pos < len(data) {
			b := data[pos]
			pos++
			if b > 127 {
				val |= int32(int(b)-192) << shift
				break
			}
			val |= int32(b) << shift
			shift += 7
		}
		cid := int((uint32(val) >> 12) & 0xFFFFF)
		return cid

	case TagStyleCidInt32:
		// Read<int32_t>(cid): signed VLE (endMarker=192), value = CID directly.
		var val int64
		var shift uint
		for pos < len(data) {
			b := data[pos]
			pos++
			if b > 127 {
				val |= int64(int(b)-192) << shift
				break
			}
			val |= int64(b) << shift
			shift += 7
		}
		return int(val)
	}
	return -1
}

// VersionFromHash returns the Dart SDK version string for a known hash,
// or empty string if unknown.
func VersionFromHash(hash string) string {
	return knownHashes[hash]
}

```